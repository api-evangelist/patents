---
title: Method, system, and program for merging log entries from multiple recovery log files
abstract: Provided are a method, system, and program for merging independent log entries in a multiple node shared nothing DBMS. Initially, log entries from multiple log entries are combined to form a single log entry sequence. Local transactions are generated from the single log entry sequence and stored in a local transactions structure. In particular, log entries with the same local transaction identifier form a local transaction. Then, local transactions having the same global identifier are merged to form global transactions.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07076508&OS=07076508&RS=07076508
owner: International Business Machines Corporation
number: 07076508
owner_city: Armonk
owner_country: US
publication_date: 20020812
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE PREFERRED EMBODIMENTS","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS","Additional Implementation Details"],"p":["1. Field of the Invention","The present invention relates to a method, system, and program for merging log entries from multiple recovery log files.","2. Description of the Related Art","A database system is one in which data is stored, retrieved, and processed. Data records in a relational database management system (RDBMS) in a computer are maintained in tables, which are a collection of rows all having the same columns. Each column maintains information on a particular type of data for the data records which comprise the rows. Tables in the database are searched using, for example, a Structured Query Language (SQL), which specifies search operations or predicates to perform on columns of tables in the database to qualify rows in the database tables that satisfy the search conditions.","Whenever a business grows, the amount of data stored by the business also grows. Whenever the amount of data grows, so do the demands to the database systems that manage the data. Today, most of the business information is stored and processed in database systems, and the-demands to the database systems that handle this data are tremendous. Despite the fact that these database systems handle terabytes of data, end-users and applications have the same demands to the database systems as they had decades ago, when database systems did not handle as much data. End-users and applications demand high performance from database systems. For example, database systems are expected to provide short response times to user requests and are expected to be always available.","A non-distributed database system fails to meet these requirements. On the other hand, distributed database technology may be able to do so. Distributed database technology refers to a collection of logically related databases distributed over a computer network. Distributed database systems deal with the performance aspect of a database system. By using interconnected computer systems, it is possible to manage large databases of several terabytes and yet provide reasonable response times for complex database queries. DB2\u00ae Enterprise Extended Edition (DB2\u00ae EEE\u00ae) is a product available from International Business Systems, Inc. (IBM) for a distributed database management system. An enterprise is a business that utilizes computers. For further information, see IBM\u00ae DB2\u00ae Universal Database Enterprise\u2014Extended Edition, \u201cQuick Beginnings V7\u201d, Document Number GC09-2963-00, 2000, which is incorporated by reference herein in its entirety.","Distributed database technology was derived in the late 1970s due to a need to integrate data from several data sources into one database system and to achieve improved processing performance. For example, for a large company that manages several terabytes of data, a single database system was not able to handle the large amount of data and provide good performance. A solution to this problem was to exploit the power of parallel computing. But parallelism can only be achieved in a database system if the amount of data is split into several parts and manipulated in parallel. From the need for parallelism, came the need for distribution.","Data replication is the process of copying data from a source database to one or more target databases. Data replication provides many advantages to an enterprise's database system and gives businesses a sophisticated means to improve their database system's availability. Data replication allows businesses to have their data available where the businesses want the data and when the businesses need the data, by maintaining identical copies of a data source in several locations. Data replication is not tied directly to database technology. For example, data replication can also be found in file replication tools.","Data replication becomes more and more important for enterprises today. For example, the performance and the availability of a database system may highly increase by using data replication. DB2\u00ae DataPropagator (DPROPR\u00ae) is a product available from International Business Machines, Inc. (IBM) for relational data replication. For further information, see IBM\u00ae DB2\u00ae Universal Database, \u201cReplication Guide and Reference V7\u201d, Document Number SC26-9920-00, 2000, which is incorporated by reference herein in its entirety.","There is a need in the art for combining distributed database technology and data replication for improved database systems.","Provided are a method, system, and program for merging log entries from multiple recovery logs. Local transactions are recorded within each recovery log using a local transaction identifier. Local transactions are merged to form global transactions across the multiple recovery logs using global transaction identifiers.","In certain implementations, each log entry for a single transaction includes a local transaction identifier, and each recovery log entry involved in commit processing for a global transaction includes a global identifier.","In additional implementations, one or more recovery log entries include a causally ordered, ascending timestamp that can be used to order global transactions.","In further implementations, a method, system, and program for restarting the merging of log entries from multiple recovery logs are provided. Restart information is held in persistent recoverable storage. Each logged transaction is merged and processed using the restart information an entry point is stored for each of the multiple log files. Processing of the multiple log files may be restarted at the entry point for that log file. In certain implementations, a global, ascending, causally ordered commit timestamp of a last processed transaction is stored. In further implementations, a transaction for which the global, ascending, causally ordered timestamp is smaller than a stored global, ascending, causally ordered timestamp is not merged or processed.","The described implementations provide improved techniques to combine distributed database technology and data replication for improved database systems. In particular, multiple log entries in multiple log files may be used to form local transactions and then global transactions.","In the following description, reference is made to the accompanying drawings which form a part hereof and which illustrate several embodiments of the present invention. It is understood that other embodiments may be utilized and structural and operational changes may be made without departing from the scope of the present invention.","In certain implementations of the invention, both distributed database technology and data replication technology are combined to provide an improved data replication solution that works in a distributed database system. In certain implementations, DB2\u00ae DataPropagator (DPROPR\u00ae and DB2\u00ae Enterprise Extended Edition (DB2\u00ae EEE\u00ae) from International Business Systems, Inc. (IBM) are combined. DPROPR\u00ae is IBM's solution for relational data replication, DB2\u00ae EEE\u00ae) is IBM's distributed database management system. The combination provided by implementations of the invention enables an enterprise's data to be available most of the time and nearly everywhere.","In certain implementations, DPROPR\u00ae is enhanced to enable data replication from DB2\u00ae EEE\u00ae. The design extends one component within DPROPR\u00ae, and this component will be referred to herein as a \u201cMerging Independent Log Entries\u201d (MILE) program. Although examples herein will be directed to DPROPR\u00ae, DB2\u00ae EEE\u00ae, and other IBM products, the techniques of the invention are applicable to other products from other sources.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 1A","b":["100","100","102","104","106","108","110","102","104","106","108","110","104","106","108","110","102","104","106","108","110","102","104","106","108","110"]},"The log reader  retrieves data input of the MILE program . Each node in a distributed database system stores a recovery log, which is also referred to as a \u201cdatabase recovery log,\u201d (e.g., as a recovery log file) that describes the changes of all transactions that were performed at that node. For each one of the multiple nodes, the log reader  retrieves log entries (i.e., log records) from the node's recovery log files . The log reader  determines the order of reading the nodes using a node priority list . The output of the log reader  is a single log entry sequence , which contains log entries from all of the recovery log files . During processing, the log reader  stores log entries in a temporary log entry buffer .","The transaction builder  and transaction merger  contain log entry processing logic. From the single log entry sequence  output by the log reader , the transaction builder builds local transactions and stores them into a local transactions structure  for each node (i.e., there is one local transactions memory structure per node for which there are log entries). The transaction merger  creates a mapping from local to global transactions in a global transactions structure . In a cluster of nodes, two or more nodes may participate in a global transaction.","The staging table inserting logic  and restart logic  create the MILE program output and update the restart information. Since both actions happen at approximately the same time, in certain implementations, the staging table inserting logic and restart logic may be combined into one component.",{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 1B","b":["150","102","124","104","124","126","152","106"]},"1. Data Replication","For today's enterprises, data is the key to business. As companies automate their business practices and procedures, they collect and manage large volumes of data. This data often resides in more than one database. As separate organizations (e.g., an accounting department and a human resources department) within enterprises work together, they find that they would like to share certain data with each other. Data replication is a powerful means to achieve this goal. Moreover data replication enhances data availability and system performance.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 2","FIG. 2"],"b":["200","202","204","206","208","200"]},"Data replication is the process of maintaining multiple copies of specified data sets (i.e., replicated data). In the replication process, data changes are captured from a data source and then applied to one or more data targets. Instead of working directly on the data source, applications can then work on the replicas instead. Some benefits of data replication technology include:\n\n","For further information on the benefits of data replication, see Lindsay, Bruce, \u201cData Where You Want It, When You Need It\u201d, DB2\u00ae and Business Intelligence Technical Conference, Florida, Oct. 1\u20135, 2001, which is incorporated by reference herein in its entirety.","Data replication is more complex than simply copying data from location A to location B. The maintenance and administration of replicated data is fairly complex and needs many resources.  illustrates an example scenario for data replication in accordance with certain implementations of the invention. In particular,  illustrates a map  with several locations of an enterprise. The headquarters is located in Chicago , which is responsible for maintaining all customer information in the customer database. The other branches, which are located in New York , Houston , and San Francisco , need to access the customer database . Each branch , , and  is connected to the headquarters  through a WAN connection. The branches , , and  do not need to update the customer database , a read access is sufficient. The branches , , and  operate on copies (i.e., replicas) , , and  of the customer database , which are synchronized with the data in the customer database  at headquarters  periodically, (e.g., once a day).","In the example illustrated in , replication increases the overall system performance and the data availability. The performance increase is achieved by off loading the headquarter's  database system. In particular, accessing the local replicas , , and  at the branches , , and , respectively, is faster and offloads the headquarter's database system. Data availability is also enhanced, since the headquarter's  customer database  can be disconnected and the branches , , and  are still able to query their replicas , , and . Whenever the headquarters  goes online again, new changes to the customer database  get replicated to the replicas , , and  at the branches , , and . In certain implementations, to keep the data amount to a minimum, only the changed data records since the last synchronization process get replicated from the headquarters  to the branches , , and . In certain implementations, a defined subset of the customer database  gets replicated to the replicas , , and  at the branches , , and .","Data replication includes data dissemination and consolidation, which are illustrated in  in accordance with certain implementations of the invention. Data dissemination distributes data from one source  with read\/write capability (i.e., data may be read from or written to the database) to multiple targets  and  having read capability (i.e., data may be read from the databases). Data consolidation integrates data from several sources  and  into one target .  illustrates workload partitioning in accordance with certain implementations of the invention. With workload partitioning, each peer  and  has source data with read\/write capability  and  and target data with read capability  and ","Data replication can be either synchronous or asynchronous. Synchronous, or real time, replication replicates changes from a source to a target at the time the source is updated. With synchronous data replication, the target is an exact copy of the data source at a given time. Synchronous data replication typically uses a two-phase commit protocol, which will be described in further detail below, to protect the data's integrity between the source and the target. While synchronous data replication keeps an exact real time copy of the data source, synchronous data replication does so at the expense of possible loss of availability and performance.","Asynchronous, or non-real time, replication replicates changes to the target in a different transaction scope than the originating transaction. This means there is a time interval lag involved, which can range from a sub-second to hours, depending on the implementation and performance factors. The interval depends on the enterprise's needs and whether the enterprise chooses data dissemination or consolidation. For example, the interval may depend on how up-to-date the data in the replicas needs to be. In implementations discussed herein, the asynchronous replication type will be used for illustration. IBM's DataPropagator is an asynchronous replication solution.","Units of asynchronous data replication are not always whole databases or whole tables. It is possible to replicate a subset of the data source (i.e., a subset of columns, a subset of rows, or both). The definition of the subset may be compared to a SQL Select clause.  illustrates replication information  used to perform asynchronous data replication in accordance with certain implementations of the invention. The replication information  includes identification of a source database, one or more source tables, one or more columns and\/or rows of the source tables, one or more target databases, one or more target tables, and an interval for the synchronization process. This information generates a mapping from the source to the one or more targets.","2 Distributed Database Systems","A distributed database system (DDBS) is a collection of data items stored on multiple computer systems that are interconnected by a network. The computer systems commonly are referred to as nodes or sites and are failure-independent systems. The term site is often used to emphasize the physical distribution for the distributed database system. The nodes can be geographically distributed or located at one physical site and connected by a local area network (LAN). The DDBS distributes a data set (i.e., a database) across the nodes, and the distribution is transparent to users and applications.","Applications submitted by users to a DDBS request actions to be performed in the form of one or more transactions. For recovery (i.e., to apply transactions again that may have been lost, for example, due to a disaster) and rollback (i.e., undoing transactions) purposes, transactions are recorded by the DDBS into a node's recovery log file.","Due to the data distribution over several sites, there exist two types of transactions: local and global. A local transaction updates data on the node on which the local transaction was initiated, and this node is referred to as an originating or coordinator node. A global transaction, in contrast, accesses and updates data on multiple nodes or on a node different from the coordinator node, which is referred to as a participant or subordinate node.","A distributed database system (DDBS) stores data on a series of computers that are interconnected by a communication network. Each computer system stores a data repository, such as a relational database. The DDBS acts as a main layer that integrates the repositories from all systems into a single, logical entity. The fact that the data consists of several partitions is transparent to users and applications.","Similar to a non-distributed database management system (DBMS), a distributed DBMS achieves data integration by storing and managing data in one place. The integration happens on a logical level. On a physical level the data is distributed across a group of sites. The distribution not only includes data, but also DBMS functionality. The four basic properties of a transaction, also referred to as ACID properties, are:\n\n","It is the task of a transaction manager to manage the execution of transactions and to coordinate database requests on behalf of a transaction. A scheduler implements a strategy for the transaction execution order. In order to ensure data atomicity and durability, the transaction manager in a DDBS typically uses a distributed commit protocol, such as a two-phase commit protocol. Use of a distributed commit protocol ensures the atomicity of the transaction and ensures that all participating nodes in a distributed database environment remain in a consistent state.",{"@attributes":{"id":"p-0064","num":"0072"},"figref":"FIG. 6","b":["610","620","630","610","620","630","612","622","632","600","612","622","632","600","610","622","632","620","630","610","600","612","622","632","610","620","630","620","630","610","610","600","620","630","620","630"]},"A distributed database management system (DDBMS) manages the following tasks: data distribution, concurrency control, load balancing, and failure recovery. The data distribution is transparent to users and applications, and a distributed database appears as one logical unit. This ensures compatibility, since the applications do not have to be aware of the data distribution. The goal of concurrency control is to ensure that individual users see a consistent database, although the DDBMS has incorporated updates from many users.","Just as a traditional DBMS hides facts from users and applications about the internal management of a database, a DDBMS also distributes the data within the system in a transparent manner. Instead of showing the data distribution, the DDBMS presents a logical entity of a database. Applications and end-users do not need to be aware of the data distribution and therefore do not need additional changes to work with the DDBMS. One technique for distributing data divides a database into several database fragments according to some criteria (e.g., horizontal, vertical, or hybrid fragmentation) and distributes these fragments across the system. Distributing the data provides improved performance.","One technique for increasing the processing speed of transactions is to exploit the power of parallel and distributed computing. For example, symmetric multiprocessing (SMP) machines that break up complex tasks into several smaller tasks and execute them in parallel provide improved performance. This is achieved by the SMP architecture, which provides several separate processors within the SMP machine that allow this parallelism.","Some DBMSs today support parallelism, but only within the SMP architecture. Typically, many disk operations are performed, but the processors share one common bus to the hard disc. Thus, accesses to the hard disc have to be serialized and the real parallelism is gone.","On the other hand, a DDBMS achieves real parallelism across a system of several computers, where each machine is autonomous to a certain extent. The main demands to such a DDBMS are: high performance (throughput, transactions per second), high availability (nearly zero downtime), good scalability, transparency of data distribution, and high failure tolerance.","A DDBMS is useful for many enterprises, which have the need to integrate information from different data sources. Additionally, a DDBMS provides a higher processing speed over larger data sets. That is, whenever too many users access the database system at once or the amount of data gets too big to be handled efficiently by a DBMS, a DDBMS is used.",{"@attributes":{"id":"p-0071","num":"0079"},"figref":"FIG. 7","b":["700","710","700"]},"Computer network technology  enables distribution of either processing logic, functions or data across a network of several computer systems. Computer network technology  provides means to interconnect several computer systems that may be geographically apart, but still acting as one whole logical system.","The database technology  stores and manages a set of data in one place, a kind of centralization. On the other hand, the computer network technology  is used to distribute resources. Because a goal of database technology is integration of data, rather than the centralization of data, and since integration may be achieved without centralization, database technology  works well with computer network technology . The combination leads to a distributed database system .","The DB2\u00ae Enterprise Extended Edition (DB2\u00ae EEE\u00ae) provides increased processing power. DB2\u00ae EEE\u00ae is a complete homogeneous distributed database system. That is, all databases are from the same logical structure and run on one operating system.","Whenever an enterprise grows, the enterprise faces more and more users accessing the enterprise's database system and the amount of data in the database system grows. In the long run, the enterprise requires a high performance database system that is able to handle a large amount of data with authority and that keeps the response time to user requests low.","The motivation for combining database and computer network technologies came both from the user side and the technology side. From the technology side, there were high performance computers and reliable data communication facilities, which made distributed computing highly available and less expensive than it was a decade ago. So on one side more and more users and applications demand a higher performance from the database system and the other side we have technology progress that supports the demand.","Table fragmentation may occur in distributed databases. Table fragmentation refers to a splitting of a single table in some form. Existing table fragment techniques are vertical table fragmentation, horizontal table fragmentation, and a combination of both vertical and horizontal table fragmentation techniques, which is referred to as hybrid fragmentation. DB2\u00ae EEE\u00ae uses horizontal table fragmentation to divide tables.","Horizontal fragmentation implies the division of relations, i.e. tables, along tuples. This technique can be understood as a SELECT statement on the table, where the WHERE clause determines which tuples go into which table fragment. The vertical table fragmentation technique divides a table by splitting between the table's attributes, i.e. columns. Again, the fragmentation is a SELECT clause, where this time the SELECT clause determines which attributes, i.e. columns, go into which table fragments. The hybrid table fragmentation technique is a combination of both vertical and horizontal fragmentation. For example, a table may be divided vertically, and then one of the vertical table fragments may be divided horizontally.","Database technology and computer network technology may be combined in numerous ways. For example, there are distributed database systems and federated database systems. In a (homogeneous) distributed database system, a database is fragmented (e.g., horizontal, vertical, or hybrid table fragmentation) into several partitions and is distributed across several machines that are interconnected by a network.  illustrates data partitioning in a DDBMS in accordance with certain implementations of the invention. For example, data may be stored in partition  , partition  , or partition  .","The database manager partitions the data, relocates the data within the system, performs query optimization, and more. All this happens transparently to end users and applications, for whom the database appears as a single, logical database. Transparency has the advantage that an end-user or an application does not have to be aware of the fact that the database is distributed across multiple computer systems. A federated database system is a special case of a multi-database system. Certain implementations of the invention are directed to distributed database systems, but the techniques of the invention are applicable to federated database systems.","3. DB2\u00ae DataPropagator","The DB2\u00ae DataPropagator (DPROPR\u00ae) is IBM's solution for asynchronous replication tasks. DPROPR\u00ae enables asynchronous data replication from DB2\u00ae sources to DB2\u00ae targets, and non-IBM sources and targets.  illustrates components of DPROPR\u00ae in accordance with certain implementations of the invention. DPROPR\u00ae consists of several components, including a Capture program , an Apply program , and a control center. The Capture program  captures data changes at the data source. The Apply program  reads the data changes from the Capture program  and applies them to the data target. The control center is the main GUI that helps the user to configure replication tasks by defining the data source, target and many more parameters.","DPROPR\u00ae replicates data asynchronously from and to relational databases. This task is divided into capturing the data changes from the source database (i.e., with the Capture program ) and applying the data changes to the target database (i.e., with Apply). In certain implementations, The Capture program  and Apply are separate computer programs. The Capture program  runs against the source database and processes the source database's recovery log file. The recovery log file is the database's activity protocol. Each change to data records, i.e. updates, inserts, and deletes are recorded in the recovery log file. From the contents of the recovery log file, the Capture program  deduces changes that occurred at the data source and stores them into staging tables. The Apply program  runs against one or more data targets. The Apply program  reads the data changes that have been captured by the Capture program  and applies them to the data target.","The Capture program  is a log based replication solution (i.e., the Capture program  scans the recovery log file of a database for data changes). The Capture program  scans the recovery log file of a database sequentially and examines each recovery log file entry, i.e. a log entry. A log entry is a data structure that describes the action that was performed on an object within the database. In DB2\u00ae, a log entry consists of one common log entry header and a record. The common log entry header, which is referred to as a Log Manager Log Record Header, contains information detailing the log entry and transaction information, such as a unique transaction identifier (TID). The transaction identifier allows the log entries relating to the same transaction to be identified uniquely within the recovery log file for a non-distributed DBMS. All log entries written by a single transaction contain the same transaction identifier. The transaction identifier ties together all log entries that belong to one single transaction. The end of a transaction is signaled with a Commit or Abort log entry, but the beginning of a transaction does not necessarily write a specific log entry, such as Begin.","In a DB2\u00ae recovery log file, each log entry is uniquely addressed by a log sequence number (LSN), which is a relative byte address for the first byte of the log entry. Since the log file of a database and its log entries provide information about database activity that happened in the past, complete transactions may be extracted from the log file. In particular, the Capture program  extracts transactions by scanning the recovery log file of a database for specific log entries (e.g., log entries that belong to tables that are registered as replication sources within the database) and extracts essential information from the recovery log file. Internally, the Capture program  builds a transaction in memory, until the Capture program  sees a Commit log entry for this transaction. The Capture program  does not necessarily commit the transaction immediately to the staging table. The commitment to the staging table happens after a specified interval has elapsed, and this interval is referred to as a commit interval. Records describing the changes of each transaction within the memory of the Capture program  are inserted into the staging table, which supplies data to the Apply program .","A database's recovery log file contains actions recorded by the data manager (including a Long Field) by a LOB and Datalink manager, and by a transaction manager. The data manager protocols handle data changes on rows (e.g., updates, inserts, and deletes). The transaction manager coordinates transactions.","The term warm start refers to the restart of a program, such as the Capture program , with the \u201cwarm start\u201d option. The warm start option allows the Capture program  to begin where the Capture program  had stopped at its last termination. Thus, instead of reading the source recovery log file from the beginning, the Capture program  continues reading the recovery log file from a previously saved position. In particular, during a warm start the Capture program  continues reading the log file from a certain position, which has been stored during the last run of the Capture program .",{"@attributes":{"id":"p-0087","num":"0095"},"figref":["FIG. 10","FIG. 10"],"b":["1","2","3","1","1","2","2","3","3","1004","1","3","2","1004","2","2","1004","1002"]},"Thus, the entry point (i.e., \u201cstarting point\u201d or \u201crestart point\u201d) for the Capture program  is stored in a specific LSN value labeled as \u201cmin inflight LSN\u201d . An entry point is an address that is recorded within a memory structure, such as a table and specifies an earliest reported log entry for a transaction that has not completed due to some failure (e.g., system failure) or planned termination of the Capture program .","The term \u201ccold start\u201d refers to a situation in which the Capture program  starts \u201cfrom scratch.\u201d All replicas are re-initialized and the Capture program  reads the recovery log file of the database from the current end of the log.","DB2\u00ae provides a log read application programming interface (API) to retrieve log entries from a recovery log file. The log read API returns log entries for tables that have been created with the \u2018data capture\u2019 changes attribute. By calling the log read API, the Capture program  retrieves log entries that are relevant for data replication. In this manner, overhead is minimized.","Restart is a feature within the Capture program  that ensures that replication of changes can be resumed after a restart. The restart of the Capture program  refers to a situation in which the Capture program  has been manually stopped by the user or stopped without warning due to, for example, a hardware or software failure. A warm start is performed the next time the Capture program  starts up. For a restart, two LSNs are stored. One LSN is the entry point for a restart. This LSN ensures that the Capture program  does not miss any log entries. The second LSN, named MAX_COMMIT_LSN, ensures that the Capture program  does not capture log entries from a single transaction more than once.","4. DB2\u00ae Enterprise Extended Edition","The DB2\u00ae Enterprise Extended Edition (DB2\u00ae EEE\u00ae) is a distributed database system product. DB2\u00ae EEE\u00ae provides the ability to distribute relational databases across multiple nodes. Every node runs on the same operating system. Also, in the DB2\u00ae EEE\u00ae context the term data partitioning refers to data distribution. The partitioning is transparent to end users and applications. Thus, end users and applications work on a partitioned DB2\u00ae EEE\u00ae database as if the partitioned DB2\u00ae) EEE\u00ae database were a single logical entity. The data distribution is also fully managed by the DB2\u00ae EEE\u00ae DBMS. DB2\u00ae EEE\u00ae uses the primary key of a table's tuple. In certain implementations, a user has no influence on how a table's data gets distributed. The participating nodes for a DB2\u00ae EEE database are defined by an administrator.","DB2\u00ae EEE\u00ae uses a shared-nothing hardware architecture. This architecture is a version of DB2\u00ae that supports the distribution of a single database over several machines that are interconnected through a high speed network. DB2\u00ae EEE\u00ae belongs to the family of homogenous distributed database systems. DB2\u00ae) EEE performs a horizontal partitioning on data tables. The distribution of the data rows over the nodes is determined by a hash function, which uses the partitioning key of a table as an argument of the hash function.","The recovery log file structure on each node is the same as in a non-partitioned DB2\u00ae database. The DB2\u00ae EEE\u00ae system uses a derivative of the two-phase commit protocol (2PC), which is the presumed commit protocol (PrC). PrC has been discussed in \u201cAn Argument in Favor of the Presumed Commit Protocol,\u201d Yousef J. Al-Houmaily, et al., University of Pittsburgh, which is incorporated by reference herein in its entirety. For the partial ordering of the events by the distributed computing system used by DB2\u00aet EEE\u00ae, the DB2\u00ae EEE\u00ae) transaction manager uses a Lamport clock technique for the timestamp generation. The Lamport clock technique is described in \u201cTime, Clocks, and the Ordering of Events in a Distributed System,\u201d by Leslie Lamport, Communications of the ACM, Volume 21 Number 7, July 1978, which is incorporated by reference herein in its entirety. The timestamp generation results in a causally ordered, ascending timestamp.","5. Merging Independent Log Entries (MILE) Program","In certain implementations, a MILE program is provided to enable DPROPR\u00ae and DB2\u00ae EEE\u00ae to work together. The MILE program works with a partitioned source database (rather than a non-partitioned source database). Thus, there are multiple physical database partitions and recovery log files. The MILE program is a log based, asynchronous replication solution that performs asynchronous data replication tasks at the data source, i.e. capturing the data changes from a DB2\u00ae EEE\u00ae source database and storing them externally for use by, for example, Apply program .",{"@attributes":{"id":"p-0096","num":"0104"},"figref":"FIG. 11","b":["1100","1110","1112","1112","1110","1114","1116","1118","1116","1122","1120","1124","1124","1120","1110","1118","1114","1122","1116"]},"The restart logic  keeps one LSN per node as the entry point for the MILE program. This LSN may be referred to as \u201cMININFLIGHT_LSN.\u201d Additionally, in certain implementations, the max commit LSN  () has been replaced by a global timestamp of the last transaction processed by the CD inserter . The global timestamp prevents the MILE program from capturing a transaction twice.","The multiple recovery log files are accessed and read by the MILE program. The MILE program merges the log entries from each node to local transactions, respecting the log entries' local order. The local transactions are merged to global transactions, and the MILE program determines a correct order of the global transactions. The restart logic is enhanced for multiple recovery log files. In particular, the restart table stores restart points for multiple recovery log files on multiple nodes. Also, the end-of-log (EOL) case is properly managed while reading the recovery log files. When the end-of-log has been reached, there is no sequentially next log entry.","DPROPR\u00ae uses an asynchronous log read API (e.g., DB2\u00aeAPI) to retrieve log entries from a node. For further information, see IBM DB2\u00ae Universal Database, \u201cAdministrative API Reference V7\u201d, Document Number SC09-2947-00, 2000, which is incorporated by reference herein in its entirety. The prerequisite for the log read API usage is an active connection to the node. If the connection call is made without specifying a node, DB2\u00ae EEE\u00ae chooses a node by default. This node can be different with every connection call. To determine which node the MILE program wants to connect to, the MILE program sets either an environment variable or an internal API value, which is an API parameter.","In order to process the node's log entries, the MILE program determines which nodes belong to the source database, establishes a connection to each node, and retrieves a node's recovery log file contents through the log read API. Since DB2\u00ae EE\u00ae keeps a database's partitioning transparent, the source database appears as a single logical entity.","The MILE program determines which nodes belong to the partitioned DB2\u00ae EEE(database. The identity of the nodes is used to make a connection to the specific node. The determination of the participating nodes takes place on a physical level. After the identifiers of the participating nodes are retrieved, the MILE program establishes a database connection to each node. The connection to a node is the prerequisite for the use of an asynchronous read log (arl) interface. The asynchronous read log interface is then used for retrieving the log entries from a node. The MILE program then processes the contents of the log entries in order to build transactions.","The access of multiple recovery log files may be performed with access and scan one recovery log file at a time (i.e., a \u201csingle log reader approach\u201d) or with access and scan of all recovery log files simultaneously (i.e., a \u201cmultiple log reader approach\u201d). The first alternative, the single log reader approach, is beneficial when there is an extremely large number of nodes, and thus recovery log files in the system. The second alternative, the multiple log reader approach, is beneficial if executed on an SMP machine with many resources, since the multiple log reader approach requires one separate thread for each node. The multiple log reader approach requires additional synchronization effort on the simultaneously accessed recovery log files. Although the multiple log reader approach promises a higher performance on the MILE program input processing, the multiple log reader approach does so for a more complex design and implementation. Thus, in certain implementations, the single log reader approach is applied. The techniques of the invention may be extended to the multiple log reader approach, and, in certain implementations, the multiple log reader approach is applied.","The output of the single log reader approach is a single, logical log that is generated from multiple physical logs. The MILE program stores the logical log entries internally in memory. The logical log is processed to extract the transactions. Since the single log reader approach accesses and scans one recovery log file at a time, the single log reader approach controls the concurrency of log accesses. The single log reader approach determines the recovery log file that will be scanned next and the point at which the scanning of the determined recovery log file will stop.","With the single log reader approach, log entries have unique log sequence numbers (LSNs) and timestamps that are unique and always ascending. The single log reader approach generates a logical log from multiple physical logs by catenating log entries from different recovery log files at different nodes. The LSNs of the log entries are extended to render them unique across nodes, by, for example catenating a log entry's LSN with its corresponding node identifier. A node identifier is unique across nodes. By this LSN extension, a log entry is uniquely addressable in the logical log.","Throughout the log entry sequence, the timestamps appearing in selected ones of the log entries are ascending. The transaction manager (TM) log entries contain timestamp information. For any timestamp Tn appearing in a transaction manager log entry Cn, the following condition is true: Cn\u22121.Tn<Cn.Tn<Cn+1.Tn< . . . The transaction builder and\/or the transaction merger use the timestamp to order the log entries of the merged log. The order of the data manager log entries is the same as their order in the recovery log file.",{"@attributes":{"id":"p-0106","num":"0114"},"figref":"FIG. 12","b":["1200","1210","1220","1220","1200","1210"]},"5.1 Building Local Transactions","From the single log entry sequence, or logical log, that has been generated by the single log reader technique, the MILE program builds local transactions. Since in DB2\u00ae EEE\u00ae there exist local and global transactions, the MILE program provides a log entry merging technique and a transaction merging technique. The log entry merging technique merges a node's log entries together to local transactions, and the transaction merging technique merges these local transactions back to global transactions.","The MILE program builds local transactions by catenating log entries with identical transaction identifiers (TIDs), which is illustrated in  in accordance with certain implementations of the invention.  illustrates a recovery log file  for node  with several log entries. The log entries with identical TIDs were written by the same transaction. The TID is stored in each data manager (DM) and transaction manager (TM) log entry. A transaction identifier for a log entry that updates, inserts, or deletes data is associated with a data manager log entry . A transaction identifier for a log entry that commits or aborts a transaction is associated with a transaction manager log entry . Additionally, besides the local transaction identifier (TID), transaction manager log entries contain the global transaction identifier (GTID) of the global transaction. All transaction manager log entries for a same global transaction contain the same global transaction identifier value. Each TID is a node-local TID (rather than a global TID). The Commit log entries  and  with TID1 and TID2 indicate that the transactions had been successfully committed to the database.","While concatenating the log entries with identical TIDs, the MILE program maintains the log entry's local order. This order reflects the order the data changes took place in the node and is used to ensure data consistency.","5.2 Merging Local Transactions to Global Transactions","The building of the local and global transactions is performed by processing the single log entry sequence, which is the output of the single log reader technique. To reflect all the data changes that a distributed transaction made, the local transactions from the nodes are merged to a single, global transaction.","At the time a global transaction is executed against the distributed database, the global transaction generates at least one local transaction. If the local transaction is on the coordinator node, it is a solely local transaction, thus not global anymore. If at least one local transaction is on a node other than the coordinator node, i.e. on a subordinate node, the transaction is global.",{"@attributes":{"id":"p-0112","num":"0120"},"figref":"FIG. 13","b":["1400","1","1400","1410","1410","1","1420","1410","1422","1424","2","1430","1410","1432","1434","1400","1422","1432","1422","1432","1410","1","1400","1","2","1422","1432","1","2","1","2","1","1400","1","2","1424","1434"]},"From the type of the transaction manager (TM) log entry, the MILE program decides whether a transaction has been normal, local, or aborted. The type of the log entry is in the log entry that indicates the end of the transaction (e.g., a Commit entry). In DB2\u00ae EEE\u00ae, a TM log entry is one of the following types: Normal Commit, Normal Abort, MPP Prepare (also referred to as subordinate Prepare to Commit), or MPP Commit (also referred to as a coordinator commit).","With a Normal Commit log entry, the DBMS indicates that the transaction has been local on the node and no other nodes were involved in this transaction. This is a normal transaction. No merge of local transactions is necessary, since only this node was affected by the transaction.","A Normal Abort log entry indicates that the transaction has been aborted. Regardless of whether there have been other local transactions on other nodes, the transaction did not make any changes to the database. The capturing of this transaction can be discarded, since the DBMS performed a rollback at this point of time.","An MPP Prepare or MPP Commit log entry indicates that the DBMS had to perform a two-phase commit for this transaction. The MPP Prepare and MPP Commit are said to be of the kind related to the two-phase commit protocol. This means that there has been at least one more local transaction on another node, and the transaction is a local transaction that is part of a global transaction. Therefore the MILE program performs a transaction merge. The merge of local transactions is done using a second transaction identifier. Thus, in addition to a local transaction identifier, a MPP Prepare and MPP Commit log entries include a global transaction identifier (\u201cglobal TID\u201d or \u201cGTID\u201d). This global TID is stored in every MPP log entry, i.e. MPP Prepare and MPP Commit.",{"@attributes":{"id":"p-0117","num":"0125"},"figref":["FIG. 15","FIG. 15"],"b":["1","1500","2","1520","1500","1520","1502","1522","1","2","1","1540","1542","1540","1542"]},"After the local transactions from the different nodes have been merged together to global transactions, the correct order of the global transactions among each other is determined by the MILE program. This order is the same order in which transactions have been committed to the source database. The MILE program determines the order using the timestamp in the transaction's transaction manager log entries (i.e., within a regular Commit or an MPP Commit or MPP Prepare log entry). In certain implementations, the data manager (DM) log entries do not contain a timestamp.","In certain implementations, DB2\u00ae EEE\u00ae uses the Lamport clock technique, and so the timestamps determine the partial ordering of the transactions. Based on this timestamp, the MILE program is able to determine that \u201clog entry A happened before log entry B\u201d without knowing at what time they were actually written. This statement is consistent throughout all nodes participating in the DB2\u00ae EEE\u00ae database and is sufficient for maintaining the right ordering among the transactions.","5.3 Handling Multiple Warmstart Positions","A warm start increases the performance of the MILE program by allowing the MILE program to continue processing where the MILE program left off at the last program termination. Since there are multiple recovery log files in a DB2\u00ae EEE\u00ae database, there are also multiple restart positions (i.e., entry points or starting points) for a warm start. For a warmstart, the MILE program avoids capturing a transaction more than once. The MILE program also ensures that a transaction is not missed or read partially. There are three approaches to achieve these goals:\n\n","The first approach is the most straightforward approach, while the third approach is more complex. The third approach requires little update effort while updating the restart table, but requires more processing (e.g., since data needs to be converted into a timestamp) while starting up the MILE program. In certain implementations, the second approach was selected because it provides a good balance between the needed time for updating the restart table and the time necessary for the restart. The techniques of the invention are applicable to the first and third approaches.","In the DB2\u00ae EEE\u00ae case there are multiple recovery log files, and the LSNs can not be used to determine the ordering of the log entries. Also, each recovery log file has a set of restart information, since the MILE program reads the logs in different \u201cspeeds\u201d (i.e., more log entries may be read from one log rather than another, depending on what is in each log). That is, the MILE program may be at different positions in different log files. Since the MILE program deals with several log files, the progress of the log reader within each log file is different whenever the MILE program terminates.","The MILE program handles multiple restart positions.  illustrates the MILE program at different positions in different recovery log files in accordance with certain implementations of the invention. In particular, for recovery log file , the MILE program is at position , while for recovery log file , the MILE program is at position . For each node, the MILE program has a valid entry point. This entry point LSN provides an entry point in the log file, from which the MILE program can continue scanning the log, and a timestamp, from which the MILE program can determine whether a transaction has been previously processed.","Whenever the log read API hits the end of a node's recovery log file, the log read API returns an end-of-log (EOL) return code to the caller. In this case the DBMS did not write any new log entries to the recovery log file yet. With the return code, the log read API also returns a virtual timestamp (vts). The virtual timestamp is the timestamp the DBMS would have written at the time the EOL situation happened if a timestamp would have been needed.","Since the MILE program handles multiple recovery log files, the logic for handling an end-of-log (EOL) case differs from the Capture program  implementation due to the reading order of the recovery log files. Whenever the Capture program  encounters the end of a recovery log file, the log read API returns no more log entries from the recovery log file and returns a code for EOL. In certain implementations, although EOL is returned, DB2\u00ae may still be writing log entries to the recovery log files. For a DB2\u00ae EEE\u00ae database, it is possible that only one out of 10 log files reports an EOL situation. Regardless of how many log files report an EOL situation, the MILE program is able to handle the EOL situations. The MILE program gets a timestamp (e.g., a Lamport clock value) along with an EOL state. The timestamp is used to determine what activity is happening in logs relative to each other and which log should supply the next entry for the merged, logical log.","6. MILE Design",{"@attributes":{"id":"p-0126","num":"0137"},"figref":"FIG. 17","b":["1700","1700","1702","1704","1706","1708"]},"The log reader logic  retrieves data input of the MILE program , i.e. the log entries of the node's recovery log files. The output of the log reader logic  is a single log entry sequence which contains log entries.","From the output of the log reader logic (i.e., the single log entry sequence), the transaction builder logic  builds local transactions  and stores them into a local transaction memory structure for use by the transaction merger logic . The transaction merger logic  generates global transactions  (i.e., creates a mapping from local to global transactions in the global transaction structure).","The staging table inserting logic  uses staging table  to store data from log entries, while restart table  stores restart points for each one of multiple recovery log files. In certain implementations, the staging table inserting logic and restart logic may be combined into one component.","6.1 Log Reader","The log reader is responsible for MILE program's input. The log reader accesses the recovery log files and prepares the contents for the Transaction Builder. The log reader's functionality is to determine the nodes of the DB2\u00ae EEE\u00ae source database and connect to each node; to retrieve log entries from the nodes and concatenate them to a single log entry sequence; and to handle an end-of-log case while accessing the recovery log files.","To determine which nodes participate in the DB2\u00ae EEE\u00ae source database, the log reader reads a configuration file (e.g., \u2018DB2nodes.cfg\u2019 file) that is stored on each DB2\u00ae EEE\u00ae node. From this configuration file, the log reader determines the names of all nodes that belong to the DB2\u00ae EEE\u00ae source database. With the node's names, the log reader establishes a connection to each node. The log reader maintains connections to all the nodes, but, in certain implementations, one connection at a time is active. Within the active connection, the log reader calls the log read API to retrieve a node's log entries.","The log read logic within the log reader controls the access and scanning of the recovery log files. The log read logic determines which log will to be accessed next and how far the log will be scanned. The output of the technique is a single log entry sequence created from multiple recovery log files.",{"@attributes":{"id":"p-0133","num":"0144"},"figref":"FIGS. 18A and 18B","b":["1800","1802","1804"]},{"@attributes":{"id":"p-0134","num":"0145"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"node_name* determine_next_node (NPL)"]},{"entry":[{},"{"]},{"entry":[{},"determine entry in NPL with MIN(timestamp);"]},{"entry":[{},"return entry's node_name;"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"In block , the log reader determines whether node picked from the node priority list is one that has been previously read by the log reader. In this case, the log reader does not need to switch the context\/connection to the node and processing continues to block . Otherwise, if it is a different node, the log reader switches the active connection to the new node (block ) and continues to block . The following pseudocode may be used to determine whether to switch connections:",{"@attributes":{"id":"p-0136","num":"0147"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"boolean same_node (node_name)"]},{"entry":[{},"{"]},{"entry":[{},"IF node_name = active_node_name"]},{"entry":[{},"{ return TRUE; }"]},{"entry":[{},"ELSE { return FALSE; }"]},{"entry":[{},"}"]},{"entry":[{},"Void switch_connection (node_name)"]},{"entry":[{},"{"]},{"entry":[{},"set current connection inactive;"]},{"entry":[{},"switch connection to node_name;"]},{"entry":[{},"set active_node_name = node_name;"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"In block , the log reader fetches a log entry in the recovery log file of the selected node. For example, the log reader may call a log read API to retrieve the next log entry from the node. In certain implementations, the log read API returns multiple log entries to a log reader buffer. The log reader calls the log read API when the log reader buffer is empty. The log reader determines whether it is at the end of the recovery log file (block ). In particular, if no more log entries are in the recovery log file, the log reader receives an end-of-log indicator from the log read API. If a log entry is retrieved, processing continues to block , otherwise, processing continues to block .","In block , the log reader determines whether the log entry was a transaction manager log entry. If so, processing continues to block , otherwise, processing continues to block . In block , the log reader stores the log entry into a temporary log entry buffer and returns to block  to fetch another log entry.","In block , the log reader extracts a timestamp from the log entry. In block , the log reader determines whether the timestamp is less than the minimum timestamp in the node priority list. If so, processing continues to block , otherwise, processing continues to block . In block , the log reader moves the log entry from a temporary buffer to the log entry buffer and returns to block  to fetch another log entry. In block , the log reader updates the node priority list with the new timestamp entry value for the node and proceeds to block .","Returning to block , if the log reader received an end-of-log (EOL) condition, which occurs whenever the log read API does not return any more log entries because it has encountered the end of the node's recovery log file, processing continues to block . In block , the log reader receives a virtual timestamp from the log read API. The virtual timestamp is a timestamp that the DBMS would write at that moment and is referred to as a \u201cvirtual\u201d timestamp. The \u201cvirtual\u201d timestamp is used to determine whether the current active log should supply the logically next log record. If the \u201cvirtual\u201d timestamp is the minimal timestamp of the node priority list, the MILE program repeatedly queries the log read API until the \u201cvirtual\u201d timestamp is no longer the minimal timestamp of the node priority list or a newly added log entry is returned. If this timestamp is not the smallest one, the log reader continues with node priority list logic. When the log reader tries to read the log file (that reported the end-of-log before) later again, it is likely that another end-of-log condition will not occur.","In particular, in block , the log reader determines whether the virtual timestamp is less than the minimum (i.e., smallest) timestamp in the node priority list. If so, processing continues to block , otherwise processing continues to block .","If the log reader encounters a data manager (DM) log entry, the record is stored in the log entry buffer (block ) and the log reader continues with reading the next log entry from the same log file. This loop is exited when the log reader reads a log entry of the transaction manager (TM) type.","6.2 Transaction Builder","In certain implementations, a log merger is used to concatenate log entries, while a transaction builder is used to build a transaction using one or more log entries. In certain implementations, the log merger and transaction builder may be merged to form one component.","The transaction builder processes the output data structure, i.e. the log entry sequence of the log reader. The transaction builder builds the local transactions from the log entry sequence. , B, and C illustrate logic performed by the transaction builder and log merger in accordance with certain implementations of the invention. Control begins at block  when the transaction builder determines whether the log merger has stopped. If the log merger has stopped, processing terminates at block , otherwise, processing continues to block . The log merger first reads a log entry from the log entry sequence (block ), which has been generated by the log reader and stored in a log entry buffer. In block , the transaction builder determines whether the log entry buffer is empty. If the log entry buffer is empty (i.e., contains no more log entries), processing continues to block , otherwise processing continues to block . In block , the log merger determines whether the log reader is stopped (i.e., whether the log reader is continuing to read log entries and add them to the log entry buffer). If the log reader has stopped, the log merger will stop (block ). If the log reader has not stopped, the log merger will fetch another log entry (block ). In particular, if the log entry buffer is empty, but the log reader is still running, it is likely that the log entry sequence will be filled with log entries again. In this case, the log merger sleeps for a while or waits for a wake up signal from the log reader.","Once the log merger retrieves a log entry from the log entry sequence, the log merger distinguishes between a data manager (DM) log entry and a transaction manager (TM) log entry. In block , the log merger determines whether the log entry is a data manager log entry. If so processing continues to block . Otherwise processing continues to block .","In the case of a DM log entry, the log merger checks whether the transaction identifier (TID) for this node ID has already been stored (i.e., whether the TID and node number are known) (block ). If the TID is not known, the log merger creates a new transaction entry for this TID and node ID in the local transactions memory structure (block ). Once the entry has been created, or if the TID and node number are known, the log merger attaches the DM log entry information to the transaction in the local transactions memory structure (block ). After doing this, the log merger continues to block .","In block , the log merger determines whether the log entry is a transaction manager two-phase commit log entry. If so processing continues to block . Otherwise, processing continues to block . In block , the log merger associates a global transaction identifier (GTID) with the local transaction identifier (TID) in the log entry.","In block , the log merger determines whether the log entry indicates a commit from a coordinator node. If so, processing continues to block , otherwise processing continues to block . In block , the log entry is ignored and processing continues to block .","In block , the log merger determines whether a timestamp is less than a restart maxCommit. If so, processing continues to block , otherwise, processing continues to block . If a commit has been received, transaction merger logic is started (block ) and processing continues to block . That is, in case the log merger encounters a TM log entry (i.e., a commit), the log merger branches towards the transaction merger logic. In block , the log merger ignores or removes all local transactions with the same GTID. In certain implementations, processing continues from block  to block . In certain implementations, processing continues from block  to block .","6.3 Transaction Merger","The transaction merger works on the set of local transactions that is created by the log merger. The transaction merger takes all local transactions belonging to a single global transaction and ties them together. From there on, the global transactions are ready for publishing to a staging table or to a persistent queue.","Before any local transactions can be merged together by the transaction merger, the transaction merger ensures that all local transactions have been built up by the log merger. When it comes to the merging of the local transactions, the log merger determines how many nodes participate in a transaction. This is needed so no local transaction information is missed. In certain implementations, the determination is based on the lowest captured timestamp of all log files and the MPP log entry ordering within DB2\u00ae EEE\u00ae. The smallest (i.e., earliest) \u201cglobal\u201d timestamp is referred herein as MinGlobalTS. MinGlobalTS is determined by a minimum technique working on the local transactions memory structure. In particular, the timestamp in the MPP Commit (i.e., coordinator Commit) log entry of any transaction is greater than the timestamps of MPP Prepare (i.e., a subordinate Prepare to Commit) log entries. That is, when a coordinator node commits, the coordinator node records a commit log entry in a recovery log file. When a subordinate node receives a Prepare to Commit from a coordinator node, the subordinate node records a Prepare to Commit log entry in a recovery log file. If the minimum timestamp of the node priority list is the timestamp of the coordinator commit log entry, all the local transactions for this global transaction have been captured.",{"@attributes":{"id":"p-0152","num":"0163"},"figref":"FIG. 20","b":["2000","2002","2004","2008","2006","2006","2000","2002"]},{"@attributes":{"id":"p-0153","num":"0164"},"figref":"FIG. 21","b":["2100","2110","2120","2100","2110","2120","2120","2130","2100","2110","2100","2132","2100","2134","2110","2120","2138"]},"Physically, the database consists of n nodes, where each node maintains a recovery log file. In order to capture the data changes from the source, the MILE program processes n recovery log files. The MILE program is also able to properly manage local and global transactions. In particular, the MILE program receives the multiple recovery log files as input. In certain implementations, the output of the MILE program matches the output of the Capture program  to ensure compatibility to the existing Apply program . For example, the structure of the staging tables remain unchanged. Likewise, the partitioning of the DB2\u00ae EEE\u00ae source database is transparent for the MILE program, since it is operating on the application level.","In summary, in certain implementations, the MILE program determines changes caused by a single transaction that spans multiple, physical database nodes and determines transaction order when transaction changes are recorded in multiple database recovery logs containing log entries in support of transaction recovery and the two-phase commit protocol. In particular, a globally unique transaction identifier for each transaction is recorded in the log entries pursuant to the two-phase commit protocol, and multiple log entries in multiple database recovery logs may correspond to one transaction. A causally ordered, ascending timestamp value is maintained in the log entries pursuant to the two-phase commit protocol. All log entries related to a single transaction in a single database recovery log are identically marked with a unique mark to the given transaction in the given recovery log. With this information, local and global transactions are identified. The log entries describe changes to the database made by application driven transactions.","The log entries of each recovery log are sequentially examined. A logically next log entry is the next log entry from a recovery log having a minimal preceding causally ordered, ascending timestamp in an entry of the kind related to the 2-phase commit protocol. The logically next database recovery log entries are combined into groups marked identically as belonging to a same transaction within a given one of the recovery logs, and the log entries of the combined group are ordered by the order dictated by the sequential examination. When a log entry of an MPP Prepare (i.e., a subordinate Prepare to Commit) entry kind or a MPP Commit (i.e., a coordinator commit) entry kind is encountered, a combined group of identically marked entries is identified as a completed combined group identified by globally unique transaction identifier (e.g., GTID). When a log entry of the MPP Commit (i.e., coordinator commit) entry kind is encountered, all completed combined groups identified by the globally unique transaction identifier are combined into a complete transaction, with the complete transaction being the next transaction in a transaction order.","When there is no sequentially next entry for one of the recovery logs (e.g., an end of log condition), the causually ordered, ascending timestamp value that would be maintained in a next log entry is generated.","In certain implementations, the causally ordered, ascending timestamp is the greater of a current time (e.g., based on Greenwich Mean Time (GMT)) or a number greater (e.g., one greater) than the last generated or observed causally ordered, ascending timestamp. That is, the timestamp generated is greater than any previously generated timestamp and also greater than any timestamp received in a message relating to the two phase commit protocol. The greater of the current time (e.g., GMT) and a number greater (e.g., one greater) than the last generated or observed causally ordered, ascending timestamp is passed in a two-phase commit protocol message or applied to transaction manager log entries.","In certain implementations, there are no recovery log entries of the coordinator commit kind, but an entry of single subordinate commit kind is available. In this case, local transactions and global transactions are formed upon receiving this kind of Commit.","In certain implementations, the MILE program coordinates the processing of complete transactions with specific log entries of each of several recovery logs. The MILE program is robust to system failures. In certain implementations, complete transactions are processed exactly once by recoverably updating a database or other recoverable object. Operations on a database are recoverable or nonrecoverable, and those that are recoverable may be applied to the database after, for example, a system failure. Thus, recoverably updating a database refers to updating the database so that it may be recovered. The address of the earliest entry point for a transaction which is not complete and not yet processed in each recovery log is recorded, along with the causally ordered, ascending timestamp of the log entry of the commit kind for the most recently completed and processed transaction. The recoverable changes of completed transactions, the earliest reported entry points for incomplete transactions (i.e., points in the recovery log at which an incomplete transaction would start upon a warm start), and the causally ordered, ascending timestamp are atomically committed, along with the recoverable changes pursuant to the processing of completed transactions (e.g., inserts into CD tables).","In certain implementations, a recovery log has no outstanding reported entries relating to an incomplete transaction (e.g., end of log or nothing to report). Then, the address of the next log entry that could be reported from that recovery log is recorded. That is, when processing stops while a transaction is incomplete (i.e., inflight), upon restart, the recovery log is read from the beginning of the earliest incomplete transaction and this beginning is an entry point that is recorded. Transactions that were completed and processed may occur while earlier log entries for incomplete transactions remain to be processed. Recoverably recording the global timestamp of the most recently completed and processed transaction allows avoiding the re-processing of completed transactions.","In certain implementations, the MILE program resumes determining changes and transaction order following a failure of normal termination. Initially, addresses of the earliest log entries for transactions which are not complete and the causally ordered, ascending timestamp are retrieved. Each of the recovery logs is examined at the retrieved addresses. Completed transactions whose causally ordered, ascending timestamp from a log entry of the commit kind is less than or equal to the retrieved causally ordered, ascending timestamp are not processed (i.e., they are ignored).","IBM, DB2, DPROPR, and EEE are trademarks of International Business Machines, Inc. of Armonk, N.Y.","The merging independent log entries technique may be implemented as a method, apparatus or article of manufacture using standard programming and\/or engineering techniques to produce software, firmware, hardware, or any combination thereof. The term \u201carticle of manufacture\u201d as used herein refers to code or logic implemented in hardware logic (e.g., an integrated circuit chip, Programmable Gate Array (PGA), Application Specific Integrated Circuit (ASIC), etc.) or a computer readable medium, such as magnetic storage medium (e.g., hard disk drives, floppy disks, tape, etc.), optical storage (CD-ROMs, optical disks, etc.), volatile and non-volatile memory devices (e.g., EEPROMs, ROMs, PROMs, RAMs, DRAMs, SRAMs, firmware, programmable logic, etc.). Code in the computer readable medium is accessed and executed by a processor. The code in which preferred embodiments are implemented may further be accessible through a transmission media or from a file server over a network. In such cases, the article of manufacture in which the code is implemented may comprise a transmission media, such as a network transmission line, wireless transmission media, signals propagating through space, radio waves, infrared signals, etc. Of course, those skilled in the art will recognize that many modifications may be made to this configuration without departing from the scope of the present invention, and that the article of manufacture may comprise any information bearing medium known in the art.","The illustrated logic of , A, B, A, B, and  indicates certain events occurring in a certain order. In alternative implementations, certain operations may be performed in a different order, modified or removed. Morever, steps may be added to the above described logic and still conform to the described implementations. Further, operations described herein may occur sequentially or certain operations may be processed in parallel. Yet further, operations may be performed by a single processing unit or by distributed processing units.",{"@attributes":{"id":"p-0166","num":"0177"},"figref":"FIG. 22","b":["2200","2202","2204","2206","2206","2206","2204","2202","2208","2210","2202","2212","2202","2204","2202"]},"The foregoing description of the preferred implementations of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. It is intended that the scope of the invention be limited not by this detailed description, but rather by the claims appended hereto. The above specification, examples and data provide a complete description of the manufacture and use of the composition of the invention. Since many implementations of the invention can be made without departing from the spirit and scope of the invention, the invention resides in the claims hereinafter appended.","The foregoing description of the preferred embodiments of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. It is intended that the scope of the invention be limited not by this detailed description, but rather by the claims appended hereto. The above specification, examples and data provide a complete description of the manufacture and use of the composition of the invention. Since many embodiments of the invention can be made without departing from the spirit and scope of the invention, the invention resides in the claims hereinafter appended."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Referring now to the drawings in which like reference numbers represent corresponding parts throughout:",{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 1A","FIG. 1B"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIGS. 4A","b":["4","4"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIGS. 18A and 18B"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIGS. 19A","b":["19","19"]},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 22"}]},"DETDESC":[{},{}]}
