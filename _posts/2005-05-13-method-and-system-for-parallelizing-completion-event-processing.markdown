---
title: Method and system for parallelizing completion event processing
abstract: Disclosed are methods for handling RDMA connections carried over packet stream connections. In one aspect, I/O completion events are distributed among a number of processors in a multi-processor computing device, eliminating processing bottlenecks. For each processor that will accept I/O completion events, at least one completion queue is created. When an I/O completion event is received on one of the completion queues, the processor associated with that queue processes the event. In a second aspect, semantics of the interactions among a packet stream handler, an RDMA layer, and an RNIC are defined to control RDMA closures and thus to avoid implementation errors. In a third aspect, semantics are defined for transferring an existing packet stream connection into RDMA mode while avoiding possible race conditions. The resulting RNIC architecture is simpler than is traditional because the RNIC never needs to process both streaming messages and RDMA-mode traffic at the same time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07761619&OS=07761619&RS=07761619
owner: Microsoft Corporation
number: 07761619
owner_city: Redmond
owner_country: US
publication_date: 20050513
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION","Introduction","Overview of an Exemplary RDMA Architecture","Specifics of an Exemplary RDMA Architecture","Initialization","Specifics of an Exemplary RDMA Architecture","Offload","Specifics of an Exemplary RDMA Architecture","State Variables","Specifics of an Exemplary RDMA Architecture","Completion and Asynchronous Event Handling","Specifics of an Exemplary RDMA Architecture","Parallelizing CQ Completion Event Handling on Multiple Processors","Specifics of an Exemplary RDMA Architecture","Closing a Connection and Error Handling"],"p":["The present application is related to U.S. Patent Applications \u201cMethod and System for Closing an RDMA Connection,\u201d Ser. No. 11\/128,875, and \u201cMethod and System for Transferring a Packet Stream to RDMA,\u201d Ser. No. 11\/128,710.","The present invention is related generally to remote direct memory access (RDMA), and, more particularly, to local processing of RDMA connections carried over packet streams.","DMA (direct memory access) is a traditional technology that moves or copies items from one place to another in the dynamic memory of a computing device while using only a small amount or none of the resources of the computing device's central processing unit. RDMA extends this concept and moves or copies memory items from one computing device to another. In high-speed networking and in high-performance computing environments, RDMA is expected to become increasingly invaluable. For example, data centers and server farms will rely on RDMA to coordinate computing devices connected by networks running packet protocols, such as TCP.","Due to the great commercial value of RDMA, various aspects of it are being standardized by, for example, the RDMA Consortium. However, these efforts do not as yet adequately address all of the areas of RDMA processing that are significant for producing the efficiencies promised by RDMA. For example, RDMA connections are often of long duration and often require intensive use of local input\/output (I\/O) resources. When a single computing device is called upon to support multiple, simultaneous RDMA connections, the local processing involved can overwhelm the resources of the computing device, leading to a bottleneck and to RDMA transfer inefficiencies.","In another area of concern, the network interface controller (NIC) that supports the RDMA connection protocol can get confused or overwhelmed because it also supports the underlying network packet protocol. Coordinating these two protocols with their disparate demands, and coordinating both with the operating system of the computing device, leads to complex problems and error-prone implementations. Most critically, problems can arise either when closing an existing RDMA connection or when initiating an RDMA connection on top of an existing packet stream.","The above are just a few examples of the areas of concern left to be addressed before RDMA can achieve its full potential.","In view of the foregoing, the present invention provides techniques for efficiently processing I\/O completion events by distributing those events among a number of processors in a multi-processor computing device. For each processor that will accept I\/O completion events (not all processors in the computing device need participate in this), at least one I\/O completion queue is created. Each completion queue supports one or more RDMA connections. When an I\/O completion event is received on one of the completion queues, the processor associated with that queue processes the event. In this manner, multiple processors simultaneously handle multiple completion events, eliminating processing bottlenecks.","In some embodiments, each participating processor is assigned a unique identifier. When an interface comes up, an interface queue is created for that interface. The interface queue contains an array of descriptors, one descriptor for each participating processor. Each descriptor also stores an identifier of the completion event handler for its processor. Whenever a new completion queue is created, it is bound to one of the completion event handlers and thus to one of the participating processors.","Whenever a new completion queue is created, a load-balancing algorithm can be run to decide which participating processor will be given responsibility for events coming in on the new completion queue. Many load-balancing algorithms are known in the art and can be applied here.","Turning to the drawings, wherein like reference numerals refer to like elements, the present invention is illustrated as being implemented in a suitable computing environment. The following description is based on embodiments of the invention and should not be taken as limiting the invention with regard to alternative embodiments that are not explicitly described herein.","In the description that follows, the environment surrounding the present invention is described with reference to acts and symbolic representations of operations that are performed by one or more computing devices, unless indicated otherwise. As such, it will be understood that such acts and operations, which are at times referred to as being computer-executed, include the manipulation by the processing unit of the computing device of electrical signals representing data in a structured form. This manipulation transforms the data or maintains them at locations in the memory system of the computing device, which reconfigures or otherwise alters the operation of the device in a manner well understood by those skilled in the art. The data structures where data are maintained are physical locations of the memory that have particular properties defined by the format of the data. However, while the invention is being described in the foregoing context, it is not meant to be limiting as those of skill in the art will appreciate that various of the acts and operations described hereinafter may also be implemented in hardware.","RDMA is a recently developing technology that enables one computer to access the memory of a remote peer directly with little or no processor overhead. RDMA enables zero-copy sends and receives over a conventional packet network, e.g., over a TCP (Transmission Control Protocol) stream.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 1","b":["100","102","104","104","102","102"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 1","b":["100","100"]},"The computing device  of  may be of any architecture.  is a block diagram generally illustrating an exemplary computer system that supports the present invention. The computer system of  is only one example of a suitable environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention. Neither should the computing device  be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in . The invention is operational with numerous other general-purpose or special-purpose computing environments or configurations. Examples of well known computing systems, environments, and configurations suitable for use with the invention include, but are not limited to, personal computers, servers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set-top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, and distributed computing environments that include any of the above systems or devices. In its most basic configuration, the computing device  typically includes at least one processing unit  and memory . The memory  may be volatile (such as RAM), non-volatile (such as ROM or flash memory), or some combination of the two. This most basic configuration is illustrated in  by the dashed line . The computing device  may have additional features and functionality. For example, it may include additional storage (removable and non-removable) including, but not limited to, magnetic and optical disks and tape. Such additional storage is illustrated in  by removable storage  and by non-removable storage . Computer-storage media include volatile and non-volatile, removable and non-removable, media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules, or other data. Memory , removable storage , and non-removable storage  are all examples of computer-storage media. Computer-storage media include, but are not limited to, RAM, ROM, EEPROM, flash memory, other memory technology, CD-ROM, digital versatile disks, other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage, other magnetic storage devices, and any other media that can be used to store the desired information and that can be accessed by the computing device . Any such computer-storage media may be part of the computing device . The computing device  may also contain communications channels  that allow it to communicate with other devices, including devices on the network . Communications channels  are examples of communications media. Communications media typically embody computer-readable instructions, data structures, program modules, or other data in a modulated data signal such as a carrier wave or other transport mechanism and include any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communications media include optical media, wired media, such as wired networks and direct-wired connections, and wireless media such as acoustic, RF, infrared, and other wireless media. The term \u201ccomputer-readable media\u201d as used herein includes both storage media and communications media. The computing device  may also have input devices  such as a touch-sensitive display screen, a hardware keyboard, a mouse, a voice-input device, etc. Output devices  include the devices themselves, such as the touch-sensitive display screen, speakers, and a printer, and rendering modules (often called \u201cadapters\u201d) for driving these devices. All these devices are well know in the art and need not be discussed at length here. The computing device  has a power supply .","The following definitions are helpful in discussing RDMA.\n\n",{"@attributes":{"id":"p-0039","num":"0056"},"figref":["FIG. 3","FIG. 3","FIG. 3"],"b":["300","300","312"]},"While similar, the RDMA chimney differs from the traditional TCP chimney offload architecture in several important aspects.\n\n","The RDMA Module  includes an RDMA Off-Load Manager (ROLM) (not shown in ). The ROLM performs the following functions (see a later section for exemplary implementation details):\n\n","The following is a brief overview of the semantics of the WSK API RDMA programming model. There are guarantees and constraints to ensure the proper ordering of a user's RDMA operations. The user can also request fence indicators on certain RDMA operations. All calls are asynchronous.\n\n","The RAL proxy interface interacts with the SDP (Sockets Direct Protocol) to enable kernel-bypass RDMA. The interface to the RAL Proxy is a control interface, thus it is significantly more sophisticated than the WSK API. The RAL Proxy control interface allows the RAL Proxy to directly manipulate PDs, CQ, Memory Windows, and STags for locally accessed buffers. However, all other constraints of the WSK API apply, such as ordering constraints. Note that data transfer is not done through this control interface: a QP is set up for direct user-mode access, so all send and receive data are communicated directly from and to the RNIC  by the user-mode application.","The RDMA Module  uses the Transport Layer Interface  interface to talk with the TCP chimney module  to start and terminate (or upload) a TCP connection. Once the connection is offloaded to the RNIC , the RDMA Module  interacts directly with the NDIS Miniport Driver  to access the RNIC miniport. To support the RAL Proxy, the RDMA Module  can add and remove TCP Listen requests through the Transport Layer Interface .","There are three parts to the RNIC Initialization with NDIS: (1) advertising RNIC offload capabilities, (2) advertising offload handlers, and (3) providing call handlers.","(1) NDIS obtains offload capabilities from the miniport by calling the MINIPORT_REQUEST_HANDLER to query the RNIC miniport's capabilities at initialization time. NDIS issues NdisRequest to query information with OID_TCP_OFFLOAD_TASK. The RNIC miniport returns a list of offload tasks supported by this RNIC through the completion routine. At the end of the offload task list, there is a task structure whose task type equals RdmaChimneyOffloadNdisTask. The TaskBuffer field of that task structure contains the NDIS_TASK_RDMA_OFFLOAD structure. This structure contains a list of variables that the RNIC advertises according to the verb specification.","(2) The miniport advertises its dispatch routines (offload handlers) to NDIS. There are two types of chimney offload handlers: generic offload handlers and chimney-specific offload handlers. Generic chimney offload handlers (and their completion handlers) are shared across all types of chimneys. They include InitiateOffload, TerminateOffload, UpdateOffload, and QueryOffload. Because an RDMA chimney is built upon a TCP chimney, RDMA offload uses the same set of generic offload handlers as does the TCP chimney. Generic offload handlers are advertised to NDIS when the miniport initializes its TCP chimney. Chimney-specific offload handlers are specific to one type of chimney and are advertised to NDIS individually by different chimneys. The RDMA chimney defines RDMA-specific offload handlers for some of the most frequently used verbs, e.g., Post SQ and Post RQ. For RDMA, most of the Update and Query type of verbs are \u201cembedded\u201d into the two RDMA-specific offload handlers RdmaOffloadUpdateHandler and RdmaOffloadQueryHandler. For example, Query QP is implemented as an opcode of the RdmaOffloadQueryHandler.","To set RDMA-specific offload handlers, the miniport calls NdisSetOptionalHandlers.",{"@attributes":{"id":"p-0049","num":"0083"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NDIS_STATUS"]},{"entry":[{},"NdisSetOptionalHandlers"]},{"entry":[{},"("]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003NDIS_HANDLE","NdisHandle,"]},{"entry":[{},"\u2003PNDIS_DRIVER_OPTIONAL_HANDLERS","OptionalHandlers"]},{"entry":[{},")"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}},"br":[{},{}]},"The following structure is defined for the miniport to store RDMA-specific offload handlers. The miniport sets the following fields before passing the structure into the above function: the Type field of the NDIS_OBJECT_HEADER is set to NDIS_OBJECT_TYPE_PROVIDER_CHIMNEY_OFFLOAD_CHARACTERISTICS; the field OffloadType is set to NdisRdmaChimneyOffload; and RDMA-specific offload handlers are set to corresponding miniport dispatch routines.",{"@attributes":{"id":"p-0051","num":"0085"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"322pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef struct_NDIS_PROVIDER_CHIMNEY_OFFLOAD_RDMA_CHARACTERISTICS"},{"entry":"{"},{"entry":"\u2003NDIS_OBJECT_HEADER Header;"},{"entry":"\u2003\/\/ Header.Type = NDIS_OBJECT_TYPE_PROVIDER_CHIMNEY_OFFLOAD_CHARACTERISTICS"},{"entry":"\u2003ULONG Flags;"},{"entry":"\u2003\/\/ Not used by NDIS for now."},{"entry":"\u2003NDIS_CHIMNEY_OFFLOAD_TYPE OffloadType;"},{"entry":"\u2003\/\/ Set this field to NdisRdmaChimneyOffload."},{"entry":"\u2003\/\/RDMA-specific offload handlers go here:"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003MINIPORT_RDMA_OFFLOAD_POST_SQ_HANDLER","RdmaOffloadPostSQHandler;"]},{"entry":["\u2003MINIPORT_RDMA_OFFLOAD_POST_RQ_HANDLER","RdmaOffloadPostRQHandler;"]},{"entry":["\u2003MINIPORT_RDMA_OFFLOAD_POLL_CQ_HANDLER","RdmaOffloadPollCQHandler;"]},{"entry":["\u2003MINIPORT_RDMA_OFFLOAD_UPDATE_HANDLER","RdmaOffloadUpdateHandler;"]},{"entry":["\u2003MINIPORT_RDMA_OFFLOAD_QUERY_HANDLER","RdmaOffloadQueryHandler;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"322pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u2003MINIPORT_RDMA_OFFLOAD_REQUEST_COMPLETION_NOTIFICATION_HANDLER"},{"entry":"\u2003\u2003RdmaOffloadRequestCompletionNotificationHandler;"},{"entry":"\u2003MINIPORT_RDMA_OFFLOAD_SET_COMPLETION_EVENT_HANDLER_HANDLER"},{"entry":"\u2003\u2003RdmaOffloadSetCompletionEventHandlerHandler;"},{"entry":"} NDIS_PROVIDER_CHIMNEY_OFFLOAD_RDMA_CHARACTERISTICS,"},{"entry":"*PNDIS_PROVIDER_CHIMNEY_OFFLOAD_RDMA_CHARACTERISTICS;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"(3) The miniport obtains RDMA chimney-specific completion and event handlers from NDIS by calling the NdisMGetOffloadHandlers API:",{"@attributes":{"id":"p-0053","num":"0087"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"VOID"},{"entry":"NdisMGetOffloadHandlers"},{"entry":"("}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003IN NDIS_HANDLE","NdisMiniport-"]},{"entry":[{},"Handle,"]},{"entry":["\u2003IN NDIS_CHIMNEY_OFFLOAD_TYPE","ChimneyType,"]},{"entry":["\u2003OUT PNDIS_OFFLOAD_EVENT_HANDLERS","*OffloadHandlers"]},{"entry":");"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},{"@attributes":{"id":"p-0054","num":"0088"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"329pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef struct_NDIS_RDMA_OFFLOAD_EVENT_HANDLERS"},{"entry":"{"},{"entry":"\u2003NDIS_OBJECT_HEADER Header;"},{"entry":"\u2003\/\/Header.Type == NdisRdmaChimneyOffload."},{"entry":"\u2003NDIS_RDMA_OFFLOAD_ASYNCHRONOUS_EVENT_INDICATE_HANDLER"},{"entry":"\u2003\u2003NdisRDMAAsynchronousEventIndicate;"},{"entry":"\u2003NDIS_RDMA_OFFLOAD_UPDATE_COMPLETE_HANDLER"},{"entry":"\u2003\u2003NdisRdmaOffloadUpdateCompleteHandler;"},{"entry":"\u2003NDIS_RDMA_OFFLOAD_QUERY_COMPLETE_HANDLER"},{"entry":"\u2003\u2003NdisRdmaOffloadQueryCompleteHandler;"},{"entry":"} NDIS_RDMA_OFFLOAD_EVENT_HANDLERS, *PNDIS_RDMA_OFFLOAD_EVENT_HANDLERS;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The RDMA Module  needs to be notified by the TCP offload module whenever an interface is brought up or brought down. The RDMA Module  also needs to be notified by the TCP offload module of all existing interfaces at the time it initializes. After being notified of the interface events, the RDMA Module  has an NDIS handle to that interface and can then register up-calls for the interface with NDIS. After this, the RDMA Module  can begin to use this interface for RDMA offload purposes.","At initiation, the RDMA offload module registers up-calls to the TCP offload module using the following dispatch table:",{"@attributes":{"id":"p-0057","num":"0091"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"280pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u2003typedef struct_TL_OFFLOAD_CLIENT_DISPATCH"},{"entry":"\u2003{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003\u2003USHORT","Version;"]},{"entry":["\u2003\u2003USHORT","Length;"]},{"entry":["\u2003\u2003USHORT","UpperLayerProtocolId;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"280pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"\u2003\u2003\/\/This is the protocol ID that is using the TCP offload module."}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003\u2003PTL_OFFLOAD_CLIENT_ADD_INTERFACE","AddInterfaceIndicate;"]},{"entry":["\u2003\u2003PTL_OFFLOAD_CLIENT_DELETE_INTERFACE","DeleteInterfaceIndicate;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"280pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u2003\u2003...."},{"entry":"\u2003\u2003<Other client dispatch routines that are used by offload, e.g., initiate offload complete.>"},{"entry":"\u2003\u2003...."},{"entry":"\u2003} TL_OFFLOAD_CLIENT_DISPATCH, *PTL_OFFLOAD_CLIENT_DISPATCH;"},{"entry":"The up-call TL_OFFLOAD_CLIENT_ADD_INTERFACE is defined as follows:"},{"entry":"\u2003typedef"},{"entry":"\u2003VOID"},{"entry":"\u2003(NTAPI *PTL_OFFLOAD_CLIENT_ADD_INTERFACE)"},{"entry":"\u2003("}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003\u2003IN PTL_OFFLOAD_INDICATE_INTERFACE","Args,"]},{"entry":["\u2003\u2003IN CONST TL_OFFLOAD_INTERFACE_CHARACTERISTICS","*TLCharacteristics"]},{"entry":"\u2003);"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"The TCP offload module calls the above \u201cadd interface notification\u201d up-call to the RDMA Module  when a new interface has been brought up in the system or when the RDMA Module  registers with the TCP offload module. For the later case, interface(s) may have already been brought up in the system, and the TCP offload module needs to call up-calls for each existing interface.","In order to initiate an RDMA offload process, the RDMA Module  calls the initiate offload function of the TCP offload module because RDMA is a dependent protocol of TCP. As such, the RDMA Module  needs to obtain Initiate offload handlers from the TCP module and set corresponding completion handlers to the TCP module. These two sets of handlers are exchanged through the Transport Layer Interface .","Following are the definition of the Initiate Offload handler provided by the TCP module to the RDMA Module  and its completion handler:",{"@attributes":{"id":"p-0061","num":"0095"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef"},{"entry":"NTSTATUS"},{"entry":"(*PTL_PROVIDER_OFFLOAD_INITIATE_OFFLOAD)"},{"entry":"("}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"140pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2002HANDLE","TCPConnectionHandle,"]},{"entry":["\u2002PNDIS_PROTOCOL_OFFLOAD_BLOCK","OffloadBlock"]},{"entry":")"},{"entry":"typedef"},{"entry":"VOID"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"(*PTL_CLIENT_OFFLOAD_INITIATE_OFFLOAD_COMPLETE)"},{"entry":"("}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"140pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2002PNDIS_PROTOCOL_OFFLOAD_BLOCK","OffloadBlock"]},{"entry":")"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Offload handlers are exchanged between the TL client and provider in the following way. When a TL client is bound to a TL provider, it is provided with the following structure:",{"@attributes":{"id":"p-0063","num":"0097"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef struct_TL_PROVIDER_DISPATCH"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003PTL_PROVIDER_IO_CONTROL","IoControl;"]},{"entry":["\u2003PTL_PROVIDER_QUERY_DISPATCH","QueryDispatch;"]},{"entry":["\u2003PTL_PROVIDER_ENDPOINT","Endpoint;"]},{"entry":["\u2003PTL_PROVIDER_MESSAGE","Message;"]},{"entry":["\u2003PTL_PROVIDER_LISTEN","Listen;"]},{"entry":["\u2003PTL_PROVIDER_CONNECT","Connect;"]},{"entry":["\u2003PTL_PROVIDER_RELEASE_INDICATION_LIST","ReleaseIndicationList;"]},{"entry":["\u2003PTL_PROVIDER_CANCEL","Cancel;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} TL_PROVIDER_DISPATCH, *PTL_PROVIDER_DISPATCH;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"br":{}},{"@attributes":{"id":"p-0064","num":"0098"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef"},{"entry":"NTSTATUS"},{"entry":"(NTAPI *PTL_PROVIDER_QUERY_DISPATCH)"},{"entry":"("}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"140pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003IN HANDLE","ClientHandle,"]},{"entry":["\u2003IN PTL_REQUEST_QUERY_DISPATCH","QueryDispatchRequest"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":");"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"The following data structure is used to exchange the call handlers:",{"@attributes":{"id":"p-0066","num":"0100"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef struct_TL_REQUEST_QUERY_DISPATCH"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003IN PTL_CLIENT_CREATE_REQUEST_COMPLETE","RequestComplete;"]},{"entry":["\u2003IN PVOID","RequestContext;"]},{"entry":["\u2003IN PNPIID","NpiId;"]},{"entry":["\u2003IN CONST VOID","*ClientDispatch;"]},{"entry":["\u2003OUT CONST VOID","*ProviderDispatch;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} TL_REQUEST_QUERY_DISPATCH, *PTL_REQUEST_QUERY_DISPATCH;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"br":{}},{"@attributes":{"id":"p-0067","num":"0101"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{"]},{"entry":[{},"\u2003TLOffloadAddInterfaceIndicate,"]},{"entry":[{},"\u2003TLOffloadDeleteInterfaceIndicate,"]},{"entry":[{},"\u2003TLOffloadInterfaceWillGoDownIndicate,"]},{"entry":[{},"\u2003TLOffloadInitiateOffloadComplete,"]},{"entry":[{},"\u2003TLOffloadTerminateOffloadComplete,"]},{"entry":[{},"\u2003TLOffloadUpdateOffloadComplete,"]},{"entry":[{},"\u2003TLOffloadQueryOffloadComplete"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},{"@attributes":{"id":"p-0068","num":"0102"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{"]},{"entry":[{},"\u2003TLOffloadInitiateOffload,"]},{"entry":[{},"\u2003TLOffloadTerminateOffload,"]},{"entry":[{},"\u2003TLOffloadUpdateOffload,"]},{"entry":[{},"\u2003TLOffloadQueryOffload"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"To avoid a race condition that might occur during the initiation of an RDMA connection offload, the RDMA Module  asks the TCP layer to flush all pre-posted receive buffers. Moreover, the RDMA Module  ignores all receive indications from the TCP layer after a certain point in the state transition. Here is a function provided by the TLNPI layer and called by the RDMA Module  to flush all pre-posted receive buffers on a connection:",{"@attributes":{"id":"p-0070","num":"0104"},"tables":{"@attributes":{"id":"TABLE-US-00012","num":"00012"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NTSTATUS"]},{"entry":[{},"TLFlushReceiveBuffer"]},{"entry":[{},"("]},{"entry":[{},"\u2003HANDLE\u2003EndPointHandle"]},{"entry":[{},")"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"This section is illustrated with a series of workflow diagrams that represent offload procedures. In the calls in these diagrams, a \u201cW\u201d refers to \u201cWSK\u201d, an \u201cR\u201d refers to the RDMA Module , and an \u201cM\u201d refers to the RNIC miniport. So, for example, \u201cWR\u201d represents a call between the WSK module and the RDMA Module .","For APIs provided by the different modules, the naming convention is:\n\n","For the WSK layer, a socket can have the following states: StreamingMode, RdmaTransitionInProgress, or RDMAMode. For the RDMA Module  layer, a connection can have the states: NotReadyToOffload, ResourceReservationInProgress, ReadyToOffload, WaitForFirstRecvBuffer, OffloadInProgress, or Offloaded.",{"@attributes":{"id":"p-0074","num":"0111"},"figref":"FIG. 4","b":["400","300","308","300","300","402","300"]},{"@attributes":{"id":"p-0075","num":"0112"},"b":["402","400"]},"The WR1 call forwards the SIO_RDMA_RESERV_RESOURCE Ioctl request from WSK to the RDMA Module . This call essentially starts the state machine in the RDMA Module . The RDMA Module  maintains a separate state machine for each connection. The successful completion of this call places the connection in the ReadyToOffload state. While this call is pending, the state of the connection is ResourceReservationInProgress. This API is provided by the RDMA Module  to the WSK Module:",{"@attributes":{"id":"p-0077","num":"0114"},"tables":{"@attributes":{"id":"TABLE-US-00013","num":"00013"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NSTATUS"]},{"entry":[{},"RDMAOffloadAllocateOffloadResoruce"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"(",{},{}]},{"entry":[{},"\u2003IN HANDLE","TCPConnectionHandle,"]},{"entry":[{},"\u2003IN ULONG","IRD","OPTIONAL,"]},{"entry":[{},"\u2003IN ULONG","ORD","OPTIONAL,"]},{"entry":[{},"\u2003IN BOOL","EnableRDMARead","OPTIONAL,"]},{"entry":[{},"\u2003IN BOOL","EnableRDMAWrite","OPTIONAL,"]},{"entry":[{},"\u2003IN ULONG","LengthOfSQ","OPTIONAL,"]},{"entry":[{},"\u2003IN ULONG","LengthOfRQ","OPTIONAL,"]},{"entry":[{},"\u2003IN HANDLE","RelatedConnection","OPTIONAL,"]},{"entry":[{},"\u2003IN HANDLE","CompletionRoutine,"]},{"entry":[{},"\u2003IN HANDLE","RequestContext"]},{"entry":[{},")"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}]}}},"WR1-C is the completion routine of WR1, and it indicates the result of that call. If the return result is STATUS_SUCCESS, then the actual values of the QP properties are also returned.",{"@attributes":{"id":"p-0079","num":"0116"},"tables":{"@attributes":{"id":"TABLE-US-00014","num":"00014"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef"},{"entry":"VOID"},{"entry":"(*RDMA_OFFLOAD_ALLOCATE_OFFLOAD_RESOURCE"},{"entry":"COMPLETE)"},{"entry":"("}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003IN HANDLE","RequestContext,"]},{"entry":["\u2003IN ULONG","ActualIRD,"]},{"entry":["\u2003IN ULONG","ActualORD,"]},{"entry":["\u2003IN ULONG","ActualLengthOfSQ,"]},{"entry":["\u2003IN ULONG","ActualLengthOfRQ,"]},{"entry":["\u2003IN NTSTATUS","CompletionStatus,"]},{"entry":["\u2003IN ULONG","CompletionReasonCode"]},{"entry":")"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"RM1 is potentially a series of calls made by the RDMA Module  to the RNIC miniport to create a QP. To create the QP, the miniport needs to be provided with a Protection Domain ID and a Completion Queue handle. Multiple QPs can share one PD and one CQ. The RDMA Module  decides whether the QP to be created will share PDs or CQs with other QPs based on its PD\/CQ sharing policy. For the WSK interface, by default a PD is unique on a per connection basis, but the consumer has the option to put different connections into one PD. A CQ is shared among a limited number of QPs. For the RAL Proxy interface, there are no defaults: The RDMA Module  exposes essentially all of the parameters that can be set for the creation of a PD, CQ, and QP directly to the RAL Proxy. If the RDMA Module  decides that a new PD\/CQ should be created for this QP, then the following dispatch routines are called.","RM1-PD is an asynchronous call to create a PD. Upon successful completion, the Protection Domain ID (PDID) is created. In terms of the NDIS API, this call is embedded into the \u201cUpdate Offload\u201d call with \u201ccreate PD\u201d as its op-code.","RM1-AllocateSTag allocates a set of STags for Fast-Register.","RM1-CQ creates a CQ or modifies a previously created CQ. The call to create a CQ is asynchronous and specifies the length of the CQ. That length is the sum of the lengths of the RQs and SQs (send queues) that share this CQ. The length of a CQ can change when more SQs and RQs are associated with this CQ. In terms of the NDIS API, the create CQ call is embedded into the \u201cUpdate Offload\u201d call with \u201cCreate CQ\u201d as its op-code. After the CQ has been successfully created, completion notification is requested on the new CQ. It is required by the RDMA verb spec that a consumer of a QP request completion notification for a CQ if notification has been requested when a CQE (completion queue event) is queued. Otherwise, the completion event handler is not called if anything is queued into this CQ.","The following apply when RM1-CQ is called to modify an existing CQ. (1) If the RDMA Module  decides that this QP can share a CQ with other QPs, then it retrieves the handle of an existing CQ that is to be shared from its internal table. However, the existing CQ may not be large enough to accommodate the new QP so it may need to be resized by the Modify CQ verb. (2) Modify CQ is called after the RM1-QP (create QP) call. The RDMA Module  first tries to create a QP of the desired size, and, if the creation of the QP is successful, then it tries to modify the existing CQ that will be shared by the newly created QP. (3) If the CQ cannot be grown to accommodate the additional QP, then a new CQ is created. (4) In terms of the NDIS API, this call is embedded into the \u201cUpdate Offload\u201d call with \u201cModify CQ\u201d as its op-code. (5) The re-sizing operation on a CQ is expensive and may affect the operation of the QPs that are associated with the CQ being resized. The RDMA Module  tries to re-size the CQ as few times as possible and associates only a reasonable number of QPs with a CQ.","RM1-QP creates a QP. After the PD ID and CQ handle have been created, the RDMA Module  layer calls the Create QP verb to create a QP for this connection. This call is made before the RM1-CQ call if the RM1-CQ call is to modify an existing CQ. In other words, a QP is created first, and then the CQ is modified to accommodate that new QP. In terms of the NDIS API, this call is embedded into the \u201cUpdate Offload\u201d call with \u201cCreate QP\u201d as its op-code.","RM1-C-QP, RM1-C-PD, and RM1-C-CQ are the completion handlers corresponding to the above original calls.","When the completion handler of Create QP is called, the RNIC state for this connection has been allocated. The PD, CQ, and QP are initialized. (The QP is in the IDLE state.) The RDMA Module  calls WR1-C with the corresponding status and reason code. The completion chain eventually pops up to the WSK or RAL Proxy consumer, and this finishes the Ioctl call to reserve RDMA offload resources. At the successful completion of this process, the RDMA Module  sets the connection state to ReadyToOffload.","After RDMA resources have been successfully allocated, the consumer may wish to exchange additional configuration information before transitioning into RDMA mode. The only parameter that can be changed through the WSK interface is the amount of RDMA read resources (IRD and ORD). This call can be made while the connection is in streaming mode or RDMA mode. If there are outstanding calls to WskRdmaGet( ), the RDMA Module  completes the call with an error. If there are no outstanding WskRdmaGet( ) calls, then the ORD value may be changed. The IRD value should only be changed if there will be no RDMA Read Requests arriving on the link. If there are, changing IRD could cause the connection to be torn down. For some applications, this value will be changed before any RDMA Reads can be generated. For other applications, an application-specific negotiation is done to flush RDMA Read Requests before the change is made. Note that both the IRD and ORD are specified. If no change is desired, then the values from the last call which set the IRD or ORD resource should be used.","In , a request  is made to change RDMA read resources. RR1-WR simply passes the request structure through to the RDMA Module . The RDMA Module  then issues a Modify QP (RR1-RM) to change the RDMA Read Resources, if there are no outstanding RDMA Read Requests. Note that it is expected that changing IRD while the QP is still in the IDLE state will always succeed.",{"@attributes":{"id":"p-0090","num":"0127"},"figref":"FIG. 6","b":"600","ul":{"@attributes":{"id":"ul0009","list-style":"none"},"li":{"@attributes":{"id":"ul0009-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0010","list-style":"none"},"li":["The consumer ensures that the request to transfer to RDMA mode () is only made after the last streaming mode message from the remote peer is received. This clearly defines the transition between TCP mode and RDMA mode on the incoming half of the TCP stream. The consumer makes sure of this by his own protocols with the remote peer. All incoming traffic after the last streaming mode message is expected to be in iWARP mode.","The consumer cannot post any more traditional socket WskRecv calls after this call. An in-line error is returned for such an attempt. All outstanding WskRecv calls that have been posted before this call  but have not yet been completed are completed with zero bytes.","The consumer may post one or more WskSend calls after this call  and before the first WskRdmaRecv call . The last WskSend call posted by the consumer during this period is the last outgoing streaming mode message.","The consumer is required to post the first WskRdmaRecv call , otherwise, the RDMA offload process never begins."]}}}},"WSK sets the state of this connection to \u201cRdmaTransitionInProgress\u201d and keeps the connection in this state until it receives a successful completion of the offload (). When  is called, the connection has been switched into RDMA mode. WSK moves the state of this connection to \u201cRDMAMode.\u201d","Immediately after WSK moves to the \u201cRdmaTransitionInProgress\u201d state, it flushes the receive buffers and begins to ignore any receive indications from the TCP layer. It returns STATUS_DATA_NOT_ACCEPTED for all receive indication up-calls from the TCP layer. By doing so, it effectively asks the TCP layer to process all incoming data and then buffer them. Later, the buffered data are forwarded to the RNIC . This is required to avoid a race condition that could happen during RDMA offload initiation. Moreover, immediately after WSK moves to the \u201cRdmaTransitionInProgress\u201d state, all of its pre-posted receive requests (if any) to the TCP layer are completed with a certain number of bytes (most likely with zero bytes).","At 2, the following API is used by the WSK to signal the transition to RDMA mode. This API requests that the TCP stack flush all pre-posted receive buffers. (TLNPI should expose an API for this purpose). Moreover, this API sets the state of this connection in the RDMA Module  to \u201cWaitForFirstRecvBuffer\u201d state, which is the last state before the offload actually starts. Note that the TCP state may be in the host stack or it may have been offloaded already.",{"@attributes":{"id":"p-0094","num":"0135"},"tables":{"@attributes":{"id":"TABLE-US-00015","num":"00015"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NTSTATUS"]},{"entry":[{},"RDMAOffloadStartOffload"]},{"entry":[{},"("]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003IN HANDLE","TCPConnectionHandle,"]},{"entry":[{},"\u2003IN HANDLE","CompletionRoutine,"]},{"entry":[{},"\u2003IN HANDLE","RequestContext"]},{"entry":[{},")"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"The following call is made by the RDMA Module  layer to the TCP layer. It asks the TCP layer to flush all pre-posted receive buffers. This call is specified by the TLNPI interface.",{"@attributes":{"id":"p-0096","num":"0137"},"tables":{"@attributes":{"id":"TABLE-US-00016","num":"00016"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NTSTATUS"]},{"entry":[{},"TLFlushReceiveBuffer"]},{"entry":[{},"("]},{"entry":[{},"\u2003IN HANDLE\u2003\u2003EndPointHandle"]},{"entry":[{},")"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"At , the consumer may perform one or more normal TCP sends on the outgoing half of the TCP stream. This feature may be used by some ULPs to set up the RDMA connection. If a ULP requires that a last streaming mode message be sent to the remote peer to trigger the remote peer to switch to RDMA mode, then that last streaming mode message is sent in this step, that is, after call 2 and before step . After the consumer has sent his last streaming mode message to the remote peer, the consumer posts the first RDMA receive request  to trigger the real transition process and to notify the RDMA module  that the last streaming mode message has been sent. After step , the consumer cannot send any more streaming mode messages.","A consumer is not required to wait for the completion of call 3 (WskSend) before making call 4 (WskRdmaRecv). As such, it is possible that the consumer may make call 4 to trigger the offload process before the TCP layer completes sending the last streaming message. In other words, call 4 may be made by the consumer before the TCP ACK for the last streaming message is received, or even before the TCP layer sends out the last streaming message. If this happens, the RDMA Module  waits for the completion of call 3 before it actually starts executing call 4 for the consumer. This helps solve many race conditions that would have happened if un-completed outgoing streaming mode messages were handed down to the RNIC  as part of the RDMA offload state. This means that the RNIC  need not have dual modes to support both Streaming mode and RDMA Mode traffic at the same time. This also frees the RNIC  from the complications of re-transmitting the last streaming mode message when the hardware is in RDMA mode. From the RNIC 's point of view, there will be no last streaming mode message to send: The message should have already been sent (and TCP ACK received) by the software stack before the offload initiates. This also implies that no outgoing streaming mode messages are forwarded down to the RNIC  at or after RDMA offload initiation.","At step , the consumer makes a WskRdmaRecv call, and the actual RDMA offload process begins. The consumer should be able to estimate the size of the first incoming RDMA message based on his application and protocol needs. This call is designed to avoid a potential race condition when entering RDMA mode. If the consumer were not required to pre-post a buffer before entering RDMA mode, it is possible for the remote peer to send an RDMAP Send Type Message before the consumer has time to post a receive buffer (after the transition to RDMA mode completes). If this occurs, the connection would be torn down. Thus the API requires that the consumer pre-post at least one buffer. After WSK gets this call at 4, it forwards the request to the RDMA Module  through call WR4 (not shown in ).","WR4 is an API provided by the RDMA Module  to let users pass in a receive buffer after requesting the transfer to RDMA mode. WR4 posts an RDMA receive buffer to the RDMA Module  layer and starts the offload process by calling TCP offload functions. The WR4 API is specified as follows:",{"@attributes":{"id":"p-0101","num":"0142"},"tables":{"@attributes":{"id":"TABLE-US-00017","num":"00017"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"NSTATUS"},{"entry":"RDMAOffloadPostFirstReceiveBuffer"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"140pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["(",{}]},{"entry":["\u2003IN HANDLE","TCPConnectionHandle,"]},{"entry":["\u2003IN PWSK_BUFLIST","LocalReceiveBufferList,"]},{"entry":["\u2003IN PWSK_RDMA_LOCAL_BUFSGL","LocalBufferSGL,"]},{"entry":["\u2003IN HANDLE","CompletionRoutine,"]},{"entry":["\u2003IN HANDLE","RequestContext"]},{"entry":")"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"The WR4 call is implemented in the RDMA Module  as follows:\n\n","RT4c is the initiate offload call provided by the TCP layer. The RDMA Module  passes in an NDIS_PROTOCOL_OFFLOAD_BLOCK which has RDMA_OFFLOAD_STATE.",{"@attributes":{"id":"p-0104","num":"0151"},"tables":{"@attributes":{"id":"TABLE-US-00018","num":"00018"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef"},{"entry":"NTSTATUS"},{"entry":"(*PTL_PROVIDER_EXTENSION_INITIATE_OFFLOAD)"},{"entry":"("}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003HANDLE","TCPConnection-"]},{"entry":[{},"Handle,"]},{"entry":["\u2003PNDIS_PROTOCOL_OFFLOAD_BLOCK","OffloadBlock"]},{"entry":")"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},{"@attributes":{"id":"p-0105","num":"0152"},"tables":{"@attributes":{"id":"TABLE-US-00019","num":"00019"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"typedef struct _RDMA_OFFLOAD_STATE"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003IN ULONG","OpCode;"]},{"entry":[{},"\u2003OUT ULONG","RDMAReasonCode;"]},{"entry":[{},"\u2003union"]},{"entry":[{},"\u2003{"]},{"entry":[{},"\u2003\u2003struct"]},{"entry":[{},"\u2003\u2003{"]},{"entry":[{},"\u2003\u2003\u2003HANDLE","QPHandle;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003\u2003}StatesToInitiateOffload"]},{"entry":[{},"\u2003\u2003struct"]},{"entry":[{},"\u2003\u2003{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003\u2003\u2003PVOID","InputBuffer;"]},{"entry":[{},"\u2003\u2003\u2003ULONG","InputBufferLength;"]},{"entry":[{},"\u2003\u2003\u2003PVOID","OutputBuffer;"]},{"entry":[{},"\u2003\u2003\u2003ULONG","OutputBufferLength;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003\u2003}StatesToBeUpdatedOrQueried;"]},{"entry":[{},"\u2003}StateCategory;"]},{"entry":[{},"}RDMA_OFFLOAD_STATE, *PRDMA_OFFLOAD_STATE;"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"A set of calls is made by the TCP chimney to start its offload process. This goes all the way down to the RNIC  with a linked list of offload state blocks. In that linked list, the RDMA protocol offload block is a dependant block of the TCP protocol offload block. As such, the miniport knows that this TCP connection is also going to be offloaded as an RDMA connection. The QP handle is contained in the RDMA_OFFLOAD_STATE block, and it will be the QP used for this connection. A completion routine is called by the RNIC miniport to the TCP chimney to indicate that the offload has been completed. It indicates that both the TCP and the RDMA offload have been completed.","The TCP layer signals completion to the RDMA Module . This is the completion routine corresponding to call RT4c. At this point, the RDMA Module  is notified that the RDMA offload has been completed, and it takes two actions immediately: (1) It signals a completion for call 2 which is the first call made by the user to initiate the RDMA offload process. This completion is not signaled for WR4, because that is a Receive call which posts a receive buffer, and it should not be completed until the receive buffer is filled. The WR4 call will be completed by WR4-C later. (2) The RDMA Module  sets its internal state machine for this connection to the Offloaded state. The prototype of this completion call is:",{"@attributes":{"id":"p-0108","num":"0155"},"tables":{"@attributes":{"id":"TABLE-US-00020","num":"00020"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef"},{"entry":"VOID"},{"entry":"(*PTL_CLIENT_EXTENSION_INITIATE_OFFLOAD_COMPLETE)"},{"entry":"("},{"entry":"\u2003PNDIS_PROTOCOL_OFFLOAD_BLOCK\u2003\u2003OffloadBlock"},{"entry":")"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"Upon receiving a completion indication corresponding to the start offload call, the WSK layer sets the state of this connection to RDMAMode. The completion routine is called by the RDMA Module  layer and is defined as follows:",{"@attributes":{"id":"p-0110","num":"0157"},"tables":{"@attributes":{"id":"TABLE-US-00021","num":"00021"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"typedef"]},{"entry":[{},"VOID"]},{"entry":[{},"(*RDMA_OFFLOAD_START_OFFLOAD_COMPLETE)"]},{"entry":[{},"("]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003IN HANDLE","RequestContext,"]},{"entry":[{},"\u2003IN NTSTATUS","CompletionStatus,"]},{"entry":[{},"\u2003IN ULONG","CompletionReasonCode"]},{"entry":[{},")"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"The completion routine corresponding to call 2, the WSK Ioctl call that sets the socket into RDMA mode, is called by the WSK layer to the user of WSK. Upon receiving a successful completion at this point, the user of WSK can be sure that the RDMA connection has been offloaded and that new RDMA requests can be posted on this connection. The WSK sets the state of this socket to \u201cRDMAMode.\u201d","WR4-C is the completion routine for the WR4 call. It is called by the RDMA Module  after it receives a CQ completion indication from the RNIC . The CQE retrieved from the CQ indicates that the receive buffer posted at the beginning of the offload by WR4 has been filled. The receive completion routine is defined as follows:",{"@attributes":{"id":"p-0113","num":"0160"},"tables":{"@attributes":{"id":"TABLE-US-00022","num":"00022"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"typedef"]},{"entry":[{},"VOID"]},{"entry":[{},"(*RDMA_OFFLOAD_RECEIVE_COMPLETE)"]},{"entry":[{},"("]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003IN HANDLE","RequestContext,"]},{"entry":[{},"\u2003IN ULONG","BytesReceived,"]},{"entry":[{},"\u2003IN NTSTATUS","CompletionStatus,"]},{"entry":[{},"\u2003IN ULONG","CompletionReasonCode"]},{"entry":[{},")"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"The completion routine for call 4 indicates that the receive buffers posted have been filled with RDMA data.","To summarize the WSK states, WSK is in StreamingMode before the consumer makes call 2, is in RdmaTransitionInProgress immediately after call 2 and before call 2 completes, and is in RDMAMode immediately after call 2 completes. While the WSK is in StreamingMode, the consumer can call:","all WSK Normal APIs (WskSend, WskRecv, etc),","SIO_RDMA_RESERVE_RESOURCE, SIO_RDMA_READ_RESOURCES,","SIO_RDMA_SWITCH_TO_RDMA_MODE, WskRdmaAllocateSTag,","WskRdmaDeallocateSTag, and WskRdmaMapBuffer","but cannot call:","WskRdmaMapAndSend, WskRdmaRecv, WskRdmaPut, or WskRdmaGet.","While the WSK is in RdmaTransitionInProgress, the consumer can call:","WskSend (allowed before WskRdmaRecv is called), WskRdmaRecv,","WskRdmaAllocateSTag, WskRdmaDeallocateSTag, WskRdmaMapBuffer, and","SIO_RDMA_READ_RESOURCES","but cannot call:","all other WSK APIs, SIO_RDMA_RESERVE_RESOURCE,","SIO_RDMA_SWITCH_TO_RDMA_MODE, WskRdmaPut, WskRdmaGet,","WskRdmaMapAndSend, or","WskSend (not allowed after WskRdmaRecv is called).","When the WSK is in RDMAMode, the consumer may call:","SIO_RDMA_READ_RESOURCES, WskRdmaMapAndSend, WskRdmaRecv,","WskRdmaPut, WskRdmaGet, WskRdmaAllocateSTag, WskRdmaDeallocateSTag,","WskRdmaMapBuffer, and WskDisconn","but cannot call:","any of the WSK Normal APIs, except for WskDisconn,","SIO_RDMA_RESERVE_RESOURCE, or","SIO_RDMA_SWITCH_TO_RDMA_MODE.","After the RNIC  has transferred the TCP stream into RDMA mode, incoming data may have been buffered by the TCP layer. As discussed above, no outgoing streaming mode data are forwarded to the RNIC  during RDMA chimney offload. The RNIC  does not need to send the last streaming mode message: The message should have already been sent (and a TCP ACK received) by the software stack before the offload initiates. However, the RNIC  does need to process incoming RDMA mode data that are received before and during the RDMA offload process. Those data are either handed down to the RNIC as part of the TCP offload delegated state or forwarded to the RNIC through the TCP forwarding interface.","There is a potential race condition in which a remote peer may begin to send RDMA mode data even before the local peer initiates offload. In this case, the TCP software stack accepts all incoming data, does normal TCP protocol processing on these data, and buffers the TCP payload in its buffer. The \u201cTCP payload\u201d is actually RDMA protocol data including MPA marker, DDP header, RDMA header, etc. Data that are received at this stage are handed down to the RNIC as part of the TCP delegated state with the initiate offload call. The RNIC  processes these data as pure RDMA data. They have already been \u201cTCP-processed\u201d by the software stack (TCP CRC checked, TCP ACK sent, etc.).","RDMA data may also come in during the offload process, i.e., RDMA mode data may come in after the RDMA module  requests Initiate offload to the RNIC  and before the RNIC  completes the offload request. In this case, the TCP software stack accepts all incoming data and buffers them as raw data. No TCP protocol processing is performed on these data. As soon as offload completion is signaled by the RNIC , the TCP layer forwards all incoming raw data that are buffered during this stage to the RNIC  through the TCP forwarding interface. The RNIC  first \u201cTCP-processes\u201d these forwarded raw data and then processes the TCP payload as RDMA data.","For resource allocation, there are two types of error: recoverable errors and non-recoverable errors. Recoverable errors are caused when the user's resource demands exceed the RNIC 's capacity, e.g., Create QP fails because the requested IRD\/ORD is too large, or Modify CQ fails because the new CQ size cannot be supported. The RDMA Module  returns a reason code to indicate to the user what has gone wrong. The user can then decide to re-request resource reservation or just abort. Non-recoverable errors include those caused by an RNIC  failure or a lost connection. Those errors return their own error codes, and the user can abort the offload attempt and return an error message to the remote peer if possible. Non-recoverable errors include: NIC is not an RNIC, failure to create a new PD, and failure to create QP even with the minimum input values. During the offload process, if the RDMA offload fails, then the connection is torn down instead of being switched back into TCP streaming mode.","For an RDMA chimney offload, a \u201cgang offload\u201d uses the same algorithm and design as that of the TCP chimney, but there are some additional steps to take care of:\n\n","At the end of the resource reservation stage, the following RDMA states are established on the RNIC :\n\n","At the beginning of the offload, the following state is passed in as the RDMA_OFFLOAD_STATE block to the chimney driver:","QP Handle: The Queue Pair which the RDMA connection will use.","After the RDMA Module  successfully offloads the connection, the QP has the following states: Idle, RTS, Closing, Terminate, and Error. These states are handled by the RDMA Module , and they are not seen by the user. The user is notified of termination, error, and closing events by the RDMA Module  through event handlers.","STags are required for RDMA data transfer operations. STags can have invalid and valid states after they are created. The consumer needs to keep track of the states of local STags that have been advertised for remote access and invalidate them as necessary. The consumer also needs to keep track of any remote STags that are received from the remote peer and invalidate them as necessary. For local STags that are used for local access only, the user may choose to keep track of them if he wants to re-use the buffers. Otherwise, the RDMA Module  transparently handles this type of STags.","The RDMA Module  sets completion event handlers to the miniport through the Set Completion Event Handler verb. An RNIC  may support more than one completion event handler. Each time a new completion event handler is set, the RNIC miniport returns an identifier to the consumer. The identifier is used when the consumer creates a new CQ and associates that CQ with the completion event handler. This is the definition of the completion event handler:",{"@attributes":{"id":"p-0144","num":"0200"},"tables":{"@attributes":{"id":"TABLE-US-00023","num":"00023"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"typedef"]},{"entry":[{},"VOID"]},{"entry":[{},"(*RDMA_OFFLOAD_COMPLETION_EVENT_HANDLER)"]},{"entry":[{},"("]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003IN NDIS_HANDLE","NdisMiniportHandle,"]},{"entry":[{},"\u2003IN PVOID","CQHandle"]},{"entry":[{},");"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"The miniport calls the above handler when there is a CQE queued into a CQ and the completion notification has been requested for the CQ. The completion event handler is given the CQ Handle as an input. The RDMA Module  implements the completion event handler as follows:\n\n","When the RDMA Module  creates WRs to post to the SQ, it sets the Completion Notification Type of most of the WRs as \u201csignaled completion.\u201d However, to avoid completion processing overhead, the RDMA Module  sets some of the WRs as \u201cunsignaled completion.\u201d Those WRs that are set as unsignaled completion have their completion status indirectly notified by immediately subsequent WRs. The following WRs are set as unsignaled completion if they are immediately followed by other WRs: PostSQ Fast Register and PostSQ Invalidate Local STag.","Similar to the handling of Work Request Completions, there is only one Asynchronous Event handler for an RNIC . That asynchronous event handler is called by the RNIC  when there is an affiliated asynchronous event. The RDMA Module  registers an asynchronous event handler to the miniport at the time the NDIS exchanges call handlers with the miniport. This is the definition of the asynchronous event handler:",{"@attributes":{"id":"p-0148","num":"0211"},"tables":{"@attributes":{"id":"TABLE-US-00024","num":"00024"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"typedef"]},{"entry":[{},"VOID"]},{"entry":[{},"(*NDIS_RDMA_OFFLOAD_ASYNCHRONOUS_EVENT"]},{"entry":[{},"HANDLER)"]},{"entry":[{},"("]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003IN NDIS_HANDLE","NdisMiniportHandle,"]},{"entry":[{},"\u2003IN UCHAR","EventSource,"]},{"entry":[{},"\u2003IN PVOID","EventSourceHandle,"]},{"entry":[{},"\u2003IN ULONG","EventIdentifier"]},{"entry":[{},");"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"Most asynchronous events are signaled when the RNIC  encounters remote or local errors, and the RDMA connection is going to be closed. The RDMA Module  processes the event, logs the error, and initiates the connection tear-down and resource clean-up processes with the RNIC . The RDMA Module  eventually makes the Connection terminate up call back to its user signifying that the connection has been torn down.","When an RDMA CQE is indicated from the RNIC  to the host stack, the host stack usually polls the CQ, takes out all CQEs of the CQ, and processes them one by one. Traditionally, even on a multi-processor computing device, only one processor performs this work while the rest of the processors are idle.  and the following text describe how multiple processors can be used in parallel to speed up CQE processing. This method is applicable to any RNIC  that supports multiple CQE handlers.","In step  of , when an RNIC  is indicated as up to the RDMA module , the RDMA module  sets up a per-interface data structure to track the interface. That per-interface data structure contains an array of descriptors. Each descriptor corresponds to one processor and stores a completion event handler ID for that processor (step ). Later, if there are CQs to be created on that processor, this completion event handler ID is used for them.","The array is initialized at interface up time. The RDMA module  uses the SET_COMPLETION_EVENT_HANDLER verb to set completion event handlers to the RNIC . The RDMA module  calls this verb N times where N equals the number of processors in the system (or the subset of the total number of processors that will be involved in CQE processing). As shown in , for each call the RDMA module  provides the RNIC  with a data structure containing a processor number and a completion callback function. This associates each completion event handler with one processor. For each invocation of the SET_COMPLETION_EVENT_HANDLER verb, the RNIC  returns a unique completion event handler ID. Thus, a one-to-one mapping is established between completion event handler IDs and processors.  illustrates the process of initializing the per-interface completion event handler ID array using the augmented SET_COMPLETION_EVENT_HANDLER call.","When a new RDMA connection is to be established, the RDMA module  decides whether a new CQ should be created for that RDMA connection. If a new CQ is created, then the RDMA module  runs a load-balancing algorithm and other heuristics to determine on which processor to create the CQ (step  of ). Once a decision is made to create a new CQ on a processor, for example on processor K, the RDMA module  uses K as an index into its per-interface array of completion event handler IDs and retrieves the completion event handler ID of processor K. That ID is used as an input to create this new CQ. Doing so effectively tells the RNIC  that this new CQ is bound to processor K. The result of this step is, for each processor, a two-level tree of CQs and QPs rooted from the processor. For a multi-processor computing device, this becomes a forest of trees as illustrated in .","When a CQE is queued into a CQ and a decision is made to indicate the CQE to the host OS (step  of ), the RNIC miniport driver schedules a DPC to run on the processor that is associated with the CQ. The RDMA Module  polls the CQ and processes each CQE polled in the context of the DPC routine (step ). Because multiple DPC routines can run on multiple processors simultaneously, this achieves the goal of parallel CQE processing.","Closing an RDMA connection can be a very complex and error-prone process if not handled carefully. Complexity mainly comes from two aspects: (1) interactions between the host OS and the RNIC  hardware and (2) interactions between the RDMA Module  and the TCP layer of the host OS.","The following rules and processes define the interactions between the RNIC  (and its miniport driver) and the host OS for successfully handling RDMA connection closure. These general rules are illustrated below in the context of specific closure scenarios.\n\n","The TCP Disconnect Request Handler is used by the TCP software stack to issue a graceful or an abortive disconnect request to the RNIC 's miniport driver. The TCP Disconnect Event Handler is used by the miniport driver to indicate a graceful or an abortive disconnect event to the TCP software stack. In the context of RDMA offload, the software stack is notified through this event handler about connection status, and it then performs RDMA state transitions accordingly.","As a first illustration of these concepts,  presents an overview of the procedure for handling a graceful disconnect request. After an RDMA connection is established (step ), the RNIC miniport is called to perform a TCP graceful disconnect (step ).\n\n","When the RNIC miniport is called to perform a TCP abortive disconnect, this is considered the equivalent of \u201cModify QP(RTS\u2192Error).\u201d\n\n","When a graceful disconnect event is signaled by the miniport driver to the host OS through the TCP Disconnect Event Handler:\n\n","When an abortive disconnect event is signaled by the miniport driver to the host OS through the TCP Disconnect Event Handler, the RNIC miniport driver applies normal TCP semantics. Briefly: If a TCP RST is received from the remote peer, indicate this event; If the connection is lost (times out), indicate this event. If the RNIC  wants to send out an RST for whatever reason, indicate this event. For RDMA Chimney, if the miniport needs to perform an abortive LLP close due to RDMA conditions, then the miniport should do so. The miniport is allowed to send out a TCP RST by itself. As soon as the LLP connection is abortively closed, the miniport indicates this abortive disconnect event back to the host.","These are definitions of the semantics and rules of the TerminateOffload call for the RDMA Chimney offload architecture.\n\n","To more fully explain the above concepts,  illustrate the following possible RDMA closing and error scenarios:\n\n","The following abbreviations are used in  and in the accompanying text:\n\n","In :\n\n",{"@attributes":{"id":"p-0166","num":"0277"},"figref":"FIG. 11","b":"308"},"The detailed process is:\n\n",{"@attributes":{"id":"p-0168","num":"0288"},"figref":"FIG. 12","ul":{"@attributes":{"id":"ul0037","list-style":"none"},"li":["(1) Moves the QP to the Closing State.","(2) Resets the TCP connection (by sending out a TCP RST).","(3) Completes the original graceful disconnect request with STATUS_ABORTED.","(4) Moves the QP to the Error State and begins flushing the SQ and the RQ.","(5) Indicates an abortive disconnect event to the TCP stack."]}},"At point A in , the RDMA Module  knows that the connection has been reset (aborted), and it calls down Terminate Offload. It also knows that the QP is in the Error state.","At point B in , the RDMA Module  calls \u201cModify QP(Error\u2192Idle).\u201d If the QP is still flushing, then the miniport driver returns STATUS_PENDING to the RDMA Module  upon a \u201cModify QP(Error\u2192Idle)\u201d request. Once the QP has completed flushing, the miniport driver completes the original \u201cModify QP(Error\u2192Idle)\u201d request with STATUS_SUCCESS. Otherwise, if the miniport driver deems that the RNIC  hardware is taking too long to flush (or is being non-responsive), then the miniport driver can complete the original \u201cModify QP(Error\u2192Idle)\u201d request with a special error status (STATUS_ABORTED). Regardless of the completion status of this request, the host stack begins the RDMA resource destroy sequence which includes a DestroyQP call.",{"@attributes":{"id":"p-0171","num":"0296"},"figref":"FIG. 13","ul":{"@attributes":{"id":"ul0038","list-style":"none"},"li":["(1) The local peer receives a TCP RST from the remote peer.","(2) The LLP close times out. This could be one of the following:","(2.a) After sending out the TCP FIN, the ACK for the FIN never comes back.","(2.b) After sending out the TCP FIN and receiving the ACK for the FIN, the RNIC  and the RDMA Module  expect that the remote peer will shortly send back a TCP FIN. The RNIC  waits for this incoming TCP FIN to complete the LLP close and to move the QP to the Idle state. As soon as a TCP FIN is received, the RNIC  indicates a DisconnEvent(g) back to the host stack and moves the QP to the Idle state. However, the remote peer may never send the FIN (or anything) back. To deal with this, the RDMA Module  fires a timer to wait for that DisconnEvent(g), and if that timer expires, then the RDMA Module  calls Disconn(a) to reset the connection.","(3) After sending out the TCP FIN, any data come in. This is classified as an error case by the verb spec.","(4) Somehow, Work Requests are posted on to the SQ\/RQ when the QP is in the Closing state. This error condition is outlined by the RDMA verb spec.","(5) For a number of reasons, the host stack calls Terminate Offload before the LLP connection is completely closed.\n\nWhenever any of the above errors occurs, the RNIC  resets the LLP connection, indicates an abortive disconnect event to the TCP host stack, and moves the QP to the Error state.\n"]}},{"@attributes":{"id":"p-0172","num":"0304"},"figref":"FIG. 14","b":"308","ul":{"@attributes":{"id":"ul0039","list-style":"none"},"li":["(1) Sends an ACK to the remote peer to acknowledge the TCP FIN.","(2) Modifies QP(RTS\u2192Closing) and starts flushing the RQ.","(3) Indicates DisconnEvent(g) to the TCP host stack.","(4) Shortly after this indication, the TCP stack calls Disconn(g) down to the RNIC miniport.","(5) As soon as the miniport is called with Disconn(g), it sends out a FIN to the remote peer and completes this Disconn(g) after it receives an ACK for the FIN.","(6) Once the RQ flushing is complete and the LLP has been completely closed, it moves the QP to the Idle state. According to the RDMAC verb spec, the miniport must indicate an RDMA Event \u201cLLP Closed\u201d to the consumer. The RDMA Module  is waiting for this event to know that the QP is in the Idle state."]}},"At point A in , the RDMA Module  knows that the LLP has been completely closed so that it can call down Terminate Offload. As soon as the Terminate Offload completes, the RDMA Module  calls Query QP (if necessary) to get the current state of the QP. If the result shows that the QP is in the Closing State, then the RDMA Module  starts a timer to wait for the \u201cLLP Closed\u201d event. At point B, the RDMA event \u201cLLP Closed\u201d is signaled to the RDMA Module  so that the RDMA Module  knows that the QP is in the Idle state, and the RDMA Module  starts the RDMA resource clean-up sequence. Point B may happen at any time after point A.","Note: If some serious problems happened to the RNIC  that prevent it from flushing the RQ successfully, then the RDMA Module  is not signaled with the RDMA event \u201cLLP Closed,\u201d and the QP is hanging in the Closing state. The RDMA Module  does not wait forever for this event: It starts the RDMA resource destroy sequence when a timer expires.",{"@attributes":{"id":"p-0175","num":"0313"},"figref":"FIG. 15","b":"308"},"Note that the RDMA Module  may call Query QP in this case because it needs to differentiate this case from the cases of . For those two cases, the QP should be in the Closing state, and a timer is needed to wait for the RNIC  to signal either a \u201cBad Close\u201d or an \u201cLLP Closed\u201d RDMA event. In the present case, the Query QP returns the Error state, and the processing at point B of  is performed.",{"@attributes":{"id":"p-0177","num":"0315"},"figref":"FIG. 16","ul":{"@attributes":{"id":"ul0040","list-style":"none"},"li":["(1) The local peer receives a TCP RST from the remote peer.","(2) The LLP close times out.","(3) Somehow, Work Requests are posted on to the SQ\/RQ when the QP is in the Closing state. This error condition is outlined by the RDMA verb spec.\n\nWhenever any of the above errors occurs, the RNIC  resets the LLP connection, indicates an abortive disconnect event to the TCP host stack, and moves the QP to the Error state.\n"]}},"Here are further explanations for the error processing in this case:\n\n","Note that in the no-error case (see  and accompanying text), the RNIC  signals the RDMA event \u201cLLP Closed\u201d after it successfully moves the QP state from Closing to Idle. So, the \u201cBad Close\u201d event differentiates the present case from that case.","Also note that the RDMA verb spec requires that the RNIC  signal either \u201cLLP Lost\u201d or \u201cLLP Reset\u201d in case of an LLP failure. However, these two RDMA events are redundant with DisconnEvent(a). In the RDMA chimney, the RDMA Module  always waits on DisconnEvent(a) and ignores RDMA Events \u201cLLP Lost\u201d and \u201cLLP Reset.\u201d","The remaining cases all involve abnormal closes. An RDMA abnormal close is initiated either by the RNIC  itself or by the consumer because of RDMA errors or LLP errors. During an RDMA abnormal close, the LLP connection may be closed abortively or, if possible, gracefully. Typically, a terminate message is sent or received by the RNIC  if conditions allow.",{"@attributes":{"id":"p-0182","num":"0326"},"figref":"FIGS. 17 and 18","ul":{"@attributes":{"id":"ul0042","list-style":"none"},"li":["(1) In the case illustrated by , the local peer's RNIC  detects RDMA operation errors on this connection and initiates an abnormal close. If the LLP is still working, then the RNIC  tries to send a Terminate message and moves the QP to the terminate state. (However, if the LLP is not working, then the RNIC  moves the QP to the Error state directly and does not send a Terminate message, a case illustrated by .)","(2) In the case of , the local peer's consumer determines that the RDMA connection should be abnormally closed and that a Terminate message should be sent to the remote peer. The consumer calls Modify QP(RTS\u2192TERM)."]}},{"@attributes":{"id":"p-0183","num":"0329"},"figref":"FIG. 17","b":["308","308"],"ul":{"@attributes":{"id":"ul0043","list-style":"none"},"li":["(1) Notifies the host stack about the error through either one of the two ways: signaling an asynchronous event or completing a Work Request with error status.","(2) Stops all QP processing and prepares and sends the Terminate message.","(3) Waits for the host stack to call down Disconn(g) to send out a FIN. The host stack calls down Disconn(g) as soon as it (a) receives an RDMA Asynchronous Error Event, (b) polls a CQE with Error Completion status, or (c) receives a DisconnEvent(g) indication.","(4) If the remote peer sends a FIN, the RNIC  sends back an ACK and then notifies the host stack by DisconnEvent(g).","(5) Errors may occur at any time during the process. If any error occurs, the TCP connection is reset (if it is still there), and an DisconnEvent(a) is indicated back to the host stack. The QP is moved to the Error state. Possible errors for this process include:","(5.a) A TCP RST is received from the remote peer.","(5.b) The LLP close times out because (i) an ACK cannot be received for the FIN sent or (ii) the Terminate message cannot be sent.","(5.c) A FIN cannot be received from the remote peer. The remote peer may possibly send nothing back at all. See the discussion of error (2.b) accompanying .\n\nNote that DisconnEvent(g) or DisconnEvent(a) may happen any time after the RNIC  indicates an asynchronous error and sends the Terminate message.\n"]}},"Note that in , point E indicates that a DisconnEvent(g) or a DisconnEvent(a) might also be signaled by the RNIC miniport at this point. The miniport signals DisconnEvent(g) as soon as it receives a TCP FIN from the remote peer and signals DisconnEvent(a) as soon as the LLP is reset or lost. Both of these events may happen before or after the host stack calls down Disconn(g). This is the implication of point E.","After the Terminate Offload call completes, the RDMA Module  may call Query QP to query the current state of the QP if necessary. Query QP is called to differentiate this case from the non-error closing case.",{"@attributes":{"id":"p-0186","num":"0340"},"figref":["FIG. 18","FIG. 18"],"b":"308"},{"@attributes":{"id":"p-0187","num":"0341"},"figref":"FIG. 19","b":"308","ul":{"@attributes":{"id":"ul0044","list-style":"none"},"li":["(1) The local consumer issues a Disconn(a). This is marked as point B in .","(2) The LLP is lost or reset, and the local RNIC  moves the QP state from RTS to Error.","(3) The RNIC  decides to reset the LLP immediately due to various RDMA errors and conditions.\n\nCases (2) and (3) are indicated to the host stack with a DisconnEvent(a) (point A in ).\n"]}},{"@attributes":{"id":"p-0188","num":"0345"},"figref":"FIG. 20","b":"300","ul":{"@attributes":{"id":"ul0045","list-style":"none"},"li":["(1) The LLP times out waiting for the TCP FIN or the local RNIC  never receives an ACK for the FIN sent.","(2) The local RNIC  receives a TCP RST from the remote peer.","(3) After sending out a TCP FIN, the local RNIC  expects the remote peer to send back a TCP FIN shortly. However, this FIN may never come in. This is the same error 2.b discussed above with respect to ."]}},"During the entire process, if the RNIC miniport receives a TCP FIN from the remote peer, it indicates a DisconnEvent(g) to the host stack, and if it receives a TCP RST or if it sends a TCP RST, it indicates a DisconnEvent(a) to the host stack.","Note that in , a DisconnEvent(g) or a DisconnEvent(a) might also be signaled by the RNIC miniport at point E.","No Figure: The remote peer initiates an abnormal close by sending a TCP RST. No Terminate message is sent or received by the local peer. The LLP connection is abortively closed.","In view of the many possible embodiments to which the principles of the present invention may be applied, it should be recognized that the embodiments described herein with respect to the drawing figures are meant to be illustrative only and should not be taken as limiting the scope of the invention. Those of skill in the art will recognize that some implementation details, such as the detailed semantics and procedures of the RDMA Chimney architecture, are determined by specific situations. Although the environment of the invention is described in terms of software modules or components, some processes may be equivalently performed by hardware components. Therefore, the invention as described herein contemplates all such embodiments as may come within the scope of the following claims and equivalents thereof."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["While the appended claims set forth the features of the present invention with particularity, the invention, together with its objects and advantages, may be best understood from the following detailed description taken in conjunction with the accompanying drawings of which:",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 20"}]},"DETDESC":[{},{}]}
