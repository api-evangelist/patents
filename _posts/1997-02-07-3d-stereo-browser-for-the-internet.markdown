---
title: 3D stereo browser for the internet
abstract: A viewer for viewing stereo images either downloaded over a network, such as the Internet, or resident on a personal computer uses a graphical user interface (GUI) to facilitate the display of wireframes with or without texture applied in a variety of formats. In stereo mode, the GUI permits adjustment of the neutral plane and of camera offset. The file sizes utilized with the viewer are very small and permit rapid transmission over a network. The files contain wireframe information, texture map information and animation information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07038698&OS=07038698&RS=07038698
owner: 
number: 07038698
owner_city: 
owner_country: 
publication_date: 19970207
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","BEST MODE FOR CARRYING OUT THE INVENTION"],"p":["This application claims priority of U.S. Application Ser. No. 60\/011,356 filed Feb. 8, 1996 which is hereby incorporated by reference in its entirety.","When capturing and reproducing 3-dimensional images in the prior art, information from one camera of a stereo pair of cameras was depicted as one color (e.g. orange) or band of colors and information from the other camera of the pair was depicted in a complimentary color or color band. When viewing such images through 3-dimensional viewers, such as red\/blue glasses, the reproduced image would not be perceived in color.","The orange elements in the picture are only seen through the blue lens, the red lens \u201cwashing out\u201d the orange elements. For the same reason, the green-blue elements are only seen through the red lens. Hence, each eye sees only one of the two colored pictures. But because the different colored elements are horizontally shifted in varying amounts, the viewer's eyes must turn inward to properly view some elements, and turn outward to properly view others. Those elements for which the eyes turn inward, which is what the viewer does to observe a close object, are naturally perceived as close to the viewer. Elements for which the viewer's eyes turn outward are correspondingly perceived as distant. Specifically, if the blue lens covers the viewer's right eye, as is generally conventional, then any blue-green element shifted to the left of its corresponding orange element appears to the viewer as close. The element appears closer the greater the leftward shift. Conversely, as a green-blue element is shifted only slightly leftward, not at all, or even to the right of its corresponding red element, that element will appear increasingly more distant from the viewer.","When 3-dimensional images are captured, corresponding points of the left image are displaced from the same points in the right image horizontally. A measurement of the amount of displacement is called \u201cdisparity\u201d. In the prior art when stereo images are made, the disparity for all subject matter visible in both images is fixed. In digital images, disparity can be measured in terms of the number of pixels a point on a left image is displayed from the corresponding point in the right image. Fixed focal length lenses are customarily used for the cameras","In an object with zero disparity, the corresponding pixels for the left and right images are perfectly superimposed and the object appears to be located on the screen. Zero disparity objects are seen most clearly when the eyes are crossed just enough to focus on the plane of the screen. Negative disparity objects appear to come out of screen toward the viewer and are seen most clearly when the eyes are more crossed. Positive disparity objects appear to be more distant than the screen and are seen most clearly when the eyes are less crossed.","The eyes cross or uncross in order to get similar image features on or near the fovea of each eye. The \u201cfarthest\u201d object that can be seen in an anaglyph is limited by the observers ability to comfortably uncross the eyes. (The usual limit to distant viewing is set by the condition where the eyes look along parallel axes, as when looking at a very distant object such as a star in the night sky. When the eyes attempt to diverge beyond the parallel axes viewing limit, a \u201cwall-eyed\u201d condition exists that is rarely comfortable to the observer.)","Some stereo images cover such a great range of depth and will have such widely varying values (even without a \u201czoom-in\u201d) that some portions of the image will always be out of range of the observer's ability to see the stereo effects, regardless of how the anaglyph was formed.","Three dimensional techniques are closely related to the psychology and physiology of an observer's cognitive processes. Subtle changes in selection of portions of the spectrum presented to each eye can result in significant changes in the observer's perception. Even when viewing the same 3-dimensional image through the same viewers, different observers may perceive a 3-dimensional image in different ways.","The depth location of the point at which the left and right image points for objects at that distance coincided constitutes a \u201cneutral plane\u201d and when observing a fixed disparity 3-dimensional image, the neutral plane would be found at the surface of the medium of reproduction (i.e. paper or CRT display). Items that appear closer than the medium surface and those points in the image which appear behind the neutral plane would have different disparity. The loss of depth perception when disparity exceeds a certain value generally means that when zooming-in on part of a stereo image pair that disparity will become so great that depth perception will be lost.","In the prior art, there is no way to control an image so as to position it either in front of or behind a neutral plane in a controllable fashion. This limits the ability to create 3-dimensional animations.","In addition, both anaglyphs in stereoscopic optical arrangements are known which permit a user to view images in stereo either using red-blue glasses or separate optical channels for each eye.","Computer systems are also known which attempt to provide a sense of \u201cvirtual reality\u201d by which a user perceives a computer generated environment as if the user were immersed in that environment. Typically, these systems permit a measure of interaction between the user and the computer simulated environment. To make the virtual reality environments appear realistic, it is preferable that a user see the environment in three dimensions or, in other words, in a stereo view.","The Problems","One of the serious problems of the prior art is the fact that three dimensional stereo presentations, whether static images or dynamic animations of some sort, typically require much more memory than an XY image that does not contain depth information or suffer from a loss of resolution in the vertical image direction to \u201cline interlace\u201d effects that are necessary to convey \u201chalf-image\u201d information to the left eye and \u201chalf image\u201d information to the right eye. The size of the files associated with a virtual reality presentation therefore constitute a substantial impediment to the use of those files across networks, especially relatively low speed networks such as the Internet. This is especially true for dynamic, animation presentations where even simple non-stereoscopic-viewing \u201cflick\u201d files (Autodesk *.FLC and *.FLI files), audio-visual-interlace files (Microsoft *.AVI files) and Apple Quicktime VR files can easily occupy 5\u2013100 Mbytes of file space.","It would thus be desirable to have a \u201csmall file\u201d size (20\u2013300 Bytes of file space) virtual reality system which would permit rapid file transfer across a relatively low speed network for interactive display with the user at the other end of the network connection.","Another problem with the prior art is that typically, even if the large files can be transferred, the processing required to render a surface texture on a three dimensional wire frame has been excessive. As a result, extremely high performance work stations have been required to do even relatively simple transactions involving virtual reality or stereoscopic presentations.","Further, the generation of wire frames and their subsequent texturing has been an extremely expensive, time consuming process. It would be desirable to be able to capture images, create wire frames and package them for presentation to a user in a rapid, efficient and cost effective manner.","The problems with the prior art are overcome in accordance with one aspect of the invention, by providing a three dimensional stereo viewer which is suitable for use with the Internet and with other relatively low speed networks.","In accordance with another aspect of the invention, both wire frame, texture map information and animation information are stored in a single file for use in the rapid creation and rendering of three dimension stereo images.","Another aspect of the invention lies in the very rapid capture and creation of wire frames from image data and their subsequent texturing using only relatively inexpensive and readily available personal computer systems.","The invention also relates to a computer having a processor, a memory, and a stereo viewer loaded in memory, said stereo viewer including a graphical user interface including a viewing window in which wireframes can be viewed with and without texture and a plurality of controls for manipulating a wireframe, a wireframe's texturing or a view of a wireframe.","The invention also relates to a computer system, having a network, at least one server connected to said network containing files of images to be presented in stereo, a computer, having a memory and a browser application, connected to said network, for retrieving one or more files of images to be presented in stereo, and a stereo viewer loaded in said memory, said stereo viewer including a graphical user interface including a viewing window in which wireframes can be viewed with and without texture and a plurality of controls for manipulating a wireframe, a wireframe's texturing or a view of a wireframe.","The invention is also directed to a method of storing wireframe information for presentation as a stereo image, by: storing x,y,z coordinates of vertices of a wireframe together with X\u2032Y\u2032 coordinates specifying a corresponding location in a bit map containing texturing information.","The invention is also directed to a method of displaying wireframe information stored in a file, by extracting wireframe vertex information and a compressed bit map from said file, decompressing said compressed bitmap, and displaying a wireframe specified by said wireframe information, with texture taken from said bitmap. Animation information extracted from the file may also be used to control the display of the textured wireframe in a sequence of different positions and orientations.","The invention is also directed to a computer program product, including a memory medium, and a computer program stored on said memory medium, said computer program containing instructions for storing x,y,z coordinates of vertices of a wireframe together with u,v coordinates specifying a corresponding location in a bit map containing texturing information.","The invention is also directed to a computer program product, comprising: a memory medium, and a computer program stored on said memory medium, said computer program containing instructions for extracting wireframe vertex information and a compressed bit map from said file, decompressing said compressed bitmap, and displaying a wireframe specified by said wireframe information, with texture taken from said bitmap","The invention is also directed to a computer program product, including a memory medium, and a computer controlling information stored on said memory medium, said computer controlling information including vertex location information for a plurality of vertices, a bit map of texture for faces of a wireframe and a set of u;v coordinates for each vertex pointing to a corresponding location on said bit map.","Still other objects and advantages of the present invention will become readily apparent to those skilled in the art from the following detailed description, wherein only the preferred embodiment of the invention is shown and described, simply by way of illustration of the best mode contemplated of carrying out the invention. As will be realized, the invention is capable of other and different embodiments, and its several details are capable of modifications in various obvious respects all without departing from the invention. Accordingly, the drawings and description are to be regarded as illustrative in nature and not as restrictive.",{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 1","b":["100","110","100","120","100","120","100"]},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 2"},"A central processing unit (CPU)  is connected to bus . A drive controller  is also coupled to the bus  for controlling writing to and reading from a variety of drives. Theses drives may be a CDROM , a hard drive , a floppy drive  or some other device which can be modeled as a drive. Display controller  interfaces the computer display, such as a cathode ray tube or a semiconductor or liquid crystal display. An I\/O controller  interfaces both the mouse  and the keyboard  and manages the gathering of information required to interact with the user during the use of the computer. Communications port  is also connected to bus  and serves to provide a link to a network, if a network connection is desired.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIG. 3","FIG. 2"],"b":["300","310","310","330"]},"The operating system is preferably the Windows 95 operating system from Microsoft. The browser  is preferably the Netscape browser from Netscape Communications Corporation. The .vrx viewer  is the subject of this application and is discussed more hereinafter.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 4","FIG. 2"],"b":["400","410"]},{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 5","b":["100","500","100","100","520"]},{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 6","FIG. 6"],"b":["610","600"]},"Animation Information () specifies a sequence of views of the wireframe by specifying, for example, the object position and orientation and camera position and\/or orientation. This permits a sequence of views of the wireframe to be displayed either with or without texture.","The one of the L1 or R1 images to be utilized for providing texture is converted to a .jpg (JPEG\u2014(Joint Motion Pictures Expert Group)) standard format and compressed at step . Compression algorithms other than JPEG may be used. They include Fractal compression, Wavelet compression, and many others. JPEG was selected because of the universal use by the PC community of graphical users. The 0.3DP file as output from the Wire Frame Express may require some conversion of format before being passed to the rendering engine for the application of texture to a wire frame (). The file format utilized in this particular application, is a .dat file and is a format required by the preferred rendering engine. In the preferred embodiment, the rendering engine is BRender, version 1.1.2, produced by Argonaut Technologies Limited of Capitol House, Capitol Way, Colindale, London NW9 0DZ, United Kingdom. Alternative rendering engines can be \u201cReality Lab\u201d 3D Application Programming Interface by RenderMorphics Ltd, 3DR and MMX technology by Intel and DirectX by Microsoft.","The .jpg texture map and the .dat wire frame representation from blocks  and , respectively, are compressed in block , the output of which forms the .vrx viewer file . The particular compression algorithm utilized is not important. What is important is that it is desired to have both the wire frame information from block  and the texture information from block  in a single file. This avoids having a fragmented downloading process and permits all information to be available for viewing at the viewer.","Note that there are relatively few products which will create wire frames from two digital images of the same scene. The Wire Frame Express product from Synthonics Technologies of Westlake Village, Calif., permits this to be done with great facility and with great economy of vertices. As a result, the resulting file sizes are considerably smaller than would otherwise be required.","Note also that when utilizing images for the creation of wire frames, it is often desirable to take pictures of a three-dimensional object at approximately every 30 degrees of solid angle so that wire frames created utilizing pairs of adjacent pictures can be pieced together into a wire frame covering 360 degrees of solid angle. This is not required, however, it is desirable when a large portion of a real object is to be modeled. When a model is piecewise constructed in the manner just described, the construction of the .vrx viewer file will include a plurality of segments, each segment constituting wire frame vertices converted in a manner suitable for the rendering engine together with bit map image information selected for use with that wire frame. Thus, a multi-segment project will have a plurality of files of wire frame vertices and respective bit mapped texture information which can be assembled into an entire textured model of the object.",{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 7","b":["650","710","740","720","730","730","760","770"]},{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 8"},"Although a particular coordinate system may be utilized to define a wire frame, when the wire frame so defined is moved to a different system, it will be viewed from a different perspective location, such as the origin of the L, M, N coordinate system. Thus, the projection of vertices, L, M, N on a plane between the vertex and the origin will define an L\u2032M\u2032 intersection point. Note that the value of X, Y, Z can be related to the value of L, M and N by a simple generalized coordinate transformation.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":["FIG. 10","FIG. 9","FIG. 10"],"b":["1110","1110","1120","1130"]},{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 11","b":["1100","1110","1120","1130","1120","1100","1110"]},{"@attributes":{"id":"p-0074","num":"0073"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["Icon No.","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2002(1)","EXIT"]},{"entry":["\u2002(2)","File Open"]},{"entry":["\u2002(3)","Reset Center"]},{"entry":["\u2002(4)","Reset Roll"]},{"entry":["\u2002(5)","Toggle Stereo"]},{"entry":["\u2002(6)","Display Wireframe"]},{"entry":["\u2002(7)","Display Face Map"]},{"entry":["\u2002(8)","Display Textured Object"]},{"entry":["\u2002(9)","Magnify"]},{"entry":["(10)","Reduce"]},{"entry":["(11)","Spin Object"]},{"entry":["(12)","Animate Object"]},{"entry":["(13)","Move Neutral Plane In"]},{"entry":["(14)","Move Neutral Plane Out"]},{"entry":["(15)","Increase Camera Offset"]},{"entry":["(16)","Decrease Camera Offset"]},{"entry":["(17)","About"]},{"entry":["(18)","Help"]},{"entry":["(19)","Display Wireframe and Texture Map"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 12","b":["1200","1210","1220","1230"]},{"@attributes":{"id":"p-0076","num":"0075"},"figref":"FIG. 13","b":["1300","1305","1310","1330","1335","1340","1345","1350"]},{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 14","b":["1400","1410"]},{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 15","b":["1500","1510","1520"]},{"@attributes":{"id":"p-0079","num":"0078"},"figref":["FIG. 16","FIG. 11"],"b":["1610","1650","1610","1020","1030","1630"]},{"@attributes":{"id":"p-0080","num":"0079"},"figref":"FIG. 17","b":["1700","1710"]},{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 18","b":["1800","1810"]},{"@attributes":{"id":"p-0082","num":"0081"},"figref":"FIG. 19","b":["1900","1910","1920"]},"Thus, Icons 6, 7, 8 and 19 describe four different image modes. In the first, only the wire frame is displayed. It had no texturing. In the second, a very plain texture is applied to the wire frame. In the third bit map information from the .vrx file is utilized to apply texture for the wire frame and in the fourth, both the wireframe and the textured object are displayed.","When captured using Wire Frame Express, the vertex information for the wire frame contains many fewer vertices than would be otherwise required if a wire frame were created, for example, using a Cyberware scanner known from the prior art. In Wire Frame Express, large areas can be circumscribed by points forming a closed polygon around a loop. With such surface elements defined, the texture bit map can be applied directly to the area circumscribed by the polygon. Certain types of wire frame handling products are incapable of handling polygons, but require instead triangles. If that is the case, the area bounded by the polygon can be partitioned into triangular subelements and texture applied to the individual subelements accordingly. The file output from Wire Frame Express includes, the X, Y, Z, and X\u2032Y\u2032 locations points discussed in connection with .","Each vertex is associated with a pair of coordinates U and V which represent the relative position of that vertex in the bit mapped image utilized to apply texture. For example, if the raw pixel data derived from decompressing at both the .vrx and .jpg level into raw pixel data, contained 1,000 pixels in a horizontal direction and 1,000 pixels in a vertical direction for display, a pixel located at point , would be identified by UV coordinates as U=0.1 and V=0.1. The 0.1 represents on a scale, typically from zero to one, the percentage of displacement in the X direction or the percentage of displacement in the Y direction where the bit map texture information for that vertex begins. Thus, when texturing a wire frame, the U,V information contained in the Wire Frame Express file format is passed to the rendering engine so that it will know exactly where to begin placing texture information on a particular face of the surface bounded by vertices.",{"@attributes":{"id":"p-0086","num":"0085"},"figref":"FIG. 20","b":["2000","2010","2020","2030"]},{"@attributes":{"id":"p-0087","num":"0086"},"figref":"FIG. 21","b":["2100","2110","2120","2130","2140"]},{"@attributes":{"id":"p-0088","num":"0087"},"figref":"FIG. 22","b":"2200"},{"@attributes":{"id":"p-0089","num":"0088"},"figref":"FIG. 23","b":["2320","2330","2340"]},{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 24","b":"2410"},{"@attributes":{"id":"p-0091","num":"0090"},"figref":"FIG. 25","b":["2500","2510"]},{"@attributes":{"id":"p-0092","num":"0091"},"figref":"FIG. 26","b":["2600","2610"]},{"@attributes":{"id":"p-0093","num":"0092"},"figref":"FIG. 27","b":["1900","1910","1920"]},"In the preceding, a graphical user interface has been described which overcome the problems of the prior art and permits the rapid, efficient and cost effective display of three dimensional stereo information to the user.","There has been shown and described only the preferred embodiment of the invention, but, as aforementioned, it is to be understood that the invention is capable of use in various other combinations and environments. It is capable of changes or modifications within the scope of the invention concept as expressed herein."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 4","FIG. 2"]},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 27"}]},"DETDESC":[{},{}]}
