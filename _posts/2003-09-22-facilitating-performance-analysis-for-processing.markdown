---
title: Facilitating performance analysis for processing
abstract: Facilitating performance analysis for processing includes capturing a state of a processing unit and capturing a plurality of commands submitted to the processing unit for processing. Both the captured state and the captured plurality of commands are also saved. The saved state and commands can be used for analysis, such as by processing only a subset of the commands or processing a modified set of the commands.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07095416&OS=07095416&RS=07095416
owner: Microsoft Corporation
number: 07095416
owner_city: Redmond
owner_country: US
publication_date: 20030922
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This invention relates to performance analysis, and more particularly to facilitating performance analysis for processing.","As computing technology has advanced, the hardware on which video games are run has also advanced and lead to increasingly complex video games. Such complexity can result in video games with excellent graphics and a wide range of actions that can be performed by the users. However, such complexity can also make it difficult for game designers to create video games.","Problems or errors encountered in building and designing video games oftentimes are resolved by \u201cdebugging\u201d the instructions that make up the video game. Unfortunately, such debugging can be a very tedious and time-consuming process. For example, in order to maintain the desired playback rate for frames in a video game (typically a rate of 30 frames per second or 60 frames per second), each frame should require no more than a designated amount of time to be drawn (e.g., at 60 frames per second, each frame should require no more than 16.67 ms (milliseconds) to be drawn). If this designated amount of time is exceeded, then the video playback can appear slow and the on-screen action may not appear smooth. When the game designer sees portions of the video playback that are slow, he or she typically tries to debug the instructions by finding out why the designated amount of time is being exceeded, and changing the instructions so that the certain amount of time is no longer exceeded.","Such debugging, however, can be very difficult. One reason for this difficulty is that many video games are designed to be run on game systems that include a graphics processing unit (GPU). The GPU receives commands to draw various aspects of a scene, and renders the scene as indicated by these commands. Unfortunately, the GPU frequently provides very little feedback, if any, to the designer as to why the certain amount of time may be violated. As such, much of the debugging effort is reduced to a trial and error methodology. Thus, it would be beneficial to improve the quality and\/or amount of information available to game designers as they build and test their video games.","Facilitating performance analysis for processing is described herein.","According to certain aspects, a set of commands to be submitted to a processing unit is identified. A subset of the set of commands is selected and submitted to the processing unit for processing. The processing performed by the processing unit in response to the subset of the set of commands is analyzed.","According to other aspects, a stream of commands previously submitted to a processing unit is identified. The stream of commands are modified and the modified of commands are submitted to the processing unit. A difference between a first amount of time required by the processing unit to process the stream of commands and a second amount of time required by the processing unit to process the modified stream of commands is determined.","According to other aspects, a state of a graphics processing unit is captured. A plurality of commands submitted to the graphics processing unit in order to draw a frame of video is also captured. Both the captured state and the captured plurality of commands are saved.","Facilitating performance analysis for processing is described herein. Although discussed herein primarily with reference to graphics processing and graphics processing units, performance analysis for other types of processors can also be facilitated. Commands submitted to a graphics processing unit (GPU) for drawing a frame of video data are captured and saved. These captured commands can subsequently be modified and submitted to the GPU, and\/or only some of the commands may be submitted to the GPU. By modifying the captured commands appropriately, and\/or submitting appropriate subsets of the captured commands, a wide variety of information can be obtained regarding how the frame is being drawn.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 1","b":["100","100","100"]},"In process , commands for drawing a frame of video data are captured and saved. The video data is typically the video portion of a video game, such as video games played on gaming consoles or computers. However, it is to be appreciated that the video data may be associated with other types of applications other than video games, such as educational or reference applications, simulation or emulation applications, productivity or office applications, and so forth.","Video is typically made up of a series of individual images which are played back sequentially. When played back at a fast enough rate, different objects within these images appear to the human eye to move smoothly. Each one of these individual images is referred to as a frame or a scene herein. Different rates of playback can be used, and the rates of 30 frames per second or 60 frames per second are commonly used with the NTSC (National TV Standards Committee) standard.","Process  is initiated by a request, typically from a user, to initiate a frame capture. In response to the request, the state of the graphics processing unit is captured (act ) when drawing of the current frame is finished. Given the speed at which video frames are drawn, a request to capture a frame or scene is typically received while another frame or scene is being drawn. Process  waits until drawing of the current frame is finished so that all of the data desired to be captured for drawing an entire frame can be captured.","The state of the graphics processing unit refers to all of the registers, buffers, and\/or other memory of the graphics processing unit in which variables or settings are stored. These variables or settings are used by the graphics processing unit in drawing frames. A variety of different variables or settings may be used, such as shading or lighting variables, transparency variables, and so forth. Many of these variables and\/or settings can be programmed by the game designer, and thus their settings are relevant to the frame about to be drawn. For example, a frame being drawn may appear differently if transparency is turned on than if transparency is turned off.","After the state of the graphics processing unit is captured, the commands sent to the graphics processing unit for a frame are captured (act ). The number of commands sent to the graphics processing unit in order for the unit to draw a single frame can vary, but can easily be in the hundreds if not thousands of commands. Additional information associated with these commands (e.g., the contents of memory referenced by the commands) may also be captured, as discussed in more detail below. A set of commands sent to the graphics processing unit is also referred to herein as a command stream or stream of commands.","The captured state of the graphics processing unit from act  and the captured set of commands from act  are saved (act ). By saving the state of the GPU and the captured set of commands, at a later time the GPU can be set to the same state as when the set of commands were captured, and then selected ones of the commands can be submitted to the GPU, as discussed in more detail below.","Alternatively, rather than capturing the commands or in addition to capturing the commands, timing data may be captured in act  and saved in act . As discussed in more detail below, this timing data can identify, for example, an amount of time taken to draw the frame and\/or amounts of time taken to draw different parts of the frame.","The set of captured commands can optionally be modified (act ). This modification can be changing one or more of the commands in the set, adding one or more commands to the set, removing one or more commands from the set, and\/or reordering one or more commands in the set. The specific way in which the modification is performed can vary based on the type of information to be ascertained. For example, the modification may involve analyzing the set of commands to identify redundant commands and then removing those redundant commands. Additional details regarding modifications to the set of captured commands are discussed below.","The GPU is then set to the state that was captured in act  (act ). This setting can be performed by, for example, setting all of the registers, buffers, and\/or other memory of the graphics processing unit in which variables or settings are stored to the same settings as were captured in act .","Once the GPU is set to the captured state, at least a subset of the set of commands captured in act  are sent to the GPU (act ). These commands sent to the GPU in act  may optionally include the set of commands as modified in act . For example, if there are commands to draw the terrain in a frame and commands to draw characters in the frame, only the commands to draw the terrain may be sent to the GPU in act  to allow the user to see how the terrain was drawn without the characters being present. By way of another example, if the set of commands is modified in act  to remove the redundant commands, then the modified set of commands (having the redundant commands removed) may be sent to the GPU in act .","After the commands are sent to the GPU in act , feedback is returned based on the commands sent in act  (act ). This feedback can take a variety of different forms. For example, the feedback may be the frame drawn given the commands sent to the GPU in act . By way of another example, the feedback may be an indication of how long it took the GPU to draw the frame given the commands sent to the GPU in act . The feedback may also take other forms, as discussed in additional detail below.",{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 2","b":["150","150","152","154","152"]},"Game device  includes a central processing unit (CPU)  and a graphics processing unit (GPU) . CPU  runs a game or other application , and during running of the game  various commands are presented to GPU  in order to generate the video data for display by the game. Any of a variety of conventional CPUs and GPUs can be used as CPU  and GPU , respectively. GPU  processes the commands it receives and outputs its results into a memory commonly referred to as a frame buffer. Once GPU  has processed all of the commands it has received and output its results to the frame buffer, the display device can display the frame using the contents of the frame buffer. In certain embodiments, the frame buffer is a bit map that identifies, for each pixel of the display device, what color is to be displayed for that pixel. The processing of the commands and outputting of results into the frame buffer by GPU  is also referred to as GPU  drawing the frame.","The video is displayed on one or more display devices , and the user can control the game through one or more input devices . Display device  is intended to represent any device on which video can be displayed. Display device  can be, for example, a television (e.g., cathode-ray tube (CRT), plasma, projection, etc.), a computer monitor (e.g., CRT, plasma, LCD, etc.), a display device built into the same housing as game device  (e.g., a plasma display, LCD display, etc.), and so forth. Input device  is intended to represent any device which can input data to the game device . Input device  can be, for example, a handheld controller (e.g., having a joystick(s), button(s), and\/or triggers), a mouse or other cursor control device, a steering wheel and pedals, a keyboard, a microphone, and so forth. Input device  can be external to game device , or alternatively may be included as part of game device .","Computing device  is a remote device to game device . Computing device  may be located close to game device  (e.g., on the same desk or in the same room), or alternatively may be located further away from game device  (e.g., in another part of the building, or across the Internet). Computing device  represents any of a variety of computing devices (e.g., a desktop PC, workstation, portable or notebook computer, etc.). Computing device  similarly is coupled to (and\/or includes) one or more display devices  and one or more input devices . Display device  can be any device on which video can be displayed, analogous to display device . Input device  can be any device which can input data to computing device , analogous to input device .","Computing device  includes a capture control application  that is executed by one or more processors (not shown) of computing device . Capture control application  displays, on display device , a user interface that allows a user (e.g., a game designer or tester) to request that frames of video be captured and\/or to present feedback (e.g., from act  of ) to the user by way of display device .","When a user, such as a game designer or tester, desires to capture a frame of video data, he or she indicates to capture application  to begin capturing a frame of video data. Capture application  can be invoked to begin capturing a frame of video data in a variety of different manners. In certain embodiments, a command is entered by the user to capture control application  by way of input device  (e.g., a keyboard sequence may be entered, a \u201ccapture\u201d button or menu option displayed in the user interface provided by application  may be selected, a verbal command may be input, and so forth). When such a command is received by application , application  sends a request to capture application  for capture application  to begin capturing a video frame. In other embodiments, the command may be entered by the user to capture application  by way of input device  (e.g., a keyboard sequence may be entered, a sequence of buttons, triggers, and\/or joystick positions on a game controller may be entered, a verbal command may be input, and so forth).","The game designer or tester may desire to capture frames of video data at different times for a variety of different reasons. For example, the designer or tester may simply desire to randomly capture video frames while playing the game in order to analyze the frames and verify they are being drawn as desired. By way of another example, the designer or tester may play the game and, whenever he or she perceives that the game is running slower than he or she believes it should, then he or she can have a video frame selected at this \u201cslow\u201d spot. This allows, for example, the designer or tester to analyze a frame in a \u201cslow\u201d spot of the game in order to ascertain whether the frame is being drawn as fast as it should be, and if not why not.","When capture application  receives the command to begin capturing a video frame, application  waits for drawing of the current frame to finish, then captures the state of GPU  and saves that state in capture storage . Capture storage  can be any of a variety of storage devices (e.g., volatile or nonvolatile memory such as RAM or Flash memory, a magnetic or optical disk, etc.). Although illustrated as being part of game device , capture storage may be located entirely or partially elsewhere. For example, capture storage  may be distributed across multiple storage devices, or may be located entirely on a storage device in another location. Other locations where capture storage  may be located include an input device , computing device , input device , and so forth.","After capturing the state of GPU , capture application  proceeds to capture all commands that are sent to GPU  for the frame and stores the captured commands in capture storage . Capturing the commands sent to GPU  is a process in which running application , which sends commands to GPU , is interrupted each time it sends a command and the command is copied into capture storage . When the command has been copied, running application  continues to execute and submits its next command to GPU . After all of the commands for the frame have been sent to GPU , capture application  stops capturing the commands. Capture application  then waits until it again receives a command to capture a frame before proceeding to capture any additional frames.","Although described herein as typically capturing only one frame at a time, alternatively multiple frames may be captured by capture application  when it receives a command to capture a frame. Capture application  may be pre-configured or pre-programmed with a number of frames it will capture when it receives a command to capture a frame, capture application  may have a default number of frames it will capture, the user that initiates the command to capture a frame may supply as part of the command the number of frames to be captured, and so forth. For example, capture application  may capture two, three, four, or more consecutive frames in response to such a command. By way of another example, capture application  may capture one frame, then capture a second frame some amount of time afterwards (e.g., the second frame may be the 45frame after the command is received). By way of yet another example, a user may specify when the capture is to begin and then frames are captured until the user specifies that the capture should end. In this situation, a variable number of frames would be captured.","Capture application  can capture timing data regarding commands submitted to GPU  and\/or the commands submitted to GPU . When timing data and the commands are both captured, care should be taken that the time involved in capturing of commands is not reflected in the captured timing data. This situation can be resolved in different manners. In certain embodiments, either the timing data or the commands are captured, and then the game  is informed that it should repeat the frame. The game repeats preparing that frame at which time the other of the timing data and commands are captured. In alternate embodiments, the commands are captured and then timing data is obtained subsequently as part of the analysis process (e.g., in acts  and  of ).","The way in which the state of the GPU  and the commands sent to the GPU  (or timing data) are captured can vary. The state of the GPU  and commands sent to the GPU  may be captured in different manners due to design choices as well as due to differences in the architecture of GPU  and\/or game device .","In certain embodiments, game device  includes a Direct3D\u00ae (D3D) Application Programming Interface DLL (dynamic link library) which is a library of graphics functions that can be invoked by game . Capture application  can optionally be incorporated into the D3D library.","Table I illustrates an example list of CPU events for which timing data can  be captured, as well as whether there is a GPU event that corresponds to the CPU event. These events refer to calls to API (application programming interface)  functions or procedures. The time when the call to the API is made, as well as when the called function or procedure ends, is recorded as part of the timing data.",{"@attributes":{"id":"p-0066","num":"0065"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE I"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["CPU Event","API","GPU Event"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Clear","Clear","Yes"]},{"entry":["DrawVertices","DrawVertices,","Yes"]},{"entry":[{},"DrawPrimitive"]},{"entry":["DrawVerticesUP","DrawVerticesUP,","Yes"]},{"entry":[{},"DrawPrimitiveUP"]},{"entry":["DrawIndexedVertices","DrawIndexedVertices,","Yes"]},{"entry":[{},"DrawIndexedPrimitive"]},{"entry":["DrawIndexedVerticesUP","DrawIndexedVerticesUP,","Yes"]},{"entry":[{},"DrawIndexedPrimitiveUP"]},{"entry":["CopyRects","CopyRects","Yes"]},{"entry":["BeginPush\/EndPush","BeginPush\/EndPush","Yes"]},{"entry":["RunPushBuffer","RunPushBuffer","Yes"]},{"entry":["Begin\/End (Vertices)","Begin\/End","Yes"]},{"entry":["Swap","Swap, Present","No"]},{"entry":["LockSurface","D3DSurface_LockRect","No"]},{"entry":["LockTexture","D3DTexture_LockRect","No"]},{"entry":["LockVertexBuffer","D3DVertexBuffer_Lock","No"]},{"entry":["LockPalette","D3DPalette_Lock","No"]},{"entry":["BlockOnObject","D3D block","No"]},{"entry":["BlockOnPushbuffer","D3D block","No"]},{"entry":["BlockOnFence","D3D block","No"]},{"entry":["BlockUntilIdle","D3D block","No"]},{"entry":["BlockOnSwap","D3D block","No"]},{"entry":["VBlank","None","No"]},{"entry":["VBlankSwap","None","No"]},{"entry":["VBlankMissed","None","No"]},{"entry":["PrimeVertexCache","PrimeVertexCache","Yes"]},{"entry":["DrawTri\/RectPatch","DrawTri\/RectPatch","Yes"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"Capture application  can obtain the current state of GPU  in a variety of manners. In certain embodiments, capture application  submits one or more commands specific to GPU , in response to which GPU  returns its state (e.g., the current values of all of the registers, buffers, and\/or other memory of GPU  in which variables or settings are stored). Other static information in GPU  may also be obtained as part of the capture, such as the instructions of programs used internally by GPU  (e.g., pixel shader or vertex shader programs used GPU ). In other embodiments, the regions of memory in GPU  are accessible by memory address to capture application , and capture application  can read from these memory addresses.","Capture application  can capture commands sent to GPU  by monitoring the commands that are sent to GPU  (e.g., from the D3D DLL). Every time a command is sent from the D3D DLL library, application  captures the command and all of the parameters of the command. Additionally, some commands may have as parameters references to other memory locations. In these situations, application  obtains the data from the referenced memory location(s) and captures that data as well. Additionally, rather than always capturing the data at the referenced memory location, application  can check whether that memory location was previously referenced by another command already captured for this frame\u2014if so, then application  can check whether the data previously obtained from that memory location is the same as the data currently obtained from that memory location, and if so then the data need not be captured again for this command. Such a check can be performed in different manners, such as by maintaining a record of memory locations accessed and their contents when accessed, by searching through the commands already captured, and so forth.","By obtaining data from other memory locations referenced in calls to GPU , the capture performed by application  is more robust. As a specific example, assume that texture mapping is being used to draw the surfaces of tree leaves in a frame. The texture mapping for the leaves is stored in the same memory location, but CPU  may modify that texture mapping for two different leaves in the frame. So, even though each command sent to GPU  references the same memory location, the texture mapping used for the two different leaves is different. Thus, in order to accurately capture the frame being drawn, the data at that memory location (the texture map) should be captured as well.","In certain embodiments, a capture opcode in the D3D DLL is used to indicate whether the next frame is to be captured. When a command to capture a frame is received by capture application , capture application  sets the capture opcode. The end of a frame is indicated by game  by use of a Present( ) or Swap( ) call. When a Present( ) or Swap( ) call is detected by the D3D DLL, the D3D DLL checks whether the capture opcode has been set. If the capture opcode has been set, then application  proceeds to begin capturing the next frame. Additionally, application  clears the capture opcode so that at the end of the frame being captured the capture opcode will not be set and another frame will not be captured.","Additionally, the game designer may design the game to specify certain information when the game is submitting commands to GPU . For example, the game designer may include information identifying what part of the frame is being drawn (e.g., the character's left arm, the character's right arm, the character's weapon, the background terrain, etc.). When such information is present, capture application  can capture this information and save it in capture storage . This captured information can then subsequently be used when feedback is presented to the user (e.g., in act  of ). For example, a timeline may be presented to the user in act  of  showing when different parts of the frame were drawn, and the information identifying what part of the frame is being drawn at any particular time can be shown on the timeline.","In addition, stack trace information may also be captured by application . Stack trace information tells the user which software routines called a particular function (e.g., a D3D function) which resulted in a command being sent to GPU . Each time a function is called, the return address is placed on the stack. The stack trace is obtained by parsing back through the stack from the current stack pointer and retrieving these return addresses. Using this series of return addresses, capture application  examines the symbols for running application  and converts the addresses to symbols that are more informative to the user. For example, a fully resolved stack trace might look something like the following:",{"@attributes":{"id":"p-0073","num":"0072"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Main( )"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"GameLoop( )"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Render( )"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"DrawMainCharacter( )"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"FirstPass( )"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"RightArm( )"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"DrawIndexedVertices( )"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The last function listed in the stack trace, DrawIndexedVertices( ), is typically a function that resulted in a GPU command being passed to GPU . When a developer is analyzing data from a captured scene, the stack trace helps the developer to identify which drawing calls are which.",{"@attributes":{"id":"p-0075","num":"0074"},"figref":["FIG. 3","FIG. 1"],"b":["200","200","150","200"]},"Game device  includes a CPU  (analogous to CPU  of ), a GPU  (analogous to GPU  of ), capture storage  (analogous to capture storage  of ), and game  (analogous to game  of ). Game device  is coupled to (or includes) display device  (analogous to display device  or  of ), and is also coupled to (or includes) input device  (analogous to input device  or  of ).","Game device  also includes a capture control application  and a capture application . Capture control application  is similar to capture control application  of , and Capture application  is similar to capture application  of . However, applications  and  different from applications  and  in that applications  and  are part of the same game device . So, any commands or data sent between application  and capture application  are sent internal to game device  rather than between two devices. Additionally, capture control application  presents its user interface by way of display device .",{"@attributes":{"id":"p-0078","num":"0077"},"figref":["FIG. 4","FIG. 2","FIG. 2","FIG. 2","FIG. 2","FIG. 2","FIG. 2"],"b":["240","240","242","244","242","246","156","248","158","242","250","162","252","164","244","254","166","256","168"]},"Game device  is similar to game device  of , and in certain embodiments devices  and  are the same device (or at least the same type of device, such as both the same type of gaming console). The difference between game devices  and  is that game device  is running an application(s) to facilitate playback and analysis of a frame based on previously captured commands and GPU state (e.g., captured by capture application  of ).","Computing device  includes an analysis control and feedback application . Application  provides a user interface, through display device . The user interface allows the user of device  to input, through input device , requests for analysis of a frame to be performed. These requests can also be referred to as questions regarding the frame. The user interface provided by application  also displays feedback regarding the frame to the user of device  (e.g., the feedback in act  of ). The specific feedback provided to the user can vary based on the analysis performed, as discussed in more detail below.","Requests for analysis are sent from application  to analysis application . Analysis of a frame can begin immediately after the frame is captured, or alternatively at some later time. For example, when the designer or tester captures a frame, the analysis of the frame may begin right after the frame is captured, or alternatively multiple frames may be captured and the designer or tester (or some other user) may begin analysis of the captured frames at some later time.","Analysis application  receives the requests for analysis and sends the appropriate portions of captured data  to GPU . Feedback regarding the drawing of the data sent to GPU  is then returned by analysis application  to application  for presentation to the user on display device . Depending on the analysis requested, analysis application  may generate modified data  that is sent to GPU  in place of, or alternatively in addition to, captured data .","The captured data  is the same data for the frame as was captured and stored in the capture storage (e.g., storage  of ). In certain embodiments, the captured data is maintained in the game device and referred to when requests are sent by application . In other embodiments, when analysis of a frame is to begin, the captured data is sent to game device  by application . In other embodiments, the portions of the captured data (and\/or modified data) necessary for the analysis are sent by application  along with the request.","Additionally, although analysis application  is shown as being part of game device , portions of analysis application  may be implemented in computing device . For example, any required modifications to the data may be performed by computing device  rather than game device . Additionally, some analysis can be performed by computing device  without any help from game device . For example, the size of the captured data and the number of commands in the data can be determined by computing device  by parsing through the command stream.","When analysis of a frame is to begin, the state of GPU  is set to the previously captured state (e.g., as captured in act  of ). The various memory location and register values that were captured as part of the state of the GPU (e.g., GPU  of ) are written back to GPU . By writing these values back go the GPU, the GPU will be in the same state as it was at the beginning of the captured frame.","It should be noted that, during the analysis process, certain other memory locations in game device  may be accessed. For example, the memory location(s) for texture map(s) used in drawing the frame may be accessed. In such situations where other memory locations are accessed, analysis application  writes the appropriate data (as captured) to those memory locations prior to their being accessed by the captured commands.","One type of analysis that can be performed by analysis application  is timing analysis. Timing analysis refers to determining an amount of time a particular frame or portion of a frame takes to be drawn. Game device  has a clock (not shown) that can be used to determine an amount of time taken for a particular frame to be drawn. The commands for drawing the frame are sent to GPU  by analysis application , so application  can identify the current time of the clock when the first command is sent to GPU  (e.g., immediately prior to sending the first command to GPU ). Application  also sends a command to GPU  to indicate that it has completed sending commands to GPU  (e.g., the Present( ) or Swap( ) commands discussed above). When GPU  has completed drawing the last command, GPU  returns an indication to the application sending the commands to GPU  (analysis application  in this instance) that the last command is completed. Application  can then identify the current time of the clock. By knowing the time when drawing of the frame began and the time when drawing of the frame was completed, the difference between these two times can be readily determined in order to identify the amount of time taken to draw the frame.","The amount of time taken to draw a portion of a frame can be determined in an analogous manner. By accessing the clock, the time when drawing of the portion begins and drawing of the portion is completed can be readily determined. These different portions can correspond to, for example, the events identified above in Table I.","The timing analysis can be used as a basis to provide various feedback to the user. The amount of time taken for a frame or portion of a frame to be drawn can be returned to the user. Additionally, other information can be ascertained based on the timing analysis and this other information can be returned to the user. This other information can be ascertained by analysis application  and\/or analysis control and feedback application .","A wide variety of information can be ascertained based on this timing analysis. For example, which portions (e.g., objects) of the frame took the longest or shortest time to draw can be ascertained.","The timing analysis can also be performed based on modified data . This allows analysis application  to modify captured data  and then submit the modified data to GPU . The time taken to draw both the unmodified data and the modified data can be determined, and these two times used to determine how much the modification affected the time taken to draw the frame. For example, analysis application  may analyze captured data  to identify redundant commands. Redundant commands within the set of commands that is captured data  refers to duplicate commands that are present in the set of commands but one or more of these duplicate commands can be removed without altering the frame drawn by the set of commands. E.g., multiple commands to turn off transparency may be present in the set of commands, even though no other command in the set of commands operates to turn on transparency. Thus, all of the commands to turn off transparency after the first command to turn off transparency could be removed from the set of commands (the first command may also be removed if there is no previous command or state of the GPU  that would have caused transparency to be turned on).","It should be noted that some timing data for performing the timing analysis may be captured when the frame is captured, rather than being determined during the analysis process. For example, situations may arise where the amount of time taken by the CPU in the game device to determine particular values to be used in drawing the frame is very large. By capturing the timing data when the CPU is determining the particular values, rather than capturing the timing data based on the resultant captured values, situations where the GPU goes idle can be more easily detected. For example, the CPU can be so busy that it waits too long to issue a new command to the GPU which causes the GPU to go idle because it has nothing to work on. This is an important case for developers to be aware of because they typically endeavor to keep the GPU busy at all times. This information is lost when playing back a captured stream of commands because the commands are played back one-after-another without regard for any idle spots that may have been present when the application (e.g., game) originally ran.","Another type of analysis that can be performed by analysis application  is a partial frame draw. All of the commands in the captured data  are used to draw the entire frame. A partial frame draw can be performed by sending only a subset of the commands in the captured data  to GPU  and having GPU  draw the frame using only that subset (and thus less than all of the captured commands). For example, analysis application  may choose to send only the first five commands or the first ten commands, or all of the commands leading up to a particular command, etc. to GPU .","Whatever the subset of commands is, GPU  receives the subset and draws a frame given only that subset. Analysis application  can then return this frame to analysis control and feedback application  for display to the user on display device . Application  can send this frame in different manners, such as generating a bitmap representing the frame as drawn by GPU  and sending that bitmap to application . Drawing a partial frame can be useful to the developer as it allows the developer to see what the frame looks like after the first n drawing commands are completed (where the value of n can be set by the developer). Much like single-stepping a program, this allows the developer to see the scene being drawn step-by-step and to quickly determine which step drew something incorrectly.","Another type of analysis that can be performed by analysis application  is the determining of internal non-exposed state of GPU . Some state of the GPU  can be accessed by devices external to GPU  (e.g., the settings of certain variables, register values, etc.), and these states are captured as discussed above (e.g., in act  of ). These states are typically states that affect all future drawing commands on GPU .","However, GPU  may also include additional internal state for which GPU  provides no mechanism for any component or module external to GPU  to access (e.g., no command can be sent to GPU  to read particular internal register values). Such states are typically transitory states. Transitory states can be thought of as similar to scratchpad memory, where the contents are only valid during a particular instruction of a particular invocation of the vertex or pixel shader program. When the next vertex or pixel is processed, this state is overwritten. Such transitory states are typically not easily retrievable because GPUs typically have no way to halt execution at a particular point so that these states can be read.","Some GPUs include internal programs that process some of the data received as commands. For example, one or more vertex shader programs and\/or one or more pixel shader programs may be included in the GPU that operate on some of the data received by the GPU. As these programs within the GPU can make use of their own internal variables (e.g., registers and\/or other memories), it may be useful to the designer or tester to know what the values of these registers and\/or variables are as each pixel or vertex is processed. These registers and\/or variables are often transitory states, such as the contents of a temporary register after a particular instruction has executed in a pixel shader program of GPU  that is a particular pixel in a particular drawing operation in the scene (e.g., the tmp( ) register contents after instruction  has executed in the pixel shader program that is processing pixel , in the 7drawing operation in the scene). By modifying the captured commands, and possibly internal programs for the GPU, additional information can be obtained.","Such modifications to identify settings of internal registers and\/or other variables is illustrated by the following example. Assume that a pixel shader program used by the GPU is as follows (where t0, t1, and r0 are internal GPU registers):","tex t0 \/\/ load the result of texture stage t0 into register t0","tex t1 \/\/ load the result of texture stage t1 into register t1","add r0, t0, c0 \/\/ r0=t0+c0","mul r0, r0, t1 \/\/ r0=r0*t1\n\n","Analysis application  can determine the internal value of the register rin the third instruction as follows. The shader programmer is modified to be as follows:","tex t0 \/\/ load the result of texture stage t0 into register t0","tex t1 \/\/ load the result of texture stage t1 into register t1","add r0, t0, c0 \/\/ r0=t0+c0\n\n","The program can be modified again as follows:","tex t0 \/\/ load the result of texture stage t0 into register t0","tex t1 \/\/ load the result of texture stage t1 into register t1","mov r0, t1 \/\/r0=t1\n\n","Now, the value written by the GPU to the frame buffer will be the value of the t1 register in the second instruction. This process can be followed repeatedly to extract the values of all the internal registers.","In certain embodiments, analysis control and feedback application  has multiple default requests or questions that it submits to analysis application . These default requests or questions are pre-programmed into application . Additionally, the user of computing device  may also request information that involves one or more additional requests or questions be sent to analysis application .","In certain embodiments, analysis application  and\/or analysis control and feedback application  analyze the requests sent to analysis application  and generate warnings for the user regarding rules or recommendations that were violated by the frame. For example, each different type of GPU typically has its own recommended programming practices. Tests to determine whether these programming practices were violated can be programmed in to application  or , so that each time a frame is analyzed these tests can be performed to determine whether the recommendations for programming the GPU were violated. A variety of such recommendations may exist, such as not setting certain register values if certain GPU functionality is not being used in a frame, issuing certain commands in certain orders, having the frame buffer and depth buffer both in tiled memory, not clearing the screen multiple times (e.g., clearing the screen after it has already been cleared), not submitting redundant commands, and so forth. Additionally, warnings can be given different priorities. For example, the warnings can be ranked according to how much time adhering to their associated recommendations would save for this frame. By way of another example, particular warnings may be presented only if they satisfy certain constraints (e.g., display a warning to the user only if not violating the recommendation would have allowed the frame to be drawn a threshold amount faster).","Analysis of the frame can continue until analysis application  is informed to stop analyzing the frame. The user, for example, can select a \u201cstop\u201d or \u201ccancel\u201d option on the user interface presented by application  to stop analyzing the frame.","It should be noted that all of the analysis of the set of commands, whether captured commands or modified commands are sent to GPU , is based on the commands being performed by the same GPU as will be running the game. As the actual GPU can be used, an emulator or simulator need not be used. By using the actual GPU, the accuracy of the analysis is improved due to any approximations or errors that may be introduced by an emulator or simulator. Additionally, any timing measurements obtained by an emulator or simulator would have little, if any, meaning.",{"@attributes":{"id":"p-0116","num":"0119"},"figref":["FIG. 5","FIG. 4"],"b":["300","300","240","300"]},"Game device  includes a CPU  (analogous to CPU  of ), a GPU  (analogous to GPU  of ), captured data  (analogous to captured data  of ), and modified data  (analogous to modified data  of ). Game device  is coupled to (or includes) display device  (analogous to display device  or  of ), and is also coupled to (or includes) input device  (analogous to input device  or  of ).","Game device  also includes an analysis control and feedback application  and an analysis application . Analysis control and feedback application  is similar to analysis control and feedback application  of , and analysis application  is similar to analysis application  of . However, applications  and  different from applications  and  in that applications  and  are part of the same game device . So, any  commands or data sent between application  and application  are sent internal to game device  rather than between two devices. Additionally, analysis control and feedback application  presents its user interface by way of display device .","The analysis control and feedback application (e.g., application  of  or application  of ) can present feedback to the user using any of a variety of user interfaces, including graphical user interfaces.  illustrates an example user interface that may be presented by the analysis control and feedback application. In the example of , the user interface display  includes a timeline window , an events window , and a frame window .","Timeline window  displays the captured timing information graphically using a timeline. This captured timing information can include, for example, when particular CPU or GPU events occurred.","Events window  contains a listing or grid of all of the events that have been captured along with all of the data regarding the frame that has been calculated as part of the analysis of the frame (e.g., by analysis application  of  or analysis application  of ).","Frame window  displays information regarding the display of the frame, and may include images showing how the frame appears at different points during its being drawn. Windows , , and  are discussed in additional detail below.","It should be noted that although all three windows , , and  are illustrated in , alternatively only one or more of the windows may be displayed. For example, user interface display  may display only window , only window , only window , windows  and  but not window , windows  and  but not window , or windows  and  but not window .","Windows , , and  are illustrated in  with particular positions relative to one another. Alternatively, one or more of windows , , and  may be positioned elsewhere. Additionally, windows , , and  are illustrated in  as being adjacent to one another. Alternatively, one or more of windows , , and  may be positioned away from (not adjacent to) one or more of the other windows , , and .",{"@attributes":{"id":"p-0125","num":"0128"},"figref":["FIG. 7","FIG. 6"],"b":["360","360","340","360","362","364","366","362","368","370","370","362","368","368","370"]},"An event as discussed herein can be different things in different embodiments. For example, in certain embodiments there may be particular commands that constitute events, such as those listed in Table I above. In other embodiments, every command submitted to the graphics processing unit may be an event. In other embodiments, the events may be identified by the game designer. For example, as discussed above the game designer may design a game to specify certain information when the game is submitting commands to the graphics processing unit (e.g., identifying what part of the frame is being drawn, such as the character's left arm, the character's right arm, the character's weapon, the background terrain, etc.). Such information can be used as events (e.g., each part of the frame being drawn can be a separate event).","Timeline window  displays the events that are listed in events window . These events can be hierarchical in nature. For example, a MainCharacter event may contain other events (referred to as children events) for DrawLeftArm, DrawHead, DrawWeapon, and so forth. When one event contains other events, it is displayed with a small plus sign next to it in events window . When the plus sign is clicked, the event is expanded so that its children events are displayed. When this happens, the event display in timeline window  changes. The horizontal bar that represented the parent event is now replaced with one or more horizontal bars that represent the child events. These horizontal bars may be the same color as the parent event or a different color. the space covered by the children events on the timeline does not exceed the space covered by the parent event.","All of the bars in timeline  may be the same color, or different colors may be used to signify different events. For example, clear commands may be one color, draw commands may be another color, swap commands may be yet another color, and so forth.","Additionally, more specific information may be available to the user by moving a cursor (e.g., an arrow or other on-screen cursor) over a part of timeline . The cursor can be moved using any of a variety of devices, such as a mouse, game controller, keyboard, track pad, trackball, and so forth. When the cursor is stationary over an event for greater than a threshold amount of time (e.g., one or two seconds), more specific information can be displayed to the user. Alternatively, when the event is \u201cselected\u201d (such as by depressing a mouse button or game controller button when the cursor is over the event) the more specific information can be displayed to the user. This more specific information can take a variety of different forms, such as the specific start and end times for the event (e.g., in nanoseconds).","Timeline window  can include a timeline for the CPU, a timeline for the GPU, or timelines for both the CPU and the GPU.  illustrates an example timeline window  which could be displayed as timeline window  of . Timeline window  includes a CPU timeline  on which CPU events are displayed and a GPU timeline  on which GPU events are displayed. In many instances, a CPU event has a corresponding GPU event, and in such situations when either the CPU event or the GPU event is selected (e.g., by depressing a button on a cursor control device when the cursor is over the event, or moving a directional key (e.g., the + and \u2212 keys) of a keyboard), an arrow is displayed to link the CPU and GPU events.","When a CPU event is selected, the head of the arrow that points to the CPU event is solid and the head of the arrow that points to the corresponding GPU event is hollow. When a CPU event is selected, the arrow keys cause the CPU cursor to move linearly along CPU timeline . The down-arrow key moves the solid headed arrow down to the GPU event and subsequent arrow-key presses move the cursor linearly along GPU timeline . Pressing the up-arrow key moves the solid arrow head back up to CPU timeline  and the corresponding CPU event is selected. When a CPU event is selected, the other arrow points to the corresponding GPU event. Likewise, when a GPU event is selected, the other arrow points to the corresponding CPU event.","One or more graphs  may also be included in timeline window . Different information may be graphed, and in certain embodiments the user is able to select one of the columns from the events window (e.g., window  of , as discussed in more detail below). The data from the selected column is then plotted against time in graph . In the example graph , time is along the horizontal axis and the data from the selected column is along the vertical axis. Different columns can be selected from pull-down menu .","Returning to , events window  includes a table with a columnar listing of all of the events for the frame that have been captured along with all of the data regarding the frame that has been calculated as part of the analysis of the frame (e.g., by analysis application  of  or analysis application  of ). Each row in the table represents an event. A CPU-only event will contain values in the CPU Start and CPU Duration columns. An event that also occurs on the GPU will have valid values in the GPU Start and Duration columns. If there is no timing information available, none of these four columns will have data. The remaining columns are calculated by the analysis application and will be empty if no analysis has been performed.  illustrates another example events window  with additional data.","The ordering of the events listed in events window  is ordinarily determined by the CPU Start Time column. Clicking on another column will cause the events to be listed in ascending order for that column. Clicking again on the header will cause the events to be listed in descending order for that column. An option is provided in the context menu (e.g., activated by right-clicking in the window) to restore the event sorting to its default value. Each column can be resized by dragging the edge of the column header with a cursor control device. The headers remain in place vertically as the events are scrolled up or down but they track the horizontal movement of the table as it is scrolled from side-to-side. Right clicking on the table or the columns brings up a context menu with additional options for resizing or other operations.","One example of such an operation is to export the entire table to a file that can be loaded into a spreadsheet or other program for further analysis. Another example of such an operation is to specify one or more columns that will be graphed in the timeline window along with the GPU event data (e.g., as graph  of ). Another example of such an operation is display of a column chooser to assist the user in managing the display of the columns. User-selection of this operation causes a temporary window (not shown) to be displayed that will allow a set of columns and their order to be chosen. Columns that are not chosen will not be displayed in window . One or more predetermined column configurations for particular tasks (such as analyzing fill rate) may be presented to the user as part of the column chooser.","One or more rows of the table can be highlighted. The highlighted row(s) represent the event(s) which correspond to the event(s) that are represented by the currently selected horizontal bar of timeline . When a new horizontal bar(s) of timeline  is selected, then a new row(s) of the table is highlighted (the new row(s) representing the same event(s) as the newly selected horizontal bar(s)). Similarly, if a new row(s) of the table is selected and highlighted, then a new horizontal bar(s) of timeline  is selected (the new horizontal bar(s) representing the same event(s) as the newly selected row(s).","The last row in the table is a summary row. The summary row contains calculated values based on all of the other events in the table. Each column has a summary type associated with it that is one of a maximum value, a minimum value, an average value, or a sum value. The summary value is calculated based on the summary type and the data in the column.","The events window will also support a hierarchical display of events. An application can specify user-defined events in a hierarchical way. When these events encompass other events, the user will have an option to display the user-event, the CPU and GPU events, and\/or other hierarchical events that comprise it. For example, a game may specify a Start time for their physics engine and an end time. If no graphics events occurred during this time, the physics engine event will show up as a discrete CPU-only event in the events window. A game may also specify a start time for rendering the main character in the game and also an end time. In between these times are all the rendering calls for the main character. This event can be displayed in the events window with an expansion icon next to it. If the user clicks on this expansion icon, the events window will display all of the graphics events that occurred during the user event. When the user event is displayed, its columns will contain a summary of the information contained by the events under it in the hierarchy based on the summary type specified for each column.","By way of example, events window  of  shows a hierarchical event Bear Mesh  along with its children events (DrawIndexedVertices, KickPushBuffer, KickPushBuffer, DrawIndexedVertices, and DrawIndexedVertices). Other hierarchical events are also shown, such as Bear Mesh , although its expansion icon has not been selected so its children events are not displayed.","A variety of different columns can be included in events window . Table II lists examples of such columns. Reference is made in Table II, as well as elsewhere in this description, to the \u201cpush buffer\u201d or \u201cpushbuffer\u201d. The push buffer or pushbuffer refers to the commands and their associated data that are submitted to the graphics processing unit to be drawn. These commands and their associated data are captured, as discussed above.",{"@attributes":{"id":"p-0141","num":"0144"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE II"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["Column","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Back-end Time","Total back-end time that the rendering primitive took,"]},{"entry":[{},"as measured at the Z-cull stage of the graphics"]},{"entry":[{},"hardware pipeline. A hardware back-end flush is done"]},{"entry":[{},"between primitives to measure each primitive"]},{"entry":[{},"independently from one another. Because the flush"]},{"entry":[{},"eliminates overlaps in the pipeline between primitives,"]},{"entry":[{},"the sum of the back-end times may be more than the"]},{"entry":[{},"overall back-end render time."]},{"entry":["Pre-Occlusion","The number of pixels that would have been rendered if"]},{"entry":["Cull Pixel Count","depth, stencil, and alpha comparison functions"]},{"entry":[{},"were ALWAYS. When multi-sampling, this is the"]},{"entry":[{},"post-multisample-expansion count."]},{"entry":["Post-Occlusion","The number of pixels that are actually rendered, taking"]},{"entry":["Cull Pixel Count","into account depth, stencil, and alpha occlusion. When"]},{"entry":[{},"multi-sampling, this is the post-multisample-expansion"]},{"entry":[{},"count."]},{"entry":["Pixels Occlusion","Percent of pixels that are occlusion culled."]},{"entry":"Culled"},{"entry":["Effective Fill","Effective pixel fill rate, relative to the back-end time."]},{"entry":"Rate"},{"entry":["Ideal Fill Rate","Ideal pixel fill rate, relative to the back-end time. This"]},{"entry":[{},"is measured using all of the current state with the"]},{"entry":[{},"current render target, but using large quads that are"]},{"entry":[{},"rendered such that Z and stencil tests always pass, and"]},{"entry":[{},"with all textures forced to be opaque and 1 \u00d7 1"]},{"entry":[{},"(or 1 \u00d7 1 \u00d7 1) texels in size. This is the fill-rate"]},{"entry":[{},"that could be achieved with the current primitive in the"]},{"entry":[{},"current state if the current Z compression was 100%,"]},{"entry":[{},"there was 100% utilization of the 4 pixel pipelines, and"]},{"entry":[{},"the texture reads had no performance impact."]},{"entry":["Vertex Count","Vertex count."]},{"entry":["Triangle Count","Triangle Count."]},{"entry":["Effective","Effective triangle fill rate, relative to the back-end"]},{"entry":["Triangle Rate","time."]},{"entry":["Vertex Shader","Measured speed of the current vertex shader program"]},{"entry":["Cost","(or fixed-function T&L), in GPU cycles."]},{"entry":["Back-end Time","The same measurement as the back-end time, but done"]},{"entry":["With 1-Pixel","with all textures set to opaque, 1 \u00d7 1 (or 1 \u00d7 1 \u00d7 1)"]},{"entry":["Textures","texel size."]},{"entry":["% Texture Bound","Measures how much of the rendered primitive time is"]},{"entry":[{},"attributable to texture fetches, as computed using the"]},{"entry":[{},"back-end times for 1 \u00d7 1 and normal sized textures."]},{"entry":["Back-end Time","The same measurement as the back-end time, but done"]},{"entry":["With 0-Pixel","with the viewport forced to a zero-pixel size."]},{"entry":"Viewport"},{"entry":["% Fill Bound","Measures how much of the rendered primitive time is"]},{"entry":[{},"attributable to fills, as computed using the back-end"]},{"entry":[{},"times for zero-pixel and normal sized viewports."]},{"entry":["Z-Compressed","The percentage of Z packets that are compressed after"]},{"entry":["Packets","the primitive is rendered. Note that this is not the"]},{"entry":[{},"effective compression of the Z-buffer (after a Z clear,"]},{"entry":[{},"the percentage of Z-compressed packets will be 100%,"]},{"entry":[{},"but the effective compression is 87.5% due to 8-to-1"]},{"entry":[{},"compression)."]},{"entry":["Push-buffer","The number of bytes that are written into the push"]},{"entry":["Inline Data","buffer to handle the command for the primitive"]},{"entry":[{},"rendering. For DrawIndexedVertices, this is effectively"]},{"entry":[{},"the amount of index data that has to be copied to the"]},{"entry":[{},"push buffer."]},{"entry":["Push-buffer","The number of bytes of state change commands in the"]},{"entry":["Setup Data","push buffer that preceded the rendered primitive."]},{"entry":["Push Buffer","Where the event occurs chronologically in drawing of"]},{"entry":["Event","the frame."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"Returning to , frame window  displays information regarding the display of the frame. This information regarding the frame may be a display of the frame as drawn, or different aspects of the frame (e.g., a depth buffer or wireframe view, shader programs used, warnings, and so forth as discussed below). Depending on the type of information being displayed, the information may be for the entire frame or the information may be displayed for different chronological points relative to the drawing of the frame. For example, if the information comprises warnings, then the information is for the entire frame. By way of another example, the information displayed in frame window  may show information regarding display of the frame as it appeared after being fully drawn, as it appeared after being only 25% drawn, as it appeared immediately after a particular event was finished being drawn, and so forth. Which chronological point is displayed in frame window  can vary based on which event in events window  is selected. Whenever an event in events window  is selected, frame window  displays information regarding display of the frame as it appeared immediately after the selected event was finished being drawn.","Different windows can be displayed as the frame window . Examples of such windows that can be displayed as the frame window  include an images window (examples of which are illustrated in ), a call stack window (an example of which is illustrated in ), a warnings window (an example of which is illustrated in ), a pushbuffer window (an example of which is illustrated in ), a summary window (an example of which is illustrated in ), a shaders window (an example of which is illustrated in ), a renderstates window (an example of which is illustrated in ), a texturestates window (an example of which is illustrated in ), and an other state window (an example of which is illustrated in ). Frame window  displays a set of tabs  which can be selected by the user to determine the window to be displayed as frame window .",{"@attributes":{"id":"p-0144","num":"0147"},"figref":["FIG. 10","FIG. 7","FIG. 7","FIG. 10","FIG. 11","FIG. 12","FIG. 13","FIG. 14","FIG. 15"],"b":["420","366","420","422","420","424","420"]},"The surfaces can be displayed within the images window  at various sizes (e.g., 100%, 200%, 400%, 50%, 25%, fit to window, etc.).","When the mouse is moved over a particular place on a surface displayed in the images window, the actual values at that pixel will be displayed in a status bar. An example status bar  is illustrated in .","For one or more of the views of the images window, such as the render target view, a particular pixel or group of pixels can be selected by the user. This selection can be made, for example, by the user moving a cursor over a pixel and activating the pointing device being used to control the cursor (e.g., clicking on the mouse button). By way of another example, a user could click and drag a rectangle to select a group of pixels. When such a pixel(s) is selected, all of the events in the events window (view  of ) that render to that pixel will be highlighted.","The render target view  shows the color and alpha values held by the frame buffer. These values can correspond to the final image that is the frame, or alternatively may be some point during drawing of the frame. For example, as discussed above, only the commands for drawing a particular part of the scene may be submitted to the graphics processing unit, and the resultant frame can be displayed using the render target view.","In certain embodiments, the render target view  in conjunction with the timeline in timeline window  or the events in events window  can allow a user to \u201cstep through\u201d the drawing of a frame event by event. For example, the user can select the first event (the first row) in the grid of window  and have the resultant view after only that first event is drawn by the graphics processing unit displayed as the render target view . The user can then select the second event (the second row) in the grid of window  and have the resultant view after both the first and second events are drawn by the graphics processing unit displayed as the render target view . This process can continue, allowing the user to slowly see how the frame is drawn and to easily identify any drawing problems associated with each event.",{"@attributes":{"id":"p-0150","num":"0153"},"figref":"FIG. 11","b":"420"},{"@attributes":{"id":"p-0151","num":"0154"},"figref":"FIG. 12","b":"420"},{"@attributes":{"id":"p-0152","num":"0155"},"figref":["FIG. 13","FIG. 13","FIG. 13"],"b":["420","428","430","432","434","434","428","430","432"]},{"@attributes":{"id":"p-0153","num":"0156"},"figref":"FIG. 14","b":"420"},{"@attributes":{"id":"p-0154","num":"0157"},"figref":"FIG. 15","b":"420"},{"@attributes":{"id":"p-0155","num":"0158"},"figref":["FIG. 16","FIG. 7","FIG. 7","FIG. 7"],"b":["450","366","450","450","362","364","452"]},"In the example call stack window , the stack trace data displayed to the user shows the sequence of calls that resulted in the listed event being sent as a command to the GPU. Each line in the display corresponds to a function call in the program. The first function listed shows the function that submitted a command to the GPU that resulted in the listed event. The next line shows the function that called the first function, etc. The last function listed for each event is the top-level function in the game. The filename and line number where each function is located in the game source code is also displayed.",{"@attributes":{"id":"p-0157","num":"0160"},"figref":["FIG. 17","FIG. 7","FIG. 7","FIG. 7","FIG. 7"],"b":["460","366","460","460","364","460","366","460","460","460","362","364"]},"Each warning has a priority associated with it from 1 to 3. Priority 1 warnings are serious problems that may have a significant impact on the time it takes the game to draw a frame. Priority 2 warnings are less important but still important to consider when performance-tuning a game. Priority 3 warnings are suggestions that are good to follow but may not have a large impact on the overall performance. The user can use check boxes  to choose which warnings should be displayed according to their priority.",{"@attributes":{"id":"p-0159","num":"0162"},"figref":["FIG. 18","FIG. 7","FIG. 7","FIG. 7","FIG. 7"],"b":["464","366","362","364","362","366"]},{"@attributes":{"id":"p-0160","num":"0163"},"figref":["FIG. 19","FIG. 7"],"b":["468","366"]},{"@attributes":{"id":"p-0161","num":"0164"},"figref":["FIG. 20","FIG. 7"],"b":["472","366","474","476"]},{"@attributes":{"id":"p-0162","num":"0165"},"figref":["FIG. 21","FIG. 7"],"b":["480","366","480","480"]},{"@attributes":{"id":"p-0163","num":"0166"},"figref":["FIG. 22","FIG. 7"],"b":["484","366","484","4840"]},{"@attributes":{"id":"p-0164","num":"0167"},"figref":["FIG. 23","FIG. 7"],"b":["488","366","488","480"]},{"@attributes":{"id":"p-0165","num":"0168"},"figref":["FIG. 24","FIG. 6"],"b":["500","500","342","344","346","500","500"]},"Pixel history window  lists each event that affects the selected pixel during the frame, or alternatively only up to a particular point in the frame (e.g., as identified by the user). Additional information regarding each event as it affects the selected pixel is also displayed. The specific information displayed can vary based on the event. In the illustrated example of pixel history window , initial frame buffer values  are displayed. The frame then starts with a clear command, which is shown as clear event . Each subsequent event  affecting the selected pixel is also identified in window , as well as additional information regarding those events. For example, the pixel shader output color and frame buffer color after blending may can be identified.","Pixel history window  may also include links to the event, a pixel shader debugger, a vertex shader debugger, and a mesh debugger. If the link to the event is selected by the user, then that event is made the current event in the user interface (e.g., windows , , and  of ) and the other windows are updated accordingly. If the pixel shader debugger link is selected by the user, then a pixel shader debugger window is opened to display information regarding the pixel shader used for the selected pixel. If the mesh debugger link is selected by the user, then a mesh debugger window is opened to display information regarding the triangle currently being drawn (as of the current event) that the selected pixel is part of.",{"@attributes":{"id":"p-0168","num":"0171"},"figref":["FIG. 25","FIG. 24"],"b":["520","520","500","520","520"]},"Pixel shader debugger window  also includes a vertex portion  that includes information regarding the vertices of the triangle currently being drawn (as part of the current event) that the selected pixel is part of. The vertex shader debugger window can be displayed in response to a user selection of such an option in window , such as user selection of one of the vertices identified in vertex portion .",{"@attributes":{"id":"p-0170","num":"0173"},"figref":["FIG. 26","FIG. 24","FIG. 25"],"b":["540","540","500","540","520","540"]},{"@attributes":{"id":"p-0171","num":"0174"},"figref":["FIG. 27","FIG. 24","FIG. 24","FIG. 7","FIG. 26"],"b":["560","560","500","560","500","364","560","560","562","564","540"]},"It should be noted that, with reference to  above, as different views and\/or windows are selected, the selected pixel(s) and\/or events remain the same. For example, a user could select a pixel in the render target view of images window  (of ), and then select the shaders window  (of ) to have the pixel and\/or vertex shader program for that selected pixel displayed.","Although the discussions above primarily discuss facilitating performance analysis for graphics processing, the techniques described herein can similarly be used to facilitate performance analysis for other types of processors, including general purpose processors and specific purpose (e.g., dedicated) processors. The techniques described herein can be applied to virtually any processor that accepts a command stream and can be used to provide information regarding processing of the command stream. For example, the techniques described herein can be used to facilitate performance analysis for general purpose processors (e.g., CPUs). Correspondingly, the techniques described herein can be used to facilitate performance analysis for processors on other computing devices other than game devices.","Depending on the type of application being executed on the computing device and the type of processor, the capture of commands sent to the processor can vary. For example, if the application is a graphics or video application, then the application may still send commands to the processor indicating the beginning and ending of frames. Thus, the commands to be captured can be identified on a frame-by-frame basis. In other examples, the application may not issue any such indications of the beginning and ending of frames. In such situations, the beginning and ending points for capture would be identified in different manners. For example, a separate command(s) may be embedded in the application that indicate the beginning and ending of points for capture, or the capture may simply begin as soon as the request to capture is received, and then end after some amount of time (e.g., the request may indicate how long the capture should continue for, such as a length of time in milliseconds or seconds, or a number of commands to be captured, etc.).","Capturing commands for a general purpose processor can permit a great deal of information regarding processing of those commands by the processor to be returned to the application designer. For example, using the techniques described herein precise measures of how long processing of particular commands or groups of commands took can be made. By way of another example, instruction traces identifying the specific instructions executed in the captured portion can be readily determined.",{"@attributes":{"id":"p-0176","num":"0179"},"figref":"FIG. 28","b":["600","600","600","600"]},"Computer environment  includes a general-purpose computing device in the form of a computer . Computer  can be, for example, game device  or computing device  of , game device  of , game device  or computing device  of , or game device  of , and may implement process  of . The components of computer  can include, but are not limited to, one or more processors or processing units , a system memory , and a system bus  that couples various system components including the processor  to the system memory .","The system bus  represents one or more of any of several types of bus structures, including a memory bus or memory controller, a peripheral bus, an accelerated graphics port, and a processor or local bus using any of a variety of bus architectures. By way of example, such architectures can include an Industry Standard Architecture (ISA) bus, a Micro Channel Architecture (MCA) bus, an Enhanced ISA (EISA) bus, a Video Electronics Standards Association (VESA) local bus, and a Peripheral Component Interconnects (PCI) bus also known as a Mezzanine bus.","Computer  typically includes a variety of computer readable media. Such media can be any available media that is accessible by computer  and includes both volatile and non-volatile media, removable and non-removable media.","The system memory  includes computer readable media in the form of volatile memory, such as random access memory (RAM) , and\/or non-volatile memory, such as read only memory (ROM) . A basic input\/output system (BIOS) , containing the basic routines that help to transfer information between elements within computer , such as during start-up, is stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently operated on by the processing unit .","Computer  may also include other removable\/non-removable, volatile\/non-volatile computer storage media. By way of example,  illustrates a hard disk drive  for reading from and writing to a non-removable, non-volatile magnetic media (not shown), a magnetic disk drive  for reading from and writing to a removable, non-volatile magnetic disk  (e.g., a \u201cfloppy disk\u201d), and an optical disk drive  for reading from and\/or writing to a removable, non-volatile optical disk  such as a CD-ROM, DVD-ROM, or other optical media. The hard disk drive , magnetic disk drive , and optical disk drive  are each connected to the system bus  by one or more data media interfaces . Alternatively, the hard disk drive , magnetic disk drive , and optical disk drive  can be connected to the system bus  by one or more interfaces (not shown).","The disk drives and their associated computer-readable media provide non-volatile storage of computer readable instructions, data structures, program modules, and other data for computer . Although the example illustrates a hard disk , a removable magnetic disk , and a removable optical disk , it is to be appreciated that other types of computer readable media which can store data that is accessible by a computer, such as magnetic cassettes or other magnetic storage devices, flash memory cards, CD-ROM, digital versatile disks (DVD) or other optical storage, random access memories (RAM), read only memories (ROM), electrically erasable programmable read-only memory (EEPROM), and the like, can also be utilized to implement the example computing system and environment.","Any number of program modules can be stored on the hard disk , magnetic disk , optical disk , ROM , and\/or RAM , including by way of example, an operating system , one or more application programs , other program modules , and program data . Each of such operating system , one or more application programs , other program modules , and program data  (or some combination thereof) may implement all or part of the resident components that support the distributed file system.","A user can enter commands and information into computer  via input devices such as a keyboard  and a pointing device  (e.g., a \u201cmouse\u201d). Other input devices  (not shown specifically) may include a microphone, joystick, game pad, satellite dish, serial port, scanner, and\/or the like. These and other input devices are connected to the processing unit  via input\/output interfaces  that are coupled to the system bus , but may be connected by other interface and bus structures, such as a parallel port, game port, or a universal serial bus (USB).","A monitor  or other type of display device can also be connected to the system bus  via an interface, such as a video adapter . In addition to the monitor , other output peripheral devices can include components such as speakers (not shown) and a printer  which can be connected to computer  via the input\/output interfaces .","Computer  can operate in a networked environment using logical connections to one or more remote computers, such as a remote computing device . By way of example, the remote computing device  can be a personal computer, portable computer, a server, a router, a network computer, a peer device or other common network node, and the like. The remote computing device  is illustrated as a portable computer that can include many or all of the elements and features described herein relative to computer .","Logical connections between computer  and the remote computer  are depicted as a local area network (LAN)  and a general wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet.","When implemented in a LAN networking environment, the computer  is connected to a local network  via a network interface or adapter . When implemented in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the wide network . The modem , which can be internal or external to computer , can be connected to the system bus  via the input\/output interfaces  or other appropriate mechanisms. It is to be appreciated that the illustrated network connections are examples and that other means of establishing communication link(s) between the computers  and  can be employed.","In a networked environment, such as that illustrated with computing environment , program modules depicted relative to the computer , or portions thereof, may be stored in a remote memory storage device. By way of example, remote application programs  reside on a memory device of remote computer . For purposes of illustration, application programs and other executable program components such as the operating system are illustrated herein as discrete blocks, although it is recognized that such programs and components reside at various times in different storage components of the computing device , and are executed by the data processor(s) of the computer.","Various modules and techniques may be described herein in the general context of computer-executable instructions, such as program modules, executed by one or more computers or other devices. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. Typically, the functionality of the program modules may be combined or distributed as desired in various embodiments.","An implementation of these modules and techniques may be stored on or transmitted across some form of computer readable media. Computer readable media can be any available media that can be accessed by a computer. By way of example, and not limitation, computer readable media may comprise \u201ccomputer storage media\u201d and \u201ccommunications media.\u201d","\u201cComputer storage media\u201d includes volatile and non-volatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules, or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by a computer.","\u201cCommunication media\u201d typically embodies computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as carrier wave or other transport mechanism. Communication media also includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared, and other wireless media. Combinations of any of the above are also included within the scope of computer readable media.","One or more flowcharts are described herein and illustrated in the accompanying Figures. The ordering of acts in these flowchart(s) are examples only\u2014these orderings can be changed so that the acts are performed in different orders and\/or concurrently.","Although the description above uses language that is specific to structural features and\/or methodological acts, it is to be understood that the invention defined in the appended claims is not limited to the specific features or acts described. Rather, the specific features and acts are disclosed as exemplary forms of implementing the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The same numbers are used throughout the document to reference like components and\/or features.",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 10","FIG. 7"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 16","FIG. 7"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 17","FIG. 7"]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 18","FIG. 7"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 19","FIG. 7"]},{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 20","FIG. 7"]},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 21","FIG. 7"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 22","FIG. 7"]},{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 23","FIG. 7"]},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 28"}]},"DETDESC":[{},{}]}
