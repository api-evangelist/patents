---
title: Object-oriented processor design and design methodologies
abstract: Also provided is a method for designing a distributed processing system for an application. The method includes steps of partitioning the application into functions and data messages; configuring a host processor having a host communication infrastructure (HCI) to pass data messages via the HCI to control the application; configuring a plurality of class processors to compute the functions into which the application is partitioned in response to the data messages; and interconnecting the class processors to the host processor via application program interface modules in a star configuration. Systems designed in accordance with this method embodiment are well-suited for integration on a single chip, and can be easily updated and modified as necessary, because changes made to a class processor have minimal effect on the remainder of the system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07062769&OS=07062769&RS=07062769
owner: National Semiconductor Corporation
number: 07062769
owner_city: Santa Clara
owner_country: US
publication_date: 19990707
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This invention relates generally to methods for object-oriented hardware design and to hardware produced thereby, and more particularly to distributed memory, object-oriented, class-based methods for processor design and the processors produced thereby.","Voice over Internet protocol (VoIP), wideband code division multiple access (WCDMA), third generation wireless networks, and other advanced wireless and wired broad-band communication systems require many complex, computationally-intensive signal processing functions. Examples of such functions include orthogonal frequency division multiplexing (OFDM) modems, Viterbi decoders, and Reed-Solomon decoders. In many cases, it is desirable for these signal processing functions to be fabricated on a single-chip integrated circuit.","One known methodology for placing such highly complex systems on a single chip is to provide powerful computational platforms on the chip to process all functions in a sequential manner in conjunction with a number of tightly-coupled intellectual property (IPs) cores, i.e., special-purpose processor and firmware layouts that are licensed for use in chip layouts for more complex processors. Computational platforms used in this design methodology include one or more microprocessors or digital signal processors (DSPs) and one or more standard or proprietary communication backbones, interface buses, or virtual sockets to connect all the necessary components into a unified environment. Such platforms can be characterized as being \u201cprocessor-centric,\u201d because the various processors and IP cores share complex bus architectures to process all of the functions and algorithms sequentially. As systems become larger and more complex, even more powerful core processors are required.","Although presently known signal processing architectures and design methodologies are sufficient for many present applications, it is becoming increasingly difficult to meet processing demands of new applications with these architectures for several reasons. First, newer bus and controller architectures have become very complicated because memory speed cannot keep up with the increasing speed of central processing units (CPU), even with cache memory. Thus, there is a CPU-memory bottleneck that manifests itself in faster applications due to physical propagation factors whenever the silicon die area used by a processor is sufficiently large. Second, present architectures require a costly investment in very large and complex software. When suitable software is written, it is necessarily operating system (OS) dependent, because such dependency is required to ensure that each process receives an appropriate time slice of the CPU's computational resources. Whenever changes to a processor are necessary or a move is made to another OS platform, the prior effort and investment in developing the application software are largely wasted or rendered obsolete. Third, computational demands on processor-centric architectures require increased computational speed as the processes themselves become more complex. Increases in computational speed necessarily raise power consumption.","It would therefore be desirable to provide methods for designing complex application processors that avoid CPU memory bottlenecks due to large silicon die areas. It would also be desirable to provide a processor architecture that provides reduced dependence upon an operating system of any particular core processor and a design method that provides greater freedom to redesign the application processor around a different host processor. It would also be desirable to provide an application processor architecture in which smaller functional sets not requiring a single high-speed processor are performed relatively independently of one another, thereby avoiding the CPU-memory bottleneck.","There is therefore provided, in one embodiment of the present invention, a distributed processing system having a host processor including a host communication infrastructure (HCI) configured for communication with said host processor; a plurality of class processors each having an associated private localized read\/write memory; and a plurality of application program interface modules each configured to provide an interface between said host communication infrastructure and at least one said class processor, wherein each said class processor responds to selected data messages on said HCI to perform selected computations utilizing said read\/write memory. This embodiment provides an ideal architecture for fabrication on a single chip. This embodiment also avoids processor and bus bottlenecks by providing distributed processing power with local memory for each class processor.","There is also provided, in another embodiment of the present invention, a method for designing a distributed processing system for an application. The method includes steps of partitioning the application into functions and data messages; configuring a host processor having a host communication infrastructure (HCI) to pass data messages via the HCI to control the application; configuring a plurality of class processors to compute the functions into which the application is partitioned in response to the data messages; and interconnecting the class processors to the host processor via application program interface modules in a star configuration. Systems designed in accordance with this method embodiment are well-suited for integration on a single chip, and can be easily updated and modified as necessary, because changes made to a class processor have minimal effect on the remainder of the system.","Other advantages of these embodiments and the others disclosed herein will become apparent to those skilled in the art upon reading the detailed description in conjunction with the accompanying drawings.","As used herein, the term \u201cobject-oriented\u201d refers to a paradigm in which variables and command statements operating on the variables are termed \u201cobjects,\u201d variables associated with an object are called \u201cattributes,\u201d and functions that operate on them are termed \u201cmethods.\u201d \u201cEncapsulation\u201d refers to a feature provided by the object oriented paradigm in that the only way to operate on, view, or otherwise alter, read, or access attributes of an object is by invoking the object's methods.","In one embodiment of the present invention, distributed processing system hardware is designed in accordance with the object-oriented paradigm. An application, for example, a physical layer processor for a communication system, is divided into active entities, i.e., signals, processing units, and defined transformations of signals. A correspondence is drawn between signals and objects and between transformations and methods, with transformations being defined as mathematical operations that are performed on signal objects. In cases in which it is possible to divide the application into active entities in more than one manner, a division is selected that localizes resources needed for implementation so that communication with other functions is reduced or minimized. This criterion reduces a potential for system conflicts and also reduces timing overhead for coordinating shared resources.","For example, a physical layer processor of a type suitable for some applications is partitioned according to this method embodiment into (1) an A\/D converter for converting an analog signal into a time domain digital signal \u201cA;\u201d (2) a standalone FFT using radix-2 to transform time domain digital signal \u201cA\u201d into a frequency domain signal \u201cB,\u201d the standalone FFT processor including twiddle factor coefficients and many repeated operations; (3) a Viterbi or convolutional decoder to decode signal \u201cB\u201d into a signal \u201cC\u201d using a read\/write memory; (4) a standalone FFT using a radix-4 transform to convert signal \u201cC\u201d to signal \u201cD\u201d and including other twiddle factor coefficients and many repeated operations; and (5) a multiplexer to take signal \u201cD\u201d to a host processor in the form of another digital signal \u201cE.\u201d It follows from the above partitioning and from the definition of an object, that signals A, B, C, D, and E are objects. It also follows that an analog to digital conversion, a fast Fourier transformation, a convolutional decoding, and a multiplexer mapping operation are methods. Computational engines that implement the methods are also identified as objects. Twiddle factors and memory are identified as attributes of objects, because they are attributes of the computational engines.","Groups of related functions and objects are then selected with an objective of minimizing communication between functional groupings, although it will be understood that not all application processors will be broken down into functions and objects that can be grouped in this manner. For example, a Fourier transform class providing an FFT and a DFT is recognized as a class grouping. Each computational object is configured to respond to requests from at least a host processor, such requests being defined as predefined or selected data messages that differ for each function. The transfer of messages between function processors, which henceforth are referred to as \u201cclass processors\u201d, allows relatively intense computation to be performed by the class processors without excessive loading of a host processor data bus.","Referring now to , an exemplary embodiment of a class processor  of the present invention comprises a special purpose processor . Suitable special purpose processors  include, but are not limited to, a very short instruction word (VSIW) processor, a digital signal processor (DSP), an application specific integrated circuit (ASIC) processor, a suitably-programmed microprocessor subcomponent, and hardwired components. In one embodiment in which class processor  is an FFT processor, special purpose processor  is a VSIW DSP processor. In one embodiment in which class processor  is a RAKE finger receiver, special purpose processor  is an ASIC processor. In one embodiment, special purpose processor  includes software or firmware (not shown) to provide a portion of its functionality.","Depending upon functions to be performed by class processor , one or more localized read\/write memories , , and  are provided and interconnected with special purpose processor  so as to be directly accessible to it, i.e., visible and addressable in its memory space. Memory  is a private localized read\/write memory  that is used by and is accessible only by special purpose processor  through its implemented methods. Memory  is a localized protected read\/write memory that is used by special purpose processor  to store and\/or read data accessible only by other class processors  of the same grouping or class. For example, where class processor  is a fast Fourier transform (FFT) processor, another class processor  (not shown in ) that implements a similar function or functions is able to access protected memory . Examples of two class processors sharing protected localized read\/write memory  are two FFT processors used at the same time, or an FFT processor and a discrete Fourier transform (DFT) processor that computes discrete Fourier transforms somewhat differently, for example, using a Winograd DFT. Access to protected localized read\/write memory  is provided by one or both of a direct interconnection  from protected localized read\/write memory  to the other class processor  or by providing special purpose processors  of each class processor  belonging to the same class with special knowledge of messages that can be passed between class processors  of that class. Memory  is a public read\/write memory that can be addressed by other components, including a host processor (not shown in ). In one embodiment, public read\/write memory is directly accessible via a memory mapped mailbox or an application program interface (API) module . It will be recognized by those skilled in the art that not all embodiments of class processors  require all three types of memories , , and . API module  comprises a communication port, for example, a hardware or software communication port that including a memory-mapped dual port memory bank. In another embodiment, API module  includes a memory stack.","In another embodiment and referring to , a block diagram of an exemplary physical layer communications processor  is shown. In this example, processor  is an object oriented communications signal processor (OOCSP) fabricated on a single chip. OOCSP  comprises a host processor  and various functional class processors , , , , and  in addition to an embodiment of FFT class processor  of . Host or main processor  is a standard microprocessor embodiment or \u201cIP core.\u201d The invention places no restriction on the type of host processor . Exemplary host processors  useful for this embodiment are ARM, MIPS, x86, 68xxx, TMS320, DSP16xxx and DSP56xxx series processors. Each of these host processors is characterized by a native host communication infrastructure (HCI) , which includes a bus and a port configuration.","Class processors , , , , , and  provide computational power for invoking methods of data or signal objects for OOCSP . For the embodiment exemplified by , the class processors are implemented as hard IPs and are FFT class processor , Galois field (GF) field class processor , synchronization object , forward error correction (FEC) object , Rake finger object , and I\/O class processor , the latter being provided to increase data pumping capabilities of OOCSP  beyond that already provided by native I\/O processing of host processor . Class processors , , , , , and  are each designed to processes certain specialized functions and no others on data structures, or in other words, each performs operations on a selected proper subset of application objects. Each class processor , , , , , and  is an application oriented functional unit programmable for its intended application. For example, FFT class processor  can initiate various real and complex FFT operations at different word-length accuracy, and is the hardware analog to an object-oriented language class. The functions of class processors , , , , , and  are selected and grouped to enhance abstraction, i.e., making the action of OOCSP  more readily accessible to a programmer of host processor , and to enhance encapsulation, i.e., hiding of internal workings of each class. Memory  is also provided for programming and local data storage of host processor . For efficiency and speed, memory  is organized in a native structure of host processor , whether it is provided internally or externally to host processor . Memory  is of a suitable type (e.g., RAM, ROM, DRAM, eDRAM, etc.) and amount needed for host processor  to control the functions of class processors , , , , ,  and their communication with host processor .","In the embodiment of , APIs  provide communication between class processors , , , , , and  and other subsystems, including host processor  and other class processors. Each API  provides \u201cpublic visibility\u201d by providing an interface to HCI . Each API  provided to a different class processor , , , , , and  implementing different functions is slightly different, in that each provides a visibility to host processor  for its respective class processor that effectively defines a programming interface for its class processor. Thus, the API of a class effectively describes what a class can do, while implementation of the class describes how it does it, in a manner analogous to application programming interfaces of software programs. Particular implementation of APIs  is a design choice, in that APIs  can be a virtual socket interface or any type of bus communication or I\/O port data exchange mechanism. Use of a memory mapped dual port RAM bank, stack, and FIFO memory permits native HCI  to be easily maintained.","It will be observed that OOCSP  provides a number of advantages over known processors. First, communication among class processors , , , , , and  is restricted, in that in the embodiment of , no class processor has any knowledge of any other class processor or any ability to communicate with any other class processor. All communication is with host processor , i.e., OOCSP  is arranged in a \u201cstar\u201d configuration. No complex, fast busses are needed. Because class processors , , , , , and  each provide separately implemented functions with a defined interface, no class processor has any particularized knowledge of the internal workings of any other class processor, and class processors are referred to only through their defined interfaces. Each class processor has all the memory it requires in close proximity to itself to reduce propagation delays, and the minimization of public or global memories and data structures is kept to a minimum to limit the opportunity for class processors to affect one another. Because of abstraction and data hiding behind a defined interface, class processors , , , , , and  can be provided as hard IP objects that can be used without concern as to their inner workings. Moreover, any changes to one of the class processors has only minimal, if any, effect on the operation of others, so the effect of design revisions is localized. Also, class processors that are closely coupled to the host processor or to other class processors (i.e., that require frequent or speedy, low propagation delay access to one another) can be placed close to one another on a chip.","In another embodiment and referring to , a block diagram of a single-chip OOCSP application layer processor  is shown. Although designed for a different purpose, the architecture of application layer processor  is similar to that of physical layer processor  of , except that host processor  and HCI  communicate with class processors , , , , , and , most of which are different from those comprising physical layer processor . More particularly, application layer processor  comprises an audio class processor , a filter bank class processor , a synchronization object  a video class processor , a discrete cosine transform (DCT) object and an I\/O class processor . This example shows the reuse of I\/O class processor , which is made possible, in part, because of the loose coupling, i.e., data hiding and encapsulation, of the object-oriented design paradigm. Synchronization object  is related to synchronization object , but differ because synchronization methods applicable to a physical layer and to an application layer are, in general, somewhat different. Class processors , , , ,  and  are arranged so that those functions that would be most adversely affected by propagation delays are electrically closest to host processor  in that propagation delays are minimized. For further efficiency, although not shown in the embodiments of  or , related class processors, i.e., those of the same class, share a protected localized read\/write memory  in other processor embodiments. Sharing is accomplished in one embodiment by direct coupling of memory  via a semi-private bus  to the sharing class processor or processor, or in another embodiment by configuring processors  of class processors of the same class to communicate messages to one another through their APIs , either by direct communication with one another or indirectly through a host processor . Otherwise, class processors have no knowledge of communication protocols of class processors not in the same class and thus, cannot communicate with or reference the other processors, and memories  are not directly or indirectly accessible to class processors of different classes. In one embodiments, class processors are provided with public memories  that are addressable by host processor  via HCI  and API , such as by memory mapping.","From the preceding description of various embodiments of the present invention, it is evident that complex processors are produced from the design methodologies of embodiments of the present invention without CPU memory bottlenecks due to large silicon die areas, because of data hiding and the providing of localized private memories for class processors. Moreover, the application processor architecture resulting from embodiments of the present invention isolate host processors from the complexity of the functions provided by the class processors with an application programming interface, so that the resulting architectures are relatively independent of an operating system running on the host processor. Also, the functional decomposition of the application processor allows greater freedom to change host processors and removes high speed processing constraints by shifting much of the processing load to specialized processors rather than the host processor.","Although the invention has been described and illustrated in detail by reference to specific embodiments, it is to be clearly understood that the same is intended by way of illustration and example only and is not to be taken by way of limitation. For example, one skilled in the art will recognize that one can build up a collection of reusable objects, classes, and class hierarchies for different applications, their reuse being facilitated by their appearance to a programmer of a host processor as simple API module calls. Reuse and design validation is further enhanced and facilitated because software simulators of object-oriented classes and their associated objects can be made identical in behavior to the processors themselves to allow rapid and accurate software development and final compilation and integration of an overall device. Indeed, devices designed using method embodiments of the present invention can be implemented using technologies analogous to software compilers. It will also be observed that the invention is generally applicable to many different applications, including, for example, user-layer applications such as object-oriented HDTV processors and object-oriented audio processors, and also to applications not related to signal processing, as such. Because of the modularity of design provided by the present invention, the present invention can be used in the design of, and incorporated into the architecture of \u201csuper\u201d OOCSP platforms in which different OOCSP cores are combined. Accordingly, the spirit and scope of the invention are to be limited only by the terms of the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0011","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0011"},"figref":"FIG. 3"}]},"DETDESC":[{},{}]}
