---
title: Runtime optimization of application bytecode via call transformations
abstract: A method and system for optimizing application code via transformation of calls made by the application code during runtime. A computer system loads the application code that has been intermediately compiled into bytecode. The computer system then compiles and executes the application code. During runtime, the application code makes a call from a call site to an implementation of an operation that returns a value to the application code. The computer system runs an implementer of the implementation and an agent that operates independently of a compiler. The agent receives a notification of the call, performs an analysis on the application code during runtime to determine whether the value is used by the application code, and optimizes the application code by transforming the call site based on a result of the analysis.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09183021&OS=09183021&RS=09183021
owner: Red Hat, Inc.
number: 09183021
owner_city: Raleigh
owner_country: US
publication_date: 20110531
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","DETAILED DESCRIPTION"],"p":["Embodiments of the present invention relate to runtime optimization of bytecode, and more specifically, to runtime optimization of bytecode via transformation of calls that are made to an implementation of an operation.","One of the commonly-used data structure in Java language is \u201cmap,\u201d which is a data store that organizes data as (key, value) pairs. The key in a (key, value) pair uniquely identifies the corresponding value. An application programming interface (API) to the map supports operations which allow values to be added to (via a put operation), retrieved from (via a get operation), or removed from (via a remove operation) the map. In all of these three cases, a key is presented to the API to identify the corresponding value being added, retrieved or removed.","In some scenarios, the data store can be very large and can be partitioned and\/or replicated across many host machines. Thus, any changes to the (key, value) pairs need to be propagated from machine to machine. As an example, Red Hat\u00ae Infinispan implements a high-performance cache organized as a map. When an Infinispan client requests a put operation to be performed on a cache value identified by a key, the put operation can potentially replace an existing cache value (i.e., a previous value). Thus, the client can be presented with a choice between a first put operation that returns a previous value (or some clearly identified null value if no entry was present previously), or a second put operation that does not return a previous value. A client that requires a return value may need to wait while the update is propagated to other host machines in order to be sure the correct previous value is returned. By contrast, a client that does not need the return value can proceed without waiting and, therefore, can speed up its operations.","In other scenarios, a client is presented with an API that only implements a put operation that returns a previous value, regardless of whether or not the client needs the previous value. For example, there are two standard APIs defined by the Java language runtime interfaces \u201cMap\u201d and \u201cConcurrentMap,\u201d both of which support the set of operations: get, put and remove, but the put operation has only the implementation that returns the previous value. This means that a client needs to wait for the result to be computed and returned, even if it ignores the returned result. This unnecessary wait time can significantly slow down the operations of the application code.","The problem of unnecessary wait time may be resolved, in some cases, by re-writing the client application so it is parameterized to accept only an Infinispan cache. In cases where the return value is needed, the client can invoke the put operation that returns a result. In cases where the return value is ignored, the other put operation can be invoked. However, there are legitimate cases where code needs to be able to operate on any map, not just an Infinispan cache. There may also be other reasons why it is not possible to redefine client code, e.g., the client code is proprietary, the client code forms part of the Java runtime, or the client code is frozen due to logistical, commercial or other hurdles.","Described herein is a method and system for optimizing application code via transformation of calls made to a slow implementation of an operation during runtime. In one embodiment, a computer system loads the application code that has been intermediately compiled into bytecode. After the computer system compiles the application code with a compiler, it executes the compiled application code. During runtime, the application code makes a call to an implementation of an operation that returns a value to the application code. The computer system runs an implementer of the implementation and an agent that operates independently of the compiler. The agent receives a notification of the call from the implementer, performs an analysis on the application code during runtime to determine whether the value is used by the application code, and optimizes the application code by transforming the call site based on a result of the analysis.","Embodiments of the invention have a wide range of applicability. In addition to the scenario of a put operation performed on a map, embodiments of the invention can be applied to application code invoking an operation (e.g., put or other operations) that returns a result, where the operation can have two alternative concrete implementations in a library, a slow implementation that returns a value and a fast implementation that does not. The application code that makes a request to perform the operation provides no hint to the called routine as to whether it really needs to use the return value. Embodiments of the invention optimize the application code by monitoring calls to the original slow implementation, analyzing the application code that has invoked the original slow implementation, and identifying whether or not the application code uses (e.g., consumes or stores) the return value. If the application code does not use the return value and it is legitimate to transform the call site, the application code is transformed such that further calls from the call site will be made to the fast implementation in place of calls to the original slow implementation. In one embodiment, the transformation from the original slow implementation to the fast implementation is referred to as a primary transformation.","In some embodiments, the primary transformation can be supplemented with a secondary transformation to further optimize the performance of the application code. The secondary transformation is applied to the cases where the return value is used, or where it is not possible to determine whether it is legitimate to invoke the fast implementation. The secondary transformation transforms a call site from calling the original slow implementation into calling an alternative slow implementation, which returns the same value as the original slow implementation but avoids performing any monitoring operation. This serves to avoid unnecessary, repeated analysis of the application code at the same call site.","Embodiments of the invention modify the application code with the primary and secondary transformations while the application code is running. In one embodiment, the application code is an intermediate compiled version (e.g., bytecode) of original application source code. In one embodiment, the bytecode transformation is enabled by an agent that runs on a virtual machine (e.g., the Java Virtual Machine (JVM)). The transformation introduces a linkage dependency between the transformed code and the implementation code such that calls to the fast and the alternative slow implementations can be performed. Embodiments of the invention resolve this dependency using the agent's capability.","Although certain embodiments described herein reference JAVA and the Java Virtual Machine, it should be understood that other embodiments may use other programming languages, other compilers, and\/or other runtime environments (e.g., C++, C#, .NET, etc.). In one embodiment, the JVM may permit loaded bytecode to be inspected and transformed (e.g., modified). The JVM may also permit the transformed bytecode to be submitted (e.g., sent and\/or communicated to) a Just-InTime (JIT) compiler so that the transformed bytecode could be compiled using the JIT compiler. It should be understood that various JVMs permit bytecode to be transformed and submitted to a JIT compilers. It should also be understood that in other embodiments, other types of virtual machines may be used and these other types of virtual machines may also allow bytecode to be transformed and submitted to a compiler.","In the following description, numerous details are set forth. It will be apparent, however, to one skilled in the art, that the present invention may be practiced without these specific details. In some instances, well-known structures and devices are shown in block diagram form, rather than in detail, in order to avoid obscuring the present invention.",{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1","b":["100","100","100","120","120"]},"In one embodiment, the computer system  is coupled to a remote computer  over a network . The computer system  can download application code , in the form of intermediately compiled bytecode, from the remote computer  (e.g., a Web server). The computer system  is also coupled to one or more host computers  via the network . In one embodiment, the host computers  provide a data store (\u201cmap \u201d) that stores a collection of (key, value) pairs. Each host computer  can store a portion of and\/or a replica of the map . The network  can be a private network (e.g., a local area network (LAN), a WAN, intranet, or other similar private networks), a public network (e.g., the Internet), or a combination of the above networks. In an alternative embodiment, the map  can be stored in a centralized location remotely from or locally at the computer system . In yet another alternative embodiment, the computer system  is not coupled to the remote computer  and\/or the host computers , and can receive the application code  and\/or retrieve stored data values from other sources (e.g., local sources).","In one embodiment, the application code  is loaded into the virtual machine  and compiled from bytecode into machine code. The virtual machine  can compile the bytecode using a Just-in-Time (JIT) compiler  (e.g., a compiler which compiles application code into machine code, as the application code is needed and\/or used), and executes the machine code on the computer system .","In some scenarios, the application code  includes instructions that request an operation (e.g., a put operation) to be performed. In one embodiment, the virtual machine  includes an agent  that analyzes the application code  at runtime and transforms the application code , also at runtime, to reduce or eliminate the wait for a return value when the return value is not used. The virtual machine  also includes a library , which can be an application library provided by a third party (which is different from the provider of the application code ). Thus, the library  receives no hints and has no knowledge of the calls that the application code  made during runtime (i.e., during execution time of the application code ). In one embodiment, the library  includes an implementer , which implements and performs the transformed operations.",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 2","b":["140","150","130","150","230","140","130","240","140","250","230","240","250","170","230","240","250"]},"In one embodiment, the implementer  implements the original slow implementation  (e.g., a Java method) and the associated API (e.g., a Java interface) that defines the original slow implementation . The implementer  can also implement abstract operations (e.g., abstract Java methods) and one or more abstract APIs defining these abstract operations, where the abstract operations and the abstract APIs can resolve to the original slow implementation  (e.g., a concrete and non-abstract Java method) at linkage time (i.e., when the compiled application code  is linked to the specific resources in the library ). Thus, when the application code  calls the abstract APIs and associated abstract operations at runtime, it is the original slow implementation  that is called. All of these operations have the same signature (e.g., parameter types and return type). Additionally, the implementer  implements the alternative slow implementation  and the fast implementation , as well as an alternative API (e.g., a Java interface) that defines two associated alternative operations. The alternative API and its associated alternative operations can be resolved to the implementations  and  at linkage time. The fast implementation  has the same parameter types as the original slow implementation  and a void return type. The alternative slow implementation  has the same signature as the original slow implementation .","With the fast implementation , the implementer  can take whatever short cuts appropriate to allow it to operate correctly as an implementation of the abstract API while profiting from the fact that it does not have to return a result. The original and alternative slow implementation ,  are identical, except for one small difference with respect to agent notification. Both implementations ,  implement the abstract operation so that they operate correctly as an implementation of the abstract API returning a result. However, the original slow implementation  notifies the agent  that the original slow implementation  has been called, while the alternative slow implementation  sends no notification.","In one embodiment, when the agent  is notified for the first time during runtime of the application code , the notification to the agent  can involve installing the agent  onto the runtime virtual machine . In an alternative embodiment, the agent  can be pre-installed onto the virtual machine  when the virtual machine  is started. In one embodiment, the first agent notification for a given operation can also involve registering with the agent  the linkage information regarding implementations ,  and . In an alternative embodiment, the implementer  can pre-register this linkage information with the agent . In one embodiment, the linkage information includes details for linking an abstract API (as well as its associated abstract operation) to the original slow implementation , and details for linking an alternative API (as well as its associated alternative operations) to the alternative slow implementation  and the fast implementation .","In one embodiment, the notification to the agent  initiates analysis and transformation of the call site in the application code . The \u201ccall site\u201d refers to a CALL instruction in the application code  that invokes the original slow implementation . Upon notification, the agent  captures runtime information in the notification, which identifies the method from which the call to the original slow implementation  was made. The agent  then identifies the class that defines the method and schedules a selected scope (e.g., the call site, other calls within the identified method, all methods in the identified class) of the application code  for transformation. In some scenarios, the agent  may receive other notifications in parallel with this transformation process. In one embodiment, the agent  keeps track of the call sites that call the original slow implementation , and detects and ignores any repeated notifications which occur while the transformation is being performed.","In one embodiment, the agent  includes an analyzer  that performs analysis on the application code , and a transformer  that transforms the application code  when appropriate (as described below). The analysis performed by the agent  is relatively simple. Upon notification from the implementer , the agent  searches the code (e.g., in the form of bytecode) of any class identified from the notification for calls that invoked operations in the original linkage set (which includes direct calls to the original slow implementation  as well as calls to the abstract APIs and associated abstract operations). Whenever the agent  finds such a call, it checks the bytecode following the call site to detect whether the value returned from the call is used. In one embodiment, the agent  does not need to identify every case where the value is unused. Rather, the agent  identifies that the value is not used by noting that the next instruction (to the call site) in the bytecode is a pop (e.g., Java bytecode POP) or return (e.g., Java bytecode RET). The agent  applies a primary transformation  (which transforms a call site into calling the fast implementation ) if it is decided that the value is not used. The agent  applies a secondary transformation  (which transforms a call site into calling the alternative slow implementation ) in other cases (when the value is used, when it cannot be determined whether the value is used, and when it cannot be determined whether the call site can be transformed into the fast implementation ). In an alternative embodiment, the agent  can perform a full check on the application code  by analyzing all operations subsequent to the call site. The analysis can include determining whether the application code  consumes the value, stores the value for later retrieval (e.g., in a local storage location, a global storage location, or in an object field), or uses the value in any manner and for any purpose. However, this alternative embodiment is much more time-consuming than the embodiment in which only the next instruction to the call site is checked.","As described above, a call site is a specific location where a CALL instruction in the application code  invokes the original slow implementation . In one embodiment, there can be more than one CALL instruction in the application code  that can invoke the original slow implementation , because the application code  may need to read or update a map or a cache at many different points during execution. In one embodiment, the agent  can select a scope of transformation on the call site or call sites out of necessity or based on policy considerations. For example, the agent can apply the transformation to the method that includes the CALL instruction (as well as other CALL instructions), or the class defining the method (as well as other methods). If there is enough information available in the notification, the agent  can restrict the transformation to a specific subset of the calls within the method, or a single call that actually invokes the original slow implementation .","As a preliminary matter, it is noted that the application code  is organized as a set of independent methods, each of which belongs to a specific class. So, any given call site that will occur belongs to a unique class\/method. However, this does not guarantee a bi-directional uniqueness. Any given method may contain more than one call site. This is the reason why it may be necessary to update multiple call sites during transformation.","In one embodiment, the instrumentation code in the original slow implementation  is guaranteed to be able to identify which application class and method included the call site, but it cannot be guaranteed to identify the exact location of the CALL instruction inside that method. In some cases there may only be one call site so it is clear the call was made from that site. In other cases the method may include information which allows the location of the call site to be identified or, at least, restricted to some of the possible locations. But in most cases the agent  can only know that the original slow implementation  was called from one of the possible call sites in a specific application class\/method, but it cannot know which one.","In one embodiment, when the agent  performs the transformation it may locate the class\/method and limit any changes it makes to code belonging to that method. If the agent  cannot determine which CALL instruction actually invokes the original slow implementation , it needs to transform every possible call site within the method. The agent  finds each CALL instruction within the method, determines whether the target of the call could be the original slow implementation  and, if so, transforms that call site and so on to the next one.","There is also a policy decision which can be made during transformation. An application class which is known to contain a call site in one of its methods may well contain call sites in other methods. The agent  can decide to \u201ceagerly\u201d transform code belonging to other methods of the class. Adopting this policy can be beneficial because it can do all the transformation work in one go with the minimum of effort. However, in some scenarios, transforming the calls within the whole class can be a waste of time, e.g., because it turns out that there are no other call sites, or because the other possible call sites do not actually get visited during execution so the extra transformation work is wasted effort. This \u201ceager\u201d transformation is an extrapolation from the fact that a call to the original slow implementation  has occurred to the assumption that other calls within the same class might end up invoking the same implementation . That is why this \u201ceager\u201d transformation is an extra policy option rather than a necessary step.","In one embodiment, the agent  can adopt different strategies for selecting the scope of the application code  to be transformed, so long as it ensures that it keeps track of duplicate notifications at a comparable level of granularity (e.g., a class, the method, a single call within the method, or a subset of calls within the method). Duplicated notifications are tracked such that the same scope of the application code  is not analyzed more than once.","In one embodiment, the primary transformation  performed by the agent  replaces a call to the abstract implementation (i.e., abstract APIs and associated abstract operations) or a direct call to the original slow implementation  with a call to the fast implementation . In some embodiments, the primary transformation  can additionally patch up the stack to account for the lack of a return value with the fast implementation . In the case where the next instruction (to the call site) is a pop, this instruction (pop) can be removed. In the case where the next instruction is a return instruction, no patching is necessary since the stack values are discarded at return. Other cases based on deeper analysis can be dealt with by stacking a null (or zero) value. Since the value is not used, it actually does not matter what value is employed in the stack.","In some scenarios, the primary transformation  described above cannot be performed. It is only appropriate to call the fast implementation  when the target of the abstract operation is an instance of a class which implements the alternative API. This is true if the call site employs a direct call to the original slow implementation , but is not necessarily true if the call is via one of the abstract APIs.","In one embodiment, if the call is via one of the abstract APIs, then a slightly more complex transformation is necessary. The original call (and the next instruction if it is a pop) is replaced by an instruction sequence starting with a runtime type test (e.g., Java instruction INSTANCEOF) to determine whether the target instance implements the alternative API followed by a branch instruction. The true branch includes a type cast (e.g., Java instruction CHECKCAST) followed by a call to the fast implementation  (plus a null or zero stack if the original call was not followed by a pop). The false branch includes the original call (plus a pop if the original code included one). Both branches then continue at the instruction following the original call (or after the pop if the call was followed by a pop).","In one embodiment, the agent  performs the secondary transformation  by replacing the call to the abstract implementation (or a direct call to the original slow implementation ) with a call to the alternative slow implementation . However, since the replacement call returns a result in the same way as the original slow implementation , there is no need to patch up the stack.","Similar to the first transformation, the secondary transformation  may not be performed in some scenarios. It is only appropriate to call the alternative slow implementation  when the target of the abstract operation is an instance of a class which implements the alternative API. This is true if the call site employs a direct call to the original slow implementation , but is not necessarily true if the call is via one of the abstract APIs.","If the call is via one of the abstract APIs, then a slightly more complex transformation (similar to the primary transformation  described above) is necessary. The original call is replaced by an instruction sequence starting with a runtime type test (e.g., Java instruction INSTANCEOF) to determine whether the target instance implements the alternative API followed by a branch instruction. The true branch includes a type cast (e.g., Java instruction CHECKCAST) followed by a call to the alternative slow implementation . The false branch simply includes the original call. Both branches then continue at the instruction following the original call.","The combination of the primary transformation  and secondary transformation  is \u201cself-healing,\u201d that is, it ensures that the original slow implementation  eventually stops being called from the same call site, in favor of either the fast implementation  or the alternative slow implementation . This means that once the initial cost of performing the transformation ( or ) has been met, there is no additional overhead involved in detecting and ignoring repeat notifications. Omitting the secondary transformation  is also an option, but it means that calls that cannot be transformed to employ the fast implementation  keep incurring the overhead of notifying a previously identified call site.","Resolving Linkage Issues: The original application code  prior to transformation is able to invoke the implementer's  original slow implementation  without the need for the implementer class to be in its classloader scope (class B is in the classloader scope of class A when references to class B by name in the code of class A are correctly resolved during linking). The transformed application code  includes references to the alternative API (e.g., a Java interface) which means this alternative API needs to be visible in the classloader scope of the transformed application code .","This requirement can be satisfied by ensuring that the API class is loaded via the bootstrap classloader. Classes which are loaded in this way are in scope for every class in the virtual machine  (e.g., a JVM), including the classes which implement the JVM itself. Alternatively, the code can be made available via the system loader, which ensures that the application code  (but not the JVM runtime code) will be able to resolve the registered API. The capability of the agent  enables both these options to be performed when the implementer  registers its API. It is also noted that the implementer  itself needs to reference the API. However, the loading of the implementation code can be organized such that this requirement is satisfied.","Embodiments of the invention have many advantages. The optimization (including analysis and transformation) is dynamic and adaptive. That is, the optimization is performed at runtime in response to calls to the original slow implementation , so optimization occurs in response to invocation of a registered implementation.","The optimization is autonomous. The optimization opportunity is detected and notified by the implementer  at runtime which operates independently of the compiler  of .","The optimization is third party. The optimization is negotiated by the implementer , but applied to the independent application code  which has been built without any compile or link time dependency on the implementer . The implementer  is part of the library  that operates independently of the application code . The library  can be provided by a third party which is independent of the provider of the application code . The provider of the library  may have no knowledge of the details of the application code , and, thus, the library  receives no hints of the calls that will be made by the application code  during runtime. Nevertheless, the library  can, with the use of the agent , optimize the execution of the application code .","The optimization occurs in the \u201cuser space\u201d (as opposed to the \u201csystem space\u201d performed by the compiler ). The optimization is performed at runtime on intermediate compiled application code  (e.g., bytecode), so it is not an offline source-to-source transformation. Yet the optimization is performed by the agent , which in one example is a loadable Java program. The optimization can be performed on the bytecode at any time during runtime. After the bytecode is transformed, the transformed bytecode can be re-compiled, also at runtime, by the built-in JIT compiler  provided by the virtual machine .","The optimization is extensible. Multiple implementations (e.g., the original slow, alternative slow and fast implementations , ,  and other implementations) can register with the agent . The optimization of calls to these implementations and their APIs can be performed repeatedly as necessary.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 3","FIG. 1","FIG. 5","FIG. 1"],"b":["300","130","300","500","300","100"]},"Referring to , in one embodiment, the method  begins when the virtual machine  loads the application code  (in bytecode), compiles the application code, and executes the compiled application code (block ). During runtime (i.e., when the application code  is being executed), the application code  calls the original slow implementation  that returns a value (block ). The implementer  (more specifically, the original slow implementation ) notifies the agent  of the call (block ). Upon notification, the agent  analyzes the application code  (block ). The agent  determines whether the return value is used (e.g., consumed or stored) by the application code  (block ). If the return value is not used, the agent  further determines whether the application code  (more specifically, the call site) can be transformed to call the fast implementation  (block ). If the call site can be transformed to call the fast implementation , the agent  transforms the call site to call the fast implementation  (block ). The agent  transforms the application code  to call the alternative slow implementation  (block ) in other scenarios, e.g., if the return value is used, if it cannot be determined whether the return value is used, if the call site cannot be transformed to call the fast implementation , or if it cannot be determined whether the call site can be transformed to call the fast implementation . After the transformation, the application code  is recompiled and continues to be executed on the virtual machine  (block ).",{"@attributes":{"id":"p-0051","num":"0050"},"figref":["FIG. 4","FIG. 1","FIG. 5","FIG. 1"],"b":["400","140","130","400","500","400","100"]},"Referring to , in one embodiment, the method  begins when the agent  receives a notification of a call to the original slow implementation  from the implementer  (more specifically, the original slow implementation ) (block ). From the notification, the agent  identifies the method from which a call to the original slow implementation  is made and identifies the class that defines the method (block ). The agent  then determines whether the return value from the original slow implementation  is used by the application code ; e.g., by checking the instruction next to the call site (block ). If the return value is not used, the agent  also determines whether the call site can be transformed to the fast implementation  (block ). If the call site can be transformed to the fast implementation , in some embodiments, the agent  can select a scope of transformation (block ); e.g., the method identified from the notification, all methods in the class defining the method, a single call within the method (e.g., the call site), or a subset of calls within the method. Based on the determinations at blocks  and , the agent  transforms the application code  in the selected scope to call either the fast implementation  (if the return value is not used and the call site can be transformed to call the fast implementation ), or the alternative slow implementation  (in other cases) (block ).",{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 5","b":"500"},"The exemplary computer system  includes a processing device , a main memory  (e.g., read-only memory (ROM), flash memory, dynamic random access memory (DRAM) such as synchronous DRAM (SDRAM), Rambus DRAM (RDRAM), or other variations of memory devices), a static memory  (e.g., flash memory, static random access memory (SRAM), or other variations of static memory), and a secondary memory  (e.g., a data storage device), which communicate with each other via a bus .","The processing device  represents one or more general-purpose processing devices such as a microprocessor, central processing unit, or the like. More particularly, the processing device  may be a complex instruction set computing (CISC) microprocessor, reduced instruction set computing (RISC) microprocessor, very long instruction word (VLIW) microprocessor, processor implementing other instruction sets, or processors implementing a combination of instruction sets. The processing device  may also be one or more special-purpose processing devices such as an application specific integrated circuit (ASIC), a field programmable gate array (FPGA), a digital signal processor (DSP), network processor, or the like. The processing device  is configured to execute optimization logic  for performing the operations and steps discussed herein.","The computer system  may further include a network interface device . The computer system  also may include a video display unit  (e.g., a liquid crystal display (LCD) or a cathode ray tube (CRT)), an alphanumeric input device  (e.g., a keyboard), a cursor control device  (e.g., a mouse), and a signal generation device  (e.g., a speaker).","The secondary memory  may include a machine-readable storage medium (or more specifically a non-transitory computer readable storage medium ) on which is stored one or more sets of instructions (e.g., the optimization logic ) embodying any one or more of the methodologies or functions described herein (e.g., the agent  and the implementer  of  and ). The optimization logic  may also reside, completely or at least partially, within the main memory  and\/or within the processing device  during execution thereof by the computer system ; the main memory  and the processing device  also constituting machine-readable storage media. The optimization logic  may further be transmitted or received over a network  via the network interface device .","The non-transitory computer readable storage medium  may also be used to store the optimization logic  persistently. While the non-transitory computer readable storage medium  is shown in an exemplary embodiment to be a single medium, the term \u201cnon-transitory computer readable storage medium\u201d should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and\/or associated caches and servers) that store the one or more sets of instructions. The term \u201cnon-transitory computer readable storage medium\u201d shall also be taken to include any medium that is capable of storing or encoding a set of instructions for execution by the machine that causes the machine to perform any one or more of the methodologies of the present invention. The term \u201cnon-transitory computer readable storage medium\u201d shall accordingly be taken to include, but not be limited to, solid-state memories, and optical and magnetic media.","The computer system  may additionally include optimization modules  for implementing the functionalities of the agent  and the implementer  of  and . The module , components and other features described herein (for example in relation to  and ) can be implemented as discrete hardware components or integrated in the functionality of hardware components such as ASICS, FPGAs, DSPs or similar devices. In addition, the module  can be implemented as firmware or functional circuitry within hardware devices. Further, the module  can be implemented in any combination of hardware devices and software components.","Some portions of the detailed descriptions which follow are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here, and generally, conceived to be a self-consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like.","It should be borne in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise, as apparent from the following discussion, it is appreciated that throughout the description, discussions utilizing terms such as \u201cloading,\u201d \u201cexecuting,\u201d \u201creceiving,\u201d \u201cperforming,\u201d \u201coptimizing,\u201d or the like, refer to the action and processes of a computer system, or similar electronic computing device, that manipulates and transforms data represented as physical (electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.","Embodiments of the present invention also relate to an apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes, or it may comprise a general purpose computer system selectively programmed by a computer program stored in the computer system. Such a computer program may be stored in a computer readable storage medium, such as, but not limited to, any type of disk including optical disks, CD-ROMs, and magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic disk storage media, optical storage media, flash memory devices, other type of machine-accessible storage media, or any type of media suitable for storing electronic instructions, each coupled to a computer system bus.","The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with programs in accordance with the teachings herein, or it may prove convenient to construct a more specialized apparatus to perform the required method steps. The required structure for a variety of these systems will appear as set forth in the description below. In addition, the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.","It is to be understood that the above description is intended to be illustrative, and not restrictive. Many other embodiments will be apparent to those of skill in the art upon reading and understanding the above description. Although the present invention has been described with reference to specific exemplary embodiments, it will be recognized that the invention is not limited to the embodiments described, but can be practiced with modification and alteration within the spirit and scope of the appended claims. Accordingly, the specification and drawings are to be regarded in an illustrative sense rather than a restrictive sense. The scope of the invention should, therefore, be determined with reference to the appended claims, along with the full scope of equivalents to which such claims are entitled."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention is illustrated by way of example, and not by way of limitation, and can be more fully understood with reference to the following detailed description when considered in connection with the figures in which:",{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":["FIG. 4","FIG. 2"]},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
