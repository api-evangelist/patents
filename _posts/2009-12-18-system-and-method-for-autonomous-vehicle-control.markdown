---
title: System and method for autonomous vehicle control
abstract: A system for localizing an autonomous vehicle to a target area can include a position indicator adapted for association with the vehicle in a three dimensional configuration, a detection device configured to detect the position indicator, a computation device configured to compute a position of the vehicle based on the detected position indicator and the relationship of the configuration to the vehicle orientation, a transmitter configured to receive information from the computation device and produce a signal carrying the information, a receiver configured to receive the signal from the transmitter and filter the information therefrom, and a control system configured for association with and control of one or more directional control components of the vehicle, the control being based on the information received from the receiver relating to localizing the vehicle to the target area. A method of for localizing a vehicle to a target area is also disclosed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08301326&OS=08301326&RS=08301326
owner: ReconRobotics, Inc.
number: 08301326
owner_city: Edina
owner_country: US
publication_date: 20091218
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATION","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The present application claims priority to U.S. Provisional Application No. 61\/203,246, filed Dec. 19, 2008, entitled Techniques for Autonomous Vehicle Control. The present application is also related to U.S. Non-provisional application, filed on Dec. 18, 2009 entitled System and Method for Determining an Orientation and Position of an Object. The contents of both of the above referenced applications are hereby incorporated by reference herein in their entireties.","The present disclosure relates to systems and methods for autonomous vehicle control. In particular, the present disclosure relates to systems and methods for automated, feedback-controlled localization of a vehicle to a point in two or three dimensions.","An autonomous or automated vehicle may generally be described as any type of vehicle, whether operating underwater, over land, or in the air, that is controlled, in whole or in part, by computerized control systems. Such vehicles typically operate unmanned\u2014that is, without an operator physically present in the vehicle\u2014and are used in a variety of applications where it may be too dangerous, uneconomical, or impractical to employ the conventional, manned vehicle counterpart. As technology advances, autonomous vehicles have found increasing use in civilian and military settings.","Autonomous underwater vehicles (AUVs), also known as unmanned underwater vehicles, may be used to perform a variety of underwater missions such as detecting and mapping submerged wrecks, rocks, and obstructions that pose a hazard to navigation for commercial and recreational vessels. Unmanned ground vehicles (UGVs) may be used in a variety of applications where it is dangerous or impractical for humans to travel, such as over un-surveyed terrain, or through areas of hostile activity in military applications. Unmanned Aerial Vehicles (UAVs) are remotely piloted or self-piloted aircraft that can carry cameras, sensors, communications equipment or other payloads, including military ordinances.","A particular focus of research in autonomous or automated vehicles has been the systems and methods by which they are controlled during their operation. For example, with regard to UAVs, size and weight restrictions can limit the amount of equipment a UAV can carry for performing precision autonomous landings. Rather, current UAV's are designed to be crash resistant\u2014i.e., they are not designed to be able to land at all, but rather to be \u201cusable\u201d subsequent to a crash landing. Despite this, greater than one third of UAV's may be damaged beyond repair during crash landing. At a price exceeding $50,000 per unit, it would be desirable to have a UAV capable of autonomous landing so as to avoid these repair\/replacement costs. Other autonomous vehicles (AUVs, UGVs) may also encounter control problems during their operation, which would be benefited by improved autonomous control.","In one embodiment, a system for localizing an autonomous vehicle to a target area can include a position indicator adapted for association with the vehicle in a three dimensional configuration where the configuration has a relationship to the vehicle orientation. The system can also include a detection device adapted for association with the target area and configured to detect the position indicator. A computation device in communication with the detection device can also be provided and can be configured to compute a position of the vehicle based on the detected position indicator and the relationship of the position indicator configuration to the vehicle orientation. A transmitter can be provided in communication with the computation device and configured to receive information from the computation device and produce a signal carrying the information. A receiver can be adapted for positioning on the vehicle and configured to receive the signal from the transmitter and filter the information therefrom. Additionally, a control system in communication with the receiver can be provided. The control system can be configured for association with and control of one or more directional control components of the vehicle. The control can be based on the information received from the receiver relating to localizing the vehicle to the target area.","In a particular embodiment of the system described, the vehicle can be an unmanned aerial vehicle. In this embodiment, the position indicator can include a plurality of point sources and at least one of the point sources can be positioned on each of two wingtips of the unmanned aerial vehicle. Additionally, at least one can be positioned on an underside or a top side of a vertical stabilizer of the unmanned aerial vehicle.","In a particular embodiment of the system for localizing a vehicle to a point, the position indicator can include a plurality of point sources adapted for arrangement on the vehicle in the three dimensional configuration. The point sources can include sources of electromagnetic radiation. In one embodiment, the sources of electromagnetic radiation comprise LED's. In another embodiment, the sources of electromagnetic radiation are defined by a paint scheme on the vehicle. The detection device can be adapted for capture of electromagnetic radiation from the point sources on a two dimensional plane. In one embodiment, the detection device can be a camera configured to detect visible light.","In one embodiment of the system for localizing a vehicle to a point, the computation device can be a personal computer. In another embodiment, the computation device can include an image capture module configured to control the detection of the detection device. In another embodiment, the computation device can include a position calculating module configured to convert a two dimensional representation of the position indicator to a three dimensional position and orientation of the vehicle.","In another embodiment, a method for localizing an autonomous vehicle to a target area can include capturing a two dimensional representation of a position indicator positioned on the vehicle, computing a position and orientation of the vehicle based on the two dimensional representation and further based on a known configuration of the position indicator and a known relationship between the configuration and vehicle orientation. The method can also include transmitting information to a control system associated with one or more directional control components of the vehicle and manipulating the one or more directional control components using the control system, based on the transmitted information, to localize the vehicle to the target area.","In a particular embodiment of the method described, the capturing step can include receiving electromagnetic radiation projected on a two dimensional plane. The method can also include filtering background noise out of the two dimensional representation. Additionally, the method can include analyzing the two dimensional representation to determine the two dimensional orientation of the position indicator.","In one embodiment of the method, the computing step can include solving linear equations. The linear equations can be bounded by one or more assumptions and in some embodiments can include a Taylor series expansion.","In one embodiment of the method, the vehicle can be an unmanned aerial vehicle and manipulating the one or more directional control components can include manipulating one or more of the ailerons, rudder, elevator, or powerplant of the unmanned aerial vehicle. Manipulating the one or more directional control components can cause the unmanned aerial vehicle to localize toward the target area. Additionally, the target area can be a landing area and the detection device can be located near the target area thereby causing the unmanned aerial vehicle to perform an approach for landing.","The present disclosure relates to a system and method for autonomous vehicle control. Specifically, the present disclosure relates to systems and methods for automated, feedback-controlled localization of a vehicle to a point in two or three dimensions. For example, referring to , a vehicle can be located at a first coordinate A (x, y, z) in three dimensional space. The system in accordance with the present disclosure can be used to localize the vehicle along the arrow C to a second coordinate B (x, y, z).","An autonomous vehicle capable of use with the systems and methods of the present disclosure may include, but is not limited to, an autonomous underwater vehicle, an unmanned ground vehicle, or an unmanned aerial vehicle. It is to be noted that autonomous control can be provided with or without the presence of an onboard operator or remote operator. As such, the disclosed system is not limited to unmanned vehicles or those without remote control capabilities.","Referring to , the use of the system with an unmanned aerial vehicle (UAV) is shown. An environment  is depicted including a vehicle  in a flying configuration at an altitude above the ground  equal to the distance C. The system of the present disclosure may cause the vehicle  to localize approximately along the path A (and approximately along the over-ground projection B) to a target area D located, for example, on the ground , or at any other position, such as on a tripod, on a capture net, on a moving vehicle, on top of a building, aerial refueling craft, docking space, etc. Thus, in localizing to the target area D, the UAV together with the system herein described may be capable of performing an autonomous, feedback controlled approach to landing.","Referring still to , the system may generally include two sub-systems: a first sub-system  located on and integrated within the vehicle , and a second sub-system  independent of the vehicle  and located at a fixed position relative to the vehicle , for example at or near position D. The first sub-system  may comprise components which receive information, process that information, and control the direction of the vehicle  in two or more dimensions. Such components may be referred to as an \u201cautopilot.\u201d The first sub-system  may also comprise components which allow the vehicle's position to be detected. The second sub-system , which may be located at or near target area D, may comprise components for detecting the position of the vehicle , which may work in cooperation with the components of the first sub-system  which allow the vehicle's position to be detected. The second sub-system  may also comprise components that process the vehicles position and transmission components that allow the second sub-system  to transmit information to the directional control components of the first sub-system . Thus, the autonomous feedback controlled localization may function generally in the following manner. The components of the second sub-system  may detect the position of the vehicle . The position may be processed to determine the vehicle's current position relative to the target area and the second sub-system  may transmit positional or control information to the first sub-system  located on the vehicle . The first sub-system  may then receive the transmitted information, process the information as required, and control the vehicle  so as to localize to the target area D.","Referring now to , particular attention can be drawn to the components of the first sub-system . The first sub-system  can include a receiver , an inertial measurement unit (IMU), a computation device , a control system , and a position indicator . In some embodiments, the computation device  may or may not be provided. For example, depending on the nature of the system, the first sub-system  may be adapted to develop control information based on a position provided by the second sub-system . In this system, a computation device  may be provided to develop this control information. In other embodiments, this control information may be developed by the second sub-system  and the computation device  can be omitted. Additionally, the IMU  may be operatively coupled to the computation device . The IMU may include, but is not limited to, any of the following components alone or in combination: gyros, accelerometers, magnetometers, global positioning system (GPS), barometer, thermometer, thermocouple, or alpha beta sensor, etc.","The receiver  can be positioned on the vehicle  and can be configured to receive a signal from the second sub-system . The signal may carry control instructions or positional information developed or obtained, respectively, by the second sub-system  and transmitted thereby. The receiver  can thus be configured to filter the control instructions or the positional information from the signal. In the case of control instructions, the receiver  can further be configured to communicate the instructions to the control system . In the case of positional information, the receiver can further be configured to communicate the instructions to the computation device . The receiver may be any known receiver capable of receiving a signal, filtering the signal, and communicating the information carried by the signal to another device. In one embodiment, the receiver  a radio receiver adapted to receive radio wave transmissions with digital or analog information relating to a vehicle's position or control. The computation device  may receive additional measurement information from the IMU .","The control system  can also be positioned on the vehicle  and can be operably connected to the directional controls of the vehicle . The directional controls to which the control system  is connected depend on the type of vehicle  being employed. The control system  may be configured to control the vehicle's motion in one or more dimensions. For example, in the case of an autonomous underwater vehicle, the control system  may be operably connected to the fins, rudder, and propulsion system in order to control the vehicle's depth, lateral position, and forward position in the water. In the case of an unmanned ground vehicle, the control system  may be connected to the accelerator\/decelerator and steering mechanism to control the vehicle's forward position and lateral position over the ground. Furthermore, in the case of an unmanned aerial vehicle, the control system  may be connected to the engine and the flight control surfaces, in order to control the vehicle's altitude, and lateral and forward positions. A control system  may be connected to other types of vehicles in like manners to control such vehicles' motion in one or more dimensions.","In one embodiment, as shown in , the control system  may be connected to the directional control components of a UAV. Such directional control components may include, the elevator , rudder , ailerons , and powerplant  (e.g., reciprocating piston, turbofan, etc.). The control system  may preferably be configured to fully control all aspects of the UAV's directional movement, including controlling full range of motion of the elevator , rudder , and ailerons , and full throttling of the powerplant  from idle to full throttle. The individual mechanized components of such a control system  will be known to and appreciated by those skilled in the art, and may include, for example, actuator\/cable assemblies, servos, hydraulics and air\/fuel mixture regulators, among others.","The first sub-system  may further include a computation device  to compute control instructions for the control system  to use to control the movement of the directional control components of the UAV to cause the UAV to fly in a desired manner. For example, such a computation device  may provide control instructions to the control system  to cause the UAV to fly from a first, known position to a second, desired position through appropriate manipulation of the directional control components. Thus, if the computation device  receives known positional information of the UAV which is, for purposes of illustration, below and to the left of (relative to the direction of flight) a desired position, the computation device  may develop instructions such that the control system  causes the elevator  to deflect upwardly (thereby causing the UAV to gain altitude), the powerplant  to increase output (thereby causing the UAV to maintain adequate airspeed during a climb), the left aileron  to deflect downwardly and the right aileron  to deflect upwardly (thereby causing the UAV to bank to the right), and the rudder  to deflect to the right (thereby counteracting adverse yaw caused by the banking and possibly the induced p-factor in the case of a propeller driven UAV). Such positional information may be augmented\/validated by the measurements made by the IMU  and sent to the computation device . The magnitude of such positional control inputs by the control system  may be determined by the relative distance between the known position and the desired position, among other factors. Further positional information received by the computation device  may cause further changes to the directional control components, again based on the UAV's known position relative to a desired position.","With continued reference to , the first sub-system may further include one or more position indicators  located on the vehicle . A position indicator  may include an element, detail, surface scheme or other indicating feature adapted to mark a point on the vehicle . Any number of position indicators can be provided. Preferably three or more are provided. In the shown, the position indicators  are in the form of three discreet point sources of electromagnetic radiation located at three points on the vehicle . The electromagnetic radiation emitted by these indicators  may include, but is not limited to, radio waves, microwaves, terahertz radiation, infrared radiation, visible light, ultraviolet radiation, X-rays and gamma rays. Point sources of electromagnetic radiation may be generated on the vehicle in any known manner. For example, LED lights may emit point sources of visible light of any color. In some embodiments, a point source may be a reflection of electromagnetic radiation. For example, reflectors or reflective tape may be positioned on the exterior of the vehicle  causing sunlight to be reflected at those points. Or more simply, the point sources may be known, discreet positions along the exterior of the vehicle which reflect sunlight and thereby provide a point source of electromagnetic radiation of visible light in the color of that point on the exterior of the vehicle . In one embodiment, a particular paint pattern can be used to define the point sources. In still another embodiment, reflective paint may be used such as paint with metal flecks or other reflective materials included in the paint. The vehicle  shown in  includes three position indicators  in the form of three point sources of electromagnetic radiation disposed about the exterior of the vehicle, although it will be appreciated that greater than three point sources may also be used.","In one embodiment of the presently disclosed system, the position indicator  can be in the form of an LED-type point sources of a particular wavelength. The point sources can be provided at any position on the exterior of the vehicle . In one embodiment, the point sources can be provided at the greatest possible distances separated from the center of gravity (CG) of the vehicle . For example, as shown in , point sources may be provided on each wingtip, and on the top or bottom side of the vertical stabilizer of the UAV. Alternatively, point sources may be provided on each wingtip, and on the front of the UAV's nose, so as to avoid occlusion of the light source, which may occur depending on the configuration and orientation of the UAV. LED's or other power requiring point sources may be connected to the internal battery or other power source of the vehicle . Alternatively, each point source may have its own power source, e.g., battery.","Referring now to , general reference will now be made to the previously mentioned second sub-system  of the system of the present disclosure. The second sub-system  may include a detection device , a computational device , and a transmitter . The detection device  may be adapted to detect the position and orientation of a vehicle , while the computational device  may be adapted to interpret the information from the detection device  and determine the orientation and position as well as develop control instructions. The positional information and\/or the control instructions can then be transmitted via the transmitter  to the first sub-system .","In one embodiment, the detection device  can be adapted to detect the position indicators  of the first sub-system. In a particular embodiment, the detection device  can be an electromagnetic radiation detection device. In this embodiment, the detection device  can be configured to detect the position of three or more point sources of electromagnetic radiation in two dimensions. The device  may be configured to provide a two dimensional display of the detected position indicators . The two dimensional display may thereby show the detected two-dimensional positions of the detected position indicators  relative to one another. In one embodiment, the detection device  may be a camera configured to detect visible light of a particular wavelength. For example, the camera may be adapted to detect the particular wavelength or range of wavelengths generated by the particular position indicators  provided on the vehicle. More particularly, the camera may be adapted to detect the wavelength generated by LEDs. Alternatively, the camera may be adapted with software or firmware to only detect a particular frequency of flashing light, wherein the light sources may utilize frequency modulation to provide the desired frequency. For example, a camera with a fixed and steady frame rate may be employed of detected light source flashing at a frequency of \u215b, \u2153, \u00bc, \u00bd, etc, the frame rate of the camera.","Referring to , a detection device  is depicted as detecting the electromagnetic radiation from the position indicators  located on the exterior of the vehicle . As shown therein, the vehicle  may generally be localizing toward the detection device  in the direction A, and in this configuration, the position indicators  may generally be detectable (i.e., not obstructed by other parts of the vehicle) by the detection device .","Referring to , a two dimensional display  of the detection device is shown. The image shown on the display  is what may appear from the configuration depicted in . Specifically, position indicators  are depicted on the two-dimensional display  as the detection device  detects their position in two dimensions.  depicts a ghost image of the vehicle  in relation to the detected position indicators . Referring to , the two dimensional display  has been filtered to show only the position indicators  and not the ghost image.","Referring again to , in one embodiment as adapted for use with a UAV, the detection device  may be located at any position, for example, on a tripod, on a capture net, on a moving vehicle, on top of a building, aerial refueling craft, docking space, etc., and at any distance from the flight path (arrow A) of the UAV. Preferably, the detection device  may be located on the ground near a landing area  where the UAV is desired to be landed. The detection device may display the detected location of the radiation in two dimensions. Preferably, the first dimension is the azimuth of the source relative to the horizon, and the second dimension is the altitude of the source relative to the horizon.","Referring again to , the second sub-system  may further include a computer , or other computation device capable of performing mathematical calculations. The computer  may be operably connected to the detection device , and may be configured to receive the two-dimensional display\/data of the positional indicators  generated by the detection device . In particular, a computer  in accordance with the present disclosure may have encoded instructions thereon configured to calculate the two or three dimensional position of the positional indicators  relative to the detection device , based on the two dimensional display  generated by the detection device  and further based on the known configuration of the position indicators  on the vehicle . For example, in the case where the position indicators  are three point sources on the exterior of an autonomous vehicle, the computer  may have information stored thereon related to the position of the point sources on the exterior of the vehicle, and may use that information to calculate the vehicle's two or three dimensional position relative to the detection device  based on the two-dimensional display  of the three point sources generated by the detection device . Such calculation may be accomplished by any known mathematical method, or approximation thereof.","The second sub-system  may further include a transmitter  operably connected to the computer . The transmitter  may be configured to transmit control instructions or position information related to the control or position of the vehicle . The control instructions or position information to be transmitted may be based on the computed two or three dimensional position of the vehicle , as computed from the two-dimensional display  of the position indicators . In particular, control information may be transmitted based on the vehicle's current position in relation to a desired position. The transmitter  may transmit in a manner, for example radio waves, such that the transmission is receivable by the receiver  of the first sub-system , located on the vehicle .","In one embodiment of the presently disclosed system for use with UAVs, as depicted in , a computer  may be operably connected to detection device  to mathematically transform the two dimensional positional information of a UAV into three dimensional positional information (the third dimension being the distance of the UAV from the detection device, or range), using the known positioning of the position indicators  on the UAV. This calculation may be performed using mathematical formulae. Preferably, the calculation is carried out using linear approximations.","A transmitter  operably connected to the computer  may be configured to transmit positional information (arrow B) so as to be receivable by the receiver  (shown in ) of the first sub-system  on the UAV, as previously discussed. Alternatively, the transmitter  may be configured to transmit control information to the receiver . Where control information is to be transmitted, the computer  may use the calculated position of the UAV as compared to the desired position of the UAV to transmit control information to the UAV to cause the UAV to fly toward the desired position (along arrow A), as also discussed above. The instructions here can be the same or similar to those instructions provided by the computation device  described with respect to the first sub-system  for the condition where the first sub-system received only positional information from the second sub-system .","As previously mentioned, the present disclosure relates to systems and methods for automated, feedback-controlled localization of a vehicle to a point in two or three dimensions. A method in accordance with the present disclosure may include detecting the position indicators , displaying the position indicators  on a two-dimensional display, calculating the two or three dimensional position of the vehicle  based on the detected position indicators and on the known configuration of the indicators  on the vehicle, developing control information, transmitting positional or control information to the vehicle based on its calculated position relative to a desired position, receiving the positional or control information, developing control information as required, and adjusting the vehicle controls to cause the vehicle to localize to a point, based on the positional or control information received.","Accordingly, embodiments of the presently described method may be adapted for use with a UAV to cause the UAV to localize to a desired position in three-dimensional space, for example, an autonomous feedback controlled approach to landing. As depicted in , such a method may include, for example, detecting the position indicators  (reference numeral ), displaying in two dimensions the detected positions of the point sources of the UAV on a display (reference numeral ), computing the three-dimensional position of the UAV based on the detected two dimensional position of the point source and further based on the location of the point sources on the exterior of the UAV (reference numeral ), developing control instructions (reference numeral ), transmitting position or control information to the UAV (reference numeral ), and manipulating the directional control components of the UAV to cause the UAV to fly to a desired position (reference numeral ). As noted by the circular nature of the FIG., this process can occur in a looped fashion to repeatedly capture the position of the UAV and repeatedly control its path of flight.","With specific attention to the procedures of the method outlined above, detecting the position indicators  may include capturing a visual image of the vehicle  including the position indicators . The device may provide a two dimensional display  of the detected position of the sources of electromagnetic radiation relative to one another. Providing this display may include portraying the positions on a viewable screen or it may include merely creating an electronic record of the positions of the position indicators  in a two dimensional plane.","Based on these relative positions of the point sources on the two dimensional display, the two or three dimensional position of the vehicle  relative to the detection device  may be calculated. The calculation may include the known position of the position indicators  on the vehicle . A computer, or other computation device,  connected to the detection device  may compute using the two dimensional information generated from the device  with the position indicator  position information to provide a two or three dimensional position of the vehicle  relative to the detection device . The computation may be done by any mathematical technique. Such mathematical techniques may include, for example, a series of two or three linear approximations, for example, Taylor series expansions.","Depending on the nature of the system, the computer  may also calculate control instructions. That is, where the system is set up to provide control instructions to the first sub-system  in lieu of merely positional information, the computer  can further calculate control instructions. This calculation can include a comparison of the position of the vehicle  as compared to the desired position and can further include developing vehicle commands for adjusting the trajectory of the vehicle .","Based on the calculated position of the vehicle  relative to the detection device , a transmitter connected to the computer or computation device  may transmit position or control information to the vehicle . This transmission can occur via radio transmission or other transmission capable of carrying the position or control information. A receiver  on the vehicle  may be configured to receive such position or control information. The receiver  may be operably connected to a control system  on the vehicle , the control system  being capable of controlling all of the directional control components of the vehicle . The vehicle  may use this positional or control information to localize to a desired point or location. In one embodiment, the vehicle  may localize to the position of the detection device .","In the case of positional information being transmitted to the vehicle , the computation device  may determine whether the vehicle  is localizing to the desired point based on the vehicle's change in position over time. If the computation device  determines that the vehicle is proceeding on a path to the desired point, then the system may not implement any directional control changes. If, alternatively, the computation device  determines that the vehicle  is deviating from the localizing course, appropriate directional control changes may be input to the vehicle's directional control components to cause the vehicle  to localize to the desired point or position.","As mentioned above, in the case of control information being transmitted to the vehicle control system, the computer or computation device  of the second sub-system  may first determine whether the vehicle  is properly localizing to the desired point based on its calculated changes in position over time, and then directly transmit directional control information to the vehicle , if needed. Upon receiving such control information, the control system  on the vehicle  may cause directional control changes to be input to the directional control components of the vehicle .","Referring to , in one embodiment of the method of the present disclosure suitable for use with a UAV, the detection device  may be positioned at or near a desired landing area  for the UAV. The computed position of the UAV, based on the detected position of the points sources of electromagnetic radiation and the known configuration of the point sources on the exterior of the UAV, may be used to localize the UAV (along line A) to the position of the detection device , thereby causing the UAV to localize to the landing area  as an approach for landing. Position or control information may be transmitted (via transmitter ) from the detection device \/computer  to cause the control system  on the UAV to manipulate the directional controls of the UAV to maintain a desired approach course (including horizontal (azimuthal) position, glideslope (altitude), and airspeed) to the landing area .","Certain components of the system and method of the present disclosure will now be described in greater detail with regard to preferred embodiments adapted for use with a UAV. As will be appreciated by those of skill in the art, other components may be used interchangeably without departing from the spirit and scope of the disclosure, as set forth in the appended claims\u2014thus, the following example embodiments are not in any way intended to be limiting.","In one embodiment, position indicators  may include point sources in the form of LEDs. LEDs are desirable because they are lightweight, durable, have a high output to power ratio, have a wide viewing angle, and are distinguishable against background noise for purposes of detection. -depict the detected electromagnetic radiation from LEDs positioned on a UAV at a distance of approximately 500 feet, wherein the UAV is oriented, respectively, at 60, 45, 30, and 0 degrees relative to a detection device configured to detect LED light. The left LED in each Figure has a power of 1 Watt, while the right LED in each Figure has a power of 3 Watts, although any Wattage of LED may be used. Desirable wavelengths of electromagnetic radiation (LED light) may be in the approximately 635-808 nanometer range, which is largely distinguishable against sunlight, blue skies, and red sunsets.  shows a graph of relative intensities of background visible light caused by the sky and the sun, which may be used in selecting an appropriate wavelength of LED for use with the teachings of the present disclosure. Other suitable sources of electromagnetic radiation in the visible spectrum may include, but are not limited to, incandescent, fluorescent, arc lamp, and gas discharge lighting.","With regard to the detection device , some embodiments in accordance with the present disclosure may employ a camera sensor. Desirable characteristics of an detection device  may include, but are not limited to, frame rate, resolution, and range of wavelength detection capabilities. For example, the Micron\u00ae MTV9032 camera sensor has been found to be desirable for use in detecting LED light in the approximately 635-808 nanometer range, as discussed above, or more broadly in the approximately 375-900 nanometer range. This particular model has the benefits of a high frame rate (60 frames per second) and a high resolution (2.4 megapixel) to more accurately determine and display the position of the point sources of electromagnetic radiation for subsequent positional calculations. Other camera types and styles can be used. The device may further be configured with a variety of lenses. Appropriate lens selection may be determined by the environment in which the system is being used. For example, some applications may require a long focal length (for example, where detecting the UAV at long distance is desirable); alternatively, some applications may require a wide viewing window or horizon length (for example, where detecting the UAV across a broad range along the horizon is desirable). To determine field of view and focal length, the following equations may be used. With respect to the field of view:",{"@attributes":{"id":"p-0065","num":"0064"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["\u03b8","FOV"]},"mo":"=","mrow":{"mn":"2","mo":["\u2062","\u2062"],"mi":"arctan","mfrac":{"mi":"DesiredHorizonLength","mrow":{"mn":"2","mo":"\u2062","mi":"D"}}}}}},"br":{}},{"@attributes":{"id":"p-0066","num":"0065"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"FocalLength","mo":"=","mfrac":{"mi":"C","mrow":{"mi":"tan","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["\u03b8","FOV"]}}}}}}},"br":{}},"Furthermore, the detection device  may be outfitted with an appropriate light (optical) filter, for example, a band pass filter, to further enable the device to more accurately detect the position of the LEDs, and reduce the background \u201cnoise\u201d which may be particularly prevalent on sunny days. Such an optical filter may be a narrow band pass filter which allows the specific frequency of LED light to pass through while attenuating others. In one embodiment employing 635 nm LEDs, a band pass filter with a 10 nm pass may be used. Preferably, a band pass filter will not attenuate the pass band at all\u2014however, if a sharp attenuation of wavelengths outside the band is desired, a band pass filter which attenuates the pass band up to 60% or more may be used. In alternative embodiments, electromagnetic radiation outside the visible spectrum may be employed to avoid visible light background noise.","With regard to the computer or computation device , as depicted in , the computation device  may comprise a processing board  having included thereon an electromagnetic radiation detector (sensor) port  for receiving information from the electromagnetic radiation detector  through cable , a signal converter  for converting the two dimensional display from the detector into an electronic signal, RAM , a processor  for performing the position and\/or control calculations, a signal converter  for converting the positional or control information into a transmittable signal, memory , a radio controller transmitter port  for communicating positional\/control information, via cable , to the radio controller  and transmitter antenna . In some embodiments, the memory  can be in the form of program memory. Desirable qualities of a computation system may include a high frequency processing rate and large memory capacity, due to the large amount of data being sent from the detection device.","In particular, the Analog Devices\u00ae Blackfin Dual DSP chip (BF561) has been determined to be a suitable computation device for use with the presently disclosed systems and methods. In particular, this device achieves a high computation rate, which aides the speed with which positional or control information may be transmitted to the UAV after detecting the position indicators . Programming of the computation device may be done in any computer language, with VisualDSP++ 4.5 being a preferred language. Using this particular example computation device, the image may be captured by the detection device  and transferred to the processing board  using a parallel data bus running at 27 MHz. The BF561 may read in the frame data through its Parallel Port Interface (PPI), PPIO. The frame data may be transferred via Direct Memory Access (DMA) to Level 3 (L3) SDRAM, which has 64 MB divided into four banks. Core A of the BF561 may handle the PPIO interrupt routine, which simply signals that a frame has been successfully captured. Core A may also handle in its main function, which consists of an infinite loop, the buffering scheme to place input frames into one of two frame buffers.","Using frame buffers in separate memory banks may benefit the processing speed because of the nature of the DMA channels and SDRAM memory access. SDRAM memory access may experience increased latencies if simultaneous DMA transfers are initiated on the same bank. Further, if DMA transfers are initialized on the DMA channels, latencies may increase. In one embodiment, a set of frame buffers for the camera input frames in two separate banks may be employed. Thus, the system may switch back and forth between two input buffers; while one frame is being processed, the next frame may be loaded via the PPI\/DMA channels.","Core A may also perform background subtraction, thresholding, and blob-finding (i.e., locating possible LED \u201cblobs\u201d in the image), as will be discussed in greater detail below. Because of latencies involved in multiple accesses to the same SDRAM bank, data may be transferred from SDRAM to L1 cache via DMA channels in order to process image data faster. The processor can access L1 cache at the system clock speed; therefore, even though it takes some time to transfer data via DMA, performing the processing on L1 cache may be significantly faster. One line (752 pixels) of data may be transferred at a time into L1 cache, using two L1 data buffers when transferring lines via DMA; while one line is being processed, the DMA transfers the next line. The purpose of the buffer, like the input buffers for the entire image frame through the PPI, may be to minimize the wait time by utilizing hardware memory transfers (i.e., DMA) that do not lock up the processor. On each pixel, background subtraction may be performed with a reference frame pixel. The reference frame is updated periodically every few seconds. After background subtraction, a threshold is used to determine which pixels are examined further in the blob-finding routine. The threshold may adjust manually, by noting at what distances we can distinguish LEDs without bleeding from intensities that are too bright in combination with changing the aperture size (thus allowing more or less light into the camera sensor). Alternatively, the threshold may be set automatically to adjust for the aperture size and the threshold used.","In an alternate configuration of a computer or computation device, as depicted in , the computation device  may comprise a PC  having connected thereto the electromagnetic radiation detector (sensor)  through cable . The previously described calculations may be performed using software stored on or accessible by the PC . Such software may comprise an application programming interface (API) which may be exportable to any other PC. Control components, such as radio controller  may also comprise an independent API. The PC  may output information through a cable  to a signal converter box  for converting the information to a form transmittable by the radio controller  and the transmitter antenna . Similar data processing techniques, as discussed above, may also be used in this configuration.","In the embodiment of or , the computation device  may include one or more modules for carrying out the method described with respect to  and more particularly with respect to  below. Accordingly, as shown in , the computation device  can include an image capture module , an image analyzing module , a position calculating module , and a control development module . Each of these modules or components thereof, can include software or a portion thereof, hardware or a portion thereof, or a combination of software and hardware adapted to perform the associated method. It is also noted that each module or component thereof can be combined or overlapped with or combined with modules or components performing other tasks in the process. In some embodiments, this overlap or combination may include tasks or steps adjacent to one another in a process, but in other embodiments, the tasks and steps may not be adjacent one another. Moreover, any module or component thereof may or may not be included in the system depending on the nature of the system desired. Additionally, the computation device  or any module or component thereof can each include an input and output module adapted to receive or send information from or to, respectively, other devices, modules, or components. As such, these input and output modules can include physical ports or connection to a bus where the input or output module is of the hardware type. Other types of input and output hardware can be used. In the case of software based input and output modules, these can include lines of code causing a processor to step or jump from one location to another or an application programming interface, for example. Other types of software based input and output can also be used.","The modules and components thereof can be located within the computation device  in one or more of the locations shown in and for a given configuration. For example, in the case of a module where all or a portion of it is software, the software can be located, for example, in the memory , for being accessed by the processor . In other embodiments, the processor  can include the software. In the case of a module where all or a portion of the module is hardware, for example, the hardware may be a circuit board in communication with the computation device  for access by the processor . Those of skill in the art will understand and appreciate the several configurations available for using software, hardware, or a combination thereof to provide a module.","With regard to the image capture module , this module can be adapted to control the detection device  such that images of the vehicle can be captured. For example, this module can include a shutter control and other controls associated with activating the detection device  to capture an image. The capture module can include an initial detection component that continuously or intermittently activates the detection device to determine whether a vehicle has come into view of the detection device. Upon recognition of a vehicle, the initial detection component may activate the detection device. In the active mode, the detection device may capture images at a certain frequency. To this end, the image capture module may include a timing component that compares an elapsed time since the previous image capture process to a desired period and actuates the detection device when the elapsed time reaches the desired period. In addition, the image capture module can include a shut down component that deactivates the detection device when a vehicle is no longer in range.","With regard to the image analyzing module , this module can be adapted to apply filtering techniques to an image or electronic record thereof. As such, the image filtering module can perform the image processing portion of step  as shown in . More particularly, for example, with regard to , the image filtering module  may include a background subtraction component adapted to adjust the image for background noise as described above and with respect to  below. The image filtering module may also include a threshold image component, a component labeler, a centroid calculating component, and a LED isolator component. Each of these components can include a combination of software and\/or hardware adapted to perform the steps of  as described below.","With regard to the position calculating module , this module can be adapted to determine the position and orientation of a vehicle from the two-dimensional representation of the vehicle received from the detection device  and based on the known configuration of position indicators  on the vehicle. As such, the position calculating module can be configured to perform the method steps described with respect to method step  of  and more particularly, the detailed portions of this step as shown in  described below. As such, the position calculating module  can include an assumption application component, a processing component, and a result component. Each of these components can include a combination of software and\/or hardware adapted to perform the steps depicted in  as described below.","With regard to the control development module , it is first noted that this module can be located within the computation device  in addition to or in an alternative to being located within the computation device . In either or both cases, the control development module can be adapted to compare the calculated position of the vehicle to the desired position of the vehicle and provide vehicle control component commands for controlling the trajectory or direction of travel of the vehicle. In the case of a UAV, these commands can include aileron, rudder, elevator, and power commands. In other embodiments, the control development module  can be adapted to develop commands for corresponding vehicle control components. As such, the control development module  can include a plurality of command components adapted for development of commands particular to a given control component of the vehicle. For example, in the case of a UAV, a command component may be provided for each control component. That is, the module  may include a aileron command component, a rudder command component, and elevator command component, and a power command component. In the case of a ground operated vehicle, these components of the control development module may include a steering command component, a power command component, and a braking component, for example.","With continued reference to the computer or computation device ,  shows a more detailed method of displaying an image , as originally shown in . Having captured the image (), the background subtraction component can subtract the background (that which excludes the detected point sources) () using a reference image or any other known technique. Then, a threshold image component may create a threshold image () from the brightest remaining pixels. The point sources remaining on the image may then be digitally labeled buy a component labeler with their respective two dimensional (x,y) coordinates (). In some embodiments, the centroids of the point sources, if they appear larger than one pixel, may be calculated () by a centroid calculating component. Thereby, the LEDs or other point sources of electromagnetic radiation may be mathematically isolated in coordinate space (), the positions of which may be used to calculate attitude and position (), and transmit such positional information to the control system on the UAV or further perform control instruction calculations ().","With particular reference to procedure () and thus the functionality of the threshold image component, one particular known method of thresholding is the \u201cpeak and valley\u201d method. First, a histogram is taken of the intensity values of the image. Then, the threshold is chosen based on the deepest valley (least frequent intensity) between the two peaks (most occurring intensities) in the histogram. Other known methods include erosion and dilation. With particular reference to procedure () and thus the functionality of the component labeler, labeling may be accomplished in accordance with any known technique, including that described in \u201cA linear-time component-labeling algorithm using contour tracing technique,\u201d by Chang et al. With particular reference to procedure () and thus the functionality of the centroid calculating component, centroids may be calculated according to the following \u201cCenter of Mass\u201d equation:",{"@attributes":{"id":"p-0081","num":"0080"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["X","center"]},"mo":"=","mfrac":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"N"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["x","i"]}},"mi":"N"}}}},"br":{},"b":"44"},{"@attributes":{"id":"p-0082","num":"0081"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["X","center"]},"mo":"=","mfrac":{"mrow":{"msub":[{"mi":["X","max"]},{"mi":["X","min"]}],"mo":"+"},"mn":"2"}}}},"br":{}},"Referring now to , a more detailed chart is shown relating to calculating the position of an object , previously referred to as method step  on . As previously discussed, positional information may be determined based on the detected positions of position indicators , and the position of those position indicators  on the exterior of the vehicle. Such calculation may be made in any manner known to those of skill in the mathematical arts. In some embodiments, the mathematical calculations may comprise linear approximations. As depicted in , such a linear approximation may generally comprise identifying the reference points (), decoupling the points into 3 orthogonal planes () (one for each dimension of movement in space), calculating the angles on the planes, based on the point coordinates and the known configuration of the points on the vehicle (), recombining the three linear dimensional approximations into a three-dimensional orientation and position (), and transmitting such information to a vehicle control algorithm (). This control algorithm may be located in the control system on the vehicle or in the computation device connected to the detection device. The assumption application component of the position calculating module  can allow for decoupling the points into the three orthogonal planes by applying boundary assumptions. The processing component can then calculate the angles on each of the three orthogonal planes, and the results component can recombine the three linear dimensional approximations into a solution defining the three dimensional orientation and position of the vehicle.","With particular regard to calculating the position of a vehicle in procedures - above, some additional information regarding the behavior of a three dimensional object in free space can be provided. The behavior of a 3 dimensional object in free space can often occur about a centralized point and the centralized point is most often the center of mass. Free space can be defined as a medium which is uniformly unrestrictive in all directions such as air, space, water, etc. The motion of an object being limited to motion about a centralized point can allow for decoupling of the objects orientation into three orthogonal planes intersecting at the centralized point or the center of mass as noted in . This can occur through the use of reference points such as point sources associated with the orientation of the object. Where the reference points are not positioned so as to be coaxial to any single axis, the orientation of the object can be determined. This determination can be most accurate when the reference points are further from the center of mass.","In the case of using three reference points, the range of rotations of the object can be more limited and efforts to determine the three dimensional orientation from an arbitrary position will still yield multiple solutions. However, where the variables being used to solve for the position are limited, the solution can be obtained more quickly and without multiple solutions. For example, bounding conditions in the case of an aircraft conducting terminal guidance for landing can be based on the knowledge of the orientation bounds of the aircraft. In the case of three reference points for the aircraft landing scenario, it can be assumed that the aircraft will not exceed +\/\u221290 degrees of yaw in relation to a detection device and further that it will not be inverted on approach. It is noted, however, that even if these bounds are exceeded, there are control methods can be implemented to determine the orientation by observing the behavior of the object in subsequent frames. That is, for example, if the orientation calculation leaves the option for an upright and an inverted orientation and the airplane reacts in a downward direction due to a control command causing the elevator to create upward motion, the aircraft can be then found to be inverted. However, these assumptions regarding yaw and an upright approach allow for solving for the position with a single image rather than images over time. Additionally, it is possible to use more reference points and other methods such as using methods to individually distinguish each marker through frequency modulation or using wavelength filtering.","In cases other than aircraft other assumptions can be made. For example, in the case of an object that is not in free space having a bounded barrier such as an object sitting on the ground, the orientation behavior can be different. This can further simplify the orientation calculation. For example, if the ground surface being encountered is generally flat (e.g., a floor of a building) the orientation can be bounded by the ground or a floor. In these cases a more simplified approach can include breaking the analysis into two orthogonal planes which are orthogonal to the grounding plane thus being simpler than the three orthogonal plane approach noted in .","In the case of any vehicle control situation, one set of assumptions can relate to the dimensions and characteristics of the vehicle being controlled. For example, where reference points are positioned on the vehicle, the reference points can be placed in known positions relative to the center of mass thereby allowing determination of the vehicle orientation based on these reference point locations and orientation. Additionally, in cases where the currently disclosed methods are used in a sensing and avoiding context, for example, the goal may include controlling the behavior of a vehicle where a detection device is positioned on the vehicle. In these circumstances, the detection device may be able to sense or see other objects without knowing their dimensions or characteristics and yet plot a trajectory for the vehicle to avoid the objects.","Accordingly, a linear approximation may comprise a bounded (using boundary assumptions) linear calculation using a Taylor series expansion. As discussed and will be appreciated by those skilled in the art, the minimum number of data points required to approximate the positional orientation, or \u201cpose\u201d, of a three dimensional object that is free to move and rotate in three dimensions and about three axes respectively, is three points. In order to achieve the greatest positional accuracy, these points may be as far from the center of gravity (CG) of the object. In some embodiments, these points can also be coaxial to the axes of rotation. However, in other embodiments the points can be mathematically transformed to points falling on the axes as long as all three do not coexist on a single axis of rotation.","As previously discussed, there are several methods which exist to calculate a three dimensional pose. One computational difficulty that may be encountered is that there is always at least one more unknown variable than there are equations. Using linear approximations to solve for one unknown variably allows the remaining equations to be solved in a traditional manner, thereby evening the number of unknown variables to the number of equations required to be solved.","In order to use such a linear approximation, several mathematical boundary assumptions may be made. Generally, the fewer reference points there are, the more bounded the conditions may need to be for a solution to be available. Additionally, the analysis time can be greater where fewer boundary conditions are known or assumed and the time to determine a solution can be a factor in situations such as landing an aircraft, whereas, other situations such as analyzing a stationary object may not be as concerned with time. In the latter case, multiple images may be used and\/or fewer boundary conditions may be assumed.","As eluded to above, the assumptions can be based on the situation involving landing of a UAV. Alternatively, these assumptions may be applied to the control of any vehicle in two or three dimensions. In the case of an aircraft, three non-collinear reference points are sufficient with the below boundary conditions to determine an orientation and position.","In one embodiment, the assumption application component of the position calculating module can focus the scope of the solution to the linear equations by applying the following assumptions. First, it may be assumed that the airplane will be approaching the detection device  from the front. That is, the UAV can be programmed to approach a landing area from a given direction and the detection device  can be positioned to pickup UAV's as they approach. Second, it may be assumed that the airplane will be oriented right side up with a roll angle less than 90 degrees to either side. This assumption is based on knowledge of the UAV flight capabilities as well as general assumptions regarding their general attitude status as they approach a landing area. Third, it may be assumed that the actual dimensions of the UAV are known as well as the location and distances from the CG of the 3 reference points. This requires that the dimensions and orientations of the position indicators  be placed in particular locations relative to one another and in particular locations relative to the plane and further that this information be input into the computer  or computation device . Fourth, it may be assumed that because the reference points on the wing are close to being co-axial with the CG, then the only transformation that affects their perceived distance is yaw. Reference points may also be mathematically transformed from other positions, not on or near an axis of rotation, to positions on the wing. It is therefore also assumed that airplane pivots about its CG. These assumptions are based on knowledge of general airplane construction and flight behavior. Fifth, it may be assumed that positional angles of the detected position indicators  will be calculated in relation to the display image plane of the detection device, and not in relation to \u201creal world\u201d coordinates. This is due to the fact that the display image plane is not really a plane but a bounded section of a sphere. Therefore, the display image plane changes as the position of the aircraft changes in relation to the camera. It will only change as a two dimensional approximation due to the up, down, left, and right changes of the aircraft, but not forward and backwards.","These assumptions help establish the boundary conditions of the positional calculations and allow for more quickly determining the position of the UAV. Similar assumptions can be made for other vehicles depending on the nature of the vehicle and the conditions within which the vehicle is being used. For example, for a UGV, assumptions relating to the vehicle  being upright and within a certain range of roll angle could be assumed, etc. It is also noted that the assumption application component may or may not be provided depending on the nature of the system. That is, where a particular system is configured for use in a particular application, the system may be loaded with a set of linear equations, or other three dimensional processing analysis, that has already been limited by a list of assumptions similar to those listed above. In this embodiment, the processing component of the position calculating module may be loaded with a bounded set of linear equations, or other bounded three dimensional processing analysis, applicable to a particular application.","Having applied the assumptions, the processing component of the position calculating module can solve the linear equations to determine certain aspects of the three dimensional orientation and position. For example, in computing the position of a UAV in accordance with the present disclosure, the aircraft may first be mathematically \u201cun-yawed\u201d in order to determine the distance between the wingtips as detected by the detector. Once this distance is calculated, the range of the aircraft may be calculated. Then, once the range is known, this variable may be used with the standard linear equations, discussed above, in order to solve for the aircraft position.","In particular, the yaw of the aircraft may be calculated using the following equation:",{"@attributes":{"id":"p-0096","num":"0095"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"Yaw","mo":"=","mrow":{"mrow":[{"msup":{"mi":"tan","mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mfrac":{"mi":"a","mrow":{"mi":"D","mo":"\/","mn":"2"}}},{"msup":{"mi":"sin","mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mfrac":{"mi":"a","mrow":{"msup":{"mi":["D","\u2032"]},"mo":"\/","mn":"2"}}}],"mo":"="}}}},"br":{}},"Then, the range can be calculated using the following equation:",{"@attributes":{"id":"p-0098","num":"0097"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msup":{"mi":["D","\u2032"]},"mo":"=","mrow":{"mi":"focallength","mo":["\u2062","\u00d7"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mfrac":{"mi":["ActualWingspan","Range"]}}}}},"br":{}},"With yaw and range known, the remaining variables to be solved for include roll angle and pitch. Roll angle may be calculated using a trigonometric identity, based on the yaw-corrected wingtip points. Specifically:",{"@attributes":{"id":"p-0100","num":"0099"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"\u03b8","mo":"=","mrow":{"mi":"arctan","mo":"\u2062","mfrac":{"mrow":[{"mi":["\u0394","y"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":["\u0394","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}}}}},"br":{}},{"@attributes":{"id":"p-0101","num":"0100"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"PitchAngle","mo":"=","mrow":{"msup":{"mi":"sin","mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"F"},"msup":{"mi":["D","\u2032"]}}}}}},"br":{}},"The results component of the position calculating module can then combine these results to define the orientation and position of the vehicle. Once the position and orientation of the UAV has been determined using the above described equations and calculation methods, position or control information may be developed and transmitted to the UAV, and the control system on the UAV may make appropriate control inputs to the directional controls of the UAV to achieve or maintain a localizing course to the desired point, for example, the landing area where the detection device has been positioned. This process may be continually repeated and in this manner, a UAV may be autonomously controlled to the point of landing, so as to enable the UAV to be usable for subsequent applications\/missions.","With specific reference now to the directional control system, as embodied in a UAV, one objective may be to achieve and maintain an acceptable glide slope for the UAV descent which will result in a safe and successful approach to landing. In some applications, it may be desirable for the glide slope to be configured so as to allow the UAV to clear a vertical wall of approximately 12 feet at a range of approximately 500 feet. With the assumption that the components of the second sub-system are placed on flat ground, a minimum glides slope of 3.4 degrees is required to safely clear the wall in this manner. However, an excessively steep glide slope may result in a vertical velocity that would cause stress upon the UAV at touchdown. Therefore, a glide slope of approximately between 3.4 degrees to 15 degrees may be desirable, and more particularly a glide slope of 6 degrees may be desirable. In other embodiments, steeper or less steep glide angles can be selected depending on the conditions and surrounding necessary to land the UAV safely and without damage. In some embodiments, the glide angle can be adjusted as the UAV approaches a landing area so as to feather the approach and provide for a softer landing. The glide angle may therefore be configurable to allow for precision landing at any point in front of the detection device and within the detection range of the detection device.","As previously mentioned, there are four control surfaces that exist on the UAV witch determine the UAV's three dimensional trajectory. Referring once again to , the ailerons  on the back of each wing mainly affect the bank angle. Their movements may be tied together, so as the left aileron rotates down the right aileron rotates up at exactly the same rate. Thus, the left aileron  angle may always be the negative of the right aileron  angle with respect to the wing. The elevator  on the back of the horizontal stabilizer mainly affects the UAV's pitch, moving the nose up or down with respect to the UAV's center of gravity. The rudder  on the back of the vertical stabilizer primarily affects the yaw of the UAV. Lastly, the powerplant  affects overall velocity.","The directional control system may comprise four separate parallel closed loop systems, each controlling individual control surfaces of the airplane; ailerons, elevator, rudder, and powerplant. Each system may have both inner and outer loop components running in parallel which are then output to the control surface as a weighted sum. This approach to controlling the UAV flight may optimize control for optical sensing.","More particularly, aileron controls may be a weighted summation of bank error based on a constant desired bank of zero degrees, horizontal velocity on the display image plane displacement, and an integration of desired bank error. Elevator controls may be based on a desired pitch of the UAV relative to the radial position vector from the center of the image plane to the normal plane of the aircraft. This may give result in pitch that varies the true pitch of the aircraft with vertical position on the display image plane. Rudder controls may also be a weighted summation of the following components: the UAV's yaw relative to the radial position vector from the center of the display image plane to the normal plane of the UAV, the integration of the yaw error, and the product of the horizontal velocity vector in the image plane with the aircraft horizontal displacement in the image plane and the calculated aircraft range. Throttle controls may be a weighted sum of the vertical displacement of the UAV in the image plane and the vertical velocity of the aircraft in the image plane. Other directional control algorithms are known in the art, and may be employed in connection with the directional control system in alternative embodiments.","Referring again to and , a control stick  may be operably connected to the computer or computation device . A control stick  may be required where remote manual operation of the UAV is desired during certain portions of flight. The control stick  motions may be electronically sent to the computer or computation device , indicating desired control changes in the UAV. Alternatively, during autonomous control, the computer or computation device  may generate its own control or position instructions\/information, as previously discussed. The computer or computation device  may be operably connected to a transmitter  in a manner, for example, as shown in greater detail in -. The transmitter  transmits a radio or other electronic signal  comprising the aforementioned position or control information. Such information in the signal  is receivable by a receiver  located in the first sub-system  of the UAV. The receiver  may be operably connected to the directional control system  of the UAV, which may comprise, for example, various actuator\/cable assemblies, servos, hydraulics and air\/fuel mixture regulators, among others.","In one particular embodiment, the transmitter  may be a Futaba 6EX-PCM radio system. Such system is a 72 MHz radio system that uses Pulse Code Modulation. It sends information via a binary coded signal (the bit length being determined by the number of channels) to the receiver , followed by a 16 bit checksum. Pulse Code modulation may be desirable as the form of transmission because it is less prone to signal noise or error, although it will be appreciated that any form of transmission may be used in accordance with the present disclosure.","As will be appreciated by those skilled in the art, closed-loop feedback control systems may have an inherent latency between detection and response. Such latency may cause instability in the system. In selecting the particular components of the system as shown in  for use with a particular application, the following considerations may be taken into account which may reduce latency. 1) Employing Pulse Position Modulation transmissions as opposed to Pulse Coded Modulation; 2) using fewer channels; 3) using digital servos; or 4) using a 2.4 GHz spread spectrum radio (e.g., a Futuba 2.4 GHz spread spectrum radio system).","With continued reference to the directional control system , in order to control the control component positions, e.g. servo positions, on the UAV (which subsequently control the UAV's movements through the ailerons, elevator, rudder, and throttle), a Futaba-specific Pulse Position Modulated (PPM) signal may be sent through the trainer port of our Futaba radio transmitter (or other similar signal in embodiments not using Futuba radio systems). The PPM signal may be an approximately 0 to 5 Volt digital signal with the following format: 1) An approximately 9 ms high synchronizing pulse. 2) A low pulse lasting for approximately 400 \u03bcs. 3) Up to 8 channels with the following format: a high pulse lasting approximately from 0.680 ms to 1.52 ms, with approximately 1.12 ms being at a neutral position, indicating the servo position of that particular channel, followed by a low pulse of 400 \u03bcs. A timer interrupt with a period of 10 \u03bcs may be used to output the desired PPM signal through a output pin on the BF561 (or similar component of embodiments using a computation device other than the BF561). If any signal noise is experienced during such transmissions, shielded wires or copper foil may be employed on the electrical components of the system in order to mitigate such noise.","Although the present disclosure has been described with reference to various embodiments, persons skilled in the art will recognize that changes may be made in form and detail without departing from the spirit and scope of the invention. The techniques of this disclosure may be embodied in a wide variety of devices or apparatuses. Any components, modules, or units have been described to emphasize functional aspects and does not necessarily require realization by different hardware units, etc.","Accordingly, the techniques embodied\/described herein may be implemented in hardware, software, firmware, or any combination thereof. Any features described as modules or components may be implemented together in an integrated logic device or separately as discrete but interoperable logic devices. If implemented in software, the techniques may be realized at least in part by a computer-readable medium comprising instructions that, when executed, performs one or more of the methods described herein. The computer-readable medium may comprise random access memory (RAM) such as synchronous dynamic random access memory (SDRAM), read-only memory (ROM), non-volatile random access memory (NVRAM), electrically erasable programmable read-only memory (EEPROM), FLASH memory, magnetic or optical data storage media, and the like.","If implemented in software, the software code may be initially stored on a computer readable medium, and may be executed by one or more processors, such as one or more digital signal processors (DSPs), general purpose microprocessors, an application specific integrated circuits (ASICs), field programmable logic arrays (FPGAs), or other equivalent integrated or discrete logic circuitry. The term \u201cprocessor,\u201d as used herein may refer to any of the foregoing structure or any other structure suitable for implementation of the techniques described herein. In addition, in some aspects, the functionality described herein may be provided within dedicated software modules or hardware modules configured for encoding and decoding, or incorporated in a combined video codec. Also, the techniques could be fully implemented in one or more circuits or logic elements.","Many other aspects of this disclosure will become apparent from the teaching below. Nothing in this disclosure should be construed as any admission regarding prior art or known systems. Any discussion of background material is provided for context, and does not necessarily mean that such background material was known, or that problems akin to background material were known."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE FIGURES","p":["While the specification concludes with claims particularly pointing out and distinctly claiming the subject matter that is regarded as forming the various embodiments of the present disclosure, it is believed that the embodiments will be better understood from the following description taken in conjunction with the accompanying Figures.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 3","FIG. 2","FIG. 2"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 4","FIG. 2"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 5","FIG. 2"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 6","FIG. 2"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 7","FIG. 2"]},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 8","FIG. 2"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 10","FIG. 2"],"i":["a","d "],"b":"10"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 12","FIG. 2"],"i":"a "},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 12","FIG. 2"],"i":"b "},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 12","i":"c "},{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 13","FIG. 9"]},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 14","FIG. 9"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 15","FIG. 2"]}]},"DETDESC":[{},{}]}
