---
title: Methods and apparatuses to reduce context switching during data transmission and reception in a multi-processor device
abstract: A method and apparatus are provided for efficiently transferring data between a first and second processors having shared memory. A plurality of data packets are aggregated into a packet bundle at the first processor. The packet bundle is then transferred from the first processor to the second processor using the shared memory, wherein the transfer of the packet bundle is performed in a single context switch at the first processor. The packet bundle is then unbundled into individual data packets at the second processor, wherein a processing load of the second processor is reduced due to the aggregation of the data packets into the packet bundle by the first processor.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08588253&OS=08588253&RS=08588253
owner: QUALCOMM Incorporated
number: 08588253
owner_city: San Diego
owner_country: US
publication_date: 20090625
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CLAIM OF PRIORITY","FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["As provided in 35 U.S.C. \u00a7119, this application claims priority to Provisional Application No. 61\/076,088 entitled METHODS AND APPARATUSES TO REDUCE CONTEXT SWITCHING DURING DATA NETWORKING IN DUAL PROCESSOR ACCESS TERMINALS filed on Jun. 26, 2008 and assigned to the assignee of this application, the contents of which is incorporated by reference into this document.","One feature relates to communication systems, and more particularly, to a method for reducing context switching and interruptions of processors during data transfer between two or more processors.","As consumers seek every more mobile technologies and convenience, more content and services are being delivered to mobile and\/or compact devices. At the same time, access terminals, such as mobile phones, are ever smaller or compact in size to allow users to conveniently carry them anywhere they go. Due to their small size, the access terminals often have limited processing capabilities and\/or power source (e.g., batteries). A trade-off is often made between processing performance and battery life. More powerful processors consume more power, thereby shortening the life of the battery between charging. However, less powerful processors may not provide sufficient processing power needed for newer applications. For example, with the advent of third generation (3G) and fourth generation (4G) telecommunication standards based on the International Telecommunication Union (ITU), high speed data applications (e.g., internet access, voice over IP, video delivery, etc.) are being implemented for wireless networks. The higher data rates provided by 3G and 4G networks place increasing pressure on processor cores with limited clock rate to support these higher data rates. For handset manufacturers and other original equipment (OEMs) manufacturers that incorporate wireless communication chips and chip sets, these factors lead to added pressure to support the high speed data applications by using off-the-shelf (OTS) commercial mobile operating systems, such as, Windows Mobile, Linux, or Symbian. Unfortunately, such mobile operating systems frequently consume significant processing time in switching contexts, presenting a major hurdle for efficiently supporting next generation high data rates, especially for layered software architectures required by OTS mobile operating systems. Moreover, mobile device hardware typically attempts to reduce the clock rate of the processor core in an effort to conserve or otherwise minimize power consumption.","Consequently, techniques are needed to reduce power consumption of limited clock rate processors without sacrificing processing performance for higher data rates.","The following presents a simplified summary of one or more embodiments in order to provide a basic understanding of some embodiments. This summary is not an extensive overview of all contemplated embodiments, and is intended to neither identify key or critical elements of all embodiments nor delineate the scope of any or all embodiments. Its sole purpose is to present some concepts of one or more embodiments in a simplified form as a prelude to the more detailed description that is presented later.","According to one feature, a method operational in a first processor is provided for transferring data to a second processor. Data packets may be aggregated into a packet bundle by the first processor. The first processor may then process the packet bundle in a single context switch when transferring the packet bundle to the second processor via a shared memory, where a processing load of the first processor is reduced due to the aggregation of the data packets into the packet bundle. Additionally, the processing load of the second processor may also be reduced due to the aggregation of the data packets into the packet bundle. Aggregating data packets into the packet bundle may also reduce context switching at the second processor. Context switch may include the interleaved sharing of a processing resource by multiple functions. Context switching at the first processor may be reduced by virtue of aggregating the data packets into a packet bundle so that fewer data transfer operations are performed by the first processor for the same amount of data packets.","The packet bundle may be transferred to the second processor upon the occurrence of one or more triggers. For example, the one or more triggers may include at least one of: (a) a timeout trigger based on a maximum amount time between successive transfers of packet bundles from the first processor to the second processor; (b) a queue level trigger based on a size for a transmit queue where the data packets are aggregated into the packet bundle; (c) a buffer usage trigger based on the usage of a transfer buffer within the shared memory used to transfer the packet bundle between the first processor and second processor; (d) a load trigger based on the load for the second processor; or (e) a minimum data rate trigger based on a data rate at which the second processor transmits information over a wireless network.","The first processor may implement functions across multiple layers and performs context switching between the functions. The functions may include a function driver and an interconnect driver that transfer data between each other via a transmit queue and a receive queue. In one example, the interconnect driver may control the aggregation of the data packets in the transmit queue and schedules the transfer of the packet bundle to the second processor. In an alternative example, the function driver may control the aggregation of data packets in the transmit queue and schedules the transfer of the packet bundle to the second processor.","According to one feature, a method operational in a first processor for receiving data transfers from a second processor. The first processor may receive an interrupt indicating that the data bundle is being transferred from the second processor. The packet bundle is then obtained from the second processor via a shared memory in a single context switch, wherein the packet bundle includes aggregated data packets. The first processor may then unbundle the packet bundle into a plurality of data packets, wherein a processing load of the first processor is reduced due to the aggregation of the data packets into the packet bundle by the second processor. The processing load of the second processor may also be reduced due to the aggregation of the data packets into the packet bundle. The first processor may implement functions across multiple layers and may perform context switching between the functions. Such functions may include a function driver and a interconnect driver that transfer data between each other via a transmit queue and a receive queue.","An access terminal is also provided comprising a first processor and a second processor and adapted to transfer data from the first processor to the second processor. A plurality of data packets may be aggregated into a packet bundle at the first processor. The packet bundle is then transferred from the first processor to the second processor using a shared memory, wherein the transfer of the packet bundle is performed in a single context switch at the first processor. The second processor may receive an interrupt indicating that the packet bundle is being transferred from the first processor, wherein the number of interrupts at the second processor is reduced due to the aggregation of the data packets at the first processor. The packet bundle may the be unbundled into individual data packets at the second processor, wherein a processing load of the second processor is reduced due to the aggregation of the data packets into the packet bundle by the first processor. The first processor and second processors may each implements functions across multiple layers, where the functions at each of the first and second processors may include a function driver and an interconnect driver that transfer data between each other via a transmit queue and a receive queue.","Similarly, a second plurality of data packets may be aggregated into a second packet bundle at the second processor. The second processor then transfers the second packet bundle to the first processor using the shared memory, wherein the transfer of the packet bundle is performed in a single context switch at the second processor. The first processor then unbundles the second packet bundle into individual data packets, wherein a processing load of the first processor is reduced due to the aggregation of the data packets into the second packet bundle by the second processor.","In one example, the first processor may be an application processor and the second processor may be a modem processor, both processors operating within a wireless communication device. Alternatively, the second processor may be an application processor and the first processor may be a modem processor, both processors operating within a wireless communication device.","In the following description, specific details are given to provide a thorough understanding of the embodiments. However, it will be understood by one of ordinary skill in the art that the embodiments may be practiced without these specific details. For example, circuits may be shown in block diagrams, or not be shown at all, in order not to obscure the embodiments in unnecessary detail. In other instances, well-known circuits, structures and techniques may not be shown in detail in order not to obscure the embodiments.","As used herein, the term \u201caccess terminal\u201d may refer to, but is not limited to, a mobile phone, a cellular phone, a communication device, a wireless device, a satellite radio, a personal digital assistant, a laptop, and\/or a palm-held computing device having wireless communication capabilities. The term \u201cdata\u201d refers to all types of information and\/or content that may be transmitted between processor or through a network.","Overview","One feature provides a data aggregation scheme for reducing interrupts and\/or context switching when transferring data between a first processor and a second processor on the same device. The first processor aggregates or accumulates data packets into a packet bundle to be transferred to the second processor. The aggregated data packets are then transferred from the first processor to the second processor in a single context switch and based at least in part on one or more triggers. A shared memory or transfer buffer accessible to both the first processor and second processor may be used to transfer the aggregated data packets. The second processor receives an interrupt indicating that data is being transferred from the first processor. By aggregating the data packets at the first processor, the number of context switches at the first and\/or second processors is reduced. The aggregated data packets may then be unbundled at the second processor and sent along to a higher application layer or for transmission over a wireless network or tethered device.","The data aggregation may be performed to match channel characteristics of a communication channel (e.g., transmission channel for a wireless network) and to effectively reduce context switches, thereby improving (reducing) processor utilization and increasing processor idle time. Intelligent scheduling of aggregated data transfer between the first and second processors may be based on calculations of low and high queue levels in a queue used for the data transfer. These related queue levels may be adjusted for differing network data rates. A timeout timer may also be utilized to guarantee transfer of aggregated data packets within a predefined period of time. Additionally, other triggers may be utilized to determine when aggregated data should be transferred. For example, a buffer usage trigger may be used, where the buffer usage trigger is based on the usage or capacity of a transfer buffer utilized to transfer the aggregated data between the first processor and second processor. Similarly, a load trigger may also be used, where the load trigger may be based on the processing load for the second processor. In another example, a minimum data rate trigger based on a data rate at which the second processor transmits information over a wireless network.","Communication System",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 1","b":["100","104","110","108","108","108"]},"One or more access terminals AT-A , AT-B , and AT-C  may obtain service and\/or communicate over the serving network  via the access points AP-A  and AP-B . Although just three access terminals AT-A , AT-B , and AT-C  are depicted, it is to be appreciated that the communication network system  may service any number of access terminals. According to various implementations, the serving network may support high data rate services to\/from the access terminals AT-A , AT-B , and AT-C . In one example, the access terminal AT-A , AT-B , and AT-C  may include a rechargeable power source (e.g., battery) and is adapted to perform one or more techniques to reduce context switching, thereby increasing idle time for one or more processors and conserving battery power.","Note that a communication link or channel from an access point to an access terminal is often referred to as a forward link or downlink. A communication link or channel from an access terminal to an access point may be referred as a reverse link or the uplink.",{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 2","b":["202","204","216","204","206","208","218","220","210","216","206"]},"The processing circuit , modem processor , and transceiver  may form a transmit chain and\/or a receive chain that operates to process, transmit and\/or receive one or more concurrent or serial data streams to and\/or from the access terminal . In one example, each data stream may be transmitted over a respective transmit antenna. For data to be transmitted, the modem processor  may modulate the data by formatting, coding, and\/or interleaving the traffic data for each data stream based on a particular coding scheme selected for that data stream to provide coded data. Similarly, for received data, the modem processor  may demodulate the data by de-interleaving, decoding, and\/or extracting the traffic data for each data stream based on the particular coding scheme being used. At the transceiver , the transmitter module  may processes a data stream to provide one or more analog signals and may further condition (e.g., amplify, filter, and\/or up convert) the analog signals to provide a modulated signal suitable for transmission over the antenna . Similarly, the receiver module  may receive modulated signals from the antenna  and may condition (e.g., filter, amplify, and\/or downconvert) a received signal, digitizes the conditioned signal to provide samples, and further processes the samples to provide a corresponding received data stream.","The processing circuit  may also be coupled to a memory device  and one or more input\/output interfaces . The memory device  may serve to store information, data, and\/or applications that are executed by the processing circuit . In an optional implementation, the memory device  may be optionally coupled to the modem processor  and serve as a transfer buffer between the application processor and the modem processor. The input\/output interfaces  may include a display screen, a microphone, a speaker, a keypad, a touch screen, among other interfaces. Note that in other implementations, the processing circuit , the application processor , and\/or the modem processor may be coupled to a common data bus.","In one example, the modem processor  and the application processor  may reside on the same circuit or board of the access terminal . In another example, the modem processor  and application process  may be on separate circuit boards. For instance, the modem processor  may be part of an independent or removable communication card that plugs into the access terminal . Moreover, each of the modem processor  and\/or application processor  may be implemented as one or multiple processors.","According to some features, the access terminal  may be adapted to comply with 3G and\/or 4 G communication standards that use high speed data access technologies. However, the processing circuit  (or application processor ) and\/or the modem processor  may have a limited clock rates relative to the processing overhead required to reach the high data rates of 3G and\/or 4 G communications.","The processing circuit  and\/or application processor  may execute a commercial mobile operating system, such as, Windows Mobile, Linux, or Symbian. Such operating systems frequently consume significant processing time in context switching, presenting a major hurdle for efficiently supporting next generation high data rates, especially for layered software architectures used by many mobile operating systems.","The term \u201ccontext switching\u201d refers to the computing process of storing and restoring the state (context) of a processor such that multiple processes can share a single processor resource. The context switch may be employed by a multitasking operating system to perform multiple operations in seemingly concurrent basis by sharing or interleaving a processing resource. Context switches are usually computationally intensive and much of the design of operating systems is to optimize the use of context switches. According to various examples, a context switch can mean a register context switch, a thread context switch, and\/or a process\/function context switch. What constitutes the context may be determined by the processor and\/or the operating system being used.","In order to achieve the highest performance in the most energy efficient manner possible, the access terminal may be adapted to reduce the clock rate and\/or decrease the idle cycle of the processing circuit  (or application processor ) and\/or the modem processor  so as to conserve power or otherwise minimize battery consumption.","Data Aggregation Example","According to one feature, data aggregation may be employed within a processor to match channel characteristics of a communication channel and to effectively reduce context switches, thereby improving (reducing) processor utilization and increasing processor idle time.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 3","b":["300","302","304","300","302","304","348","302","304","306","302","308","310"]},"The first processor  may include or implement a function driver , an unbundling module , a transmit (Tx) queue , a receive (Rx) queue , and\/or an interconnect driver . The function driver  may include or implement an unbundling module . The interconnect driver  may include or implement a timer , a data aggregation module , and\/or an intelligent scheduler ","The second processor  may include or implement a function driver , a transmit (Tx) queue , a receive (Rx) queue , and\/or interconnect driver , an operating system networking stack , and\/or one or more applications . The function driver  may include or implement an unbundling module . The interconnect driver  may include or implement a data aggregation module , intelligent scheduler , and\/or a timer .","The elements and\/or modules illustrated for the first processor  and second processor  may be functional components operating within each processor and\/or may be combined with other components. In one example, the transfer buffer  may be a shared memory space or device accessible by the first and second processors  and . In some examples, the first and\/or second processors  and  may include internal memory in which the TX queue and RX queue are implemented. In other implementations, the TX queues and RX queues may be implemented in a shared memory (e.g., either the same memory space in a shared memory device or different memory spaces in the memory device). In one example, the transfer buffer  may implement the TX queues and RX queues for both the first and second processors  and  such that the first processor transmits aggregated data packets into the same memory space from which the second processor reads the aggregated data packets when notified by the first processor.","For data received on the forward link or downlink (i.e., data received at the access terminal), the data is received via the antenna  and collected at radio stack . The function driver  of the first processor  then transfers the data from the radio stack  into the Tx queue . The data aggregation module  and intelligent scheduler  selectively transfer bundled or aggregated data packets (also referred to as packet bundles) from the Tx queue  to the transfer buffer  based on one more factors or parameters. These factors or parameters may include, but are not limited to, a timeout value of timer , size of the Tx queue , one or more Tx queue levels (e.g., where a \u201clevel\u201d may be defined as a certain amount of data contained in the queue, measured in bytes, packets, or other units pertinent to the data transfer type), size of the transfer buffer , one or more indicators of the data rates expected from the radio stack , a processor load indicator (e.g., load of the second processor ), or a combination thereof. When the intelligent scheduler  determines that data is to be read from the Tx queue  and written to the transfer buffer , a read operation (from the Tx queue ) and a write operation (to the transmit buffer ) are performed, and an interrupt to the second processor  is generated. The interconnect driver , when responding to the interrupt, reads the aggregated data packets from the transfer buffer  and writes the data into Rx queue . The function driver  then reads the data packets from the Rx queue  and the unbundling module  separates the bundled packets into individual packets for sending to the upper layers (e.g., eventually to the application ).","Note that, in this example, an interrupt signaling path or mechanism  may be present between the first and second processors  and . In other implementations, different techniques may be implemented to a processor when to read data from the transfer buffer .","Similarly, for data to be transmitted on the reverse link or the uplink (i.e., data to be transmitted from an access terminal to an access point or base station), the data is received from upper layers (e.g., the application ) is written into the Tx queue . The data aggregation module  and the intelligent scheduler  selectively transfer bundled or aggregated data packets from the Tx queue  to the transfer buffer  based on one more factors or parameters. These factors or parameters may include, but are not limited to, a timeout value of the timer , size of the Tx queue , one or more Tx queue levels, size of the transfer buffer , a load indicator (e.g., load of the first processor ), one or more indicators of the data rates expected from the application , or a combination thereof. When the intelligent scheduler  determines that data is to be read from the Tx queue  and written to the transfer buffer , a read operation and a write operation are performed, and an interrupt to the first processor  is generated. The interconnect driver , when responding to the interrupt, reads the aggregated data packets from the transfer buffer  and writes the data into Rx queue . The function driver  then reads the data packets from the Rx queue  and the unbundling module  separates the bundled packets into individual packets for sending to the radio stack .","According to one feature, data may be aggregated at the Tx queue ( or ) for transfer between the two processors  and . That is, rather than sending each data packet as it arrives in the Tx queue ( or ), the intelligent scheduler ( and\/or ) causes the Tx queue ( or ) to accumulate data packets until a sufficiently large number of packets are accumulated. The accumulated data packets are then grouped or bundled as a single packet for transfer to the transfer buffer .","According to one example, the intelligent scheduler ( or ) may utilize low and high queue levels to determine when data transfer should be transferred. These watermark queue levels may be adjusted for differing 3G data rates or 4G data rates. The low and high queue levels may be used to determine when data packets accumulated in the Tx queue (\/) can be transferred to the transfer buffer . For instance, the low queue level may indicate a minimum amount of data that should be kept in the Tx queue (\/) while the high queue level may indicate a maximum amount of data that should be kept in the Tx queue.","Additionally, a timer ( or ) may also be utilized to facilitate aggregation of data prior to transfer between contexts. A maximum timeout value (as tracked by the timer  or ) may be utilized so that data is not kept for a long time in the Tx queue \/. In one example, the timeout value (tracked by the timer \/) may be empirically determined or tuned by locating an inflection point on a graph that plots timer timeout value versus achieved data throughput. In one case, a peak value of throughput is used to obtain an optimum timeout value, which leads to an improved processor idle time performance (e.g., for first processor  and\/or second processor  in a dual processor architecture).",{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 4","b":["402","402","404","404","404"],"ul":{"@attributes":{"id":"ul0001","list-style":"none"},"li":{"@attributes":{"id":"ul0001-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0002","list-style":"none"},"li":["(a) a timeout trigger based on a maximum amount time between successive transfers of packet bundles from a first processor to a second processor;","(b) a queue level trigger based on a size for the transmit queue  (i.e., the queue in which the data packets are aggregated into the packet bundle);","(c) a buffer usage trigger based on the usage or capacity of a transfer buffer (i.e., buffer  in ) within the shared memory used to transfer the packet bundle between the first processor and second processor;","(d) a load trigger based on the processing load for the second processor (i.e., the processor to which the packet bundle is being sent); and\/or","(e) a minimum data rate trigger based on a data rate at which the second processor transmits information over a wireless network."]}}}},"The packet bundle  is then transferred to a receive queue  in a single context switch. That is, rather than utilizing multiple context switches to transfer each individual data packet, the data packets are grouped (e.g., by a low-level function such as the function driver or interconnect driver) as a packet bundle  and a single context switch is utilized by the transmitting processor to transmit the packet bundle  and a single context switch is utilized by the receiving processor to receive the packet bundle . The packet bundle  is received in a receive queue  and the packet bundle is the unbundled to extract the individual data packets . Note that even though it may take some operations to bundle and\/or unbundled the data packets, such operations may be performed without additional context switches (or using fewer context switches), therefore making the transfer more efficient.","In one example, the \u201cbundling\u201d of data packets may merely involve transferring the individual data packets together or as a group (in a single context switch) with appropriate pointers to each data packet so that a receiving processor can read the data packets. In other implementations, the aggregated data packets may be encapsulated into a larger packet with some overhead data to identify its content.","Many mobile operating systems impose software architectures that necessitate context switching between OEM driver layers and the native operating system components, which inherently adds processing overhead to data networking functionality and may limit the opportunity to eliminate context switching requirements or optimize the overall code path. Furthermore, when the operating systems of the first processor  and second processor  differ, additional steps to reconcile the different operating system interfaces may be required to implement the data networking functionality, thereby adding further processor overhead. However, the data aggregation techniques described herein help to minimize expensive context switches on for such operating systems. That is, the intelligent scheduling of data transfers of multiple packets concurrently between the first processor  and the second processor . In another aspect, the intelligent scheduler may transfer multiple packets concurrently between a first process, thread or context and a second process, thread or context. The intelligent scheduler as described herein reduces the number of context switches needed to transfer the same amount of data between processors or processes, thereby improving processor performance and reducing overhead.","Queue Levels and Timeout Timer Operation","Referring to , according to one example of the operation of the intelligent scheduler (\/), queue levels (e.g., High Level and Low Level in ) and a timeout timer may be utilized to determine when data packets accumulated in the Tx queue (\/) should be moved to the transfer buffer . For example, the data aggregation module  may write a bundled aggregation of multiple packet data units to the transfer buffer . A timer (\/) is employed to account for and handle low size data exchanges (e.g., data for call set up) by triggering the writing process even when a triggering aggregate queue level (e.g., high queue level) has not yet been achieved. The timer (\/) may also ensure that any maximum latency requirements are met and that data flows between the first processor  and the second processor  in a manner that conforms to those latency requirements.",{"@attributes":{"id":"p-0055","num":"0059"},"figref":"FIG. 5","b":["502","504","506"]},"In one embodiment, when a first packet data unit (PDU) comes in to the Tx queue, a timer is started  which has an associated timeout value. Data is accumulated or aggregated or stacked in the Tx queue . It is noted that in this embodiment, aggregated data may be transferred between processes (or processors) rather than sending a single packet data unit (e.g., a single data packet) to the upper (next) layers one packet data unit at a time. The timeout value can be configured by a formula based on the queue depth and the consideration to avoid congestion or overloading the network side elements since once full, the queue contents may be transmitted before flow control can be applied.","In one example, the transmit queue size may be equal to a maximum data rate (bps) divided by timer timeout value(s). In another example, since data rates may vary over time, the transmit queue size may be larger than an average data rate for the maximum link speed. However, since memory is often limited on access terminals, the following steps may accommodate the memory limitation. In one aspect, the timer is configured for a very short duration (e.g., on the order of about 1 msec to about 255 msec), and the processor idle time and throughput are measured for various values of the timer timeout. An optimal tradeoff of latency (the timer timeout) versus reduced processor usage while attaining the maximum supported throughput may determine the ideal value of the timeout value.","In some cases, processor idle time may increase, but the throughput rate may decrease after the timer reaches a certain threshold that can be determined empirically, for example, by a characteristic process in which the timer threshold value is varied and the corresponding throughput measured. In this regard, the stacking or aggregation of data packets are suited for short bursts of data, especially for data protocols, such as TCP, which maintain state information and have provision for providing feedback corresponding to data sent and received. In one embodiment, the stacking of data packets for a time period or duration in the order of milliseconds achieves improvement in processor utilization, thereby resulting in an improvement in processor idle time. One consideration is that the timeout value be configured so that it is smaller than a minimum timeout value that the communication protocol specifies in order to avoid timeout issues that could result from data stacking for low size data exchanges (e.g., during connection setup) as described in greater detail hereinafter. Another consideration is that end-to-end latency requirements may influence selection of the timeout value such that the timeout value is relatively insignificant to the total latency.","When either the timer has reached the timeout value, or a high queue level is reached , but before the queue is completely full (e.g., a predefined percentage of being filled, such as 80% of queue is full), the aggregated data can be transferred from the transmit queue to another processor . For instance, aggregated data may be transferred to a transfer buffer from where it is retrieved by another processor and subsequently provided to the upper layers on the other processor, possibly in aggregated form. It is noted that the queue levels and timer values can be configured or adjusted differently in order to achieve an optimum configuration to suit a particular communication standard or specific communication technology. It is further noted that this process can be repeated, and one or more of the different parameters of factors (e.g., timeout values, queue levels, and processor loading indicators) can be customized for different communication technologies that may have different data rates.","Reducing Interrupts in Dual Processor Architectures","Note that the data packet aggregation scheme described herein reduces interrupts in dual processor architectures, thereby improving the efficiency of such processors.","In one configuration, a first processor may transfer data to a second processor via an intermediate transfer buffer or shared memory device. In a prior art approach, the first processor may write data to the transfer buffer one packet at a time. For example, when there is a data packet in the transmit queue of the first processor, an interconnect driver reads the data packet from the transmit queue and then writes that data packet to the transfer buffer. A hard interrupt is generated for the second processor whenever data is written to the transfer buffer by the interconnect driver of the first processor. Accordingly, this approach has the undesirable characteristic of decreasing the efficiency of the second processor as an interrupt is generated for each packet placed in the transfer buffer, no matter how small the packet. Similarly, when there is data to be transferred from the second processor to the first processor, the efficiency of the first processor is decreased since the interconnect driver executed on the second processor interrupts the first processor whenever it writes data to the transfer buffer.","In order to improve the transfer of packets between the first and second processors, data aggregation is employed. As previously described, data packets are aggregated by the sending processor based on one or more factors and then the aggregated data (i.e., more than one data packet at a time) is written to the transfer buffer, thereby reducing the number of interrupts to the receiving processor. For instance, if this aggregated data transfer technique is employed for transfer of data from a first processor to a second processor, the number of interrupts to the second processor is reduced, thereby increasing efficiency of the second processor.","Reducing Context Switching","Context switching occurs when a processor suspends or stops a process or thread in order to perform operations for another process or thread. For example, in  context switching may occur between Context , and Context , between Context  and Context , and between Context  and Context  as received data is passed from the interconnect driver to the application. Note that context switching, such as switching between different processes or threads that are executing on a processor, incur overhead thereby increasing latency of the processor. Therefore, it is advantageous to reduce context switching when possible but without introducing unacceptable delay.","As described above, data aggregation may serve to bundle or group a plurality of data packets into a single packet for purposes of transmission from one processor to another processor. That is, rather than sending individual data packets from one processor to another processor across a boundary (i.e., thereby causing multiple context switches and\/or interrupts), the aggregated data packets are sent together (thereby triggering just one context switch or interrupt). In this manner, bundles of data are transferred between entities as aggregated data packets requiring or utilizing a single context switch instead of transferring individual data packets in a plurality of context switches. Stated differently, the number of context switches used to transfer a fixed amount of data is reduced by the data aggregation technique described herein.","In an alternative approach, another manner in which to reduce context switching is to implement a hold-off signaling mechanism. For example, the originator of data (e.g., thread or process that has data to transfer or send) can send a hold-off signal to the receiver of the data. The hold-off signal instructs the receiver (e.g., receiving thread or process) not to read from a particular memory location until a predefined amount of data has been accumulated (e.g., written to the storage location (e.g., a storage queue)). In this manner, the number of context switches to handle a given amount of data can be reduced by processing multiple packets with a single context switch. It is noted that the signaling can be implemented across boundaries (e.g., between processors  and  in ) by utilizing a predefined interface (e.g., application programming interface (API)) between entities (e.g., processes, threads, drivers, etc.) that reside on different sides of such boundaries.","Alternative Data Aggregation Example",{"@attributes":{"id":"p-0066","num":"0070"},"figref":["FIG. 6","FIG. 3"],"b":["600","602","604","602","604","606","602","608","610"]},"In this example, the data aggregation is controlled by the function driver \/ of the first and second processors \/ rather than by the interconnect driver \/, respectively.","The first processor  may include or execute a function driver , a transmit (Tx) queue , a receive (Rx) queue , and\/or an interconnect driver . The function driver  may include or implement a data aggregation module , an unbundling module , a timer , and\/or an intelligent scheduler .","The second processor  may include or implement a function driver , a transmit (Tx) queue , a receive (Rx) queue , an interconnect driver , an operating system networking stack , and\/or one or more applications . The function driver  may include or implement a data aggregation module , an unbundling module , an intelligent scheduler , and\/or a timer .","The elements and\/or modules illustrated for the first processor  and second processor  may be functional components operating within each processor and\/or may be combined with other components.","For data received on the forward link or downlink (i.e., data received at the access terminal), the data is received via the antenna  and collected at radio stack . The function driver  of the first processor  then transfers the data from the radio stack  into the Tx queue . The function driver  may control when data is transferred out from the Tx queue . That is, the data aggregation module  may bundle or aggregate the data in the Tx queue  and the intelligent scheduler  may indicate to the interconnect driver  when the aggregated data is to be transferred into the transfer buffer  based on one more factors or parameters. These factors or parameters may include, but are not limited to, a timeout value of timer , size of the Tx queue , one or more Tx queue levels, size of the transfer buffer , one or more indicators of the data rates expected from the radio stack , a processor load indicator (e.g., load of the second processor ), or a combination thereof. When the intelligent scheduler  determines that data is to be read from the Tx queue  and written to the transfer buffer , it indicates to the interconnect driver  to perform a read operation (from the Tx queue ) and a write operation (to the transmit buffer ). An interrupt to the second processor  is also generated. The interconnect driver , when responding to the interrupt, reads the aggregated data packets from the transfer buffer  and writes the data into Rx queue . The function driver  then reads the data packets from the Rx queue  and the unbundling module  separates the bundled packets into individual packets for sending to the upper layers (e.g., eventually to the application ).","Similarly, for data to be transmitted on the reverse link or the uplink (i.e., data to be transmitted from an access terminal to an access point or base station), the data is received from upper layers (e.g., the application ) is written into the Tx queue . In this implementation, the function driver  controls the data aggregation and transfer from the Tx queue . That is, the data aggregation module  bundles or aggregates data packets in the Tx queue  and the intelligent scheduler  indicates to the interconnect driver  when to transfer the aggregated data packets from the Tx queue  to the transfer buffer  based on one more factors or parameters. These factors or parameters may include, but are not limited to, a timeout value of the timer , size of the Tx queue , one or more Tx queue levels, size of the transfer buffer , a load indicator (e.g., load of the first processor ), one or more indicators of the data rates expected from the application , or a combination thereof. When the intelligent scheduler  determines that data is to be read from the Tx queue  and written to the transfer buffer , it indicates to the interconnect driver  to perform a read operation from the Tx queue  and a write operation to the transfer buffer . An interrupt to the first processor  is also generated. The interconnect driver , when responding to the interrupt, reads the aggregated data packets from the transfer buffer  and writes the data into Rx queue . The function driver  then reads the data packets from the Rx queue  and the unbundling module  separates the bundled packets into individual packets for sending to the radio stack .","According to one feature, data may be aggregated at the Tx queue ( or ) for transfer between the two processors  and . That is, rather than sending each individual data packet as it arrives in the Tx queue ( or ), the intelligent scheduler ( and\/or ) causes the Tx queue ( or ) to accumulate data packets until a sufficiently large number of packets are accumulated. The accumulated data packets are then grouped or bundled as a single packet for transfer to the transfer buffer .","According to one example, the intelligent scheduler ( or ) may utilize low and high queue levels to determine when data transfer should be transferred. These watermark queue levels may be adjusted for differing 3G data rates or 4G data rates. The low and high queue levels may be used to determine when data packets accumulated in the Tx queue (\/) can be transferred to the transfer buffer . For instance, the low queue level may indicate a minimum amount of data that should be kept in the Tx queue (\/) while the high queue level may indicate a maximum amount of data that should be kept in the Tx queue.","Additionally, the timer ( or ) may also be utilized to facilitate aggregation of data prior to transfer between contexts. A maximum timeout value (as tracked by the timer  or ) may be utilized so that data is not kept for a long time in the Tx queue \/. In one example, the timeout value (tracked by the timer \/) may be empirically determined or tuned by locating an inflection point on a graph that plots timer timeout value versus achieved data throughput. In one case, a peak value of throughput is used to obtain an optimum timeout value, which leads to an improved processor idle time performance (e.g., for first processor  and\/or second processor  in a dual processor architecture).",{"@attributes":{"id":"p-0076","num":"0080"},"figref":"FIG. 7","b":["702","704","706","700","702","708","714","708","710","712","716","718","716","718","702","706","704","720","726","720","722","724","730","728","730","728","704","706"]},"According to one feature, the processing circuit  may be adapted to: (a) aggregate data packets into a packet bundle, and\/or (b) process the packet bundle in a single context switch when transferring the packet bundle to the second processor  via a shared memory , wherein a processing load of the first processor  is reduced due to the aggregation of the data packets into the packet bundle. Note that the first processor  may implement functions across multiple layers and performs context switching between the functions. The processing circuit  may implement a function driver  and an interconnect driver  that transfer data between each other via a transmit queue  and a receive queue . In this example, rather than utilizing multiple context switches to transfer data packets between the function driver  and the interconnect driver , a single context switch (e.g., from Context A to Context B) may be used to transfer a packet bundle, thereby reducing the processing load of the first processor . Note that the use of a packet bundle also allows the use of a single context switch (e.g., Context C to\/from Context D) between the function driver  and the interconnect driver  at the second processor , thereby reducing the processing load of the second processor .","In one implementation, the interconnect driver  may control the aggregation of the data packets in the transmit queue  and schedules the transfer of the packet bundle to the second processor . In another example, the function driver  may control the aggregation of the data packets in the transmit queue  and schedules the transfer of aggregated data packets to the second processor . Note that one benefit of directing or controlling data packet aggregation at either the function driver  and\/or the interconnect driver  is that such aggregation occurs at a low level or layer of an operating system. Consequently, such aggregation is transparent to applications and\/or networking stack at higher levels.","The transmit queue  and\/or receive queue  may be implemented within the shared memory  or may be implemented within the first processor .","According to another feature, the processing circuit  may be adapted to: (a) obtain a packet bundle via a shared memory  from the second processor  in a single context switch, wherein the packet bundle includes aggregated data packets, and\/or (b) unbundle the packet bundle into a plurality of data packets, wherein a processing load of the first processor  is reduced due to the aggregation of the data packets into the packet bundle by the second processor . In one example, the processing circuit may be adapted to receive an interrupt indicating that a data bundle is being transferred from the second processor . The processing load of the second processor  is reduced due to the aggregation of the data packets into the packet bundle.","Consequently, an access terminal is provided comprising the first processor , the second processor  and the shared memory . The first processor  may be adapted to aggregate a plurality of data packets into a packet bundle. The shared memory may be coupled to the first processor and may be used by the first processor to transfer the packet bundle to the second processor , wherein the transfer of the packet bundle is performed in a single context switch by the first processor . The second processor  may also be coupled to the shared memory and may be adapted to obtain the packet bundle from the shared memory and unbundle the packet bundle into individual data packets, wherein a processing load of the second processor  is reduced due to the aggregation of the data packets into the packet bundle by the first processor .","Additionally, the second processor  may be further adapted to aggregate a second plurality of data packets into a second packet bundle and transfer the second packet bundle from the second processor  to the first processor  using the shared memory , wherein the transfer of the packet bundle is performed in a single context switch by the second processor . The first processor  may be further adapted to unbundle the second packet bundle into individual data packets at the first processor , wherein a processing load of the first processor  is reduced due to the aggregation of the data packets into the second packet bundle by the second processor .","Note that the data aggregation techniques described herein may be implemented in a multi-processor system, circuit, or device. Thus, such data aggregation may be implemented among N processors, where N is two or greater.",{"@attributes":{"id":"p-0084","num":"0088"},"figref":"FIG. 8","b":["802","804","806"]},"The packet bundle may be transferred to the second processor upon occurrence of one or more triggers, wherein the one or more triggers include at least one of:\n\n","According to one example, the first processor may implement functions across multiple layers and performs context switching between the functions. The functions may include a function driver and an interconnect driver that transfer data between each other via a transmit queue and a receive queue. In one implementation, the interconnect driver may control the aggregation of the data packets in the transmit queue and schedules the transfer of the packet bundle to the second processor. In another example, the function driver may control the aggregation of data packets in the transmit queue and schedules the transfer of the packet bundle to the second processor.",{"@attributes":{"id":"p-0087","num":"0096"},"figref":"FIG. 9","b":["902","904","906"]},{"@attributes":{"id":"p-0088","num":"0097"},"figref":"FIG. 10","b":["1002","1004","1006","1008"]},"According to yet another feature, the packet bundle may be transferred to the second processor upon occurrence of one or more triggers. The one or more triggers may include at least one of:\n\n","The first processor and second processors may each implement functions across multiple layers, the functions at each of the first and second processors may include a function driver and an interconnect driver that transfer data between each other via a transmit queue and a receive queue. In a first example, the interconnect driver may control the aggregation of data packets in the transmit queue and schedules the transfer of the packet bundle to the second processor. In a second example, the function driver may control the aggregation of data packets in the transmit queue and schedules the transfer of the packet bundle to the second processor.","The method may further comprise aggregating a second plurality of data packets into a second packet bundle at the second processor . The second packet bundle is then transferred from the second processor to the first processor using the shared memory, wherein the transfer of the packet bundle is performed in a single context switch at the second processor . The second processor may then generate and the first processor may receive an interrupt indicating that the packet bundle is being transferred from the second processor, wherein the number of interrupts at the first processor is reduced due to the aggregation of the second plurality of data packets at the second processor . The first processor may then unbundle the second packet bundle into individual data packets, wherein a processing load of the first processor is reduced due to the aggregation of the data packets into the second packet bundle by the second processor .","It should be recognized that, generally, most of the processing described in this disclosure may be implemented in a similar fashion. Any of the circuit(s) or circuit sections may be implemented alone or in combination as part of an integrated circuit with one or more processors. The one or more of the circuits may be implemented on an integrated circuit, an Advance RISC Machine (ARM) processor, a digital signal processor (DSP), a general purpose processor, etc.","Also, it is noted that the embodiments may be described as a process that is depicted as a flowchart, a flow diagram, a structure diagram, or a block diagram. Although a flowchart may describe the operations as a sequential process, many of the operations can be performed in parallel or concurrently. In addition, the order of the operations may be re-arranged. A process is terminated when its operations are completed. A process may correspond to a method, a function, a procedure, a subroutine, a subprogram, etc. When a process corresponds to a function, its termination corresponds to a return of the function to the calling function or the main function.","As used in this application, the terms \u201ccomponent,\u201d \u201cmodule,\u201d \u201csystem,\u201d and the like are intended to refer to a computer-related entity, either hardware, firmware, a combination of hardware and software, software, or software in execution. For example, a component may be, but is not limited to being, a process running on a processor, a processor, an object, an executable, a thread of execution, a program, and\/or a computer. By way of illustration, both an application running on a computing device and the computing device can be a component. One or more components can reside within a process and\/or thread of execution and a component may be localized on one computer and\/or distributed between two or more computers. In addition, these components can execute from various computer readable media having various data structures stored thereon. The components may communicate by way of local and\/or remote processes such as in accordance with a signal having one or more data packets (e.g., data from one component interacting with another component in a local system, distributed system, and\/or across a network such as the Internet with other systems by way of the signal).","Moreover, a storage medium may represent one or more devices for storing data, including read-only memory (ROM), random access memory (RAM), magnetic disk storage mediums, optical storage mediums, flash memory devices and\/or other machine readable mediums for storing information. The term \u201cmachine readable medium\u201d includes, but is not limited to portable or fixed storage devices, optical storage devices, wireless channels and various other mediums capable of storing, containing or carrying instruction(s) and\/or data.","Furthermore, embodiments may be implemented by hardware, software, firmware, middleware, microcode, or any combination thereof. When implemented in software, firmware, middleware or microcode, the program code or code segments to perform the necessary tasks may be stored in a machine-readable medium such as a storage medium or other storage(s). A processor may perform the necessary tasks. A code segment may represent a procedure, a function, a subprogram, a program, a routine, a subroutine, a module, a software package, a class, or any combination of instructions, data structures, or program statements. A code segment may be coupled to another code segment or a hardware circuit by passing and\/or receiving information, data, arguments, parameters, or memory contents. Information, arguments, parameters, data, etc. may be passed, forwarded, or transmitted via any suitable means including memory sharing, message passing, token passing, network transmission, etc.","One or more of the components, steps, and\/or functions illustrated in the Figures may be rearranged and\/or combined into a single component, step, or function or embodied in several components, steps, or functions. Additional elements, components, steps, and\/or functions may also be added without departing from the invention. The apparatus, devices, and\/or components illustrated in the Figures may be configured to perform one or more of the methods, features, or steps described in the Figures. In some implementations, the novel algorithms described herein may be efficiently implemented in software and\/or embedded hardware.","Those of skill in the art would further appreciate that the various illustrative logical blocks, modules, circuits, and algorithm steps described in connection with the embodiments disclosed herein may be implemented as electronic hardware, computer software, or combinations of both. To clearly illustrate this interchangeability of hardware and software, various illustrative components, blocks, modules, circuits, and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system.","The various features described herein can be implemented in different systems without departing from the invention. It should be noted that the foregoing embodiments are merely examples and are not to be construed as limiting. The description of the embodiments is intended to be illustrative, and not to limit the scope of the claims. As such, the present teachings can be readily applied to other types of apparatuses and many alternatives, modifications, and variations will be apparent to those skilled in the art."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
