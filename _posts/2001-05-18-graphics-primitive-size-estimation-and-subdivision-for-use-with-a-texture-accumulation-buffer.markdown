---
title: Graphics primitive size estimation and subdivision for use with a texture accumulation buffer
abstract: A graphics system configured to apply multiple layers of texture information to primitives. The graphics system receives parameters defining a primitive and performs a size test on the primitive. If the size test cannot guarantee that a fragment size of the primitive is less than or equal to a fragment capacity of a texture accumulation buffer, the primitive is divided into subprimitives, and the graphics system applies the multiple layers of texture to fragments which intersect the primitive. The graphics system switches from a current layer to the layer next when it has applied textures corresponding to the current layer to all the fragments intersecting the primitive. The graphics system stores color values associated with the primitive fragments in the texture accumulation buffer between the application of successive texture layers.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06914610&OS=06914610&RS=06914610
owner: Sun Microsystems, Inc.
number: 06914610
owner_city: Santa Clara
owner_country: US
publication_date: 20010518
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF SEVERAL EMBODIMENTS"],"p":["Not applicable.","1. Field of the Invention","This invention relates generally to the field of computer graphics and, more particularly, to high performance graphics systems for rendering graphical objects based on a decomposition of the graphical objects into primitives such as triangles, dot and lines.","2. Description of the Related Art","A graphics system may be configured to receive a stream of graphics parameters defining primitives such as triangles, lines and dots from a host application executing on a host computer. For example, the graphics system may receive a stream of vertices defining triangles in a 3D coordinate space. The triangles represent a collection of 3D objects in the 3D world coordinate space. The graphics system may operate on the triangles to generate a video stream which represents the view of a virtual camera (or virtual observer) in the 3D world coordinate space. In particular, the graphics system may compute color values for each pixel that resides within each triangle (i.e. the two-dimensional footprint of the triangle in screen space). This process of assigning color values to pixels (or samples) internal to triangles is referred to herein as triangle rasterization.","Triangle rasterization may include the application of one or more textures. In other words, graphics system may store one or more texture maps in a texture memory and may modify the color of pixels using the one or more texture maps. For example, pixels residing internal to a given triangle comprising part of a wall may be textured with three texture maps, the first map giving the triangle the appearance of brick material, the second map for putting oil smudges on the brick-textured triangle, the third map for varying the level of illumination of pixels on the oil-smudged brick-textured triangle.","According to one conventional rasterization method, each pixel in a given triangle may be textured with all N textures (from the N corresponding texture maps) before proceeding to the next pixel (interior to the triangle) along a scan line or on the next scan line. In other words, a processor may compute color values for a pixel Pby sequentially accessing a texel from texture map #1, a texel from texture map #2, . . . , a texel from texture map #N. Then after completing the computation of color values for pixel P, the processor may compute color values for the next pixel Pinterior to the triangle by sequentially accessing a texel from texture map #1, a texel from texture map #2, . . . , a texel from texture map #N. This method of texturing triangles is very inefficient in its use of texture memory as the frequency of cache misses and page misses is large.","Thus, there exists a need for a graphics system and method which could more efficiently apply multiple layers of texture to primitives.","A graphics system configured to apply multiple layers of texture information to graphics primitives (e.g. triangles, dots, lines, etc.) is disclosed. In one set of embodiments, the graphics system includes a hardware accelerator, a frame buffer, a video output processor and a texture memory. The texture memory may store multiple layers of texture information.","The hardware accelerator receives graphical parameters such as vertices defining a primitive. The primitive resides in a rendering space which is tessellated with fragments (also referred to as bins). The hardware accelerator identifies fragments (i.e. bins) which geometrically intersect the primitive in rendering space, and applies the multiple layers of texture to the intersecting fragments. The hardware accelerator switches to a next texture layer once it has applied the textures of a current layer to all the fragments of the primitive. This scheme of processing fragments as the inner loop and texture layers as the outer loop may increase the average efficiency of accesses to the texture memory. The hardware accelerator includes (or couples to) a texture accumulation buffer which stores color data associated with the primitive fragments between the application of successive texture layers.","To prevent overflow of the texture accumulation buffer (TAB), the primitive may be limited to intersect a number of fragments which is less than or equal to the fragment capacity of the TAB (i.e. the maximum number of fragments the TAB can store). The number of fragments which intersect a primitive is referred to herein as the fragment size of the primitive. Before textures are applied to the primitive, the hardware accelerator performs a size test on the primitive. The size test determines if the fragment size of the primitive is less than or equal to the TAB fragment capacity, or more generally, if an upper bound for the fragment size is less than or equal to a lower bound for the TAB fragment capacity. If the size test fails, i.e. indicates that the fragment size is too large relative to the TAB fragment capacity, the hardware accelerator divides the primitive into subprimitives. The subprimitives have fragment sizes smaller than the TAB fragment capacity.","A number U is said to be an upper bound for a number X if U is greater than or equal to X. A number L is said to be a lower bound for a number X if L is less than or equal to X. Thus, X is itself a lower bound and an upper bound for X.","In one embodiment, the hardware accelerator may be configured to perform the size comparison on a given primitive by (1) computing a width value and height value for the first primitive, (2) determining a bit position \u03b1 of a leading one in the width value, (3) determining a bit position \u03b2 of a leading one in the height value, and (4) comparing a sum of the bit position \u03b1 and the bit position \u03b2 to a threshold value. The threshold value is determined by the TAB fragment capacity. For example, the threshold value may equal the bit position of a leading one in a binary representation of the TAB fragment capacity.","In one collection of embodiments, the hardware accelerator may be configured to incorporate more information from the width and height than just the bit positions \u03b1 a and \u03b2. The hardware accelerator may additionally generate a mantissa for the width value and a mantissa for the height value, and compute an upper bound for the primitive's fragment size based on the bit positions \u03b1 and \u03b2 and the mantissas. Because the upper bound incorporates finer information, the upper bound may more tightly bound the fragment size than when only the bit position information is used. The upper bound may be compared to the TAB fragment capacity to implement the size test.","In some embodiments, the hardware accelerator may be configured to perform the size comparison on a given primitive by computing an area (e.g. 0.5*WIDTH*HEIGHT in the case of a triangle) of the primitive, adding a positive constant (referred to herein as the marginal adjustment constant) to the area, and comparing the marginally adjusted area to the fragment capacity of the TAB. The marginal adjustment constant accounts for the fact that the geometric area of a primitive may be smaller than the fragment size of the primitive (i.e. the number of fragments which intersect the primitive). The sum of the marginal adjustment constant and the geometric area gives an upper bound for the fragment size.","The texture layers are interpreted herein as including any information capable of modifying the color of primitive fragments (or the samples populating the primitive fragments). For example, some of the texture layers may be illumination maps.","The hardware accelerator may generate sample positions in the primitive fragments, identify which of the sample positions reside interior to the primitive, and compute a color vector for each interior sample based on color vectors associated with the primitive vertices. In applying the textures (from the multiple texture layers) to the primitive fragments, the hardware accelerator may compute texture values at fragment resolution and apply each texture value to the sample color vectors of the corresponding primitive fragment. As used herein the term \u201ctexture value\u201d is to be interpreted broadly to mean any data value which may be used to modify the color (or other properties) of fragments and\/or samples.","In one alternative set of embodiments, the hardware accelerator may generate samples after all or most of the texture layers have been applied to the intersecting fragments. An initial color vector may be computed for each intersecting fragment based on a spatial interpolation of color at the primitive vertices. The multiple textures may be cumulatively applied to the initial color vectors. When the samples are generated for the primitive fragments, the finally modified color vectors are applied (e.g. flat filled) to the samples.","The hardware accelerator stores the samples (after application of the multiple texture layers) in a sample area of the frame buffer, subsequently reads and filters the samples to obtain pixel values, and store the pixel values in a pixel area of the frame buffer. The video output processor reads the pixel values from the pixel area of the frame buffer and generates a portion of a video signal from the pixel values. The video signal may be provided to a video output port for display on a display device (e.g. a projector or monitor).","While the invention is susceptible to various modifications and alternative forms, specific embodiments thereof are shown by way of example in the drawings and will be described in detail herein. It should be understood, however, that the drawings and detailed description thereto are not intended to limit the invention to the particular forms disclosed, but on the contrary, the intention is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of the present invention as defined by the appended claims. Please note that the headings are for organizational purposes only and are not meant to limit the description or claims. The word \u201cmay\u201d is used in this application in a permissive sense (i.e., having the potential to, being able to), not a mandatory sense (i.e., must). Similarly, the word \u201cinclude\u201d, and derivations thereof, are used herein to mean \u201cincluding, but not limited to.\u201d","Computer System\u2014","Referring now to , one embodiment of a computer system  that includes a graphics system is shown. The graphics system may be comprised in any of various systems, including a computer system, network PC, Internet appliance, a television, including HDTV systems and interactive television systems, personal digital assistants (PDAs), virtual reality systems, and other devices which display 2D and or 3D graphics, among others.","As shown, the computer system  comprises a system unit  and a video monitor or display device  coupled to the system unit . The display device  may be any of various types of display monitors or devices (e.g., a CRT, LCD, or gas-plasma display). Various input devices may be connected to the computer system, including a keyboard  and\/or a mouse , or other input device (e.g., a trackball, digitizer, tablet, six-degree of freedom input device, head tracker, eye tracker, data glove, or body sensors). Application software may be executed by the computer system  to display graphical objects on display device .","Computer System Block Diagram\u2014","Referring now to , a simplified block diagram illustrating the computer system of  is shown. Elements of the computer system that are not necessary for an understanding of the present invention are not shown for convenience. As shown, the computer system  includes a central processing unit (CPU)  coupled to a high-speed memory bus or system bus  also referred to as the host bus . A system memory  may also be coupled to high-speed bus .","Host processor  may comprise one or more processors of varying types, e.g., microprocessors, multi-processors and CPUs. The system memory  may comprise any combination of different types of memory subsystems, including random access memories, (e.g., static random access memories or \u201cSRAMs,\u201d synchronous dynamic random access memories or \u201cSDRAMs,\u201d and Rambus dynamic random access memories or \u201cRDRAM,\u201d among others) and mass storage devices. The system bus or host bus  may comprise one or more communication or host computer buses (for communication between host processors, CPUs, and memory subsystems) as well as specialized subsystem buses.","In , a graphics system  is coupled to the high-speed memory bus . The 3-D graphics system  may be coupled to the bus  by, for example, a crossbar switch or other bus connectivity logic. It is assumed that various other peripheral devices, or other buses, may be connected to the high-speed memory bus . It is noted that the graphics system may be coupled to one or more of the buses in computer system  and\/or may be coupled to various types of buses. In addition, the graphics system may be coupled to a communication port and thereby directly receive graphics data from an external source, e.g., the Internet or a network. As shown in the figure, one or more display devices  may be connected to the graphics system  comprised in the computer system .","Host CPU  may transfer information to and from the graphics system  according to a programmed input\/output (I\/O) protocol over host bus . Alternately, graphics system  may access the memory subsystem  according to a direct memory access (DMA) protocol or through intelligent bus mastering.","A graphics application program conforming to an application programming interface (API) such as OpenGL or Java 3D may execute on host CPU  and generate commands and data that define a geometric primitive (graphics data) such as a polygon for output on display device . As defined by the particular graphics interface used, these primitives may have separate color properties for the front and back surfaces. Host processor  may transfer this graphics data to memory subsystem . Thereafter, the host processor  may operate to transfer the graphics data to the graphics system  over the host bus . In another embodiment, the graphics system  may read in geometry data arrays over the host bus  using DMA access cycles. In yet another embodiment, the graphics system  may be coupled to the system memory  through a direct port, such as the Advanced Graphics Port (AGP) promulgated by Intel Corporation.","The graphics system may receive graphics data from any of various sources, including the host CPU  and\/or the system memory , other memory, or from an external source such as a network, e.g., the Internet, or from a broadcast medium, e.g., television, or from other sources.","Note while graphics system  is depicted as part of computer system , graphics system  may also be configured as a stand-alone device (e.g., with its own built-in display). Graphics system  may also be configured as a single chip device or as part of a system-on-a-chip or a multi-chip module. Additionally, in some embodiments, certain elements of the illustrated graphics system  may be implemented in software.","Graphics System\u2014","Referring now to , a functional block diagram illustrating one embodiment of graphics system  is shown. Note that many other embodiments of graphics system  are possible and contemplated. Graphics system  may comprise one or more media processors , one or more hardware accelerators , one or more texture buffers , one or more frame buffers , and one or more video output processors . Graphics system  may also comprise one or more output devices such as digital-to-analog converters (DACs) , video encoders , flat-panel-display drivers (not shown), and\/or video projectors (not shown). Media processor  and\/or hardware accelerator  may be any suitable type of high performance processor (e.g., specialized graphics processors or calculation units, multimedia processors, DSPs, or general purpose processors).","In some embodiments, one or more of these components may be removed. For example, the texture buffer may not be included in an embodiment that does not provide texture mapping. In other embodiments, all or part of the functionality implemented in either or both of the media processor or the graphics accelerator may be implemented in software.","In some embodiments, media processor  and hardware accelerator  may be comprised within the same integrated circuit. In other embodiments, portions of media processor  and\/or hardware accelerator  may be comprised within separate integrated circuits.","As shown, graphics system  may include an interface to a host bus such as host bus  in  to enable graphics system  to communicate with a host system such as computer system . More particularly, host bus  may allow a host processor to send commands to the graphics system . In one embodiment, host bus  may be a bi-directional bus.","Media Processor\u2014",{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 4","b":["14","14","112","80","112","80","14"]},"Transformation refers to manipulating an object and includes translating the object (i.e., moving the object to a different location), scaling the object (i.e., stretching or shrinking), and rotating the object (e.g., in three-dimensional space, or \u201c3-space\u201d).","Lighting refers to calculating the illumination of the objects within the displayed image to determine what color and or brightness each individual object will have. Depending upon the shading algorithm being used (e.g., constant, Gourand, or Phong), lighting may be evaluated at a number of different locations. For example, if constant shading is used (i.e., each pixel of a polygon has the same lighting), then the lighting need only be calculated once per polygon. If Gourand shading is used, then the lighting is calculated once per vertex. Phong shading calculates the lighting on a per-pixel basis.","As illustrated, media processor  may be configured to receive graphical data via host interface . A graphics queue  may be included in media processor  to buffer a stream of data received via the accelerated port of host interface . The received graphics data may comprise one or more graphics primitives. As used herein, the term graphics primitive may include polygons, parametric surfaces, splines, NURBS (non-uniform rational B-splines), sub-divisions surfaces, fractals, volume primitives, voxels (i.e., three-dimensional pixels), and particle systems. In one embodiment, media processor  may also include a geometry data preprocessor  and one or more microprocessor units (MPUs) . MPUs  may be configured to perform vertex transform and lighting calculations and programmable functions and to send results to hardware accelerator . MPUs  may also have read\/write access to texels (i.e. the smallest addressable unit of a texture map, which is used to \u201cwallpaper\u201d a three-dimensional object) and pixels in the hardware accelerator . Geometry data preprocessor  may be configured to decompress geometry, to convert and format vertex data, to dispatch vertices and instructions to the MPUs , and to send vertex and attribute tags or register data to hardware accelerator .","As shown, media processor  may have other possible interfaces, including an interface to a memory. For example, as shown, media processor  may include direct Rambus interface  to a direct Rambus DRAM (DRDRAM) . A memory such as DRDRAM  may be used for program and data storage for MPUs . DRDRAM  may also be used to store display lists and\/or vertex texture maps.","Media processor  may also include interfaces to other functional components of graphics system . For example, media processor  may have an interface to another specialized processor such as hardware accelerator . In the illustrated embodiment, controller  includes an accelerated port path that allows media processor  to control hardware accelerator . Media processor  may also include a direct interface, such as bus interface unit (BIU) , which provides a direct port path to memory  and to hardware accelerator  and video output processor  via controller .","Hardware Accelerator\u2014","One or more hardware accelerators  may be configured to receive graphics instructions and data from media processor  and then to perform a number of functions on the received data according to the received instructions. For example, hardware accelerator  may be configured to perform rasterization, 2D or 3D texturing, pixel transfers, imaging, fragment processing, clipping, depth cueing, transparency processing, set-up, and\/or screen space rendering of various graphics primitives occurring within the graphics data.","Clipping refers to the elimination of graphics primitives or portions of graphics primitives that lie outside of a 3D view volume in world space. The 3D view volume may represent that portion of world space that is visible to a virtual observer (or virtual camera) situated in world space. For example, the view volume may be a solid truncated pyramid generated by a 2D view window and a viewpoint located in world space. The solid truncated pyramid may be imagined as the union of all rays emanating from the viewpoint and passing through the view window. The viewpoint may represent the world space location of the virtual observer. In most cases, primitives or portions of primitives that lie outside the 3D view volume are not currently visible and may be eliminated from further processing. Primitives or portions of primitives that lie inside the 3D view volume are candidates for projection onto the 2D view window.","Set-up refers to mapping primitives to a three-dimensional viewport. This involves translating and transforming the objects from their original \u201cworld-coordinate\u201d system to the established viewport's coordinates. This creates the correct perspective for three-dimensional objects displayed on the screen.","Screen-space rendering refers to the calculation performed to generate the data used to form each pixel that will be displayed. For example, hardware accelerator  may calculate \u201csamples.\u201d Samples are points that have color information but no real area. Samples allow hardware accelerator  to \u201csuper-sample,\u201d or calculate more than one sample per pixel. Super-sampling may result in a higher quality image.","Hardware accelerator  may also include several interfaces. For example, in the illustrated embodiment, hardware accelerator  has four interfaces. Hardware accelerator  has an interface  (referred to as the \u201cNorth Interface\u201d) to communicate with media processor . Hardware accelerator  may also be configured to receive commands from media processor  through this interface. Additionally, hardware accelerator  may include an interface  to bus . Bus  may connect hardware accelerator  to boot PROM  and\/or video output processor . Boot PROM  may be configured to store system initialization data and\/or control code for frame buffer . Hardware accelerator  may also include an interface to a texture memory . For example, hardware accelerator  may interface to texture memory  using an eight-way interleaved texel bus that allows hardware accelerator  to read from and write to texture memory . Hardware accelerator  may also interface to a frame buffer . For example, hardware accelerator  may be configured to read from and\/or write to frame buffer  using a four-way interleaved pixel bus.","The vertex processor  may be configured to use the vertex tags received from the media processor  to perform ordered assembly of the vertex data from the MPUs . Vertices may be saved in and\/or retrieved from a mesh buffer .","The render pipeline  may be configured to receive vertices and convert them to fragments. The render pipeline  may be configured to rasterize 2D window system primitives (e.g., dots, fonts, Bresenham lines, polygons, rectangles, fast fills, and BLITs (Bit Block Transfers, which move a rectangular block of bits from main memory into display memory, which may speed the display of moving objects on screen)) and 3D primitives (e.g., smooth and large dots, smooth and wide DDA (Digital Differential Analyzer) lines, triangles, polygons, and fast clear) into pixel fragments. The render pipeline  may be configured to handle full-screen size primitives, to calculate plane and edge slopes, and to interpolate data down to pixel tile resolution using interpolants or components such as r, g, b (i.e., red, green, and blue vertex color); r2, g2, b2 (i.e., red, green, and blue specular color from lit textures); a (alpha); and z, s, t, r, and w (texture components).","In embodiments using supersampling, the sample generator  may be configured to generate samples from the fragments output by the render pipeline  and to determine which samples are inside the rasterization edge. Sample positions may be defined in loadable tables to enable stochastic sampling patterns.","Hardware accelerator  may be configured to write textured fragments from 3D primitives to frame buffer . The render pipeline  may send pixel tiles defining r, s, t and w to the texture address unit . The texture address unit  may determine the set of neighboring texels that are addressed by the fragment(s), as well as the interpolation coefficients for the texture filter, and write texels to the texture memory . The texture memory  may be interleaved to obtain as many neighboring texels as possible in each clock. The texture filter  may perform bilinear, trilinear or quadlinear interpolation. The pixel transfer unit  may also scale and bias and\/or lookup texels. The texture environment  may apply texels to samples produced by the sample generator . The texture environment  may also be used to perform geometric transformations on images (e.g., bilinear scale, rotate, flip) as well as to perform other image filtering operations on texture buffer image data (e.g., bicubic scale and convolutions).","In the illustrated embodiment, the pixel transfer MUX  controls the input to the pixel transfer unit . The pixel transfer unit  may selectively unpack pixel data received via north interface , select channels from either the frame buffer  or the texture memory , or select data received from the texture filter  or sample filter .","The pixel transfer unit  may be used to perform scale, bias, and\/or color matrix operations, color lookup operations, histogram operations, accumulation operations, normalization operations, and\/or min\/max functions. Depending on the source of and operations performed on the processed data, the pixel transfer unit  may then output the data to the texture memory  (via the texture buffer MUX ), the frame buffer  (via the texture environment unit  and the fragment processor ), or to the host (via north interface ). For example, in one embodiment, when the pixel transfer unit  receives pixel data from the host via the pixel transfer MUX , the pixel transfer unit  may be used to perform a scale and bias or color matrix operation, followed by a color lookup or histogram operation, followed by a min\/max function. The pixel transfer unit  may then output data to either the texture memory  or the frame buffer .","Fragment processor  may be used to perform standard fragment processing operations such as the OpenGL fragment processing operations. For example, the fragment processor  may be configured to perform the following operations: fog, area pattern, scissor, alpha\/color test, ownership test (WID), stencil test, depth test, alpha blends or logic ops (ROP), plane masking, buffer selection, pick hit\/occlusion detection, and\/or auxiliary clipping in order to accelerate overlapping windows.","Texture Memory ","Texture memory  may include several SDRAMs. Texture memory  may be configured to store texture maps and image processing buffers for hardware accelerator . Texture memory  may have many different capacities (e.g., depending on the type of SDRAM included in texture memory ). In some embodiments, each pair of SDRAMs may be independently row and column addressable.","Frame Buffer ","Graphics system  may also include a frame buffer . In one embodiment, frame buffer  may include multiple 3DRAM64s. Frame buffer  may be configured as a display pixel buffer, an offscreen pixel buffer, and\/or a supersample buffer. Furthermore, in one embodiment, certain portions of frame buffer  may be used as a display pixel buffer, while other portions may be used as an offscreen pixel buffer and supersample buffer.","Video Output Processor\u2014","A video output processor  may also be included within graphics system . Video output processor  may buffer and process pixels output from frame buffer . For example, video output processor  may be configured to read bursts of pixels from frame buffer . Video output processor  may also be configured to perform double buffer selection (dbsel) if the frame buffer  is double-buffered, overlay transparency (using transparency\/overlay unit ), plane group extraction, gamma correction, psuedocolor or color lookup or bypass, and\/or cursor generation. For example, in the illustrated embodiment, the output processor  includes WID (Window ID) lookup tables (WLUTs)  and gamma and color map lookup tables (GLUTs, CLUTs) . In one embodiment, frame buffer  may include multiple 3DRAM64s  that include the transparency overlay  and all or some of the WLUTs . Video output processor  may also be configured to support two video output streams to two displays using the two independent video raster timing generators . For example, one raster (e.g., A) may drive a 1280\u00d71024 CRT while the other (e.g., B) may drive a NTSC or PAL device with encoded television video.","DAC  may operate as the final output stage of graphics system . The DAC  translates the digital pixel data received from GLUT\/CLUTs\/Cursor unit  into analog video signals that are then sent to a display device. In one embodiment, DAC  may be bypassed or omitted completely in order to output digital pixel data in lieu of analog video signals. This may be useful when a display device is based on a digital technology (e.g., an LCD-type display or a digital micro-mirror display).","DAC  may be a red-green-blue digital-to-analog converter configured to provide an analog video output to a display device such as a cathode ray tube (CRT) monitor. In one embodiment, RGB DAC  may be configured to provide a high resolution RGB analog video output at dot rates of 240 MHz. Similarly, encoder  may be configured to supply an encoded video signal to a display. For example, encoder  may provide encoded NTSC or PAL video to an S-Video or composite video television monitor or recording device.","In other embodiments, the video output processor  may output pixel data to other combinations of displays. For example, by outputting pixel data to two DACs  (instead of one DAC  and one encoder ), video output processor  may drive two CRTs. Alternately, by using two encoders , video output processor  may supply appropriate video input to two television monitors. Generally, many different combinations of display devices may be supported by supplying the proper output device and\/or converter for that display device.","Overall Processing Flow","Hardware accelerator  receives vertices defining triangles from media processor , and renders the triangles in terms of samples. The samples are stored in a sample area of frame buffer . The samples are then read from the sample area of frame buffer  and filtered by sample filter  to generate pixels. The pixels are stored in a pixel area of frame buffer . The pixel area may be double buffered. Video output processor  reads pixels from the pixel area of frame buffer  and generate a video signal from the pixels. The video signal is made available to one or more display devices (e.g. monitors and\/or projectors).","The samples are computed at positions in a two-dimensional sample space (also referred to as rendering space). The sample space is partitioned into an array of bins (also referred to herein as fragments). The storage of samples in the sample area of frame buffer  is organized according to bins (e.g. bin ) as illustrated in FIG. . Each bin contains one or more samples. The number of samples per bin may be a programmable parameter.","Texture Pipe and Multitexturing Support","As shown in , in one embodiment, the texture pipe includes texture address unit , texture filter , texture environment  and texture accumulation buffer (TAB) . In addition, pixel transfer MUX  and pixel transfer unit  participate in texture processing operations.","The texture pipe is configured to apply multiple layers of texture to triangles. The multiple layers of texture are stored in texture memory . Each layer may comprise multiple mipmap levels. Let N be the number of texture layers stored in texture memory .","Render pipe  receives vertices defining a current triangle from vertex processor . Render pipe  determines a set of fragments (i.e. bins) which intersect the current triangle. For each intersecting fragment F, render pipe :\n\n","In response to request (b), the texture pipe accesses the layer-zero texture map of texture memory  to obtain layer-zero texels, and performs bilinear (or trilinear) filtering to generate the layer-zero texture value T.","Texture address unit  receives the fragment address of fragment Ffrom render pipe , and generates read addresses (in the address space of texture memory ) for the layer-zero texels which contribute to the computation of layer-zero texture value T.","Texture filter  uses the read addresses to access the layer-zero texels and performs the bilinear (or trilinear) filtering on the layer-zero texels to generate the layer-zero texture value T. The layer-zero texture value Tis then fed through pixel transfer MUX  and pixel transfer unit  to texture environment .","Texture environment  receives the initial color vectors Cfor each interior sample position in the fragment Fand the layer-zero texture value T, applies the layer-zero texture value Tto the initial color vector Cof each interior sample position Sto generate resultant color vectors R. The resultant color vectors Rfor the interior samples of fragment Fare stored in TAB .","Any of a variety of mathematical algorithms (including conventional algorithms) may be used by texture environment  to apply the texture values to the initial color vectors. Texture environment  may be programmable to employ different texturing algorithms at different times. Alternatively, texture environment  may employ an algorithm with fixed mathematical structure but modifiable parameters. In one embodiment, texture environment  may comprise dedicated circuitry for implementing one or more texturing algorithms.","In one set of embodiments, the initial color vector Ccontains a transparency value in addition to red, green and blue color values (e.g. diffuse color values). Other per-sample attributes may be included as well.","Texture pipe and rendering pipe process all the intersecting fragments F(i.e. all the fragments Fwhich intersect the current triangle) with respect to texture layer zero before proceeding to texture layer one. This is illustrated by the following pseudo-code fragment.","For each intersecting fragment F:\n\n","After processing all the intersecting fragments Fwith respect to layer zero, the texture pipe processes all the intersecting fragments Fwith respect to texture layer one as follows. For each intersecting fragment F, the texture pipe generates a corresponding layer-one texture value Tby accessing and filtering appropriate texels from texture layer one of texture memory . Texture environment  reads sample color vectors Rcorresponding to fragment Ffrom TAB  and applies the layer-one texture value Tto each of the sample color vectors R, thereby generating resultant sample color vectors R. Each sample of the fragment Fincludes a valid bit indicating whether it resides interior or exterior to the current triangle. Only the color vectors Rof samples interior to the current triangle need be modified with the texture value. Texture environment  stores the resultant sample color vectors Rfor fragment Finto TAB . In the preferred embodiment, texture environment  overwrites fragment Fin TAB  with the update color information, i.e. overwrites the color vectors Rwith the updated color vectors R.","Texture layers two through N- are applied in same fashion as layer one as illustrated by the following pseudo-code fragment. Let I be any integer in the range 1, 2, . . . , N-.","For each fragment F:\n\n","In the application of the last texture layer N-, texture environment  may store the final sample color vectors RNinto TAB  and send pointers to the fragments Fto fragment processor  (i.e. pointers in the TAB address space). Fragment processor  may forward the fragments (including the final sample color value vectors R(N-)to the sample area of frame buffer. Alternatively, texture environment  may send the final sample color vectors R(N-)directly to fragment processor  and thus storage of final sample color vectors R(N-)may be avoided.","In general, texture pipe processes all the intersecting fragments F(i.e. all the fragments Fwhich intersect the current triangle) with respect to texture layer I before proceeding to texture layer (I+1), where I takes any of the values 0, 1, 2, . . . , (N-). This strategy is significantly more efficient that the conventional strategy of processing all texture layers against fragment Fbefore proceeding to the next fragment F. Because the processing of successive texture layers is the inner loop, the conventional strategy very frequently makes large magnitude jumps in the address space texture memory . Thus, the rate of page misses (and cache misses in those embodiments that have a texture cache) in accesses to texture memory  is high.","In contrast, the herein disclosed strategy of processing fragments as the inner loop and texture layers as the outer loop significantly reduces thrashing of texture memory . The large magnitude address jump between texture layers may advantageously occur less often. The successive fragments within a texture layer induce relatively small address jumps in the texture memory address space because the fragments are all spatially localized (to a single triangle). Thus, there may be a significantly decreased probability of encountering page misses and cache misses.","It is noted that the processing methodology described in the embodiments above may be used for effects other than traditional texturing. For example, one of the texture layers may be interpreted as an illumination map which modulates the intensity of rendered samples and\/or fragments. Thus, the texture layers stored in texture memory  should be broadly interpreted to include any of various types of image information capable of modifying pixel or sample colors.","In one set of embodiments, hardware accelerator  is an application specific integrated circuit (ASIC) which is optimized for the sample and texture processing operations described herein. TAB  may be implemented as on-chip SRAM.","Multitexturing with Deferred Sample Generation","In a second set of embodiments, texture layers are applied to the current triangle at fragment resolution, stored in TAB  at fragment resolution, and samples are generated for fragments only after the penultimate texture layer (i.e. layer N-) has completed.","Render pipe  initially generates a single color vector Cfor each fragment Fthat intersects the current triangle. Thus, color vector Cmay be referred to as a fragment color vector. Texture environment  receives the layer zero texture value Tcorresponding to each intersecting fragment Ffrom pixel transfer unit , and applies the layer zero texture value Tto the corresponding fragment color vector C. The resulting fragment color vector Ris stored into TAB .","When all the fragments Fintersecting the current triangle have been processed with respect to layer zero, texture environment  processes layer one as follows. Texture environment  receives the layer-one texture value Tcorresponding to each intersecting fragment Ffrom pixel transfer unit , reads the fragment color vector Rcorresponding to fragment Ffrom TAB , and applies the layer-one texture Tto fragment color vector Rto generate resultant fragment color vector R. The resultant fragment color vector Ris stored into TAB .","Texture layers two through (N-) are processed in a similar fashion to layer one. Let I be any integer in the range two through N-. For each intersecting fragment F, texture environment  reads the fragment color vector R(I\u22121), receives the layer I texture value TIcorresponding to fragment Ffrom pixel transfer unit , and applies the texture value TIto the fragment color vector R(I\u22121)to generate a resultant fragment color vector RI. The resultant fragment color vector RIis stored into TAB . All fragments Fintersecting the current triangle are processed with respect to layer I before proceeding to layer (I+1).","The last texture layer (i.e. layer N-) is processed as follows. For each intersecting fragment F, sample generation and evaluation unit :\n\n","In a first set of embodiments described above, color is initially interpolated to sample resolution, and color is updated and stored in TAB  at sample resolution, although texture values are computed only at fragment resolution. In a second set of embodiments, color is initially interpolated to fragment resolution, and color is updated and stored in TAB at fragment resolution until the last texture layer is to be applied. At this last stage, samples are generated, the last texture layer is applied at the fragment level, the final texturized color is assigned to all valid samples in the fragment.","In many situations, color does not change significantly for the samples within a given fragment. In these situations, the second set of embodiments of graphics system may generate video output whose visual quality is indistinguishable or negligibly different from the first set of embodiments.","Size Estimation for Graphics Primitives","As described above, graphics system  may be configured to apply multiple texture layers to a graphics primitive (such as a triangle, dot, line or polygon). Render pipe  identifies a collection of fragments that intersect a current primitive, and the texture pipe (including texture environment ) applies the multiple layers of texture to the intersecting fragments or samples within the intersecting fragments. Texture environment  stores fragment or sample color information for the intersecting fragments in TAB  between the application of successive texture layers.","The storage capacity (i.e. size) of TAB  implies a limit on the size of primitives processed by the texture pipe. To prevent overflow of TAB , a primitive sent down to the render pipe  and the texture pipe should intersect a number of fragments which is less than or equal to the fragment capacity of TAB .","In some embodiments, TAB  may store multiple samples per fragment. In these embodiments, TAB  has a fragment capacity and a sample capacity. The sample capacity is equal to the fragment capacity times the number of samples allocated per fragment. In other embodiments, TAB  stores color information for fragments and not for samples. For example, TAB  may store a single RGB color vector per fragment.","In one embodiment, the capacity of TAB  is equal to  entries, each entry occupying a predetermined number of bits. An entry may store color information for a fragment or for a sample within a fragment. More generally, TAB  may have any desired storage capacity subject to the fundamental limitations of cost, die area, complexity, etc. Powers of two are favored for the TAB capacity.","If a primitive is so large that it intersects more fragments than the TAB can store, it is subdivided into smaller primitives that individually are small enough to fit within the TAB. In one set of embodiments, vertex processor  receives vertices (or geometric parameters) defining primitives, estimates the size of the graphics primitives, compares the size estimates to the TAB fragment capacity, and conditionally performs the subdivision of primitives depending on the result of the size comparison. Thus, vertex processor  sends down to render pipe  only primitives that are \u201csize appropriate\u201d, i.e. primitives that are guaranteed to intersect a number of fragments that is less than or equal to the fragment capacity of TAB .","The size estimation may be conservative, i.e. a value may be reported which is larger than the actual number of fragments hit by the current primitive. If the size estimate for a given primitive is larger than the TAB fragment capacity, vertex processor  subdivides the primitive into subprimitives whose sizes are smaller than the TAB fragment capacity, and sends the subprimitives down to the render pipe . The union of the subprimitives (interpreted as subsets of the two-dimensional rendering space) equal the original primitive. If the size estimate for the primitive is less than or equal to the TAB fragment capacity, vertex processor  may send the primitive down to render pipe  without subdivision.","In one set of embodiments, vertex processor  may send down multiple versions of a primitive to render pipe , i.e. as many versions as texture layers which are to be applied to the primitive. Each version may contain the same vertex color and vertex positions but designates a different one of the texture layers and contains texture coordinate data corresponding to the designated texture layer. Thus, in this set of embodiments, the subsequent rasterization hardware (downstream from vertex processor ) only needs to be able to process a primitive with respect to one designated texture layer. The fragments or samples for each layer are accumulated in TAB  until the final layer is processed. After the final layer is processed, the rendered samples may be forwarded to the sample area of frame buffer , and the vertex processor  may initiate rasterization of the next primitive (e.g. by sending down multiple versions of the next primitive to render pipe ).","As mentioned above, vertex processor  may generate a conservative size estimate for each received primitive. Vertex processor  may implement any of a variety of size estimates. Typically the computational effort for a size estimate depends on the accuracy attained by the estimate. In other words, it is computationally more expensive to obtain a size estimate which stays close to the actual size of the primitive than an estimate which reports a generous upper bound for the actual size. Accurate estimates typically require more complex arithmetic hardware\u2014more multipliers, adders and subtractors. Thus, the size estimate employed by vertex processor  may depend on the time budget (e.g. the number of clock cycles) allowed for the size estimate computation and the amount of die area allocated for the size estimate circuitry. The actual size of a primitive may be defined as the number of fragments which geometrically intersect with the primitive. For example, in , eleven fragments geometrically intersect with the given triangle. Thus, the actual size of the triangle is 11.","A perfectly accurate size estimate may be desirable but expensive to implement in hardware. In contrast, an estimate that reports too generous an upper bound for the actual size may induce a large number of unnecessary subdivisions per unit time. This results from the estimate reporting size values for primitives which are larger than the TAB fragment capacity when in fact the actual sizes of the primitives are smaller than the TAB fragment capacity.","The texture pipe operates with increasing efficiency as the actual size of primitives increases up to the TAB fragment capacity. Successive read accesses to texture memory  which involve small address jumps are more likely to hit the same memory page and to hit in the texture cache (if a texture cache is implemented) than read accesses which involve large address jumps. Recall that the texture pipe makes relatively small address jumps to access successive texels (or groups of texels) for a given primitive within a texture layer and relatively large address jumps to access successive texels from distinct texture layers. Furthermore, the texture pipe completely processes the successive fragments of a primitive with respect to one layer before proceeding to the next. Thus, when processing large primitives, the texture pipe spends a larger fraction of its time making the small address jumps and a smaller fraction of its time making the large address jumps than when processing small primitives. This implies that large primitives (provided they fit within TAB ) are handled more efficiently than small primitives. The unnecessary triangle subdivisions induced by an inaccurate size estimate represent a lost opportunity to benefit from the size-related efficiency gain of the texture pipe.","Thus, while accuracy of a size estimate is desirable it may need to be balanced with issues such as implementation cost. Different tradeoffs are contemplated for different target markets.","Much of the following discussion focuses on size estimation for triangles. However, the size estimation methodologies disclosed herein naturally generalize to other primitives such as quadrilaterals, lines and dots.","In one set of embodiments, vertex processor  may generate the size estimate for a current triangle as follows. Vertex processor  may compute the coordinates for the axis-aligned bounding box that minimally contains the current triangle. The term \u201caxis-aligned\u201d means that the bounding box has sides parallel to the coordinate axes of sample space. The coordinates of the minimal bounding box may be computed by determining the minimum and maximum of the horizontal and vertical coordinates of the triangle vertices:\n\n=min{}\n\n=max{}\n\n=min{}\n\n=max{},\n\nwhere (X,Y) defines the itriangle vertex.\n","Furthermore, vertex processor  may compute a width W and height H for the minimal bounding box according to the relations\n\n\n\n.\n\nThe area of the triangle is (\u00bd)WH. Under the assumption that each fragment is a one-by-one square in sample space with edges having integer coordinates, a generic triangle may intersect a number of fragments which is significantly larger than its area (\u00bd)WH. For example, a right triangle with vertices at (0,0), (0,10) and (10,10) intersects  fragments instead of 50=(\u00bd)(10)(10) fragments. In one set of embodiments, this discrepancy is accounted for by computing an estimate E for the area (\u00bd)WH, adding a positive integer constant Cto the estimate E, and comparing the sum E+Cto the TAB fragment capacity. The value of Cmay be chosen to be an upper bound for the discrepancy between the actual number of intersecting fragments and the triangle area for all possible triangles with actual number less than or equal to the TAB fragment capacity. The value Cmay be supplied by a user, system operator, system designer, etc.\n","In another set of embodiments, the values of W and H are increased by additive constants so that the new triangle area (\u00bd)(W+\u0394W)(H+\u0394H) is guaranteed to be greater than or equal to the number of intersecting fragments. Thus, vertex processor  may perform width and height adjustment according to the relations\n\n\n\n\n\nwhere \u0394W and \u0394H are positive constants, and generate an estimate E for the new triangle area (\u00bd)WH, and compare the estimate E directly to the TAB fragment capacity.\n","In some embodiments, vertex processor  may implement the size comparison based on the following analysis. Let W and H be represented as binary words. Let \u03b1 be the bit position of the leading one in the binary representation of W. The leading one is the one bit that occur closest to the most significant bit position in the representation of W. Bit position are counted starting from zero at the least significant bit and increase with each successively more significant bit. The following table gives several examples.",{"@attributes":{"id":"p-0112","num":"0129"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"center"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"W","\u03b1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"00110101","5"]},{"entry":[{},"00000110","2"]},{"entry":[{},"10001011","7"]},{"entry":[{},"00000001","0"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"It is a basic mathematical fact that W is less than or equal to 2. A similar statement may be made for height H. Let \u03b2 be the bit position of the leading one in the binary representation of H. is less than or equal to 2.","It follows that the triangle area (\u00bd)WH is less than (\u00bd)(2)(2)=2. If the upper bound 2is less than or equal to the TAB fragment capacity, the triangle area is automatically smaller than the TAB fragment capacity N:\n\n(\u00bd)2.\n\nLet \u03b3 be the bit position of the leading one in the binary representation of N. Then 2\u2266N, and\n\n(\u00bd)2\u22662.\n\nThus, the triangle area is guaranteed to be smaller than the TAB fragment capacity if\n\n2\u22662.\n\nHowever, the last inequality holds if and only if \u03b1+\u03b2+1\u2266\u03b3, or equivalently, \u03b1+\u03b2<\u03b3.\n","Thus, in one set of embodiments, vertex processor  may determine leading one positions \u03b1 and \u03b2 for width W and height H respectively, and perform the comparison \u03b1+\u03b2<\u03b3. Observe that this comparison does not require any multipliers, and thus, may be performed quickly.","If the TAB fragment capacity Nis not a power of two, then 2<N. Thus, it is possible for a triangle to achieve the situation 2<2\u2266N, i.e. to fail the size comparison \u03b1+\u03b2<\u03b3 and yet have area upper bound 2which is smaller than the TAB fragment capacity. Such a triangle would be unnecessarily subdivided into smaller pieces. Thus, it is advantageous for Nto equal a power of 2 because in this case Nexactly equals 2.","On average, the value 2is a fairly generous upper bound for the triangle area (\u00bd)WH. Thus, it is possible for a triangle to achieve the situation\n\n(\u00bd)2<2,\n\ni.e. to fail the size comparison \u03b1+\u03b2<\u03b3 and yet have an area less than or equal to 2 which is a lower bound for the TAB fragment capacity. Thus, the triangle would be unnecessarily subdivided. For example, let W=H=4 and N=16 results in such a situation. This inefficiency (i.e. subdividing triangles that really do fit within the TAB fragment capacity) can be reduced by generating upper bounds for W and H which utilize more information than merely the leading one positions \u03b1 and \u03b2 respectively. In other words, by creating mantissas of W and H and multiplying the mantissas, vertex processor  may more closely match the targeted inequality (\u00bd)WH<2. This comes at the expense of the multipliers and barrel shifters needed to implement the refined computation. Let L represent the number of bits in the mantissa for W, and M the number of bits in the mantissa for H. As the numbers L and M increase the implementation cost increases but the rate of unnecessary subdivision decreases. Thus, the mantissa lengths L and M may be chosen to achieve an optimal tradeoff between cost and unnecessary subdivision rate. Various embodiments are contemplated with various values for mantissa lengths L and M.\n\nSubdivision\n","If a size comparison test (i.e. any of the tests disclosed herein) for a triangle fails (i.e. the triangle has too many fragments or samples to be guaranteed of fitting into TAB ), vertex processor  may subdivide the triangle (or submit a request to some external agent such as media processor  to subdivide the triangle) into smaller subtriangles.","In one embodiment, when the test fails, an exception may be generated and the primitive processing may be halted. This exception is detected by a processor (e.g. media processor ) through a means such as an interrupt. The processor reads the geometry data of the primitive and subdivides the primitive into pieces. This involves computing appropriate color vectors for the newly generated vertices. These subdivided primitive pieces each individually are small enough to fit within TAB . The processor sends each subdivided primitive piece back to the hardware accelerator  for rasterization. When all the pieces have been sent and processed, hardware accelerator  may continue with the next primitive.","Method Flowchart",{"@attributes":{"id":"p-0120","num":"0137"},"figref":"FIG. 8","b":["310","160","320","181"]},"For each primitive of the size-limited stream, the following operations may be performed. In step , one or more fragments which intersect the primitive in the rendering space may be identified. For example, in , eleven fragments intersect the given triangle. In step , a texture memory (e.g. texture memory ) may be accessed to obtain data words from one of multiple layers of texture information stored in a texture memory. In step , fragment texture values derived from the data words (e.g. by filtration) may be applied to color data vectors associated with the intersecting fragments. In step , the updated color data vectors associated with the intersecting fragments may be stored in the buffer. Steps ,  and  may be performed repeatedly for different ones of the texture information layers.","After a final iteration of steps  and , the final color data vectors may be used (e.g. filtered) to generate pixel values as indicated in step . The pixel values define a portion of a video signal. For example, video output processor  may generate a portion of a video signal using the pixel values and provide the video signal to a video output port. The video output port may couple to a display device such as a projector or monitor.","In one set of embodiments, step  (i.e. the step of operating on the input stream to generate the size-limited stream) may be implemented by (1) performing a size comparison on each primitive of the input stream to determine if an upper bound for the number of fragments intersecting the primitive is less than or equal to a lower bound for the capacity of the buffer, and (2) subdividing the primitive into subprimitives if the size comparison indicates that the upper bound is not less than or equal to the lower bound. The upper bound is a value greater than or equal to the number of fragments that intersect the primitive. Different upper bounds may be employed in different embodiments. The lower bound is a value less than or equal to the fragment capacity of the buffer. In some embodiments, the upper bound for the number of intersecting fragments equals the number of intersecting fragments, and\/or, the lower bound for the buffer fragment capacity equals the buffer fragment capacity.","In some embodiments, the size comparison on a primitive of the input stream may be implemented by:\n\n","In other embodiments, the size comparison on a primitive of the input stream may be implemented by:\n\n","In yet another set of embodiments, the size comparison on a primitive may be implemented by: (a) computing an area of the primitive; (b) determining an upper bound for the number of fragments intersecting the primitive by adding a positive marginal adjustment constant to the area; and (c) comparing the upper bound to a lower bound for the buffer capacity. The lower bound for the buffer capacity may be the buffer capacity itself.","Although the embodiments above have been described in considerable detail, other versions are possible. Numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications. Note the headings used herein are for organizational purposes only and are not meant to limit the description provided herein or the claims attached hereto."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing, as well as other objects, features, and advantages of this invention may be more completely understood by reference to the following detailed description when read together with the accompanying drawings in which:",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 2","b":"80"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 4","b":"14"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 5","b":"18"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 6","b":"24"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
