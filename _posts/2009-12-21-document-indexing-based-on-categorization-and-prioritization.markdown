---
title: Document indexing based on categorization and prioritization
abstract: Disclosed are methods and systems for improving indexing throughput. The methods and systems involve receiving one or more documents for indexing, categorizing the one or more documents based on a document type, a document size and a processing priority, assigning buckets to the categorized one or more documents according to the document type, the document size and the processing priority and scheduling the buckets for processing based on a document type priority, a bucket type and number of threads available to process the buckets.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08983958&OS=08983958&RS=08983958
owner: Business Objects Software Limited
number: 08983958
owner_city: Dublin
owner_country: IE
publication_date: 20091221
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The field generally relates to indexing documents to be searched and more specifically to techniques for improving indexing throughput.","Business Intelligence (BI) repositories are likely to contain millions of documents. Data from these repositories can be retrieved via a search engine. The search engine typically includes two operations namely searching and indexing. Indexing is a process of exploring the BI repository of documents in real-time, extracting content from the documents and storing the documents in an index. The documents stored in the index are available for searching upon a user's search request. The indexing process is a time consuming and resource consuming process. For instance, indexing a BI repository with a million documents may take a few days or even weeks.","In real-time, resources such as processor and memory available for the indexing process are limited. The resources required for indexing documents exponentially increases with the size of the document. Indexing large BI documents may overload a system to result in out-of-memory conditions, slow down of system processes and may crash system applications. Therefore, indexing large documents increases the indexing time and significantly reduces the number of documents that are available for the user's search request thereby reducing indexing throughput.","Disclosed are methods and systems for improving indexing throughput. The methods and systems involve receiving one or more documents for indexing, categorizing the one or more documents based on a document type, a document size and processing priority, assigning buckets to the categorized one or more documents according to the document type, the document size and the processing priority and scheduling buckets for processing based on a document type priority, bucket type and number of threads available to process the buckets.","These and other benefits and features of embodiments of the invention will be apparent upon consideration of the following detailed description of preferred embodiments thereof, presented in connection with the following drawings.","Embodiments of techniques for improving indexing throughput are described herein. In the following description, numerous specific details are set forth to provide a thorough understanding of embodiments of the invention. One skilled in the relevant art will recognize, however, that the invention can be practiced without one or more of the specific details, or with other methods, components, materials, etc. In other instances, well-known structures, materials, or operations are not shown or described in detail to avoid obscuring aspects of the invention.","Reference throughout this specification to \u201cone embodiment\u201d, \u201cthis embodiment\u201d and similar phrases, means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus, the appearances of these phrases in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures, or characteristics may be combined in any suitable manner in one or more embodiments.","Many of the examples used herein to describe the various aspects and embodiments of the techniques for document indexing based on categorization and prioritization are based in the subject of Business Intelligence. However, one of ordinary skill in the art will recognize that the techniques and principles described herein can be applied to any other type of documents.","Large repositories such as Business Intelligence (BI) repositories include millions of documents. BI users are able to access the data in the BI repositories through a search request. A typical search engine performs two main processes namely searching and indexing. For a BI document to be available immediately in response to the user request, the BI document should be indexed as soon as it is available. Thus, it is desirable to improve the overall throughput of indexing to index as many documents as quickly as possible. The BI repositories are never static. During its lifetime, BI documents are added, modified and deleted from the BI repositories constantly. The BI document includes meta-data and static content along with the main contents. The meta-data may include but are not limited to the title, author, description, type and last modified timestamp of the document. The static content may include but are not limited to section headers, page headers and footers, table titles, table headers, chart titles, legend titles.","The speed of indexing a given BI document may depend on several factors including its size, the type of document it is and also on the resources that are available for the indexing process. The size of the BI documents may range from kilobytes to megabytes. Indexing throughput is a measure of extracting maximum content of the BI documents that is made available to the user in a least amount of time. The time taken to extract the content of the BI document may increase exponentially with the size of the document. The indexing process also depends on the type of documents that are being indexed. The different types of BI documents may include but are not limited to Web Intelligence reports, Crystal Reports, PDF documents, word documents, etc. For instance, indexing a BI word document may require less time and resources when compared to a Web Intelligence report of the same size.","The indexing process also depends on processor and memory resources available to index BI documents. Another aspect of the indexing process is to minimize indexing load of the system. Indexing load can be defined as the resources of the system such as processor threshold, memory threshold and number of threads available for extracting content from the BI document that are assigned to perform the indexing process. The indexing load can be specified so that indexing and associated processes consume the optimal amount of resources available. The indexing process is regulated by controlling the indexing load. This is achieved by improving or decreasing the number of threads that are available for BI content extraction.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1","b":["102","104","106"]},"In an embodiment, when content is extracted from the one or more documents, the time taken for extraction is measured and stored. If the document consumes too much memory or if the extraction fails, the failure information is recorded. If extraction failed due to long processing time, consumed too much memory or resulted in any other error, the processing priority for that document is reduced to slow. Thus, a processing priority for a particular document may be determined not only based on its size but also by an actual observation of the time taken to extract its content. As a result, even small documents can have slow extraction times and be relegated to the slow prioritization category.","At process block , the buckets are scheduled for processing based on a document type priority, bucket type and number of threads available to process the bucket. The document type priority is calculated for different document types. For instance, the document type priority is calculated for PDF, Crystal Reports and word documents. If the document priority for the PDF document is more, the PDF documents are prioritized over Crystal Reports and word documents for scheduling. The document type priority depends on the extraction efficiency required to extract content from the documents. The extraction efficiency varies for different document types. The extraction efficiency for a document type is defined as the ratio of the cumulative extraction time for all documents of that type to the cumulative size of all extracted documents of that type.","The extraction efficiency Eof a document type Tis calculated using equation",{"@attributes":{"id":"p-0025","num":"0024"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["E","Tk"]},"mo":"=","mfrac":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":"\u2062","mfrac":{"msub":[{"mi":["S","i"]},{"mi":["t","i"]}]}},"mi":"n"}}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}}},"where n is the number of extracted documents of type T\n\n","The document type priority Pfor type Tis calculated using equation",{"@attributes":{"id":"p-0028","num":"0029"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["P","Tk"]},"mo":"=","mfrac":{"msub":{"mi":["E","Tk"]},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"m"},"mo":"\u2062","msub":{"mi":["E","Tj"]}}}}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}}},"where Eis the extraction efficiency of type T,","m is the number of document types and","Eis the extraction efficiency of type T.","Fast buckets are prioritized over slow buckets during processing. Multiple buckets can be processed concurrently. The number of threads available to process the bucket is determined based on an indexing load of a system. The indexing load of the system specifies a processor threshold and a memory threshold of the system to handle the indexing process.","Below is an exemplary business scenario of the scheduling process based on the document type priority, bucket and number of threads available to process the buckets. Consider three types of documents: PDF, Crystal Reports and word documents. When document type priority is calculated for these document types, the PDF documents have the first priority, the word documents and Crystal Reports have the second and third priority respectively. Therefore, the PDF documents are first scheduled for processing. Then PDF buckets are considered. Processing priority and size of the document in the buckets are also taken into consideration. Fast PDF buckets are preferred over slow PDF buckets for processing. Fast PDF buckets may have separate buckets for small sized PDF documents and large sized PDF documents. Then fast PDF buckets having small sized PDF documents are processed based on number of threads available for processing.",{"@attributes":{"id":"p-0034","num":"0035"},"figref":"FIG. 2","b":["205","210","215","215","220","220","220","215"]},{"@attributes":{"id":"p-0035","num":"0036"},"figref":"FIGS. 3A and 3B","b":["305","310","310","315","320","325"]},"At decision block , if there is a bucket with high document priority, the process proceeds to process block . At process block  bucket considered is skipped and the process is ended.","At decision block , if the bucket is not small, the process proceeds to process block . At process block , the bucket is determined as a large bucket. At decision block  it is checked if there is an age counter for the large bucket. If there is no age counter, then the age counter is started at process block  before processing the large bucket. When a large bucket is determined, the age counter is initialized to an initial age. In one embodiment, the initial age of the counter is set to five. Other suitable numbers may be configured by an administrator with knowledge about the particular circumstances surrounding the indexing process. Every time this bucket is skipped in favor of other small buckets, the age counter is decremented. When the counter becomes 0, the bucket is processed. The process then proceeds to decision block , to check if the age counter is zero. If the age counter is zero, the process proceeds to process block , to assign the thread to the large bucket for processing. If the counter is not zero, the process proceeds to decision block . At decision block , it is checked if there are any small buckets waiting to be processed. If there are any small buckets waiting to be processed, the process proceeds to process block  to decrement the age counter of the large bucket. The process proceeds to process block  to skip the large bucket and the process is ended. On decrementing the age counter, thread is assigned to the small bucket for processing. If there is no small bucket to be processed the process directly proceeds to process block  to assign a thread for processing the large bucket.","At decision block , if the bucket is not fast, the process proceeds to process block . At process block , the bucket is determined as a slow bucket. The process proceeds to decision block  to check if there is a fast bucket to be processed. At decision block , if there is a fast bucket to be processed the process proceeds to process block  to skip the slow bucket and the process is ended. If there is no fast bucket to be processed then the process proceeds to decision block .","The buckets that are skipped are picked up again during scheduling process. The scheduling process runs at regular intervals. The interval for the scheduling process is configurable. In an embodiment the interval is set to 10 seconds.",{"@attributes":{"id":"p-0040","num":"0041"},"figref":"FIG. 4"},"The indexing load on the system is regulated for processing the categorized documents by altering the number of threads available to extract contents from the categorized one or more documents when buckets are scheduled for processing. Altering the number of threads available for extracting contents of the categorized one or more documents includes increasing or decreasing the number of threads for extracting contents from the documents according to the indexing load.","The number of threads available to process the bucket is calculated using\n\n=min()\u2003\u2003(1)\n","where:\n\n","Below is an exemplary scenario of altering the number of threads available for extracting contents of the categorized one or more BI documents. Assume a system has 2 processors and a memory of 4 GB. Suppose the initial number of threads is 8(4*number of processors). Consider processor load threshold L is 50% and the memory threshold M is 40%. This implies that the maximum processor load and memory consumed should be within 50% and 40% respectively. After allowing the processes to run for some period of time, the average processor load and memory consumption are calculated.","Assume that the calculated average processor load and the average memory load is 80% and 20% respectively. Substitute the obtained values in equation (1):",{"@attributes":{"id":"p-0045","num":"0053"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"N","mrow":{"mi":"t","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}},"mo":"=","mrow":{"mi":"min","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mn":"8","mo":"*","mrow":{"mo":["(",")"],"mrow":{"mn":["50","80"],"mo":"\/"}}},{"mn":"8","mo":"*","mrow":{"mo":["(",")"],"mrow":{"mn":["40","20"],"mo":"\/"}}}],"mo":","}}}}}},{"mtd":{"mrow":{"mo":"=","mrow":{"mi":"min","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":["5","16"],"mo":","}}}}}},{"mtd":{"mrow":{"mo":"=","mn":"5"}}}]}}},"br":{}},"Assume another exemplary scenario where the calculated average processor load and the average memory load is 20%. Substituting the values in equation (1) results in",{"@attributes":{"id":"p-0047","num":"0055"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"N","mrow":{"mi":"t","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}},"mo":"=","mrow":{"mi":"min","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mn":"8","mo":"*","mrow":{"mo":["(",")"],"mrow":{"mn":["50","20"],"mo":"\/"}}},{"mn":"8","mo":"*","mrow":{"mo":["(",")"],"mrow":{"mn":["40","20"],"mo":"\/"}}}],"mo":","}}}}}},{"mtd":{"mrow":{"mo":"=","mrow":{"mi":"min","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":["20","16"],"mo":","}}}}}},{"mtd":{"mrow":{"mo":"=","mn":"16"}}}]}}},"br":{}},"At process block , the indexing load of a system is determined. At process block , the number of threads available to process the bucket is determined. At decision block  it is checked if the number of threads available processes the bucket within the indexing load limit. If yes, the process proceeds to process block  to process the bucket. If no, the process proceeds to process block  to alter the number of threads available. The process again proceeds to decision block .",{"@attributes":{"id":"p-0049","num":"0057"},"figref":"FIG. 5","b":["500","500"]},{"@attributes":{"id":"p-0050","num":"0058"},"figref":"FIG. 6","b":["600","605","610","635","640","610","615","620","625","630"]},"The data repository  includes meta-data and content of one or more documents to be indexed. The documents include but are not restricted to Web Intelligence reports, Crystal Reports, PDF documents, word documents, etc. A processor (not shown in the figure) in communication with the memory and storage may include instructions for the content extraction engine  and indexing engine  to perform required operations. The repository crawler  in the content extraction engine  retrieves the one or more documents from the data repository . The categorizer  categorizes the retrieved one or more documents based on the document type, document size and processing priority. The categorizer  assigns buckets for the categorized documents. The categorized one or more documents are assigned to fast or slow buckets based on the document type, document size and processing priority. The buckets are in-memory objects. Multiple buckets can be processed concurrently. Scheduler  specifies an order according to which the buckets are processed. The content extractor , extracts the content from the one or more documents in the buckets and converts them into a standard XML form in preparation for indexing, and stores the extracted content. In an embodiment the extracted content is stored in temporary files on the file system. The content extractor  uses multiple threads for extracting content from one or more documents. These threads consume processor and memory resources. The number of extraction threads are regulated to keep processor and memory consumption under a threshold specified for indexing. The number of threads required for extraction can be increased or decreased to maintain an indexing load. The indexing load specifies the processor threshold and memory threshold required to regulate the load of a system for indexing. The indexing engine  receives the extracted content of the one or more documents from the content extractor  in the form of XML files. The extracted content is indexed and added to the index . The index  is a repository where the one or more indexed documents are stored. The content in the index  is available as a search response to a user's search request.","Some embodiments of the invention may include the above-described methods being written as one or more software components. These components, and the functionality associated with each, may be used by client, server, distributed, or peer computer systems. These components may be written in a computer language corresponding to one or more programming languages such as, functional, declarative, procedural, object-oriented, lower level languages and the like. They may be linked to other components via various application programming interfaces and then compiled into one complete application for a server or a client. Alternatively, the components maybe implemented in server and client applications. Further, these components may be linked together via various distributed programming protocols. Some example embodiments of the invention may include remote procedure calls being used to implement one or more of these components across a distributed programming environment. For example, a logic level may reside on a first computer system that is remotely located from a second computer system containing an interface level (e.g., a graphical user interface). These first and second computer systems can be configured in a server-client, peer-to-peer, or some other configuration. The clients can vary in complexity from mobile and handheld devices, to thin clients and on to thick clients or even other servers.","The above-illustrated software components are tangibly stored on a computer readable medium as instructions. The term \u201ccomputer readable medium\u201d should be taken to include a single medium or multiple media that stores one or more sets of instructions. The term \u201ccomputer readable medium\u201d should be taken to include any physical article that is capable of undergoing a set of physical changes to physically store, encode, or otherwise carry a set of instructions for execution by a computer system which causes the computer system to perform any of the methods or process steps described, represented, or illustrated herein. Examples of computer-readable media include, but are not limited to: magnetic media, such as hard disks, floppy disks, and magnetic tape; optical media such as CD-ROMs, DVDs and holographic devices; magneto-optical media; and hardware devices that are specially configured to store and execute, such as application-specific integrated circuits (\u201cASICs\u201d), programmable logic devices (\u201cPLDs\u201d) and ROM and RAM devices. Examples of computer readable instructions include machine code, such as produced by a compiler, and files containing higher-level code that are executed by a computer using an interpreter. For example, an embodiment of the invention may be implemented using Java, C++, or other object-oriented programming language and development tools. Another embodiment of the invention may be implemented in hard-wired circuitry in place of, or in combination with machine readable software instructions.",{"@attributes":{"id":"p-0054","num":"0062"},"figref":"FIG. 7","b":["700","700","705","755","700","740","755","710","715","710","715","705","715","700","725","730","700","725","730","700","735","700","750","750","700","745","700","720","760","760","760","750","760"]},"A data source is an information resource. Data sources include sources of data that enable data storage and retrieval. Data sources may include databases, such as, relational, transactional, hierarchical, multi-dimensional (e.g., OLAP), object oriented databases, and the like. Further data sources include tabular data (e.g., spreadsheets, delimited text files), data tagged with a markup language (e.g., XML data), transactional data, unstructured data (e.g., text files, screen scrapings), hierarchical data (e.g., data in a file system, XML data), files, a plurality of reports, and any other data source accessible through an established protocol, such as, Open DataBase Connectivity (ODBC), produced by an underlying software system (e.g., ERP system), and the like. Data sources may also include a data source where the data is not tangibly stored or otherwise ephemeral such as data streams, broadcast data, and the like. These data sources can include associated data foundations, semantic layers, management systems, security systems and so on.","The above descriptions and illustrations of embodiments of the invention, including what is described in the Abstract, is not intended to be exhaustive or to limit the invention to the precise forms disclosed. While specific embodiments of, and examples for, the invention are described herein for illustrative purposes, various equivalent modifications are possible within the scope of the invention, as those skilled in the relevant art will recognize. These modifications can be made to the invention in light of the above detailed description. Rather, the scope of the invention is to be determined by the following claims, which are to be interpreted in accordance with established doctrines of claim construction."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The claims set forth the embodiments of the invention with particularity. The invention is illustrated by way of example and not by way of limitation in the figures of the accompanying drawings in which like references indicate similar elements. The embodiments of the invention, together with its advantages, may be best understood from the following detailed description taken in conjunction with the accompanying drawings.",{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIGS. 3A and 3B"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
