---
title: Integration of sketch-based interaction and computer data analysis
abstract: Architecture that integrates the benefits of natural user interaction such as freeform sketch with computer-aided charting. The architecture integrates natural user interaction utilizing multiple modalities (e.g., sketch, multi-touch, etc.) with computer supported data analysis that allows users to explore data by drawing charts using simple strokes. Natural user interactions can be utilized to change chart types by drawing symbols, transform data by applying functions, filter data by drawing strikethrough on legends, etc. Additionally, the architecture makes an inference of visualizations the user intended from user-drawn strokes, such as the axes of a graph, the words of a label, etc. When appropriate, the architecture automatically completes visualizations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08994732&OS=08994732&RS=08994732
owner: Microsoft Corporation
number: 08994732
owner_city: Redmond
owner_country: US
publication_date: 20110307
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Information visualization systems focus on the common technical setup of a mouse, a keyboard, and a desktop display. This practice of providing visualization support only for solo desktop work ignores other exploratory phases of information work, such as preliminary sketching (on papers or whiteboards) to work out ideas and approaches to analyzing the data.","The use of paper and whiteboards among information workers is ubiquitous. Ideas, problems, and planning are oftentimes worked out initially in an informal venue. However, if the information work involves large amounts of data, it is soon necessary to make use of computational power in some tools (e.g., a spreadsheet).","Despite its familiarity and inherent benefits, the traditional whiteboard is fundamentally limited by its passive nature. All content shown must be drawn directly. For example, if charts and graphs are employed to show data, each data item must be drawn by hand. Thus, data charts on whiteboards tend to be relatively simple since drawing many data points one-by-one is tedious even for the cases where accuracy is not critical. Data-rich problem solving on a whiteboard can either be exceptionally tedious, or result in using partial or merely indicated charts and graphs.","In addition, sketched data accuracy is challenging and the quality of the plots is limited by memory; only general trends can be drawn from recollection to any real extent. Hand drawn charts are also limited in that useful functions on data are not easily estimated. Standard deviation, cardinality, and even arithmetic mean can be difficult to estimate with any accuracy, but are vital tools in the initial steps of data analysis. In other words, there is a big gap between what people think and draw on whiteboards and how people can manipulate data in the computer.","The following presents a simplified summary in order to provide a basic understanding of some novel embodiments described herein. This summary is not an extensive overview, and it is not intended to identify key\/critical elements or to delineate the scope thereof. Its sole purpose is to present some concepts in a simplified form as a prelude to the more detailed description that is presented later.","The disclosed architecture integrates the benefits of freeform sketch-based interaction with computer-aided data analysis and processing, at least in support of charting. A user can apply a simple sketched mark (also called a stroke) to an interactive component (e.g., a whiteboard), and then one or more strokes are processed to suggest a graphical representation (e.g., a chart, arrow) that is then generated and presented proximate, alone or in combination with the applied stroke for viewing via the interactive component. The generated graphical representation need not be beautified by the computing system, but be the same or similar to the hand-based stroke the user applied. In response, the architecture can plot items on the chart populated from a user dataset.","By drawing (applying one or more strokes) on the resulting graph, the user interacts with the user's own data, changing the resulting visualization dynamically, leading to a more fluid and less intrusive experience. Thus, the user can readily explore the data visually through the use of graphical representations such as scatter plots and bar charts. Moreover, analysis is easily accomplished through the application of functions to the user data. Sketch-based interactions can be utilized to change chart types (e.g., by drawing symbols), transform data (e.g., by applying functions), filter the data (e.g., by drawing a strikethrough on a legend item), etc. Additionally, the architecture makes an inference of visualizations the user intended from user-drawn strokes, such as the axes of a graph, the words of a label, etc.","By targeting more of quantitative analysis and data exploration, these principles enable non-expert users, for example, to rapidly explore the data in its visualization.","To the accomplishment of the foregoing and related ends, certain illustrative aspects are described herein in connection with the following description and the annexed drawings. These aspects are indicative of the various ways in which the principles disclosed herein can be practiced and all aspects and equivalents thereof are intended to be within the scope of the claimed subject matter. Other advantages and novel features will become apparent from the following detailed description when considered in conjunction with the drawings.","The disclosed architecture combines the casual sketching approach of paper or whiteboards with a computer's computational power to provide data exploration capabilities of computer-aided data visualization. The hand drawn appearance can be preserved and, alternatively or in combination therewith, the drawing can be processed into a more polished result. The strokes can be processed as vector entities to be fully recognizable and functional. An auto-complete functionality is supported as well.","The architecture supports multiple ways to sketch visualizations. Moreover, alternative interaction approaches are provided. For example, to specify axes for a chart, the user can draw axes and specify the axes via a handwritten axis label, draw axes and specify the axes via placing one or two data points (with data point values for each axis), and\/or draw axes and specify the axes via placing and labeling tic marks with values. Tailored data views can also be provided so the user can preview data before the user starts the draw process.","The architecture can also provide suggestions and recommendations from available data in a nonintrusive manner. Additionally, gesture and visualization auto-complete functionality can be provided where appropriate.","The architecture supports sketch-based methods for users to perform a set of actions that are common in data exploration. Examples include adjusting range\/scale for each axis, applying functions (e.g., average, standard deviation, minimum, maximum, count, etc.) without having to re-draw the visualization, sorting\/reordering, filtering, etc. In addition, the architecture provides ways to specify visual variables such as color and shape, as well as providing seamless switching between different views and different chart types (or visualizations).","The architecture can also provide ways to access to data incrementally, rather than showing the entire dataset. Thus, the user can start with a subset of the data of interest and incrementally request more data. The architecture can also assist in workflow by seamlessly performing peripheral tasks such as tracking history, forking exploration, and showing multiple visualizations for comparison, etc.","Recognition can be operationally harmonized. Linked and re-usable APIs provide seamlessly handling of the range of input modalities (e.g., pen and multi-touch) and the gestures, strokes, hand postures, and symbolic characters generated.","When using charts, for example, a user can apply simple sketched marks such as lines, arcs, etc., (also referred to as strokes\u2014the fundamental objects of the architecture) to suggest a chart to view. In response, the architecture can plot and render items on the chart populated from user data. By further interacting (e.g., drawing) with the chart users can interact with the data, and changing the resulting visualization on-the-fly, thereby leading to a more fluid and less intrusive experience.","In one implementation, a digital whiteboard is produced that emulates a traditional whiteboard, yet allows multiple, disjoint ideas (e.g., sketches) to appear on the board concurrently. Thus, a single user can interact with one or more charts\/graphs, for example, or multiple users can interact collaboratively with one or more charts\/graphs. Another example implementation can utilize a tablet PC for individual data exploration or even multiple user interaction, if desired.","In contrast to traditional systems that employ the notion of modes, the disclosed architecture permits all applications to interpret strokes independently and concurrently. The architecture observes (recognizes) user strokes and uses that knowledge to provide a service. In one implementation, the architecture is strictly stroke-driven in that there are no or minimal menu bars utilized on (e.g., around the outside of) the screen. However, this is not to be construed as limiting in any way, since other suitable user input technologies can be employed. For example, drawn strokes such as the axes of a graph or the words or letter of the user input are observed (received and recognized), and visualizations the user intended from this are inferred to complete the graphical representation (e.g., chart).","Although described herein primarily with user input as being stroke-based, it is to be understood that other input modalities that facilitate user interaction can be employed separately or in combination therewith, such as via menus and touch-based interaction.","The architecture provides users with a user input interface (e.g., sketch-based, pen-based, touch-based, etc.) operating in combination with computer-aided analysis to visually explore user data. Once user input is received, the architecture recognizes and computer-generates graphical objects associated with the input. For example, if the input is one or more user strokes (e.g., line with arrowhead) applied as marks (e.g., using a marker pen) to a whiteboard surface, the one or more strokes can then be recognized and rendered as a graphical object that is an arrow. This arrow graphical object can then be presented proximate the user-applied stroke in a cleaned-up version or as a captured rendition (image) of the user-applied stroke.","The architecture encourages collaborative data exploration through user inputs that include the user sketching or introducing strokes to a visualization interface (also referred to as a digital interactive component). Sketched lines and handwritten text can be easily erased or modified. Moreover, the architecture encourages users to explore data in different perspectives and thereby discover novel insights. Thus, strokes drawn by users can be maintained in the view to encourage erasure and modification.","Collaboration is facilitated such that multiple users can apply strokes, which are then dynamically processed to present the associated graphical objects, and to then operate on the user data under inspection. In the context of a large drawing surface such as a pen-based interactive display, for example, collaboration is supported using multiple active pens, where the pens provide a tool for interacting with a pen-based interactive visualization surface. Since people already use whiteboards in discussions and presentation contexts, the disclosed data exploration interactive architecture enhances the naturally collaborative environment familiar to users.","The disclosed architecture provides for direct manipulation (interaction) to not only minimize the cost (e.g., time) of creating new charts and modifying existing charts, but also to expedite the learning curve for novice users. Existing techniques using a spreadsheet, for example, require multiple steps, including the selection of the proper menu items and performing multiple selections to configure chart parameters. In contrast, the disclosed architecture enables direct user interaction without complex menu navigation, and emulates activities normally associated with sketching a chart on a whiteboard, for example.","The freeform nature of the architecture interface enables users to draw whatever may be conceived in as much or as little detail as desired. The user can visualize charts to express expected trends as well as to present existing trends as observed in the data. Quick sketches allow users, individually or collaboratively, to rapidly and simply try different options, discover correlations and outliers, and filter and summarize the data.","Reference is now made to the drawings, wherein like reference numerals are used to refer to like elements throughout. In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding thereof. It may be evident, however, that the novel embodiments can be practiced without these specific details. In other instances, well known structures and devices are shown in block diagram form in order to facilitate a description thereof. The intention is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of the claimed subject matter.",{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 1","b":["100","100","102","104","104","106","102","104","108","110","112","110","108","106"]},"The user data  is shown as the graphical representation  to simply convey that the qualitative and\/or quantitative information user data  can be characterized by the graphical representation  that can be a set of graphical objects. In an alternative implementation, it is within contemplation of the disclosed architecture that the some or all of the user data under observation can be presented in its raw or tabular form, separately or in combination with the graphical representation  via the interface component .","The graphical representation  can be provided by the computation component  as comprising one or more graphical objects (e.g., the axes of a chart, tic marks, etc.). For example, where the user input is a raw stroke (e.g., hand sketched on a whiteboard surface using marker pen) intended to be an arrow, the computation component  can capture this input and render the same stroke as a graphical object in the graphical view . Thus, the raw stroke can be rendered in its rough (captured as a freeform unstraightened, unsymmetrical, etc.) format as manually created by the user, proximate to the raw stroke on the board surface.","Alternatively, the raw stroke can be presented as \u201ccleaned-up\u201d (e.g., straight, symmetrical at the points, etc.) arrow object by the computation component  retrieving a predetermined and stored arrow object that is accessed and then presented in the graphical view . In any case, the resulting graphical view  can include only the raw stroke, only the rough stroke, only the cleaned-up stroke, or any combination thereof.","A presentation component  receives rendering information from the computation component  and presents this rendering information in the graphical view  as comprising the stroke (rough or cleaned-up), labels, lists, and other graphical objects, interactive or otherwise, in association with the digital interactive component . In other words, the graphical view  can be projected onto the interface component , which can be a digital whiteboard, by a projector, which is the presentation component .","Where the interactive component  is a pen-based display or touch-based display, for example, the presentation component  can be part of the computation component  or part of the display such that the graphical view  can be presented via the display capabilities of the pen-based or touch-based display.","The computation component  can include a data analysis and processing component  that can access the user data  through a data component . The data component  can be a database on a server, distributed database, files on a local client, in-memory data, etc., that makes available the user data  (e.g., dataset) for manipulation and interaction via one or more of graphical representations  (e.g., the graphical representation ). In yet another implementation, the data component  can be part of a cloud computing infrastructure.","The graphical objects are the objects used to digitally render or display a chart axis, tic marks on an axis, text, dimensions, a captured user stroke, a box, a line, etc. The graphical objects can change and\/or update based on one or more of the user interaction(s) . In contrast, the user data  is the data which the user desires to examine (e.g., sales data, financial data).","With respect to user interaction, if the user interaction  is to change the scale on the y-axis of a graphical representation such as a chart, the data analysis and processing component  adjusts the scaling of an axis according to a stroke that the user applies to an axis. Additionally, the data analysis and processing component  processes the dataset (user data ) under inspection by the user according to the new user interaction .","Note that graphical objects can be associated with an application (e.g., charting program, operating system) that provides the capability to perform graphic and charting generation and manipulation, as well as to provide extensibility to add new options for processing and presenting new graphical representations.","As previously described, the digital interactive component  (e.g., active or passive visualization surface) can be a digital whiteboard, interactive display surface, touch surface, pen-based surface, or simply a computer monitor via which the user interacts using a mouse or other pointer-driven user input device, for example, and include the appropriate software (e.g., presentation, operating system, charting\/graphing, etc.) to assist the particular digital interactive component  to recognize and process the user interaction.","The data analysis and processing component  (e.g., a computer subcomponent) performs data analysis by applying data analysis functionality (e.g., operations that includes function(s), delete, filter, mathematical operations, scale, etc.) on the user data  in response to the user interaction . For example, if the user applies a stroke to the y-axis of a chart that then is inferred by the system  to establish the scaling for that axis, the system  automatically applies the remaining tic marks for the y-axis. The data analysis and processing component  then automatically performs data analysis on the dataset under inspection (the user data ) to fit the chart (the graphical representation ).","The presentation component  (e.g., projector system, display surface, touch surface, pen-based surface, etc.) presents the one or more graphical objects in association with the graphical representation  as changed by the operation. In one implementation, the user interaction  is captured and interpreted from the digital interactive component  which is a whiteboard, and then once processed (e.g., inferred) to determine the user intended to draw a graph, the resulting graphical objects are then projected (by a video or camera system) onto the whiteboard for visualization by the user and other viewers in accordance with characterizing the user data  according to the desired dimensions and formats.","In another example, the user interaction  is captured and interpreted from the digital interactive component  which is a touch-based surface or display, and then once processed (e.g., inferred) to determine the user intended to draw a graph, the resulting graphical objects are then presented via the touch-based device (display) for visualization by the user and other viewers (local and\/or remote) in accordance with characterizing the user data  according to the desired dimensions and formats.","Note that the graphical representation  is just one of many of the graphical representations  that can be employed and utilized. For example, the graphical representation  can be a bar chart, scatter plot, polar coordinate graph, etc. Additionally, the number and type of representations and associated strokes can be extensible to add new strokes and corresponding representations for use.","The system  provides the capability of auto-completion of the graphical representation  and auto-completion based on user interaction(s)  to the graphical representation . In other words, the user interaction  can suggest the graphical representation , which can be an arrow, axes of chart, bar, etc. Note that in a touch-based interface the user interaction  can comprise a single touch or multi-touch gestures that can be combined with hand postures, for example.","The computation component  can comprise a recognition component  that receives the one or more interactions (e.g., strokes) from a user interaction collector , which can be a component that receives the user interaction(s)  as applied (input) by the user(s). The recognition component  recognizes the interaction and generates a result that facilitates the presentation of the graphical representation  suggested by the interaction.","The recognition component  employs one or more recognizers that process the user interaction  for the graphical representations  such as arrows, charts, etc. Additionally, the recognition component  handles annotations  (internally) associated with the graphical representations . An annotation is a passive data collection associated with an interaction (e.g., stroke). The user does not interact with an annotation. The annotation performs basic transformations of its underlying data (e.g., an arrow annotation may retrieve the \u201cobject\u201d at which the arrow annotation points). User interaction  first passes through the recognizers of the recognition component , which recognizers in turn may modify annotations . During a redraw event, renderers of the rendering component  read this information and display it.","A rendering component  includes different renderers for rendering data in the annotations . The rendering component  can include different renderers for different graphical representation types (e.g., chart, arrows, bars, legend, label menu, etc.). Although depicted as part of the computation component , the recognition component  and rendering component  can be implemented external thereto. For example, the rendering component  can be part of the presentation component .","The user interaction(s)  can include many different types of interactions (e.g., strokes) such that when processed present the corresponding user data  as part of a new or updated graphical representation (of the graphical representations ).","The recognition component  adds an annotation (of the annotations ) in combination with the graphical representation . The interactive component  allows the user interaction  to be applied directly to a visualization interface (e.g., display surface, whiteboard, etc.) by a user. The stroke can be a freeform stroke (sketch-based) input by a user (e.g., marker pen, digital pen, touch, etc.) and recognized for completion of the graphical representation  by the recognition component . This auto-completion feature applies equally well to other user input modes described herein, such as for touch-based inputs, pen-based inputs, etc.","The sketch-based interactions can change the graphical representation  based on symbols, transform the user data  by applying a function, and filter the user data  by removing an item of a legend from consideration (e.g., by applying a strikethrough stroke over the legend item). The user interaction  can comprise multiple input strokes that are processed to operate on the graphical representation  and associated user data  or generate a new graphical representation that characterizes the user data  in a different visual way.","The digital interactive component , data analysis and processing component , recognition component , rendering component , and presentation component  facilitate the receipt, processing, and presentation of multiple concurrent user interactions, associated suggested annotations to be retrieved for the multiple concurrent user interactions, and corresponding graphical representations.","The user interaction  can be interpreted to change the graphical representation  based on symbols, transform the user data  by applying a function, and filter the user data  by deleting a menu item from consideration (using a strikethrough stroke as the user interaction ). The user interaction  can be a freeform stroke applied directly by a user to the digital interactive component (e.g., a touch-based surface, pen-based surface, etc.).","The user interaction  can comprise multiple interactions (from a single user or multiple users) which include a second stroke that when processed presents the user data  as part of a new graphical view suggested by a combination of the stroke and the second stroke. The user interaction  can comprise multiple strokes from multiple users that are processed concurrently to operate on the graphical view  and associated user data  or to generate new graphical view of the user data . The presentation component  projects user data as characterized by the graphical representation  and a menu item onto the digital interactive component  in realtime in response to the user interaction .",{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 2","b":["200","202","126","204","200","202","122","202","126","204","128"]},"Information can be provided as the annotations , which annotations  are then associated with sets of strokes (e.g., pen-based). As strokes are added to the board (visualization surface, component, or interface), relevant features (e.g., arrow) are recognized, and appropriate annotations are added. Likewise, as strokes are erased (removed from consideration), the system  deletes the relevant annotations and ensures that the state of the system  is consistent with the erasure.","The recognizers  can include a chart recognizer, arrow recognizer, bar recognizer, legend recognizer, and label menu recognizer, just to name a few. The chart annotations  include, but are not limited to, a shape legend, label menu, color legend, function menus, axes menus, axes arrows, and so on. The rendered chart (graphical representation ) can include as set of graphical objects such as axes, tic marks, legends, points, bars, one or more label menus, arrows, and so on.","In one implementation, a registry of the recognizers  can be maintained along with a formal description of the patterns associated with the recognizers. Alternatively, each recognizer can implement its own patterns arbitrarily, and hence, there is no global description repository utilized. The recognizers  \u201clisten\u201d for updates to the system, whether the updates are new strokes (drawn by the user) or new annotations (added by other recognizers). When a stroke is added to the board (visualization surface), all listening recognizers are notified so that each recognizer can check in turn if the stroke matches the type of item that the recognizer is looking for.","A single stroke may trigger several stroke recognizers  and be matched successfully by all of the recognizers . Thus, strokes can have multiple overlapping annotations  as well. For example, strokes may be interpreted as an arrow as well as the letter \u201ct.\u201d In the case where these interpretations coexist, the ambiguous interpretation is left alone. When one interpretation excludes the other, higher level recognizers may remove a conflicting annotation (e.g., arrows recognized as axes are stripped of any textual annotations). Once an update occurs, it is up to the recognizers  to modify the annotations  appropriately to ensure that the underlying meaning of each annotation matches the strokes on the board.","Several different annotations  on strokes can be maintained by the recognizers , including, but not limited, to the following. Additionally, the following are but some examples in which the strokes can be implemented.","Arrows: users can begin the charting process by drawing two arrows (each input individually) for axes. In one design, single-stroke arrows can be utilized for performance reasons. Arrow annotations  are maintained by an arrow recognizer, which \u201clistens\u201d (or observes) for raw strokes shaped like arrows.","Charts: upon recognizing two (nearly) intersecting arrows as axes, the system creates a chart annotation for that chart. Within this structure is stored the semantic information for the chart, including the backend data sets loaded by the user, logical placement of x- and y-axis tic marks on the axes, and which columns are loaded into which axes. The chart annotation is created by a specific recognizer that listens only for intersecting arrows, but once instantiated, it is managed by its own chart recognizer that listens for axis tics (raw strokes) and axis label (text menu\/legend annotation) updates. As users add strokes to the system, the strokes are annotated internally as needed, and the results cascade up to the encompassing chart annotation. By handling multiple chart annotations independently, users are allowed to draw any number of charts that will fit on the screen (visualization surface or interface component).","Axis Legends: Created with each chart annotation are two legend annotations, one each for the color and shape axes. These data structures hold data about which data column is selected for that axis (through a label menu annotation) as well as filters applied to that column's data. These annotations are kept up-to-date by the legend recognizer that listens for raw strokes that cross out values populated from the column, and changes to label menu annotations that modify which data column is selected for that axis.","Label Menus: label menu annotations can have two forms. The first and simplest form defines an area for text entry. As users write in the area, the associated label menu recognizer monitors the resulting text annotations (e.g., as returned from queries to libraries), and chooses the first partial match among the possible options. For example, given a list of column names (e.g., \u201cCountry,\u201d \u201cPopulation,\u201d \u201cYear\u201d) as options, the label menu sets its choice as \u201cCountry\u201d as soon as a set of strokes are annotated as \u201cC,\u201d \u201cCO,\u201d \u201cCOU,\u201d etc. A second type of label menu displays the list of available options below the text entry area. Users may then circle the option the user desires to select. With this type of label menu, the menu recognizer also listens for raw strokes that circle options. Once an option is circled, the recognizer updates the annotation by setting its choice. A third type can incorporate a combination of the other two such that as the user writes text, the system shows a list of column names that matches (i.e., contains) the entered text.","Bars: when a user draws a bar-shaped stroke on the visualization surface or interface, a listening bar recognizer creates a bar annotation. The chart recognizer then checks whether the bar defined in that annotation crosses (intersects) the x-axis, and changes its chart annotation to a bar chart if the intersection exists.","While the recognizers  update and manage the underlying data of annotations, the renderers  have the task of displaying to the user the state defined in the annotations . Each annotation\/recognizer defines a method of interaction, the details of which are communicated to the user by changing the look of the board. Rendering can be restricted to adding graphics to the board (without removing or cleaning up user strokes) in order to encourage users to modify the charts through the previous strokes.","The chart rendered overlays straight lines over the user-drawn axes and tic marks, and draws colored points\/symbols\/bars at the correct position on the board. It then calls label menu and legend renderers to print text from the recognized results of handwriting in the text entry areas of the chart.","The recognizers  can be associated with specific annotations  and renderers . For example, a chart recognizer  can have a chart annotation  and a chart renderer  (that rendered axes, tics, legends, points, and bars, for example). Similarly, a bars recognizer  can have the same chart annotation  and a chart renderer . An arrows recognizer  can have an x\/y axis arrows annotation , and arrows renderer . A legend recognizer  can have a shape legend annotation  and a color legend annotation . A label menu recognizer  can have a shape legend label menu annotation , color legend label menu annotation , function menu annotation , and an x\/y axis menus annotation , as well as a label menu renderer . As shown, these are only but a few of the possible recognizers, annotations, and renderers that can be employed.","Put another way, an interactive system is disclosed that includes a digital interactive component that receives user interaction as a stroke applied directly thereto, a recognition component that recognizes the stroke and manages an annotation associated with a set of strokes, a rendering component that renders state defined in an annotation, a data analysis and processing component that performs an operation on user data based on the graphical representation to create a graphical view of the user data, and a presentation component that presents the graphical view of the user data in association with the stroke and the digital interactive component.","The presentation component can project the graphical view, and a characterization of the user data based on the graphical representation onto the digital interactive component in realtime response to the user interaction. The user interaction can be a freeform stroke that suggests at least one of a chart, graph, arrow, legend, menu, scaling, filtering, colorization, data transformation, or erasure. The user interaction is interpreted and recognized to enable analysis of the user data. The user interaction is processed to enable change of the graphical representation based on symbols or gestures, transformation of the user data via a function, and filtering of the user data, etc. The user interaction can comprise multiple sketch-based strokes applied to the digital interactive component and recognized concurrently to create corresponding suggested graphical representations.",{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIGS. 3-5"},{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 3","b":["300","302","304","306","302","304","306","302","308","310","304","306","304","306"]},"The user can then choose to analyze the data by country, and perceives that \u201cCountry or Area\u201d is an option in a list  of columns on the left of the surface . Accordingly, the user scribes a letter \u201cC\u201d in a label area  (which can be marked \u201cX-Axis\u201d) next to the horizontal axis . The system recognizes the stroke as text, when the user lifts the input device (e.g., a light pen) and chooses \u201cCountry or Area\u201d of the list  as the best choice for axis label. Labeled tic marks can then also appear (be applied) on the machine-generated x-axis  for a subset of the data values in that column.","If the user then wants product rates on the y-axis , the user scribes a letter \u201cR\u201d (for \u201cRate\u201d) in a label entry area  (e.g., marked \u201cY-Axis\u201d). The system then labels the y-axis  as \u201cRate\u201d and adds labeled tics (e.g., RATE, RATE, etc.) to the y-axis , spaced evenly across the range of values in the \u201cRate\u201d column. Upon populating the x- and y-axes, the system then draws a point corresponding to each row by its values in each column (e.g., a row for COUNTRY that has a rate of RATE will be plotted accordingly).","If the user now desires to view the maximum rate for each country, the user can apply a maximum function over data for each country via a function menu . For example, the user finds the function menu  and draws a circular stroke around the function menu item \u201cMAX\u201d to select a maximum function. In response, the system will then present each country by a single point (not shown).","Note that the user can manually write the word \u201cfunction\u201d or draws a gesture to specify function on the interactive surface , which is then recognized and interpreted to result in the interactive function menu to be presented by the computation component. Similarly, the user can manually write the word \u201ccolor\u201d or draws a gesture for color on the interactive surface , which is then recognized and interpreted to result in the interactive color menu to be presented by the computation component.",{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIG. 4"},"If the user now wishes to see the average rate for each country, the user can erase the selection stroke encircling \u201cMAX\u201d, and instead, sketch a letter \u201cA\u201d in over the function menu. The system immediately recognizes the text as indicating the selection of the choice \u201cAVERAGE\u201d, and then distills each country's data points down to the average of all the rates for that country.","Additionally, the user can then alter the chart  to see the rate per year. Thus, the user begins sketching the letters \u201cyear\u201d in the x-axis area after erasing the letter \u201cC\u201d used to specify COUNTRY OR AREA, and the system recognizes the sketches and changes the x-axis dimension from country to year. The system automatically re-processes the user data to meet the chart axis dimensions and gradations.","The user can choose to see the data in the form of a bar chart. For example, the user can scribe a partial rectangle  intersecting the x-axis (the general shape of a \u201cbar\u201d), whereupon the small circles making up each point in  are erased, and replaced with a bar.  illustrates a bar chart automatically created based on suggested user freeform input. Note that the user can switch to a bar chart even when there are multiple y-axis values. Switching the style of chart in traditional tools typically requires traversing a set of menus and windows. In contrast, and in accordance with the disclosed architecture, the data changes its representation in-place, thereby allowing users to stay focused on the data, rather than the interaction method.",{"@attributes":{"id":"p-0087","num":"0086"},"figref":["FIG. 6","FIG. 4","FIG. 6"],"b":["300","1","2","1","2","3","1","1","2","2"]},"Referring again to , as the user continues by scribing a letter \u201cS\u201d in the label area marked \u201cShape?\u201d, the unique values in the \u201cSource Level \u201d column (e.g., \u201cPolice\u201d and \u201cPublic Health\u201d) of  are populated beneath the label, each next to a small glyph corresponding to that value's symbol (e.g., Symbol S, and symbol S), and the points in the scatter plot retain their color from the previous operation, but change shape according to the shape legend axis.","Generally, in accordance with , the user enters the vertical stroke  and the intersecting horizontal stroke . The system automatically recognizes intersection as suggesting axes for the chart . Additionally, for axis dimensions, freeform input such as an \u201cR\u201d for rate on the vertical stroke  is recognized as text, and the system automatically inserts RATE proximate the vertical stroke  (or axis ). Similarly, the freeform strokes to spell \u201cyear\u201d are inserted proximate the horizontal stroke  (or axis ), which strokes are interpreted (recognized) by the text recognizer as YEAR, and accordingly, the term YEAR is presented in the visualization surface  along the horizontal stroke .","Where the user wants to explore a dataset that charts the product rates of several different countries over the years in the 1990's and 2000's, the user begins by selecting to load the user dataset into the tool (the disclosed architecture).","Once the dataset is loaded, the user can then draw the strokes ( and ) on the visualization surface  (e.g., a pen-based tablet), and the system automatically retrieves and presents annotations related to the chart  for user interaction. Once the user roughly scribes the vertical axis gradations (also referred to as tic marks or tics) and the horizontal gradations, the system automatically overlays input areas for the X, Y, Color (C=color ), and Shape (shape S=X, and shape S=\u0394) axes around the hand drawn axes.","Since the interface is fit to the user strokes ( and ), the user can just as easily draw multiple small charts, a single large chart, or any combination of charts that the user desires. (In traditional tools, viewing multiple charts at once is inefficient, since the interaction involves opening and arranging windows in a screen.)","Traditional tools require people to change modes from drawing to specify the mapping of columns to axes, either through a set of menus and windows, or by dragging a column value from a list. The disclosed architecture method of writing in axis labels provides a direct means of modifying the final graph and does not require any special knowledge about particular menu options.","The architecture also facilitates scaling and filtering. In order to view the differences in some closely clustered points, the user can choose to rescale the y-axis such that the lower rates are shown higher on the graph. This can be accomplished by sketching a small horizontal tic mark across the y-axis, which is initially labeled with the current value at that point on the axis and a box to prompt for text entry. The user can then scribe a scale value in the tic's text box, and the axis values rescale such that the scale spans from zero to the hand-drawn tic (of the scale value), and the remaining values form the scale value through the maximum value span the rest of the vertical axis.","Filtering may rescale the axis. The user can alternatively draw a short line through the text \u201cCountry\u201d in the color legend. Once the text is crossed out, the text turns a different color (e.g., red) to indicate that value is now filtered, and the points that have \u201cCountry\u201d as their \u201cCountry or Area\u201d are not drawn on the chart. The user can continue crossing out country labels either one at a time or with longer vertical strokes until only the points in which the user is interested remain. The y-axis scale fits the range zero to Country's maximum value, and the user can clearly see the distinction between the two Rates.","In order to provide in-place chart modification, the user can erase strokes as desired. The user can either tap an \u201cErase\u201d button of the surface , or press a barrel button on the pen, for example, to enter an erase mode. While in this mode, the screen can be configured to turns a different color (e.g., red) to represent the mode to the user, and any strokes the user crosses with the pen are removed from consideration in the chart . Lifting the pen exits erase mode.","At any point in the interactive process, the system can be storing the current state of the user inputs as well as the rendered graphical view. This can be initiated manually or configured to be performed automatically. Thus, the user can, at a later time, retrieve the stored graphical view for further user interaction(s).","Included herein is a set of flow charts representative of exemplary methodologies for performing novel aspects of the disclosed architecture. While, for purposes of simplicity of explanation, the one or more methodologies shown herein, for example, in the form of a flow chart or flow diagram, are shown and described as a series of acts, it is to be understood and appreciated that the methodologies are not limited by the order of acts, as some acts may, in accordance therewith, occur in a different order and\/or concurrently with other acts from that shown and described herein. For example, those skilled in the art will understand and appreciate that a methodology could alternatively be represented as a series of interrelated states or events, such as in a state diagram. Moreover, not all acts illustrated in a methodology may be required for a novel implementation.",{"@attributes":{"id":"p-0099","num":"0098"},"figref":"FIG. 7","b":["700","702","704","706","708"]},"At , a new user interaction with the graphical view is received and processed. In other words, if the user changes the scale or dimensions on axes of a graph, the data is automatically re-calculated to fit the graph. At , the user data is transformed according to the new user interaction. For example, the user data is transformed from a bar chart to a pie chart, or based on a detailed view of a segment of the bar chart, etc.",{"@attributes":{"id":"p-0101","num":"0100"},"figref":["FIG. 8","FIG. 7","FIG. 7"],"b":["800","802","804","806","808"]},"As used in this application, the terms \u201ccomponent\u201d and \u201csystem\u201d are intended to refer to a computer-related entity, either hardware, a combination of software and tangible hardware, software, or software in execution. For example, a component can be, but is not limited to, tangible components such as a processor, chip memory, mass storage devices (e.g., optical drives, solid state drives, and\/or magnetic storage media drives), and computers, and software components such as a process running on a processor, an object, an executable, a data structure (stored in volatile or non-volatile storage media), a module, a thread of execution, and\/or a program. By way of illustration, both an application running on a server and the server can be a component. One or more components can reside within a process and\/or thread of execution, and a component can be localized on one computer and\/or distributed between two or more computers. The word \u201cexemplary\u201d may be used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as \u201cexemplary\u201d is not necessarily to be construed as preferred or advantageous over other aspects or designs.","Referring now to , there is illustrated a block diagram of a computing system  that executes sketch-based interaction with computer-aided data analysis in accordance with the disclosed architecture. In order to provide additional context for various aspects thereof,  and the following description are intended to provide a brief, general description of the suitable computing system  in which the various aspects can be implemented. While the description above is in the general context of computer-executable instructions that can run on one or more computers, those skilled in the art will recognize that a novel embodiment also can be implemented in combination with other program modules and\/or as a combination of hardware and software.","The computing system  for implementing various aspects includes the computer  having processing unit(s) , a computer-readable storage such as a system memory , and a system bus . The processing unit(s)  can be any of various commercially available processors such as single-processor, multi-processor, single-core units and multi-core units. Moreover, those skilled in the art will appreciate that the novel methods can be practiced with other computer system configurations, including minicomputers, mainframe computers, as well as personal computers (e.g., desktop, laptop, etc.), hand-held computing devices, microprocessor-based or programmable consumer electronics, and the like, each of which can be operatively coupled to one or more associated devices.","The system memory  can include computer-readable storage (physical storage media) such as a volatile (VOL) memory  (e.g., random access memory (RAM)) and non-volatile memory (NON-VOL)  (e.g., ROM, EPROM, EEPROM, etc.). A basic input\/output system (BIOS) can be stored in the non-volatile memory , and includes the basic routines that facilitate the communication of data and signals between components within the computer , such as during startup. The volatile memory  can also include a high-speed RAM such as static RAM for caching data.","The system bus  provides an interface for system components including, but not limited to, the system memory  to the processing unit(s) . The system bus  can be any of several types of bus structure that can further interconnect to a memory bus (with or without a memory controller), and a peripheral bus (e.g., PCI, PCIe, AGP, LPC, etc.), using any of a variety of commercially available bus architectures.","The computer  further includes machine readable storage subsystem(s)  and storage interface(s)  for interfacing the storage subsystem(s)  to the system bus  and other desired computer components. The storage subsystem(s)  (physical storage media) can include one or more of a hard disk drive (HDD), a magnetic floppy disk drive (FDD), and\/or optical disk storage drive (e.g., a CD-ROM drive DVD drive), for example. The storage interface(s)  can include interface technologies such as EIDE, ATA, SATA, and IEEE 1394, for example.","One or more programs and data can be stored in the memory subsystem , a machine readable and removable memory subsystem  (e.g., flash drive form factor technology), and\/or the storage subsystem(s)  (e.g., optical, magnetic, solid state), including an operating system , one or more application programs , other program modules , and program data .","The operating system , one or more application programs , other program modules , and program data  can include the entities and components of the system  of , the entities and components of the system  of , the entities and components of the diagrams of , and the methods represented by the flowcharts of , for example.","Generally, programs include routines, methods, data structures, other software components, etc., that perform particular tasks or implement particular abstract data types. All or portions of the operating system , applications , modules , and\/or data  can also be cached in memory such as the volatile memory , for example. It is to be appreciated that the disclosed architecture can be implemented with various commercially available operating systems or combinations of operating systems (e.g., as virtual machines).","The storage subsystem(s)  and memory subsystems ( and ) serve as computer readable media for volatile and non-volatile storage of data, data structures, computer-executable instructions, and so forth. Such instructions, when executed by a computer or other machine, can cause the computer or other machine to perform one or more acts of a method. The instructions to perform the acts can be stored on one medium, or could be stored across multiple media, so that the instructions appear collectively on the one or more computer-readable storage media, regardless of whether all of the instructions are on the same media.","Computer readable media can be any available media that can be accessed by the computer  and includes volatile and non-volatile internal and\/or external media that is removable or non-removable. For the computer , the media accommodate the storage of data in any suitable digital format. It should be appreciated by those skilled in the art that other types of computer readable media can be employed such as zip drives, magnetic tape, flash memory cards, flash drives, cartridges, and the like, for storing computer executable instructions for performing the novel methods of the disclosed architecture.","A user can interact with the computer , programs, and data using external user input devices  such as a keyboard and a mouse. Other external user input devices  can include a microphone, an IR (infrared) remote control, a joystick, a game pad, camera recognition systems, a stylus pen, touch screen, gesture systems (e.g., eye movement, head movement, etc.), and\/or the like. The user can interact with the computer , programs, and data using onboard user input devices  such a touchpad, microphone, keyboard, etc., where the computer  is a portable computer, for example. These and other input devices are connected to the processing unit(s)  through input\/output (I\/O) device interface(s)  via the system bus , but can be connected by other interfaces such as a parallel port, IEEE 1394 serial port, a game port, a USB port, an IR interface, short-range wireless (e.g., Bluetooth) and other personal area network (PAN) technologies, etc. The I\/O device interface(s)  also facilitate the use of output peripherals  such as printers, audio devices, camera devices, and so on, such as a sound card and\/or onboard audio processing capability.","One or more graphics interface(s)  (also commonly referred to as a graphics processing unit (GPU)) provide graphics and video signals between the computer  and external display(s)  (e.g., LCD, plasma) and\/or onboard displays  (e.g., for portable computer). The graphics interface(s)  can also be manufactured as part of the computer system board.","The computer  can operate in a networked environment (e.g., IP-based) using logical connections via a wired\/wireless communications subsystem  to one or more networks and\/or other computers. The other computers can include workstations, servers, routers, personal computers, microprocessor-based entertainment appliances, peer devices or other common network nodes, and typically include many or all of the elements described relative to the computer . The logical connections can include wired\/wireless connectivity to a local area network (LAN), a wide area network (WAN), hotspot, and so on. LAN and WAN networking environments are commonplace in offices and companies and facilitate enterprise-wide computer networks, such as intranets, all of which may connect to a global communications network such as the Internet.","When used in a networking environment the computer  connects to the network via a wired\/wireless communication subsystem  (e.g., a network interface adapter, onboard transceiver subsystem, etc.) to communicate with wired\/wireless networks, wired\/wireless printers, wired\/wireless input devices , and so on. The computer  can include a modem or other means for establishing communications over the network. In a networked environment, programs and data relative to the computer  can be stored in the remote memory\/storage device, as is associated with a distributed system. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers can be used.","The computer  is operable to communicate with wired\/wireless devices or entities using the radio technologies such as the IEEE 802.xx family of standards, such as wireless devices operatively disposed in wireless communication (e.g., IEEE 802.11 over-the-air modulation techniques) with, for example, a printer, scanner, desktop and\/or portable computer, personal digital assistant (PDA), communications satellite, any piece of equipment or location associated with a wirelessly detectable tag (e.g., a kiosk, news stand, restroom), and telephone. This includes at least Wi-Fi (or Wireless Fidelity) for hotspots, WiMax, and Bluetooth\u2122 wireless technologies. Thus, the communications can be a predefined structure as with a conventional network or simply an ad hoc communication between at least two devices. Wi-Fi networks use radio technologies called IEEE 802.11x (a, b, g, etc.) to provide secure, reliable, fast wireless connectivity. A Wi-Fi network can be used to connect computers to each other, to the Internet, and to wire networks (which use IEEE 802.3-related media and functions).","What has been described above includes examples of the disclosed architecture. It is, of course, not possible to describe every conceivable combination of components and\/or methodologies, but one of ordinary skill in the art may recognize that many further combinations and permutations are possible. Accordingly, the novel architecture is intended to embrace all such alterations, modifications and variations that fall within the spirit and scope of the appended claims. Furthermore, to the extent that the term \u201cincludes\u201d is used in either the detailed description or the claims, such term is intended to be inclusive in a manner similar to the term \u201ccomprising\u201d as \u201ccomprising\u201d is interpreted when employed as a transitional word in a claim."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
