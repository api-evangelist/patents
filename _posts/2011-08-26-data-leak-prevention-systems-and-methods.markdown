---
title: Data leak prevention systems and methods
abstract: A data leak prevention system includes an application, having source code that is unavailable or non-modifiable, resident on a client device. A system call is emittable by the application as a result of an action, and is to take place before a data leak event can occur. The action involves a document and i) latest full contents of the document, ii) metadata of the document, or iii) a combination of the latest full contents and the metadata. A system call interceptor agent is also resident on the client device. The interceptor agent includes a system call interceptor to intercept the system call emitted by the application and to suspend the system call. The system also includes a policy decision engine to analyze at least some of i) the latest full contents, ii) the metadata, or iii) the combination, and implement a policy action based upon the analysis.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09219752&OS=09219752&RS=09219752
owner: Hewlett-Packard Development Company, L.P.
number: 09219752
owner_city: Houston
owner_country: US
publication_date: 20110826
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","DETAILED DESCRIPTION","EXAMPLE 1","EXAMPLE 2","EXAMPLE 3","EXAMPLE 4"],"p":["The present disclosure relates generally to data leak prevention systems and methods.","Electronic data communication is ubiquitous. Business practices and commerce often require data to be transmitted securely, such that customer, internal business, and\/or legal standards are met. One goal of these standards is to prevent the unauthorized transmission of information and attachments. In attempts to achieve this goal, policies have been implemented that require labels and tags, such as \u201cprivate\u201d, \u201cconfidential\u201d, \u201crestricted\u201d, \u201csensitive\u201d, and the like to be added to various documents and data transmissions. Other policies require keywords to be included in the actual document contents (e.g., persistent terminology that distinguishes one class of sensitive documents from another class of sensitive documents). Ensuring that these policies are effected may be difficult, at least in part because of differing levels of employee competence (e.g., new to company, job, or role; temporary replacement), genuine mistakes (e.g., distraction, forgetfulness, lack of concentration), or a lack of up to date corporate, legal, or other policy information. Policy changes may require an adequate employee training which is delivered in parallel with or shortly after the changes have been made. It is possible, however, that there could be a delay between the desired policy change and the actual roll-out. When policies are not enforced, sensitive data\/information may be leaked. Data leak incidents range from, for example, sending a sensitive e-mail to the wrong address to uploading a confidential document instead of a conference submission; and from saving an unprotected document backup on a USB device to printing a sensitive document on a widely accessible printer and then forgetting that the document was printed. Methods used to prevent data leaks include, for example, analysis of outgoing information on gateway-based systems, secure erasure solutions, and USB lock-out and mandatory encryption solutions. The existing methods are office-based leak prevention mechanisms that may not be suitable for data leaks from out-of-office devices (e.g., DVD, USB, external hard drives, etc.).","In the examples disclosed herein, sensitive data policy enforcement occurs locally on devices that are part of a trusted environment. These devices may range from desktop computers (an example of an in-office device) to mobile phones (an example of an out-of-office device). At least part of the system disclosed herein is resident on the device and captures system calls emitted by an application whose source code is not available or is not modifiable (e.g., due to practical or legal considerations). This type of application is often a third party application that has been installed on the device, and is not designed to handle sensitive data in accordance with policies set for the trusted environment. The system and method disclosed herein sandbox such applications in order to prevent policy breaches and data leaks from occurring. Sandboxing involves evaluating dynamically changing document sensitivity based on actual document contents and\/or document metadata and then-current policies before the document is allowed to be exported out of a trusted environment. The evaluating takes place when a user attempts to export the document out of the trusted environment. As such, system and method disclosed herein are designed to prevent sensitive data leaks by thwarting sensitive data export from a trusted environment before the exporting has a chance to occur.","The program to achieve sensitive data policy enforcement may be installed in a secure compartment\/account on the user's device. The program may be deployed in an advisory mode or a mandatory mode. Advisory mode provides a safety net to prevent accidental user error, and the policy enforcement solution\/program is deployed for the user's benefit. Mandatory mode means that the policy enforcement solution\/program cannot be accessed, modified, or disabled by the user.","Examples of the system and method disclosed herein automatically detect, and in some instances amend potential policy breaching user actions at the intention stage, i.e., as a corresponding system call is called by an application resident on the user's device, but before the action associated with the system call has been accomplished. Prior to deployment of the method to actually prevent data leaks from occurring, the application whose source code is not available or non-modifiable is analyzed to catalog systems calls of the application, and to minimize the system calls of the application that are captured to a set of system call(s) associated with sensitive tasks where data leak prevention is desired. The analysis of the application is shown in .","Each of the steps outlined in  is performed using hardware, firmware, and software (i.e., computer readable instructions). In an example, the hardware (e.g., a processor resident on a local\/client device) runs computer readable instructions (i.e., software) that are embedded on some non-transitory, tangible computer readable medium.","At the outset, a system call that is emitted by the application is captured and is analyzed (see reference numeral  in ). In an example, all system calls that are emitted by the application may be captured and analyzed. While all of the system calls can be captured and analyzed, in some instances, it may not be desirable to capture and analyze all of the system calls. For example, the computer readable instructions performing the analysis of the application may be programmed to recognize that certain system calls (e.g., \u201copen\u201d, \u201cnew\u201d, etc.) are not at all related to potential data leak events, and thus these system calls would not be captured and analyzed. In some examples, system calls that are triggered by a corresponding action that has a potential to leak data are filtered. In these examples then, any system call that is associated with an action that can potentially leak data from the trusted environment is captured. In one example, StraceNT (i.e., the Windows analog of an original Linux tool) may be used to intercept and record system calls for subsequent analysis. The filtering process may also be performed manually or via some automation tool in order to identify the system call(s) that correspond with potential data leaking actions.","During the analysis of the captured system calls, those system calls (e.g., a single call or a group of calls) that are identified as corresponding with or being related to a potential data leak event are filtered out (see reference numeral  in ). As used herein, \u201cpotential data leak events\u201d or \u201cdata leak events\u201d are actions that can result in sensitive data being transmitted out of the trusted environment. Included actions are those that are able to export policy recognized data out of the trusted environment. It is to be understood that exporting data may be accomplished via any channel, for example, through saving, electronic mailing, printing, copying, moving, dragging and dropping, uploading, or the like.","The action(s) may be triggered by a user of the application and client device, and these action(s) is\/are referred to herein as user action(s). Examples of user actions include pushing a button to save a document, to send an electronic mail (e-mail), to upload a document, to print a document, and to copy or move a document (e.g., using Microsoft Windows Explorer). Saving may be a data leak event when, for example, sensitive data is saved in clear text onto an external device, such as a pen drive, a USB key, an external hard drive, or the like, and the external device is then lost. Saving may also be a data leak event when, for example, the sensitive data is saved on a remote network drive, which may have a low security status or may be widely accessible. Sending an e-mail may be a data leak event when, for example, a user accidentally sends a confidential e-mail to an unintended recipient or an unintentionally wide audience, or a user sends a confidential e-mail to the correct recipient through a public network in dear text. Uploading a file may be a data leak event when, for example, the wrong file, which contains sensitive data, is accidentally uploaded to a public server instead of the originally intended file, which does not contain sensitive data. Printing may be a data leak event when, for example, a confidential or otherwise sensitive document is printed on a widely\/publicly accessible printer without enabling personal identification number (PIN) retrieval and then the document is forgotten about or left unattended.","The action(s) may also be triggered by internal application processes (i.e., an internal state of the application), and these action(s) is\/are referred to herein as application action(s). An example of an application action is when Microsoft Outlook sends a delayed or scheduled e-mail message (e.g., a user may select the desired delivery date and time in the menu \u201cOptions\u201d under sub-menu \u201cDelivery options\u201d). Another example of an application action is when Microsoft Word performs an \u201cAutoSave\u201d. Yet another example of an application action is when the application is programmed to automatically upload some information to a remote web-site.","When filtering is performed, the computer readable instructions are programmed to analyze each captured system call and determine whether the captured system call(s), uniquely or as part of a group, correspond with the potential data leak event (see reference numeral  of ). The system call(s) that are deemed unrelated to potential data leak events are not filtered out and are not subjected to any further analysis.","In contrast, those system call(s) that are filtered out during the initial analysis are subjected to further processes to define which of the filtered system call(s) correspond with a particular action that, if fully executed, could leak data from the trusted environment (see again reference numeral  of ). More particularly, the system determines which of the filtered-out system calls correspond with actions that i) take place before the data leak event can occur, and ii) involve the latest version of a document (including its latest full contents and\/or its metadata). Defining is accomplished by first identifying from the filtered system call(s) either a single call or a group of calls that is\/are responsible for actually performing the action; and then selecting from the identified system call(s), the system call(s) or other means that provide access to the latest (i.e., most recent, then-current) version of the document (i.e., contents and\/or metadata). To prevent a data leak from occurring, the system call(s) responsible for the action is\/are temporarily blocked (i.e., suspended while analyzing takes place), and the resulting behavior of the application is observed. The application's behavior in response to blocked\/suspended system call(s) identifies the lowest level system call or combination of calls that prevents the action from being executed (as opposed to not or only partially suspending the action). In other words, the very last system call(s) or the most convenient system call(s) whose context provides access to the latest document contents and\/or metadata that occur before the action has the chance to occur are identified. The application's behavior in response to blocked\/suspended system call(s) also identifies the system call that provides the latest version of the document (as opposed to, for example, only a document fragment). For example, a system call that is responsible for writing only a portion of a document, or a system call that occurs after a portion of a document has already been written to a remote drive may not be used, at least in part because the first system call does not provide the full document context and the second system call occurs too late (i.e., after some sensitive may have already leaked). In other words and in some instances, the system call(s) that involve the most recent version of the document are identified and defined as corresponding with the potential data leak event. It is to be understood, however, that other means may be deployed to recover the corresponding document contents involved in a potential data leak event. If the full document contents cannot be retrieved for a particular application and action from the corresponding action blocking system call, the latest document contents can be recovered using other means, for example, the document contents may be routinely cached during document modifying operations such that the latest is available for the evaluation when the action blocking system call is suspended.",{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 1","FIG. 1"],"b":["12","12","14"]},"When testing multiple system calls, the calls may be blocked one by one, or in groups. System call(s) that are identified as performing\/preventing the action and as being associated with the latest version of the document are added to the set of system calls for the particular action. As such, the set includes the minimum necessary system call(s) associated with the particular action. As will be described further hereinbelow, the emission of any system call within the set during application use triggers a series of processes to prevent data leakages from occurring.","Table 1 provides examples of actions, applications, and system calls that are part of a set for the particular action and a particular application. In addition to traditional system calls (e.g., writefile, replacefile, etc.), the system and method disclosed herein may be augmented by using application add-ons, plug-ins, etc. as \u201csystem calls\u201d. As shown in Table 1, higher level calls, such as events from Outlook MAPI (e.g., fnevCreated) or Browser Helper Object (BHO) events (e.g., BeforeNavigate2) may be designated as system call(s) for a particular action. The Browser Helper Object is a DLL module designed as a plugin for Microsoft's Internet Explorer web browser to provide added functionality. For example, with BHOs, one can write components that Internet Explorer will load each time it starts up. BHOs run in the same memory context as the browser and can perform any action on the available windows and modules.",{"@attributes":{"id":"p-0023","num":"0022"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},{},{},"System Call(s)"]},{"entry":[{},"Action","Application","to Capture"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Save File","Microsoft Word","WriteFile"]},{"entry":[{},{},{},"ReplaceFile"]},{"entry":[{},{},"Microsoft Excel","WriteFile"]},{"entry":[{},{},{},"ReplaceFile"]},{"entry":[{},{},"Microsoft PowerPoint","WriteFile"]},{"entry":[{},{},"Acrobat Reader","WriteFile"]},{"entry":[{},{},"Notepad","WriteFile"]},{"entry":[{},"Send Email","Microsoft Outlook","fnevCreated"]},{"entry":[{},{},"Web Based","BeforeNavigate2"]},{"entry":[{},"Upload File","Internet Explorer","BeforeNavigate2"]},{"entry":[{},"Print","Notepad","WriteFile"]},{"entry":[{},{},{},"WritePrinter"]},{"entry":[{},{},"Microsoft Word","WriteFile"]},{"entry":[{},{},{},"WritePrinter"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}}}},"As mentioned above, the method shown in  may be performed for any application whose source code is unavailable and\/or non-modifiable. System calls used by different applications, even for seemingly identical user actions, depend upon internal application behavior and its actual implementation. Therefore, system calls corresponding with the save file action in Microsoft Word may be different from the system calls corresponding with the save file action in Notepad. As such, it may be desirable that a set of system call(s) be generated for each application and for each data leak event of each application.",{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 2","FIG. 2","FIGS. 3 and 4"],"b":["10","10"]},"At the outset of the method shown in  (as shown at reference numeral ), the application  is loaded onto the local or client device , \u2032. The local or client device , \u2032 may be an out-of-intranet device or a peripheral device. Out-of-intranet devices include any company-owned mobile device (e.g., laptops, smart phones, etc.) that can potentially carry sensitive information and can be used either inside or outside of a secure\/trusted environment. A peripheral device is one that is or can be connected to the company intranet, such as an unprotected drive, USB or other memory device, a publically accessible printer, or the like.","In the examples disclosed herein, the application  is an application that is useful to the user, but is not designed to handle sensitive data in accordance with a policy set forth for the user, document, etc. The source code of the application  is not available or is not modifiable. With this type of application , the accidental or intentional cross-contamination of sensitive data can occur as a result of sensitive data being opened using the application  or by sensitive data being copied into the application . Due to the initial inability of the application  to handle sensitive data, the sandboxing method described in  is performed to better equip the application  for handling sensitive data and for preventing data leaks (see reference numeral  of ). To briefly reiterate from above, the analysis of  generates a set of system calls (which may include one system call or a group of system calls) for a particular action, where the system call occurs before any data exportation associated with the action occurs and at the same time provides a document and its full contents and\/or metadata.","As used herein, the term \u201cdocument\u201d includes text, media, video, audio, files, labels, tags, elements, phrases, patterns, programs, network data, packet streams, signal transmissions, records, emails, and data of any type. The \u201ccontents\u201d of the document include the latest data (e.g., final edits) incorporated into the document before the action (which could leak data if completed) is initiated. The document may also include the latest document metadata.","When the application  is run on the local device , \u2032 (reference numeral  of ), a system call interceptor agent  is also run in the background to intercept the defined system call(s) during each use of the application . The system call interceptor agent  is resident on the local device , \u2032 and includes hardware and computer readable instructions that are executable by at least some of the hardware. In one example, the hardware of the system call interceptor agent  includes the processor of the client device , \u2032. The configuration of the system call interceptor agent  is based, at least in part, upon the link between the action and the system call(s) for the different applications . It is to be understood that the system calls provide an interface between a user level process (e.g., running the application) and the operating system  of the client\/local device , \u2032. As described hereinabove, higher levels calls to DLLs (dynamic-link libraries), APIs (application programming interfaces), or other components (BHOs) are included as \u201csystem calls\u201d in the present disclosure. Different operating systems  may have different interfaces, which depend, at least in part, on the operating system  architecture, structure and implementation. As such, different versions of the system call interceptor agent  may be utilized with different operating systems .","In some examples, the interceptor agent  includes a system call interceptor  that scans the system calls that are emitted by the application . System calls are emitted when corresponding actions are initiated manually by the user of the device , \u2032, or automatically by the application . The system call interceptor  is programmed to scan for then-currently emitted system call(s) and to capture those system call(s) that had previously been assigned to a set of system calls for a particular action (see reference numeral  of ). As such, the system call interceptor  listens to what the application  is trying to do (i.e., what system call(s) it makes), and if the application  tries to effect any action that the system call interceptor  is programmed to detect, then the system call interceptor  captures or intercepts the request. For example, the system call interceptor  may scan all system calls emitted by an application, but may only capture\/intercept those system call(s) that is\/are part of the set designated for the actions of printing, saving, uploading, copying, moving, dragging and dropping, or emailing. The set of system calls for the particular action (which is\/are identified by the method shown in ) may be stored, for example, in a memory  of the local device , \u2032. Since only system call(s) that had previously been assigned to the set of system calls are captured, computational overhead of the interceptor agent  is minimized.","When the system call interceptor  captures system call(s) of a previously defined set, it suspends the system call(s) from being executed, and thus prevents the action associated with the system call(s) from being executed (reference numeral  of ). For example, when an associated system call is captured, the action of printing, emailing, saving, moving, copying, dragging and dropping, or uploading is prevented from being executed. The system call(s) is\/are the call(s) from the application to the operating system  that request\/instruct the operating system  to perform the action. Interceptor  suspends the system call(s) from the application  before they reach the operating system . Therefore, as a result of suspending, the operating system  does not receive the request and thus the intended action is not executed.","While the system call(s) is\/are suspended, a policy decision engine  (which in some instances\u2014see, e.g., FIGS.  and \u2014is part of the interceptor agent ) is programmed to scan and perform deep content parsing of a set of predetermined structured and\/or unstructured fields within the document that is associated with the action. In other words, the policy decision engine  looks inside the document and unravels the document's contents and\/or metadata (see reference numeral  of ). The contents and\/or metadata of the document are analyzed to determine the document sensitivity and to determine whether a policy applies to the document that is attempted to be exported from the local device , \u2032. The policy decision engine  may be programmed to successfully operate in real time, and to minimize the time it blocks the application  while the application  is being suspended and the user is waiting. In other words, the policy decision engine  is programmed to quickly determine whether the action in question may be continued. It is to be further understood that the overall internal system call interception framework is programmed so that the suspended system call(s) does\/do not destabilize and\/or crash the application .","The policy decision engine  performs some detour function for every suspicious\/suspended system call so that the document and\/or data analysis may be performed to determine if a data leak will occur if the action is continued, and so that the engine  can determine (based upon the analysis) which policy action to implement.","Different policies may be in place for different actions, such as printing, saving, uploading, emailing, etc. In some instances, policies may be coherent. For example, if a document is not allowed to be e-mailed to an external address, it may also not be allowed to be uploaded to an external server. The policies are generated and updated using a secure authoring tool , which, in some examples, is part of a policy server  (shown in ), and in other examples, is part of the client device , \u2032 (shown in ), and in still other examples, is part of a trusted server\/service  (shown in ). When part of the policy server  or trusted server\/service , the secure authoring tool  may be resident on a remote device (e.g., a central server, a distributed server with or without localization, a hybrid central\/distributed server, etc.) that is in selective communication with the local device  (or \u2033), or the tool  may be resident on a server of a cloud computing system that is in selective communication with the local device  (or \u2033).","In some examples, the policy server  or trusted server\/service  may be an organization-wide service, which may be a single server or a cluster of synchronized servers that provide reliable access through redundancy. Any of these off-board (i.e., not resident on the device \u2032) policy servers  or trusted server\/service  includes a policy repository  for storing policies. In the example shown in , the policy repository  may be in selective communication with the memory  of the client device , and two components ,  may synchronize on a schedule or when needed. As one example, the policy repository  may push new and\/or updated policies to the memory  of the client device  upon creation\/modification. In contrast, when the secure authoring tool  is part of the local device \u2032, the secure authoring tool  may be loaded as a program on the local device \u2032. The policies generated from the on-board secure authoring tool  (as shown in ) may be stored directly in the memory . When a trusted server\/service  is utilized, the secure authoring tool  may be part of the server\/service  and may transmit policies to a repository  and\/or a decision engine  that are also part of the server\/service .","Depending upon who has access to the secure authoring tool , policies may be created, changed, updated, deleted, managed, tested, reviewed, etc. by a policy manager, system administrator or the user of the local device , \u2032, \u2033. As examples, an administrator may define policies for users in a multi-user environment, and a user may implement his\/her own safeguard policies (local to his\/her device , \u2032) to protect himself\/herself from making mistakes when working with multiple applications. The secure authoring tool  is responsive to input received either manually from an individual or in an automated form from another program. The secure authoring tool  is used to create a customizable set of policies applicable to documents and\/or data that are associated with particular actions. It is to be understood that any number of policies can be created.","The policy may include, at least, a policy identifier (consisting of a unique policy identifier and a policy revision version (i.e., sequentially numbered policy updates)); the action associated with the system call(s) to be captured; a policy condition that the document contents and\/or its metadata must satisfy for the policy to become applicable; and a policy action that will be implemented if the policy condition is satisfied. A single policy may include multiple policy conditions and\/or multiple policy actions. In an example, if a set of policy actions is included in a single policy, one action may be implemented when the policy condition is satisfied and another action may be implemented when the policy condition is not satisfied. Each of the policy components will be further described hereinbelow.","As mentioned above, while the action is suspended, the policy decision engine  performs a deep scan (as defined by corresponding policy conditions) of the document that is associated with the action to determine if a policy applies. The policy decision engine  may retrieve the document contents and\/or metadata from the document storage . The document storage  may include local or network storage, a hard drive, removable media, and the like. When performing a scan, the policy decision engine  may retrieve policies associated with the particular action from the policy repository\/storage  and\/or the memory .","The sensitivity of the document is a dynamic property which depends upon the current state of the document's contents and metadata and the current state of the policies. For example, document sensitivity can be altered as the document is being edited (e.g., sensitive data can be typed, pasted, added into, removed from the document), as policies are changed (e.g., a document could satisfy a newly-added policy, or no longer satisfy an amended version of an existing policy), or as time-dependent policy conditions expire. As such, it is desirable to determine the document sensitivity at the latest point before exporting the document out of the local device , \u2032. In the examples disclosed herein, real-time document sensitivity may be determined because the system call(s) and the associated document is\/are captured just before the document is exported, but after final edits have been made.","In an example, the deep scan of the document contents and\/or its metadata is performed according to a policy condition. In an example, the policy condition is a chain of operations on Boolean-valued functions of keywords contained within a document. The keywords are policy eliciting terms (including their patterns), which can be single terms, compound terms, or a combination of terms. The policy-eliciting terms may be defined using the secure authoring tool  and broadly include any set of information, such as, classification levels, security labels, words, paragraphs, pages, symbols, phrases, patterns, data, tags, dates, logos, code, files, documents, and any other information that could be found in a document. Examples of policy-eliciting terms include the following: Confidential, Restricted, Private, Secure, Confidentiel (French), Prive (French); high-security, medium-security, low-security, level 0, level 1, credit-card numbers, social-security numbers, customer identifiers, a form, a template, workflow-eliciting terms, author, owner, creation date, modification date, parts of copyrighted works, a name\/codename of a new product, or the like.","To satisfy a policy condition, the document may be required to contain the specified policy eliciting terms simultaneously, as alternatives, or any combinations thereof. For example, to satisfy the following condition:\n\n((\u201ccustomer\u201d\u201cclient\u201d)(\u201ccontract\u201d\u201cagreement\u201d))\n\n(where ^ denotes \u201cAND\u201d and V denotes \u201cOR\u201d) the document must simultaneously contain one word from the first group {\u201ccustomer\u201d, \u201cclient\u201d} and one from the other group {\u201ccontract\u201d, \u201cagreement\u201d}. Thus, a document containing \u201ccustomer\u201d and \u201cagreement\u201d satisfies this policy condition (the policy is applicable to the document), but a document containing neither \u201ccontract\u201d nor \u201cagreement\u201d does not satisfy this policy condition (the policy is not applicable to the document). Statistical language processing (SLP) techniques (e.g., Levenshtein or Damerau-Levenshtein distances) may be used to provide fuzzy matching for these keywords to accommodate typo errors, including misspellings, such as wrong characters and swapped characters. For example, the following policy condition:\n\n(\u201ccontract\u201d\u201ccontact\u201d)(\u201cagreement\u201d)\n\nrequires a document to contain either i) the word contract, possibly misspelled with one error E=1, however the word shall not be contact or ii) the word agreement with no more than two errors E=2.\n","The policy decision engine  can be further extended to accommodate policy eliciting term stemming and lemmatization, which could render the policy decision engine  more robust in dealing with policy eliciting term inflections.","Still further, the policy decision engine  can be further extended to accommodate document metadata conditions. In these examples, Boolean-valued metadata conditions are added to the previously described content-based policy conditions using the corresponding Boolean operations. As an example of metadata, when a file with sensitive data is about to be saved, the intended destination may be one of the policy conditions. For example, if the destination is classified as a local hard drive or as another secure location, the document may be saved. However, if the destination is classified as an external device, the document may not be saved. As another example of metadata, when an email is about to be sent, the email address of the recipient may be one of the policy conditions. For example, it may be acceptable to send a confidential email to a coworker, but not to any email address that does not belong to the organization. As still other examples of metadata, when a file is about to be uploaded, the IP address of the server may serve as a policy condition, and when a document is about to be printed, the IP address of the printer or whether the printer is local may serve as policy conditions.","It is to be understood that the policy conditions may be associated with any property of the document and\/or its metadata. As such, the policy conditions may be document-specific (e.g. keywords within the document itself), user-specific (e.g. email address of a recipient) or may be action-specific (e.g., saving destination).","In some of the examples disclosed herein, the determination of document sensitivity is made on the full document contents and\/or metadata, and thus the scan is performed on each and every document part or the document as a whole, as required by the policy\/policies. In other examples, the document \u201chot\u201d areas (e.g., header, footer, first page, titles, etc.) may be analyzed alone or before analyzing the remainder of the document. For example, if a document header contains the label \u201cConfidential\u201d, the policy decision engine  may not analyze the document body to make a decision; or may analyze the full document body and at least consider this tag when making a decision. The action of the policy decision engine  depends at least in part on the policy\/policies being applied.","Each policy includes a policy action. The policy action to be taken is defined by the policy and is based on the current sensitivity level of the document. The policy decision engine  implements the policy based upon the document sensitivity (reference numeral  of ).","The policy action may be implemented\/executed using Microsoft Detours (i.e., a library for instrumenting arbitrary Win32 functions on x86, x64, and IA64 machines, it intercepts Win32 functions by re-writing the in-memory code for target functions and contains utilities to attach arbitrary DLLs and data segments to any Win32 binary), Microsoft Hooks (i.e., invokes a hook procedure that while, loadable kernel modulus (e.g., which may be deployed on Linus OS), or other suitable mechanisms. As will be described further below, the policy action may be to simply continue with the original system call, to simply deny the original system call, or to provide an alternate action in place of the original system call. The policy action may also include other actions, such as, securely logging the event, actively informing the user about the data leak detection by citing the corresponding policy, warning the user that his\/her action is being denied because it will result in a data leak, guiding the user through alternate paths for data and\/or document release (e.g. by requiring an explicit authorization, encryption, etc.)","If the scanning indicates that a document is sensitive and a policy breach may occur (e.g., policy conditions are met or indicate unsecure destinations), the policy action may be to deny\/forbid the action or to provide an alternate action that will not result in data leakage. When the action is outright denied\/forbidden, the user may be provided with clear information that the original action has not been allowed. For example, a pop-up window may appear indicating that the action is not allowed due to violation of a particular policy. Alternate actions may be provided to the user as an option or may automatically be executed when a potential policy breach by a particular application for a particular document is detected. Alternate actions include protection enforcing actions, mandatory document encryption, redirection to a secure printer or email address, redirection to a secure destination, or the like. Some specific examples of alternate actions include allowing saving or emailing to take place if encryption is used, allowing a confidential document to be emailed if the email address is changed to a company\/enterprise address, and allowing printing to take place if a secure code is required to be entered at the printer. When an alternate action is available, the alternate actions may be presented to the user (via a client device interface, e.g., monitor, screen, etc.), and the system\/program may guide the user through the alternate path(s).","If the results of scanning indicate that a document is not sensitive and a policy breach will not result (e.g., policy conditions are not met or indicate secure destinations), the policy action may be to allow the action to continue. In this example, the previously captured system call will be resumed. In these examples, the application is restored to the state it was in when it was suspended. When the action is suspended and subsequently allowed, the user may be informed that transmitting, saving, printing, etc. is in progress via a pop-up window or other on-screen indication.","The policy action(s) of a policy are defined using the secure authoring tool .","In some instances, the action that has been suspended will be blocked by default when the document associated with the action cannot be analyzed. For example, the document may not be in a supported format or may include an unknown character set. In such instances, the policy decision engine  may not be able to scan the document to determine its current sensitivity level. In such instances, in order to guarantee data leak prevention, the suspended action may be forbidden.","The following are examples of the four actions (i.e., save, email, upload, and print) that may be suspended, and the document analysis and resulting policy actions that may be implemented. These examples are meant to be illustrative and non-limiting.","Data leaks can occur when a sensitive file is saved in clear text onto an external device (e.g., a pen drive, USB key, an external hard drive), which is subsequently lost. The system call associated with the save file to external device action may be captured when the \u201csave file to external device\u201d request is input by a user. The save file to external device action is then suspended. For the save file to external device action, the policy metadata may be the path where the user wants to save the file, and the policy eliciting terms (which may be designed to recognize sensitive document contents) may be searched in the full document contents or only within specified areas, e.g., header, footer. In this example, the policy\/policies might dictate that sensitive documents need to be encrypted when saved into an external device, or the policy\/policies might forbid that the sensitive documents be saved onto an external device.","Data leaks can also occur when an email containing sensitive information or having a sensitive document attached thereto is sent to an unauthorized email address. The system call associated with the send email action may be captured when the \u201csend email\u201d request is input by a user. The send email action is then suspended. For the send email action, the policy metadata may be the email addresses of the recipients, and the policy eliciting terms (which may be designed to recognize sensitive document contents) may be searched in the email subject, body and attachments. In this example, the policy\/policies might dictate that sensitive documents need to be removed from the email and\/or that the email address needs to be changed to an authorized email address.","Data leaks can also occur when a document containing sensitive data is inadvertently uploaded to a public server. The system call associated with the upload action may be captured when the \u201cupload document\u201d request is input by a user. The upload document action is then suspended. For the upload document action, the policy metadata may be the IP address of the destination server, and the policy eliciting terms (which may be designed to recognize sensitive document contents) may be searched in the in the HTTP Post request body, and in the file name and content of any file defined in the post request. When the file is to be uploaded to a server owned\/managed by other parties (outside of the user's organization), the policy\/policies might dictate that documents containing sensitive information may not be uploaded to this server. When the file is to be uploaded to a secure server over a public network (whose packets may easily be intercepted), the policy\/policies might dictate that these communications need to be encrypted.","Data leaks can also occur when a document containing sensitive data is sent to an unsecure printer, i.e., a printer located in the public domain or accessible by external customers as well as employees. The system call associated with the print action may be captured when the \u201cprint\u201d request is input by a user. The print action is then suspended. For the print action, the policy metadata may be the IP address of the printer or whether the printer is local or not, and the policy eliciting terms (which may be designed to recognize sensitive document contents) may be searched in the PCL\/PDF\/Postscript file, once it has been parsed. If a printer is not classified as secure, the corresponding policy could be enforced by automatically enabling PIN retrieval or the job could be redirected to another (secure) printer or cancelled.","After the appropriate policy action is executed, the action will either have been denied or allowed with or without modification. In any instance, a user may continue working in the application , and a data leak that may have otherwise occurred will have been prevented.","The method(s) previously described may also be performed, for example using the system \u2033 shown in . In this example, the system call interceptor agent  resident on the client\/local device \u2033 includes the interceptor , and the policy decision engine  is resident on some other trusted server\/service  (which may be a central and\/or distributed service to which the device \u2033 subscribes). In this example, the policy decision (i.e., analysis of document according to policy condition(s)) is outsourced to the trusted server\/service . In this example, the trusted server\/service  performs the policy decision and then transmits a signal back to the system call interceptor agent  instructing the application  on how to proceed in accordance with the policy action that should be initiated. This system \u2033 may be particularly suitable for small, limited capability devices (e.g., a smartphone). For example, the policy decision engine  may be complicated for small, limited capability devices \u2033, and so it may be more desirable to securely upload a captured document to some trusted server\/service , analyze the document at the trusted server\/service , and subsequently allow\/forbid the action by transmitting a suitable signal back to the client device \u2033. Thus, for well-connected extra small capabilities devices, when a secure connection to the trusted service\/server  can be reliably established when the action is attempted to be performed, it may be beneficial to outsource the decision to the server\/service .","The following examples are provided to illustrate examples of the method of the present disclosure. It is to be understood that these examples are provided for illustrative purposes and are not to be construed as limiting the scope of the disclosure.","Notepad calls the system call WriteFile to save a file. Notepad saves a copy of the file in a temporary location on the local machine, it is analyzed, deleted, and then a decision is taken with the actual file that the user wanted to save. Microsoft Word has a more complicated mechanism to save files. Microsoft Word saves a temporary file using the WriteFile system call, it creates the doc\/docx file in the location the user wanted to save it, and then its content is replaced by the temporary file calling ReplaceFile system call. Hence, the context aware system call is ReplaceFile.","To handle the different behaviors of these applications using the system and method disclosed herein, if WriteFile is called for a forbidden location (e.g., an external harddrive), the system call may be automatically blocked and the user may be notified. If, however, the location is allowed or is allowed under certain conditions, the WriteFile system call may be allowed. When the ReplaceFile is called, the action may be suspended, and a copy of the temporary document in a trusted local temporary folder may be made and analyzed. If the policy allows saving the document in the location the user specified, ReplaceFile is allowed and the process is over. If the document is not allowed in the location the user specified, Microsoft Word's temporary file is deleted and ReplaceFile is blocked. Microsoft Word may another attempt to save the file by calling WriteFile directly for the doc\/docx document, but this WriteFile call may be blocked because the file extension is known.","Microsoft Excel also calls WriteFile for a temporary file and then ReplaceFile to put the content of the temporary file into the xls\/xlsx file. However, if ReplaceFile is blocked as described above, the application does not attempt to save the file calling WriteFile directly for the xls\/xlsx file. As such, for this application, WriteFile is not blocked.","For Microsoft Outlook, the event fnevObjectCreaetd (which is called when a MAPI object is saved) is utilized as the system call. This system call may be called when a calendar event or an email is about to be sent. The email subject, recipients, body and attachments may be analyzed according to one or more policies. If the email cannot be sent, RpcAsyncCompleteCall (Microsoft Outlook's closest system call for sending an email) is blocked. This is an example of capturing a content-aware system call for analysis (fnevObjectCreated) and blocking another system call (which is not used to extract information, but is the one that performs the \u201csend email\u201d action).","For uploading to Microsoft Internet Explorer, a BHO (Browser Help Object) may be created and the event BeforeNavigate2 (which is called just before every http request is sent) may be sunk. To handle this event, the request is analyzed according to the policy, and if there is a file name in the post sequence, that file is also analyzed. If the decided action is blocking the http request, \u201ctrue\u201d is returned because if the system call BeforeNavigate2 returns true, the http post message will not be sent. Otherwise, the value that BeforeNavigate2 would have returned if it had not been captured is returned, meaning that the natural behavior of the application continues unaltered.","The Universal Print Drive (UPD) may be used, which sends a file to the spooler, calling WritePrinter and WriteFile. For the print action, WriteFile may be captured, a copy of the file may be saved in a local temporary location and parsed (it is in PCL format), and then a decision is made in accordance with current policies. If the decision is to prevent the file from being printed, the WriteFile is blocked when it is called for the sensitive PCL file.","The system(s) and method(s) disclosed herein automatically prevent unauthorized data transmissions outside of a trusted environment by i) real-time capturing any action that triggers data export before the export has occurred, and ii) analyzing the corresponding document contents and metadata for potential policy breaches. The approaches described herein prevent data leakages and also provide immediate user feedback.","It is to be understood use of the words \u201ca\u201d and \u201can\u201d and other singular referents include plural as well, both in the specification and claims.","While several examples have been described in detail, it will be apparent to those skilled in the art that the disclosed examples may be modified. Therefore, the foregoing description is to be considered non-limiting."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Features and advantages of examples of the present disclosure will become apparent by reference to the following detailed description and drawings, in which like reference numerals correspond to similar, though perhaps not identical, components. For the sake of brevity, reference numerals or features having a previously described function may or may not be described in connection with other drawings in which they appear.",{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
