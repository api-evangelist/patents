---
title: Customer feedback measurement in public places utilizing speech recognition technology
abstract: A method, a system and a computer program product for enabling a customer response speech recognition unit to dynamically receive customer feedback. The customer response speech recognition unit is positioned at a customer location. The speech recognition unit is automatically initialized when one or more spoken words are detected. The response statements of customers are dynamically received by the customer response speech recognition unit at the customer location, in real time. The customer response speech recognition unit determines when the one or more spoken words of the customer response statement are associated with a score in a database. An analysis of the words is performed to generate a score that reflects the evaluation of the subject by the customer. The score is dynamically updated as new evaluations are received, and the score is displayed within graphical user interface (GUI) to be viewed by one or more potential customers.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08635237&OS=08635237&RS=08635237
owner: Nuance Communications, Inc.
number: 08635237
owner_city: Burlington
owner_country: US
publication_date: 20090702
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY OF ILLUSTRATIVE EMBODIMENTS","DETAILED DESCRIPTION OF AN ILLUSTRATIVE EMBODIMENT"],"p":["1. Technical Field","The present invention generally relates to computer systems and in particular to voice recognition technology within computer systems.","2. Description of the Related Art","Feedback information concerning audience dynamics, reactions, and concerns is an important aspect of the restaurant and entertainment industry. Restaurants, televisions shows, shopping entities, and entertainment entities (e.g. movie theatres, sports arenas, and amusement parks) often depend on customer feedback to provide quality products and services. Information regarding the quality of food, pricing, customer volume, and service experience in a restaurant helps the owner to identify customer requirements and maintain quality service. Viewer\/listener feedback in relation to television\/radio broadcast helps determine how many people are watching and\/or listening to a particular television or radio program. Understanding customer dynamics assists business owners gauge the \u201cpopularity\u201d of a particular business.","Feedback regarding entities such as restaurants, movies, broadcast programs (e.g. television shows, radio shows, cable provided programs etc.), video games, shopping centers, travel experiences (e.g. airlines, resorts, and amusement parks) are sparingly input and reviewed on websites. Customer responses to services and audience dynamics (audience\/customer population) provided by an entity often determine the success of an entity and provide information to decision makers (e.g. consumers, owners, managers, and marketing departments) regarding continued support for the entity. There is no available method to easily capture customer comments made while watching a movie, watching television, and\/or while utilizing a business. Motivated customers may utilize websites to voice their opinion of a movie, television show, restaurant, and\/or shopping experience. However, valuable information is lost after completion of the experience. A vast majority of consumers never have their opinion heard because they choose not to utilize resources such as internet websites and customer response surveys.","Disclosed are a method, a system and a computer program product for enabling a customer response speech recognition unit to dynamically receive customer feedback. The customer response speech recognition unit is positioned at a customer location. The speech recognition unit is automatically initialized when one or more spoken words are detected. The response statements of customers are dynamically received by the customer response speech recognition unit at the customer location, in real time. The customer response speech recognition unit determines when the one or more spoken words of the customer response statement are associated with a score in a database. An analysis of the words is performed to generate a score that reflects the evaluation of the subject by the customer. The score is dynamically updated as new evaluations are received, and the score is displayed within a graphical user interface (GUI) to be viewed by one or more potential customers.","The above as well as additional objectives, features, and advantages of the present invention will become apparent in the following detailed written description.","The illustrative embodiments provide a method, a system and a computer program product for enabling a customer response speech recognition unit to dynamically receive customer feedback. The customer response speech recognition unit is positioned at a customer location. The speech recognition unit is automatically initialized when one or more spoken words are detected. The response statements of customers are dynamically received by the customer response speech recognition unit at the customer location, in real time. The customer response speech recognition unit determines when the one or more spoken words of the customer response statement are associated with a score in a database. An analysis of the words is performed to generate a score that reflects the evaluation of the subject by the customer. The score is dynamically updated as new evaluations are received, and the score is displayed within a graphical user interface (GUI) to be viewed by one or more potential customers.","In the following detailed description of exemplary embodiments of the invention, specific exemplary embodiments in which the invention may be practiced are described in sufficient detail to enable those skilled in the art to practice the invention, and it is to be understood that other embodiments may be utilized and that logical, architectural, programmatic, mechanical, electrical and other changes may be made without departing from the spirit or scope of the present invention. The following detailed description is, therefore, not to be taken in a limiting sense, and the scope of the present invention is defined by the appended claims and equivalents thereof.","Within the descriptions of the figures, similar elements are provided similar names and reference numerals as those of the previous figure(s). Where a later figure utilizes the element in a different context or with different functionality, the element is provided a different leading numeral representative of the figure number. The specific numerals assigned to the elements are provided solely to aid in the description and not meant to imply any limitations (structural or functional or otherwise) on the described embodiment.","It is understood that the use of specific component, device and\/or parameter names (such as those of the executing utility\/logic described herein) are for example only and not meant to imply any limitations on the invention. The invention may thus be implemented with different nomenclature\/terminology utilized to describe the components\/devices\/parameters herein, without limitation. Each term utilized herein is to be given its broadest interpretation given the context in which that terms is utilized. Specifically, the term \u201csensory receiving environment\u201d includes, but is not limited to, an environment whereby one or more of the following programs\/subjects\/events are presented: a broadcast of a program, a live performance, exhibition of a video, video game play, a movie (program) is presented, and\/or output of audio (e.g. pre-recorded audio, live audio program). The sensory receiving environment may also include, but is not limited to: video game environments, shopping centers, travel experiences (e.g. airlines, resorts, and amusement parks). Within the sensory receiving environment, an audience member can hear, see, smell, touch, and\/or taste, wherein an audio response to the sensation is detected by a utility. Additionally, the terms \u201caudio\u201d and \u201caudible\u201d are utilized interchangeably, herein.","With reference now to the figures,  depicts a block diagram representation of an example data processing system. DPS  comprises at least one processor or central processing unit (CPU), of which CPU  is illustrated. CPU  is connected to system memory  via system interconnect\/bus . Also connected to system bus  is I\/O controller , which provides connectivity and control for input devices, of which pointing device (or mouse) , keyboard , and receiver (microphone)  are illustrated, and output devices, of which display  is illustrated. Additionally, removable storage drives, e.g., multimedia drive (MD)  (e.g., CDRW or DVD drive) and USB (universal serial bus) port , are also coupled to I\/O controller . Removable storage drives, such as multimedia drive  and USB port , allows removable storage devices (e.g., writeable CD\/DVD or USB memory drive, commonly called a thumb drive) to be inserted therein and be utilized as both input and output (storage) mechanisms. Voice recognition unit  and signal input unit  are illustrated as connected to I\/O controller . Signal input unit  receives antenna, cable, digital, and\/or satellite transmission signals. Signal input unit , human sensory output device (HSOD)  (such as a television or radio, for example) and voice recognition unit  communicate via a wired and\/or wireless connection. HSOD  includes, but is not limited to a television, stereo (music output device), video display, or any device that outputs information and\/or entertainment pertaining to human sensory. Additionally, DPS  also comprises storage , within which data\/instructions\/code such as a database of keywords and scores may be stored.","DPS  is also illustrated with a network interface device (NID) , by which DPS  may connect to one or more access\/external networks , of which the Internet is provided as one example. In this implementation, the Internet represents\/is a worldwide collection of networks and gateways that utilize the Transmission Control Protocol\/Internet Protocol (TCP\/IP) suite of protocols to communicate with one another. NID  may be configured to operate via wired and\/or wireless connection to an access point of the network. Network  may be an external network such as the Internet or wide area network (WAN), or an internal network such as an Ethernet (local area network\u2014LAN) or a Virtual Private Network (VPN). Connection to the external network  may be established with one or more servers , which may also provide data\/instructions\/code for execution on DPS , in one embodiment.","In addition to the above described hardware components of DPS , various features of the invention are supported via software (or firmware) code or logic stored within system memory  or other storage (e.g., storage ) and executed by CPU . Thus, for example, illustrated within system memory  is application  and voice and sound recognition (VSR) utility  (which executes on CPU  to provide VSR logic). Application  and\/or VSR utility  include a voice recognition application (e.g. IBM (International Business Machines) ViaVoice\u00ae, Dragon Naturally Speaking\u00ae, a product of Nuance Communications, Inc., Microsoft Windows\u00ae Speech Recognition, a product of Microsoft Corp). In actual implementation, VSR utility  may be combined with or incorporated within application  to provide a single executable component, collectively providing the various functions of each individual software component when the corresponding combined code is executed by CPU . For simplicity, VSR utility  is illustrated and described as a stand alone or separate software\/firmware component, which provides specific functions, as described below.","In one embodiment, servers  include a software deploying server, and DPS  communicates with the software deploying server () via network (e.g., Internet ) using network interface device . Then, VSR utility  may be deployed on the network, via software deploying server . With this configuration, software deploying server performs all of the functions associated with the execution of VSR utility . Accordingly, DPS  is not required to utilize internal computing resources of DPS  to execute VSR utility .","In another embodiment, signal input unit  receives one or more of an antenna, cable, digital, and\/or satellite transmission signals and transmits one or more of the signals to HSOD . Voice recognition unit (also described as a voice capture and recognition unit)  monitors the current broadcast program displayed on HSOD  via wired and\/or wireless connection between voice recognition unit , signal input unit , and HSOD . When or more human voices are received, voice recognition unit  and VSR utility  associate the number of unique human voices with the current broadcast program.","CPU  executes VSR utility  as well as OS , which supports the user interface features of VSR utility . In the described embodiment, VSR utility  generates\/provides several graphical user interfaces (GUI) to enable user interaction with, or manipulation of, the functional features of VSR utility . Certain functions supported and\/or implemented by VSR utility  generate processing logic executed by processor and\/or device hardware to complete the implementation of that function. For simplicity of the description, the collective body of code that enables these various features is referred to herein as VSR utility . Among the software code\/instructions\/logic provided by VSR utility , and which are specific to the invention, are: (a) code\/logic for receiving audio input within sensory receiving environment; (b) code\/logic for identifying each unique human voice among the one or more human voices received within the audio input; (c) code\/logic for determining a count of unique human voices detected in the sensory receiving environment; (d) code\/logic for outputting the count of the one or more unique human voices as a count of audience members; (e) code\/logic for identifying one or more keywords within the audio input that includes speech and speech related sounds; (c) code\/logic for comparing the one or more received keywords to one or more pre-identified words in a database; and (d) code\/logic for generating a score for the one or more received keywords, wherein the score is one of a positive, a negative, and a neutral evaluation of the one or more received keywords. According to the illustrative embodiment, when CPU  executes VSR utility , components of DPS  initiate a series of functional processes that enable the above functional features as well as additional functionalities. These functionalities are described in greater detail below within the description of .","Those of ordinary skill in the art will appreciate that the hardware components and basic configuration depicted in  may vary. The illustrative components within DPS  are not intended to be exhaustive, but rather are representative to highlight essential components that are utilized to implement the present invention. For example, other devices\/components may be used in addition to or in place of the hardware depicted. The depicted example is not meant to imply architectural or other limitations with respect to the presently described embodiments and\/or the general invention. The data processing system depicted in  may be, for example, an IBM eServer pSeries system, a product of International Business Machines Corporation in Armonk, N.Y., running the Advanced Interactive Executive (AIX) operating system or LINUX operating system.","With reference now to , there is depicted a network of devices communicating with a voice recognition unit for detecting one or more voices in an audience, within a sensory receiving environment. Sensory receiving environment  includes DPS , television unit , and server . Database  is stored at server , and server  distributes and manages audience analysis graphical user interface (GUI) . Audience member  , audience member  , audience member  , and audience member   are detected by DPS . View  identifies audience member   is viewing television unit  without any audio expression. Within sensory receiving environment , one or more voice recognition unit(s)  is positioned at a location, which may be a public, private, and\/or consumer sensory receiving environment (). Voice recognition unit  has a wired and\/or wireless connection to DPS . Internet (e.g. network  of ) is utilized to connect voice recognition unit  locally to DPS  and\/or to remote server . Database  and GUI  are provided and\/or stored by server  and\/or DPS .","In one embodiment, one or more spectrograms are created when one or more voices are received by voice recognition unit . When the one or more voices are received, the voices are digitally sampled to create one or more spectrograms for each statement received. The spectrograms are created utilizing short-time Fourier transform. The digitally sampled data is partitioned, and each partition is Fourier transformed to calculate the magnitude of the frequency spectrum. The spectra from each partition, for a given statement, are conjoined to create the spectrogram.","In another embodiment, each time a new aural output is received by voice recognition unit  a new spectrogram is dynamically generated. The spectrogram depicts the received sound in terms of time, frequency, and amplitude. The resulting spectrogram is a depiction of consonants, vowels and semi-vowels in isolation or in combination (co-articulation) as created by one or more members in the audience, for example audience member  , audience member  , audience member  , and audience member  .","In one embodiment, a new spectrogram is compared to a first spectrogram to determine when a new audience member is within sensory receiving environment . The count of unique voices (thereby audience members) is incremented by one when an analysis of the spectrogram determines the spectrogram is from a new audience member (or unique voice). A first spectrogram generated during a first program is compared by voice and sound recognition (VSR) utility ( of ) to a second spectrogram generated during the first program. The patterns and peaks depicted by the spectrograms provide information for the distinctive aural characteristics of each statement. If one or more patterns and peaks of the first spectrogram and the second spectrogram are identical (within a predetermined margin of error), the second spectrogram is not identified as a spectrogram from an unique voice (or audience member). Thereby the count of audience members is not incremented by one. If all patterns and peaks of the first spectrogram and the second spectrogram are unique (within a predetermined margin of error), the count of unique voices is incremented by one.","In one embodiment, voice recognition unit  includes an acoustic processing section for converting an analog voice signal into a digital voice signal. Voice recognition system recognizes a voice signal as a word string. The VSR utility performs one or more arithmetical operations on the received voice signal. An acoustic model (along with one or more pre-identified keywords stored in database ) is retrieved to determine the intent of the words provided in the voice signal.","In one embodiment, database  stores the keyword information such as acoustic models including, but not limited to, structures of a sentence, and a probability of appearance of words. A decoding application is included within the VSR utility for recognizing the digital voice signal as a word string. The audio response is decoded utilizing previously stored acoustic model and keyword information.","In another embodiment, VSR utility  (of ) dynamically analyzes a digital speech signal when voice recognition unit  receives one or more words from an audio response. The audio response is transformed into the frequency domain utilizing a windowed fast Fourier transform. The fast Fourier transform analyzes at least every 1\/100 of a second, and each 1\/100 of a second result in a graph of the amplitudes of frequency components. The graph of the frequency components describe the sound received within that 1\/100 of a second. Voice recognition unit  utilizes database  which includes one or more previously entered graphs of frequency components, such as a codebook. The previously entered graphs of frequency components associate one or more sounds, made by a human voice, with one or more predetermined words. The audio sounds received by voice recognition unit  are identified as one or more pre-identified keywords by matching the Fourier transformed audio response to one or more entries within the codebook. When a word within database  is a match, one more rules are imposed by one or more of an acoustic, lexical, and language model to determine the intent of the audio response.","In one embodiment, voice recognition unit  includes one more speaking modes for recognition of the audio response. A first speaking mode is an isolated word mode, whereby one or more predetermined words and phrases are received and\/or extracted by voice recognition unit  when the audio response is received. A second speaking mode is a continuous speaking mode, whereby voice recognition unit  receives the audio response and analyzes the one or more words respectively (i.e. in order, as received by voice recognition unit ). The independent and continuous speaking modes are speaker independent. In another embodiment, voice recognition unit  is associated with the signal displayed on television unit . Voice recognition unit  automatically cancels the sound output by the signal associated with sensory receiving environment . For example, when a character in a movie states \u201cI have had the best time tonight\u201d the statement is received as a separate statement at the voice recognition unit. The separate signal is inverted when received voice recognition unit . When the broadcast\/program signal is received at voice recognition unit  VRU utility adds a \u2018negative\u2019 (or inverted) signal of the received broadcast\/program signal (separate), thereby creating a null signal. The inverted separate input is added to the received input from the audio detection unit to generate a filtered output with the captured audio response from audience member  , audience member  , audience member  , and\/or audience member  . Voice recognition unit  does not receive the statement \u201cI have had the best time tonight\u201d as an audio response from the audience; instead voice recognition unit  receives a filtered output. Whereby the filtered output, or audio response received in sensory receiving environment  is an expression of individuals within the audience (audience member  , audience member  , audience member  , and\/or audience member  ). The filtered output is received by voice recognition unit , and processed as an audio input that includes speech and speech related sounds.","In another embodiment, one or more words spoken in sensory receiving environment  are compared to the subject matter associated with sensory receiving environment  (e.g. food, shopping, program, sporting event). The subject matter associated with sensory receiving environment  is compared to the audio response received. One or more subjects are linked to pre-identified keywords database . Calculating a score of the subject matter includes utilizing a predetermined analysis formula. The predetermined analysis formula calculates when a statement is not applicable to a subject matter, when a negative score should be applied for a statement, and when a positive score should be applied for a statement. When the audio response received within sensory receiving environment  does not match pre-identified keywords associated with the response, the audio response may not be applicable to the subject matter. When the audio response is not applicable to the subject matter, the inapplicable audio information is dismissed as a candidate for scoring the subject matter, or the audio information is rated neutrally. For example, when the statement \u201cnow I am hungry\u201d is made during a food commercial, the predetermined analysis formula assigns a high score to the commercial (for the associated statement) because the content of the commercial is effective in inducing a food craving (hungry) for at least one person in the viewing environment. However, when the statement \u201cnow I am hungry\u201d is made at a pet store, the predetermined analysis formula assigns a neutral score to the pet store for the statement because the statement is not associated with the efficacy of the pet store. The sensitivity of voice recognition unit  to determine when to score and dismiss statements is modified according to the viewing environment. For example, the sensitivity of a voice recognition unit to dismiss statements at a fast food restaurant is higher than at a five star restaurant because conversation at a fast food restaurant is more diverse (i.e. inclusive of a variety of subjects).","In one embodiment, voice recognition unit  is a speaker independent and a continuous speech recognition unit. Therefore voice recognition unit  is not tuned to one particular voice and does not require a pause between words to analyze the audio response. Voice recognition unit  analyzes spontaneous speech including laughter, involuntary repeat of words, long and short pauses, etc. VSR utility ( of ) analyzes stress, inflection (i.e. tone), and rhythm of the received word(s) to determine intent (e.g. sarcasm, delight, anger, frustration) of the received audio response.","In another embodiment, multiple microphones and\/or a microphone array are associated with DPS  and\/or voice recognition unit . Increasing the number of microphones lowers the signal to noise ratio, thereby improving voice recognition accuracy. Within sensory receiving environment  multiple microphones and\/or microphone arrays produce directionally sensitive gain patterns that are adjusted to increase sensitivity to audience member(s) of sensory receiving environment . Increasing the sensitivity of voice recognition for the audience members reduces the error rates associated with voice recognition analysis in sensory receiving environment .","In one embodiment, a voice recognition unit is positioned in sensory receiving environment . Sensory receiving environment  is for example a physical building, enclosed environment, or open environment. Voice recognition unit  is positioned in sensory receiving environment  and communicates with DPS . Voice recognition unit  is controlled by a utility (VSR utility ) and provides a voice recognition response application.","In one embodiment, a voice recognition unit communicates with a local (e.g. DPS ) and\/or remote device (e.g. server ) via the Internet. Voice recognition unit  receives information from and delivers information to database  and GUI  via server . Database  stores preselected and\/or pre-identified keywords and spectrograms associated with the pre-identified keywords. DPS  and\/or server  store database . GUI  displays information, such as audience dynamics (e.g. audience population, including but not limited to gender information) and audience feedback (e.g. audience response to goods, service, and environment). GUI  is automatically updated via DPS  and\/or server  when customer feedback is received. Database  is associated with an application programming interface to provide access and manipulation of GUI .","In another embodiment, a predefined subject matter for the customer feedback is received by the VSR utility. The speech recognition application enables voice recognition unit  to detect one or more audience response statements in the form of audio input within a sensory receiving environment . VSR utility ( of ) searches the received audio input for one or more words that match the previously stored (pre-identified) keywords in database . When a match of the one or more pre-identified keywords and received keywords is determined, a further analysis is performed utilizing an acoustic, lexical, and language model to determine the intent of the audience response statements.","In one embodiment, a score is applied to a response statement received within sensory receiving environment . One or more \u201cscores\u201d are assigned to each pre-identified keywords stored within database , whereby the score is a \u201cnegative\u201d, \u201cpositive\u201d, \u201cneutral\u201d, or numbered score. The VSR utility determines an association between the spoken words and the keywords within database  and assigns a score to the customer response statement. The score of the response statement, received from the customer, depicts a positive, negative, or neutral evaluation of the subject matter associated with the sensory receiving environment .","In one embodiment, one or more unique human voices in an audience are identified during a program (e.g. a broadcast of a program, a live performance, exhibition of a video, exhibition of a video game, and\/or output of audio) within a sensory receiving environment (). DPS  determines when the one or more sounds are a human sound. DPS  receives and analyzes any verbal noise that is identifiable via measureable characteristics to identify an individual (e.g. laughing, humming, singing, whispering, booing, cheering, etc).","In another embodiment, a total count of audience members within the sensory receiving environment () is detected via one or more voice recognition units. Voice recognition system  identifies one or more unique human voices during the program (e.g. a broadcast of a program, a live performance, exhibition of a video, exhibition of a video game, and\/or output of audio). Audience member  , audience member  , and audience member   are detected by a voice recognition system  and\/or DPS  (whereby voice recognition system  is associated with DPS ) when the individual members make a verbal statement. The characteristics of each human voice are analyzed at DPS . According to the unique characteristics of each of the detected voices, the VSR utility determines a count of unique human voices. The total count of audience members is calculated for all sensory receiving environments associated with the program, and the total count is utilized as an indication of the number of audience members sensing (i.e. listening to and\/or watching) the program.","In one embodiment, no voice is detected within the sensory receiving environment (), for example when a transmission of a broadcast program is received. Audience member   is watching television  without aural expression, as depicted by view . The total audience count is incremented by one when a transmission for the broadcast program is detected by DPS , for a predefined amount of time and no voice is detected. The detection of a change in the broadcast signal identifies that at least one audience member is within sensory receiving environment , even when no audio response is detected. When a new and\/or additional voice is received, such as audience member  , the current (and total) audience count is incremented by one after two unique voices are detected within sensory receiving environment . When transmission of a new program is detected, for a predefined amount of time, the audience member count is dynamically reset, and DPS  initiates a new count of the audience members for the new program.","In another embodiment, the total count of audience members detected within the sensory receiving environment is calculated. The total audience count is transmitted to an audience count database, database . Database  stores the current and past counts of audience members with respect to the associated program. Database  is associated with audience analysis GUI . When a unique human voice is detected, the count stored at database  is automatically modified to reflect the additional audience member(s). Audience analysis GUI  is dynamically updated when the audience count database is modified.","In one embodiment, a voice recognition unit is automatically initialized when one or more spoken words are detected. One or more voice recognition unit(s)  are associated with one or more audience member(s) (e.g. audience member  , audience member  , audience member  , and audience member  ). The one or more voice recognition unit(s)  dynamically receive an audience response statement from the one or more audience members. The statement comprises one or more keywords within the spoken words of the audience response statement. The spoken words are automatically detected by voice recognition unit  and compared to pre-identified keywords within a database. When a determination finds the spoken words of the audience response statement match and\/or is related to pre-identified keywords, a score is assigned to the response statement. The score and summary of the audience response statement(s) is provided in GUI , similar to (GUI  of ).","During implementation of the various embodiments, so as to respect the privacy rights of the audience within the sensory receiving environment, when voice recognition  is engaged one or more privacy statements are displayed (and\/or otherwise outputted within the environment). The privacy statement informs each individual that one or more statements output (i.e. spoken, expressed via song, laughter, etc) within sensory receiving environment  are being monitored. The privacy statement further notifies an individual entering sensory receiving environment  that although the statements are monitored, the statements are not recorded. The monitored statements are analyzed by a computer system which outputs information associated with sensory receiving environment . The information obtained within sensory receiving environment  is unassociated with the individual(s) providing the output.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 3","FIG. 2"],"b":["339","256","339","324","325","326"]},"In one embodiment, the audience response statement comprises one or more pre-identified keywords within the spoken words of the statement. The spoken words are automatically detected by a speech recognition unit and compared to preselected keywords within a database. When a determination finds the spoken words of the phrase  (consumer response statement) match and\/or is related to preselected keywords, the response statement is analyzed via the CFS utility ( of ). An audience response analysis depicts a positive, negative, or neutral evaluation from one or more audiences is provided (actions ), whereby the audience response analysis is represented as a score (as depicted in \u201cscore\u201d column of audience response GUI ).","In another embodiment, an audience response GUI  is dynamically updated. One or more predetermined analysis formulas determine the score of the audience response statement as related to the predefined subject matter. The predetermined analysis formula is associated with the audience response statement, whereby words which relate to the predefined subject matter are scored. One or more words within a database (database  of ) are assigned a score (score ). The phrases (phrase ) are displayed in audience response GUI . When one or more spoken words are equivalent in meaning to one or more words in the database, the keyword score of the word in the database is assigned to the spoken word, according to the position of the words in the sentence. A positive, negative, and\/or a neutral (action ) is applied to the word in the database (as associated with the statement of phrase ), resulting in a score (e.g. score ). The positive, negative, or neutral score is applied to the word according to the association of the word with one or more other words in the statement. For example, the term \u201cterrified\u201d in the statement \u201cWow, that was a super cool movie, I was terrified!\u201d would receive a positive score; however, the term \u201cterrified\u201d in the statement \u201cWhat a horrible movie, my children were terrified!\u201d would receive a negative score.","In one embodiment, the score of the statement is calculated according to a predetermined analysis formula, or actions . Actions  is any formula utilized to calculate the score of the audience response statement. The predetermined analysis formula may be one of: a positive feedback formula and a negative feedback formula. When the spoken words are associated with negative feedback, the score of the audience statement is adjusted negatively, and when the spoken words are associated with positive feedback, the score of the audience statement is adjusted positively, as depicted in audience response GUI . One or more of a pure score and an average score is calculated when one or more audience response statements are received.","An audience information GUI is depicted in . Audience information GUI  includes location and date , and current feedback results . Feedback button  and speaker (or microphone)  are hardware devices associated with audience information GUI . In one embodiment audience feedback GUI  is generated by a VSR utility (, of FIG. ). Audience information GUI  is automatically updated when new audience response results analysis are received by the VSR utility.","In one embodiment, the audience information GUI  is displayed by a data processing system. As new audience statements are received, current feedback results  are dynamically updated. Audience members (e.g. audience member  , audience member  , audience member  , and audience member  ) engage feedback button  and speak into speaker . The spoken words of the one or more audience members are automatically analyzed and the score within current feedback results  are dynamically updated. Programming of the voice recognition unit may be specific to a person, location, event, language and\/or any experience that provides feedback to improve and\/or modify a service, event, program, etc.","In another embodiment, audience feedback is received for one or more subjects (e.g. movie, park, and store) listed in current feedback results . An application programming interface associated with audience feedback GUI  allows the utility (VSR utility , ) to enable selection of one or more subjects. The subject associated with the audience feedback is selected before and\/or after the audience feedback (e.g. audio input is received) by speaker . The current number of responses, displayed within current feedback results , depicts the number of responses received by the voice recognition unit ( of ) for the associated subject.","In one embodiment, VSR utility  receives a signal via speaker  (associated with voice recognition unit  within sensory receiving environment ). VSR utility  receives the audio response as an acoustic signal. When an audio response is received, VSR utility  dynamically generates a subsequent GUI that outputs a message to determine whether the score of the audio response received expresses the intent of the audio response. The audience member that outputted the audio response may be given an option to accept or reject the score. When the score expresses the intent of the audio response the GUI returns to the original display and dynamically receives additional audio responses. When the score of the statement does not express the intent of the audio response, the audience member is given an option to repeat the statement until the statement expresses the intent of the audience member.","In another embodiment, an audience analysis graphical user interface is generated, wherein the total count of audience members is displayed. Audience population GUI is depicted in . Audience analysis GUI  comprises current audience count display  which includes: past listing time , current listing time , score , TV (or event) listing title , date and time stamp , and total count of audience members .","The count of unique human voices is transmitted to the server  (of ). Server  generates audience analysis GUI  utilizing information from audience count database () and\/or directly retrieved from DPS . When one or more unique human voices are detected during transmission of the broadcast program, audience analysis GUI  is dynamically updated with the total number of current audience members. As the date, time, broadcast program (or event) listing, and total audience count are updated, the following features of audience analysis GUI  are dynamically updated: date and time stamp , total count of audience members , current listing time , score , and TV listing title . Score  is an average score generated when one or more audio responses are received by one or more voice recognition units ( of ).","In one embodiment, broadcast program listings and audience counts are displayed on the audience analysis GUI. The current audience count is associated with current broadcast program (or event) listings displayed within current listing time . Past audience counts are associated with past broadcast program (or event) listings, displayed under past listing time . Past broadcast program (or event) listings are displayed with past audience counts for one or more broadcast program listings. Current broadcast program listings and current audience counts are displayed for one or more broadcast program listings.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIGS. 6-8","FIGS. 6-8","FIGS. 1-5","FIG. 1"],"b":["140","105","100","100","145","100"]},{"@attributes":{"id":"p-0062","num":"0061"},"figref":["FIG. 6","FIG. 6"],"b":["600","602","604","606","608","610","612","612","613","612","614","616"]},"The process for receiving customer feedback statements (response) is depicted in . The process begins at block , and continues to block  where the dynamic speech recognition system is enabled. At block  a customer feedback statement is automatically received by the speech recognition system. A decision is made at block , whether the spoken words (or comparable words) of the customer feedback statement are detected within the database. If the words are not identified in the database, the process continues to block . If the words are in the database the process continues to block  where the customer feedback statement is analyzed to generate a score or rating utilizing the predetermined analysis formula. At block  the score and\/or rating of the customer feedback statement is dynamically generated and displayed. The customer feedback analysis database and\/or GUI are automatically updated at block . The process ends at block .",{"@attributes":{"id":"p-0064","num":"0063"},"figref":["FIG. 8","FIG. 8"],"b":["800","802","804","806"]},"At block  a decision is made whether one or more of the voices are redundant. If one or more audience voices are redundant, the process continues to block . At block  the voice count is modified to reflect one viewer per unique voice. The process continues to block . If the audience voices are not redundant, the process continues to block . At block  the audience voice count is modified to reflect the count of unique voices within the recognized voices. The audience voice count is transmitted to the server at block . A decision is made at block , whether one or more new (additional) voices are recognized. If additional audience voices are recognized, the process continues to block . If additional audience voices are not recognized, the process continues to block . At block  the count for the current broadcast program is automatically updated. The updated count for the current broadcast program is displayed at block . The process ends at block .","In the flow charts above, one or more of the methods are embodied in a computer readable storage medium containing computer readable code such that a series of steps are performed when the computer readable code is executed (by a processing unit) on a computing device. In some implementations, certain processes of the methods are combined, performed simultaneously or in a different order, or perhaps omitted, without deviating from the spirit and scope of the invention. Thus, while the method processes are described and illustrated in a particular sequence, use of a specific sequence of processes is not meant to imply any limitations on the invention. Changes may be made with regards to the sequence of processes without departing from the spirit or scope of the present invention. Use of a particular sequence is therefore, not to be taken in a limiting sense, and the scope of the present invention extends to the appended claims and equivalents thereof.","As will be appreciated by one skilled in the art, the present invention may be embodied as a method, system, and\/or computer program product. Accordingly, the present invention may take the form of an entirely hardware embodiment, an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to herein as a \u201ccircuit,\u201d \u201cmodule,\u201d \u201clogic\u201d, or \u201csystem.\u201d Furthermore, the present invention may take the form of a computer program product on a computer-usable storage medium having computer-usable program code embodied in or on the medium.","As will be further appreciated, the processes in embodiments of the present invention may be implemented using any combination of software, firmware, microcode, or hardware. As a preparatory step to practicing the invention in software, the programming code (whether software or firmware) will typically be stored in one or more machine readable storage mediums such as fixed (hard) drives, diskettes, magnetic disks, optical disks, magnetic tape, semiconductor memories such as RAMs, ROMs, PROMs, etc., thereby making an article of manufacture in accordance with the invention. The article of manufacture containing the programming code is used by either executing the code directly from the storage device, by copying the code from the storage device into another storage device such as a hard disk, RAM, etc., or by transmitting the code for remote execution using transmission type media such as digital and analog communication links. The medium may be electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system (or apparatus or device) or a propagation medium. Further, the medium may be any apparatus that may contain, store, communicate, propagate, or transport the program for use by or in connection with the execution system, apparatus, or device. The methods of the invention may be practiced by combining one or more machine-readable storage devices containing the code according to the described embodiment(s) with appropriate processing hardware to execute the code contained therein. An apparatus for practicing the invention could be one or more processing devices and storage systems containing or having network access (via servers) to program(s) coded in accordance with the invention. In general, the term computer, computer system, or data processing system can be broadly defined to encompass any device having a processor (or processing unit) which executes instructions\/code from a memory medium.","Thus, it is important that while an illustrative embodiment of the present invention is described in the context of a fully functional computer (server) system with installed (or executed) software, those skilled in the art will appreciate that the software aspects of an illustrative embodiment of the present invention are capable of being distributed as a program product in a variety of forms, and that an illustrative embodiment of the present invention applies equally regardless of the particular type of media used to actually carry out the distribution. By way of example, a non exclusive list of types of media, includes recordable type (tangible) media such as floppy disks, thumb drives, hard disk drives, CD ROMs, and DVDs.","While the invention has been described with reference to exemplary embodiments, it will be understood by those skilled in the art that various changes may be made and equivalents may be substituted for elements thereof without departing from the scope of the invention. In addition, many modifications may be made to adapt a particular system, device or component thereof to the teachings of the invention without departing from the essential scope thereof. Therefore, it is intended that the invention not be limited to the particular embodiments disclosed for carrying out this invention, but that the invention will include all embodiments falling within the scope of the appended claims. Moreover, the use of the terms first, second, etc. do not denote any order or importance, but rather the terms first, second, etc. are used to distinguish one element from another."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The invention itself, as well as advantages thereof, will best be understood by reference to the following detailed description of an illustrative embodiment when read in conjunction with the accompanying drawings, wherein:",{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
