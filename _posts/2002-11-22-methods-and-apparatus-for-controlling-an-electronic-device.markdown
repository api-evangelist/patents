---
title: Methods and apparatus for controlling an electronic device
abstract: Methods and apparatus for controlling an electronic device connected to a network are provided. The methods and apparatus described herein convert a text based device list and/or a text based function list into text based voice prompt scripts. The voice prompt scripts are then read to a user via a text-to-speech engine. The user responds with a voice command for a device. The voice command is converted to text by a voice recognition engine. This text is then used to send a command to the electronic device via the network.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06889188&OS=06889188&RS=06889188
owner: Intel Corporation
number: 06889188
owner_city: Santa Clara
owner_country: US
publication_date: 20021122
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","DETAILED DESCRIPTION"],"p":["The present disclosure relates in general to computer systems and, in particular, to methods and apparatus for controlling an electronic device.","Designers of electronic devices, such as consumer electronic devices, use many different user interface mechanisms in an effort to increase ease of use. For example, a stereo may include a circular knob or an up\/down rocker switch for volume adjustment. Occasionally, designers of electronic devices include a voice recognition capability (e.g., \u201cdial phone\u201d)","This voice recognition capability must be integrated into each device at the time the device is designed and manufactured. In order to add voice recognition capabilities, each device must include a microphone and a voice recognition engine in the form of additional hardware and\/or software. As a result, device cost and design time are increased. Still further design time and costs are incurred if voice prompting is included (e.g., \u201cSay phone number\u201d).","In general, the example methods and apparatus described herein are used to control an electronic device connected to a network. The methods and apparatus convert text based device capabilities (i.e., functions) and\/or a text based device list into one or more text based voice prompt scripts. The voice prompt scripts are then read to a user via a text-to-speech engine. The user responds with a voice command for a device. The voice command is converted into text by a voice recognition engine. This text is then used to send a command to the electronic device via the network.","A block diagram of an example network environment is illustrated in FIG. . The illustrated environment  includes a server , a router\/modem , a personal computer (PC) , a hand-held device , a Universal Plug and Play (UPnP) enabled television , and a Universal Plug and Play enabled stereo . Of course, one or more of these devices may be combined into a single device. For example, the server , the personal computer , and\/or the router\/modem  may be combined into a single unit. Each of these devices is connected to each other via a local area network (LAN) . The local area network  allows the devices to communicate with each other and may be wired and\/or wireless. In addition, the LAN  may be connected to a wide area network (WAN) . For example, the LAN  may be connected to the Internet via the router\/modem , or the LAN  may be connected to the \u201cplain old telephone system\u201d (POTS) via the router\/modem . This connection allows external devices, such as a wireless telephone  (or any other voice input\/output device), to communicate with the LAN devices.","In order to facilitate communication between the LAN devices and\/or any WAN devices, each of the devices is structured to communicate using a common protocol. For example, each of the devices may use the Universal Plug and Play (UPnP) protocol. The Universal Plug and Play protocol is a standard protocol that uses Internet and Web protocols to enable devices to be plugged into a network and automatically know about each other. When a UPnP device is connected to a network, the device automatically acquires a Transport Control Protocol\/Internet Protocol (TCP\/IP) address and notifies other devices connected to the network of its presence using a discovery protocol such as a discovery protocol based on Hypertext Transfer Protocol (HTTP).","UPnP devices may discover the capabilities of other UPnP devices connected to the same network by transmitting a capabilities query and receiving a capabilities response. For example, a digital camera connected to a network may discover a printer connected to the same network. In this manner, the camera may issue a print command to a printer that the camera was not specifically programmed to control. Similarly, another device may issue a photo retrieve command to the digital camera. Any electronic device or appliance may be UPnP enabled. For example, a UPnP stereo and\/or a UPnP television may accept playback commands, volume commands, record commands, tuning commands, etc. from other UPnP devices.","The capabilities response may be a text based response. For example, the camera and the printer may use Extensible Markup Language (XML) and Universal Resource Locators (URLs) to talk to each other. Of course, many other protocols may be used. For example, simple object access protocol (SOAP), speech application language tags (SALT), speech application programming interface (SAPI), web service description language (WSDL), and\/or voice extensible markup language (Voice XML) may be used.","The server , the PC , and the hand-held device  are also UPnP enabled. Each of these devices may act as a control point for other UPnP devices connected to the LAN . A control point is a device which issues commands to another device. These commands may be text based (e.g., XML). For example, the hand-held device  may issue a \u201cvolume up\u201d command to the UPnP enabled television  and\/or stereo . Other devices may also act as a control point to devices on the LAN  via the Internet  and the router . For example, the wireless telephone  may issue an \u201coff\u201d command to the UPnP enabled television  and\/or stereo .","A more detailed block diagram of an example computer system  is illustrated in FIG. . The computer system  may be a personal computer (PC), a personal digital assistant (PDA), an Internet appliance, a cellular telephone, or any other computing device. In an example, the computer system  includes a main unit  powered by a power supply . The main unit  may include a processor  coupled by a system interconnect  to a main memory device  and one or more interface circuits . In an example, the system interconnect  is an address\/data bus. Of course, a person of ordinary skill in the art will readily appreciate that interconnects other than busses may be used to connect the processor  to the main memory device . For example, one or more dedicated lines and\/or a crossbar may be used to connect the processor  to the main memory device .","The processor  may be a simultaneous multi-threading (SMT) processor and\/or may include any number of processing agents and\/or processor resources. For example, the processor  may include an integer execution unit, a floating-point unit, a single instruction multiple data (SIMD) unit, etc. The processor  may include any type of well known processing unit, such as a microprocessor from the Intel Pentium\u00ae family of microprocessors, the Intel Itanium\u00ae family of microprocessors, and\/or the Intel XScale\u00ae family of processors. The processor  may also include any type of well known cache memory, such as static random access memory (SRAM). The main memory device  may include dynamic random access memory (DRAM) and\/or any other form of random access memory. For example, the main memory device  may include double data rate random access memory (DDRAM). The main memory device  may also include non-volatile memory such as FLASH memory. In an example, the main memory device  stores a software program which is executed by the processor  in a well known manner.","The interface circuit(s)  may be implemented using any type of well known interface standard, such as an Ethernet interface and\/or a Universal Serial Bus (USB) interface. One or more input devices  may be connected to the interface circuits  for entering data and commands into the main unit . For example, an input device  may be a keyboard, mouse, touch screen, track pad, track ball, isopoint, and\/or a voice recognition system.","One or more displays, printers, speakers, and\/or other output devices  may also be connected to the main unit  via one or more of the interface circuits . The display  may be cathode ray tube (CRTs), liquid crystal displays (LCDs), or any other type of display. The display  may generate visual indications of data generated during operation of the main unit . The visual displays may include prompts for human operator input, calculated values, detected data, etc.","The computer system  may also include one or more storage devices . For example, the computer system  may include one or more hard drives, a compact disk (CD) drive, a digital versatile disk drive (DVD), and\/or other computer media input\/output (I\/O) devices.","The computer system  may also exchange data with other devices via a connection to the network . The network connection may be any type of network connection, such as an Ethernet connection, digital subscriber line (DSL), telephone line, coaxial cable, etc. The network  may be any type of network, such as the Internet, a telephone network, a cable network, and\/or a wireless network.","The server  and\/or the PC  also include a voice recognition engine and a text-to-speech engine. The voice recognition engine converts human words to text and\/or other computer readable data. The text-to-speech engine converts text to human cognizable words. Using the text-to-speech engine, a text based capability response may be conveyed to a human user. Using the voice recognition engine, the user may give commands to a device.","A flow diagram of a user acting as a control point to a Universal Plug and Play device is illustrated in FIG. . In a typical scenario, the user  issues a capabilities request to a controlling application . In one example, the capabilities request is initiated by a voice command via a voice recognition engine . The voice recognition engine  may be located in any device (e.g., PC , server , and\/or wireless phone ). In another example, the capabilities request is initiated when the user  presses a button (e.g., a virtual button on the hand-held device ). In yet another example, the act of plugging in a UPnP device  (e.g., the television  or the stereo  of ) may act as an initiator of the capabilities request.","In response to the user requesting a list of capabilities and\/or in response to the detection of a UPnP device being plugged in to the network  and\/or some other event, the controlling application  transmits a UPnP device capabilities query to the UPnP device . The UPnP device  responds to the controlling application  with a UPnP capabilities response. This capabilities response includes text representations of commands the UPnP device  is capable of accepting. For example, if the UPnP device is the UPnP stereo  of , the capabilities response may include such commands as \u201cPower On\u201d and \u201cSet Volume.\u201d In addition, the capabilities response (or some other message from the device ) may include a device name (e.g., \u201cSony stereo\u201d).","The text of the capabilities response is used by a script generator  to generate a voice prompt script . The script generator  may be part of the controlling application  and\/or running on another UPnP device, such as the server  or the PC . The voice prompt script  includes text to be read to the user  by a text-to-speech engine . The text-to-speech engine  may be located in any device (e.g., PC , server , and\/or wireless phone ). The script generator  may used \u201ccanned\u201d text to generate the voice prompt script . This canned text may be combined with the text included in the capabilities response from the UPnP device  to generate the voice prompt script . For example, the canned text may be, \u201cTo turn the ______ on, please say ______,\u201d and the text from the capabilities response may include \u201cSony stereo\u201d for the device name and \u201cPower On\u201d for the power on command. As a result, the voice script may include, \u201cTo turn the Sony stereo on, please say Power On.\u201d In other words, a grammar table may be populated dynamically using data distributed on the network .","After one or more voice prompt scripts  are read to the user  via the text-to-speech engine , the user  sends a response to the controlling application  via the voice recognition engine . The user's response is then used by the controlling application  to generate a UPnP device action command. The UPnP device action command is then transmitted to the UPnP device .","The UPnP device  typically takes the action associated with the command and responds with an action response. For example, if the command is \u201cvolume up,\u201d the response may be \u201cnew volume level is seven.\u201d This response may be used to generate another voice script  and read to the user  in order to provide the user  with an audible acknowledgement that the action was taken, as well as additional information about the state of the UPnP device .","A detailed flowchart of a process  for controlling an electronic device is illustrated in FIG. . Preferably, the process  is embodied in a software program or a set of computer instructions which are stored in memory  and executed by the processor  in a well known manner. However, some or all of the blocks of the process  may be performed manually and\/or by another device. Although the process  is described with reference to the flowchart illustrated in , a person of ordinary skill in the art will readily appreciate that many other methods of performing the process  may be used. For example, the order of many of the blocks may be changed, and\/or the blocks themselves may be changed, combined and\/or eliminated.","Generally, the process  causes the processor  to convert a text based device list and\/or a text based function list into text based voice prompt scripts. The voice prompt scripts are then read to a user via a text-to-speech engine. The user responds with a voice command for a device. The voice command is converted into text by a voice recognition engine. This text is then used to send a command to the electronic device via the network.","The process  begins by causing the processor  to receive a user request for a list of devices and\/or a list of device functions (block ). The user request may be initiated by the user pressing a real button, pressing a virtual button, vocalizing a voice command to the voice recognition engine , and\/or by any other method of issuing a command to a computer. Alternatively, the processor  may detect a device  being plugged into the network  (block ). For example, the device  may send a signal to the processor  via the network , and\/or the processor  may periodically poll the network  for newly connected devices.","Subsequently, the processor  transmits a query to the devices connected to the network  (block ). For example, the query may be a query for a list of available devices and\/or a query for the capabilities of one or more devices. In response, the processor  receives the requested device list and\/or the request function list (block ). For example, the device list may include names and network addresses for a networked television , a networked stereo , and\/or any other networked device. In such an instance, the function list may include commands such as \u201cvolume up,\u201d volume down,\u201d \u201cchange channel,\u201d etc. Preferably, the capabilities are associated with one or more of the devices by name and\/or network address.","The received device list(s) and\/or function list(s) are then used to generate one or more voice prompt scripts  (block ). For example, a voice prompt script  may list one or more devices for potential selection by the user . In another example, a voice prompt script  may list one or more device commands for potential selection by the user . The list of commands may be specific to a previously selected device. In yet another example, a voice prompt script  may prompt the user  for an argument associated with a command, such as a volume level for a volume command.","Once the voice prompt scripts  are generated, the voice prompt scripts  are read to the user  via the text-to-speech engine  (block ). The user's response is then received via the voice recognition engine  (block ). The user's response (or portions of the user's response) are used to generate a device action command (block ). The device action command may include one or more command arguments. The device action command and\/or the command arguments are then transmitted to the UPnP device  via the network  (block ). In one example, Extensible Markup Language (XML) commands are transmitted to the UPnP device .","After the electronic device (e.g., the UPnP device ) receives the device action command, the device responds with a message to the processor  (block ). This response message may be used to generate a voice response (block ), which is read to the user  via the text-to-speech engine  (block ).","A ladder diagram of an example message flow for controlling an electronic device is illustrated in FIG. . The controlling application  queries the network  and receives a network list. The network list includes one or more devices connected to the network . The controlling application  then sends a formatted network list to the text-to-speech engine . The formatted network list includes additional text in order to present the network list in a more human friendly manner. The voice recognition engine  then provides the user's response.","The user's response is used to determine a device selection. The selected device is then sent a device query in order to determine the specific capabilities of the selected device. The selected device then responds with a device action list. The device action list is formatted (e.g., canned text is added), and the formatted action list is sent to the text-to speech engine . Again, the voice recognition engine  provides the user's response.","This time the user's response selects a device action (e.g., a device command) associated with the previously selected device. If necessary, the controlling application  then sends one or more argument queries to the text-to-speech engine  and receives corresponding argument responses from the voice recognition engine .","Once a device, a command, and any arguments are determined, the controlling application  sends a device action command to the device via the network . Subsequently, the device may respond with a device action response. In such an instance, the controlling application may send a formatted device action response to the text-to-speech engine .","In summary, persons of ordinary skill in the art will readily appreciate that methods and apparatus for controlling an electronic device have been provided. The foregoing description has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the scope of this patent to the examples disclosed. Many modifications and variations are possible in light of the above teachings. It is intended that the scope of this patent be defined by the claims appended hereto as reasonably interpreted literally and under the doctrine of equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
