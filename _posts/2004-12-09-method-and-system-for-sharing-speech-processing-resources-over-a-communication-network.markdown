---
title: Method and system for sharing speech processing resources over a communication network
abstract: A method and system () for sharing speech processing resources () over a (communication network () for handling multiple client types (, etc.) and multiple media protocol types. The system can include a router () coupled to the communication network, a speech response system () coupled to the router, and a server () coupled to the speech response system and the router. The server can include at least one processor programmed to determine a media protocol and a client type of a client used for speech communication with the server, adapt at least one among encoding or decoding for the speech communication based on the media protocol and the client type, and dynamically and adaptively configure of the speech processing resources based on the media protocol and the client type.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08706501&OS=08706501&RS=08706501
owner: Nuance Communications, Inc.
number: 08706501
owner_city: Burlington
owner_country: US
publication_date: 20041209
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["1. Technical Field","This invention relates to the field of communications, and more particularly to a method and system for sharing speech resources at a server.","2. Description of the Related Art","Automatic Speech Recognition (ASR) and Text to Speech (TTS) capabilities are being deployed in various computing applications. These capabilities are implemented utilizing different technologies that include, but are not limited to, desktop command and control, desktop dictation, command and control in noisy conditions, Telephony command and control, handheld device command and control, and wireless information services. As processing power to handle speech becomes affordable relative to return of investment and as speech technologies continue to grow, the number and variety of speech processing resources will also continue to grow.","Today's communications environment, however, is ill equipped to handle this growth. More specifically, no single existing server handles voice recognition and speech generation functions centrally and remotely for various kinds of media types. Different media types exist for telephony and data networks, each utilizing some form of digitized and encoded voice. Some systems process voice using packet-based standards like Voice over Internet Protocol (VoIP) standards (e.g., H.323\/SIP standards), while others use circuit-based standards. Some systems stream voice in real time, others package voice within files of file segments that do not have real time processing requirements. The different media types are also formatted according to a vast array of largely incompatible media formats, each tailored for a particular presentation device.","Using conventional communications environments, multiple systems having overlapping functionality are needed to handle different media types and speech processing tasks. Since voice processing systems are typically expensive in terms of memory utilization, CPU requirements, and software, the cost of these multiple systems can impede the growth and availability of speech processing resources. What is needed is a method and a system to cost effectively provide speech processing resources for various media types without requiring several expensive and functionally redundant systems.","Embodiments in accordance with the invention can enable a method and system where the same voice recognition engine resources on a server can process speech which comes either over telephone or IP network and also in various formats including pre-processed speech. Such a system can share the server recognition resources when calls are received from different client types.","In this regard, a first aspect of the invention involves a method of sharing speech processing resources at a server including the steps of determining a media protocol and a client type of a client used for speech communication with the server, adapting at least one among encoding and decoding for the speech communication based on the media protocol and the client type, and dynamically and adaptively configuring of the speech processing resources based on the media protocol and the client type. Adapting can be done based on speech quality requirements and configuring can be done by configuring the media protocol's application programming interfaces based on device type and application complexity. The determining step can be done by receiving and decoding a header having at least two among the client type, the media protocol type, an application type, and a language type. The processing step can involve processing the header and determining availability of speech processing resources at the server and the configuring step can involve assigning and configuring a speech engine.","In a second aspect of the invention, a system for sharing speech processing resources over a communication network for handling multiple client types and multiple media protocol types can include a router coupled to the communication network, a speech response system coupled to the router, and a server coupled to the speech response system and the router. The server can include at least one processor programmed to determine a media protocol and a client type of a client used for speech communication with the server, adapt at least one among encoding and decoding for the speech communication based on the media protocol and the client type, and dynamically and adaptively configure at least one of the speech processing resources based on the media protocol and the client type. The processor can be further programmed to adapt by adapting based on speech quality requirements and configure by configuring the media protocol's application programming interfaces based on device type and application complexity. The processor can be further programmed to determine by receiving and decoding a header having at least two among the client type, the media protocol type, an application type, and a language type. In this regard, the processor can be further programmed to process the header and determine availability of speech processing resources at the server and to configure by assigning and configuring a speech engine.","In a third aspect of the invention, a computer program has a plurality of code sections executable by a machine for causing the machine to perform certain steps as described in the method and systems outlined in the first and second aspects above.","Embodiments in accordance with the invention can share speech resources on demand or adaptively or dynamically over multiple transport mediums using different clients. Whether a client is an analog PSTN based system or a digital IP based voice system, embodiments herein can serve as intermediate middleware performing the resolution of the end points and media types based on the underlying protocol used. Speech resources can consider language type, vocabulary size, vocabulary type and background noise conditions during speech recognition for example and can further consider language type, vocabulary size, and speaker type during text to speech synthesis as examples in making appropriate routing decisions and selecting or configuring speech engines and servers.","In the implementation of many speech applications there is typically an audio interface with a microphone and a speaker on one side and a speech processing resource on the other side. As shown in , an existing communication system  illustrates a telephone caller  calling from point A, over a Public Switched Telephone Network (PSTN)  via a base station  that gets connected to servers  at point B via a PBX , a speech response system  and an optional operator  for information services or call center automation. Many servers are deployed at point B based on demand. The format of the voice signal sent from the speech response system  to the ASR\/TTS servers  in this system uses a specific packetization protocol and audio compression format. Since the endpoint in this is a telephone hand set (), the compression level is in the form of audio that accommodates a 4 kHz bandwidth of the PSTN . Such signals are mostly 8 kHz ulaw or alaw 8 bit signals.","Speech response system  can be any system capable of functioning as a speech-enabled interface between users and computer systems or software applications. Accordingly, the speech response system  can support speech recognition technologies that can replace telephone keypad input or Dual Tone Multi-Frequency (DTFM) input, which are typical input provided to many Interactive Voice Response (IVR) systems, with more natural voice responses. In one embodiment, the speech response system  can enable the execution of voice call processing and telephony channel handling using standards based technologies like VoiceXML or Call Control XML (CCXML). For example, the speech response system  can include the IBM WebSphere Voice Response from International Business Machines Corporation (IBM) of Armonk, N.Y. or any other such telephony solution that makes it possible to enable speech-based, self-service access to data and processes provided by one or more networked applications over a voice-based communication channel.","Referring to , another existing communication system  illustrates another variation where desktop devices  connect over a local area network or IP Network  via a router  to a dictation server  that is serving multiple dictation clients. The ASR\/TTS server  in this scenario receives a high quality microphone based input and again uses a packetization protocol optimized for this network condition and audio format. The signal quality in this case can be either 44 kHz or 22 kHz or 11 kHz 16 bit signed audio.","Referring to , in addition to a caller  communicating via a base station  and via an IP Network , there is a voice over IP phone  on a desktop connecting to a set of servers  for information services and call center automation applications in communication system . The voice over IP phone  can use the router  and speech response system  to communicate with the set of servers . It should be appreciated that in certain embodiments the speech response system  can be implemented in the manner previously detailed above in . For example, the speech response system  can include the IBM Websphere Voice Response for Advanced Interactive Executive (AIX). Voice over IP can also use a specific packetization and compression method to deliver the audio to the ASR\/TTS server or servers . In each of the examples shown in , the same service provider or user likely has three sets of resources serving very similar functionality but with duplication of software and hardware at a very high expense.","Now with reference to , an embodiment in accordance with the present invention can utilize shared resources to handle all three scenarios illustrated in . To achieve this, a server  in a communication system  can negotiate the different properties of the data being exchanged between the client side and the server side via an IP Network . Among the different properties being negotiated can include a simplified voice quality format (see further details below), a voice packetization format, a voice client type, and a voice capability service request (language, complexity). The clients (such as Voice over IP phone , digital handset , analog handset in telematics enabled vehicle , and desktop computers ) can have access to a routing table (in a router  for example) with available resources and will route the requests to any specific server available in the geographic proximity either directly or via a speech response system . When a server  receives a request to allocate ASR or TTS resources, it adapts to the type of request received.","More specifically, the communication system  of  illustrates an on-demand or adaptive or dynamic ASR\/TTS server farm  that can operate as a server for different kinds of clients. In one specific embodiment, the simplified voice quality format can be used to make the on demand ASR\/TTS server farm  less complex in terms of network bandwidth usage and processing complexity. The simplified quality format can be limited to two forms, namely to G.711 for voice delivered via a PSTN call to the Speech Response System which is acceptable for the band-limited audio received from PSTN and cellular calls and to RecoVC\u2014Pre-processed high quality audio from desktop or VoIP endpoints, which is an IBM proposed mechanism for distributed speech recognition where the compressed audio delivered to the speech recognition engine is in the format needed to immediately start the ASR process without any further decompression of the audio. While embodiments herein are not necessarily limited to use of the simplified quality format referenced above, such an embodiment can be ideally suited for personal digital assistants (PDAs), or Smart phones of the future using 3G networks or wireless 802.11b or g wireless LANs or Bluetooth.","Referring to , a communication system  can include a server  having a plurality of speech resources . As illustrated, each speech resource  can have an adaptive configuration . The server's speech resource  can negotiate the properties for each request. The server  can set the configuration and in turn can adapt to the processing needed. Among the properties in the adaptive configuration  that can be negotiated and set include audio type, language, complexity, and client type (among others). The audio type property can set the audio decoding logic for the speech resource . The language property can set the language requested by the client. The complexity property can allocate processing and memory for the resource  based on the complexity setting. And the client type property determines how results are delivered based on the client type. As the on-demand technology evolves, more and more properties can be associated in forming the adaptive configuration to make the servers as flexible as possible to appropriately handle various kinds of clients via server .","Each client (, , etc.) in  can have a request builder that creates a header for a request for a resource or can have the router  build a header on its behalf. Thus, intelligent clients like a Voice over IP (VoIP) phone or a Personal Data Assistant (PDA) can build their own header, while for analog handsets such as the handset in vehicle , the router  is pre-programmed to build a header. The header can have or list the capabilities for the request.","Referring to , a flow chart illustrates a method  on how a client can build a request. The request is started at step  and the headers are built at step . Then the headers can be filled at step . The headers can be filled with the appropriate properties such as audio type, language, complexity, and client type. Once the headers are filled at step , the request can be sent at step .","The request can be sent to the router  (). Referring to , another flow chart illustrates a method  of processing a request by the router  to get a resource on the speech server farm . The method  begins by getting the request at step  and processing the header at step . The availability (or suitability) of a specific resource at the server can be looked up during step . At decision block , if the resource appears to be available (or suitable), then the request is confirmed and routed to the appropriate resource on the server farm  at step . If the resource is unavailable (or unsuitable), then the request can be re-queued at step .","Meanwhile, the server or server farm  can be allocated and configured in accordance with the request as shown by the flow chart of  illustrating method . The method  can begin by accepting the request at step  and assigning or allocating an appropriate speech engine at step  based upon the request. The speech engine can be further configured at step . Once the speech engine is assigned and configured, the method  can confirm the same to the requesting client at step . Note, embodiments herein can be applied in conjunction with the concept of grid computing to enable an on-demand distributed and scaleable utility to serve various kinds of speech clients.","It should be understood that the present invention can be realized in hardware, software, or a combination of hardware and software. The present invention can also be realized in a centralized fashion in one computer system, or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software can be a general purpose computer system with a computer program that, when being loaded and executed, controls the computer system such that it carries out the methods described herein.","The present invention also can be embedded in a computer program product, which comprises all the features enabling the implementation of the methods described herein, and which when loaded in a computer system is able to carry out these methods. Computer program or application in the present context means any expression, in any language, code or notation, of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following: a) conversion to another language, code or notation; b) reproduction in a different material form.","This invention can be embodied in other forms without departing from the spirit or essential attributes thereof. Accordingly, reference should be made to the following claims, rather than to the foregoing specification, as indicating the scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["There are shown in the drawings embodiments which are presently preferred, it being understood, however, that the invention is not limited to the precise arrangements and instrumentalities shown.",{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
