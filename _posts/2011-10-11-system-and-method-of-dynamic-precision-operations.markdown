---
title: System and method of dynamic precision operations
abstract: In an embodiment, a method performs computer operations using a first fractional precision and a second fractional precision. A computer program has a source variable, a destination variable, and an operation. The source variable has a first dynamic fractional precision, the destination variable has a second dynamic fractional precision that differs from the first dynamic fractional precision, and the operation is related to the source variable and the destination variable. The source variable is aligned to a format of the destination variable, according to the first dynamic fractional precision and the second dynamic fractional precision. The operation is performed using the destination variable and the source variable. A value is assigned to the destination variable according to the operation. In this manner, a single codebase may be written that operates on various hardware that each have different bit precision capabilities, without requiring additional development and verification effort.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08880573&OS=08880573&RS=08880573
owner: Dolby Laboratories Licensing Corporation
number: 08880573
owner_city: San Francisco
owner_country: US
publication_date: 20111011
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Assignment Operation","Align Function","Rounding Mode","Assign Function","Compound Addition Operation","Addition Operation","Compound Multiplication Operation","Multiplication Operation","Compound Subtraction Operation","Subtraction Operation","Compound Division Operation","Division Operation","Conversion Operation","Equality Test Operation","Inequality Test Operation","Implementation Details","Differences from Other Existing Solutions","LIST OF REFERENCES"],"p":["This Application claims the benefit of priority to related, Provisional U.S. Patent Application No. 61\/392,314 filed on 12 Oct. 2010, hereby incorporated by reference in its entirety.","The present invention relates to computer programming, and in particular, to programming devices that implement a variety of numerical precisions.","Unless otherwise indicated herein, the approaches described in this section are not prior art to the claims in this application and are not admitted to be prior art by inclusion in this section.","It is common for software developers to provide library binaries compiled to a variety of diverse platforms. For example, a library may be compiled for an Intel processor, an Nvidia graphics processing unit (GPU), or a fixed-point digital signal processor (DSP). Developers want to take full advantage of a platform's specific architecture features. For example, to use a floating-point accelerator, or in fixed-point DSPs to take full advantage of a higher-precision architecture (say use 16 bits of precision in device A versus using 12 bits of precision in device B). Sometimes a developer may even provide source code that needs to be ported to an unknown, proprietary architecture, such as the processor for a high definition television (HDTV), a digital video disk (DVD) player or DVD recorder. Optimizing an algorithm for a specific architecture takes time, development effort, and verification effort.","In general, there are two parts in the platform-dependent code generation problem: 1) a platform-dependent makefile, and 2) platform-dependent code.","A \u201cmakefile\u201d is a file that is used by a \u201cmake\u201d utility for automatically building executable programs and libraries. \u201cCmake\u201d and \u201cGNU Make\u201d are examples of well known cross-platform build system generators that can help developers customize how to build executables for multiple platforms using a common source code tree. The makefile then generates the appropriate executable code for a given platform.","One way to address the generation of platform-dependent code is by writing a single program that includes separate code for each architecture. Then during compilation, the compiler selects the appropriate code portion to use for a given platform. For example, consider the case of writing code to be used on both a fixed point architecture and a floating point architecture. One may have two separate source code trees for each architecture, or may define separate code modules within a single file. For example, separate code modules may be defined as follows:",{"@attributes":{"id":"p-0009","num":"0008"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"#ifdef FLOAT"},{"entry":"\u2003\u2003\/\/ comment: include here C-code for a floating point architecture"},{"entry":"#endif"},{"entry":"#ifdef FIXED16"},{"entry":"\u2003\u2003\/\/ comment: include here C-code for a fixed 16-bit architecture"},{"entry":"#endif"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The \u201cFLOAT\u201d code tree is to be used for the floating point architecture, and the \u201cFIXED16\u201d code tree is to be used for the fixed point architecture. Then, on a makefile one uses the -DFLOAT or -DFIXED16 options to direct the compiler to use the appropriate code.","Another way to address the generation of platform-dependent code is described in U.S. Pat. No. 6,460,177. In the '177 patent at FIG. 3, a three-stage code modification and compilation approach is described to convert a floating point representation to a fixed point representation. First, the floating point code is compiled and run to generate statistics (see 22 in FIG. 3). Second, based on the statistics, the fixed-point representations are prescribed (see 23 in FIG. 3). Third, the fixed point code resulting from the prescribed fixed-point representations is compiled, run and tested (see 27 in FIG. 3).","Another alternative is to use base-10 instead of base-2 to represent values, as described in the document Decimal Floating Point (DFP) Functionality: Technical Preview (2007) by IBM Corp. This technique improves the accuracy of floating point representations by eliminating the inaccuracies of translating between human readable base-10 and machine oriented base-2 numbers.","The above-described methods have a number of shortcomings. First, one needs to explicitly create code for each target architecture. This takes time. Second, any change (say bug fix) for one target has to be copied and propagated to all other targets. This code maintenance takes time, as well as increases the chances of further bugs due to inaccurate adjustment when the code is copied and propagated to another target.","In response to the above-noted shortcomings, an embodiment of the present invention implements a method for maintaining platform-dependent code: the use of FIXED, a new fixed point arithmetic \u201cclass\u201d that has variable precision. Within a maximum of 64 bits (a \u201clong long\u201d) according to an embodiment, the FIXED class allows fixed point numbers to be represented using \u201ca\u201d bits for an integer part and \u201cb\u201d bits for a fractional part, represented as (a,b). The FIXED class supports a variety of operations among this new set of numbers, including shifting, addition, multiplication, division, square root, power, float to (a,b) translation, and operations with mixed precision. (As an example of an operation with mixed precision, consider (a3,b3)=(a1,b1)+(a2,b2), which is useful in FPGA\/RTL [field programmable gate array\/register transfer level] verification.)","Furthermore, the FIXED class allows programmers to dynamically change the precision of the objects as they are used or reused in the program. For example, one part of the program may use floating point precision for a variable, another part may use (2,14) fixed point precision for the variable, and another part may use (4,12) fixed point precision for the variable.","In addition, based on a switch during compile time, the FIXED class can be used for both floating point and fixed point architectures, making the codebase capable for both floating point and variable precision fixed point; this feature is helpful when prototyping new digital signal processing algorithms.","According to an embodiment, a method performs computer operations using a first fractional precision and a second fractional precision. A computer program has a source variable, a destination variable, and an operation. The source variable has a first dynamic fractional precision, the destination variable has a second dynamic fractional precision that differs from the first dynamic fractional precision, and the operation is related to the source variable and the destination variable. The source variable is aligned to a format of the destination variable, according to the first dynamic fractional precision and the second dynamic fractional precision. The operation is performed using the destination variable and the source variable. A value is assigned to the destination variable according to the operation.","According to an embodiment, the variables may have dynamic precision that includes a dynamic integer precision and a dynamic fractional precision.","According to an embodiment, various operations may be performed between the variables, including an assignment operation, an addition operation, a compound addition operation, a subtraction operation, a compound subtraction operation, a multiplication operation, a compound multiplication operation, a division operation, a compound division operation, a conversion operation, an equality test operation and an inequality test operation.","An embodiment has a number of advantages as compared to existing solutions, including ease of maintenance, speed of development, and mixed mode execution capability. Regarding ease of maintenance, developers need to maintain a single, much simpler than before, source tree. Any changes to the code are made only once. During \u201cmake\u201d one simply specifies the bit-accuracy of the target architecture and the FIXED Class takes care of the rest. Regarding speed of development, for example, one can develop a prototype algorithm in floating point, but then easily translate it to a fixed-point architecture suitable for an FPGA. Regarding mixed mode execution, a user may define which modules are to be executed in floating point and which modules are to be executed in fixed point. This allows algorithms to be executed in mixed mode, as long it is allowed by the target architecture (for example, RTL units that use specialized floating point blocks for specific tasks). Users can also take advantage of other hardware accelerators, such as a power\/square-root\/log unit, via a simple switch (instead of having to rewrite source code that was not originally written to take advantage of the hardware accelerator). Users can also select from a range of options for operation specifics like rounding modes and standard dependent math operations (e.g., IEEE divide rounding) using the options provided by the FIXED Class and application programming interface (API).","The following detailed description and accompanying drawings provide a further understanding of the nature and advantages of the present invention.","Described herein are techniques for programming using dynamic precision. In the following description, for purposes of explanation, numerous examples and specific details are set forth in order to provide a thorough understanding of the present invention. It will be evident, however, to one skilled in the art that the present invention as defined by the claims may include some or all of the features in these examples alone or in combination with other features described below, and may further include modifications and equivalents of the features and concepts described herein.","In the following description, various methods, processes and procedures are detailed. Although particular steps may be described in a certain order, such order is mainly for convenience and clarity. A particular step may be repeated more than once, may occur before or after other steps (even if those steps are otherwise described in another order), and may occur in parallel with other steps. A second step is required to follow a first step only when the first step must be completed before the second step is begun. Such a situation will be specifically pointed out when not clear from the context.","In this document, the terms \u201cand\u201d, \u201cor\u201d and \u201cand\/or\u201d are used. Such terms are to be read as having the same meaning; that is, inclusively. For example, \u201cA and B\u201d may mean at least the following: \u201cboth A and B\u201d, \u201conly A\u201d, \u201conly B\u201d, \u201cat least both A and B\u201d. As another example, \u201cA or B\u201d may mean at least the following: \u201conly A\u201d, \u201conly B\u201d, \u201cboth A and B\u201d, \u201cat least both A and B\u201d. When an exclusive-or is intended, such will be specifically noted (e.g., \u201ceither A or B\u201d, \u201cat most one of A and B\u201d).","As discussed above, the FIXED class according to an embodiment uses fixed point variables defined using a maximum of 64 bits (for example, 63 bits for the magnitude and 1 bit for the sign), with the format represented as (a1, b1). In this format, a1 is the number of whole (integer) bits and b1 is the number of fractional bits. For example, the variable x may have the format (4,12); thus 4 bits are available to represent the integer portion of the value stored in x, and 12 bits are available to represent the fractional portion of the value stored in x. The maximum number of bits may be changed in other embodiments as desired.","An embodiment of the present invention implements \u201cdynamic\u201d precision. (This may also be referred to as \u201cadjustable\u201d precision.) As discussed above, a fixed point variable has an integer part and a fractional part; the variable has dynamic precision when the number of bits allocated to or between the integer part and the fractional part may be changed. For example, the variable x may have the format (4,12); the variable x may be adjusted to have the format (8,8), to have the format (2,14), or to have the format (20,12). When the fractional part is dynamic, the variable x may be said to have dynamic fractional precision. When the integer part is dynamic, the variable x may be said to have dynamic integer precision. The integer part and the fractional part together may be less than or equal to the maximum number of bits defined for the variable (or defined by the particular implementation).","An embodiment of the present invention is implemented in the C++ language, where the FIXED class is implemented as a header file \u201cfixed.h\u201d and a header program \u201cfixed.cpp\u201d, and where the source code is written with the FIXED class in mind. C++ is an object-oriented programming language. Alternative embodiments may use programming languages other than C++, or non-object-oriented programming languages. An alternative embodiment may implement the FIXED class, or equivalent operations, as part of the compiler itself.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 1","FIG. 20"],"b":["100","100","100","102","104","106","108","110"]},"The source code  corresponds to the program to be compiled. The source code  may be a program for controlling a DSP or FPGA, or components of a DSP or FPGA. According to an embodiment, the source code  is written in the C++ language. The source code  includes dynamic precision variables in the format (a,b) as discussed above. The source code  also includes operations on and between the dynamic precision variables. The source code  may include a command to \u201cinclude\u201d the FIXED class component .","More specifically, the source code  may be viewed as including an application source  and a set of preprocessor precision directives . The application source  corresponds to the computer program that the programmer writes (that is then compiled into the object code  that controls the operation of a particular device). The preprocessor precision directives  define the specific wordlengths of FIXED objects in the application source  (and the source code ). The preprocessor precision directives  determine the dynamic precision operations in the source code . Thus, for implementing the same source code  on a different architecture device, only the preprocessor precision directives  need to be changed, and the application source  may remain the same.","The FIXED class component  contains the files that the make component  uses when performing the \u201cmake\u201d function on the source code . According to an embodiment, the FIXED class component  includes the header file \u201cfixed.h\u201d and the header program \u201cfixed.cpp\u201d. The header file \u201cfixed.h\u201d contains commands that generally define the operations and data structures of the FIXED class component . The header program \u201cfixed.cpp\u201d then uses the information in the header file \u201cfixed.h\u201d, for example via an \u201cinclude\u201d statement, to define the various tasks that the make component  is to perform when executing the make on the source code .","In another embodiment, the FIXED class component  may be part of a software library with an API that defines the methods that may be used in the source code . The software library may encapsulate the definitions and implementations of the various methods in the API to create a shared object (dynamic library) or an archive (static library).","The make component  performs the \u201cmake\u201d function as part of compiling the source code . The make component  uses the information in the FIXED class component  to replace the dynamic precision variables and operations in the source code  with the more traditional variables and functions expected by the compiler . More specifically, the header program \u201cfixed.cpp\u201d may include various \u201cinline\u201d segments that direct the make component  to replace portions of the source code  that use the dynamic precision variables and operations with the more traditional variables and functions expected by the compiler . A build utility such as GNU make may be used to implement the make component .","The compiler  compiles the output of the make component  to generate the object code . The programmer may direct the compiler  to compile the source code in a certain way so that the object code  is compiled appropriately for a specific target architecture. For example, the compiler  may compile the object code  to use floating point variables and operations in floating point mode (for example for debugging the source code ). A compiler such as the GNU C Compiler or the GNU C++ Compiler may be used to implement the compiler .","The object code  results from the compiler  compiling the source code .",{"@attributes":{"id":"p-0057","num":"0056"},"figref":["FIGS. 2A-2B","FIG. 1","FIG. 20","FIG. 2A","FIG. 2B"],"b":["200","110","102","100","200","102","108"]},"In general, the method  converts computer operations from a first fractional precision to a second fractional precision. For example, the source code  may have two variables x and y that have different dynamic precisions (a1,b1) and (a2,b2), and the method  may be used to control how the computer system behaves when performing operations on the variables x and y.","At , data and operation analysis is performed. More specifically,  includes two general operations and . At , program-specific bit precisions and word lengths are selected based on perceptual experiments. For example, for expected data values, particular bit precisions and word lengths are evaluated to verify that they produce acceptable results for a given computer program. As a more specific example, assume the computer program is to perform filtering on data; the bit precisions and word lengths are then selected such that the computer program produces acceptable results over the expected range of the data.","At , the optimal order of performing operations in the computer program is established. In general, orders the operations in the computer program in a way that recognizes the bit precisions and word lengths selected in . For example, if the program is multiplying three variables in which the order does not matter in the abstract, then orders them in a way that accounts for the bit precisions and word lengths. More specifically, if two of the variables have a high bit precision and the other has a low bit precision, the program is ordered such that the two high precision variables are multiplied together, then the result is multiplied by the low precision variable. Similarly, if two of the variables have long word lengths and the other variable has a short word length, the program is ordered such that the two long word length variables are multiplied together, then the result is multiplied by the short word length variable.","Various methods may be used to implement . For example, U.S. Pat. No. 6,460,177 describes a process that includes generating statistics in order to prescribe the fixed-point representations (see 22 and 23 in FIG. 3).","At , the application code with dynamic precision preprocessor directives is developed (see  in ).","At , the target architecture is defined. For example, a specific hardware device may have a floating point unit, or may have 16 total bits available for fixed point operations, or may have a power unit hardware accelerator, etc. This information may be provided via command line switches.","At , the computer program is compiled according to the information indicating the target architecture. For example, the compiler  compiles the source code , using the functions defined in the FIXED library , to generate the object code  (see ).","At , the computer program is executed. For example, the object code  (see ) may be executed on the particular target architecture (see  in ).",{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 2B","b":"210"},"More specifically, the method of  performs computer operations using a first fractional precision and a second fractional precision. For example, the source code  may have two variables x and y that have different dynamic precisions (a1,b1) and (a2,b2), and the method of  may be used to control how the target architecture behaves when performing operations on the variables x and y.","The source code  corresponds to a stored computer program. The computer program has a source variable, a destination variable, and an operation. The source variable has a first dynamic fractional precision, the destination variable has a second dynamic fractional precision that differs from the first dynamic fractional precision, and the operation is related to the source variable and the destination variable. For example, the source code  (see ) may include the statement \u201cx=y\u201d (referred to as an assignment operation), where x has precision (10,10) and y has precision (5,5).","At , the source variable is aligned to a format of the destination variable, according to the first dynamic fractional precision and the second dynamic fractional precision. The specifics of the alignment depend upon the particular operation. For example, in the assignment operation \u201cx=y\u201d where x has precision (10,10) and y has precision (5,5), the alignment depends on the fractional 10 bits of x and the fractional 5 bits of y. Alignment is more fully described below.","At , the operation is performed using the destination variable and the source variable. For example, for the statement \u201cx=y\u201d, the operation is an assignment operation. Various operations are described in more detail below.","At , a value is assigned to the destination variable according to the operation. For example, for the statement \u201cx=y\u201d, the value of the variable y is assigned to the variable x. Assignment is more fully described below.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":["FIG. 2C","FIG. 2A","FIG. 2A","FIG. 2A","FIG. 2A"],"b":["250","200","252","202","254","204","256","206"],"i":"a "},"The bit precision definitions  define the number of whole and fractional bits for the variables used in the process . For example, the bit precision definitions  define the number of whole and fractional bits for three variables a, b and c. The bit precision definitions  may also define other parameters used in the process . For example, the bit precision definitions  define the number of taps for the filter function implemented by application code .","The application code  controls a hardware device to perform various functions. For example, the application code  controls the hardware device to implement a finite impulse response filter with N taps. More specifically, the application code  controls the hardware device to implement the following function:",{"@attributes":{"id":"p-0075","num":"0074"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"c","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"n","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"msub":[{"mi":["a","n"]},{"mi":["b","n"]}],"mo":"*"}}}}}},"The target architecture definitions  define the target architecture. For example, the target architecture definitions  instruct the compiler  (see ) to include the compute unified device architecture (CUDA) runtime header when that target architecture is specified.","Operations","Various operations (see  in ) may be performed that are related to the dynamic precision variables. These operations may be referred to as \u201coverloaded\u201d operations: In a C++ implementation, an operator is \u201coverloaded\u201d when a user-defined class defines the operator to have special meanings. According to an embodiment, these special meanings relate to the dynamic precision of the variables. According to an embodiment, these operators are defined in the FIXED class, specifically in the \u201cfixed.cpp\u201d header program. According to an embodiment, the operators include assignment, addition, compound addition assignment, multiplication, compound multiplication assignment, subtraction, compound subtraction assignment, division, compound division assignment, apply gamma, remove gamma, square root, power, and conversion between floating point and dynamic point. (Note that the compound operations may be mentioned without the \u201cassignment\u201d phrase for brevity, e.g. \u201ccompound addition\u201d means \u201ccompound addition assignment\u201d.) The following sections detail these operations (including their related functions, such as the align function and the assign function).","In general, the assignment operation assigns the value of the source variable as the value of the destination variable. The assignment operation is represented by the equals sign \u201c=\u201d, which may also be referred to as the \u201cassignment operator\u201d. The assignment operation includes the align function (see  above, as well as the \u201calign function\u201d section below) and the assign function (see  above, as well as the \u201cassign function\u201d section below), which operate according to the dynamic fractional precisions of the source variable and the destination variable.",{"@attributes":{"id":"p-0080","num":"0079"},"figref":"FIG. 3","b":["300","300"]},"Consider the example assignment operation \u201cx=y\u201d, where x has format (a1,b1) and y has format (a2,b2). First, y is aligned to the format of x. More specifically, the number of fractional bits in x and y are compared. In the code portion , this is performed by the aligned_val( ) function. For more details on this function, see the section \u201cAlign Function\u201d below.","Second, the value of y is assigned to x. This maybe referred to as the \u201cassignment function\u201d, in which the value of y may be adjusted to reside within the dynamic range defined for x. Note that the \u201cassignment function\u201d differs from the \u201cassignment operation\u201d in that the assignment function is part of the assignment operation. More specifically, the value of y is adjusted according to the difference between the dynamic integer precisions of x and y (i.e., the assignment \u201coperation\u201d), and the adjusted value of y is assigned to x (i.e., the assignment \u201cfunction\u201d). In the code portion , the assignment function is performed by the assign_new_val( ) function. For more details on this function, see the section \u201cAssign Function\u201d below.",{"@attributes":{"id":"p-0083","num":"0082"},"figref":["FIG. 4","FIG. 2"],"b":["400","400","200","204"]},"In general, the code portion  operates as follows. Consider the variables x and y, where x has format (a1,b1) and y has format (a2,b2). If the number of fractional bits in y is smaller than that in x, i.e. b1>b2, then multiply the value of y by pow(2, b1-b2). In the code portion , this is implemented in the \u201celse\u201d path by the operation \u201creturn a.m_val<<shift\u201d, with the \u201cshift\u201d calculation performed at the top by the function \u201cint shift=m_fract-a.m_fract\u201d. (Note that when \u201cshift\u201d is 0, the \u201celse\u201d path is taken, but the value is shifted by zero. That is, when b1 and b2 are equal, there is no need to align x and y.) More generally, the value of y is increased according to the difference in fractional precisions.","If the number of fractional bits in x is smaller than that in y, i.e. b1<b2, then based on the specified rounding mode (see the section \u201cRounding Mode\u201d below), either truncate or round the additional precision bits in y while dividing the value of y by pow(2, a1+b1). More generally, the value of y is decreased according to the difference in fractional precisions, the fractional precision of y is reduced to match that of x, and the value of y is adjusted according to the specified rounding mode.","Note that the specifics of the align function depend upon the operation performed. In this section, the assign function was described with reference to the assignment operation. When a particular operation includes additional steps during alignment, those differences will be detailed along with the description of that operation (below).","In the code portion , the rounding mode is implemented by the \u201ctruncate\u201d Boolean variable. If \u201ctruncate\u201d is false, then the rounding value \u201cround_val\u201d is calculated (otherwise \u201cround_val\u201d is zero). The rounding value (zero or not) is then added to the shifted value of y.",{"@attributes":{"id":"p-0088","num":"0087"},"figref":["FIG. 5","FIG. 2"],"b":["500","500","200","208"]},"In general, the code portion  operates as follows. If the value to be assigned to the variable is above the maximum value (or below the minimum value) defined by the implementation, the value assigned is the maximum defined value (or the minimum defined value); otherwise the value is assigned as-is. (The value results from the operation performed; see for example  in .) The maximum and minimum defined values may be set as described below.",{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 6","b":["600","602","600","602","600","602"]},{"@attributes":{"id":"p-0091","num":"0090"},"figref":"FIG. 7","b":["700","700"]},"In general, the code portion  operates as follows. Consider the operation \u201cx+=y\u201d, where x has the format (a1,b1) and y has the format (a2,b2). First, y is aligned to the format of x, using the function \u201caligned_val( )\u201d (see above with reference to ). As a result, the value of y now has the same format as that of x. Second, the operation x+=y is performed (i.e., new_val+=m_val). Third, the resulting new value of x may be clipped to reside within the format defined for x, using the assign function \u201cassign_new_val( )\u201d (see above with reference to ).",{"@attributes":{"id":"p-0093","num":"0092"},"figref":"FIG. 8","b":["800","800"]},"In general, the code portion  operates as follows. Consider the operation \u201cz=x+y\u201d, where x has format (a1,b1), y has format (a2,b2) and z has format (a3,b3). First, a temporary result (\u201cresult\u201d in the code portion ) is formatted as (max(a1, a2)+1, max(b1, b2)). If the total number of bits in the format of \u201cresult\u201d exceeds the maximum number of bits for the implementation (e.g., 63), then the number of fractional bits is reduced so that the resulting number of bits in the format of \u201cresult\u201d does not exceed the maximum. This step is accomplished by the statement \u201cFIXED result(whole, fract)\u201d, where \u201cFIXED\u201d is the operation to create the \u201cresult\u201d object according to the FIXED class, and \u201cwhole\u201d and \u201cfract\u201d are the number of whole bits and fractional bits (respectively) for the temporary result, based on the formats of x and y.","Second, the temporary result is assigned the value of x. This step is accomplished by the statement \u201cresult=x\u201d. Notice that this statement includes the assignment operator \u201c=\u201d, thus this statement may be implemented by the assign function \u201cassign_new_val( )\u201d (see above with reference to ).","Third, y is added to the temporary result. This step is accomplished by the statement \u201cresult+=y\u201d. Notice that this statement includes the compound addition operator \u201c+=\u201d, thus this statement may be implemented by the compound addition operation (see above with reference to ).","Fourth, the temporary result is assigned to z. This step is accomplished by the assignment operator (\u201c=\u201d). When the result is assigned to z, the format conversion is implicit.",{"@attributes":{"id":"p-0098","num":"0097"},"figref":["FIG. 9","FIG. 8","FIGS. 3-4"]},{"@attributes":{"id":"p-0099","num":"0098"},"figref":"FIG. 10","b":["1000","1000"]},"In general, the code portion  operates as follows. Consider the operation \u201cx*=y\u201d, where x has format (a1,b1) and y has format (a2,b2). First, the value of x is multiplied by y and stored in a temporary variable. This step is accomplished by the statement \u201cnew_val=m_val*a.m_val\u201d.","Second, the value of the temporary variable is shifted to the right by the number of fractional bits in y, and the shifted value is assigned to x. In the code portion , the shifting is accomplished by the \u201cif . . . else . . . \u201d statement, and the assignment is accomplished by the \u201cassign_new_val(new_val)\u201d statement.",{"@attributes":{"id":"p-0102","num":"0101"},"figref":"FIG. 11","b":["1100","1100"]},"In general, the multiplication operation includes two implicit operations. The first implicit operation is multiplication, e.g. \u201cresult=x*y\u201d. The second implicit operation is assignment, e.g. \u201cz=result\u201d.","In general, the code portion  operates as follows. Consider the operation \u201cz=x*y\u201d, where x has format (a1,b1), y has format (a2,b2) and z has format (a3,b3). First, the \u201cresult\u201d object is created according to the number of whole and fractional bits in x and y, i.e. ((a1+a2),(b1+b2)). This step is accomplished by the statement \u201cFIXED result(whole, fract)\u201d, where \u201cwhole\u201d and \u201cfract\u201d are calculated as shown in the code portion , and where the number of fractional bits may be reduced as needed to stay within the maximum number of bits \u201cMAX_BITDEPTH\u201d defined for the implementation, e.g. 63 bits.","Second, the values of x and y are multiplied together, and the resulting value is assigned to the \u201cresult\u201d object. This step is accomplished by the statement \u201cresult.set_val((x.get_val( )*y.get_val( ))>>shift)\u201d, where \u201cshift\u201d is the number of fractional bits that get discarded when the product wordlength exceeds MAX_BITDEPTH. (In floating point operation this shift operation would return an error, hence the conditional if\/else.)","Third, the temporary result is assigned to z. This step is accomplished by the assignment operator (\u201c=\u201d). When the result is assigned to z, the format conversion is implicit.",{"@attributes":{"id":"p-0107","num":"0106"},"figref":"FIG. 12","b":["1200","1200"]},"In general, the code portion  operates as follows. Consider the operation \u201cx\u2212=y\u201d, where x has the format (a1,b1) and y has the format (a2,b2). First, y is aligned to the format of x, using the function \u201caligned_val( )\u201d (see above with reference to ). As a result, the value of y now has the same format as that of x. Second, the operation x\u2212=y is performed (i.e., new_val=m_val\u2212new_val). Third, the resulting new value of x may be clipped to reside within the format defined for x, using the assign function \u201cassign_new_val( )\u201d (see above with reference to ).",{"@attributes":{"id":"p-0109","num":"0108"},"figref":"FIG. 13","b":["1300","1300"]},"In general, the code portion  operates as follows. Consider the operation \u201cz=x\u2212y\u201d, where x has format (a1,b1), y has format (a2,b2) and z has format (a3,b3). First, a temporary result (\u201cresult\u201d in the code portion ) is formatted as (max(a1, a2)+1, max(b1, b2)). If the total number of bits in the format of \u201cresult\u201d exceeds the maximum number of bits for the implementation (e.g., 63), then the number of fractional bits is reduced so that the resulting number of bits in the format of \u201cresult\u201d does not exceed the maximum. This step is accomplished by the statement \u201cFIXED result(whole, fract)\u201d, where \u201cFIXED\u201d is the operation to create the \u201cresult\u201d object according to the FIXED class, and \u201cwhole\u201d and \u201cfract\u201d are the number of whole bits and fractional bits (respectively) for the temporary result, based on the formats of x and y.","Second, the temporary result is assigned the value of x. This step is accomplished by the statement \u201cresult=x\u201d. Notice that this statement includes the assignment operator \u201c=\u201d, thus this statement may be implemented by the assign function \u201cassign_new_val( )\u201d (see above with reference to ).","Third, y is subtracted from the temporary result. This step is accomplished by the statement \u201cresult\u2212=y\u201d. Notice that this statement includes the compound subtraction operator \u201c\u2212=\u201d, thus this statement may be implemented by the compound subtraction operation (see above with reference to ).","Fourth, the temporary result is assigned to z. This step is accomplished by the assignment operator (\u201c=\u201d). When the result is assigned to z, the format conversion is implicit.",{"@attributes":{"id":"p-0114","num":"0113"},"figref":"FIG. 14","b":["1400","1400"]},"In general, the code portion  operates as follows. Consider the operation \u201cx\/=y\u201d, where x has the format (a1,b1) and y has the format (a2,b2). First, an if\/else structure is evaluated for three cases. Case one, if x=0, the temporary result \u201cnew_val\u201d is given the value of zero. (In a 64 bit implementation, the value of zero may be represented as \u201c0LL\u201d, which is 64 bits (long-long) representing zero.) Case two, if y=0, \u201cnew_val\u201d is given the largest positive integer value defined for the implementation. (In a 64 bit implementation, the largest positive integer value may be represented by 0x7FFFFFFFFFFFFFFF in hexadecimal.) Case three, if neither x=0 nor y=0, division can occur normally according to the statement \u201cnew_val=(m_val<<a.m_fract)\/a.m_val\u201d. More specifically, the statement in case three normalizes both the numerator and the denominator prior to the divide operation to obtain the correct integer result. a.m_val has a.m_fract fractional bits. Since the numerical value returned by a.m_val is an integer, the numerator in this expression needs to be left shifted by the number of fractional bits in the denominator.","Second, the result of the division \u201cnew_val\u201d is assigned to x. This step is accomplished by the statement \u201cassign_new_val(new_val)\u201d, which implements the assign function described above (see ).",{"@attributes":{"id":"p-0117","num":"0116"},"figref":"FIG. 15","b":["1500","1500"]},"In general, the code portion  operates as follows. Consider the operation \u201cz=x\/y\u201d, where x has the format (a1,b1), y has the format (a2,b2) and z has the format (a3,b3). First, a temporary result (\u201cresult\u201d in the code portion ) is formatted as ((63-b1),b1). That is, \u201cresult\u201d is formatted to have the same number of fractional bits as x, and to have as many whole bits as to fill out the object (63 total bits of magnitude in this implementation). This step is accomplished by the statement \u201cFIXED result(whole, fract)\u201d, where \u201cFIXED\u201d is the operation to create the \u201cresult\u201d object according to the FIXED class, and \u201cwhole\u201d and \u201cfract\u201d are the number of whole bits and fractional bits (respectively) for the temporary result, based on the format of x and the maximum number of bits, and as described above regarding the compound division operation.","Second, the temporary result is assigned the value of x. This step is accomplished by the statement \u201cresult=x\u201d. Notice that this statement includes the assignment operator \u201c=\u201d, thus this statement may be implemented by the assign function \u201cassign_new_val( )\u201d (see above with reference to ).","Third, the temporary result is divided by y. This step is accomplished by the statement \u201cresult\/=y\u201d. Notice that this statement includes the compound division operator \u201c\/=\u201d, thus this statement may be implemented by the compound division operation (see above with reference to ).","Fourth, the temporary result is assigned to z. This step is accomplished by the assignment operator (\u201c=\u201d). When the result is assigned to z, the format conversion is implicit.",{"@attributes":{"id":"p-0122","num":"0121"},"figref":"FIG. 16","b":["1600","1600","1600"]},"Unary Subtraction Operation",{"@attributes":{"id":"p-0124","num":"0123"},"figref":"FIG. 17","b":["1700","1700","1700"]},{"@attributes":{"id":"p-0125","num":"0124"},"figref":"FIG. 18","b":["1900","1900"]},"In general, the code portion  operates as follows. Consider the comparison \u201cx==y\u201d, where x has the format (a1,b1) and y has the format (a2,b2). First, y is aligned to the format of x, using the \u201caligned_val( )\u201d function. Second, the newly-aligned y is compared to x, and the result of the comparison (e.g., true or false, 1 or 0, etc.) is returned.",{"@attributes":{"id":"p-0127","num":"0126"},"figref":"FIG. 19","b":["2000","2000"]},"In general, the code portion  operates as follows. Consider the comparison \u201cx!=y\u201d, where x has the format (a1,b1) and y has the format (a2,b2). First, x is compared to y using the equality test operation \u201c==\u201d, as described above with reference to . Second, the converse of the result of the equality comparison is returned.","An embodiment of the invention may be implemented in hardware, executable modules stored on a computer readable medium, or a combination of both (e.g., programmable logic arrays). Unless otherwise specified, the steps included as part of the invention need not inherently be related to any particular computer or other apparatus, although they may be in certain embodiments. In particular, various general-purpose machines may be used with programs written in accordance with the teachings herein, or it may be more convenient to construct more specialized apparatus (e.g., integrated circuits) to perform the required method steps. Thus, the invention may be implemented in one or more computer programs executing on one or more programmable computer systems each comprising at least one processor, at least one data storage system (including volatile and non-volatile memory and\/or storage elements), at least one input device or port, and at least one output device or port. Program code is applied to input data to perform the functions described herein and generate output information. The output information is applied to one or more output devices, in known fashion.","Each such computer program is preferably stored on or downloaded to a storage media or device (e.g., solid state memory or media, or magnetic or optical media) readable by a general or special purpose programmable computer, for configuring and operating the computer when the storage media or device is read by the computer system to perform the procedures described herein. The inventive system may also be considered to be implemented as a computer-readable storage medium, configured with a computer program, where the storage medium so configured causes a computer system to operate in a specific and predefined manner to perform the functions described herein. (Software per se and intangible signals are excluded to the extent that they are unpatentable subject matter.)",{"@attributes":{"id":"p-0131","num":"0130"},"figref":["FIG. 20","FIG. 20","FIG. 1","FIG. 20"],"b":["3020","102","102","110"]},"The computing system environment  is only one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention. Neither should the computing environment  be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in the exemplary operating environment .","Aspects of the invention are operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and the like.","Aspects of the invention may be implemented in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. Aspects of the invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote computer storage media including memory storage devices.","An exemplary system for implementing aspects of the invention includes a general purpose computing device in the form of a computer . Components of computer  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.","Computer  typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can accessed by computer . Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media (but not necessarily computer readable storage media; for example, a data signal that is not stored).","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , other program modules , and program data .","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through an non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media discussed above and illustrated in , provide storage of computer readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that, at a minimum, they are different copies. A user may enter commands and information into the computer  through input devices such as a keyboard  and pointing device , commonly referred to as a mouse, trackball or touch pad. Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . For complex graphics, the computer  may offload graphics processing through the graphics interface  for processing by the graphics processing unit . The graphics rendered by the graphics processing unit  may be stored in the video memory  and provided to the video interface . In addition to the monitor, computers may also include other peripheral output devices such as speakers  and printer , which may be connected through a output peripheral interface .","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on memory device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","It should be understood that the various techniques described herein may be implemented in connection with hardware or software or, where appropriate, with a combination of both. Thus, the methods and apparatus of the invention, or certain aspects or portions thereof, may take the form of program code (i.e., instructions) embodied in tangible media, such as floppy diskettes, CD-ROMs, hard drives, or any other machine-readable storage medium wherein, when the program code is loaded into and executed by a machine, such as a computer, the machine becomes an apparatus for practicing the invention. In the case of program code execution on programmable computers, the computing device generally includes a processor, a storage medium readable by the processor (including volatile and nonvolatile memory and\/or storage elements), at least one input device, and at least one output device. One or more programs that may implement or utilize the processes described in connection with the invention, e.g., through the use of an API, reusable controls, or the like. Such programs are preferably implemented in a high level procedural or object oriented programming language to communicate with a computer system. However, the program(s) can be implemented in assembly or machine language, if desired. In any case, the language may be a compiled or interpreted language, and combined with hardware implementations.","Although exemplary embodiments may refer to utilizing aspects of the invention in the context of one or more stand-alone computer systems, the invention is not so limited, but rather may be implemented in connection with any computing environment, such as a network or distributed computing environment. Still further, aspects of the invention may be implemented in or across a plurality of processing chips or devices, and storage may similarly be effected across a plurality of devices. Such devices might include personal computers, network servers, handheld devices, supercomputers, or computers integrated into other systems such as automobiles and airplanes.","An embodiment may have one or more differences as compared to other existing solutions. One difference is the ability to use differently-formatted variables (with regard to fractional bit precision) within a single operation, and to convert a variable between different fractional bit precisions. Another difference, as compared to the '177 patent, is that a statistical analysis need not be performed, but instead the target precision may be selected at compilation for a particular target architecture. Another difference, as compared to the '177 patent, is that a programmer may mix operations that have different fractional precisions; this allows the programmer to write the program to account for the precision requirements for the particular process and the target architecture. Another difference, as compared to the '177 patent, is that the programmer can write code that specifically targets the precision capabilities of specific FPGAs or DSPs (or the components therein).","Another difference, as compared to IBM's DFP document, is that the operations are natively performed in base-2 on fixed point values stored in a 64 bit word. The binary point may be adjusted using commands to change the precision, e.g. from (a1,b1) to (a2,b2). Since these are natively integer operations, the integer ALUs may perform these computations, without the need for additional hardware. However, when additional hardware units (e.g., power, square root, logarithm) are present, they may be used in order to enhance performance of the program. In addition, the FIXED class adds different rounding modes to match the order of operations with the RTL\/hardware units during the verification process.","The above description illustrates various embodiments of the present invention along with examples of how aspects of the present invention may be implemented. The above examples and embodiments should not be deemed to be the only embodiments, and are presented to illustrate the flexibility and advantages of the present invention as defined by the following claims. Based on the above disclosure and the following claims, other arrangements, embodiments, implementations and equivalents will be evident to those skilled in the art and may be employed without departing from the spirit and scope of the invention as defined by the claims.",{"@attributes":{"id":"p-0147","num":"0000"},"ul":{"@attributes":{"id":"ul0001","list-style":"none"},"li":["1. U.S. Pat. No. 6,460,177","2. IBM Corporation, Decimal Floating Point (DFP) Functionality: Technical Preview (2007)","3. U.S. Pat. No. 6,256,776","4. U.S. Pat. No. 6,941,329","5. U.S. Pat. No. 7,389,499","6. U.S. Application Pub. No. 2007\/0276647","7. U.S. Application Pub. No. 2009\/0077353","8. European Patent Office Pub. No. EP 0 378 830 B1","9. PCT Pub. No. WO 2009\/017849 A1"]}}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIGS. 2A-2B","FIG. 1"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 2C","FIG. 2A"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 20"}]},"DETDESC":[{},{}]}
