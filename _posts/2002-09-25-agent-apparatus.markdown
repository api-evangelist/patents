---
title: Agent apparatus
abstract: Apparatus for collecting information pertaining to a driver of the vehicle includes a unit for determining if the current load on the driver is a “low-load” in terms of satisfaction of one or more specific conditions. Driver information is stored and supplemented by answers to question scenarios communicated to the driver only when a “low-load” state is determined. A question information storage unit contains various question scenarios correlated with different items of driver information and from which a question scenario, corresponding to driver information not yet obtained, is retrieved for output when a “low load” is determined.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07079925&OS=07079925&RS=07079925
owner: Kabushikikaisha Equos Research
number: 07079925
owner_city: Tokyo
owner_country: JP
publication_date: 20020925
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND ART","DISCLOSURE OF THE INVENTION","DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["This invention relates to an agent apparatus which synthesizes a likeness of a human agent and, specifically, to an agent apparatus which automatically collects information on a vehicle driver through conversation between the driver and the agent.","An agent apparatus which presents an image of an agent within a vehicle, which actively engages in communication such as conversation with a user and senses a condition of the vehicle is proposed in the Japanese Patent Laid-open No. Hei 11-37766.","In use of the agent apparatus, for example, the remaining quantity of fuel such as gasoline, light oil, or the like is detected, the detected quantities immediately prior to the past five refuelings are stored, and when the average value thereof is reached, time to refuel is announced by the agent.","In such an agent apparatus, the more information on a user is collected, the more information desired by the user can be provided and the more conversations can be carried out. Accordingly, it is important for an agent apparatus to collect as much information on a driver as possible.","However, in the various agent apparatuses previously proposed, the user himself\/herself inputs each item of information, e.g. hobbies and preferences, as driver information as an initial step when the use of the agent apparatus is commenced.","As described above, since the prior art apparatus is dependent on the input by the user to collect the driver information, the burden of inputting on the user is large, even when only the bare minimum of information (essential input items without which a startup is impossible) is obtained.","The present invention seeks to solve the above problem, and it is an object of the present invention to collect information on a driver to the extent possible while placing the smallest possible burden on the driver.","The present invention attains the aforesaid object by providing an agent apparatus including: a load-on-driver detector to detect a work load on a driver; a question output means for outputting questions about the driver when a low-load state is detected by the load-on-driver detector; and an information receiver to obtain information on the driver based on the driver's replies to the questions.","The agent apparatus may further include driver information storage for storing driver information and question information storage for storing questions to obtain the driver information. The question output means referred to above reads out, from the question information storage, a question which corresponds to an item of driver information not stored in the driver information storage and outputs the question.","Furthermore in the present invention, in the agent apparatus described the state of the driver detected by the condition detector referred to above is at least one of driving and equipment manipulation. The load on the driver determined by the load-on-driver determiner referred to above is at least one of the work load imposed by driving and extent of vexation felt by the driver.","Moreover in the present invention, an agent presenter presents, as an agent, an artificial pseudo-living organism within the vehicle is provided, and the agent poses questions through at least one of a display screen and voice output.","Hereinafter, a preferred embodiment of a driver information collecting apparatus in accordance with the present invention will be explained in detail with reference to .","(1) Overview of the Embodiment","In an agent apparatus embodying the driver information collecting apparatus in the present embodiment, a personified agent is presented as a screen image (a two-dimensional image or three-dimensional image via holography, or the like) for communication with a driver.","Driver information pertaining to the driver such as age, gender, and hobbies, necessary for communications and the like with the agent according to preferences of the driver (user), is obtained and supplemented by questioning by the agent.","The questions for obtaining the driver information are posed by the agent, taking into account the load of the driving or manipulation of various items of equipment by the driver, and when in a low-load state, questions related to driver information which has not yet been obtained are output (through voice and image) in the order of highest priority.","By the driver's replies to the questions posed by the agent, the driver information is obtained and stored, which is then reflected in communications with the driver and the behavior of the agent.","For example, when the driver travels a straight road at a constant speed, without particularly listening to music or the like for a predetermined period of time or more, the agent asks the driver what type of cuisine he\/she likes (driver information of the highest priority which has not been obtained). The reply from the driver is stored in the driver information (data on hobbies and preferences), and thereafter the stored data on hobbies and preferences is utilized in recommending a restaurant (meal) to the driver, with restaurants of the genre preferred by the driver given higher priority.","As described above, by outputting questions pertaining to driver information in the form of communications with the agent, the driver information can be obtained automatically, and is the driver is thereby released from the vexation of inputting all of the driver information in advance.","Further, the questions pertaining to the driver information are output at a selected time when the work load on the driver is less. In other words, no question is output when the driver is manipulating equipment such as an air conditioner, performing a driving operation including steering, listening to audio equipment or the radio, or chatting with someone in the vehicle, so as to avoid vexation of the driver.","In addition, since the apparatus obtains and stores the driver information automatically through communication between the driver and the agent, the more questions the driver answers to, the more information and communication suitable for the driver's hobbies and preferences the agent apparatus can provide.","Additionally, the agent in the present embodiment is an artificial pseudo-living organism, and its figure (two-dimensional image or three-dimensional image) is presented within the vehicle by a display apparatus. The activity of the agent is determining by learning of the state of the vehicle itself, passengers, oncoming vehicles, and so forth. Such learning includes, not only the state of the vehicles, etc., but also answers and replies from the driver. Based on the state of the vehicle at each point in time and the learning up to that time point, the agent responds with wide variation (its behavior=action and voice) to the driver and the vehicle. This allows the driver to call up a plurality of agents within the vehicle at liberty and thereby make the in-vehicle environment comfortable.","Here, the artificial pseudo-living organism (agent) in the present embodiment has the identity of a subject such as a specific person, a creature, a comic character or the like, and such a pseudo-living organism responds with action and voice in such a manner that the identity and continuity of the subject is maintained. Further, the agent in the present embodiment, whose identity and continuity are expressed as something with a unique character and which is presented in the vehicle, has a synthesized voice, image and the like that vary according to the information learned in the past even in the same vehicle state.","(2) Details of the Embodiment",{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 1"},"In the present embodiment, an entire processing unit  controls all the communication functions. The processing unit  includes: a navigation processing unit  which searches for a route to the set destination and performs guidance through voice or displayed image; an agent processing unit ; an external I\/F unit  which interfaces the navigation processing unit  and the agent processing unit ; an image processing unit  for processing images such as an agent image, map image, and the like, as well as inputted images; a voice control unit , which controls outputting of voice, such as the voice of the agent and the route guidance voice, as well as inputted voice, are controlled; a state information processing unit  for processing the detected data for various states of the vehicle or the driver; an input control unit ; and a storage apparatus control unit .","The agent processing unit  determines the work (driving) load on the driver from the detected data for states inside and outside of the vehicle, the state operating of by the driver, and so forth, and asks questions to obtain the driver information which has not yet been accumulated when the load on the driver is low, to obtain and save the driver information from the reply as described later.","The navigation processing unit  and the agent processing unit  include a CPU (central processing unit) to control the data processing and the operations of each unit, and a ROM, a RAM, a timer and so forth connected to the CPU through bus lines such as a data bus, a control bus, and the like. The processing units  and  are connected by a network (in-vehicle LAN (local area network)) in a manner that the processed data can be exchanged therebetween.","The ROM is a read-only memory for storing in advance various data and programs for performing control functions by the CPU, and the RAM is a random access memory which the CPU uses as a working memory.","In the navigation processing unit  and the agent processing unit  in the present embodiment, the CPU reads the various programs stored in the ROM, and executes the various programs. Note that the CPU may read a computer program from an external storage medium set in the storage medium drive apparatus , store (install) the program in another storage apparatus such as agent data storage apparatus , navigation data storage apparatus  or a hard disk (not shown), read (load) a necessary program or the like from the storage media into the RAM, and execute it. Further, a program may be executed by reading directly from the storage medium drive apparatus  into the RAM.","In the present embodiment, the agent processing unit  creates various types of communicating behavior of the agent in conversation with the driver and control of operations to be performed in the navigation processing section , by assuming various conditions of the vehicle or the driver as well as input of driver information. In other words, where various conditions such as vehicle speed, time, travel region, temperature, remaining volume of gasoline, psychological distance, and driver information are the scenario startup conditions and the scene branching conditions, the actions to be taken by the agent for each condition are defined as a scenario for that condition.","Each scenario consists of a plurality of continuous scenes. A scene is a stage in a scenario, in which the agent poses a certain question, or provides information. Each scene is composed of a title, list, word balloon, background, and other small units (parts).","The scenes proceed in sequence according to the scenario. Depending on the scenario, a plurality of scenes are selected and presented according to the driver's reply to a question posed in a certain scene, the situation of the vehicle, and the like. In other words, there are scenarios in which a scenario branches and a branch is selected and followed according to a reply in the course of the scenario.","The data for the scenarios including the scenes are stored in the scenario data file  which will be described later. Correlated with a scene and stored as scenario data 1 to n of the scenario data file  are: the information to define when and where to execute a scenario (scenario startup condition), the data defining what behavior or conversation is to be performed by the agent and how the screen is to be arranged, data for instructions to be issued to a module such as the navigation processing unit  and so forth, and data for determining which scene should be selected, responsive to some event.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 2","b":"11"},"As shown in , the agent processing unit  includes a state determining unit , a scenario execution request determining unit , a scenario drive unit , a scenario data read-in unit , an image processing unit , a voice recognition control unit , a user input reception unit , and a data storage unit .","Each of the units  to  are in the form of corresponding engine (software program) stored in the CPU, the ROM, and so forth provided in the agent processing unit . The engine constituting each unit, such as the state determination unit  and the like, communicates events by transmitting data to other engines. The outputs of units  to  do not determine whether a scene should branch or not.","The state determining unit  is equipped with an API (application programming interface) for notification of a change in a state of time, place, various inputs, or the like. The state determining unit  issues a command to the scenario execution request determining unit  according to a change in such conditions (the set destination or the like).","The scenario execution request determining unit  refers to, through the API function, the determined conditions and inputs \u201cstates\u201d, and determines whether or not to execute a scenario. When a scenario is to be executed, a command requesting startup of the scenario is issued to the scenario drive unit .","Responsive to the scenario startup request issued by the scenario execution request determining unit , the scenario drive unit  determines whether or not to perform the startup.","When it is determined to execute the startup, the scenario drive unit  requests the scenario data read-in unit  to read the scenario data. Further, according to the scenario data, the scenario driver unit  forwards a request for image processing and a request governing the character's motions to the image processing unit . The scenario driver unit  also notifies the voice recognition control unit  of a dictionary used for the voice reorganization according to the scenario data. Further, the scenario drive unit  drives the scenario (controls the transition of scenes) in accordance with the results of voice recognition or inputs by the user.","In addition, the scenario drive unit  drives the scenario (controls the transition of scenes) by referring to the records such as the driver information in the data storage unit  through the API function.","The scenario data read-in unit  reads pertinent scenario data from the scenario data file  based on the request from the scenario drive unit . The scenario data read-in unit  also reads image data as commanded by the request from the scenario drive unit .","The image processing unit  renders an image of a corresponding scene or of the character (agent) based on the request from the scenario drive unit .","The voice recognition control unit  controls the instructions to a voice recognition unit . For example, the voice recognition control unit  specifies a dictionary for use as instructed by the scenario drive unit . When the results of voice recognition utilizing the specified dictionary are output by the voice recognition unit , the voice recognition control unit  issues a command corresponding to the recognized result to the scenario drive unit .","The user input reception unit  issues to the scenario drive unit  a command corresponding to the input from the user. Whether a user has input information is determined by the information from the input control unit .","The data storage unit  includes an API function to record the driver information and the like, and an API function to output the driver information and the like.","Incidentally, while the components of the agent processing unit  have been explained for the case of issuing a command and the case of using the API function, the event issuing may be applied to all the units, or the API function usage may be applied to all the units.","In , the storage medium drive apparatus  and a communication control unit  are connected to the external I\/F unit ; a display apparatus  and an imaging apparatus  are connected to the image processing unit ; a voice output apparatus  and a microphone (voice receiver)  are connected to the voice control unit ; a device  for detecting various states is connected to the state information processing unit ; and an input apparatus  is connected to the input control unit .","The detecting device  includes a current position detecting unit  and a driving operation detecting unit . The current position detector  detects absolute position (longitude and latitude) of the vehicle, and may include a GPS (global positioning system) receiver  which measures the position of the vehicle by using signals from an artificial satellite, an azimuth sensor , a rudder angle sensor , a distance sensor , a beacon receiver  for receiving positional information from beacons arranged along a road, and so forth.","While the GPS receiver  and the beacon receiver  are each capable of determining a location on its own, in a place where reception by the GPS receiver  or the beacon receiver  are impossible, current position is detected by a dead-reckoning navigation method using both the azimuth sensor  and the distance sensor .","The azimuth sensor  may be, for example, a geomagnetic sensor which determines the azimuth of the vehicle by detecting geomagnetism, a gyro such as a gas-rate gyro or an optic-fiber gyro which determines the azimuth of the vehicle by detecting the roll angular velocity of the vehicle and integrating the angular velocity, wheel sensors arranged sensors at the right and the left wheels for detecting the turning of the vehicle by the output pulse difference (moved distance difference), or the like.","The rudder angle sensor  detects a steering angle \u25a1 by using an optic rotation sensor installed on a rotating component of the steering system, a rotary variable resistor, or the like.","The distance sensor  employs various methods, for example, a method which detects and counts the number of rotations of the wheel, or a method which detects the acceleration and integrates it twice.","The distance sensor  and the rudder angle sensor  also function as driving operation state detectors.","The driving operation detecting unit  includes a brake sensor , a vehicle speed sensor , a direction indicator detector , a shift lever sensor , and a handbrake (parking brake) sensor .","Further, the driving operation detecting unit  includes an air conditioner detector , a wiper detector , and an audio detector  functioning as equipment manipulation detectors for detecting manipulation of equipment.","The brake sensor  detects whether or not the foot brake is engaged (pressed).","The vehicle speed sensor  detects the speed of the vehicle.","The direction indicator detector  detects whether or not the driver is manipulating the direction indicator, as well as whether or not the direction indicator is flashing.","The shift lever sensor  detects whether or not the driver is manipulating the shift lever, as well as the position of the shift lever.","The handbrake (parking brake) sensor  detects whether or not the driver is manipulating the hand brake, as well as the state of the hand brake (engaged or released).","The air conditioner detector  detects whether or not the driver is manipulating the various switches and the like of the air conditioner.","The wiper detector  detects whether or not the driver is manipulating the wiper.","The audio detector  detects whether or not the driver is manipulating the audio equipment such as a radio, CD player, and cassette player, and whether or not the audio equipment is operating to produce an audio output.","The driving operation detecting unit  includes, as other equipment manipulation detectors, a light detecting sensor to detect the operation of the headlights, dome lights, and the like, a seatbelt detecting sensor to detect the fastening and unfastening of the seatbelt by the driver, and other sensors.","The input apparatus  allows the driver to input the driver information, and serve as one of the means to respond to all of the remaining questions and the like by the agent.","The input apparatus  also provides for inputting: the current position at the start of driving (starting point) and the destination (arrival point) for the navigation processing; a selected traveling environment for the vehicle e.g. one which would allow transmission of a request for information such as traffic congestion information to an information providing station (transmission condition); the type (model) of the cell phone used in the vehicle; and so forth.","The input apparatus , may be a touch panel (functioning as a switch), keyboard, mouse, light pen, joystick, or remote controller utilizing infrared or the like. Audio recognition equipment may also be used. A remote controller using infrared or the like and a reception unit to receive various signals transmitted from the remote controller may also be provided.","In the remote controller, in addition to a joystick for operations such as shifting the cursor displayed on the screen, are various keys such as a menu specifying key (button) and a numeric keypad.","The input control unit  generates data corresponding to the content of input through the input apparatus  and supplies it to the agent processing unit  and the navigation processing unit . The input control unit  functions as the equipment manipulation detector by detecting whether or not the driver is in the process of manipulating equipment.","The storage medium drive apparatus  is a drive apparatus used to read a computer program from an external storage medium for the navigation processing unit  and the agent processing unit . In the computer programs stored in the storage medium, data, and the like are included.","Here, the storage medium which stores computer programs, may be a magnetic storage medium such as a floppy disk, hard disk, or magnetic tape, a semiconductor storage medium such as a memory chip or IC card, a storage medium capable of reading information optically such as a CD-ROM, MO, or PD (phase change rewritable optical disk).","Besides reading computer programs from these various storage media, if the storage media are writable storage media such as a floppy disk or IC card, the storage medium drive apparatus  is able to write in such storage media the data of the RAMs in the navigation processing unit , and the agent processing unit , or of a storage apparatus , or the like.","For example, by storing learned data such as the content for the agent functions (learning item data\/reply data) or driver information in an IC card, even when the driver drives a different vehicle, such data stored in the IC card can be read out and used, so that he\/she can communicate with the agent on the basis of data learned from his\/her past responses. Hence, it becomes possible to present, in the vehicle, not an agent for each specific vehicle, but an agent having learned content unique to each driver.","It is also possible to store scenario data in the IC card, whereby an original scenario unique to each user is made possible.","The communication control unit  is capable of being connected to cell phones utilizing wireless equipment. Besides communication over the phone circuit, the communication control unit  is configured to provide communication with the information station which provides traffic information data such as data on traffic congestion or traffic regulation, or with a station which provides karaoke data to be used for online karaoke in the vehicle.","Further, it is also possible to transmit and receive through the communication control unit  the learning data for the agent functions, the scenario data file, and so forth.","The voice output apparatus  is composed of a plurality of speakers arranged in the vehicle, to output voice under control of the voice control unit  such as voice guidance when route guidance is to be provided by voice, and to output the voice and sound for the agent's conversations with the driver as well as for the agent's questions for obtaining driver information. The voice output apparatus  may also serve as an audio speaker.","The microphone  functions to input and output voice which is the subject of the voice recognition by the voice control unit  such as the voice input of a destination and the like in the navigation processing, and conversations between the agent and the driver (including the replies by the driver) and the like. For this microphone , a dedicated directional microphone so as to properly collect the voice of the driver is used.","Note that the voice output apparatus  and the microphone  together may be in the form of a hand-free unit to allow phone communication without using a cell phone.","The microphone  and the voice recognition unit  also function as a conversation detector to detect when the driver is talking with a passenger, in which case the microphone  and the voice recognition unit  function as a state detector to detect the state of the driver.","The display apparatus  displays a road map for route guidance processed by the navigation processing unit , as well as various informational images, or displays a behavior (motion pictures) by the agent composed by the agent processing unit  as well as various parts (components) constituting a screen layout. Further, images of the inside and outside of the vehicle taken by the imaging apparatus  are displayed after being processed in the image processing unit .","The display apparatus  may be a liquid crystal display, CRT, or the like.","Note that the display apparatus  may also be equipped with an input function, as that of the aforementioned input apparatus , such as a touch panel or the like.","The imaging apparatus  is composed of cameras equipped with CCD (charge-coupled device) to take an image, and in addition to an in-vehicle camera which takes images of the driver, cameras are arranged on the exterior of the vehicle to take images of the front, rear, right side, and left side of the vehicle. The images taken by each camera of the imaging apparatus  are supplied to the image processing unit , in which such processes as image recognition are executed and each recognized result (whether with or without a passenger, recognition of the driver, and so forth) are reflected in the communications by the agent.","The storage apparatus  is connected to the storage apparatus control unit  so as to read and write data and programs under the control of the storage control apparatus .","The storage apparatus  stores agent data  and navigation data  and programs necessary to execute various agent functions and navigation functions according to the present embodiment.","The storage apparatus  may be, for example, any of various types of storage media such as a floppy disk, hard disk, CD-ROM, optical disk, magnetic tape, IC card, optimal card or the like, together with a drive apparatus thereof are used.","A plurality of different storage media and drives may be used together in such a manner that, learned item data , reply data , driver information , and scenario data files  are stored in IC cards or floppy disks which are easy to carry, while the other data would be stored on a hard drive.","The agent data  includes various types of data which are necessary for operation of the agent, such as an agent program , the scenario data file , voice data , the learned item data , the reply data , the voice data , image data  for display of images of the figure or behavior of the agent, the driver information , and so forth.","The agent program  is an agent processing program for operation of the agent function.","The learned item data  and the reply data  are data learned by the agent based on the driving operations and replies by the driver.","Accordingly, in the case of the learned item data  and the reply data , the data for each driver is stored and updated (learned).","The learned item data  includes stored items which are the subjects of learning for the agent, such as the total number of times or the number of times per day that the ignition is turned on, and data on the remaining volume of fuel at the time of refueling averaged for the last five refuelings. According to the content of the learned item data , for example, the content of the greeting by the agent at the time of appearance of the agent changes based on the number of times that the ignition has been turned on, or, on the volume of the remaining fuel falling below the average of the volume of the remaining fuel for the last five refuelings, whereupon the agent suggests refueling.","The reply data  includes, for each predetermined scenario, the past replies by the user to the behavior of the agent and for each reply item, the time and date of the reply and the content of the reply, for a predetermined number of times. Respective instances of being ignored, rejected, or accepted (tolerated) which characterize the content of the response are determined based on the voice recognition or on the input through the input apparatus , and are stored.","The scenario data file  stores the data for various scenarios which specify behavior of the agent for each condition or scene.",{"@attributes":{"id":"p-0106","num":"0105"},"figref":"FIG. 3","b":"302"},"For the scenario data file , a plurality of scenario data defining each scene are aggregated to form one file.","The scenario data file  includes a file header, scenario management table, automatic startup condition table, list of scenarios which can be started up manually, various scenario data 1 to n, and additional resource data.","The file header is a header for a scenario file and provides information on the file.","The scenario management table stores the data for managing the scenario data stored in the scenario file, such as the data for the priorities to be followed in executing each scenario.","The automatic startup condition table specifies and stores, for each scenario, the condition which triggers automatic start up of utilization of the scenario data stored in the scenario file.","The automatic startup conditions may be arrival at a specific point and or at a distance therefrom for a specific scenario, e.g. a scenario which is executed when a point at a certain distance from a specific point A is reached Another automatic startup condition may be the turning-on of the ignition which triggers a scenario in which the agent performs a salutation at the time of the startup, and or a predetermined time after the startup.","as Also included in stored data are automatic startup prohibiting conditions which prohibit automatic startup, for example: (A) priority given to manual startup, (B) another question scenario is currently being executed (C) a question scenario has been executed within, for example, the past 30 minutes, (D) music is heard, (E) steering for a curve to the right or to the left is in progress is (F) rapid deceleration or acceleration, (G) the driver is in conversation with a passenger, (H) operation of equipment, such as a navigation apparatus, audio apparatus, air-conditioning apparatus, shift lever, handbrake, wiper, or direction indicator, (I) use of audio apparatus, e.g. listening to music or a broadcast station, prohibiting automatic startup, and (J) ongoing receipt of driving route guidance. Note that the scenario management table establishes priorities so as to allow automatic startup in case of emergency (such as in the scenario making emergency contact with the fire station or the like), even when an automatic startup prohibition condition is fulfilled. The automatic startup prohibition conditions include conditions which are applied in common to all scenarios, and the conditions which are applied only to specific scenarios.","In the present embodiment, conditions which start the question scenario, in which the agent poses questions to collect the driver information, include the following conditions, as well as other conditions which determine that the load on the driver is in a low state:","(a) The question scenario has not been performed within the past one hour (a condition which prevents the posing of questions too frequently).","(b) Fifteen minutes or more have passed since the ignition was turned on (prevents questioning immediately after the start of driving).","(c) No conversation is heard in the vehicle (by collecting sound through the microphone ).","(d) The vehicle is driving on a straight road (as determined from the navigation data  and the current position), and the speed thereof has not changed for a predetermined period of time.","(e) The vehicle is waiting at a stoplight (determined from the navigation data , the current position, and the vehicle speed).","Whether all of the foregoing question-startup conditions are indispensable conditions or just one of them needs to be fulfilled for the startup is predetermined. For example, when being limited to the above conditions (a) to (e), the question-startup conditions are considered fulfilled and the question scenario may be started when (a) to (c) are entirely satisfied, and (d) or (e) is satisfied.","Even in this case, the question scenario is prohibited from starting when one of the automatic-startup prohibition conditions (A) described above is fulfilled.","Additionally, the startup determining routine based on the automatic startup conditions including the question-startup conditions is processed, for example, by a polling process repeated every one minute, or by an event specified in advance. Such an event specified in advance may be the setting of a destination, reception of an e-mail, or the like.","Among the respective conditions referred to above, the load on the driver is determined by the conditions (E), (F), (H), (J), (d), and (e), while the extent of vexation felt by the driver is determined by (C), (D), (G), (I), (J), (a), (b), and (c).","A list of manually startable scenarios is included among the scenarios stored in the scenario file.","As additional resource data, the voice data, image data, and the like to be added to the scenario data are also stored in the storage apparatus.","Each data file for scenarios 1 to n is composed of a scenario header, voice recognition dictionary DB, image data management table, scene management table, each scene data 1 to m, and actual image data. Each scenario includes a plurality of scenes.","The scenario header is the header section of the scenario data and contains information on the scenario.","The voice recognition dictionary DB is a DB of the voice recognition dictionary used in a scenario, and stores voice recognition dictionary data.","The image data management table stores data to specify images to be used in the scenario. The image of the agent is stored in the image data , and the images unique to the scenario are stored in the actual image data which is at the end of the scenario data.","The scene data management table stores data to manage the scene data stored in the scenario.","Each of the scene data files 1 to m is composed of a scene header, screen data, character motion instruction data, various routine execution instruction data, and scene branching table.","The scene header is the header section of the scene data, and stores data to manage information on the scene and each data section of the scene data.","The screen layout data is utilized to specify the screen layout in display of a certain scene, and includes data for each part of the screen layout displayed on the display apparatus .","The character motion instruction data includes instruction data for the motion and the content of speech by the character in a pertinent scene (data determining the voice data  to be used).","The various routine execution instruction data serve to request execution of a task or routine in another module (such as a navigator) in a pertinent scene.","The scene branching table consists of data for directing branching from one scene to the subsequent scene, and stores data defining the subsequent scene responsive to occurrence of an event during display of the one scene.","The voice data  stored in the storage apparatus  () includes voice data for use by the agent in conducting conversations and the like with the driver according to the scene of the selected scenario, e.g. questions to be posed in order to collect the driver information according to the present invention.","Each item of voice data  is specified by the character motion instruction data included in the scene data.","The image data , provides images representing the figure of the agent to be used in each scene specified by the scenario, for example, a front facing agent image, a bowing image, a right-hand raising image, and the like.","The figures of the agent stored in the image data  need not be a human-like figure (male or female), and may be a figure of an animal as it is such as, for example, a chicken, dog, cat, frog, or mouse, or a figure of personified animated animal, and furthermore may be a robot-like figure or a figure of a specific character. Further, the agent need not stay in a fixed age, and may be a figure that is initially a child, growing over time, changing into a figure of an adult, and then into a figure of an old person in accordance with the learning function of the agent. The image data  for one of the various figures of the agent, can be selected through the input apparatus  or the like according to the driver's preferences.","The driver information  is the information on the driver, and is used to make the behavior by the agent better suit the driver's demands, tastes, and preferences.",{"@attributes":{"id":"p-0142","num":"0141"},"figref":"FIG. 4","b":"307"},"As shown in , the driver information  includes the basic driver data such as the driver's ID (identification data), name, age, gender, marital state (married or not married), having or not having a child, the number of children, and the age of the children, as well as data on hobbies and preferences.","The hobbies and preferences data are composed of the major items such as sport, dining, and travel, and specific detailed items included in each major item. For example, a major item may include detailed data on the favorite soccer team, favorite baseball team, interest in golf, and the like.","In the present embodiment, priorities are set for the items of driver information, and the agent poses a question to elicit driver information not yet stored, in the order of descending priorities. The priority of the basic driver data is higher than that of the hobbies and preferences data.","The questions to obtain the driver information are asked by outputting the voice data specified in the character motion instruction data in the question scenario stored in the scenario data file .","The question sentences for the agent to obtain the driver information in the question scenario are illustrated by the following sentences:","\u201cWhat is your name?\u201d","\u201cWill you tell me your age?\u201d","\u201cWill you tell me your gender?\u201d","\u201cWhat is your hobby?\u201d","\u201cAre you interested in baseball?\u201d","\u201cAre you interested in golf?\u201d","\u201cAre you interested in soccer?\u201d","\u201cAre you interested in music?\u201d","\u201cWhich genre of music do you like?\u201d","\u201cWhat is your favorite soccer team?\u201d","\u201cWhat is your favorite baseball team?\u201d","\u201cDo you like hamburger?\u201d","\u201cWhen you dine out, do you go to a family restaurant most of the time?\u201d","These questions are stored as the character motion instruction data in the scenario data file  as the question sentences for each question scenario.","The data for each question sentence is delimited by each voice data stored in the voice data  in such a manner as, for example, \u201cWhat is\/your\/favorite\/baseball team?\u201d. The question is asked by the agent to the driver by reading out a unit of voice data corresponding to a delimited unit in the question sentence, and outputting it through the voice output device .","The navigation data  includes the data to be used for route guidance and so forth, communication region data file, picturized map data file, intersection data file, node data file, road data file, search data file, photo data file, and the like.","The communication region data file contains for each type of cell phone, communication region data to be used to display on the display apparatus  the region in which the cell phone used in the vehicle can communicate or to be used when searching the route.","The picturized map data file stores data for picturized maps which are picturized in the display apparatus . This picturized map data includes hierarchized maps, for example, map data for each tier such as, beginning with the highest tier, Japan, Kanto District, Tokyo, and Kanda. To each tier of the map data, a map code is respectively given.","Each intersection data file includes an intersection number specifying the intersection, intersection name, coordinates of an intersection (longitude and latitude), number for a road whose starting point or endpoint is at the intersection, presence of stoplights, and so forth.","The node data file includes node data such as the longitude and the latitude defining coordinates for each point on each road. In other words, node data is data defining one point along a road, and a road may be represented by an arc connecting the plural node columns.","Each road data file includes a road number specifying the road, number for an intersection being a starting point or an end point, numbers for roads having the same starting point or end point, width of the road, prohibition information such as prohibition of entry, photo number for photo data which will be referred later, and the like.","The road network data, composed of the intersection data, node data, and road data, stored respectively in the intersection data file, node data file, and road data file, are used to search a route.","The search data file includes intersection column data, node column data and the like composing the routes generated by the route search. The intersection column data includes information such as the intersection name, intersection number, number for a photo of a characteristic view of the intersection, turning point, distance, and the like. Further, the node column data includes information to indicate the position of the node such as the east longitude and the north latitude.","In the photo data file are stored photographs of a characteristic view or the like which is seen at each intersection or when traveling straight, by correlating them with a photo number, in the form of digital, analogue, or negative film.","The operations of thus structured driver information collecting apparatus will be explained next.",{"@attributes":{"id":"p-0173","num":"0172"},"figref":"FIG. 5","b":["111","112"]},"The scenario execution request determining unit  in the agent processing unit  obtains the current state or a change of the state from various data provided by the state determining unit  (step ), and determines on the scenario startup conditions (including whether or not the load on the driver is at a low state, which is the startup condition in the present embodiment) stored in the automatic startup condition table of the scenario data file . Further, in the present embodiment, when the event signal commands execution of a question scenario, the scenario drive unit  checks out the driver information which has not been collected in the driver information  and the priorities of the information yet to be collected, and determines a question which corresponds to the driver information of the highest priority (step ).","Subsequently, whether the automatic startup conditions are fulfilled is determined (step ), and when the conditions are fulfilled (1,3;Y), the scenario execution request determining unit  issues to the scenario drive unit  an execution request for the scenario which fulfills the automatic startup conditions (step ). On the other hand, when the automatic startup condition is not fulfilled (step ; N), the routine goes to step  without issuing the scenario execution request.","Subsequently, it is determined whether or not the automatic startup conditions for all the scenarios have been determined, and if not (step ; N), the routine returns to step  and the determination for the next scenario is carried out. When the determinations for the all scenarios are completed (step ; Y), the scenario execution request determination unit  has completed execution of the routine.",{"@attributes":{"id":"p-0177","num":"0176"},"figref":"FIG. 6"},"Responsive to an event serving as a scenario execution request, the scenario drive unit  executes the scenario drive routine, and starts up the scenario which is requested (step )","Subsequently, the scenario drive unit  determines, for each scene of the requested scenario, whether or not it is instructed to store the selected result (step ). If it is instructed to store the selected result (step ; Y), such a result selected by the driver (a reply to the question) is stored (step ). Hence, in the case of a question scenario, new driver information can be collected from the driver's reply and stored in the driver information .","After storing the driver information (step ), or when a storage instruction is not given in the step (;N), the routine is terminated.",{"@attributes":{"id":"p-0181","num":"0180"},"figref":"FIG. 7"},"The scene screen includes, as shown in  (A), an agent display screen  for displaying an image of the agent (still image\/moving image), a word balloon screen  for display of a text corresponding to the voice of the agent, title screen , and scene display screen  for display of image data specific to each scene (actual image, answer selecting button, and the like).","As shown in , when the question scenario for preferences and hobbies (on food) is started, the agent processing unit  reads out, from the scenario data file , the screen layout data for the scene which is specified by the scene header displays it on the display apparatus , and at the same time outputs from the voice output apparatus  voice corresponding to the question.","Subsequently, the agent processing unit  specifies a voice dictionary to be used by the voice recognition unit  if the reply by the driver to the question is input by voice. In the case of the first scene 0x00001 shown in ), the dictionary is specified for voice recognition for four answering buttons , which are \u201cJapanese food\u201d, \u201cWestern-style food\u201d, \u201cChinese food\u201d, and \u201cno particular preference\u201d.","In the case of the question scenario in , the agent processing unit  displays, in the scene 0x0001 shown in (a), \u201cwhat genre of food do you like?\u201d in the word balloon screen , and at the same time outputs the voice corresponding to the presentation in the word balloon screen  from the voice output apparatus.","This scene, asking a question of the driver, follows a branch of plural scenes selected according to the answer by the driver (one of ) to ()).","Accordingly, when the driver selects \u201cJapanese food\u201d in the scene of (a), the agent processing unit  displays the scene screen of the branched scene 0x0002 of  (). In this scene screen, \u201cJapanese food\u201d which has been selected is displayed in the title screen , at the same time the word balloon screen \u201cYou like Japanese food.\u201d is displayed, and the corresponding voice is outputted. Additionally, in the branched scene screen of ), the actual image of the Japanese food is read out of the scenario data and displayed in the scene display screen .","Further, the agent apparatus unit  stores the driver's answer, for example, \u201cJapanese food\u201d in the hobbies and preferences data of the driver information  (, step ).","Hence, the agent processing unit displays and outputs each scene image and voice specified by the scenario in sequence until the last scene.","In the case of the question scenario of , the agent processing unit  terminates the action by the character because one of the scenes (b) to (e) is the last scene.","Further, the agent processing unit  terminates the routine when an ending is commanded by the driver through turning-off of the ignition or operation of an ending button (step ; Y), and when not to be ended (step ; N), returns to step  and determines if the next subsequent scenario is to be executed.","As has been explained, with the present embodiment, the agent questioning scenarios are executed, and the driver information is obtained from the answers thereto, so that the burden on the driver for inputting the data on himself\/herself is reduced.","Additionally, since the question scenario by the agent stipulates a startup condition, execution of the scenario will start only when the load on the driver is low, execution of the scenario does not add to the burden of driving by the driver, and the driver is less vexed by the questions.","While only one embodiment of the driver information collecting apparatus in the present embodiment has been explained so far, the present invention is not limited to the foregoing embodiment, and various modifications thereto are possible within the scope of the claims.","For example, in the embodiment which has been described, the load on the driver is determined based on the load imposed on the driver by the driving operations and vexation of the driver, but the load may be determined based on only one of these factors.","Further, in the foregoing embodiment explained above, the scenario automatic startup conditions adopted to determine the state of the load on the driver, (A) to (J) and (a) to (e) are cited and explained, but the present invention is not limited to use of those particular conditions, and other conditions may be adopted, provided they are related to the determination of the load on the driver.","For example, conditions such as: a steering angle greater than a predetermined value; the wiper moving at a higher-than-predetermined speed; the ringtone of a cell phone; the cell phone in use; a vehicle speed V of (for example, 150) km per hour or faster; and so forth may be adopted as indicative of a high load or the driver.","Further, where a radio or television is installed on the vehicle, an automatic startup prohibition condition prohibiting start up of the question scenario when the radio or the like is ON may be adopted, As a condition giving priority to startup, the reception of a commercial may be set as a startup condition for initiation of the question scenario, combined with use of, a commercial detecting sensor.","Each of the conditions referred to above may be used by itself or in any combination with other conditions, as a condition for a specific scenario or a condition used in common for plural scenarios.","Further, in the embodiment explained above, the conditions for start up of each scenario of actions by the agent are determined in accordance with the state of vehicle, condition of the driver (including the state of the load), and the extent of learning through the agent.","Further to this, the psychological distance between the agent and the driver may be determined and added to the scenario startup conditions. As a result, the startup conditions for a specific scenario may be modified according to the physiological distance between the agent and the driver.","Here, the physiological distance between the agent and the driver is expressed by parameters such as the degree of friendliness, degree of self-confidence, degree of amenability, degree of morality, and so forth, and changes itself in accordance with the accumulated past replies and the like by the driver. For example, when words of appreciation are spoken in response to the agent's action, the the measure of friendliness is increased, and suggestions such as whether to play a CD becomes more frequent, but in contrast, when the agent is cursed, the measure of friendliness is reduced, and the actions such as actively suggesting opening of the window, playing a CD, and so forth are reduced.","Further, it is also possible to make a change into a friendly and casual way of speaking or a businesslike way of speaking, according to the stored value of the parameter for psychological distance. In this case, the character motion instruction data (see ) for each scene should include a value for each parameter of psychological distance.","When the scenario startup conditions reflecting the psychological distance between the agent and the driver are added as referred to above, an agent psychology unit is added to the agent processing unit shown in . For example, this agent psychology unit may determine the psychological state of the agent based on the determination made by the state determining unit . Further, the agent psychology unit stores routines for changing the parameter of the psychological state of the agent, and for notification of the agent's psychological state. Subsequently, the scenario drive unit  refers to the psychological state of the agent, and drives the scenario based thereo, i.e. controls the transition of the scene.","With the present invention, the driver information can be automatically collected through the communications between the agent and the driver, thus reducing the burden of driver information inputting operations on the driver."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
