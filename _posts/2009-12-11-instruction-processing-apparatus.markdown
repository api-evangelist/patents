---
title: Instruction processing apparatus
abstract: An instruction processing apparatus includes a thread execution processing section executing threads each including plural instructions, a register file including a register window having plural registers, a current window pointer indicating a position of the register where the register window is possible to be inputted and outputted, a current register reading data held by the register window designated by the current window pointer to hold the data and a replacement buffer holding data transferred from the register file to the current register, a first transfer path transferring data in a register file to one of the replacement buffer, a second data transfer transferring data in a replacement buffer to one of the current registers, a calculation section executing a switching instruction of the register window, and a control section controlling, if the calculation section executes the switching instruction, the first data transfer path and the second data transfer path.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07962732&OS=07962732&RS=07962732
owner: Fujitsu Limited
number: 07962732
owner_city: Kawasaki
owner_country: JP
publication_date: 20091211
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["This is a continuation application of PCT\/JP2007\/062424, filed on Jun. 20, 2007.","The present invention relates to an instruction processing apparatus including a multithreading function to execute plural threads simultaneously.","Instructions included in a program are processed through a series of stages, such as instruction fetch (fetch), instruction decode (decode), instruction execution and execution result commit (commit), in an instruction processing apparatus typified by a CPU. Conventionally, there has been known a technique called pipeline where CPU resources are allocated for each of instructions in a timesharing manner to perform processing. By applying the pipeline, it is possible to perform a parallel processing while an instruction is executed, for example, to decode a next instruction and to fetch a second next instruction. And in addition, an instruction execution itself is performed through the pipeline, so that it is possible to enhance a processing speed in the instruction processing apparatus.","In recent years, a superscalar system where the pipelines described above are provided in plural to further enhance the speed has been widely used. In addition, out-of order execution where if a condition to execute an instruction is satisfied, the instruction may be executed without following a program order of the instruction has been applied.",{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 1","b":["501","502","503","504","501","502","504","503"]},"To achieve out-or-order execution illustrated in , in execution processing (step S) where plural instructions are executed in parallel, data to be used in those instructions is required to be held without being overwritten. In an instruction processing apparatus employing out-of-order execution of a superscalar system, there is a case where plural data storage places (hereinafter, the storage places each is referred to as register window) connected in a ring form is switched to be used.",{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 2"},"The register file A includes eight register windows W-W. The register window being currently used (in , first register window W) is pointed by a CWP (Current Window Pointer). In the example of , each of the register windows W-W includes 32 registers. Eight registers of the 32 registers are all used as a global area common in the register windows W-W, 24 registers out of the 32 registers are divided into three areas of an in-area, a local-area and out-area, eight registers each.","For example, in the register window W surrounded by a bold line, an in1 area on the left end overlaps an out0 area of the register window W which is one before the window and the in1 area also functions as the out0. In addition, a local1 area in the center does not overlap other window and the register window W occupies the local1 area. An out1 area on the right end overlaps an in2 area of the register window W which is one after the window W and is used commonly by the register windows W and W.","When a SAVE instruction to increment the CWP, a RESTORE instruction to decrement the CWP and a CWP update instruction to move the CWP to an arbitrary position or a trap is issued, the CWP moves according to the instruction so that the register window is switched.","Here, because the register file A has a number of registers, it takes mach time of processing to search a register window which the CWP points every time an instruction is received. Therefore, by providing a work register in which a part of the register file A is copied separately from the register file A as a master file having all the registers, processing time required for searching a register is reduced. Patent document 1 describes an instruction processing apparatus in which a general purpose register (GPR: General Purpose Register) including a replacement buffer (CRB: Current Window Replace Buffer) storing a copy of a register window adjacent to a current register window, in addition to a master register file (WRF: Master Register File) storing an original of data and a current register file (CWR: Current Window Register) storing a copy of the current register window pointed by the CWP.",{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 3","FIG. 4"]},"As illustrated in , the general purpose register (GPR)  includes a master register file (MRF) , a replace buffer (CRB)  and a current register file (CWR) . Between the master register file (MRF)  and the replace buffer (CRB) , and between the replace register (CRB)  and the current register (CWR)  are connected by data buses ,  to be transfer paths for data, respectively. The master register file (MRF)  is a file to be an original of data. Data of a register window pointed by a current pointer (CWP)  is copied in the current register (CWR) . Data of the register window is copied in the replace buffer (CRB) .","As illustrated in , when the SAVE instruction to increment the current pointer (CWP) is issued, the SAVE instruction is decoded and data stored in the (n+1)th register window which is immediately after the nth register window pointed by the current pointer (CWP)  is copied in the replace buffer (CRB) . The data copied in the replace buffer (CRB)  is transferred, when preceding instructions are all processed, to the current register (CWR) .","In a case where, before transferring to the current register (CWR) , further consecutively, for example, a SAVE instruction is issued, transferring of data from the master register file (MRF)  to the replace buffer (CRB)  in the second SAVE instruction is inhibited (stalled) because the replace buffer (CRB)  is in use by the first SAVE instruction.","In the instruction processing apparatus, processing in an instruction preceding to the SAVE instruction is executed using data stored in the current register (CWR) , the data stored in the replace buffer (CRB)  is used to process a consecutive instruction after the SAVE instruction by out-of-order execution. When the processing in the preceding instruction is completed and committed, the current register (CWR)  is released, the current pointer (CWP)  is increased by one according to the first SAVE instruction, and the data stored in the replace buffer (CRB)  is transferred to the current register (CWR)  so that data of the (n+1)th register window becomes available for using.","In addition, when transferring of the data from the replace buffer (CRB)  to the current register (CWR)  is completed, the replace buffer (CRB)  is released, the second SAVE instruction is decoded, and data stored in the (n+2)th register window in one next to the (n+1)th register window pointed by the current pointer is copied in the replace buffer (CRB) .","As described above, by updating the replace buffer (CRB)  when a SAVE instruction or a RESTORE instruction is decoded, and by updating the current register (CWR)  when those instructions are committed, data to be used in a consecutive instruction for the SAVE instruction and the like is able to be prepared to execute an out-of-order processing, so that it is possible to speed up processing time.","Conventionally, the multitask has been commonly utilized where CPU resources are allocated a time-sharing manner for each of plural applications and the plural applications are executed in parallel, such as using an application for spreadsheet calculation while using an application for word processing. In addition, in the instruction processing apparatus is provided with plural kinds of computing units, and when an instruction is executed a computing unit according to the contents of the instruction as an object to be executed is used. However, there are a few chances when all kinds of the computing units are simultaneously used, and there may be a computing unit being not in use. Therefore, there is a considerable amount of margin in the operation rate of the calculating units.","Then, as a technique to enhance the operation rate of the calculating units, simultaneously multi threading (SMT: Simultaneously Multi Threading) has been proposed where a calculating unit being not in use for a certain thread is allocated for another thread so that instructions of plural threads are simultaneously processed in parallel.",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 5","FIG. 5"]},"In addition, a clock cycle in an instruction processing apparatus is illustrated along the horizontal axis. In an example of , in a first cycle (step S), an instruction of the thread A is executed by two calculating units in the upper two cells, and an instruction of the thread B is executed by two computing units in the lower cells. In a second cycle (step S), an instruction of the thread A is executed by two calculating units in the uppermost and lowermost cells an instruction of the thread B is executed in two calculating units in the middle cells. In a third cycle (step S), an instruction of the thread A is executed by three computing units in these upper cells and an instruction of the thread B by the computing unit in the lowest cell.","As described, in the SMT function, it is possible to execute instructions of plural threads in each cycle simultaneously and in parallel, and it is possible to execute an instruction execution in regardless of a program order if a condition to execute the instruction is satisfied (out-of-order).",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 6"},"In plural instructions that belongs to a same thread, instruction fetch, instruction decode and commit are required to be executed according to a program order. In contrast, in plural instructions belonging to different threads, in any stage, an instruction in which a condition is satisfied may be executed regardless of an order in which the instruction is issued. In addition, according to SMT function, regarding an instruction belonging to a same thread, there is a case where stall that commit is waited until execution processing of another instruction is completed occurs, however, regarding an instruction belonging to a different thread, it is possible to further reduce the processing time for an application as a whole because it is not required to wait for a commit order and the like.\n\n","Here, in order to achieve out-of-order execution by SMT function as illustrated in , it is conceivable to prepare CPU resources such as a decoder illustrated in , a general purpose register (GPR)  and buses ,  illustrated in  for the number of threads. However, there is a problem in which in recent years, the number of threads has been increased and so adding CPU resources introduces size increasing of an instruction processing apparatus and increasing of cost.","In view of the foregoing, it is an object of the present invention to provide an instruction processing apparatus in which size increasing of the apparatus and cost increasing are suppressed and simultaneous multithreading is achieved.","An instruction processing apparatus according to the invention to obtain the object described above, includes:","a thread execution processing section that executes threads each including plural instructions;","a register file that includes a register window including plural registers and is provided individually for the thread;","a current window pointer that is provided individually for the thread and indicates a position of the register where the register window is possible to be inputted and outputted;","a current register that is provided individually for the thread and reads out data held by the register window designated by the current window pointer from the register file to hold the data;","a replacement buffer that is provided individually for the thread and holds data which is transferred from the register file to the current register;","a first transfer path that transfers data in a register file selected from the plurality of register files to one of the plural replacement buffers;","a second data transfer path that transfers data in a replacement buffer selected form the plural replacement buffers to one of the plural current registers;","a calculation section that is provided individually for the thread and executes a switching instruction of the register window; and","a control section that controls, if the calculation section executes the switching instruction included in the one of the plural threads, the first data transfer path and the second data transfer path, corresponding to the thread including the switching instruction.","In the instruction processing apparatus according to the invention, the register file, the replace buffer and the current register are prepared for each thread and the first data transfer path to connect the register file and the replace buffer, and the second transfer path to connect the replace buffer and the current register are commonly used in plural threads. In a case where data is transferred according to each of plural switching instructions belonging to threads which are different from each other, it is possible to switch register windows in plural threads without preparing a data path fort each of the plural threads, and it is possible to realize the simultaneous multithreading function while suppressing size increasing of the apparatus and cost increasing because competing between the first data transfer path and the second data transfer path is mediated.","In addition, of data stored in the register file, data to be used in a subsequent switching instruction is stored in the replace buffer, and when updating the current register, by copying the data stored in the replace buffer, it is possible to save processing time to search target data from the register file in which a lot of data is stored.","In addition, in the instruction processing apparatus, it is preferable that the calculation section obtains information to identify the thread to which the switching instruction belongs from other thread and switches the register window corresponding to the thread identified by the information.","According to the preferable instruction processing apparatus of the invention, it is possible to readily distinguish and perform data transfer between the register file, the replace buffer and the current register.","In addition, in the instruction processing apparatus according to the invention, it is preferable that \u201cthe instruction processing apparatus further includes a decode section that decodes the instruction; and an execution section that executes an instruction other than the switching instruction which the calculation section executes, of the instructions decoded in the decode section and is capable of executing plural instructions simultaneously, wherein the calculation section transfers, if the switching instruction is decoded by the decode section, the data to the replacement buffer, and transfers, if all the instructions to be completed before the switching instruction is completed are completed, the data to the current register.\u201d","When a switching instruction is decoded, data is transferred, and if all instructions to be completed before the switching instruction are completed, the data is transferred to the current register, so that out-of-order execution is performed and it is possible to reduce processing time.","In addition, in the instruction processing apparatus according to the invention, it is preferable that the decode section decodes the instruction of each of the plural threads at one time with respect to one of the plural threads, and the execution section is capable of executing simultaneously plural instructions included in the threads which are different from each other.","According to the preferable instruction processing apparatus of the invention, while suppressing a circuit size by commonly using a decode section which is in general complicated and large, it is possible to execute simultaneously plural instructions belonging to plural threads.","In addition, in the instruction processing apparatus according to the invention, it is preferable that the calculation section receives the switching instruction which has been decoded by the decode section and transfers the data to the replacement buffer, and the calculation processing apparatus further includes a switching instruction stack that receives, if the switching instruction is decoded by the decode section and there is an instruction which has not been completed and which is to be completed before the switching instruction, the switching instruction before being sent to the calculation section from the decode section to hold the received instruction.","The switching instruction stack is provided, so that it is possible to reliably avoid a failure in which the decode section is occupied by stall.","In addition, in the instruction processing apparatus according to the invention, it is preferable that the switching instruction stack is capable of holding the switching instructions, and the control section controls the first data transfer path and the second data transfer path by sending one by one the switching instructions held by the switching instruction stack to the calculation section.","The switching instructions held in the switching instruction stack are transferred one by one to the calculation means, so that it is possible to readily mediate competing between the first data transfer path and the second data transfer path.","In addition, in the instruction processing apparatus according to the invention, it is preferable that the control section sends to the calculation section first, the switching instruction where all the instructions to be completed before the switching instruction are completed first, of the switching instructions held by the switching instruction stack.","Plural switching instructions are transferred not in an order of being held in the switching instruction stack and switching instruction of the plural switching instructions which is first in a state where the switching instruction is possible to be transferred is first sent to the calculation means, so that it is possible to use effectively the first data transfer path and the second data transfer path, and to reduce processing time.","In addition, in the instruction processing apparatus according to the invention, it is preferable that the control section sends first, if all the instructions to be completed before the switching instructions are completed simultaneously with respect to the plural switching instructions held by the switching instruction stack, the switching instruction which is held first by the switching instruction stack of the plural switching instructions.","According to the preferred instruction processing apparatus, it is possible to readily mediate competing between the first data transfer path and the second data transfer path.","In addition, in the instruction processing apparatus according to the invention, it is preferable that the switching instruction stack also holds, associating with the switching instruction, a thread identifier to identify the thread to which the switching instruction belongs from the other thread and an instruction identifier to identify the switching instruction from the other instruction being in execution in the instruction processing apparatus.","The thread identifier and the instruction identifier are held with being associated with a switching instruction, so that it is possible to readily identify what thread the switching instruction belongs to and which switching instruction in the thread is the switching instruction.","In addition, in the instruction processing apparatus according to the invention, it is preferable that the instruction processing apparatus further includes an instruction input section that obtains the instruction from each of the plural threads to input the inputted instruction to the decode section, and stops, if the switching instruction is held in the switching instruction stack, inputting the instruction with respect to the thread to which the switching instruction belongs, and inputs the instruction belonging to the other thread.","Commonly, in plural instructions belonging to a same thread, those instructions need to be executed according to a program order and in plural instructions each belonging to threads which are different from each other, those instructions may be executed in any order. When a switching instruction is held in the switching instruction stack, inputting an instruction is interrupted for a same thread as that the switching instruction belongs to and an instruction belonging to another thread is inputted, so that data of an instruction which may be executed first may be transferred first, and it is possible to reduce processing time.","In addition, in the instruction processing apparatus according to the invention, it is preferable that the decode section simultaneously holds the instructions and decodes the instructions which the decode section holds, and the instruction processing apparatus further includes a pre-decode section that confirms, before the decode section, whether or not the instruction is the switching instruction by decoding which is simpler than decoding of the instruction by the decode section and an instruction input section that obtains the instruction from each of the plural threads and inputs the obtained instruction to the decode section, and adjusts an input timing such that at most one instruction which is confirmed to be the switching instruction by the pre-decode section is held at one time by the decode section.","For an instruction confirmed to be a switching instruction, input timing is adjusted such that at most one instruction confirmed to be the switching instruction is held in the decode section at one time, so that it is possible to securely avoid stall in the decode section.","The object and advantages of the invention will be realized and attained by means of the elements and combinations particularly pointed out in the claims.","It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory and are not restrictive of the invention, as claimed.","In the following, an embodiment will be explained with reference to the drawings.",{"@attributes":{"id":"p-0085","num":"0085"},"figref":"FIG. 7","b":"10"},"The CPU  is mounted in a personal computer and the like to execute various processing. Simultaneous multi threading (SMT: Simultaneous Multi Threading) in which plural threads each including a series of plural instructions are simultaneously executed is employed in the CPU . In addition, an out-of-order mechanism where an instruction first meets a condition where the instruction is to be executed may be executed first regardless of an issuing order of the instruction is employed among the plural threads.","The CPU  illustrated in  is for simultaneously processing instructions in two kinds of threads, processes of seven stages illustrated in the following are sequentially performed. That is, the processes of the seven stages: a fetch stage (step S) to alternately fetch instructions of the two kinds of threads by in-order execution; a decode stage (step S) to decode a process represented by a fetched instruction by in-order execution; a dispatch stage (step S) to store by in-order execution a decoded instruction in a reservation station, which will be described later, connected to a computing unit required to execute a process of the instruction and to deliver the stored instruction to the computing unit by out-of-order execution; a read out stage (step S) to read out from a register an operand required to execute the instruction stored in the reservation station by out-of-order execution; an execution stage (step S) to execute an instruction stored in the reservation station using an operand read out from the register by out-of-order execution; a memory stage (step S) to perform recording an execution result in a memory outside the CPU  and the like by out-of-order execution; and a commit stage (step S) to perform commit to update a register for storing the operand and the like according to an execution result to commit the execution result by in-order execution, are sequentially performed.","In the following, each of the stages will be explained in detail.","In the fetch stage (step S), instruction fetch (fetch) is designated by two program counters  prepared for the respective two kinds of threads (thread  and thread ) respectively, an instruction fetch section  fetches an instruction from an input side primary cache  of to an instruction buffer . The two program counters  alternately operate, in fetch in one time, either one of the two program counters  instructs to fetch an instruction of a corresponding thread. Further, in this embodiment, in fetch in one time, fetch of eight instructions is performed in a process order in the thread by in-order execution.","The CPU  includes a branch prediction section . The branch prediction section  predicts whether or not there is an instruction to be fetched in an order different from a written order, and a position where the instruction is written in a thread, before executing a preceding instruction. Then, the instruction fetch section  executes fetch, referring to a predicted result of the branch prediction section .","Here, a program to be executed by the CPU  according to this embodiment is stored in an external memory, which is not illustrated. The CPU  is connected to the external memory and the like via a system bus interface  connected to a secondary cache  included in the CPU . When the program counters  instruct to fetch an instruction, the instruction fetch section  refers to the prediction result of the branch prediction section  to request the input side primary cache  eight instructions. Then, the requested eight instructions are inputted from the external memory via the system bus interface  and the secondary cache  to the input side primary cache , and the input side primary cache  delivers those instructions to the instruction buffer . At this time, in this embodiment, on delivering, a pre-decode section  applies a simple decode (pre-decode) to each instruction. Then, the pre-decode section  adds a flag representing a result by the pre-decode described later to each instruction to be delivered to the instruction buffer .","In the decode stage (step S), the instruction buffer  inputs four instructions of the eight instructions taken in and held by a decode section  by in-order execution. The decode section  decodes each of the inputted four instructions by in-order execution. In addition, for each instruction, a number from \u201c0\u201d to \u201c63\u201d as an instruction identification (IID: Instruction IDentification) is allocated in a decode order for each instruction with respect to each thread. Here, in this embodiment, when an instruction of the thread  is decoded, IIDs from \u201c0\u201d to \u201c31\u201d are allocated, and when an instruction of the thread  is decode, IIDs from \u201c32\u201d to \u201c63\u201d are allocated. At this time, the decode section  sets the IID allocated for the instruction to be decoded in a vacant entry in a group of entries to which an instruction as an object to be decoded belongs of a commit stack entry (CSE)  (described later) which has 64 entries in total of 32 entries for the thread  and 32 entries for the thread .","The decode section  determines, for each of the decoded four instructions to which IID is allocated respectively, a computing unit required to execute processing of each instruction. Then, the decode section  stores each decoded instruction in a reservation station connected to the computing unit required to execute processing of each instruction by in-order execution.","The reservation station holds plural of the decoded instructions. The reservation station in the dispatch stage (step S), delivers each instruction to the computing unit by out-of-order execution. In other words, the reservation station delivers first an instruction in which an operand required to execute processing and the computing unit are confirmed, regardless of an process order in the thread. At this time, if there are plural instructions which may be delivered, the reservation station delivers first an instruction which is decoded first of those plural instructions. The CPU  of the present embodiment includes following four kinds of reservation stations. That is, the four kinds of reservation stations: a reservation station for address creation (RSA: Reservation Station for Address Creation) ; a reservation station for integer calculation (RSA: Reservation Station for Execution) ; a reservation station for floating point calculation (RSL: Reservation Station for Floating Point) ; and a reservation station for branch (RSBR: Reservation Station for BRanch)  are included in the CPU . Here, RSA , RSE  and RSF  are connected to corresponding computing units via registers for storing operand, respectively. In contrast, RSBR  is connected to the above-described branch prediction section , and plays roles such as waiting for confirmation of a prediction result in the branch prediction section  and re-fetch of an instruction in a case of a prediction failure.","In the register readout stage (step S), an operand in a register is read out by out-of-order execution. In other words, regardless of a processing order in a thread, an operand in a register connected to the reservation station which has delivered the instruction to the computing unit is read out, and is delivered to a corresponding computing unit. The CPU  includes two kinds of registers: an integer register (GPR: General Purpose Register) ; and a floating point register (FPR: Floating Point Register) . Here, GPR  and FPR  are both visible to a program and are provided in each of the thread and the thread . In addition, a buffer to hold an execution result of an instruction until each register is updated is connected to each of the GPR  and the FPR . An integer register update buffer (GUB: GPR Update Buffer)  is connected to the GPR . A floating point register update buffer (FPR Update Buffer)  is connected to the FPR .","Because address creation and integer calculation are executed using an integer operand, the GPR  is connected to the RSA  and RSE  described above. In addition, because integer calculation using an operand held in the GUB  in a stage before the GPR  is updated is permitted, the GUB  is connected to the RSA  and the RSE . Further, because floating point calculation is executed using an operand in a floating point form, the FPR  is connected to the above-described RSF . In addition, in the present embodiment, because floating point calculation using an operand held in the FUB  is permitted, the FUB  also is connected to the RSF .","In addition, two of address creation computing units (EAGA and EAGB: Effective Address Creation units A and B) , , two of integer computing units (EXA and EXB) ,  and two of floating point computing units (FLA and FLB) ,  are included in the CPU  of the present embodiment. The GPR  and GUB  are connected to the EAGA , EAGA , EXA  and EXB  which use an integer operand. The FPR  and FUB  are connected to the FLA  and FLB  which use a floating point operand.","In the execution stage (step S), execution of an instruction is performed by out-of-order execution by a computing unit. In other words, regardless of a processing order in a thread, a computing unit to which an instruction is delivered from a reservation station and to which an operand required for calculation is delivered from a register, of the above-describe plural kinds of computing units, executes processing of the delivered instruction using the delivered operand. In addition, in the execution stage (step S), when the instruction and the operand are delivered to another computing unit while a certain computing unit is executing, those computing units execute processing simultaneously and in parallel.","In this execution stage (step S), when an instruction of address creation is delivered to the EAGA  from the RSA  and an integer operand is delivered to the EAGS  from the GPR , the EAGA  executes address creation processing using the integer operand. In addition, when an instruction of integer calculation processing is delivered to the EXA  from the RSE  and an integer operand is delivered to the EXA  from the GPR , the EXA  executes integer calculation processing using the integer operand. When an instruction of floating point processing is delivered to the FLA  from the RSF  and a floating point operand is delivered to the FLA  from the FPR , the FLA  executes floating point calculation processing using the floating point operand.","Because execution results of the EAGA  and the EAGB  are used for an access to the external memory via a cache section or the system bus interface , these computing units are connected to a fetch port  which is a readout port of data from a memory and a store port  which is a write port. The execution results of the EXA  and the EXA  are connected to GUB , an intermediate buffer for updating the GPR  and further to the store port  which play a role of an intermediate buffer for updating a memory. In addition, execution results of the FLA  and FLB  are connected to FUB , an intermediate buffer for updating the FPR , and further to the above-described store port  for updating a memory. In addition, the EXA , EXB , FLA  and FLB  are connected to a CSE  by a connecting line, whose illustration is omitted for avoiding complication of the figure. In a case where processing executed in each computing unit is processing that is completed by completion of processing in each computing unit without requiring an access to an external memory, an execution completion notification is sent from each computing unit to the CSE  at the time of completion of execution.","In the memory stage (step S), an access to the external memory such as storing an execution result to the external memory is performed by out-of-order execution. In other words, in a case where there are plural instructions requiring such an access, the access is performed in an order in which the execution results are obtained regardless of an order of processing in a thread. In this memory stage (step S), accessing is performed by the fetch port  or the store port  via a memory cache , the secondary cache  and the system bus interface . In addition, when accessing the external memory is completed, an execution completion notification is sent from the fetch port  or the store port  to the CSE  via a connecting line not illustrated.","In the commit stage (step S), the CSE  updates by in-order execution a control register  that holds an operand used for processing other than the above-described processing in the GPR , FPR , program counters  and the CPU  as follows. In the execution completion notification sent to the CSE  from the above-described computing units and the like, there are described an IID of an instruction corresponding to the execution completion notification and information (commit information) required for commit (commit) of a execution result such as a register of target to be updated after completion of the instruction. When the execution completion notification is sent to the CSE , the CSE  stores the commit information described in the execution completion notification in an entry for which an IID same as the IID described in the execution completion notification is set, of the 64 entries included in the CSE . Then, the CSE  executes by in-order execution updating of a register according to each instruction already stored, according to an order of processing in the thread.","The CPU  is configured in such manner in general, and operates along the above-described seven stages.","In the following, transfer control of data in the GPR  illustrated in  and detail configurations of elements relating to the transfer control of data will be explained. Incidentally, in order to simplify the explanation, an example in which the two threads are executed simultaneously will be explained, those two threads are distinguished by alphabets \u201cA\u201d and \u201cB\u201d affixed to ends of the references.",{"@attributes":{"id":"p-0105","num":"0105"},"figref":"FIG. 8","b":"10"},"In the present embodiment, GPR A, B corresponding to the respective two threads are prepared in the CPU . As explained in , the GPR A, B are divided into plural register windows, and data of a register window pointed by the CWP is used in the calculation stage (step S) in . In the following, an instruction to switch a register window used in the step S by moving the CWP one by one is referred to a switching instruction.","The CPU  includes an instruction cache section , an instruction input section , an instruction decode section , a D_MOVE_STACK , a D_MOVE_SLOT , GPR A, B, a computing units , CSE A, B and an instruction commit section . The instruction cache section  caches plural instructions included in each of the two threads. The instruction input section  inputs the instructions cached in the instruction cache section  to the instruction decode section . The instruction decode section  decodes the inputted instructions. If an instruction decoded in the decode section  is a switching instruction, the switching instruction is stored in the D_MOVE_STACK . An instruction for executing the switching instruction is inputted to the D_MOVE_ISSUE_SLOT . The GPR A, B are also illustrated in . The computing unit  executes in parallel the decoded plural instructions. The CSE A, B are tables to manage in instruction execution state for each thread. The commit section  commits completion of a thread at a stage in which a series of instructions included in each thread are completed. For plural instructions belonging to a same thread, the instructions are decoded in a predetermined order in the instruction decode section  (in-order), processing is executed in parallel beyond the order in the computing unit  (out-of-order), commit is performed in a determined order after waiting completion of a preceding instruction belonging to the same thread in the instruction commit section  (in-order). In addition, for plural instructions belonging to different threads, the instructions are decoded for each thread one by one in the instruction decode section , processing is simultaneously carried out for both in the computing unit , the instructions are committed for each thread one by one in the instruction commit section , and it is possible to execute the plural instructions by out-of-order execution.",{"@attributes":{"id":"p-0108","num":"0108"},"figref":["FIG. 9","FIG. 8"],"b":["114","114"]},"As explained with reference to , MRF A, B are divided into plural register windows. Data of a register window that the CWP is currently pointing is stored in CWR A, B. The CRB A, B are provided between the MRF A, B and CWR A, B. Data to be used in a subsequent instruction for a switching instruction is stored in the CRB A, B.","As a switching instruction to switch a register window used in the computing unit  to an adjacent register window, there exist a SAVE instruction to increment the CWP and to advance a register window to be referred to a register window immediately forward and a STORE instruction to decrement the CWP and to return a register window to be referred to a register window immediately backward. As an instruction to change the register window other than the switching instruction, there is a CWP update instruction, trap and the like. The CWP update instruction directly designates a register window pointed by the CWP and switches a register window to be referred to an arbitrary register window. When a switching instruction is decoded, data of a register window according to the switching instruction is transferred from the MRF A, MRF B corresponding to a thread to which the switching instruction belongs to the CRB A, B. When processing of a preceding instruction belonging to the same thread to which a switching instruction belongs is completed in the computing unit , the CWR A, B corresponding to the thread are released and data is transferred to the CWR A, B released from the CRB A, B. In the following, transferring of data from the MRF A, B to the CRB A, B by the SAVE instruction and the RESTORE instruction is referred to D_MOVE, and transferring of data from the CRB A, B to the CWR A, B by the SAVE instruction and the RESTORE instruction is referred to W_MOVE.","Transferring of data by a CWP update instruction or a trap is referred to MOVE_ALL. In MOVE_ALL, when the CWP update instruction is committed and when trap processing is determined to be executed, data pointed by the CWP is all transferred from the MRF A, B via the CRB A,  to the CWR A, B. At this moment, the CRB A, B become relaying buffers.","The MRF A, B and the CRB A, B are connected through a D_MOVE bus  that is a data transfer path. The CRB A, B and the CWR A, B are connected through a W_MOVE bus  that is a data transfer path. In the present embodiment, the D_MOVE bus  and the W_MOVE bus  are shared by the two threads. By this manner, increasing of entire size of the CPU  and cost increasing are suppressed.","In the present embodiment, the GPR A, B to store data, the CSE A, B that are tables for commit processing, and the like are prepared for the number of threads. The computing unit  is capable of executing in parallel plural instructions belonging to each of plural threads. The instruction decode section , the instruction commit section , the D_MOVE bus , the W_MOVE bus  and the like are shared by plural threads. Therefore, an execution order of each kind of processing needs to be controlled such that competing between common elements is not caused by plural instructions belonging to each of threads. Particularly, in the switching instruction, in addition to mediating competing between the D_MOVE bus and the W_MOVE bus in plural instructions of different threads, in order to avoid overwriting of data used in processing in execution, an execution order of the plural instructions belonging to the same thread needs to be controlled.",{"@attributes":{"id":"p-0114","num":"0114"},"figref":"FIG. 10"},"In , a decode control section , a MOVE startup control section , a register file MOVE processing control section  and the GPR A, B are illustrated. The decode control section  controls timing of decode of an instruction. The MOVE startup control section  controls timing of data transfer processing according to a switching instruction. The register file MOVE processing control section  receives an instruction of data transfer processing from the MOVE startup control section  to execute the D_MOVE, the W_MOVE or the MOVE_ALL.","Firstly, information that is used in controlling execution timing in each of elements illustrated in  will be explained.",{"@attributes":{"id":"p-0117","num":"0117"},"figref":["FIG. 11","FIG. 12"],"b":["241","242","261","261"]},"The D_MOVE_STACK  is a stack in which a switching instruction in wait is stored in a case where the D_MOVE processing may not be started. The D_MOVE_STACK  is prepared one for each of the two threads. The D_MOVE_ISSUE_SLOT  is connected to a D_MOVE processing control section  and is a buffer to relay for only one cycle when starting D_MOVE processing. A SAVE instruction and a RESTORE instruction which are decoded in the decode section  are registered in the D_MOVE_STACK  and the D_MOVE_ISSUE_SLOT . The SAVE instruction and the RESTORE instruction include instruction contents (VAL), a SAVE flag (D_MOVE), a RESTORE flag (D_RESTORE), a thread identification (D_THREAD_ID) and an instruction identification (IID). When an instruction is a SAVE instruction, \u201c1\u201d is set in the SAVE flag (D_SAVE). When an instruction is a RESTORE instruction, \u201c1\u201d is set in the RESTORE flag (D_RESTORE). The thread identification (D_THREAD_ID) identifies a thread to which the instruction belongs. The instruction identification (IID) identifies each instruction from others.","In addition, for the CSE A, B illustrated in , tables are prepared for each thread. Each table is associated with a thread number for identifying each thread. An entry of each of plural instructions belonging to each thread is registered in each table. Each entry of the CSE  A, B includes: a processing flag (VAL); a bus use flag (MOVE_BUS_USE); and a D_MOVE flag (D_MOVE_COMP). When execution of processing is completed, \u201c1\u201d is set in the processing flag (VAL). When an instruction is an instruction opcode (OPCODE), d a SAVE instruction and a RESTORE instruction, \u201c1\u201d is set in the bus use flag (MOVE_BUS_USE). When D_MOVE processing starts, \u201c1\u201d is set in the D_MOVE flag (D_MOVE_COMP).","A portion of various kinds of information registered in these D_MOVE_STACK , the D_MOVE_ISSUE_SLOT  and the CSE A, B is registered in the decode control section  illustrated in .","The decode control section  illustrated in  includes the instruction cache section , the instruction input section  and the instruction decode section .",{"@attributes":{"id":"p-0122","num":"0122"},"figref":"FIG. 13","b":"310"},"When an instruction belonging to each thread is issued, the instruction is cached in the instruction cache section , and the instruction is pre-decoded in the instruction input section  illustrated in . Then, whether or not the instruction is a SAVE instruction or a RESTORE instruction and a thread to which the instruction belongs are identified. Further, the instruction input section  stores the instruction in an instruction buffer \u2032 and also sets \u201c1 (indicates a SAVE instruction or a RESTORE instruction)\u201d in a flag prepared in advance in a case where the instruction is a SAVE instruction or a RESTORE instruction.","Further, in a case where a switching instruction is not registered in the D_MOVE_STACK , the instruction input section  inputs an instruction stored in the instruction buffer \u2032 to the instruction decode section .","In addition, in a case where a switching instruction is already registered in the D_MOVE_STACK , the instruction input section  acquires a thread identification (D_THREAD_ID) illustrated in  from the D_MOVE_STACK . If an instruction belonging to a same thread as that represented by the thread identification obtained is stored in the instruction buffer \u2032, the instruction input section  inhibits the instruction from being inputted to the instruction decode section . If an instruction belonging to a thread different from one represented by the thread identification (D_THREAD_ID) acquired is stored in the instruction buffer \u2032, the instruction input section  input the instruction first to the instruction decode section . An instruction which is stalled is inputted to the instruction decode section  after the switching instruction registered in the D_MOVE_STACK  is sent to the register file MOVE processing control section  and the stall is released.","The switching instruction which is stacked in the D_MOVE_STACK  is in standby until use of the D_MOVE bus  by other switching instruction is completed and permission to use the D_MOVE bus  is obtained. Therefore, when an instruction belonging to the same thread as that of a switching instruction in wait in the D_MOVE_STACK  is inputted to the instruction decode section , a subsequent instruction is inhibited (stall) from being executed until the preceding switching instruction is executed. Therefore, the instruction decode section  is occupied by the subsequent instruction and it becomes impossible to execute an instruction belonging to another thread. If an instruction belonging to the same thread as one of the instruction stacked in the D_MOVE_STACK  is stored in the instruction buffer \u2032, an instruction in an executable state may be executed first by inhibiting inputting the instruction to the instruction decode section  (stall) and by inputting an instruction belonging to a different thread to the instruction decode section , so that it is possible to speed up processing.","In the instruction decode section , the inputted instruction is decoded so that a thread number to which the instruction belongs, a kind of the instruction and the like are identified. In addition, in the instruction decode section , the instruction identification (IID) is attached to each instruction and at the same time \u201c0: in process\u201d (VAL) is set in a processing flag in an entry of the instruction of the CSE A, B associated with the thread number identified, and an instruction opcode (OPCODE) is set. If the instruction is a switching instruction (SAVE instruction or RTSOTRE instruction), \u201c1\u201d is set in the bus use flag (MOVE_BUS_USE).","When decoding of the instruction is completed, if the instruction is a normal calculation instruction other than a switching instruction, the calculation instruction is inputted to the computing unit  illustrated in , and processing according to the calculation instruction is executed in the computing unit . If the decoded instruction is a switching instruction, the instruction is inputted to the D_MOVE startup control section .","The MOVE startup control section  includes a stack section , a commit control section  and a trap\/CWP update instruction detect section . The stack section  includes the D_MOVE_STACK  and the D_MOVE_ISSUE_SLOT . The commit control section  includes the CSE A, B and the instruction commit section  illustrated in . The trap\/CWP update instruction detect section  issues the MOVE_ALL instruction to switch the CRB and the CWR.","In addition, if the instruction decoded in the instruction decode section  is a SAVE instruction to execute SAVE or a RESTORE instruction to execute RESTORE, the SAVE instruction or the RESTORE instruction is transmitted to the stack section .",{"@attributes":{"id":"p-0131","num":"0131"},"figref":"FIG. 14","b":"240"},"As illustrated in , the stack section  includes two of D_MOVE_STACKs _, _, the D_MOVE_ISSUE_SLOT , connecting lines connecting them, and a switch circuit to switch a switching instruction inputted from the instruction decode section  to each stack to store.","In a state where there is neither a preceding SAVE instruction nor a preceding RESTORE instruction that has not committed, there is no switching instruction that waits for a turn of data transferring from the MRF A, B to the CRB A, B illustrated in , so that CRB A, B are released and overwriting does not occur. Further, if the D_MOVE bus  is released and there is no stall factor, an instruction inputted to the stack section  is stored in the D_MOVE_ISSUE_SLOT . In the D_MOVE_ISSUE_SLOT , an instruction to execute D_MOVE processing is issued toward the register file MOVE processing control section  illustrated in .","Further, if there is a preceding SAVE instruction or a preceding RESTORE instruction that has not committed, the stored instruction indicates waiting for release of the CRB A, B, the CRB A, B are in use and data may be overwritten. If there is a stall factor in a state where the D_MOVE bus  is in use, the switching instruction inputted to the stack section  is once stored in the D_MOVE_STACK _, _. Incidentally, while the instruction is stored in the D_MOVE_SRACK _, _, because inputting of an instruction belonging to a same thread as that to which the instruction belongs is stalled, the instruction belonging to the same thread as that to which the instruction belongs is not stored in the D_MOVE_STACK _, _. In other words, at most one instruction for each of threads which are different from each other is stored in the D_MOVE_STACK _, _.","When the D_MOVE bus  is released, of the instructions stored in the D_MOVE_STACK _, _, an instruction of a thread whose overwriting of the CRB A, B is available first is first transferred to the D_MOVE_ISSUE_SLOT . In addition, if stall of the instructions stored in each of the D_MOVE_STACK _, _ are simultaneously released, an instruction that is stored first in the D_MOVE_STACK _, _ is transferred first to the D_MOVE_ISSUE_SLOT .","When the switching instruction is stored in the D_MOVE_ISSUE_SLOT , an instruction to execute the D_MOVE is issued toward the register file MOVE processing control section  illustrated in . In addition, when the instruction to execute the D_MOVE is issued from the D_MOVE_ISSUE_SLOT  to the MOVE processing control section , \u201c1:D_MOVE start\u201d is set in the D_MOVE_COMP flag of an entry corresponding to the switching instruction, of the CSE A, B.","The register file MOVE processing control section  includes a D_MOVE processing control section  and a W_MOVE processing control section .","The instruction to execute the D_MOVE processing issued from the D_MOVE_ISSUE_SLOT  and the instruction to execute the MOVE_ALL processing issued from the trap\/CWP update instruction detect section  are transmitted to the D_MOVE processing control section . The D_MOVE processing control section  uses the D_MOVE bus  for each switching instruction to cause data to be transferred from the MRF A, B corresponding to a thread to which the switching instruction belongs to the CRB A, B.",{"@attributes":{"id":"p-0139","num":"0139"},"figref":["FIG. 15","FIG. 15"],"b":["271","271","272","272"]},"As illustrated in , a switching instruction inputted to the stack section  is set, after being directly or once stored in the D_MOVE_STACK _, , in the D_MOVE_ISSUE_SLOT  (cycle t).","The preceding switching instruction is inputted in a next cycle t to the D_MOVE processing control section . Then, in a further next cycle t, D_MOVE processing according to the preceding switching instruction is executed using the D_MOVE bus .","An instruction belonging to a different thread from one to which the preceding instruction belongs is in standby in the D_MOVE_STACK _, _ until the preceding instruction is inputted to the D_MOVE processing control section  and then the D_MOVE_ISSUE_SLOT  is released and the D_MOVE bus is released (cycle t). An instruction belonging to a different thread from one to which the preceding instruction belongs is set in the D_MOVE_ISSUE_SLOT  in a cycle t and is inputted to the D_MOVE processing control section  (cycle t). Because use of the D_MOVE bus  by the preceding instruction is supposed to be just completed in cycle t, processing of a next D_MOVE is started without competing and a gap (cycle t).","As explained, in this manner, by once storing the decoded instruction in the D_MOVE_STACK _, _ to control an order to input to the D_MOVE processing control section , it is possible to readily mediate competing of the D_MOVE bus .","When use of the D_MOVE bus  is permitted for the switching instruction, data of a target register window is transferred from the MRF A, B corresponding to a thread to which the switching instruction belongs through the D_MOVE bus  to the CRB A, B. As explained, when an instruction is decoded, data to be used by the instruction is transferred to the CRB A, B, data required for processing of an instruction after the switching instruction is read out from the CRB A, B, so that the instructions before and after the switching instruction are executed by out-of-order execution, and it is possible to reduce processing time.","In the above-described manner, processing of the D_MOVE is executed.","Next, processing of the W_MOVE processing of commit will be explained.","Firstly, processing of commit in a normal calculation process will be explained.","In the instruction decode section  illustrated in , when a calculation instruction to execute calculation processing is decoded, an entry of the calculation instruction is created in the CSE A, B corresponding to a thread to which the calculation instruction belongs, of the CSE A, B illustrated in . In addition, the calculation instruction decoded in the calculation decode section  is transmitted to the computing unit  and is executed in the computing unit . When calculation processing according to the calculation instruction is completed, \u201c1:processed\u201d is set in a processing flag (VAL) of an entry corresponding to the calculation instruction, of the CSE A, B.","The commit control section  of  monitors the processing flags (VAL) of the CSE A, B, and when all processing flags of plural instructions belonging to a same thread become all \u201c1:processed\u201d, transmits those instructions to the instruction commit section .","In the instruction commit section , the plural instructions transmitted from the CSE A, B are committed in a predetermined program order, and an entry corresponding to a committed instruction is released.","Next, W_MOVE processing and commit processing by a SAVE instruction and a RESTORE instruction will be explained.","When a switching instruction (SAVE instruction, RESTORE instruction) is decoded in the decode section  of , an entry of the instruction is created in the CSE A, B corresponding to a thread to which the instruction belongs, of the CSE A, B illustrated in . In addition, the decoded instruction is stored in the D_MOVE_ISSUE_SLOT , and the above-described D_MOVE processing is executed. In the D_MOVE_ISSUE_SLOT , when the stored switching instruction is inputted to the D_MOVE processing control section , \u201c1: D_MOVE start\u201d is set in a D_MOVE_COMP flag of an entry corresponding to the switching instruction, of the CSE A, B.","The commit control section  monitors execution timing of commit processing by confirming the D_MOVE_COMP flags of the CSE A, B.",{"@attributes":{"id":"p-0154","num":"0154"},"figref":"FIG. 16","b":"260"},"The commit control section  monitors alternately the D_MOVE_COMP flags of the CSE A, B at each clock cycle, and when \u201c1:D_MOVE start\u201d is set in the D_MOVE_VOMP flag, acquires a thread number associated with the CSE A, B to which the entry belongs and sets the thread as a commit candidate.","Next, whether or not \u201c1: processed\u201d is set in the processing flag (VAL) of the entry corresponding to a preceding instruction belonging to the same thread of the CSE A, B after predetermined cycles (2 cycles in this embodiment) after the commit candidate is set and a use state of the W_MOVE bus  are checked. If all preceding instructions are completed in processing and the W_MOVE bus  is not in use, the commit control section  issues an instruction to execute W_MOVE processing toward the W_MOVE processing control section  of the register file MOVE processing control section  illustrated in , to perform commit of the SAVE instruction or the RESTORE instruction (W_MOVE processing).","If there exists a processing instruction not completed in processing or the W_MOVE bus  is used by another MOVE processing, after the CWR A, B and the W_MOVE bus  are released, an execution instruction of the W_MOVE processing is issued from the commit control section  toward the W_MOVE processing control section  and commit of the SAVE instruction and the RESTORE instruction (W_MOVE processing) is performed.","Upon receipt of the instruction to execute the W_MOVE processing, the W_MOVE processing control section  transfers data stored in the CWR A, B to the CRB A, B.","As illustrated in the lower part of , in the present embodiment, when an instruction to execute D_MOVE processing is issued from the D_MOVE_ISSUE_SLOT , while the D_MOVE processing is in process (2 cycles), the state is in commit waiting in the commit control section . Subsequently, if the W_MOVE bus  is released, commit is executed in the commit control section , and the W_MOVE processing is executed in the W_MOVE processing control section .",{"@attributes":{"id":"p-0160","num":"0160"},"figref":["FIG. 17","FIG. 17"],"b":["272","272","273","273"]},"As illustrated in , when an instruction to execute W_MOVE processing is issued from the commit control section  toward the W_MOVE processing control section  of the register file MOVE processing control section , the W_MOVE is executed in the W_MOVE processing control section , commit of a switching instruction of another thread is inhibited by the commit control section  in 2 cycles after the instruction to execute the W_MOVE processing is issued (including the cycle in which the W_MOVE is issued), and issuing of an instruction to execute the W_MOVE processing is inhibited. On and after the third cycle after the instruction to execute W_MOVE processing is issued, commit of a subsequent switching instruction is permitted by the commit control section . Because it takes 1 cycle to issue an instruction to execute the W_MOVE processing in the switching instruction, and on and after the fourth cycle where actually the subsequent W_MOVE processing is executed, the W_MOVE processing is completed, it is possible to avoid competing of the W_MOVE bus .","Next, the MOVE_ALL processing by the CWP update instruction and the trap will be explained.","When a CWP update instruction is committed or a trap occurs, the fact is informed to the rap\/CWP update instruction detect section , and a MOVE_ALL execution instruction (D_MOVE execution instruction+W_MOVE execution instruction) is issued from the trap\/CWP update instruction detect section  toward the register file MOVE processing control section . The D_MOVE instruction control section  and the W_MOVE processing control section  execute the above-described D_MOVE processing and W_MOVE processing. Incidentally, for a case of CWP update instruction, decoding a subsequent instruction is stopped until the MOVE_ALL processing after the instruction commit is completed, and if a trap occurs, a subsequent instruction is all canceled from the pipeline, and further, decoding the subsequent instruction is stopped until the MOVE_ALL processing is completed.",{"@attributes":{"id":"p-0164","num":"0164"},"figref":"FIG. 18"},"When an instruction to execute MOVE_ALL is issued from the trap\/CWP update instruction detect section  toward the register file MOVE processing control section , the D_MOVE processing and the W_MOVE processing are executed. In this example, 32 words (referred to register in ) included in one register window are transferred in four times separately for eight wards each. First, in the first transfer, data is transferred from the MRF A, B to the CRB A, B in the first cycle, and data is transferred from the CRB A, B to the CWR A, B in the second cycle. In the second transfer, the D_MOVE is executed in the second cycle in the first transfer, and the W_MOVE is executed in the third cycle in the first transfer. Subsequently, similarly, preceding W_MOVE and subsequent D_MOVE are executed in parallel by the pipeline.","Further, in a time interval until the last transfer is started after the instruction to execute MOVE_ALL is issued, issuing an instruction to execute D_MOVE by another switching instruction is prohibited, and in this interval in the D_MOVE_STACK is in waiting. Ina time interval until the W_MOVE in the last transfer is started after the instruction to execute MOVE_ALL is issued, issuing an instruction to execute W_MOVE by another switching instruction is prohibited. This is controlled by inhibiting commit in the commit control section in this time interval. In this manner, it is possible to mediate the D_MOVE bus  and W_MOVE bus .","Lastly, an entire flow of the processing will be explained using a concrete switching processing example.",{"@attributes":{"id":"p-0168","num":"0168"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0169","num":"0169"},"figref":"FIG. 19","b":["0","0","1"]},"When the first SAVE instruction belonging to the first thread  is issued, the first SAVE instruction is decoded and then stored in the D_MOVE_ISSUE_SLOT , and data is transferred from the MRF A (GPR mask) to the CRB A using the D_MOVE bus  (D_MOVE). Due to this, the CRB A is in use by the first SAVE instruction. Concretely, data of the CRB A is used to execute a subsequent instruction of the first SAVE instruction by out-of-order execution.","The second SAVE instruction belonging to the first thread  is, after decoded, stored in the D_MOVE_STACK . The second SAVE instruction is in a stall state in the D_MOVE_STACK _, _ until the CRB A is released by the first SAVE instruction belonging to the same thread.","In contrast, the third SAVE instruction belonging to the second thread  does not need to wait release of the CRB A by the first SAVE instruction, and when use of the D_MOVE bus  is permitted, the third SAVE instruction is stored in the D_MOVE_ISSUE_SLOT  before the second SAVE instruction. Then, data is transferred from the MRF B to the CRB B using the D_MOVE bus  (D_MOVE).","When processing of the instruction belonging to the first thread  is completed, and after use of the CWR A is completed and then the CWR A is released, data is transferred from the CRB A to the CWR A by the first SAVE instruction belonging to the first thread  and then the CRB A is released. As a result, stall in the second SAVE instruction is released.","When the stall is released, competing between the third SAVE instruction and the D_MOVE bus  is mediated in the D_MOVE_STACK , , the second SAVE instruction is stored in the D_MOVE_ISSUE_SLOT  and the D_MOVE is executed.","By inhibiting storing plural switching instructions belonging to a same thread into the D_MOVE_STACK, it is possible to avoid a failure in which those plural switching instructions are simultaneously executed and data of the CRB A, B and the CWP A, B which are in use is overwritten. And further, by controlling an input order of instructions stacked in the D_MOVE_STACK into the D_MOVE processing control section , it is possible to readily mediate the D_MOVE bus  and a second bus.","As explained, in the present embodiment, it is possible to obtain simultaneous multithreading while suppressing cost increasing and size increasing of the apparatus.","Here, in the above explanation, the example of instruction processing apparatus to execute two threads simultaneously is explained. However, the instruction processing apparatus (according to the invention) may be one in which three or more threads are simultaneously executed.","Further, in the above explanations, the example in which the instruction processing apparatus according to the invention is applied to a CPU of a personal computer is explained. However, the instruction processing apparatus according to the invention may be, for example, a CPU of a server apparatus.","All examples and conditional language recited herein are intended for pedagogical purposes to aid the reader in understanding the invention and the concepts contributed by the inventor to furthering the art, and are to be construed as being without limitation to such specifically recited examples and conditions, nor does the organization of such examples in the specification relate to a showing of the superiority and inferiority of the invention. Although the embodiments of the present inventions have been described in detail, it should be understood that the various changes, substitutions, and alterations could be made hereto without departing from the spirit and scope of the invention."],"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND ART","DISCLOSURE OF THE INVENTION","BEST MODE FOR CARRYING OUT THE INVENTION"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0065","num":"0065"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0066","num":"0066"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0067","num":"0067"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0068","num":"0068"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0069","num":"0069"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0070","num":"0070"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0071","num":"0071"},"figref":"FIG. 7","b":"10"},{"@attributes":{"id":"p-0072","num":"0072"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0073","num":"0073"},"figref":["FIG. 9","FIG. 8"]},{"@attributes":{"id":"p-0074","num":"0074"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0075","num":"0075"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0076","num":"0076"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0077","num":"0077"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0078","num":"0078"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0079","num":"0079"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0080","num":"0080"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0081","num":"0081"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0082","num":"0082"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0083","num":"0083"},"figref":"FIG. 19"}]},"DETDESC":[{},{}]}
