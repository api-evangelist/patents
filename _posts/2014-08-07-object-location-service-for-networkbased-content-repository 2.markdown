---
title: Object location service for network-based content repository
abstract: A distributed object store in a network storage system uses location-independent global object identifiers (IDs) for stored data objects. The global object ID enables a data object to be seamlessly moved from one location to another without affecting clients of the storage system, i.e., “transparent migration”. The global object ID can be part of a multilevel object handle, which also can include a location ID indicating the specific location at which the data object is stored, and a policy ID identifying a set of data management policies associated with the data object. The policy ID may be associated with the data object by a client of the storage system, for example when the client creates the object, thus allowing “inline” policy management. An object location subsystem (OLS) can be used to locate an object when a client request does not contain a valid location ID for the object.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09565254&OS=09565254&RS=09565254
owner: NetApp, Inc.
number: 09565254
owner_city: Sunnyvale
owner_country: US
publication_date: 20140807
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This is a continuation of U.S. patent application Ser. No. 12\/633,745, filed on Dec. 8, 2009, which is incorporated herein by reference in its entirety.","At least one embodiment of the present invention pertains to network storage systems, and more particularly, to an object location service of a content repository in a network storage server system.","Network based storage, or simply \u201cnetwork storage\u201d, is a common approach to backing up data, making large amounts of data accessible to multiple users, and other purposes. In a network storage environment, a storage server makes data available to client (host) systems by presenting or exporting to the clients one or more logical containers of data. There are various forms of network storage, including network attached storage (NAS) and storage area network (SAN). In a NAS context, a storage server services file-level requests from clients, whereas in a SAN context a storage server services block-level requests. Some storage servers are capable of servicing both file-level requests and block-level requests.","There are several trends that are relevant to network storage technology. The first is that the amount of data being stored within a typical enterprise is approximately doubling from year to year. Second, there are now multiple classes of storage devices available on the market today, each with its own performance characteristics. These two trends together have caused users to want storage systems that mix different kinds of storage in such a way that it is possible to seamlessly move data across storage tiers based on some policy or policies.","In addition, users often would like to apply policies to collections of data objects. For example, an online social networking site\/service might want to replicate all of its original size photos (e.g., photos of its members\/users) three times, but not the thumbnail versions, since the thumbnails can be recreated from the originals. Yet today, setting policy within a storage system is a cumbersome process that has to be done out-of-band by a system administrator. Application writers and users cannot specify policies on groups of files\/objects.","A problem associated with conventional storage systems is that the use of path names, such as in a traditional filesystem, imposes a hierarchical organization on the data, to which applications need to conform and use for different purposes, such as navigation and retrieval, access control, and data management. However, a hierarchical organization may not make sense for uses other than navigation and retrieval, and as a result, it can lead to inefficiencies such as duplication of content and consequent administrative overhead.","Furthermore, a hierarchical organization has also proven to be ineffective for navigation and retrieval. Consider a photo that is stored under a given path name, such as \u201c\/home\/eng\/myname\/office.jpeg\u201d. In a traditional storage system, this name maps to a specific server\/controller, a specific volume and a specific file location (e.g., inode number) within that volume. Thus, path names are tied to storage location.","The techniques introduced here provide a distributed object store in a network storage server system. The distributed object store can be part of a content repository, which aside from the distributed object store includes a presentation layer, a metadata subsystem, and a policy-based management subsystem. The content repository can be implemented in a multi-node storage server cluster.","The distributed object store creates and uses system-generated, location-independent (location-transparent), global object identifiers (IDs) for sub-volume level data objects (e.g., files) managed by the storage system. A \u201cdata object\u201d can be any unit of data, such as a file, a block of data, or a logical unit (\u201cLUN\u201d). A \u201csub-volume level\u201d data object is a data object that can be stored within a volume (defined below). The global object ID described herein enables the corresponding data object to be seamlessly moved from one location to another (e.g., from one physical or logical storage container to another) without affecting clients of the storage system, i.e., transparently to the clients; this capability can be called \u201ctransparent migration\u201d.","The global object ID can be part of a multilevel object handle, which also includes (in addition to the global object ID) a location identifier that indicates the specific location at which the data object is stored. The multilevel object handle can also include other information, such as a policy ID that identifies a set of one or more data management policies associated with the data object. The policy ID may be associated with the data object by a client of the storage system, for example at the time the client creates the data object. Embedding policy information within the object handle allows policy management to be implemented efficiently within the input\/output (I\/O) path of the server system, i.e., \u201cinline\u201d policy management. For example, in response to receiving from a client a request that includes the object handle, the server system uses the policy ID in the object handle to look up in a database the particular policy or policies associated with that policy ID, and then applies such policy or policies to the request and\/or to the data object.","When a client submits a data access request that includes a valid location ID (i.e., within an object handle), the server system can often use that location ID to directly locate and access the target data object. However, in some instances the location ID in the object handle may be invalid, such as if the target data object has been moved, or if the client did not provide a complete object handle. For use in such instances, the server system also includes an object location subsystem (OLS) to locate the target data object. The OLS includes a data structure that maps global object IDs to corresponding valid (up-to-date) location IDs of data objects. The server system further maintains a namespace which is independent of the OLS mapping structure and which includes a mapping of path names to global object IDs of the data objects stored in the server system. A \u201cnamespace\u201d, as the term is used herein, is a mechanism for allowing end users or applications to name and organize data objects (which may, for example, provide hierarchical naming and\/or organization of data, such as a directory\/file structure). The namespace together with the OLS provides a layer of indirection between (i.e., provides a logical separation of) path names and storage locations of the stored data objects. This separation facilitates transparent migration (i.e., an object can be moved without affecting its name), and moreover, it enables any particular data object to be represented by multiple paths names, thereby facilitating navigation. In particular, this allows the implementation of a hierarchical protocol such as NFS or CIFS on top of an object store, while at the same time maintaining the ability to do transparent migration.","Other aspects of the technique will be apparent from the accompanying figures and from the detailed description which follows.","References in this specification to \u201can embodiment\u201d, \u201cone embodiment\u201d, or the like, mean that the particular feature, structure or characteristic being described is included in at least one embodiment of the present invention. Occurrences of such phrases in this specification do not necessarily all refer to the same embodiment.","System Environment",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIGS. 1 and 2","FIG. 1","FIG. 1"],"b":["104","1","104","2","102","106","104","1","104","2","102","102","108","110","112","105","212"]},"The storage server (or servers)  may be, for example, one of the FAS-xxx family of storage server products available from NetApp, Inc. The client systems .-. are connected to the storage server  via the computer network , which can be a packet-switched network, for example, a local area network (LAN) or wide area network (WAN). Further, the storage server  is connected to the disks  via a switching fabric , which can be a fiber distributed data interface (FDDI) network, for example. It is noted that, within the network data storage environment, any other suitable numbers of storage servers and\/or mass storage devices, and\/or any other suitable network technologies, may be employed.","The storage server  can make some or all of the storage space on the disk(s)  available to the client systems .-. in a conventional manner. For example, each of the disks  can be implemented as an individual disk, multiple disks (e.g., a RAID group) or any other suitable mass storage device(s). The storage server  can communicate with the client systems .-. according to well-known protocols, such as the Network File System (NFS) protocol or the Common Internet File System (CIFS) protocol, to make data stored on the disks  available to users and\/or application programs. The storage server  can present or export data stored on the disk  as volumes to each of the client systems .-.. A \u201cvolume\u201d is an abstraction of physical storage, combining one or more physical mass storage devices (e.g., disks) or parts thereof into a single logical storage object (the volume), and which is managed as a single administrative unit, such as a single file system. A \u201cfile system\u201d is a structured (e.g., hierarchical) set of stored logical containers of data (e.g., volumes, logical unit numbers (LUNs), directories, files). Note that a \u201cfile system\u201d does not have to include or be based on \u201cfiles\u201d per se as its units of data storage.","Various functions and configuration settings of the storage server  and the mass storage subsystem  can be controlled from a management station  coupled to the network . Among many other operations, a data object migration operation can be initiated from the management station .",{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 2","FIG. 1","FIG. 2"],"b":["200","204","204","1","204","202","206","204","202","202","208","208","1","208","210","212","212","1","212","212","212","208"]},"Each of the nodes  is configured to include several modules, including an network module , a data module , and an management host  (each of which can be implemented by using a separate software module) and an instance of a replicated database (RDB) . Specifically, node . includes an network module ., a data module ., and an management host .; node .N includes an network module .N, a data module .N, and an management host .N; and so forth. The network modules .-.M include functionality that enables nodes .-.N, respectively, to connect to one or more of the client systems  over the network , while the data modules .-.N provide access to the data stored on the disks .-.N, respectively. The management hosts  provide management functions for the clustered storage server system . Accordingly, each of the server nodes  in the clustered storage server arrangement provides the functionality of a storage server.","The RDB  is a database that is replicated throughout the cluster, i.e., each node  includes an instance of the RDB . The various instances of the RDB  are updated regularly to bring them into synchronization with each other. The RDB  provides cluster-wide storage of various information used by all of the nodes , including a volume location database (VLDB) (not shown). The VLDB is a database that indicates the location within the cluster of each volume in the cluster (i.e., the owning data module  for each volume) and is used by the network modules  to identify the appropriate data module  for any given volume to which access is requested.","The nodes  are interconnected by a cluster switching fabric , which can be embodied as a Gigabit Ethernet switch, for example. The network modules  and data modules  cooperate to provide a highly-scalable, distributed storage system architecture of a clustered computing environment implementing exemplary embodiments of the present invention. Note that while there is shown an equal number of network modules and data modules in , there may be differing numbers of network modules and\/or data modules in accordance with various embodiments of the technique described here. For example, there need not be a one-to-one correspondence between the network modules and data modules. As such, the description of a node  comprising one network module and one data module should be understood to be illustrative only.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 3","b":["208","301","301","320","340","370","380","390","370","208","208","270","214","216"]},"The storage controller  can be embodied as a single- or multi-processor storage system executing a storage operating system  that preferably implements a high-level module, such as a storage manager, to logically organize the information as a hierarchical structure of named directories, files and special types of files called virtual disks (hereinafter generally \u201cblocks\u201d) on the disks. Illustratively, one processor  can execute the functions of the network module  on the node  while another processor  executes the functions of the data module .","The memory  illustratively comprises storage locations that are addressable by the processors and adapters , ,  for storing software program code and data structures associated with the present invention. The processor  and adapters may, in turn, comprise processing elements and\/or logic circuitry configured to execute the software code and manipulate the data structures. The storage operating system , portions of which is typically resident in memory and executed by the processors(s) , functionally organizes the storage controller  by (among other things) configuring the processor(s)  to invoke storage operations in support of the storage service provided by the node . It will be apparent to those skilled in the art that other processing and memory implementations, including various computer readable storage media, may be used for storing and executing program instructions pertaining to the technique introduced here.","The network adapter  includes a plurality of ports to couple the storage controller  to one or more clients  over point-to-point links, wide area networks, virtual private networks implemented over a public network (Internet) or a shared local area network. The network adapter  thus can include the mechanical, electrical and signaling circuitry needed to connect the storage controller  to the network . Illustratively, the network  can be embodied as an Ethernet network or a Fibre Channel (FC) network. Each client  can communicate with the node  over the network  by exchanging discrete frames or packets of data according to pre-defined protocols, such as TCP\/IP.","The storage adapter  cooperates with the storage operating system  to access information requested by the clients . The information may be stored on any type of attached array of writable storage media, such as magnetic disk or tape, optical disk (e.g., CD-ROM or DVD), flash memory, solid-state disk (SSD), electronic random access memory (RAM), micro-electro mechanical and\/or any other similar media adapted to store information, including data and parity information. However, as illustratively described herein, the information is stored on disks . The storage adapter  includes a plurality of ports having input\/output (I\/O) interface circuitry that couples to the disks over an I\/O interconnect arrangement, such as a conventional high-performance, Fibre Channel (FC) link topology.","Storage of information on disks  can be implemented as one or more storage volumes that include a collection of physical storage disks cooperating to define an overall logical arrangement of volume block number (VBN) space on the volume(s). The disks  can be organized as a RAID group. One or more RAID groups together form an aggregate. An aggregate can contain one or more volumes\/file systems.","The storage operating system  facilitates clients' access to data stored on the disks . In certain embodiments, the storage operating system  implements a write-anywhere file system that cooperates with one or more virtualization modules to \u201cvirtualize\u201d the storage space provided by disks . In certain embodiments, a storage manager  () logically organizes the information as a hierarchical structure of named directories and files on the disks . Each \u201con-disk\u201d file may be implemented as set of disk blocks configured to store information, such as data, whereas the directory may be implemented as a specially formatted file in which names and links to other files and directories are stored. The virtualization module(s) allow the storage manager  to further logically organize information as a hierarchical structure of blocks on the disks that are exported as named logical unit numbers (LUNs).","In the illustrative embodiment, the storage operating system  is a version of the Data ONTAP\u00ae operating system available from NetApp, Inc. and the storage manager  implements the Write Anywhere File Layout (WAFL\u00ae) file system. However, other storage operating systems are capable of being enhanced or created for use in accordance with the principles described herein.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 4","b":["330","330","410","410","214","410","412","206","410","410","440"],"i":"a "},"In addition, the storage operating system  includes a set of layers organized to form a backend server  that provides data paths for accessing information stored on the disks  of the node . The backend server  in combination with underlying processing hardware also forms the data module . To that end, the backend server  includes a storage manager module  that manages any number of volumes , a RAID system module  and a storage driver system module .","The storage manager  primarily manages a file system (or multiple file systems) and serves client-initiated read and write requests. The RAID system  manages the storage and retrieval of information to and from the volumes\/disks in accordance with a RAID redundancy protocol, such as RAID-4, RAID-5, or RAID-DP, while the disk driver system  implements a disk access protocol such as SCSI protocol or FCP.","The backend server  also includes a CF interface module to implement intra-cluster communication  with network modules and\/or other data modules. The CF interface modules and can cooperate to provide a single file system image across all data modules  in the cluster. Thus, any network port of an network module  that receives a client request can access any data container within the single file system image located on any data module  of the cluster.","The CF interface modules  implement the CF protocol to communicate file system commands among the modules of cluster over the cluster switching fabric  (). Such communication can be effected by a data module exposing a CF application programming interface (API) to which an network module (or another data module) issues calls. To that end, a CF interface module  can be organized as a CF encoder\/decoder. The CF encoder of, e.g., CF interface on network module  can encapsulate a CF message as (i) a local procedure call (LPC) when communicating a file system command to a data module  residing on the same node or (ii) a remote procedure call (RPC) when communicating the command to a data module residing on a remote node of the cluster. In either case, the CF decoder of CF interface on data module  de-encapsulates the CF message and processes the file system command.","In operation of a node , a request from a client  is forwarded as a packet over the network  and onto the node , where it is received at the network adapter  (). A network driver of layer  processes the packet and, if appropriate, passes it on to a network protocol and file access layer for additional processing prior to forwarding to the storage manager . At that point, the storage manager  generates operations to load (retrieve) the requested data from disk  if it is not resident in memory . If the information is not in memory , the storage manager  indexes into a metadata file to access an appropriate entry and retrieve a logical VBN. The storage manager  then passes a message structure including the logical VBN to the RAID system ; the logical VBN is mapped to a disk identifier and disk block number (DBN) and sent to an appropriate driver (e.g., SCSI) of the disk driver system . The disk driver accesses the DBN from the specified disk  and loads the requested data block(s) in memory for processing by the node. Upon completion of the request, the node (and operating system) returns a reply to the client  over the network .","The data request\/response \u201cpath\u201d through the storage operating system  as described above can be implemented in general-purpose programmable hardware executing the storage operating system  as software or firmware. Alternatively, it can be implemented at least partially in specially designed hardware. That is, in an alternate embodiment of the invention, some or all of the storage operating system  is implemented as logic circuitry embodied within a field programmable gate array (FPGA) or an application specific integrated circuit (ASIC), for example.","The network module  and data module  each can be implemented as processing hardware configured by separately-scheduled processes of storage operating system ; however, in an alternate embodiment, the modules may be implemented as processing hardware configured by code within a single operating system process. Communication between an network module  and a data module  is thus illustratively effected through the use of message passing between the modules although, in the case of remote communication between an network module and data module of different nodes, such message passing occurs over the cluster switching fabric . A known message-passing mechanism provided by the storage operating system to transfer information between modules (processes) is the Inter Process Communication (IPC) mechanism. The protocol used with the IPC mechanism is illustratively a generic file and\/or block-based \u201cagnostic\u201d CF protocol that comprises a collection of methods\/functions constituting a CF API.","Overview of Content Repository","The techniques introduced here generally relate to a content repository implemented in a network storage server system  such as described above.  illustrates the overall architecture of the content repository according to one embodiment. The major components of the content repository include a distributed object store , and object location subsystem (OLS) , a presentation layer , a metadata subsystem (MDS)  and a management subsystem . Normally there will be a single instance of each of these components in the overall content repository, and each of these components can be implemented in any one server node  or distributed across two or more server nodes . The functional elements of each of these units (i.e., the OLS , presentation layer , MDS  and management subsystem ) can be implemented by specially designed circuitry, or by programmable circuitry programmed with software and\/or firmware, or a combination thereof. The data storage elements of these units can be implemented using any known or convenient form or forms of data storage device.","The distributed object store  provides the actual data storage for all data objects in the server system  and includes multiple distinct single-node object stores . A \u201csingle-node\u201d object store is an object store that is implemented entirely within one node. Each single-node object store  is a logical (non-physical) container of data, such as a volume or a logical unit (LUN). Some or all of the single-node object stores  that make up the distributed object store  can be implemented in separate server nodes . Alternatively, all of the single-node object stores  that make up the distributed object store  can be implemented in the same server node. Any given server node  can access multiple single-node object stores  and can include multiple single-node object stores .","The distributed object store provides location-independent addressing of data objects (i.e., data objects can be moved among single-node object stores  without changing the data objects' addressing), with the ability to span the object address space across other similar systems spread over geographic distances. Note that the distributed object store  has no namespace; the namespace for the server system  is provided by the presentation layer .","The presentation layer  provides access to the distributed object store . It is generated by at least one presentation module  (i.e., it may be generated collectively by multiple presentation modules , one in each multiple server nodes ). A presentation module  can be in the form of specially designed circuitry, or programmable circuitry programmed with software and\/or firmware, or a combination thereof.","The presentation layer  essentially functions as a router, by receiving client requests, translating them into an internal protocol and sending them to the appropriate data module . The presentation layer  provides two or more independent interfaces for accessing stored data, e.g., a conventional NAS interface  and a Web Service interface . The NAS interface  allows access to the object store  via one or more conventional NAS protocols, such as NFS and\/or CIFS. Thus, the NAS interface  provides a filesystem-like interface to the content repository.","The Web Service interface  allows access to data stored in the object store  via either \u201cnamed object access\u201d or \u201craw object access\u201d (also called \u201cflat object access\u201d). Named object access uses a namespace (e.g., a filesystem-like directory-tree interface for accessing data objects), as does NAS access; whereas raw object access uses system-generated global object IDs to access data objects, as described further below. The Web Service interface  allows access to the object store  via Web Service (as defined by the W3C), using for example, a protocol such as Simple Object Access Protocol (SOAP) or a RESTful (REpresentational State Transfer-ful) protocol, over HTTP.","The presentation layer  further provides at least one namespace  for accessing data via the NAS interface or the Web Service interface. In one embodiment this includes a Portable Operating System Interface (POSIX) namespace. The NAS interface  allows access to data stored in the object store  via the namespace(s) . The Web Service interface  allows access to data stored in the object store  via either the namespace(s)  (by using named object access) or without using the namespace(s)  (by using \u201craw object access\u201d). Thus, the Web Service interface  allows either named object access or raw object access; and while named object access is accomplished using a namespace , raw object access is not. Access by the presentation layer  to the object store  is via either a \u201cfast path\u201d  or a \u201cslow path\u201d , as discussed further below.","The function of the OLS  is to store and provide valid location IDs (and other information, such as policy IDs) of data objects, based on their global object IDs (these parameters are discussed further below). This is done, for example, when a client  requests access to a data object by using only the global object ID instead of a complete object handle including the location ID, or when the location ID within an object handle is no longer valid (e.g., because the target data object has been moved). Note that the system  thereby provides two distinct paths for accessing stored data, namely, a \u201cfast path\u201d  and a \u201cslow path\u201d . The fast path  provides data access when a valid location ID is provided by a client  (e.g., within an object handle). The slow path  makes use of the OLS and is used in all other instances of data access. The fast path  is so named because a target data object can be located directly from its (valid) location ID, whereas the slow path  is so named because it requires a number of additional steps (relative to the fast path) to determine the location of the target data object.","The MDS  is a subsystem for search and retrieval of stored data objects, based on metadata. It is accessed by users through the presentation layer . The MDS  stores data object metadata, which can include metadata specified by users, inferred metadata and\/or system-defined metadata. The MDS  also allows data objects to be identified and retrieved by searching on any of that metadata. The metadata may be distributed across nodes in the system. In one embodiment where this is the case, the metadata for any particular data object are stored in the same node as the object itself.","As an example of user-specified metadata, users of the system can create and associate various types of tags (e.g., key\/value pairs) with data objects, based on which such objects can be searched and located. For example, a user can define a tag called \u201clocation\u201d for digital photos, where the value of the tag (e.g., a character string) indicates where the photo was taken. Or, digital music files can be assigned a tag called \u201cmood\u201d, the value of which indicates the mood evoked by the music. On the other hand, the system can also generate or infer metadata based on the data objects themselves and\/or accesses to them.","There are two types of inferred metadata: 1) latent and 2) system-generated. Latent inferred metadata is metadata in a data object which can be extracted automatically from the object and can be tagged on the object (examples include Genre, Album in an MP3 object, or Author, DocState in a Word document). System-generated inferred metadata is metadata generated by the server system  and includes working set information (e.g., access order information used for object prefetching), and object relationship information; these metadata are generated by the system to enable better \u201csearching\u201d via metadata queries (e.g., the system can track how many times an object has been accessed in the last week, month, year, and thus, allow a user to run a query, such as \u201cShow me all of the JPEG images I have looked at in the last month\u201d). System-defined metadata includes, for example, typical file attributes such as size, creation time, last modification time, last access time, owner, etc.","The MDS  includes logic to allow users to associate a tag-value pair with an object and logic that provides two data object retrieval mechanisms. The first retrieval mechanism involves querying the metadata store for objects matching a user-specified search criterion or criteria, and the second involves accessing the value of a tag that was earlier associated with a specific object. The first retrieval mechanism, called a query, can potentially return multiple object handles, while the second retrieval mechanism, called a lookup, deals with a specific object handle of interest.","The management subsystem  includes a content management component  and an infrastructure management component . The infrastructure management component  includes logic to allow an administrative user to manage the storage infrastructure (e.g., configuration of nodes, disks, volumes, LUNs, etc.). The content management component  is a policy based data management subsystem for managing the lifecycle of data objects (and optionally the metadata) stored in the content repository, based on user-specified policies or policies derived from user-defined SLOs. It can execute actions to enforce defined policies in response to system-defined trigger events and\/or user-defined trigger events (e.g., attempted creation, deletion, access or migration of an object). Trigger events do not have to be based on user actions.","The specified policies may relate to, for example, system performance, data protection and data security. Performance related policies may relate to, for example, which logical container a given data object should be placed in, migrated from or to, when the data object should be migrated or deleted, etc. Data protection policies may relate to, for example, data backup and\/or data deletion. Data security policies may relate to, for example, when and how data should be encrypted, who has access to particular data, etc. The specified policies can also include polices for power management, storage efficiency, data retention, and deletion criteria. The policies can be specified in any known, convenient or desirable format and method. A \u201cpolicy\u201d in this context is not necessarily an explicit specification by a user of where to store what data, when to move data, etc. Rather, a \u201cpolicy\u201d can be a set of specific rules regarding where to store what, when to migrate data, etc., derived by the system from the end user's SLOs, i.e., a more general specification of the end user's expected performance, data protection, security, etc. For example, an administrative user might simply specify a range of performance that can be tolerated with respect to a particular parameter, and in response the management subsystem  would identify the appropriate data objects that need to be migrated, where they should get migrated to, and how quickly they need to be migrated.","The content management component  uses the metadata tracked by the MDS  to determine which objects to act upon (e.g., move, delete, replicate, encrypt, compress). Such metadata may include user-specified metadata and\/or system-generated metadata. The content management component  includes logic to allow users to define policies and logic to execute\/apply those policies.",{"@attributes":{"id":"p-0066","num":"0065"},"figref":["FIG. 6","FIGS. 2 through 4","FIG. 6","FIG. 6"],"b":["208","208"]},"In one embodiment, the distributed object store  is implemented by providing at least one single-node object store  in each of at least two data modules  in the system (any given data module  can include zero or more single node object stores ). Also implemented in each of at least two data modules  in the system are: an OLS store  that contains mapping data structures used by the OLS  including valid location IDs and policy IDs; a policy store  (e.g., a database) that contains user-specified policies relating to data objects (note that at least some policies or policy information may also be cached in the network module  to improve performance); and a metadata store  that contains metadata used by the MDS , including user-specified object tags. In practice, the metadata store  may be combined with, or implemented as a part of, the single node object store .","The presentation layer  is implemented at least partially within each network module . In one embodiment, the OLS  is implemented partially by the network module  and partially by the corresponding management host , as illustrated in . More specifically, in one embodiment the functions of the OLS  are implemented by a special daemon in the management host  and by the presentation layer  in the network module .","In one embodiment, the MDS  and management subsystem  are both implemented at least partially within each management host . Nonetheless, in some embodiments, any of these subsystems may also be implemented at least partially within other modules. For example, at least a portion of the content management component  of the management subsystem  can be implemented within one or more network modules  to allow, for example, caching of policies in such network modules and\/or execution\/application of policies by such network module(s). In that case, the processing logic and state information for executing\/applying policies may be contained in one or more network modules , while processing logic and state information for managing policies is stored in one or more management hosts . As another example, at least a portion of the MDS  may be implemented within one or more data modules , to allow it to access more efficiently system generated metadata generated within those modules.","Administrative users can specify policies for use by the management subsystem , via a user interface provided by the management host  to access the management subsystem . Further, via a user interface provided by the management host  to access the MDS , end users can assign metadata tags to data objects, where such tags can be in the form of key\/value pairs. Such tags and other metadata can then be searched by the MDS  in response to user-specified queries, to locate or allow specified actions to be performed on data objects that meet user-specified criteria. Search queries received by the MDS  are applied by the MDS  to the single node object store  in the appropriate data module(s) .","Distributed Object Store","As noted above, the distributed object store enables both path-based access to data objects as well as direct access to data objects. For purposes of direct access, the distributed object store uses a multilevel object handle, as illustrated in . When a client  creates a data object, it receives an object handle  as the response to creating the object. This is similar to a file handle that is returned when a file is created in a traditional storage system. The first level of the object handle is a system-generated globally unique number, called a global object ID, that is permanently attached to the created data object. The second level of the object handle is a \u201chint\u201d which includes the location ID of the data object and, in the illustrated embodiment, the policy ID of the data object. Clients  can store this object handle , containing the global object ID location ID and policy ID.","When a client  attempts to read or write the data object using the direct access approach, the client includes the object handle of the object in its read or write request to the server system . The server system  first attempts to use the location ID (within the object handle), which is intended to be a pointer to the exact location within a volume where the data object is stored. In the common case, this operation succeeds and the object is read\/written. This sequence is the \u201cfast path\u201d  for I\/O (see ).","If, however, an object is moved from one location to another (for example, from one volume to another), the server system  creates a new location ID for the object. In that case, the old location ID becomes stale (invalid). The client may not be notified that the object has been moved or that the location ID is stale and may not receive the new location ID for the object, at least until the client subsequently attempts to access that data object (e.g., by providing an object handle with an invalid location ID). Or, the client may be notified but may not be able or configured to accept or understand the notification.","The current mapping from global object ID to location ID is always stored reliably in the OLS . If, during fast path I\/O, the server system  discovers that the target data object no longer exists at the location pointed to by the provided location ID, this means that the object must have been either deleted or moved. Therefore, at that point the server system  will invoke the OLS  to determine the new (valid) location ID for the target object. The server system  then uses the new location ID to read\/write the target object. At the same time, the server system  invalidates the old location ID and returns a new object handle to the client that contains the unchanged and unique global object ID, as well as the new location ID. This process enables clients to transparently adapt to objects that move from one location to another (for example in response to a change in policy).","An enhancement of this technique is for a client  never to have to be concerned with refreshing the object handle when the location ID changes. In this case, the server system  is responsible for mapping the unchanging global object id to location ID. This can be done efficiently by compactly storing the mapping from global object ID to location ID in, for example, cache memory of one or more network modules .","Refer now to , which shows an example of the overall process by which the distributed object store services a data access request from a client . Initially, at  the server system  receives from a client  a request to access the target data object (e.g., a read or write request). The request at least includes a global object ID for the target data object. The server system  then determines at  whether the request includes a location ID (as noted above, in some instances a client may provide only the global object ID with the request). If the request includes a location ID, then the process proceeds with the fast path I\/O, i.e., to operation ; otherwise, the process proceeds with the slow path, to operation .","At  the distributed object store gets the location ID in the provided object handle. Next, at  the server system  attempts to access the target data object according to that location ID. Part of attempting to access the data object is determining whether the location ID provided in the object handle is valid. In one embodiment this is accomplished by examining a flag in metadata of the target object, where such flag is set whenever the object is deleted or moved. For example, such a flag may exist in an inode representing the target object. If the object has been deleted or moved, the location ID will be invalid.","In this regard, note that the location ID maps to an internal file handle, which includes a number of fields. Once a data module  receives a file handle, it can determine by looking at these fields whether the file handle is recent. The two relevant fields in this regard are the file ID (or inode number) and the generation number. The file ID (or inode number) can be used to determine if an inode for the target data object exists (and so, whether the data object itself exists), and the generation number can be used to determine whether the file handle refers to the correct version of the data object. The file ID (or inode number) maps to the data object's inode, and the generation number is a counter stored within the inode. Whenever the inode is reused (e.g., the previous data object is deleted and a new one is created), the generation number within the inode is incremented. This allows a data module  (and, more specifically, its storage manager ) to detect access to a valid inode with an invalid generation number. Once this occurs the storage manager  in the data module  returns a \u201cStale file handle\u201d error, which triggers an \u201cInvalid Location ID\u201d error. Thus, the file ID can be used to determine if an inode for the target data object exists (and so, whether the data object itself exists) and the generation number can be used to determine whether the file handle refers to the correct version of the data object. If one of these is not valid, an \u201cInvalid Location ID\u201d error is returned and can be used to trigger access the OLS  to get an updated location ID.","Referring still to , if the location ID in the object handle is valid (), then at  the server system  accesses the target data object according to that location ID. The server system  then sends an appropriate response to the client at  (e.g., including the requested data in the case of a read or a confirmation in the case or write), and the process then ends.","If the location ID was not valid (), then the process branches to the slow path, proceeding to operation . At  the server system  gets the global object ID from the object handle provided by the client. At  the server system  invokes the OLS , passing the global object ID to the OLS . The OLS  then determines and returns the valid location ID for the target data object at , in a manner which is described below. The server system  then accesses the target data object at  according to the valid location ID, and at  the server system  sends an appropriate response to the client, including the new (valid) location ID for the target object. The process then ends.","Referring again to , if the request from the client did not include a location ID, the system uses the slow path, proceeding to  as described above.","As noted above, an object handle can contain a policy ID to support inline policy management (i.e., policy management within the normal I\/O path), which allows fast execution of policies. When a data object is created, the create function can also specify the policy or set of policies that needs to be applied on the object. Examples of such a policy (expressed here in natural language for simplicity) include \u201creplicate an object twice\u201d, \u201ccompress the object after storing it\u201d, and \u201cstore the object on cheap, low-power disks\u201d. One or more such policies can be represented by a policy ID.","Each time during an object read\/write or delete, the server system  uses the policy ID encoded in the object handle to quickly look up in the policy store the action that needs to be taken. For example, if the policy states \u201cdo not delete this file until 2015\u201d, a delete operation will fail until after that year. If for some reason a policy ID cannot be specified (as may be the case with certain protocols, such as NFS or CIFS), a default policy or a policy based on the data object's location or type can be applied.",{"@attributes":{"id":"p-0084","num":"0083"},"figref":"FIG. 9","b":["901","202","204","902","202","903","202"]},"If the policy ID is determined not to be valid at , then the process branches to , where the server system  looks up the valid policy ID for the object handle in the OLS , using the global object ID in the object handle as a lookup key. The process then continues to .","After , or after the policy ID is determined to be valid at , the server system  looks up in the policy store the policy or policies that correspond to the (valid) policy ID, at . At  the server system  then applies the identified policy or policies. A policy may apply to a specific data object (e.g., \u201cencrypt file A\u201d). A policy can also (or alternatively) apply to a particular client or user (e.g., \u201cJoe is prohibited from accessing file A\u201d) or to a particular logical container (e.g., \u201cvolume X is read-only\u201d). The server system  sends an appropriate response to the client at , and the process then ends.",{"@attributes":{"id":"p-0087","num":"0086"},"figref":"FIG. 10","b":["1001","202","204","1002","202","1003","202","202","1004","1005","202","202","1006","202","1007"]},"If it is determined at  that the request from the client does not specify a policy, then a default policy or a policy based on the data object's location will be used; accordingly, the process in that case branches to , where the server system  creates an object handle for the object and includes the policy ID of the default (or selected) policy in the object handle. The server system  then proceeds to  and continues as described above.","Object Location Subsystem (OLS)","The OLS  is a mechanism the primary purpose of which is to allow a valid location ID of a data object to be determined from the object's global object ID. However, the OLS  also allows the policy ID and\/or any other metadata associated with a data object to be identified in essentially the same way. An example of how this can be implemented is described now with reference to .","In one embodiment, each global object ID used by the server system  is a multi-bit entity which is logically divided into multiple segments. Each segment includes at least one bit and typically includes multiple bits. In the example of , a global object ID  is a nine-bit value, which is divided into three segments, X, Y and Z, each of which includes three bits. A first segment X represents the three most significant bits of the global object ID, a second segment Y represents the next most significant bits of the global object ID, and segment Z represents the three least significant bits of the global object ID. These particular numbers of bits and segments are used here only to facilitate description; for any given system, the number of segments and bits in a global object ID can be chosen to accommodate the system's anticipated storage needs (i.e., a greater number of segments\/bits allows a greater number of data objects to be represented).","The OLS  includes a mapping data structure  (which can be stored in the OLS store  in ) that maps global object IDs to their corresponding location IDs and policy IDs (and\/or any other metadata that may be associated with a data object). Each predefined segment of the global object ID is used to index into a different level of the mapping data structure . In the example of , each three-bit segment of the global object ID can have eight possible values, e.g., 0, 1, 2, . . . , 7, and therefore, can represent eight different entries within a given level of the mapping data structure . For example, the value of segment X is used to select the appropriate entry in the top level of the mapping data structure , the value of segment Y is used to select the appropriate entry in the next lower level of the mapping data structure , and the value of segment Z is used to select the appropriate entry in the lowest level of the mapping data structure . The selected entry in the lowest level contains the current (valid) location ID and policy ID of the global object ID . In this way, the OLS enables the current location ID, policy ID and\/or any other metadata associated with a data object to be easily located based on the global object ID of the object.","In one embodiment, each node in the structure depicted in  is a directory in a file system, and the traversal of the tree structure is accomplished by a conventional directory traversal operation performed by the storage manager  () of a data module . In another embodiment, the leaf nodes can contain multiple mappings instead of just one. In that case, the entries in each leaf node have the form <object id least significant bits>:<location ID, policy ID>. That is, the \u201cremaining\u201d least significant bits of the object ID that were not used in the directory traversal to locate the leaf node are used as the lookup key in the directory that is the leaf node.","These nodes (both the leaves and the internal nodes) can reside on any storage container on any data module  in the system. The use of a global namespace in the storage cluster allows the \u201cstitching\u201d of these nodes into a single tree that can be traversed using standard directory tree traversal. By spreading the tree across multiple data modules , the performance of the OLS  can be scaled out, and we can avoid the OLS  becoming a centralized bottleneck.","Note also that the OLS tree can be populated \u201con demand\u201d as objects are created that \u201cfall\u201d into specific areas of the tree. This approach represents a trade-off between space and time, i.e., the space consumed for storing potentially unused sections of the tree versus the increased latency of creating objects due to having to create these OLS nodes in line during object creation.","As noted above, the server system  logically separates path names from object handles. In a traditional storage system, a file is represented by a path such as \u201c\/u\/foo\/bar\/file.doc\u201d. In this example, \u201cu\u201d is a directory under the root directory \u201c\/\u201d, \u201cfoo\u201d is a directory under \u201cu\u201d, and so on. Each component in this path gets mapped to a specific handle that identifies a specific storage location on a specific storage device. Therefore, the entire path name maps to a specific location, making it very difficult to move files around without having to rename them.","The multi-level object handle technique introduced here allows the server system  to break the tight relationship between path names and location that is characteristic of conventional storage systems. In one embodiment, path names in the server system  are stored in a POSIX namespace  (), which is maintained by the presentation layer  and is independent of actual locations of objects. The POSIX namespace  includes a data structure for mapping path names to corresponding global object IDs. By using this mapping in conjunction with the OLS  (i.e., by mapping path name to global object ID and then mapping global object ID to location ID), the server system  can mimic a traditional filesystem hierarchy. In certain embodiments the global object ID is stored within the object handle presented by the NAS protocol, thus avoiding a need to lookup the mapping on every access.","The POSIX namespace  together with the OLS  thereby provides a layer of indirection between (i.e., provides a logical separation of) path names of stored data objects and the storage locations of the data objects, and also provides a layer of indirection between object identifiers of the stored data objects and the storage locations of the data objects. This separation facilitates transparent migration (i.e., an object can be moved without affecting its name), and moreover, it enables any particular data object to be represented by multiple paths names, thereby facilitating navigation. In particular, this allows the implementation of a hierarchical protocol such as NFS on top of an object store, while at the same time maintaining the ability to do transparent migration. For example, when an object is moved to a new location, all that is necessary is update its OLS mapping to point to the new location. After that, subsequent requests by path name are carried out by mapping the existing path name to the existing global object ID and then mapping that global object ID to the new location ID.","The techniques introduced above can be implemented by programmable circuitry programmed or configured by software and\/or firmware, or entirely by special-purpose circuitry, or in a combination of such forms. Such special-purpose circuitry (if any) can be in the form of, for example, one or more application-specific integrated circuits (ASICs), programmable logic devices (PLDs), field-programmable gate arrays (FPGAs), etc.","Software or firmware for implementing the techniques introduced here may be stored on a machine-readable storage medium and may be executed by one or more general-purpose or special-purpose programmable microprocessors. A \u201cmachine-readable medium\u201d, as the term is used herein, includes any mechanism that can store information in a form accessible by a machine (a machine may be, for example, a computer, network device, cellular phone, personal digital assistant (PDA), manufacturing tool, any device with one or more processors, etc.). For example, a machine-accessible medium includes recordable\/non-recordable media (e.g., read-only memory (ROM); random access memory (RAM); magnetic disk storage media; optical storage media; flash memory devices; etc.), etc.","The term \u201clogic\u201d, as used herein, can include, for example, special-purpose hardwired circuitry, software and\/or firmware in conjunction with programmable circuitry, or a combination thereof.","Although the present invention has been described with reference to specific exemplary embodiments, it will be recognized that the invention is not limited to the embodiments described, but can be practiced with modification and alteration within the spirit and scope of the appended claims. Accordingly, the specification and drawings are to be regarded in an illustrative sense rather than a restrictive sense."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["One or more embodiments of the present invention are illustrated by way of example and not limitation in the figures of the accompanying drawings, in which like references indicate similar elements.",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 6","FIGS. 2 through 4"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
