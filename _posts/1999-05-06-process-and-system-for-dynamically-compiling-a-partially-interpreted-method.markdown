---
title: Process and system for dynamically compiling a partially interpreted method
abstract: A process and system for dynamically compiling a partially interpreted method is provided. A set of bytecodes for a method is interpreted within a virtual machine. During the interpretation of the method, it is determined, according to the satisfaction of predetermined criteria, that the method contains an execution hot spot and should be just-in-time compiled (JITed) in order to increase the processing speed of the method. The interpretation of the method is halted with a halted execution state and at a halted execution location. Another method is constructed using information from the partially interpreted method and its execution state. The newly constructed method is just-in-time compiled and invoked in such a manner that the newly constructed method recreates the execution state of the partially interpreted method. Once the newly constructed method recreates the execution state of the partially interpreted method, the execution flow follows the bytecode sequence of the partially interpreted method.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06851109&OS=06851109&RS=06851109
owner: International Business Machines Corporation
number: 06851109
owner_city: Armonk
owner_country: US
publication_date: 19990506
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["The present invention is related to application entitled Method and Apparatus For Partial Just In Time Compiling in a Data Processing System, Ser. No. 09\/303,106, assigned to the same assignee, and incorporated herein by reference.","1. Technical Field","The present invention relates generally to an improved data processing system and, in particular, to a process and system for dynamically compiling a program.","2. Description of Related Art","Since Java is an interpreted language, any programs written in Java, after being converted into Java class files, are interpreted by a Java virtual machine (JVM). In order to improve performance, many JVMs may compile Java classes into platform-specific binary code after they are loaded into the JVM. Then, instead of being interpreted, Java classes are executed in their compiled native code format, similar to programs written in other languages, such as C, C++, etc. Such just-in-time (JIT) compilation of Java programs can significantly improve the speed of execution of Java programs.","In some early implementations of JIT compilers, JIT compilation is enabled for every method loaded into the JVM for all Java applications. However, the just-in-time compilation time becomes part of the execution time of a Java program. For a given Java class method, JIT compilation can be justified only if the compiled method code executes in less time than the JIT compilation time for the method. Otherwise, the method should be executed by interpreting the method's bytecodes. For typical Java applications, there are many class methods which are only rarely invoked, making JIT compilation of such methods unjustified. As a result, on JVMs with early JIT compilers, loading Java applications with JIT compilation enabled is typically slower than loading the same Java applications with interpretation only (JIT compilation disabled). This is mainly due to the fact that during the Java application loading time, a large number of class methods are invoked relatively few times, making their JIT compilation times unjustified.","In more advanced JVM implementations, JIT compilers compile Java methods selectively, depending on the frequency with which the methods are invoked. This so-called \u201chot-spot compiling\u201d is a hybrid of interpreting and just-in-time compiling that attempts to combine both techniques in order to yield Java programs that run as fast as natively compiled code. This type of execution may be performed by an interpreter in the execution engine called a \u201cmixed mode interpreter.\u201d A mixed-mode interpreter attempts to analyze or profile the execution of the program in order to determine the locations of the program that justify the time expense for compiling a portion of the program.","The usual approach to optimization is to profile the program to discover exactly where the program spends most of its time and then spend time optimizing portions of the program which execute most often. A Java virtual machine (JVM) that performs hot-spot compiling attempts to optimize only the time-critical portions of a program. In this approach, the JVM begins the execution of the program by interpreting the program. As the JVM interprets the program's bytecodes, it analyzes the execution of the program to determine the program's \u201chot spots,\u201d which is the part of the program where the program spends most of its time. When it identifies a hot spot, the JVM just-in-time compiles only the portion of the code that encompasses the hot spot.","As the program continues to run, the JVM continues to analyze the program. If another hot spot is revealed, the JVM can just-in-time compile and optimize new areas. Also, the JVM can revert back to using bytecodes for areas that no longer seem time-critical in order to keep the memory footprint at a minimum. Depending upon the host platform, a smaller memory footprint may make the difference between a program fitting or not fitting in memory.","It is important to note that the unit of Java program being JIT compiled or interpreted is whole Java methods. That is, a Java method is either entirely JIT compiled or interpreted in a JVM. Typically, mixed-mode interpreters allow each Java method to be interpreted for a number of times before it is compiled. In one previous solution, each method has an associated invocation counter that is decremented whenever the method is invoked and also when backward branches are encountered. When the counter reaches zero, the associated method is compiled at its next invocation, and subsequent invocations for the method use the compiled code.","A major disadvantage of this solution is that it causes low performance for Java methods with very long running loops. For example, a daemon thread may use an \u201cinfinite\u201d or essentially non-terminating loop to handle almost all of its work. Once the daemon thread enters the method, it may never exit. In this extreme but not so uncommon case, the method would be continually interpreted because the daemon thread may never return from the method so that it can be just-in-time compiled (or JITed). As a result, the daemon thread spends all its time in the interpretation mode, even though the method is already determined to be a \u201chot spot\u201d and is a candidate for JIT compilation.","Therefore, in order to improve the performance of certain Java programs, it would be particularly advantageous to provide a mixed-mode interpreter with the ability to improve the performance of a program with particular types of \u201chot spots,\u201d such as methods with essentially non-terminating loops.","The present invention provides a process and system for dynamically compiling a partially interpreted method. A set of bytecodes for a method is interpreted within a virtual machine. During the interpretation of the method, it is determined, according to the satisfaction of predetermined criteria, that the method contains an execution hot spot and should be just-in-time compiled (JITed) in order to increase the processing speed of the method. The interpretation of the method is halted with a halted execution state and at a halted execution location. Another method is constructed using information from the partially interpreted method and its execution state. The newly constructed method is just-in-time compiled and invoked in such a manner that the newly constructed method recreates the execution state of the partially interpreted method. Once the newly constructed method recreates the execution state of the partially interpreted method, the execution flow follows the bytecode sequence of the partially interpreted method.","With reference now to , a pictorial representation depicts a data processing system in which the present invention may be implemented in accordance with a preferred embodiment of the present invention. A personal computer  is depicted, which includes a system unit , a video display terminal , a keyboard , storage devices , which may include floppy drives and other types of permanent and removable storage media, and mouse . Additional input devices may be included with personal computer . Personal computer  can be implemented using any suitable computer, such as an IBM Aptiva\u2122 computer, a product of International Business Machines Corporation, located in Armonk, N.Y. Although the depicted representation shows a personal computer, other embodiments of the present invention may be implemented in other types of data processing systems, such as network computers, Web based television set top boxes, Internet appliances, etc. Computer  also preferably includes a graphical user interface that may be implemented by means of system software residing in computer readable media in operation within computer .","With reference now to , a block diagram illustrates internal components of a data processing system that may implement the present invention. Data processing system  is an example of a personal computer, such as computer  in FIG. . Data processing system  employs a peripheral component interconnect (PCI) local bus architecture. Although the depicted example employs a PCI bus, other bus architectures, such as Micro Channel and ISA, may be used. Processor  and main memory  are connected to PCI local bus  through PCI bridge . PCI bridge  also may include an integrated memory controller and cache memory for processor . Additional connections to PCI local bus  may be made through direct component interconnection or through add-in boards. In the depicted example, local area network (LAN) adapter , SCSI host bus adapter , and expansion bus interface  are connected to PCI local bus  by direct component connection. In contrast, audio adapter , graphics adapter , and audio\/video adapter  are connected to PCI local bus  by add-in boards inserted into expansion slots. Expansion bus interface  provides a connection for a keyboard and mouse adapter , modem , and additional memory . SCSI host bus adapter  provides a connection for hard disk drive , tape drive , and CD-ROM drive . Typical PCI local bus implementations will support three or four PCI expansion slots or add-in connectors.","An operating system runs on processor  and is used to coordinate and provide control of various components within data processing system  in FIG. . The operating system may be a commercially available operating system such as OS\/2, which is available from International Business Machines Corporation. \u201cOS\/2\u201d is a trademark of International Business Machines Corporation. An object oriented programming system such as Java may run in conjunction with the operating system and provides calls to the operating system from Java programs or applications executing on data processing system . \u201cJava\u201d is a trademark of Sun Microsystems, Inc. Instructions for the operating system, the object-oriented operating system, and applications or programs are located on storage devices, such as hard disk drive , and may be loaded into main memory  for execution by processor .","Those of ordinary skill in the art will appreciate that the hardware in  may vary depending on the implementation. Other internal hardware or peripheral devices, such as flash ROM (or equivalent nonvolatile memory) or optical disk drives and the like, may be used in addition to or in place of the hardware depicted in FIG. . Also, the processes of the present invention may be applied to a multiprocessor data processing system.","For example, data processing system , if optionally configured as a network computer, may not include SCSI host bus adapter , hard disk drive , tape drive , and CD-ROM . In that case, the computer, to be properly called a client computer, must include some type of network communication interface, such as LAN adapter , modem , or the like. As another example, data processing system  may be a stand-alone system configured to be bootable without relying on some type of network communication interface, whether or not data processing system  comprises some type of network communication interface. As a further example, data processing system  may be a Personal Digital Assistant (PDA) device which is configured with ROM and\/or flash ROM in order to provide non-volatile memory for storing operating system files and\/or user-generated data.","Other examples for data processing system  include an Internet information appliance for surfing the Internet and the World Wide Web. Internet information appliances may include Web-based interactive television set-top boxes. The depicted example in FIG.  and above-described examples are not meant to imply architectural limitations.","With reference now to , a block diagram illustrates the relationship of software components operating within a computer system that may implement the present invention. Java-based system  contains platform specific operating system  that provides hardware and system support to software executing on a specific hardware platform. Java Virtual Machine (JVM)  is one software application that may execute in conjunction with the operating system. JVM  provides a; Java run-time environment with the ability to execute Java application or applet , which is a program, servlet, or software component written in the Java programming language. The computer system in which JVM  operates may be similar to data processing system  or computer  described above. However, JVM  may be implemented in dedicated hardware on a so-called Java chip, Java-on-silicon, or Java processor with an embedded picoJava core.","The present invention provides a method and apparatus for dynamically compiling a Java method that has been partially executed through interpretation. Hence, the present invention operates in conjunction with a Java virtual machine yet within the boundaries of a JVM as defined by Java standard specifications. In order to properly present the present invention, portions of the operation of a Java virtual machine according to Java specifications are herein described.","At the center of a Java run-time environment is the JVM, which supports all aspects of Java's environment, including its architecture, security features, mobility across networks, and platform independence.","The JVM is a virtual computer, i.e. a computer that is specified abstractly. The specification defines certain features that every JVM must implement, with some range of design choices that may depend upon the platform on which the JVM is designed to execute. For example, all JVMs must execute Java bytecodes and may use a range of techniques to execute the instructions represented by the bytecodes. A JVM may be implemented completely in software or somewhat in hardware. This flexibility allows different JVMs to be designed for mainframe computers and PDAs.","A JVM must load class files and execute the bytecodes within them. The Java virtual machine contains a class loader, which loads class files from an application and the class files from the Java application programming interfaces (APIs) which are needed by the application. The execution engine that executes the bytecodes may vary across platforms and implementations.","The simplest type of software-based execution engine is a just-in-time compiler. With this type of execution, the bytecodes of a method are compiled to native machine code upon the first invocation of the method. The native machine code for the method is then cached and reused upon the next invocation of the method. The execution engine may also be implemented in hardware and embedded on a chip so that the Java bytecodes are executed natively. JVMs usually interpret bytecodes, but JVMs may also use other techniques, such as just-in-time compiling, to execute bytecodes.","When an application is executed on a JVM that is implemented in software on a platform-specific operating system, a Java application may interact with the host operating system by invoking native methods. A Java run-time environment may have two kinds of methods: Java and native. A Java method is written in the Java language, compiled to bytecodes, and stored in class files. A native method is written in Java or some other language and compiled to the native machine code of a particular processor. Native methods are stored in a dynamically linked library whose exact form is platform specific.","With reference now to , a block diagram of a Java virtual machine is depicted in accordance with a preferred embodiment of the present invention. Java virtual machine (JVM)  includes a class loader subsystem , which is a mechanism for loading types, such as classes and interfaces, given fully qualified names. JVM  also contains runtime data areas , execution engine , native method interface , and memory management . Execution engine  is a mechanism for executing instructions contained in the methods of classes loaded by class loader subsystem . Execution engine  may be, for example, Java interpreter  or just-in-time compiler . Native method interface  allows access to resources in the underlying operating system. Native method interface  may be, for example, a Java native interface.","Runtime data areas  contain native method stacks , Java stacks , PC registers , method area , and heap . These different data areas represent the organization of memory needed by JVM  to execute a program.","Java stacks  are used to store the state of Java method invocations. When a new thread is launched, the JVM creates a new Java stack for the thread. The JVM performs only two operations directly on Java stacks: it pushes and pops frames. A thread's Java stack stores the state of Java method invocations for the thread. The state of a Java method invocation includes its local variables, the parameters with which it was invoked, its return value, if any, and intermediate calculations. Java stacks are composed of stack frames. A stack frame contains the state of a single Java method invocation. When a thread invokes a method, the JVM pushes a new frame onto the Java stack of the thread. When the method completes, the JVM pops the frame for that method and discards it. A JVM does not have any registers for holding intermediate values; any Java instruction that requires or produces an intermediate value uses the stack for holding the intermediate values. In this manner, the Java instruction set is well-defined for a variety of platform architectures.","PC registers  are used to indicate the next instruction to be executed. Each instantiated thread gets its own pc register (program counter) and Java stack. If the thread is executing a JVM method, the value of the pc register indicates the next instruction to execute. If the thread is executing a native method, then the contents of the pc register are undefined.","Native method stacks  store the state of invocations of native methods. The state of native method invocations is stored in an implementation-dependent way in native method stacks, registers, or other implementation-dependent memory areas.","Method area  contains class data while heap  contains all instantiated objects. The JVM specification strictly defines data types and operations. The data types can be divided into a set of primitive types and a reference type. Reference values refer to objects, but primitive values are actual data. All the primitive types of the Java programming language, except \u201cboolean\u201d, are primitive types of a JVM. In a manner similar to the C language, \u201cbooleans\u201d are represented by an \u201cint\u201d or \u201cbyte\u201d in compiled Java bytecodes, with \u201cfalse\u201d represented by integer zero and \u201ctrue\u201d by any nonzero integer. All primitive types of the Java programming language other than \u201cboolean\u201d are numeric types of the JVM. Numeric types include the integral types \u201cbyte\u201d, \u201cshort\u201d, \u201cint\u201d, \u201clong\u201d, \u201cchar\u201d, and the floating-point types \u201cfloat\u201d and \u201cdouble\u201d. As with the Java programming language, primitive types of the JVM always have the same possible range of values. A \u201clong\u201d in the JVM always acts like a 64-bit signed two's-complement number, independent of the underlying host platform. The JMV has one additional primitive type that is unavailable in the Java programming language\u2014the \u201creturnValue\u201d type. This primitive type implements \u201cfinally\u201d clauses of Java programs.","All JVMs have one method area and one heap, each of which are shared by all threads running inside the JVM. When the JVM loads a class file, it parses information about a type from the binary data contained in the class file. It places this type information into the method area. Each time a class instance or array is created, the memory for the new object is allocated from heap . JVM  includes an instruction that allocates memory space within the memory for heap  but includes no instruction for freeing that space within the memory. Memory management  in the depicted example manages memory space within the memory allocated to heap . Memory management  may include a garbage collector which automatically reclaims memory used by objects that are no longer referenced by an application. Additionally, a garbage collector also may move objects to reduce heap fragmentation. Memory management  also may include an object relocator to relocate objects to a seldom used object store.","With reference now to , a block diagram depicts the memory areas that the JVM creates for each thread. These areas are private to each thread; a thread may not access the pc register or Java stack of another thread.",{"@attributes":{"id":"P-00049","num":"00049"},"figref":"FIG. 5","b":["500","1","3","1","520","522","524","2","530","532","538","3","540","542","546","502","506","510","1","3","510","3","504","548","3"]},"Threads  and  are executing Java methods while thread  is executing a native method. Stacks , , and  grow \u201cdownward\u201d in the figure with the top of each stack containing stack frame  for each thread. Stack frames , , and  are the stack frames for currently executing methods. A thread's current method is the method that is currently executing. A current method's stack frame is the current frame. The current method's class is the current class, and the current class's constant pool is the current constant pool. As it executes a method, the JVM keeps track of the current class and current constant pool. When the JVM executes a method's instructions for data stored in a stack frame, it performs those operations on the current frame.","When a thread invokes a Java method, the JVM creates and pushes a new frame onto the thread's Java stack. This new frame then becomes the current frame. As the method executes, it uses the frame to store parameters, local variables, intermediate computations, and other data. When a thread invokes a method, the method's local variables are stored in a frame on the invoking thread's Java stack. The only thread that may access these local variables is the thread that invoked the method. A method can complete either normally, i.e. completing execution, or abruptly, i.e. completing by throwing an exception. When a method completes, either normally or abruptly, the JVM pops and discards the completing method's stack frame. The frame for the previous method then becomes the current frame.","Java stack and stack frames do not need to be contiguous in memory. Frames may be allocated on a contiguous stack, on a heap, or both. The Java specification does not specify the actual data structures that implement the Java stack and stack frames.","A stack frame has three parts: local variables, operands, and frame data. The sizes of the local variables and operand portion of the stack frame, which are measured in words, depend on the needs of each individual method. These sizes are determined at compile-time and are included in the class file data for each method. The size of the frame data is implementation-dependent. When the JVM invokes a Java method, it checks the class data to determine the number of words required by the method in the local variables and operand stack. The JVM creates a stack frame of the proper size for the method and pushes the stack frame onto the Java stack.","The local variable section of the Java stack frame is organized as a zero-based array of words. Instructions that use a value from the local variable section provide an index into the zero-based array. Values of type \u201cint\u201d, \u201cfloat\u201d, \u201creference\u201d, and \u201creturnValue\u201d occupy one entry in the local variables array. Values of type \u201cbyte\u201d, \u201cshort\u201d, and \u201cchar\u201d are converted to \u201cint\u201d before being stored into the local variables. Values of type \u201clong\u201d and \u201cdouble\u201d occupy two consecutive entries in the array.","To refer to a \u201clong\u201d or \u201cdouble\u201d in the local variables, instructions provide the index of the first of the two consecutive entries occupied by the value. For example, if a \u201cdouble\u201d occupies array entries five and six, instructions would refer to that \u201cdouble\u201d by index five. All values in the local variables are word aligned. Dual-entry \u201clongs\u201d and \u201cdoubles\u201d can start at any index.","With reference now to , examples of Java source code and its effects on Java stack frames are provided.  provides examples of Java programming language source code statements for an instance method and a class method.  depicts the state of a local variables section of a stack frame.","The local variables section contains a method's parameters and local variables. Compilers place the parameters into the local variable array first, in the order in which they are declared.  shows the local variables section for the two methods shown in FIG. A.",{"@attributes":{"id":"P-00058","num":"00058"},"figref":"FIG. 6B","b":["6","1","6","2"]},"Data types \u201cbyte\u201d, \u201cshort\u201d, \u201cchar\u201d, and \u201cboolean\u201d in the source code of  have data type \u201cint\u201d in the local variables and operand portions of the stack. Each is manipulated as an \u201cint\u201d while on the stack frame and then converted back into the proper type when stored in the heap or method area.","All objects are passed by reference, such as \u201cObject Object\u201d that is passed as a reference to \u201cFigureBmethod( )\u201d. In Java, all objects are passed by reference. Therefore, only object references appear on the stack.","Compilers must place a method's parameters into the local variables array first and in order of declaration. However, Java compilers can arrange the local variables array arbitrarily. Compilers can place the method's local variables into the array in any order, and they can use the same array entry for more than one local variable. For example, if two local variables have limited scopes that do not overlap, compilers are free to use the same array entry for both variables. As with all the other runtime memory areas, implementation designers can use whatever data structures they deem most appropriate to represent the local variables. The JVM specification does not indicate how \u201clongs\u201d and \u201cdoubles\u201d should be split across the two array entries they occupy. Implementations that use a word size of 64 bits could, for example, store an entire \u201clong\u201d or \u201cdouble\u201d in the lower of the two consecutive entries, leaving the higher entry unused.","Like the local variables, the operand stack is organized as an array of words. But unlike the local variables, which are accessed via array indices, the operand stack is accessed by pushing and popping values. If an instruction pushes a value onto the operand stack, a later instruction can pop and use that value. The virtual machine stores the same data types in the operand stack that it stores in the local variables: \u201cint\u201d, \u201clong\u201d, \u201cfloat\u201d, \u201cdouble\u201d, \u201creference\u201d, and \u201creturnType\u201d. It converts values of type \u201cbyte\u201d, \u201cshort\u201d, and \u201cchar\u201d to \u201cint\u201d before pushing them onto the operand stack.","Other than the program counter, which cannot be directly accessed by instructions, the JVM has no registers. The JVM is stack-based rather than register-based because its instructions take their operands from the operand stack rather than from registers. Instructions can also take operands from other places, such as immediately following the opcode in the bytecode stream or from the constant pool. The JVM instruction set's main focus of attention, however, is the operand stack.","With reference now to , an example is provided for the manner in which a Java virtual machine adds two local variables that contain two integers of type \u201cint\u201d, and store the \u201cint\u201d result in a third local variable.","The JVM uses the operand stack as a workspace. Many instructions pop values from the operand stack, operate on them and push the result. For example, the \u201ciadd\u201d instruction adds two integers by popping two values of type \u201cint\u201d off the top of the operand stack, adding them and pushing the \u201cint\u201d result.","As shown in the example bytecodes in , two instructions, iload_ and iload_, push the \u201cints\u201d stored local variable position zero and one onto the operand stack. The \u201ciadd\u201d instruction pops those two \u201cint\u201d values, adds them and pushes the \u201cint\u201d result back onto the operand stack. The fourth instruction, istore_, pops the result of the add off the top of the operand stack and stores it into local variable position two.",{"@attributes":{"id":"P-00067","num":"00067"},"figref":["FIG. 7B","FIG. 7B"],"b":"7"},"In addition to the local variables and operand stack, the Java stack frame has a frame data portion that includes data to support the operation of the JVM with respect to the method: a pointer to the constant pool, normal method return, and the dispatch of exceptions. The stack frame may also include other information that is implementation-dependent, such as data to support debugging.","Many instructions in the JVM's instruction set refer to entries in the constant pool. Whenever the JVM encounters any of the instructions that refer to an entry in the constant pool, it uses the frame data's pointer to the constant pool to access that information. References to types, fields and methods in the constant pool are initially symbolic. When the JVM looks up a constant pool entry that refers to a class, interface, field or method, that \u201creference\u201d may still be symbolic. If so, the JVM must resolve the \u201creference\u201d at that time.","The frame data must assist the JVM in processing a normal or abrupt method completion. If a method completes normally by returning, the JVM must restore the stack frame of the invoking method. It must set the pc register to point to the instruction in the invoking method. If the completing method returns a value, the JVM must push that value onto the operand stack of the invoking method.","The frame data must also contain some kind of reference to the method's exception table, which the JVM uses to process any exceptions thrown during the course of execution of the method. An exception table defines ranges within the bytecodes of a method that are protected by catch clauses. Each entry in an exception table gives a starting and ending position of the range protected by a catch clause, an index into the constant pool that gives the exception class being caught, and a starting position of the catch clause's code. When a method throws an exception, the Java virtual machine uses the exception table referred to by the frame data to determine how to handle the exception. If the virtual machine finds a matching catch clause, the method completes abnormally. The virtual machine uses the information in the frame data to restore the invoking method's frame and then rethrows the same exception in the context of the invoking method.","With reference now to , a list describes some of the Java instructions that may be used to manipulate the stack. Although most instructions operate on a particular type, some instructions are generic, typeless instructions. Several opcodes push \u201cint\u201d and \u201cfloat\u201d local variables onto the operand stack. Some opcodes implicitly refer to a commonly used local variable position. For example, \u201cfload_\u201d loads the \u201cfloat\u201d local variable at position one. Instructions for \u201clong\u201d and \u201cdouble\u201d move two words from the local variable section of the stack frame to the operand stack section. Other opcodes push local variables to move object references (which occupy one word) from the local variables section of the stack frame to the operand section. For each opcode that pushes a local variable onto the stack, a corresponding opcode exists that pops the top of the stack back into the local variable. The names of the pop opcodes can be formed from the names of the push opcodes by replacing \u201cload\u201d with \u201cstore.\u201d","The present invention provides a method and apparatus for dynamically compiling a Java method that has been partially executed through interpretation. As noted previously, a mixed-mode interpreter allows a Java method to be interpreted a number of times before it is compiled; it stops a partially interpreted Java method, compiles it, and then resumes execution of the compiled code.","The interpreter of the present invention is a mixed-mode interpreter that attempts to find particular \u201chot spots\u201d that include methods with long-running loops. To improve the performance of methods with long-running loops, essentially non-terminating loops, or infinite loops, a new method is constructed and just-in-time compiled (JITed) that \u201creplaces\u201d the previous, partially executed, interpreted method. The newly constructed method is similar to the previous method because the exact execution state of the running thread is reproduced in the JITed version of the method. However, the new JITed_method has extra code placed at the beginning of the method that recreates the exact execution state of the previous, partially executed, interpreted method. Once the new method is JITed and its execution is initiated, then the method achieves the same execution state as before the interpreter attempted to optimize the \u201chot spot\u201d of the method. One important advantage of the present invention is that it optimizes a \u201chot spot\u201d without changes to the JIT compiler; any other JIT optimizations may still be applied to the new method as well as the original method.","With reference now to , a diagram depicts, in pseudo-bytecode, an example of a Java method that is a candidate for the optimization process of the present invention. Method , named \u201coldMethod\u201d, contains long-running loop . For simplicity, it may be assumed that only one thread is executing method  when the interpreter attempts to JIT the method.","In the interpretation mode, the interpreter maintains an invocation counter for each method that is initialized to some predetermined but possibly variable value. An invocation counter is decremented with each invocation of the method and with each backward branch within the method. A backward branch is any of several Java bytecodes specifying a conditional or unconditional jump, where the destination address (called the target) is lower than the address of the jump instruction itself. Each iteration of loop  contains a backward branch that causes the method's invocation counter to be decremented. At some point in time after long-running loop  has been executed many times, the invocation counter reaches zero. It is determined that loop  is a long-running loop, and method  becomes eligible to be JITed, i.e. the interpreter should stop interpretation and JIT the method. In this case, the interpreter stops interpretation just before interpreting the target of the backward jump, i.e. statement , which is labeled \u201clabel_i.\u201d","At the point at which the interpreter determines to JIT the method containing the long-running loop, the interpreter can be viewed as a state machine that is in some state of execution for the interpreted method. There are four parts to the state of the method: the configuration of operands on its Java stack frame\u2014state variables \u201cS\u201d; the values of its local variables\u2014state variables \u201cV\u201d; the location of the looping label that causes the backward branch\u2014state variable \u201cL\u201d, and any monitors held\u2014state variable \u201cM\u201d. The state of the method may be denoted as methodState(S, V, L, M).","The present invention constructs a new method based on the original method, and the new method has the following execution characteristics: (a) the execution of the new method always reaches the location of the looping label that causes the backward branch; (b) when the execution of the new method first reaches the location of the looping label that causes the backward branch, methodState(S, V, L, M) must be reproduced exactly; and (c) once the new method reaches the location of the looping label that causes the backward branch, the execution flow follows the original bytecode sequence of the original method that was JITed. Each of these requirements is achieved as explained further below.","The current stack frame contains most of the information necessary for constructing the current method's execution state\u2014methodState(S, V, L, M). Among other things, it contains some X operand items (S, S, S, . . . S) and some Y local variables (V, V, V, . . . V). Note that either S, or Vmay contain an object reference, including an array or data of some scalar type, such as boolean, byte, short, char, int, long, float, or double. The format of the new stack frame for the compiled method may be different than the previous stack frame for the interpreted method, but with the previous stack frame and the information in the method itself, the new frame can be constructed.","It should be noted that, in the new frame, all local variables will be method arguments. The method of the present invention is possible given the fact that the JVM is stack-based rather than register-based. Because all of the local variables and all of the method arguments are stored in the method's stack frame, the location of the data within the stack frame may be manipulated to achieve the optimization of JITing a long-running loop.","The JVM treats method arguments similarly to the manner in which it treats local variables within the method. Method arguments are local variables (0, 1, . . . i) in the stack frame, and local variables declared inside the method are numbered (i+1, . . . , y). Hence, if the process of the present invention adds arguments (i+1, . . . , y) to the signature of the newly constructed method and invokes it with the values that the local variables had at the moment that the interpreter stopped interpretation of the original method, the instructions dealing with local variables that were present in the original method can be kept unchanged. In other words, since the stack frame indices for the added arguments of the newly constructed method are identical to the stack frame indices of the local variables for the interpreted method, the instructions within the body of the method that access the local variables do not need to be changed.","The process of adding the previous local variables as arguments to the signature of the newly constructed method provides a mechanism for ensuring that the values of its local variables, state variables \u201cV\u201d in methodState(S, V, L, M), are preserved between the previously interpreted method and the newly constructed method.","With reference now to , a diagram depicts, in pseudo-bytecode, an example of a Java method that replaces a partially executed method that is being optimized by the process of the present invention.  has method , named newMethod, that contains long-running loop . Method  is an example of a method constructed according to the process of the present invention. Method  may replace method  that is being JITed in order to optimize the \u201chot spot\u201d of long-running loop . The newly created method also has the backward jump of the long-running loop, i.e. statement , whose target is \u201clabel_i.\u201d","Method  in  has a signature in which a certain number and type of parameters were passed to the method. The signature of method  has at least the same number and type of parameters as method , but the signature of method  is extended by adding to its argument list all of the local variables in method  that were not arguments originally. Method  is then invoked with the values of the local variables in method  at the time of the suspension of the execution of method , i.e. at the time that the interpreter determined to JIT the previous method.","At the beginning of method , which is the newly constructed method, bytecodes  are added to reproduce exactly the state of the Java stack frame. Bytecode , which is a \u201cgoto\u201d bytecode instruction, is then inserted to jump to \u201clabel_i\u201d, the point at which execution in method , named oldMethod, was stopped. The other original bytecodes from method  follow the newly inserted \u201cgoto\u201d bytecode . The bytecodes following the first \u201cgoto\u201d are identical to those in the original method. Exception ranges may have to be adjusted to account for the extra instructions at the beginning of the method.",{"@attributes":{"id":"P-00086","num":"00086"},"figref":"FIG. 10A"},"In order to reproduce the exact state, i.e. the configuration of the Java stack frame\u2014state variable \u201cS\u201d, of the Java stack frame for the newly constructed method from the previously interpreted method, bytecodes are added at the beginning of the new method to push any other values onto the stack that were present on the stack when the interpreter stopped interpreting the method. Preferably, instructions would be placed into the method that load the appropriate values onto the stack with so-called \u201cimmediate data\u201d, i.e. data that is stored immediately following the instructions that operate on the immediate data. Since there are no bytecodes for directly pushing values other than \u201cchar\u201d and \u201cshort\u201d onto the stack, the signature of the new method is extended in order to pass in the previous method's stack values as arguments. The signature of the newly constructed method comprises: the same parameters as the original method, followed by one argument for each local variable declared in the original method, followed by the values that were on the stack when the interpreter stopped interpretation.","Load instructions of the appropriate type (iload, fload, aload, etc.) push these values onto the stack. If the stack depth was \u201cX\u201d when the interpreter stopped interpreting the original method, then at the beginning of the new method, there will be \u201cX\u201d instructions to push the correct values onto the stack. For example, if the i-th stack entry, S, is of type \u201cint\u201d, then the following bytecode is needed: iload <one of the new parameters>.",{"@attributes":{"id":"P-00089","num":"00089"},"figref":["FIG. 10B","FIG. 10B"],"b":["10","1000","1002","1000","1004","1000","1010","1014"]},"With reference now to , diagrams depict examples of a partially interpreted Java method that is being optimized by the process of the present invention, a newly constructed method, and the stack states at various points during the optimization process. FIG. A depicts the declaration of a method named \u201coldMethod\u201d, which has two parameters and contains a long-running loop that the mixed-mode interpreter of the present invention will attempt to optimize.  depicts the invocation of \u201coldMethod\u201d from a calling method with two example values,  and .  depicts a representative declaration of a method named \u201cnewMethod\u201d that is constructed according to the process of the present invention. In this example, in addition to two parameters, \u201coldMethod\u201d has five local variables, all of type \u201cint\u201d. The constructed method has the same parameters as the previous method that is being optimized plus additional parameters: a parameter for each local variable within the method being optimized, and a parameter for each value that is to be pushed onto the stack. In this example, at the moment the interpreter stops interpreting \u201coldMethod\u201d and starts to construct \u201cnewMethod\u201d, the five local variables have values , , , , and , and that there are three values of type \u201cint\u201d on the JVM stack: ,  and .  shows the invocation of the newly constructed method with values for the parameters that match the values retrieved from the previous stack frame of the method that is being optimized.  shows snapshots of the state of the current stack frame for \u201coldMethod\u201d or \u201cnewMethod\u201d at various points during the optimization process. After the stack values are pushed onto the operand portion of the stack, the locations within the local variables portion of the stack frame become undefined and available for other uses.","The above-described process already provides a mechanism for ensuring that any monitors held in its stack frame\u2014state variables \u201cM\u201d in methodState(S, V, L, M), are preserved between the previous interpreted method and the newly constructed method. Monitors are constructs that provide thread synchronization associated with one or more sections of critical code that need to be executed as one indivisible operation.","If the thread executing the original method held any monitors when the interpreter stopped interpreting it, all of the monitors must be held during the process of generating, compiling and invoking the newly constructed method, lest other threads acquire them and change the state of the object they protect. Nothing else needs to be done in the new method that is constructed. If the thread was inside a synchronized block, execution will jump back inside that block when the JITed method resumes execution, and the monitor will be released when and if execution leaves the block. Similarly, a synchronized method will release its monitor when it exits. When invoking the new method, the process should not try to acquire the monitor, even if the original method was synchronized, because the thread already owns it.","The previously defined requirements, i.e. the requirements for the new method to behave as necessary so that the newly constructed method has an initial state and execution flow as the previous method, have been achieved with the above described process. With respect to the first requirement, after the stack variables have been pushed onto the stack and the \u201cgoto\u201d bytecode has been executed, then the execution of the new method reaches the location of the looping label that is the target of the backward branch. With respect to the second requirement, when the execution of the new method first reaches the location of the looping label that is the target of the backward branch, methodState(S, V, L, M) is reproduced exactly. No bytecodes are executed between the point at which the exact stack state is restored and the point at which the method performs the \u201cgoto\u201d instruction, hence no bytecodes can disturb the state of the stack. With respect to the third requirement, once the new method reaches the location of the looping label that is the target of the backward branch, the execution flow follows the original bytecode sequence of the original method that is being JITed.","After the method is constructed, processing is identical to any other JIT optimization. The newly constructed method may be compiled by invoking the JIT compiler. All other JIT optimizations can be applied on this new method. The current stack frame is first removed. Then the compiled new method is invoked with certain values of the current execution state (local variables and stack items) as the actual parameters. The thread may then be executed.","With reference now to , a flowchart depicts the overall flow of the optimization process for dynamically compiling a partially executed, interpreted method according to the process of the present invention. The process begins when the mixed-mode interpreter within the JVM detects that the current method contains a long-running loop and should be JITed in order to enhance the processing speed of the method (step ). A new method is constructed that is similar to the current method by including the bytecodes of the current method into the newly constructed method (step ). Push bytecodes are then included in the new method for pushing operand values onto the operand portion of the stack frame (step ). A \u201cgoto\u201d bytecode is included in the new method after the inserted push bytecodes with a destination location equal to the entry location of the long-running loop (step ). The signature of the new method is extended to include the local variables of the current method as parameters of the newly constructed method (step ). The signature of the new method is then extended to include the values of the operand portion of the current stack frame (step ). The current stack frame of the current method is removed (step ), and the newly constructed method is JITed (step ). The process ends with the invocation of the newly constructed method as the current method (step ).","It is possible that a method with long-running loops is invoked concurrently by many threads, all of which are in the interpretation mode, i.e. a multithreaded case. At the point in time when the interpreter decides to JIT a method, other threads may be executing the method with a different methodState(S, V, L, M). When the mixed-mode interpreter first JITs the method, a flag associated with the method may be set to indicate that the method has already been JITed. At any point that the interpreter executes a backward branch for the method of another thread, it checks this flag for the method it is interpreting. If the flag is set, the interpreter begins generating a new version of the method specific to this thread's state. The newly constructed method may then be; JITed and invoked without initiating another compilation of the original method, as was done for the first thread. It should be noted that it is not necessary to perform a compilation for each thread that is executing the method at the moment that the process decides to compile. Threads with identical operand stack configurations (same number and same type of values on the stack) and same \u201cgoto\u201d target can use the same compiled version of \u201cnewMethod\u201d because the operand stack configuration and \u201cgoto\u201d target are the only possible differences between the various versions of \u201cnewMethod\u201d.","If a long-running loop occurs in an exception handler, then the approach of the present invention may be difficult to implement. For most applications, such a situation is an \u201cexception.\u201d In such a case, the JVM may simply continue interpretation.","The advantages provided by the present invention should be apparent in light of the detailed description of the invention provided above. The present invention provides a method and apparatus for dynamically compiling a Java method that has been partially executed through interpretation. The purpose of the invention is to improve the performance of methods with long-running loops for which Java virtual machines with a mixed-mode of interpretation and JIT compilation cannot normally achieve adequate performance. The described method takes the following steps.","The first step of the present invention is to recognize methods with long-running loops. One solution is to introduce a counter to each Java method. The counter is initialized to 0 when the Java class containing the method is first loaded into the Java virtual machine. Each time a loop in a method is executed one iteration by the interpreter, the counter associated with the method is incremented by one. Once the counter reaches some predetermined number, e.g., 1,000,000, the process concludes that the method contains at least one long-running loop, and it becomes a candidate for application of the present invention. Those of ordinary skill in the art will appreciate that the method of recognizing methods with long-running loops may vary depending on the implementation.","Once a method is recognized as containing at least one long-running loop, the next step is to halt interpretation on the current thread, preserve the state of the virtual machine, construct a new method, and then compile the new method using the existing JIT compiler. The new method is constructed from the original method with two additions: (1) extra arguments that pass the current state of the virtual machine to the new method; and (2) extra bytecodes added to the beginning of the method to use the extra arguments to reproduce the virtual machine's state. The newly constructed method is then compiled by the JIT compiler. It is important to note that the newly constructed method in the present invention will always satisfy the following conditions: (1) the execution flow always reaches the point at which the interpreter stopped; (2) when the execution flow reaches the stop point, the original state of the virtual machine is exactly reproduced; and (3) once the execution flow reaches the stop point, it follows the original bytecode sequence of the original method.","Next, the current invocation frame of the interpreter is removed, and the new method's JIT compiled code is invoked. Control is then transferred from the interpreter to the JIT compiled code.","The present invention effectively solves the performance problem of methods with long-running loops. In addition, the present invention does not require changes to the JIT compiler; any JIT optimizations may still be applied to the new method as well as to the original method.","Mixed-mode interpreters that attempt to optimize hot spots within a Java program have had the disadvantage of requiring that a method that contains a hot spot must exit before the interpreter may JIT the method and improve its efficiency. The requirement that the method exit before it may be JITed poses a difficulty for methods that may have essentially non-terminating loops, such as loops in a daemon thread. The present invention detects these long-running loops and provides a method for terminating the interpretation of the method and initiating the construction of a new method that, when invoked with the proper parameters, will reach an execution state that is identical to the execution state of the previously, partially interpreted method. The present invention not only improves the performance of an interpreted Java program but also improves its speed on-the-fly.","It is important to note that while the present invention has been described in the context of a fully functioning data processing system, those of ordinary skill in the art will appreciate that the processes of the present invention are capable of being distributed in the form of a computer readable medium of instructions and a variety of forms, and that the present invention applies equally regardless of the particular type of signal bearing media actually used to carry out the distribution. Examples of computer readable media include recordable-type media such as floppy disks, a hard disk drive, RAM, CD-ROMs, and transmission-type media such as digital and analog communications links.","The description of the present invention has been presented for purposes of illustration and description but is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. The embodiment was chosen and described in order to best explain the principles of the invention and the practical application, and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The novel features believed characteristic of the invention are set forth in the appended claims. The invention itself, however, as well as a preferred mode of use, further objectives and advantages thereof, will best be understood by reference to the following detailed description of an illustrative embodiment when read in conjunction with the accompanying drawings, wherein:",{"@attributes":{"id":"P-00016","num":"00016"},"figref":"FIG. 1"},{"@attributes":{"id":"P-00017","num":"00017"},"figref":"FIG. 2"},{"@attributes":{"id":"P-00018","num":"00018"},"figref":"FIG. 3"},{"@attributes":{"id":"P-00019","num":"00019"},"figref":"FIG. 4"},{"@attributes":{"id":"P-00020","num":"00020"},"figref":"FIG. 5"},{"@attributes":{"id":"P-00021","num":"00021"},"figref":"FIGS. 6A-6B"},{"@attributes":{"id":"P-00022","num":"00022"},"figref":"FIGS. 7A-7B"},{"@attributes":{"id":"P-00023","num":"00023"},"figref":"FIG. 8"},{"@attributes":{"id":"P-00024","num":"00024"},"figref":"FIG. 9"},{"@attributes":{"id":"P-00025","num":"00025"},"figref":"FIGS. 10A-10B"},{"@attributes":{"id":"P-00026","num":"00026"},"figref":"FIGS. 11A-11E"},{"@attributes":{"id":"P-00027","num":"00027"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
