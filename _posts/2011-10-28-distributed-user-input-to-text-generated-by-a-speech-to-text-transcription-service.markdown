---
title: Distributed user input to text generated by a speech to text transcription service
abstract: A particular method includes receiving, at a representational state transfer endpoint device, a first user input related to a first speech to text conversion performed by a speech to text transcription service. The method also includes receiving, at the representational state transfer endpoint device, a second user input related to a second speech to text conversion performed by the speech to text transcription service. The method includes processing of the first user input and the second user input at the representational state transfer endpoint device to generate speech to text adjustment information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08930189&OS=08930189&RS=08930189
owner: Microsoft Corporation
number: 08930189
owner_city: Redmond
owner_country: US
publication_date: 20111028
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Interfaces for software used by computing devices, such as personal computers, laptops, tablets, gaming devices, and phones, are increasing usage of speech recognition, and the demand for high quality in automated audio to textual content is also increasing. Machine algorithms have been used for speech to text conversion, but such algorithms often generate text with errors.","A mechanism to utilize crowd sourcing to increase the quality of speech to text transcription is disclosed. In a particular embodiment, a method includes receiving at a representational state transfer (REST) endpoint device a first user input related to a first speech to text conversion performed by a speech to text transcription service, receiving at the REST endpoint device a second user input related to a second speech to text conversion performed by the speech to text transcription service, and processing the first user input and the second user input at the REST endpoint device to generate speech to text adjustment information. Processing at the REST endpoint device enables the use of crowd sourcing (e.g., using input from the first user, the second user and possibly one or more additional users) to improve the speech to text transcription service.","In another aspect, a computer readable storage device includes instructions executable by a computer to receive captured speech data from a plurality of client devices, to convert the captured speech data to text for each of the plurality of client devices, and to send payload data that includes the text to each of the plurality of client devices. The payload data includes at least one attribute that indicates a location of a device that is configured to process user input related to the perceived accuracy of the conversion of the captured speech data to the text.","In another aspect, a computer implemented method includes sending captured speech data to a speech to text transcription service, receiving a payload including text from the speech to text transcription service, displaying the text at a display device of an electronic device, displaying a user interface at the display device, where the user interface enables a user to provide user input regarding the accuracy of the text, receiving the user input and at least one phoneme alternative to the text, and communicating the user input to a remote device. The remote device may be a REST endpoint device. Thus, a method and system of crowd sourcing may improve speech to text transcription results.","Crowd sourcing of quality of speech to text transcription across a diversity of devices, device manufacturers, and carriers provides a method of improving machine algorithms for speech to text transcription. For example, in a particular implementation, when speech to text transcription is performed by an algorithmic process, several attributes may be attached along with transcribed text to a payload. The attributes may include an attribute that indicates that the transcribed text provided was machine translated, an attribute that specifies an acceptable user feedback scale range for voting on a quality of the transcribed text, and an attribute that identifies a representational state transfer (REST) endpoint device where voting on the quality of the text is to be provided. Optionally, the payload can include additional attributes based on user opt-in settings of an initiating device (e.g., a client device from which the transcribed speech was received). The attributes may include a language of a speaker, which may be explicitly collected by an initiating application of the initiating device or may be derived from a base language of an operating system of the initiating device, a current location of the speaker, and a uniform resource locator (URL) for the initiating application.","When the payload is delivered to a client device (e.g., a mobile phone, a television, a computer, a tablet, a gaming device, etc.), the client device can optionally expose a user interface to enable the recipient to vote on the quality of the translation. The interface may be appropriate to the application experience (e.g., the interface may be generated based on a particular application that is executing at the client device) and within constraints identified by a range in the payload.","For example, the user interface may be implemented as three buttons, \u201cGreat\u201d, \u201cClose\u201d or \u201cAwful\u201d. Alternately or in addition, the user interface may be implemented as a set of thumbs up or thumbs down buttons, a slider control that represents a range, or a star rating system. A rating provided by the user may be sent to the URL of the REST endpoint device that was identified as an attribute in the payload. The REST endpoint device can be a centralized service and does not need to be tied to the originator of the initiating application or to the client device. For example, different handset manufacturers may create applications that utilize speech to text translation for mobile devices and that provide user data to the REST endpoint device. The REST endpoint device may be centralized with a particular party (e.g. a third party service) or may be specific to a handset manufacturer or mobile carrier. Ratings provided by each user are used as votes, optionally in combination with source language and\/or user location information, to enhance speech to text translation engines with contextual and geographic data that can aid in more accurate translations, specifically towards regional dialects and accents, emerging language and slang additions, etc. Thus, the REST endpoint device, operating in conjunction with the client device and the speech to text transcription service, enables crowd sourcing to improve speech to text transcription for diverse, potentially unrelated, devices and users.","Referring to , a particular illustrative embodiment of a distributed computer system  is shown. The distributed computer system  includes a server  that provides a speech to text transcription service . The server  may be a computing device executing instructions to provide automated speech to text transcription. The distributed computer system  also includes a computer network  that is coupled to a plurality of client devices, such as a representative first client device  and a representative second client device . The distributed computer system  further includes a server at a representational state transfer (REST) endpoint device . The server at the REST endpoint device  includes rating and phoneme alternatives analysis logic . The first client device  and the second client device  may each be located remotely from the REST endpoint device .","Various components of the distributed computer system  interact to provide speech to text transcription and to continuously, regularly or occasionally improve or tune a speech to text transcription process using crowd sourcing to provide more accurate transcription of speech. To illustrate, as a general overview, the speech to text transcription service  may be implemented by instructions that are executable by a computer to receive captured speech data from a plurality of client devices. The instructions may convert the captured speech data to text for each of the plurality of client devices. The speech to text transcription service  may send payload data that includes the text to each of the plurality of client devices. The payload data may include information that can be used to tune or train an algorithm used by the speech to text transcription service  to transcribe the speech. For example, the payload data may include one or more attributes that indicate a location of a computer device, such as the server at the REST endpoint device , that is configured to process user input related to accuracy of the transcription. The payload data may also include one or more attributes that facilitate gathering of the user input, such as a rating scale range. The user input may be sent to the REST endpoint device . User input from the client devices may include information indicating a quality or accuracy of the speech to text transcription, alternate transcription information (e.g., phoneme alternatives), information about the user (e.g., user location, client device type, etc.), and\/or other information.","The REST endpoint device  may use the user input to determine adjustments (e.g., speech to text adjustment information ) to tune or train the speech to text transcription service . The REST endpoint device  may also provide other information to the speech to text transcription service  to facilitate speech to text transcription. For example, the REST endpoint device  may generate speaker profiles for users of the distributed computing system . The speaker profiles may be used to further adjust or improve the speech to text transcription by enabling the speech to text transcription service to account for factors such as geographic location and other characteristics of a particular user. The distributed computing system  may also send information to a third party crowd sourcing for phoneme evaluation system  to gather additional information that may be used to adjust or improve the speech to text transcription. Thus, the distributed computing system  may enable continuous or occasional adjustment and tuning of speech to text transcription even when components of the distributed computing system  are unrelated (e.g., are provided by unrelated or distinct business entities).","Each of the client devices ,  may include computer instructions executable by a processor to perform computer implemented methods. For example, a computer implemented method may include capturing speech provided by a user and sending corresponding captured speech data ,  to the speech to text transcription service . For example, first speech  may be captured by the first client device  and corresponding captured speech data  may be communicated via the network  to the speech to text transcription service . In a particular embodiment, the first client device  includes an application , such as a search engine or a mobile application, that may display text or that may receive speech input from the first user .","The computer implemented method may further include receiving a payload, such as the first payload , that includes text from the speech to text transcription service . The method may further include displaying text at a display device of an electronic device. For example, text from the first payload  may be displayed at a display device of the first client device . The first client device  may further display a user interface that prompts the first user  to provide input related to the displayed text. For example, the user interface  may prompt the first user  to provide the first user input . The first user input  may include information regarding the accuracy of the displayed text with respect to the captured speech data  corresponding to the first speech . The computer implemented method may also include receiving user input that may include at least one phoneme alternative to the text. User input data, such as the first user input , may be communicated to a remote device, such as to the REST endpoint device .","The first client device  and the second client device  may be the same type of device or may be different types of devices. For example, the first and second client devices ,  may be mobile phones, televisions, computers, gaming devices, tablets, or other electronic devices that includes a display for displaying images and text. In a particular embodiment, the first client device  selectively displays the user interface . For example, the first client device  may selectively launch the user interface  upon receiving the first payload . Alternatively, an application  may receive a plurality of data payloads and may selectively launch the user interface  when a certain amount of text has been generated and received via multiple payloads  or at a different time as determined by the application . To illustrate, the application  may collect multiple transcribed words corresponding to a complete sentence prior to launching the user interface  to present a display of the complete sentence.","The user interface  may gather user ratings or feedback regarding text received from the speech to text transcription service . For example, the user interface  may display visual expressions that are used to gather the user ratings. Examples of such visual expressions include a thumbs up\/thumb down icon, a slider, a scale of 1-10, or another rating display that may be visually presented to the first user  to receive user input. The user rating may be provided via the user interface  as binary ratings, a range of ratings, or a set of selectable ratings (e.g., more than two selectable ratings). An example of a binary rating is a thumbs up or thumbs down indicator. A range of ratings may be a range from 1-10 or other similar ranges. A set of selectable ratings may be a defined set such that a user may select specific values such as 1, 2, 3, 4, or 5, or a number of stars or other indicators. The user interface  may optionally also include alternative transcription selections or an input field for a user to enter text. The first client device  is responsive to speech  from the first user  and is also responsive to the first user input  to the user interface  that may be provided by the first user .","Similarly, the second client device  may include a second application  and a second user interface . The second client device  may interact with the second user  who provides second speech  and second input . The second input  may indicate the second user's rating of text received via a second payload  from the speech to text transcription service .","During operation, the first client device  receives the first speech  from the first user  and captures the first speech . Data corresponding to the first speech  is communicated as first captured speech data  via the network  to the speech to text transcription service . Similarly, the second client device  may capture the second speech  and communicate data corresponding to the second speech  as second captured speech data  via the network  to the speech to text transcription service . In response to receiving the captured speech data , , the speech to text transcription service  at the server  transcribes the captured speech of the first user  and the second user  and generates text. The server  may communicate the first payload  that includes transcribed text and other attributes via the network  to the first client device . Similarly, the server  may communicate the second payload  that includes transcribed text and attributes via the network  to the second client device . The attributes of each payload ,  may include a scale range of user input, a REST endpoint identification, other attributes (e.g., a language, a location, or a uniform resource locator (URL) of an application to be executed at a client device), or a combination thereof.","In response to receiving the first payload , the first client device  may display the transcribed text carried by the first payload . The first user  may provide the first user input  to the user interface  in response to the text displayed at the first client device . The first user input  may indicate user feedback regarding the quality or accuracy of the transcribed text that corresponds to the first captured speech data .","The first user  may interact with the first client device  to provide the first user input  in response to the displayed text. For example, the first user  may enter the first user input  via the user interface  in response to display of the transcribed text from the first payload . More specifically, the first user  may indicate feedback by providing a rating of the transcribed text, such as by using a thumbs up or thumbs down indicator, a slider indicator, a scale of 1-10 (e.g. where 1 is poor transcription and 10 is excellent transcription) or another alternate designator indicating accuracy or quality of the transcription. The user interface  may also enable the first user  to indicate an alternative transcription corresponding to the first captured speech data  or a portion of the first captured speech data . To illustrate, the user input  may include a selection or text entered into a text field of the user interface . For example, the first user  may type in a correct word or multiple words of a phrase that accurately corresponds to the first captured speech data .","The first client device  may communicate the first input  as the first user input data  to the server at the REST endpoint device . For example, the first user input data  may include rating and phoneme alternative transcription information. The server at the REST endpoint device  may be identified by one of the attributes within the first payload . Thus, for each speech to text transcription performed by the speech to text transcription service , a user of a client device may provide input, such as rating information and\/or phoneme alternatives, and the input may be captured and communicated to the server at the REST endpoint device . In a similar manner, the second user  may provide second input  via the second user interface , and the second input  may be captured and communicated as second user input data  to the server at the REST endpoint device .","While only the first and second client devices ,  have been shown, it should be understood that a variety of different types of client devices and a plurality of devices (e.g. more than two devices) may be used. Such devices may be coupled to the network , may have access to the speech to text transcription service , and may provide user input that is captured and distributed to the server at the REST endpoint device . Thus, the distributed computer system  may enable crowd sourcing to improve speech to text transcription.","The REST endpoint device  may perform rating analysis on a plurality of user ratings based on user input data received from a plurality of client devices. The rating analysis may receive input information that includes a plurality of REST compliant user votes (e.g., ratings associated with transcribed text), source language information, and user location information. For example, the REST endpoint device  may receive the first user input data  that is related to a first speech to text transcription performed by the speech to text transcription service  and the second user input data  related to a second speech to text transcription performed by the speech to text transcription service  and may perform ratings analysis based on the user input data , .","In a particular embodiment, the ratings analysis is performed by the rating and phoneme alternatives analysis logic  of the server at the REST endpoint device , which processes the first user input data  and the second user input data  in order to generate speech to text adjustment information . For example, the rating analysis may include a weighted computation based on information received via the user input data , , such as ratings associated with particular speech to text transcriptions, user location information, user identification information, and other information. In a particular embodiment, the REST endpoint device  collects user identification information of a particular user (such as the first user ) and generates a speaker profile. The speaker profile may also include information related to context and\/or geography of the user or client device (e.g., a geographic location of the first client device ). The speaker profile may be used by the rating and phoneme alternatives analysis logic  to generate the speech to text adjustment information . Additionally or in the alternative, the speaker profile may be communicated as part of the speech to text adjustment information  to the speech to text transcription service  to further refine or tune speech to text transcription performed by the speech to text transcription service  for the particular user. The speech to text adjustment information  may be dependent on a particular speaker profile.","The speech to text adjustment information  may be communicated to the speech to text transcription service  of the server . The speech to text adjustment information  may include information to adjust or tune a speech to text transcription algorithm used by the speech to text transcription service .","The REST endpoint device  may be implemented by a computing device coupled to the network . The REST endpoint device  may be located remote from the server  or the REST endpoint device  and the server  may be co-located. Thus, the speech to text adjustment information  may be communicated from the REST endpoint device  to the server  either via the network  or via an alternative connection between the REST endpoint device  and the server .","The network  may optionally provide access to a third party crowd sourcing phoneme evaluation system . Information from the third party crowd sourcing phoneme evaluation system  may be communicated to the speech to text transcription service  in order to improve the quality of the speech to text transcription. Alternately, or in addition, the information from the third party crowd sourcing phoneme evaluation system  may be communicated to the REST endpoint device  and may be used to determine the speech to text adjustment information .","In a particular illustrative embodiment, the speech to text transcription service  is a multi-tenant service that provides different speech to text transcription applications on behalf of multiple entities. Alternatively, the speech to text transcription service  may be a single machine transcription software program from a single entity. The attributes of the payloads (e.g., the first payload  and the second payload ) sent by the speech to text transcription service  to client devices (e.g., the first client device  and the second client device ) may include an identifier of the REST endpoint device . The client devices ,  may use the identifier to determine a location or address of the REST endpoint device  so that the user input data (e.g., the first and second user input data , ) may be sent to the REST endpoint device . Thus, user input data that can be used to tune the speech to text transcription algorithm used by the speech to text transcription service  can be provided to the REST endpoint device  even by client devices that are not associated with the REST endpoint device .","In a particular embodiment, the first speech  and the second speech  may refer to the same spoken word or words and the speech to text transcription service  may convert such speech to common text. In another embodiment, due to differences between the speech  and , the speech to text transcription service  may convert the same spoken word or words to different texts. The speech to text transcription service  may receive a variety of speech input and may be adjusted responsive to the speech to text adjustment information  in order to improve machine text transcription from such speech input.","In a particular embodiment, the first payload  includes a first identifier that correlates to the speech to text transcription of the first speech  and the second payload  includes a second identifier that correlates to the speech to text transcription of the second speech . The first identifier of the first payload  may be the same as the second identifier of the second payload . For example, the identifier may indicate a particular word or phrase transcribed from the speech data , . Thus, when the first speech  and the second speech  include the same word or phrase, the first identifier and the second identifier may be the same. Alternatively, the first identifier may be different from the second identifier. The first application  may send the first identifier to the REST endpoint device  with the first user data . The REST endpoint device  may determine the speech to text adjustment information  based on the first user input  and may send the speech to text adjustment information  associated with the first user input  along with the first identifier to the speech to text transcription service . Thus, the speech to text transcription service  can correlate user feedback and speech to text adjustment information  associated with the first captured speech data  to text transcription using the first identifier. Likewise, the second application  may send the second identifier to the REST endpoint device  with the second user input data . The REST endpoint device  may determine the speech to text adjustment information  based on the second user input data  and may send the speech to text adjustment information  associated with the second user input data  along with the second identifier to the speech to text transcription service . Thus, the speech to text transcription service  can correlate user feedback and speech to text adjustment information  associated with the second captured speech data  to text transcription using the second identifier. Using the identifiers, the speech to text transcription service  is able to receive feedback from the client devices ,  regarding particular speech to text transcriptions performed by the speech to text transcription service , even when the client devices or other aspects of the system , such as the ratings and phoneme alternatives analysis logic , are not associated with or provided by the speech to text transcription service  (i.e., are associated with third-parties, unrelated entities or other service providers).","Service providers, device manufacturers, software providers, and other business entities may participate in the distributed computer system  to receive a higher quality product that is influenced directly by customers. Application manufacturers (receivers) may participate in the distributed computer system , for example, to provide improved speech to text transcription capability to improve user experience. End users may be encouraged to participate to receive benefit from more accurate speech to text transcription.","Referring to , a particular illustrative embodiment of a computer system  is shown. The computer system  includes the rating and phoneme alternatives analysis logic  of the REST endpoint device . The rating and phoneme alternatives analysis logic  includes processing logic to perform a weighted analysis  for speech to text transcription. The weighted analysis  may receive transcription service input , user input , source language input , user location information input , or a combination thereof. In a particular embodiment, the weighted analysis  receives each of the inputs -; however, in other embodiments the weighted analysis  receives fewer than all of the inputs -. For example, the weighted analysis  may only receive the user input  without receiving other information. The transcription service input  may include one or more words that are generated by a speech to text transcription service, such as the speech to text transcription service  of . The user input  may include one or more of the user input data ,  of  and\/or other user input of other devices (not shown). In a particular embodiment, the user input  includes user rating information related to particular speech to text transcriptions. The user input  may optionally include alternative transcriptions suggestions, such as alternative phonemes, or specific text input by a user. The source language input  may indicate a language of the speech. The user location information input  may include geographic information associated with a source of each user input  (e.g., a location of a particular user). The weighted analysis  may correspond to a particular correlation identifier that is associated with a particular transcription performed by the speech to text transcription service . The correlation identifier may be provided by the speech to text transcription service  when particular transcribed text is provided to a client device to enable the client device to provide the speech to text transcription service  feedback associated with the particular transcribed text.","In a particular embodiment, the rating and phoneme alternatives analysis logic  includes a speaker profile generation module . The speaker profile generation module  may include instructions that are executable by a computing device to generate a speaker profile for one or more users. For example, when particular user input is received, the particular user input may include or be associated with a speaker profile identifier. The speaker profile identifier may be used to indicate user input received from a particular user. The user input received from the particular user over a period of time may be collected and analyzed in order to generate a speaker profile of the particular user.","The weighted analysis  performed by the ratings and phoneme alternatives analysis logic  may be used to adjust or tune the speech to text transcription service . For example, the rating and phoneme alternatives analysis logic  may generate the speech to text adjustment information . The speech to text adjustment information  may include information related to the speaker profile generated by the speaker profile generation module . Examples of speech to text adjustment information  may include suggested alternative transcriptions of speech based on user inputs of multiple users that provide feedback regarding accuracy of a transcription of the speech to text transcription service . The rating and phoneme alternatives analysis logic  may also retrieve transcription service data including alternatives and confidence scores via a database . The database  may provide information associated with speech to text transcription performed by the speech to text transcription service . For example, each transcribed word or words, and alternatives with corresponding confidence scores, may be stored within the database . The weighted analysis , in response to the user input  and in response to other inputs, may consider the alternatives and confidence scores from the database  in order to provide the speech to text adjustment information  that may be used to enhance or improve accuracy of the speech to text transcription service .","The weighted analysis  uses a number of inputs to determine the order (confidence) of suggested matches for any given phrase. These inputs include, but are not limited to, the confidence output by the speech to text transcription service , responses\/judgments from individual users, tuning parameters passed in from or associated with a speaker profile, or manual overrides by a \u201csuper user.\u201d","By default, the confidence is based on the confidence output by the speech to text transcription service . The weighted analysis  also uses a ranked list of alternative transcriptions, both for individual words and phrases if available, ranked in confidence order. When correction data is supplied from a user of the system , data may be weighted based on the nature of the correction (thumbs up\/down, 1-5 stars, alternative word\/phrase, etc.) and the historical reliability of the user. For each user provided judgment\/response, the system's confidence in a particular word or phrase may be altered, possibly leading to the next alternative becoming the highest confidence\/preferred selection. How much weight the system gives to an individual user's responses can be determined using historical input, including how often their responses agree with responses by other users, how long the user has been using the system, etc.","The weightings can be represented as a multiplier assigned to a particular user's vote. System operators can also assign a higher weighting to known and\/or vetted users (e.g. professional staff assigned to review and correct results) so that their responses or approval of another user's suggested corrections are more heavily weighted and have a higher impact when being used to compare responses with other users in order to assign confidence values to those users. The system  can also support the capability to prevent a particular user's judgments (i.e. the speaker him\/herself) from being automatically over-ridden and\/or to require manual approval before promoting an alternative over their selection. Thus, the weighted analysis  may consider a variety of factors in order to select or adjust a particular word or phrase.","Referring to , a particular illustrative embodiment of a computer implemented method  is shown. The computer implemented method  may be performed by a computing device, such as the server  of . The computer implemented method  includes receiving captured speech data from a plurality of client devices, at . For example, the speech to text transcription service  of  may receive the captured speech data ,  from the client devices , , respectively. The computer implemented method  may further include converting the captured speech data to text for each of the client devices, at . For example, the speech to text transcription service  of  may convert the captured speech data ,  to text using one or more speech to text machine transcription methods or algorithms. The computer implemented method  further includes sending payload data that includes the text to each of the client devices, at . The payload data may also include at least one attribute related to analysis of user input regarding accuracy of the conversion of the captured speech data to the text. The payload data may also include a location (e.g., a communication address or a network address) of a computer device (such as the REST endpoint device  of ). For example, the speech to text transcription service  of  may generate the first payload  and the second payload , and each payload ,  may include text and attributes. The attributes may include, for example, an address or other data specifying a location of the REST endpoint device . The speech to text transcription service  may receive captured speech from a plurality of different client devices and may generate corresponding text. The text and attributes may be distributed to the client devices. The attributes may include an identifier of a particular remote device to perform subsequent processing of user feedback related to the accuracy of the text generated by the speech to text transcription service . Thus, the computer implemented method  enables crowd sourcing to improve speech to text transcription.","Referring to , a particular illustrative embodiment of a computer implemented method  is shown. The computer implemented method  may be performed by a client device, such as either of the client devices ,  of . The computer implemented method  includes sending captured speech data to a speech to text transcription service, at , and receiving a payload including text from the speech to text transcription service, at . The payload may also include a locator of a remote device (e.g., an address of a device that gathers user feedback regarding speech to text transcription). The computer implemented method  further includes displaying the text at a display device of an electronic device (e.g., a display device of the client device), at , and displaying a user interface at the display device, at . The user interface may enable the user to provide user input regarding the accuracy of the text transcription of the captured speech. For example, the user interface may prompt the user to rate the accuracy of the text. The user interface may also enable the user to provide an alternative transcription of the text or a portion of the text (e.g., to suggest one or more phoneme alternative transcriptions). The computer implemented method  further includes receiving the user input via the user interface, at , and communicating the user input to the remote device, at . For example, the first client device  of  may send the captured speech data  to the speech to text transcription service . The first client device  may receive the first payload  from the speech to text transcription service . The first payload  may include the transcribed text and a locator (e.g., an address) of the REST endpoint device . The first client device  may display the text from the first payload  and may display the user interface . The first client device  may receive the first user input  via the user interface  and may communicate the first user input data  derived from the first user input  to the server at the REST endpoint device .","Thus, the computer implemented method  may enable a client device to receive text from a speech to text transcription service and to provide user input in response to the text via an interactive user interface. The interactive user interface may be used to prompt and receive feedback from a user regarding accuracy of the text generated by the speech to text transcription service . Thus, the computer implemented method  enables use of crowd sourcing to improve speech to text transcription.","Referring to , a particular illustrative embodiment of a portion  of a user interface that may be displayed at a client device is shown. For example, the portion  of the user interface may be a portion of the user interface  of , which may be presented at a display device of the first client device . The portion  of the user interface may include a first view  that includes transcribed text received from a speech to text transcription service in response to speech data. In the example illustrated in , the transcribed text is, \u201cAs I was saying, this cumquat is terrible.\u201d The first view  may also include a user selectable option to provide feedback regarding a quality or accuracy of the transcribed text relative to the speech data. For example, the user selectable option may include a thumbs up and a thumbs down indicator. In the example illustrated in , the speech data included the sentence, \u201cAs I was saying, this caption is terrible.\u201d Thus, the user of the interface may indicate a low rating of the text corresponding to the input speech by selecting the thumbs down indicator as shown at a second view . When the user provides negative feedback, e.g., by selecting the thumbs down indicator, the user interface may enable the user to indicate whether a single word or multiple words of the transcribed text are deemed to be incorrect.","For the case of a single incorrect word, a revised view  may be presented. The revised view  may be used to highlight a particular word that has been transcribed incorrectly. Upon selecting the particular word as shown by the revised view , an updated view  may be displayed. The updated view  may include user options to provide an alternate word to replace the highlighted word. For example, the updated view  may include a dropdown menu that lists alternative transcriptions for the highlighted word. In another example, the updated view  may include another user interface field to receive input to correct the highlighted word, such as a text entry field. To illustrate, for the selected word \u201ccumquat\u201d a plurality of selections may be shown, such as the selections \u201ccaption,\u201d and \u201ccaptain,\u201d and\/or a blank text field where a user may enter his or her own alternative word. Upon selection of one of the presented alternatives or upon the user inputting text, a second revised view  may be displayed. The second revised view  displays revised transcribed text, such as \u201cAs I was saying, this caption is terrible.\u201d The user may indicate acceptance of the revised transcribed text by selecting a thumbs up indicator. Feedback may be provided to the user to indicate that the revised transcribed text has been received. For example, in response to the user selecting the thumbs up indicator, a positive icon may be shown, such as a \u201csmiley face\u201d as illustrated in the second revised view . Alternately, when the user provided input indicates that the revised transcribed text is not correct (e.g., by selecting the thumbs down icon), the user interface may again prompt the user to highlight a word to be changed, for example, by returning to the revised view  displaying the revised transcribed text.","In a scenario where multiple words are indicated or selected to be revised or displayed, a view  may be presented. The view  may display multiple alternate words, such as alternate phrases or sentences. As shown at view , the user may select (or enter text) indicating that an entire phrase or sentence is to be replaced with an alternative phrase or sentence. In response to user input indicating the alternative phrase or sentence, the second revised view  is presented. Thus, a user may interact with the user interface in order to view transcribed text corresponding to prior speech input and to provide feedback or other user input with respect to the quality or accuracy of the transcribed text as compared to the speech input.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 6","b":["600","610"]},"The computing device  includes at least one processor  and a system memory . Depending on a configuration and type of the computing device , the system memory  may be volatile (such as random access memory or \u201cRAM\u201d), non-volatile (such as read-only memory or \u201cROM,\u201d flash memory, and similar memory devices that maintain stored data even when power is not provided), or some combination of the two. The system memory  typically includes an operating system , one or more application platforms , one or more applications , and program data . The system memory  may also include a speech to text transcription application  and a payload generation application . In an illustrative embodiment, the speech to text transcription application , the payload generation application , or any combination thereof, may include instructions that are executable by the processor(s)  to perform the functions and methods disclosed herein. For example, functionality of the server  of  may be performed by the applications  and  or by the operating system . Alternatively or in addition, the computing device  may be used to implement the functions of the REST endpoint device  and the functions of the rating and phoneme alternatives analysis logic  of . The computing device  may also be used to implement any of the computer implemented methods or computing devices disclosed herein, such as the methods illustrated in . In this case, the applications ,  would be replaced by client device applications. The computing device  may also be used to implement or display one or more of the user interfaces disclosed herein, such as the user interfaces illustrated in .","The computing device  may also have additional features or functionality. For example, the computing device  may include removable and\/or non-removable additional data storage devices, such as magnetic disks, optical disks, tape devices, and standard-sized or flash memory cards. Such additional storage is illustrated in  by removable storage  and non-removable storage . Computer storage media may include volatile and\/or non-volatile storage and removable and\/or non-removable media implemented in any technology for storage of information such as computer-readable instructions, data structures, program components or other data. The system memory , the removable storage  and the non-removable storage  are all examples of computer storage media. The computer storage media includes, but is not limited to, RAM, ROM, electrically erasable programmable read-only memory (EEPROM), flash memory or other memory technology, compact disks (CD), digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium that can be used to store information that can be accessed by the computing device . Any such computer storage media may be part of the computing device .","The computing device  may also have input device(s) , such as a keyboard, a mouse, a pen, a voice input device, a touch input device, a motion or gesture input device, etc, connected via one or more wired or wireless input interfaces. In an illustrative embodiment, the input device(s)  may receive user input, such as the user input ,  of . Output device(s) , such as a display, speakers, printer, etc. may also be connected via one or more wired or wireless output interfaces. The output devices  may include one or more display devices. For example, a display device may be associated with any of the client devices ,  of .","The computing device  also includes one or more communication connections  that allow the computing device  to communicate with other computing devices  over a wired or a wireless network, such as the network  of .","The illustrations of the embodiments described herein are intended to provide a general understanding of the structure of the various embodiments. The illustrations are not intended to serve as a complete description of all of the elements and features of apparatus and systems that utilize the structures or methods described herein. Many other embodiments may be apparent to those of skill in the art upon reviewing the disclosure. Other embodiments may be utilized and derived from the disclosure, such that structural and logical substitutions and changes may be made without departing from the scope of the disclosure. Accordingly, the disclosure and the figures are to be regarded as illustrative rather than restrictive.","Those of skill would further appreciate that the various illustrative logical blocks, configurations, modules, and process steps or instructions described in connection with the embodiments disclosed herein may be implemented as electronic hardware or computer software. Various illustrative components, blocks, configurations, modules, or steps have been described generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application, but such implementation decisions should not be interpreted as causing a departure from the scope of the present disclosure.","The steps of a method described in connection with the embodiments disclosed herein may be embodied directly in hardware, in a software module executed by a processor, or in a combination of the two. A software module may reside in computer readable media, such as random access memory (RAM), flash memory, read only memory (ROM), registers, a hard disk, a removable disk, a CD-ROM, or any other form of storage medium known in the art. An exemplary storage medium is coupled to a processor such that the processor can read information from, and write information to, the storage medium. In the alternative, the storage medium may be integral to the processor or the processor and the storage medium may reside as discrete components in a computing device or computer system.","Although specific embodiments have been illustrated and described herein, it should be appreciated that any subsequent arrangement designed to achieve the same or similar purpose may be substituted for the specific embodiments shown. This disclosure is intended to cover any and all subsequent adaptations or variations of various embodiments.","The Abstract of the Disclosure is provided with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition, in the foregoing Detailed Description, various features may be grouped together or described in a single embodiment for the purpose of streamlining the disclosure. This disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather, as the following claims reflect, inventive subject matter may be directed to less than all of the features of any of the disclosed embodiments.","Although the subject matter has been described in language specific to structural features and\/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as example forms of implementing the claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
