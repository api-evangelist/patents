---
title: Enhanced input using touch screen
abstract: Provided are methods and systems for enhanced input using a touch screen, as well as computer programs encoded on computer storage devices and configured to perform the actions of the methods. One or more applications executing on a mobile device receive a user input through the touch screen of the mobile device, without displaying information identifying a command associated with the user input on the touch screen. The one or more applications then determine the command associated with the received user input and display a result of applying the command on an external display that is connected to the mobile device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08363009&OS=08363009&RS=08363009
owner: Google Inc.
number: 08363009
owner_city: Mountain View
owner_country: US
publication_date: 20110930
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application is a continuation of U.S. application Ser. No. 13\/154,853, filed Jun. 7, 2011, and claims the benefit of U.S. Pat. App. No. 61\/428,324, filed Dec. 30, 2010, both of which are incorporated herein by reference.","Mobile devices, such as smart phones, personal digital assistants (PDAs), and other mobile computing devices, typically include a touch screen, through which the user of the mobile device can provide input, and through which the mobile device can display information to the user. Commonly, a single touch screen is used to input information to, and output information from, the mobile device. Because mobile devices are sized so as to be portable, the touch screen is typically small compared to display devices such as televisions and computer monitors. As such, the amount of information that can be displayed on the touch screen of a mobile device is limited.","According to one general implementation, a user may input commands to a mobile device that is connected to an external display using the touch screen of the mobile device. The touch screen itself may not display information, e.g., icons or text, identifying the command that is being input. Rather, the command may be inferred by the nature of the input itself, such as when a gesture associated with the input suggests that a user intends to scroll or fling a screen object, or the command may be associated with a region of the touch screen through which the input is provided.","In one aspect, one or more applications executing on a mobile device receive a user input through the touch screen of the mobile device, without displaying information identifying a command associated with the user input on the touch screen. The one or more applications then determine the command associated with the received user input and display a result of applying the command on an external display that is connected to the mobile device.","These and other embodiments may each optionally include one or more of the following features. For instance, in some embodiments the one or more applications display nothing on the touch screen when the user input is received. In other embodiments, when the user input is received, the one or more applications display information on the touch screen other than information identifying the command that is being input, but display nothing in the region of the touch screen with which the user interacted.","In some embodiments, determining the command associated with the user input involves the identification, by the one or more applications, of additional information. For instance, in some embodiments, before receiving the user input, the one or more applications define one or more input regions within the touch screen. The one or more applications then identify an input region associated with the user input and determine the command associated with the identified input region. In some embodiments, the one or more applications identify a gesture associated with the user input and determine the command associated with the identified gesture. In other embodiments, the one or more applications identify a state of the application and determine the command associated with the state.","In some embodiments, the command is a navigation control command, a gaming control command, or a media control command.","Other embodiments of these aspects include corresponding systems, apparatus, and computer programs, configured to perform the actions of the methods, encoded on computer storage devices.","The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other potential features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.","Like reference numbers and designations in the various drawings indicate like elements.",{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1","b":["100","101","103","101","103","102","101","103","102","102"]},"Mobile device  may be a smartphone, or any other appropriate computer device. Generally speaking, a smartphone is a mobile device that offers advanced computing capabilities, such as the ability to execute applications and to communicate with other computing devices and with peripheral devices such as external display . Mobile device  may include a computer-readable medium  for storing data  and computer programs such as application , and a processing device  (e.g., a microprocessor) and memory  (e.g., RAM) for executing computer programs. A touch screen  displays, to a user, information and images that are generated by mobile device . The touch screen  is touch-sensitive, enabling a user to provide input by interacting with various regions of the screen. For example, a user may provide input via a virtual keyboard or by input regions defined by applications executing on the mobile device.","In addition, mobile device  may include other input\/output devices . For example, a physical QWERTY keyboard and\/or a scroll wheel may be provided for user input. Mobile device  may also include an audio output device . Mobile device , and computer applications executed thereon, may also be configured to accept commands through other input mechanisms, such as voice commands, and to perform functions in response to such commands.","Mobile device  runs an operating system . Computer programs, including applications, are stored, e.g., in computer-readable medium , and execute on top of the operating system. Among these computer programs is application , which may interface with other applications of the mobile device. Application  may be, e.g., a navigation application, a gaming application, or a media application. Although application  is depicted and described as a single application, application  may be one or more applications configured to perform the processes described herein. The information involved in the processes described herein may be stored as data  on computer-readable medium  of the mobile device.","When executed on mobile device , application  receives user input through touch screen  of the mobile device, without displaying information identifying a command associated with the user input on the touch screen. For example, in some implementations the application is configured such that, when the user input is received, nothing is displayed by the application on the touch screen. In other implementations, the application is configured such that, when the user input is received, nothing is displayed by the application in the region of the touch screen with which the user has interacted.","The nature of the user input, e.g., the gesture used to effect the input or the location through which the input is received, may be suggestive to the user of the command, thereby eliminating the need to display information identifying the command on the touch screen. For instance, the user may intuitively touch the right side of a screen to invoke a \u201cfast forward\u201d command when a media player application is playing, or touch the center of the touch screen to \u201cpause\u201d a slide show. In either case, the application receiving the command does not need to display information identifying the command on the touch screen itself.","After receiving user input, application  identifies a command associated with the received input, applies the command, and displays a result of applying the command on external display . For example, when executed on the mobile device , application  may define one or more input regions within the touch screen . Having defined input regions within the touch screen, the application may identify an input region associated with the user input when the user input is received, and may determine the command associated with the identified input region. In , e.g., application  has defined five regions within touch screen  of mobile device . These are input regions , , , , and .","Upon receiving user input and identifying an associated input region, application  may reference data , stored within computer-readable medium  of mobile device , in order to determine the command associated with the identified input region. For example, application  may reference command table , included within data . Command table  specifies media control commands associated with five regions: 1, 2, 3, 4, and 5. These regions may correspond to, e.g., , , , , and , respectively. In determining the command associated with received user input, application  may further identify a gesture associated with the user input. Command table  includes gestures that may be associated with user input: tap, swipe up, swipe down, swipe left, and swipe right. Application  may further identify a state of the application , and determining the command based on the received user input may further comprise determining the command associated with the state.","After determining the command, application  applies the command, and displays the result of applying the command on external device , which is connected to mobile device , e.g., through network . For instance, the application  inputs the command to itself (or to another application), causing the application  (or the other application) to display a user interface in a subsequent state on the external device .",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 2","FIG. 2"],"b":["210","220","230","240","250","260","101","211","221","231","241","251","261","103"]},"In more detail, at state (I), depicted by conceptual views  and , media player application  receives a user input through touch screen  of mobile device , without displaying information identifying a \u201cpause\u201d command associated with the user input on touch screen . Before receiving the user input, media application  defined five input regions within the touch screen: , , , , and . Application  identifies an input region associated with the user input, in this case input region . Application  also identifies a gesture associated with the user input, in this case a tap. Application  further identifies a state of application .","As illustrated by conceptual view , at state (I) media player application  is playing \u201csong 1.\u201d After identifying the input region, gesture, and state, application  selects the command associated with the user input with reference to command table , included in data  stored in computer-readable medium  of mobile device . As illustrated by command table  in , the media control command associated with a user input in the form of a tap gesture received in region  while application  is playing a song is \u201cPause.\u201d As such, application  determines that the command associated with the received user input is \u201cPause.\u201d Before transitioning to state (II), application  applies the \u201cPause\u201d command by inputting or otherwise applying a \u201cpause\u201d signal.","At state (II), application  displays the result of applying the \u201cPause\u201d command on external display , as depicted by conceptual view . Also, at state (II), media player application  receives an additional user input through touch screen  of mobile device , without displaying information identifying a command associated with the user input on touch screen . Application  identifies an input region associated with the user input, in this case input region . Application  also identifies a gesture associated with the user input, in this case a tap. Application  further identifies a state of application .","As illustrated by conceptual view , at state (II) media player application  is paused at song 1. After identifying the input region, gesture, and state, application  determines the command associated with the user input with reference to command table . As illustrated by command table  in , the media control command associated with a user input in the form of a tap gesture received in region  is \u201cNext Song.\u201d As such, application  determines that the command associated with the received user input is \u201cNext Song.\u201d Before transitioning to state (III), application  applies the \u201cNext Song\u201d command.","At state (III), application  displays the result of applying the \u201cNext Song\u201d command on external display , as depicted by conceptual view . Also, at state (III), media player application  receives an additional user input through touch screen  of mobile device , without displaying information identifying a command associated with the user input on touch screen . Application  identifies an input region associated with the user input, in this case input region . Application  also identifies a gesture associated with the user input, in this case a tap. Application  further identifies a state of application .","As illustrated by conceptual view , at state (III) media player application  is paused at song 2. After identifying the input region, gesture, and state, application  determines the command associated with the user input with reference to command table . As illustrated by command table  in , the media control command associated with a user input in the form of a tap gesture received in region  while application  is playing a song is \u201cPlay.\u201d As such, application  determines that the command associated with the received user input is \u201cPlay.\u201d Before transitioning to state (IV), application  applies the \u201cPlay\u201d command.","At state (IV), application  displays the result of applying the \u201cPlay\u201d command on external display , as depicted by conceptual view . Also, at state (IV), media player application  receives an additional user input through touch screen  of mobile device , without displaying information identifying a command associated with the user input on touch screen . Application  identifies an input region associated with the user input, in this case input region . Application  also identifies a gesture associated with the user input, in this case a swipe to the left. Application  further identifies a state of application .","As illustrated by conceptual view , at state (IV) media player application  is nearly finished playing song 2. After identifying the input region, gesture, and state, application  determines the command associated with the user input with reference to command table . As illustrated by command table  in , the media control command associated with a user input in the form of a swipe left gesture received in region  is \u201cRewind.\u201d As such, application  determines that the command associated with the received user input is \u201cRewind.\u201d Before transitioning to state (V), application  applies the \u201cRewind\u201d command.","At state (V), application  displays the result of applying the \u201cRewind\u201d command on external display , as depicted by conceptual view . Also, at state (V), media player application  receives an additional user input through touch screen  of mobile device , without displaying information identifying a command associated with the user input on touch screen . Application  identifies an input region associated with the user input, in this case input region . Application  also identifies a gesture associated with the user input, in this case an upward swipe. Application  further identifies a state of application .","As illustrated by conceptual view , at state (V) media player application  is playing song 2 at a low volume. After identifying the input region, gesture, and state, application  determines the command associated with the user input with reference to command table . As illustrated by command table  in , the media control command associated with a user input in the form of a swipe up gesture received in region  is \u201cIncrease Volume.\u201d As such, application  determines that the command associated with the received user input is \u201cIncrease Volume.\u201d Before transitioning to state (V), application  applies the \u201cIncrease Volume\u201d command.","At state (VI), application  displays the result of applying the \u201cIncrease Volume\u201d command on external display , as depicted by conceptual view .","In the preceding examples, illustrated by the conceptual views of , application  is a media player application, and the commands associated with received user input are the media control commands of command table . However, other implementations are possible.","For example, in one implementation, application  may be a gaming application, and the commands associated with received user inputs may be gaming control commands. In a different implementation, application  may be a navigation application, and the commands associated with received user inputs may be navigation control commands.  illustrates additional command tables that can be included in data  stored in computer-readable medium  of mobile device . Command table  contains gaming control commands, and command table  contains navigation control commands.","In an implementation in which application  is a gaming application, it could receive a user input through touch screen  of mobile device , without displaying information identifying a command associated with the user input on touch screen . Gaming application  could then reference command table  in order to determine a gaming control command associated with the received user input and could then display the result of applying the gaming control command on external display device .","In an implementation in which application  is a navigation application, it could receive a user input through touch screen  of mobile device , without displaying information identifying a command associated with the user input on touch screen . Navigation application  could then reference command table  in order to determine a navigation control command associated with the received user input and could then display the result of applying the navigation control command on external display device .","In a different implementation, application  may be a display application that interacts with other applications stored in computer-readable medium  of mobile device , or on other computing devices accessible to mobile device  through network . Display application  could interact with these other applications using an Application Programming Interface (API).","For example, display application , executing on mobile device , could receive user input through touch screen  of the mobile device without displaying information identifying a command associated with the user input on touch screen . Application  could then identify that, in its current state, it is interacting with a media player application. Having identified that it is interacting with a media player application, external display application  could then determine a command associated with that state, and with the received user input, by referencing the media control commands of command table . If application  had instead identified that it was interacting with a gaming application, it could determine a command associated with that state, and with the received user input, by instead referencing the gaming control commands of command table . Finally, if application  had identified that it was interacting with a navigation application, it could determine a command associated with that state, and with the received user input, by referencing the navigation control commands of command table . Having determined a command associated with its state and with the received user input, display application  could then display a result of applying the command on external display , connected to mobile device  through network .","A person having ordinary skill in the art will recognize, however, that these examples are not limiting, and that display application  could interact with any number of other applications stored in computer-readable medium  of mobile device  or accessible to mobile device  through network .",{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIG. 2","FIG. 4","FIG. 4"],"b":["110","105","101","110","105","407","408","409","410","411","412","110","105"]},"For example, in an implementation in which application  is a media player application executing on mobile device , the application  receives a user input through touch screen , without displaying information identifying a command associated with the user input, during each of example states (VII)-(XII). However, application  may display other information on touch screen  when it receives user input.","At state (VII), illustrated by conceptual view , application  defines four user input regions within touch screen  of mobile device : , , , and . Application  displays borders around these regions, without identifying a command associated with the user input, when it receives user input. In state (VIII), illustrated by conceptual view , application  defines four regions within touch screen , , , , and , but displays nothing on touch screen  when it receives user input. In state (IX), illustrated by conceptual view , application  defines a single user input region within the touch screen , , and displays a border around that region along with a background image when it receives user input. However, application  displays nothing within the region , the region with which the user interacted.","In state (X), illustrated by conceptual view , application  displays the text \u201cMEDIA PLAYER\u201d and \u201cPRESS CENTER\u201d on touch screen  when it receives user input. In state (XI), illustrated by conceptual view , application  defines a single user input region , and displays a border around that region along with the text \u201cMEDIA PLAYER\u201d when it receives user input. Finally, at state (XII), illustrated by conceptual view , application  defines a single user input region , and displays a border around that region along with the text \u201cSWIPE REGION\u201d when it receives user input.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 5","b":["500","100","110","101","102","110","108","101"]},"Referring to , application  executing on mobile device  receives user input through touch screen , without displaying information identifying a command associated with the user input on the touch screen (). Before receiving the user input, application  may define one or more input regions within touch screen . After receiving the user input, application  determines a command associated with the received user input (). Before determining the command, application  may identify an input region associated with the user input, may identify a gesture associated with the user input, or may identify a state of application . In determining the command associated with the received user input, application  may determine the command associated with the identified input region, gesture, or state. Following the determination, application  displays a result of applying the determined command on external display , which is connected to mobile device  ().",{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 6","b":["600","650","600","650"]},"Computing device  includes a processor , memory , a storage device , a high-speed interface  connecting to memory  and high-speed expansion ports , and a low speed interface  connecting to low speed bus  and storage device . Each of the components , , , , , and , are interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate. The processor  can process instructions for execution within the computing device , including instructions stored in the memory  or on the storage device  to display graphical information for a GUI on an external input\/output device, such as display  coupled to high speed interface . In other implementations, multiple processors and\/or multiple buses may be used, as appropriate, along with multiple memories and types of memory. Also, multiple computing devices  may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).","The memory  stores information within the computing device . In one implementation, the memory  is a volatile memory unit or units. In another implementation, the memory  is a non-volatile memory unit or units. The memory  may also be another form of computer-readable medium, such as a magnetic or optical disk.","The storage device  is capable of providing mass storage for the computing device . In one implementation, the storage device  may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations. A computer program product can be tangibly embodied in an information carrier. The computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above. The information carrier may be a non-transitory computer- or machine-readable medium, such as the memory , the storage device , memory on processor , or a propagated signal. For example, the information carrier may be a non-transitory, machine-readable storage medium.","The high speed controller  manages bandwidth-intensive operations for the computing device , while the low speed controller  manages lower bandwidth-intensive operations. Such allocation of functions is exemplary only. In one implementation, the high-speed controller  is coupled to memory , display  (e.g., through a graphics processor or accelerator), and to high-speed expansion ports , which may accept various expansion cards (not shown). In the implementation, low-speed controller  is coupled to storage device  and low-speed expansion port . The low-speed expansion port, which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input\/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.","The computing device  may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server , or multiple times in a group of such servers. It may also be implemented as part of a rack server system . In addition, it may be implemented in a personal computer such as a laptop computer . Alternatively, components from computing device  may be combined with other components in a mobile device (not shown), such as device . Each of such devices may contain one or more of computing device , , and an entire system may be made up of multiple computing devices ,  communicating with each other.","Computing device  includes a processor , memory , an input\/output device such as a display , a communication interface , and a transceiver , among other components. The device  may also be provided with a storage device, such as a microdrive or other device, to provide additional storage. Each of the components , , , , , and , are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.","The processor  can execute instructions within the computing device , including instructions stored in the memory . The processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. The processor may provide, for example, for coordination of the other components of the device , such as control of user interfaces, applications run by device , and wireless communication by device .","Processor  may communicate with a user through control interface  and display interface  coupled to a display . The display  may be, for example, a TFT LCD (Thin-Film-Transistor Liquid Crystal Display) or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology. The display interface  may comprise appropriate circuitry for driving the display  to present graphical and other information to a user. The control interface  may receive commands from a user and convert them for submission to the processor . In addition, an external interface  may be provide in communication with processor , so as to enable near area communication of device  with other devices. External interface  may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used.","The memory  stores information within the computing device . The memory  can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units. Expansion memory  may also be provided and connected to device  through expansion interface , which may include, for example, a SIMM (Single In Line Memory Module) card interface. Such expansion memory  may provide extra storage space for device , or may also store applications or other information for device . Specifically, expansion memory  may include instructions to carry out or supplement the processes described above, and may include secure information also. Thus, for example, expansion memory  may be provide as a security module for device , and may be programmed with instructions that permit secure use of device . In addition, secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a manner that is not modifiable by the end-user.","The memory may include, for example, flash memory and\/or NVRAM memory, as discussed below. In one implementation, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as the memory , expansion memory , memory on processor , or a propagated signal that may be received, for example, over transceiver  or external interface .","Device  may communicate wirelessly through communication interface , which may include digital signal processing circuitry where necessary. Communication interface  may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver . In addition, short-range communication may occur, such as using a Bluetooth, Wi-Fi, or other such transceiver (not shown). In addition, GPS (Global Positioning System) receiver module  may provide additional navigation- and location-related wireless data to device , which may be used as appropriate by applications running on device .","Device  may also communicate audibly using audio codec , which may receive spoken information from a user and convert it to usable digital information. Audio codec  may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device .","The computing device  may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone . It may also be implemented as part of a smartphone , personal digital assistant, or other similar mobile device.","Various implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and\/or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and\/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.","These computer programs (also known as programs, software, software applications or code) include machine instructions for a programmable processor, and can be implemented in a high-level procedural and\/or object-oriented programming language, and\/or in assembly\/machine language. As used herein, the terms \u201cmachine-readable medium\u201d \u201ccomputer-readable medium\u201d refers to any computer program product, apparatus and\/or device (e.g., magnetic discs, optical disks, memory, Programmable Logic Devices (PLDs)) used to provide machine instructions and\/or data to a programmable processor, including a machine-readable medium that receives machine instructions as a machine-readable signal. The term \u201cmachine-readable signal\u201d refers to any signal used to provide machine instructions and\/or data to a programmable processor.","To provide for interaction with a user, the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.","The systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (\u201cLAN\u201d), a wide area network (\u201cWAN\u201d), and the Internet.","The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.","A number of implementations have been described. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure.","In addition, the logic flows depicted in the figures do not require the particular order shown, or sequential order, to achieve desirable results. In addition, other steps may be provided, or steps may be eliminated, from the described flows, and other components may be added to, or removed from, the described systems. Accordingly, other implementations are within the scope of the following claims.","Elements of different implementations described herein may be combined to form other implementations not specifically set forth above. Elements may be left out of the processes, computer programs, Web pages, etc. described herein without adversely affecting their operation. Furthermore, various separate elements may be combined into one or more individual elements to perform the functions described herein.","Other implementations not specifically described herein are also within the scope of the following claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
