---
title: System and method for rendering a particle-based fluid surface
abstract: A method for rendering a particle-based fluid surface includes generating a depth image of a plurality of particles which form a fluid surface, and smoothing the depth image to generate a smoothed depth image. From the smoothed depth image, a smoothed surface position and a smoothed surface normal for each of a plurality of pixels included within the smoothed depth image is determined, and a shaded surface of the fluid is rendered as a function of the smoothed surface positions and the smoothed surface normals.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08947430&OS=08947430&RS=08947430
owner: NVIDIA Corporation
number: 08947430
owner_city: Santa Clara
owner_country: US
publication_date: 20100226
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS"],"p":["The present invention relates generally to systems and methods for graphics rendering, and more particularly to a system and method for rendering a particle-based fluid surface.","For interactive scenes, particle-based fluid simulation methods like Smoothed-Particle Hydrodynamics (or SPH) are commonly preferred to grid-based fluid simulation methods. Particle-based fluid representation permits fluid flow throughout the scene without the need to define a grid over the scene area, which would be costly in memory and computation. It is also more convenient to integrate into existing physics infrastructure, as particles can collide against the scene geometry just like other objects.","However, a drawback with particle-based fluid simulation is it is difficult to extract a surface for rendering. In some conventional techniques, the fluid surface is constructed in world-space, either as a mesh directly or as an implicit surface, and then polygonized using Marching Cubes or other similar methods. After this, relaxation and optimization operations can be applied to the entire mesh to reduce the bumpiness of the surface, which is computationally and memory intensive.","Likewise, implicit surface polygonization methods also suffer from grid discretization artifacts in frame-to-frame coherence, as the grid is static and does not move with the fluid. This is especially visible at low-resolution grids, whereas using high-resolution grids can prohibit real-time visualizations, because evaluating the metaball densities at each grid point is expensive. For acceptable visual quality, the grid must be much finer than the particle spacing. The need for a fixed grid also restricts the fluid to a box, whereas not having this restriction is one of the reasons for choosing particle-based fluid surface rendering.","Accordingly, a new particle-based fluid surface rendering technique is needed to overcome the aforementioned disadvantages.","The present invention provides an improved technique for rendering particle-based fluid surfaces. Among the embodiments of the present invention, a method for rendering a particle-based fluid surface is included, this method including generating a depth image of a plurality of particles which form a fluid surface, and smoothing the depth image to generate a smoothed depth image. From the smoothed depth image, a smoothed surface position and a smoothed surface normal for each of a plurality of pixels included within the smoothed depth image is determined, and a shaded surface of the fluid is rendered as a function of the smoothed surface positions and the smoothed surface normals.","These and other aspects of the invention will be better understood in light of the following drawings and detailed description of exemplary embodiments.","For clarity, previously-defined features retain their reference indicia in subsequent drawings.",{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1","b":["100","102","104","106","108"]},"Exemplary embodiments of operations ,  and  are further described below. Exemplary of operation , scene data residing view-wise behind the fluid surface is written to a buffer\/render target where it is stored as a background image for use in operation . The background image, referred to as S(x,y) as described herein, can be used to determine the color of the fluid surface, depending upon, e.g., the color and thickness of the fluid surface, as described below. Further particularly, the texture coordinates used to sample the background image may be perturbed based upon the normal n of the fluid surface in order to give the illusion of refracting the object behind the fluid. These and other aspects of the background image are described in greater detail below.","Image of the Fluid Surface",{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 2","FIG. 1"],"b":["102","202"],"sub":["i ","i","i ","i "]},"Depth Image","At , a depth image of the fluid surface (e.g., a depth map) is generated and stored in a buffer (render target). In one embodiment, a depth image of the fluid surface is generated, whereby the near-most (view-wise) surface of the fluid is determined, and the particles along that surface are rendered with a corresponding a depth\/z-value. For example, the aforementioned SPH algorithm may be employed to determine the positions of the particles, and those particles may then be splatted onto the screen. A render target for the surface depth is initialized with a predefined depth value representing a very large depth (i.e., furthest most surface). For each pixel, the depth value for the near-most particle is retained, with the current depth value being overwritten by a depth value corresponding to a particle which is closer to the camera\/view point. After the particles are rendered, the render target will contain the depth to the viewer of the nearest particle for each pixel in the viewport.","The particles identified in operation  may be rendered as spheres, or alternatively, as \u201cpoint sprites\u201d, a feature that is provided by OpenGL, Direct3D and other 3D graphics application programming interfaces. As used herein, a point sprite refers to a screen-oriented quad. Further particularly, the depth\/z-value of the point sprite is varied within the fragment shader according to the equation:\n\n()=\u221a{square root over (1\u2212)}\u2003\u2003eq. (1)\n\nwhere x and y varies between unit values \u22121 and +1 over a two dimensional screen space position of the particle and d(x,y) is the depth value of the particle output from the fragment shader. The size of the point sprite is computed by applying projective transformation, so that the size is constant in world-space. Rendering the particles as point sprites requires significantly less computation with little degradation in the quality of the computation compared to rendering the particles as geometrically-correct spheres. When a particle is rendered as a point sprite, the corresponding depth\/z-value of the point sprite is according to the equation:\n",{"@attributes":{"id":"p-0024","num":"0023"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mrow":[{"mover":{"munder":{"mi":"min","mrow":{"mi":"i","mo":"=","mn":"0"}},"mi":"n"},"mo":"\u2062","msub":{"mi":["z","i"]}},{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":[{"mrow":{"mi":"x","mo":"-","msub":{"mi":["x","i"]}},"msub":{"mi":["\u03c3","i"]}},{"mrow":{"mi":"y","mo":"-","msub":{"mi":["y","i"]}},"msub":{"mi":["\u03c3","i"]}}],"mo":","}}}],"mo":"+"}],"mo":"="}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"2"}}}]}}}},"br":{},"sub":["i","i ","i ","i "]},"Optionally, stray particles may be excluded from rendering, as they do not form part of the fluid surface. This effect can be accomplished by applying a threshold on the density \u03c1obtained from the simulation, and rendering the low density particles separately from the fluid surface as spray to make the transition smoother.","Smoothed Depth Image","Operation  represents a process, whereby the depth image of the fluid surface generated in operation  is smoothed. Smoothing the depth image of the fluid surface hides the spherical nature of the particles so that the surface does not appear unnaturally blobby or jelly-like. In one embodiment of this process, the smoothing operation includes Gaussian filtering, whereby a convolution of a Gaussian kernel is applied to the depth image provided in eq. (2). In such an embodiment, blending over silhouettes is minimized, and the amount of smoothing is varied as a function of the particle depth. Further exemplary, the kernel is substantially constant in width in world space. Further particular, bilateral Gaussian filtering is implemented, which, e.g., may be split into two one-dimensional passes.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 3","b":["206","204"]},"According to the method , at  a normal is computed for each pixel included in the depth image generated at . At , a mean curvature value is computed at each of the pixels, and at , the depth of the pixel is varied as a function of the mean curvature value corresponding to said pixel.","Exemplary of operation , a normal for each pixel of the fluid surface image is computed, whereby a projection transformation of a pixel is inverted to map a value in the depth buffer to a point P in view space, where Vand Vare the dimensions of the viewport, and Fand Fis the focal length in x and y direction, respectively:",{"@attributes":{"id":"p-0030","num":"0029"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mfrac":{"mrow":{"mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"x"},"msub":{"mi":["V","x"]}},"mo":"-","mn":"1.0"},"msub":{"mi":["F","x"]}}}},{"mtd":{"mfrac":{"mrow":{"mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"y"},"msub":{"mi":["V","y"]}},"mo":"-","mn":"1.0"},"msub":{"mi":["F","x"]}}}},{"mtd":{"mn":"1"}}]}},{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}],"mo":"\u2062"}],"mo":"="}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"3"}}}]}}}}},"The normal is calculated by taking cross product between the derivatives of P in x and y direction.",{"@attributes":{"id":"p-0032","num":"0031"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"n","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mrow":[{"mfrac":[{"mrow":[{"mo":"\u2202","mi":"P"},{"mo":"\u2202","mi":"x"}]},{"mrow":[{"mo":"\u2202","mi":"P"},{"mo":"\u2202","mi":"y"}]}],"mo":"\u00d7"},{"mrow":[{"mrow":[{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"msub":{"mi":["C","x"]},"mo":"\u2062","mi":"z"},{"msub":{"mi":["W","x"]},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]}}],"mo":"+"}}},{"mtd":{"mrow":{"msub":{"mi":["W","y"]},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]}}}},{"mtd":{"mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]}}}]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":["W","x"]},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]}}}},{"mtd":{"mrow":{"mrow":[{"msub":{"mi":["C","y"]},"mo":"\u2062","mi":"z"},{"msub":{"mi":["W","y"]},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"y"}]}}],"mo":"+"}}},{"mtd":{"mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]}}}]}}],"mo":"\u00d7"},{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":["C","x"]},"mo":"\u2062","mi":"z"}}},{"mtd":{"mn":"0"}},{"mtd":{"mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]}}}]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mn":"0"}},{"mtd":{"mrow":{"msub":{"mi":["C","y"]},"mo":"\u2062","mi":"z"}}},{"mtd":{"mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"y"}]}}}]}}],"mo":"\u00d7"}],"mo":"\u2248"},{"mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mo":"-","msub":{"mi":["C","x"]}},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]}}}},{"mtd":{"mrow":{"mrow":{"mo":"-","msub":{"mi":["C","y"]}},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"y"}]}}}},{"mtd":{"mrow":{"msub":[{"mi":["C","x"]},{"mi":["C","y"]}],"mo":["\u2062","\u2062"],"mi":"Z"}}}]}},"mo":"\u2062","mi":"z"}],"mo":"="}],"mo":"="}],"mo":"="}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"4"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0033","num":"0032"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["C","x"]},"mo":"=","mfrac":{"mn":"2","mrow":{"msub":[{"mi":["V","x"]},{"mi":["F","x"]}],"mo":"\u2062"}}},{"msub":{"mi":["C","y"]},"mo":"=","mfrac":{"mn":"2","mrow":{"msub":[{"mi":["V","y"]},{"mi":["F","y"]}],"mo":"\u2062"}}},{"msub":{"mi":["W","x"]},"mo":"=","mfrac":{"mrow":{"mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"x"},"msub":{"mi":["V","x"]}},"mo":"-","mn":"1.0"},"msub":{"mi":["F","x"]}}},{"msub":{"mi":["W","y"]},"mo":"=","mfrac":{"mrow":{"mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"y"},"msub":{"mi":["V","y"]}},"mo":"-","mn":"1.0"},"msub":{"mi":["F","y"]}}}],"mo":[",",",",","]}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"5"}}}]}}}}},"The terms of the derivatives of P that depend on the view position Wand Wmay be ignored because this assumption results in almost no visual difference in rendering, and simplifies the following computations significantly. By normalizing n(x,y), the unit normal is obtained:",{"@attributes":{"id":"p-0035","num":"0034"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mover":{"mi":"n","mo":"^"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mfrac":[{"mrow":[{"mi":"n","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mo":["\uf603","\uf604"],"mrow":{"mi":"n","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}]},{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mrow":{"mo":"-","msub":{"mi":["C","x"]}},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]}},{"msub":[{"mi":["C","y"]},{"mi":["C","x"]},{"mi":["C","y"]}],"mo":["\u2062","\u2062","\u2062","\u2062"],"mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"y"}]},"mi":"z"}],"mo":"-"}},"mi":"T"},"msqrt":{"mrow":{"mrow":[{"msubsup":{"mi":["C","x"],"mn":"2"},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","msup":{"mi":"z","mn":"2"}},{"mo":"\u2202","mi":"x"}]}},{"msubsup":{"mi":["C","y"],"mn":"2"},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","msup":{"mi":"z","mn":"2"}},{"mo":"\u2202","mi":"y"}]}},{"msubsup":[{"mi":["C","x"],"mn":"2"},{"mi":["C","y"],"mn":"2"}],"mo":["\u2062","\u2062"],"msup":{"mi":"z","mn":"2"}}],"mo":["+","+"]}}}],"mo":"="}],"mo":"="}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"6"}}}]}}}}},"Exemplary of operation , the mean curvature H is defined as the divergence of the unit normal of a surface:\n\n2\u2003\u2003eq. (7)\n","The z component of the divergence is zero, as z is a function of x and y, and thus doesn't change when these are kept constant.",{"@attributes":{"id":"p-0038","num":"0037"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mn":"2","mo":"\u2062","mi":"H"},{"mrow":{"mfrac":[{"mrow":[{"mo":"\u2202","msub":{"mover":{"mi":"n","mo":"^"},"mi":"x"}},{"mo":"\u2202","mi":"x"}]},{"mrow":[{"mo":"\u2202","msub":{"mover":{"mi":"n","mo":"^"},"mi":"y"}},{"mo":"\u2202","mi":"y"}]}],"mo":"+"},"mo":"=","mfrac":{"mrow":{"mrow":[{"msub":[{"mi":["C","x"]},{"mi":["E","x"]}],"mo":"\u2062"},{"msub":[{"mi":["C","y"]},{"mi":["E","y"]}],"mo":"\u2062"}],"mo":"+"},"msup":{"mi":"D","mfrac":{"mn":["3","2"]}}}}],"mo":"="}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"8"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0039","num":"0038"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"4.4em","height":"4.4ex"}}},"mo":"\u2062","mrow":{"mrow":{"mi":"D","mo":"=","mrow":{"mrow":[{"msubsup":{"mi":["C","x"],"mn":"2"},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","msup":{"mi":"z","mn":"2"}},{"mo":"\u2202","mi":"x"}]}},{"msubsup":{"mi":["C","y"],"mn":"2"},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","msup":{"mi":"z","mn":"2"}},{"mo":"\u2202","mi":"y"}]}},{"msubsup":[{"mi":["C","x"],"mn":"2"},{"mi":["C","y"],"mn":"2"}],"mo":["\u2062","\u2062"],"msup":{"mi":"z","mn":"2"}}],"mo":["+","+"]}},"mo":","}}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"9"}}}]},{"mtd":[{"mrow":{"msub":{"mi":["E","x"]},"mo":"=","mrow":{"mrow":[{"mrow":{"mo":"-","mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","msup":{"mi":"x","mn":"2"}}]}},"mo":"\u2062","mi":"D"},{"mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msubsup":{"mi":["C","x"],"mn":"2"},"mo":["\u2062","\u2062"],"mfrac":[{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]},{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","msup":{"mi":"x","mn":"2"}}]}]},{"msubsup":{"mi":["C","y"],"mn":"2"},"mo":["\u2062","\u2062"],"mfrac":[{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"y"}]},{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","msup":{"mi":"y","mn":"2"}}]}]},{"msubsup":[{"mi":["C","x"],"mn":"2"},{"mi":["C","y"],"mn":"2"}],"mo":["\u2062","\u2062","\u2062"],"mi":"z","mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]}}],"mo":["+","+"]}}}],"mo":"+"}}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"10"}}}]}]}}},"br":{}},{"@attributes":{"id":"p-0040","num":"0039"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["E","y"]},"mo":"=","mrow":{"mrow":[{"mrow":{"mo":"-","mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","msup":{"mi":"y","mn":"2"}}]}},"mo":"\u2062","mi":"D"},{"mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"y"}]},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msubsup":{"mi":["C","x"],"mn":"2"},"mo":["\u2062","\u2062"],"mfrac":[{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"x"}]},{"mrow":[{"mo":"\u2202","mi":"z"},{"mrow":[{"mo":"\u2202","mi":"x"},{"mo":"\u2202","mi":"y"}],"mo":"\u2062"}]}]},{"msubsup":{"mi":["C","y"],"mn":"2"},"mo":["\u2062","\u2062"],"mfrac":[{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"y"}]},{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","msup":{"mi":"y","mn":"2"}}]}]},{"msubsup":[{"mi":["C","x"],"mn":"2"},{"mi":["C","y"],"mn":"2"}],"mo":["\u2062","\u2062","\u2062"],"mi":"z","mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"y"}]}}],"mo":["+","+"]}}}],"mo":"+"}}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"11"}}}]}}}}},"Exemplary of operation , the smoothing of the depth image is performed by varying the depth\/z-value of the pixels in proportion to the local pixel's mean curvature H:",{"@attributes":{"id":"p-0042","num":"0041"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":{"mrow":[{"mo":"\u2202","mi":"z"},{"mo":"\u2202","mi":"t"}]},"mo":"=","mi":"H"}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"12"}}}]}}}},"br":{}},"The foregoing operations ,  and  may be repeated an arbitrary number of times depending on the smoothness that is desired, wherein the obtained depth\/z-value is successively modified to provide a smoother depth image. The number of iterations and smoothness obtained can be balanced against the cost of increased computation time for the added iterations.","The depth\/z-values computed according to the foregoing are written to a render target (the collective depth\/z-values referred to as the smoothed depth image) as an intermediate result for forming a final image of the fluid in operation . In a particular embodiment, the render target used to store the depth image (eq. 2) is also used as the render target for the smoothed depth image, whereby the nearer\/closer (view-wise) depth\/z-values computed from the aforementioned smoothing operations overwrite the depth\/z-values of the depth image.","Further exemplary of operation , from the smoothed depth image, a smoothed surface position and a smoothed surface normal are determined for one or more pixels included within the smoothed depth image. The smoothed surface position for a pixel can be ascertained from the depth image d(x,y) of the particles included within the screen space of that pixel by back-projecting the pixel coordinates (x,y) and its depth d(x,y). The smoothed surface normal n for a pixel can be determined by computing, for a particle which is overlaid by the pixel, the partial derivatives of the particle in the x and y directions, and computing the cross-product of the partial derivatives to compute the smoothed surface normal, as per eq. (6). When discontinuities occur in the fluid surface, using the finite differences in only one direction can result in artifacts along the silhouettes. When the difference in depth is greater than a predefined threshold, that is when a discontinuity is detected, the smallest absolute finite difference is chosen in an exemplary embodiment. For example, the smallest of the quantities |z(x,y)\u2212z(x+1,y)| and |z(x,y)\u2212z(x\u22121,y)| is chosen.","Fluid Thickness","Operation  optionally includes computing a \u201cthickness value\u201d per pixel for the fluid surface image generated in operation  and modifying the fluid surface image based upon the thickness values of the pixels composing the fluid surface image. For example, the thickness values may be used to model the changes in the visibility or color of a background image over which the fluid is shown to flow.","Exemplary of this operation, the particles (identified in operation ) are rendered as spheres using point sprites with a fixed size in world space. Depth test is enabled such that only particles in front of the scene geometry are rendered. The thickness value of a depth image pixel, the depth image pixel corresponding to a given particle, is computed according to the equation:",{"@attributes":{"id":"p-0048","num":"0047"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"T","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"0"},"mi":"n"},"mo":"\u2062","mrow":{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":[{"mrow":{"mi":"x","mo":"-","msub":{"mi":["x","i"]}},"msub":{"mi":["\u03c3","i"]}},{"mrow":{"mi":"y","mo":"-","msub":{"mi":["y","i"]}},"msub":{"mi":["\u03c3","i"]}}],"mo":","}}}}],"mo":"="}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"13"}}}]}}}},"br":[{},{}],"sup":["2","2"],"sub":["i ","i ","i "],"b":"102"},"Exemplary, the noise texture in operation  may be generated using Perlin noise. In Perlin noise, a fractal noise texture is generated by adding multiple octaves of filter noise, where each octave is a filtered random function, and scales the amplitude and frequency with a factor dependent on the octave,",{"@attributes":{"id":"p-0050","num":"0049"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"fnoise","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"p"}},{"munderover":{"mo":"\u2211","mrow":[{"mi":"i","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"msup":{"mi":["\u03b1","i"]},"mo":"\u2062","mrow":{"mi":"noise","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msup":{"mn":"2","mi":"i"},"mo":"\u2062","mi":"p"}}}}}],"mo":"="}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"14"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 4","b":["104","402","102","404","204","206"]},"Exemplary of operation , a point sprite is rendered with a Gaussian kernel to generate a point sprite value, and the point sprite value is multiplied by an exponent value, the exponent value based upon the depth of the particle below the fluid surface. For example, the noise kernel I(x,y) generated at  may be computed as:\n\n()=noise()\u2003\u2003eq. (15)\n\nwhere noise (x,y) is the Gaussian kernel, quantity p is the view space position of the particular pixel, quantity d represents the depth\/z-value of the particle as sampled from the surface depth texture computed in eq. (1), and quantities x and y vary between \u22121 and +1. Further particularly, the noise texture is varied per particle to prevent patterns from becoming visibly apparent. A three-dimensional noise texture may be used for this, with the first two dimensions based on the position within the particle, and the third dimension based upon the particle identifier.\n","Exemplary of operation , the noise kernel in eq. (15) is summed for every particle on the screen to provide the noise texture N(x,y) for the fluid surface image:",{"@attributes":{"id":"p-0054","num":"0053"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"0"},"mi":"n"},"mo":"\u2062","mrow":{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":[{"mrow":{"mi":"x","mo":"-","msub":{"mi":["x","i"]}},"msub":{"mi":["\u03c3","i"]}},{"mrow":{"mi":"y","mo":"-","msub":{"mi":["y","i"]}},"msub":{"mi":["\u03c3","i"]}}],"mo":","}}}}],"mo":"="}},{"mrow":{"mi":"eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"16"}}}]}}}},"br":{},"sub":["i ","i ","i "]},"Further exemplary of operation , the noise texture is generated such that the fluid surface appears more turbulent when the flow is fast or violent. This may be achieved by marking particles of the fluid surface image when a large change in velocity occurs. In particular, the velocity of a particle may be determined, and the amplitude of the noise texture for the particle is modulated based upon the particle's velocity. For example, particles may be marked, when the velocity vparticles change by more than a threshold value:\n\n|()\u2212(1)|>\u03c4\u2003\u2003eq. (17)\n\nwhere \u03c4 is a threshold value. Above this change, the amplitude of the noise kernel in eq. (15) is varied (e.g., increased) to provide more pronounced fluid turbulence. Once the change in the particle's velocity falls below this threshold, the amplitude of the noise kernel may be reduced to provide the effect of less fluid turbulence. Of course, three or more different amplitude levels may be employed to provide different noise effects of the fluid surface image ranging from very still to extremely turbulent.\n\nFluid Surface Rendering\n","Referring again to , operation  may be performed by combining the fluid surface image, noise texture, and background image to form an image of the fluid surface, which may be rendered, e.g., as a full screen quad.","In one embodiment, the fluid surface image may be a depth image of the fluid surface or a smoothed version thereof, each as described above. Further exemplary, thickness values assigned to pixels of the fluid surface image may be used to modify visible properties of the fluid surface image. For example, the output color and transparency\/opacity of the fluid surface may be based determined as a function of fluid thickness values. In a specific embodiment described below, the fluid surface image includes (i) a smoothed depth image to avoid a blobby or jelly-like fluid appearance, and (ii) fluid thickness values which permit additional control over rendering the fluid surface color as a function of the thickness of the fluid and other parameters as described below.","In a detailed implementation of operation , depth test is enabled when rendering the fluid surface image, and the depth returned by the fragment shader is read from the depth buffer produced when rendering the fluid surface image. This ensures that only particles in front of the scene geometry are rendered.","Normals of the fluid surface image in view-space n are calculated to shade the surface of the fluid, starting from the surface depth d(x,y). Further particularly, finite differences are used to calculate the partial derivatives in the x and y directions, then the normal is derived by taking the cross product of these (as per eq. (6)). When discontinuities occur in the fluid surface, using the finite differences in only one direction can result in artifacts along the silhouettes. When the difference in depth is greater than a predefined threshold, that is when a discontinuity is detected, the smallest absolute finite difference is chosen in an exemplary embodiment. For example, the smallest of the quantities |z(x,y)\u2212z(x+1,y)| and |z(x,y)\u2212z(x\u22121,y)| is chosen.","The noise texture N(x,y) is used to perturb the normals to add small, wave-like surface detail to the fluid, by adding the partial derivatives of N(x,y) to the calculated normals. In particular, the noise texture N(x,y) is used to modulate the normals of pixels which form the depth (or smoothed depth) image, thereby imparting a noisy or irregular appearance to the fluid surface. Further exemplary, a grayish color is added to the surface of the fluid to simulate a surface foam effect as a function of the magnitude of the noise N(x,y).","In a further exemplary embodiment, the thickness value T(x,y) is used to attenuate the refracted color of the fluid a, according to the equation:\n\n=lerp((),)\u2003\u2003eq. (18)\n\nwherein Cis the color of the fluid (per pixel), S(x,y) is the background image, and T(x,y) is the thickness value of a pixel within the fluid surface as described in eq. (13), above. Quantity \u03b2 increases linearly with the thickness, according to the equation:\n\n\u03b2=()\u03b3\u2003\u2003eq. (19)\n\nwhere \u03b3 is a constant that depends on the kind of fluid, and determines how much the background is refracted. The linear interpolation of eq. (18) allows the effects of a thicker fluid retaining its own color and less of the underlying background image color, and a thin fluid showing more of the background image color.\n","Exemplary, the optical properties of the fluid (per pixel) are based on the Fresnel equation, with a reflection and refraction component and a Phong shaded specular highlight, computing the output color of the fluid, C.\n\n(1())+()+()\u2003\u2003eq. (20)\n\nwhere F is Fresnel function, a is the refracted fluid color computed in eq. (18), b is the reflected scene color, kand \u03b1 are constants for the specular highlight, n is the surface normal, and h is the half-angle between the camera and the light, and v is the camera vector. The reflected color b can be determined by sampling a cube-map texture of the environment based on the reflected direction, and computed from the surface normal and the view vector.\n","Further exemplary of the operations -, operations - may be performed at a first resolution, and operation  is performed at a second resolution. This arrangement allows a balancing of image rendering quality versus performance\/speed. In a specific embodiment, operations - are performed at a lower resolution than that of the screen (for example, half or quarter resolution horizontally and vertically), and operation  is performed whereby the fluid is scaled up to the full resolution of the screen. Exemplary, the upscaling is integrated into the rendering step. Further exemplary, silhouettes are detected and process separately from the scaling, as applying a linear interpolation to them may result in invalid intermediate values. Inside the body of fluid, the depth is linearly interpolated, and the silhouettes are process separately therefrom. Further exemplary, the final shaded color is blended and computed at a low resolution over edges instead of the normal or depth value, thus providing a smoothing effect for the silhouettes.",{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 5","b":["500","502","504","506","508"]},"Exemplary of operation , point sprites are supplied to a shader, the shader operable to generate depth values. For example, operation  can be carried out in accordance with operations  and  described above in which an SPH algorithm is used to determine the particle positions, the particles splatted onto the screen, and a render target is initialized with a predefined depth value representing a very large depth (i.e., furthest most surface). The particles may be rendered as point sprites, in which case the depth\/z-value of the point sprite is varied within the fragment shader according to the eq. (1). Alternatively, the particles may be rendered as geometric spheres.","Exemplary of operation , a filtering process may be applied to the depth image. Further specifically, the bilateral Gaussian filtering process may be applied to the depth image, as described above. In another embodiment, the above described screen-space curvature technique may be applied to smooth the depth image of the fluid surface.","Exemplary of operation , the smoothed surface position for a pixel can be ascertained from the depth image d(x,y) of the particles included within the screen space of that pixel by back-projecting the pixel coordinates (x,y) and its depth d(x,y). Further exemplary of operation , a smoothed surface normal n for a pixel is determined by computing, for a particle which is overlaid by the pixel, the partial derivatives of the particle in the x and y directions, and computing the cross-product of the partial derivatives to compute the smoothed surface normal, as per eq. (6). When discontinuities occur in the fluid surface, using the finite differences in only one direction can result in artifacts along the silhouettes. When the difference in depth is greater than a predefined threshold, that is when a discontinuity is detected, the smallest absolute finite difference is chosen in an exemplary embodiment. For example, the smallest of the quantities |z(x,y)\u2212z(x+1,y)| and |z(x,y)\u2212z(x\u22121,y)| is chosen.","Exemplary of operation , a shaded fluid surface is rendered using the smoothed particle positions and the smoothed particle normals n determined from operation . Further specifically, the operations and computations illustrated for eq. (20) are used to render the shaded fluid surface. The fluid surface's output pixel described by eq. (20) includes input arguments n, which corresponds to the pixel's smoothed surface normal, and v (camera vector) which corresponds to the pixel's smoothed surface position.",{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 6","b":["600","602","502","506"]},"At , a fluid thickness value is generated for each of the pixels of the smoothed depth image. Exemplary of this operation, the fluid thickness values are computed in accordance with eq. (13) above.","At , a shaded surface of the fluid is rendered (displayed, written to a render target, etc.) as a function of the smoothed surface positions, smoothed surface normals, and the fluid thickness values. Exemplary of this operation, the shaded fluid surface is rendered using the operations and computations illustrated for eqs. (18), (19), and (20), above.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 7","b":["700","702","502","508","602","606","704","104","402","404","706"]},{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 8","b":["800","802","502","508","602","606","702","706","804","106","806","802","108"]},{"@attributes":{"id":"p-0074","num":"0073"},"figref":["FIG. 9","FIGS. 1-8"],"b":["900","900","902","904","904","904"]},"The processor  may further include local shared memory , which may be physically or logically allocated to a corresponding parallel processing architecture . The system  may additionally include a global memory  which is accessible to each of the parallel processing architectures . The system  may further include one or more drivers  for controlling the operation of the processor  in accordance with the methods of . The driver(s)  may include one or more libraries for facilitating control of the processor . In one embodiment, the system  is included within in a graphics card. In another embodiment, the system  is included within the motherboard of an imaging system, e.g., a digital camera. The system  may be implemented in other components, for example, a computer or a game console, or in an embedded system, such as in a cellular telephone or internet device.","The processor circuitry of the processor  is operable to perform (e.g., execute instructions to carry out) any of the operations illustrated in  herein. In an embodiment exemplified by , circuitry of processor  (herein \u201cprocessor circuitry\u201d) is operable to generate an image of the fluid surface, a noise texture of the fluid surface, and a background image of the fluid surface, and to combine these into a final image.","In an embodiment exemplified by , the processor circuitry is operable to determine positions of particles making up the fluid, generate and store a depth image of the fluid based upon the determined particle positions, and generate and store a smoothed depth image of the fluid surface based upon the depth image. Further optionally, the processing circuitry is operable to generate thickness values of the fluid based upon the determined particle positions.","In an embodiment exemplified by , the processor circuitry is operable to compute a normal for particles included within the depth image, compute a mean curvature value for each particle, and vary the depth value of the particle as a function of the mean curvature value corresponding to that particle. In an embodiment exemplified by , the processor circuitry is operable to generate a noise kernel for each particle, and sum the noise kernels to compute a noise texture for the fluid surface. In a further exemplary embodiment, the processor includes processor circuitry operable to perform operations - at a first rate of resolution for the images formed thereby, and processing circuitry operable to perform operation  at a second rate of resolution for the composite image formed thereby, the first and second resolution rates being different. In a particular embodiment the first resolution rate is lower than the second resolution rate.","In an embodiment exemplified by , the processor circuitry is operable to generate a noise kernel for each particle, and to sum the noise kernals over for a plurality of particles to compute a noise texture for the fluid surface.","In an embodiment exemplified by , the processor circuitry is operable to generate a depth image of the fluid surface, smooth the depth image, determine a smoothed particle position and a smoothed particle normal for particles in the smoothed depth image, and render a shaded fluid surface using the smoothed particle positions and smoothed particle normals.","In an embodiment exemplified by , the processor circuitry is operable to perform operations -, generate a fluid surface thickness value for each particle of the smoothed depth image, and render a shaded fluid surface based upon the smoothed particle positions and normals, and the fluid surface thickness values.","In an embodiment exemplified by , the processor circuitry is operable to perform operations - or - to render a shaded fluid surface, to further generate a noise texture for the fluid surface, and combined the shaded fluid surface with noise texture to render an image of the fluid surface.","In an embodiment exemplified by , the processor circuitry is operable to perform operations -, or operations -, or operations - to render a fluid surface, to further provide a background image of the fluid surface, and to combine the fluid surface with background image to render an image of the fluid surface.","Several advantages of the invention are realized in that (i) rendering speed versus image quality can be varied, (ii) processing, rendering and shading can be performed directly on graphics hardware, (iii) the screen-space curvature flow technique disclosed herein avoids prevents the rendered fluid surface from appearing with a blobby or jelly-like consistency, (iv) the rendering technique does not rely upon polygonization and thus does not suffer from artifacts associated therewith, (v) the method is easy to implement requiring a few passes of a fragment shader and intermediate render targets, and (vi) the method has inherent view-dependent level-of-detail, as the method is based on a grid on screen-space.","As readily appreciated by those skilled in the art, the described processes and operations may be implemented in hardware, software (a computer program element), firmware or a combination of these implementations as appropriate. In addition, some or all of the described processes and operations may be implemented as computer readable instruction code resident on a computer readable medium or product, the instruction code operable to control a computer of other such programmable device to carry out the intended functions. The computer readable medium on which the instruction code resides may take various forms, for example, a removable disk, volatile or non-volatile memory, etc.","The terms \u201ca\u201d or \u201can\u201d are used to refer to one, or more than one feature described thereby. Furthermore, the term \u201ccoupled\u201d or \u201cconnected\u201d refers to features which are in communication with each other, either directly, or via one or more intervening structures or substances. The sequence of operations and actions referred to in method flowcharts are exemplary, and the operations and actions may be conducted in a different sequence, as well as two or more of the operations and actions conducted concurrently. The described features are not limited only to their implementation in the exemplary embodiment described therefor, and the skilled person will appreciate that these features can be implemented in the other described embodiments of the invention as well. Reference indices (if any) included in the claims serve to refer to one exemplary embodiment of a claimed feature, and the claimed feature is not limited to the particular embodiment referred to by the reference indicia. The scope of the clamed feature shall be that defined by the claim wording as if the reference indicia were absent therefrom. All publications, patents, and other documents referred to herein are incorporated by reference in their entirety. To the extent of any inconsistent usage between any such incorporated document and this document, usage in this document shall control.","The foregoing exemplary embodiments of the invention have been described in sufficient detail to enable one skilled in the art to practice the invention, and it is to be understood that the embodiments may be combined. The described embodiments were chosen in order to best explain the principles of the invention and its practical application to thereby enable others skilled in the art to best utilize the invention in various embodiments and with various modifications as are suited to the particular use contemplated. It is intended that the scope of the invention be defined solely by the claims appended hereto."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0011","num":"0010"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 4","FIG. 1"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 9","FIGS. 1-8"]}]},"DETDESC":[{},{}]}
