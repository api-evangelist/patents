---
title: Processing of data sets in a computer network
abstract: A system and method for the resource-saving collaborative handling of data sets in a computer network is described. The method comprises the steps of providing a data set having an initial collaborative workflow, determining if the data set satisfies a set of one or more first start conditions to trigger a random function query, providing the data set to a random function if the random function query is triggered, stochastically determining, by the random function, whether or not to assign a modified collaborative workflow to the data set, and replacing the initial workflow with the modified workflow for the data set if the random function determines to assign the modified workflow.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07917467&OS=07917467&RS=07917467
owner: SAP Ag
number: 07917467
owner_city: Walldorf
owner_country: DE
publication_date: 20040618
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["DESCRIPTION OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS"],"p":["1. Field of the Invention","The invention relates to the processing of one or more data sets in a computer network. More specifically, the invention relates to the processing of data sets in a collaborative workflow.","2. Background of the Invention","Data set-related processes commonly transverse a plurality of stages, such as processing, storing, review and transmission stages, typically defined in the form of a workflow. Transitions from one workflow stage to another may be accompanied by the generation or modification of status information specific for a particular transition and indicative of the current workflow stage. The transition from one workflow stage to another may be initiated automatically or by automated dialogue-type communications.","The computer-assisted procurement of goods and services or the computer-assisted manufacturing of complex machinery are typical examples of multi-stage data set-related processes. During a procurement process, for example, data pertaining to different collaborative processing steps, such as purchase requisitions, goods ordering, goods receipt and invoicing, are successively generated and have to be successively stored, processed and confirmed. Hence, individual data sets or data set states associated with the individual processing steps will have to be handled as the procurement process proceeds.","As complex collaborative processes necessitate the interaction of a plurality of users, software mechanisms handling the generation, storage and manipulation of process-related data sets typically operate on distributed components of a computer network. This requirement implies that individual data sets will be accessed from different network components at different workflow stages.","A problem addressed by the present invention is that when a data set is subjected to a collaborative workflow and waiting to be checked and approved or rejected by a review intervention, this data set may be identified as \u201cwaiting\u201d for review. Such waiting periods considerably lengthen the duration of the entire workflow. Another problem is that during (or waiting for) the review intervention, such a data set may not be accessible by other network components to ensure data integrity. This restriction results in other users experiencing an access delay which, depending on the specific situation, can range from several seconds to several hours or days. Such access delays are disruptive in scenarios of the above kind where several stages have to be traversed before the workflow is completed, and particularly in arrangements that involve numerous collaborative users, workflow stages, and processes running in parallel.","A further problem addressed by the invention is the automatic association of a particular data set with the appropriate collaborative workflow. Usually, complex start conditions have to be specified and evaluated to determine the particular workflow matching the peculiarities of a particular data set. It is self evident that this determination becomes increasingly error-prone (and thus often requires undesirable human interaction) as the complexity of the start conditions increases.","A still further problem addressed by the invention is the generally high network traffic associated with collaborative workflows.","It is an object of the present invention to enable an efficient handling of large numbers of data sets in a collaborative workflow scenario as described above. More particularly, it is an object of the present invention to provide an approach that enables an automatic and standardized processing of large numbers of data sets and ensures an accelerated processing thereof while at the same time providing a consistently high quality work product.","According to one aspect of the invention, a method of handling a data set subjected to one or more stages of a collaborative workflow executed in a computer network connecting a plurality of computer network components is provided, wherein the collaborative workflow relates to a manipulation of status information associated with the data set and the status information controls the processing of at least one of the data set itself and of an associated data set. The method comprises the steps of providing a data set having an initial workflow, determining if the data set satisfies a set of one or more first start conditions to trigger a random function query, providing the data set to a random function if the random function query is triggered, stochastically determining, by the random function, whether or not to assign a modified workflow to the data set, and replacing the initial workflow with the modified workflow for the data set if the random function determines to assign the modified workflow.","Combining suitably selected start conditions with a stochastic workflow replacement mechanism provides the basis for a plurality of technical advantages, such as reduced access delays, reduced network traffic and a smoother transmission between individual workflow stages. The implementation of the stochastic process reduces, on the average, the occupied processing and network resources compared with conventional workflow scenarios.","The modified workflow that is to replace the initial workflow may be selected out of a predefined set of workflows. The initial workflow may also be selected out of this predefined workflow set or out of a separate predefined set of initial workflows. Selection of the modified workflow may be performed in dependence on the set of first start conditions satisfied by the data set. In a similar manner the initial workflow may be selected in dependence on a set of second start conditions satisfied by the data set. The first and second start conditions may be defined such that the first start conditions are narrower than the second start conditions. In many cases this helps to simplify and accelerate the definition, evaluation and maintenance of the second start conditions. Due to the simplified second start conditions, the selection of the initial workflow can be accelerated and becomes more stable and less error-prone.","The first start conditions evaluated in context with the triggering of the random function query may relate to at least one of the initial workflow, a threshold value, a workflow event, a data set type and data set sub-type. Accordingly, the necessity of stochastically initiating a modified workflow may, for example, depend on the type of the workflow initially assigned to the data set (i.e., the initial workflow). Alternatively, or additionally, one or more numerical parameters included in the data set may be compared with one or more corresponding threshold values. The second start conditions may relate to the data set type and\/or sub-type. Preferably, the second start conditions do not relate to a threshold value.","Each set of first start conditions may be associated with one or more stochastic parameters that control the stochastic determination process. The stochastic parameters may, for example, include control values that influence the probability with which the initial workflow will be replaced with a modified workflow. According to one variant of the invention, a stochastic parameter in the form of a percentage value may be defined.","The one or more stochastic parameters that control the stochastic determination process may be automatically adjusted. According to one embodiment of the invention, the number of workflow replacements (for example per predefined time interval) may be monitored and the one or more stochastic parameters may be adjusted in dependence on the number of workflow replacements. This adjustment can be performed such that a predefined number of workflow replacements is attained.","Each data set may be associated with a stochastic identifier. The stochastic identifier may take the form of a flag or the like and may be provided for the purpose of controlling the process of subjecting the data set to the random function. The stochastic identifier may be manipulated (e.g., set, changed, etc.) if the data set satisfies one set of first start conditions. This manipulation may be performed such that a control routine recognizes the manipulation and, as a result of the recognition, subjects the data set to the random function.","As has initially been mentioned, the (initial or modified) workflow may include a manipulation of status information associated with the data set. The status information may be manipulated fully automatically. Alternatively, the status information may be manipulated semi-automatically in response to dialogue-type communication.","The status information may relate, for example, to a particular processing status of the data set (or processing stage of the workflow). Alternatively, or additionally, the status information may be indicative of the state or the result of a review intervention (e.g., an approval) or any other automatic, or automated dialogue-type, intervention. The status information may automatically be evaluated for the purpose of controlling the further processing (including sending, deleting, etc.) of the data set itself and\/or of a follow-on data set associated with the data set that is subjected to the collaborative workflow.","According to one embodiment, the initial workflow includes an automatic manipulation of the status information. Thus, the initial workflow may not require any dialogue-type intervention and can therefore be concluded very rapidly. The automatic manipulation of the status information allows in many cases to refrain from routing the data set to other network components for status manipulation purposes. Accordingly, no network traffic may occur during the initial workflow (or network traffic can at least be reduced).","The modified workflow may include the step of routing the data set (or parts thereof) to one or more network addresses. The data set may be sent together with a status manipulation request that prompts the receiving network component to automatically initiate a status manipulation process as mentioned above.","Each (initial or modified) workflow may precede and\/or control the generation of a follow-on data set for the data set subjected to this workflow. The follow-on data set may be attached or related to the initial data set.","The individual workflows and in particular the initial workflow on the one hand and the modified workflows on the other hand may differ in the number of routing processes included in the workflows. Whereas, for example, the initial workflow may include no or only one routing process, one or more of the modified workflows may include one, two or more such routing processes. This means that the initial workflow may generally cause less network traffic than the modified workflows. Such an approach is advantageous if the initial workflow is statistically performed more often than the modified workflows (depending on the stochastic determination process). If, however, the modified workflows are statistically performed more often then the initial workflow, the modified workflows may include less routing processes than the initial workflow. Additionally, or alternatively, the individual workflows may differ in the network addresses to which the data sets or parts thereof are routed.","The invention may be practiced as a software solution, as a hardware solution or as a combination thereof. As regards a software solution, the invention relates to computer program product comprising program code portions for performing the steps of the invention when the computer program product is run on one or more computer network components or computer systems. The computer program product may be stored on a computer readable recording medium.","As regards a hardware solution, a computer network component for controlling the handling of a data set that will be subjected to one or more stages of a collaborative workflow executed in a computer network connecting a plurality of computer network components is provided, wherein the collaborative workflow relates to a manipulation of status information associated with the data set and wherein the status information controls the processing of at least one of the data set itself and of an associated data set. The network component comprises a provision unit for providing a data set having an initial workflow, a determination unit for determining if the data set satisfies a set of one or more start conditions to trigger a random function query and for providing the data set to a random function unit if the random function query is triggered, a random function unit for stochastically determining whether or not to assign a modified workflow to the data set, and a replacement unit for replacing the initial workflow with the modified workflow for the data set if the random function determines to assign the modified workflow.","According to a further aspect of the invention a computer network comprising the above computer network component as well as a plurality of further computer components is provided, wherein the data set or a part thereof is sent to one or more of the computer network components as specified by the workflow that has been assigned to the data set in dependency on the set of start conditions satisfied by the data set and, if involved, in dependency on the stochastic determination of the random function unit.","It will be appreciated that the present invention provides a distributed status manipulation control for data sets. This flexible control simplifies the conditions that have to be satisfied to initiate a workflow, and enhances the effectiveness of the overall process by reducing network traffic and workload associated with status manipulation processes. The present invention accomplishes these benefits while maintaining a high level of control and review over the workflow.","In the following description, for purposes of explanation and not limitation, specific details are set forth, such as particular data formats and processes utilized in connection therewith in order to provide a thorough understanding of the present invention. It will be apparent to one skilled in the art that the present invention may be practiced in other embodiments that depart from these specific details. In particular, while the different embodiments described herein below are incorporated into or used in conjunction with particular types of multi-stage workflows, it will be appreciated by the skilled artisan that the present invention is applicable to a wide variety of workflows having at least some criteria requiring manipulation of status information. Where appropriate, the same reference numbers will be used throughout this detailed description in conjunction with the drawings to refer to the same or like parts.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 1","b":["100","101","102","190","100","101","102"]},"Each network component , ,  comprises a processor , a memory , a bus , and, optionally, one or more input devices  and output devices  (I\/O devices) acting as a user interface , coupled and operating together in a conventionally known manner. The present invention may be embodied in a computer program product (hereinafter CPP) residing on a program carrier  and\/or in the memory , and generating program signals , collectively called a \u201cprogram\u201d.","The network components , , which are also referred to as \u201cremote computers\u201d, typically may comprise many or all of the elements described with respect to the network component . Hence, the elements  to  in the network component  collectively illustrate corresponding elements that may be found within the other network components ,  of the network .","The network component  can be, for example, a conventional personal computer (PC), a desktop or a hand-held device, a multiprocessor computer, a microprocessor-based or programmable consumer electronics device, a minicomputer, a mainframe computer, a personal mobile computing device, a mobile communications device, a portable or stationary personal computer, a palmtop computer or the like. The processor  can be, for example, a central processing unit (CPU), a micro-controller unit (MCU), a digital signal processor (DSP), or the like.","The memory  symbolizes elements or components that can temporarily or permanently store data and instructions. Although the memory  is conveniently illustrated as a part of the network component , a memory function can also be implemented as an independent node in the network , in the other components of the network, in the processor  itself (e.g., cache, register), or elsewhere. The memory  can be a read only memory (ROM), a random access memory (RAM), or a memory with other access options or capabilities. The memory  may be physically implemented as machine-accessible media, such as a magnetic media (like a hard disk, a floppy disk, or other magnetic disk, or a tape), an optical media (like an optical disk, e.g. a CD-ROM or a digital versatile disk\u2014DVD), a semiconductor media (like DRAM, SRAM, EPROM, EEPROM, or a memory stick), or by any other media. Optionally, the memory  is distributed across different media. Portions of the memory  can be removable or non-removable with respect to a particular network component. For reading from media and for writing into media, the network component  uses devices well known in the art such as, for example, disk drives, tape drives, memory card or memory stick reader\/writers, etc.","The memory  can store software program support modules such as, for example, a basic input output system (BIOS), an operating system (OS), a program library, a compiler, an interpreter, communication programs, drivers, protocol converters, application software programs like text processors, (Internet-) browsers, or database applications. Although the CPP is illustrated as being stored in memory , the CPP can also be located elsewhere. For example, the CPP can also be embodied on the program carrier .","The CPP comprises program instructions and, optionally, data or variables that cause processor  to execute the steps forming the methodology of the present invention. The method steps are explained in greater detail below. The CPP defines and controls the operation of the network component  and its interaction in the network system . For example, and without the intention to be limiting, the CPP can be available as source code in any programming language, and as object code (\u201cbinary code\u201d) in a compiled presentation. Persons of ordinary skill in the art can use the CPP in connection with any of the above mentioned support modules. The functionalities of one or more of the network components , ,  and of the CPP are closely related. Phrases, such as \u201cthe computer provides\u201d or \u201cthe program provides\u201d, are used hereinafter to express actions by one or more network nodes that is\/are controlled by the CPP in accordance with the invention.","The program carrier  is illustrated as being outside the network component . For communicating the CPP to the network component , the program carrier  is conveniently inserted into the input device . The carrier  is implemented as any computer readable medium, such as one of the media explained above (cf. memory ). Generally, the program carrier  is an article of manufacture comprising a computer readable medium having computer readable program code portions embodied therein for executing the method of the present invention. Further, the program signals  can also embody the CPP. The signals  travel on the computer network  to and from the network component . The steps of the computer program product CPP can be executed solely in the network component , in which case the computer network  may be omitted, or can be executed in a distributed manner in one or more of the components of the computer network .","The input device  is a device that provides data and instructions for being processed by the network component . For example, the device  can be a keyboard, a pointing device (e.g., a mouse, a trackball, cursor direction keys), a microphone, a joystick, a game pad, a scanner, etc. While these examples are devices requiring human interaction, the device  can also operate without human interaction, such as a wireless receiver (e.g., with satellite dish or terrestrial antenna), a sensor, a counter (e.g., goods counter in a factory), etc. The input device  can also serve to retrieve the program code of the CPP from the program carrier .","The output device  is a device that presents instructions and data that have been processed. It can be, for example, a monitor or display (such as a cathode ray tube, a flat panel display, or a liquid crystal display), a speaker, a printer, a plotter, a vibration alert device, etc. or a combination thereof. Similar to the input device , the output device  mainly communicates with the user(s), but it can also communicate with further network components or devices. The input device  and the output device  can be combined into a single device.","The bus  and the computer network  provide logical and physical connections by conveying instructions and data signals. While connections and communications inside the network component  are conveniently handled by the bus , connections and communications between different network components are handled by the network . Optionally, the network  comprises gateways and routers being computers that are dedicatedly programmed to effect data transmission and protocol conversion.","The input\/output devices  and  are coupled to the network component  by the bus  (as illustrated) or by the network  (optional). While the signals inside the network component  can be mostly electrical signals, the signals in the network can be electrical, magnetic, optical, or wireless (radio) signals.","The network  can include one or more of an office-wide computer network, an enterprise-wide computer network, an intranet or the Internet (i.e., the world wide web). The world wide web (www) represents all of the computers on the Internet that offer users access to information on the Internet via interactive documents or Web pages. Web information resides on Web servers on the Internet or within company or community networks (intranets). The network  can include a wired or a wireless network, such as, for example, a local area network (LAN), a wide area network (WAN), a wireless LAN (WLAN), a public switched telephone network (PSTN), an integrated services digital network (ISDN), an infra-red (IR) or Bluetooth link, a radio link e.g. according to the Universal Mobile Telecommunications System (UMTS), the Global System for Mobile Communication (GSM), a Code Division Multiple Access (CDMA) system, or satellite link.","Transmission protocols, mechanisms and data formats to effect communications between network components which are connected to and by the network  are known, for example, as transmission control protocol\/internet protocol (TCP\/IP), hyper text transfer protocol (HTTP), secure HTTP, wireless application protocol (WAP), unique resource locator (URL), unique resource identifier (URI), hyper text markup language HTML, extensible markup language (XML), extensible hyper text markup language (XHTML), wireless application markup language (WML), electronic data interchange (EDI), which is an electronic exchange of business information between or inside organizations and their information technology (IT) infrastructure in a structured format, remote function call (RFC), or via an application programming interface (API), etc.","Interfaces coupled between individual elements and components are also well known in the art. For simplicity, interfaces are not illustrated. An interface can be, for example, a serial port interface, a parallel port interface, a game port, a universal serial bus (USB) interface, an internal or external modem, a video adapter, or a sound card.","The software and the hardware infrastructure of an embodiment of the invention utilize the network component  having the graphical display unit  and the input unit , e.g. a mouse or a trackball. The network component  is connected to a wide area network (WAN) , for operating in an intranet and for providing access to the Internet to which a number of members of a group of the similar or identical network components ,  are also connected. In order to operate the CPP according to the invention, one of the network components ,  acts as a host server having an archival data storage for access by the group. In addition to its server tasks, the host server may also provide firewall functions, authenticate the distributed client components connected to the computer network , and provide other similar functionality.","The CPP according to the present invention can be part of a complex software system embedded in a hardware structure. The cooperation of the software system and the hardware structure is sometimes referred to as IT backbone system. The backbone system can have a layered structure with individual software components acting in accordance with the client\/server concept as service providers, service requesters, or both. For example, application software can include software components that provide services for presentation, acting as a server. But at the same time, the application software also can act as service requester of database services provided by a lower layer. The layered components can communicate with each other via predefined (hardware and software) interfaces.","With regard to a possible implementation of a layered software structure, a lower layer may include network-related functionalities, a physical database and an operating system for the network components. A middle layer that interfaces with the lower layer integrates software applications in the upper layer above it. This middle layer may include components like software tools, system administration tools, data handling tools, authorization and security management tools, cross-application modules, and a system kernel. The system kernel can use communications and application program interfaces to access components like application software in the upper layer or the operating system, the database, and the network in the lower layer. This system kernel can operate independently from the applications and is located \u201cunder\u201d the application software and the data layers of the software system. The upper layer contains the different software applications (e.g., for controlling and monitoring processes relating for example to the management of human resources, sales and distribution, financials, materials, manufacturing, etc.).","One possible client\/server configuration in which the present invention can be carried out is the so-called three-tiered architecture which separates a network system's components into three functional groups: presentation, application, and database. This is illustrated in  in a hardware-related view.","With the three-tiered architecture shown in , each hardware group is configured to support demands of its functions. The one or more database servers  contain the databases. Application servers  interfacing the database servers  include the processing logic of the system with services such as spooling, dispatching user requests, and formatting data. The tasks related to the presentation of data are handled by presentation servers , which are typically personal computers or workstations, enabling easy access to the system. External presentation servers  may be connected to the application servers  via the Internet and a web server\/Internet transaction server . Communication among the three tiers can be accomplished with the use of standard protocol services mentioned above, such as the ones provided by TCP\/IP or CPIC. CPIC stands for Common Programming Interface Communication and includes standard functions and services for program-to-program communication.","The three-tiered hardware architecture depicted in  is shown in  in a software-related view. As becomes apparent from , the software components used in context with the present invention include a GUI installed on the presentation server  of  and an application that runs on the application server . The application has interfaces to the database installed on database servers , to the Internet and, via the messaging component installed on a message server , to the GUI. The message server  is a service used by different application servers  to exchange data and internal messages. The main tasks of the message server  include the transfer of messages and the distribution of workload between individual application servers .","The application running on the application server  includes a dispatcher  interfacing the message server  and one or more presentation servers  on the one hand and a plurality of parallel workflows  on the other hand. Each workflow process  has an interface to the database on the database server . Furthermore, a gateway  is provided that may either be installed, from a hardware point of view, on the application server  or on a dedicated gateway server (not shown). The gateway service provided by the gateway  allows for a communication between different applications using the CPIC protocol. The function of the gateway  is to exchange large amounts of data between application servers, in contrast to the message server  which only exchanges brief internal and control messages. The application component depicted in  further includes dispatcher queues , memory pipes  and an Internet Communication Manager (ICM) , interfacing the Internet.","In the following the interrelation among the individual software components depicted in  is described in more detail.","As data is entered in the presentation server  (or otherwise generated), the data is received by the GUI, converted to a standard format, and sent via the messaging server  to the dispatcher . The connection between the GUI on the presentation server  and the dispatcher  is made with a protocol like DIAG, according to which small data packages are sent through the network  depicted in .","The dispatcher  checks whether there are available work tasks for processing the request received from the GUI. A workflow typically involves a plurality of such work tasks. If no work tasks are available, the request is kept together with other requests in the dispatcher queues  until a work task becomes available.","Once a work task becomes available, the dispatcher  sends the user data to the available work process . A work process  is a program in charge of executing application tasks of the present invention. Each work process  acts as a specialized system service. From the point of view of an operating system, a group of parallel work process  as depicted in  makes up a runtime system. Each individual work process  includes a task handler, a processor, and a database interface (not shown).","The work process  may execute dialogue steps for the presentation server . These steps generally relate to the processing or display of a single GUI screen, which means that right after one work process  finishes the execution of a dialogue step for a user session, it is immediately available for use by another user session. For its processing, each dialogue step needs code, dictionary objects, and data. These elements may come from the database residing on the database servers  or from an internal memory of the application server . Within a dialogue step, the task handler (not shown) is in charge of assigning the corresponding tasks to the internal components (dialogue interpreter and processor), finally sending a SQL request to the database servers . The database servers  send the requested data back to the work process , which in turn process it and passes it via the dispatcher  to the presentation server . The GUI on the presentation server  formats the requested data and builds up the screen for the user.","If during a particular work process  application data has to be exchanged with other applications such as legacy applications or external applications, the functionality of the gateway  is activated.","The ICM  allows the direct processing of HTTP requests coming from the Internet and\/or a browser running on a presentation server , and for sending HTTP requests as HTTP client requests to the Internet. The ICM , which may be configured as a dedicated kernel process, uses threads to communicate as a server or as a client on the Internet. If an HTTP request is being processed by a work process , the memory pipes  are used for data transfer. The memory pipes  are located in a shared memory portion. In its Web client position a work process  creates an HTTP request which is sent to a Web server. It then receives the HTTP response and the work process  proceeds on the basis of the HTTP response.","The basic steps constituting an example of an electronic procurement process involving a plurality of individual workflows (and corresponding work processes ) and a plurality of network components as described with reference to  are depicted in .","The process starts with an electronic requirement request to create a shopping cart data set (or simply \u201cshopping cart\u201d). Then, a follow-on data set in the form of a purchase order data set (or simply \u201cpurchase order\u201d) is created, and if desired, a status and tracking query is formulated. A consecutive follow-on data set in the form of a goods and services receipt data set (or simply \u201cconfirmation\u201d) follows. Generation of a final follow-on data set, in the form of an invoice data set (or simply \u201cinvoice\u201d), electronic invoice approval and payment complete the process.","As is illustrated in , the entities involved in the electronic procurement process include a company's intranet, as well as an Internet layer attached to the intranet as has been explained with reference to . The intranet basically includes presentation services, message services, application services, and database services while the Internet layer includes Internet transaction services and web services for hosting various databases like an electronic catalog and a vendor database as well as for providing an electronic marketplace. The electronic marketplace focuses on the efficiency of virtual communities and provides a collaborative platform that enables electronic procurement to take place across multiple software systems and services. The electronic marketplace provides the necessary infrastructure for virtual markets, allowing multiple organizations to electronically communicate with the purpose of conducting collaborative processes. A network component located in the intranet of  can access the electronic marketplace for example to publicly post a request for quotation (RFQ) for certain materials or services. Once the request is posted, bidding on the request may be performed. Once a bid is accepted, all necessary data sets (like purchase orders, invoices, etc.) are transferred via the electronic marketplace thereby forming a closed-loop scenario.","In a first step of the electronic procurement process depicted in , a shopping cart is created by searching the electronic catalog. The electronic catalog is regularly updated and allows real-time pricing and availability checking for goods or services to be ordered. Updating of the electronic catalog is performed via the vendor database. It should be noted that the electronic catalog may partially or completely be located in a central database of the intranet. Instead of or in addition to using the electronic catalog, requirements may be entered directly on a GUI of a presentation server located in the intranet (not shown) and transferred to the shopping cart.","A shopping cart may include only a single data item (e.g., product category) or a plurality of data items in the case of complex orders. Additionally, each shopping cart includes a header with general data (time stamp, denomination, etc.) and a follow-on data set table. The follow-on data set table contains all follow-on data set records for the shopping cart or references to these records. As a result, the individual processing stages are documented and dependencies are saved.","Once a shopping cart has been created, the requirements comprised therein may be held or ordered. When holding the requirements, the shopping cart is temporarily stored locally and can be processed again at a later time. When the user wishes to initiate the next processing stage (ordering), including creation of a follow-on data set in the form of a purchase order, (depending on whether the shopping cart was processed in a collaborative workflow to manipulate its initial status and depending on its final status as described in more detail below) the application server (not shown) checks whether the shopping cart needs to be approved.","Generally, a requirement request (shopping cart) must have a predefined approval status before a purchase order can be created. For status manipulation purposes, the application server initiates a Web-compatible collaborative workflow. Approval status manipulation can be carried out using an automated release strategy without routing the shopping cart through the intranet (initial or standard workflow) or, for example if the requisition value is above a predefined threshold allowed for automatic approval, and in dependence of the result of a stochastic process, the approval status can be manipulated in the course of a modified workflow as will be described in more detail below.","If a shopping cart has assumed the required approval status or if it is determined that no approval is required, the system automatically creates the purchase order as follow-on data set (step ). Both the shopping cart and the purchase order are stored in the central database of the intranet. On creation of the purchase order, a reference to this follow-on data set is written in the follow-on data set table of the shopping cart. By this, the purchase order is associated with the shopping cart. It should be noted that two or more individual purchase orders may be created for a single shopping cart. This may be the case for example if different data items (goods\/services) of the shopping cart are ordered from different vendors.","Once a purchase order has been created, it is sent electronically via the Internet to the vendor's system using for example XML. Other messaging protocols and messaging services like e-mail or EDI may be used also. As an alternative to sending the purchase order to a particular vendor, it may also be placed on the electronic marketplace as mentioned above (step ).","After the goods have been delivered or after the services have been performed, a confirmation data set is created (step ). Before the final follow-on data set (invoice) can be created, the confirmation data set must have an approved status. For status manipulating purposes, a web-compatible collaborative workflow is initiated. Depending on the start conditions fulfilled by the confirmation data set and depending on the result of a stochastic process that will be described in more detail below, status manipulation is carried out using either an initial (or standard) workflow or a modified workflow.","Once the confirmation has been created, a reference to this follow-on data set is written in the follow-on data set table of the shopping cart. Additionally, the confirmation is stored in the central database of the intranet and, if required, printed by printer LPT. It should be noted that for a single purchase order two or more confirmations may be created, for example when the ordered goods are received with different deliveries. In such a case a first confirmation is created for the initial delivery and one or more further confirmations are created for the amount of goods still open after the first delivery.","In a fifth step, a final follow-on data set in the form of an invoice is created by the vendor's system and transferred for example by XML to the intranet where it is stored in the central database. At the same time a reference to this newly created follow-on data set is written in the follow-on data set table of the shopping cart and a collaborative approval workflow may started as discussed above (not depicted). If required, the invoice may be printed using the printer LPT.","It should be noted that in principle, the invoice may also be created within the intranet. On the other hand, the confirmation need not necessarily be created within the intranet but may be created by the vendor's system and transferred to the intranet via the Internet layer.","As has become apparent from the above, the electronic procurement process described with reference to  involves the distributed handling of a plurality of data sets including an initial data set (shopping cart) and three independent follow-on data sets (purchase order, confirmation, invoice).","Two of the four data sets shown in  are subjected to collaborative workflows that relate to a manipulation of approval status information associated with(e.g., written in a data field of) the respective data set. As has become apparent from the above, the approval status information controls the subsequent creation of follow-on data sets. If, for example, the status of the initial data set (shopping cart) is not changed from \u201cpending approval\u201d to \u201capproved\u201d, no follow-on data set (purchase order) is created for this initial data set. Manipulation of the approval status is performed during a generally collaborative approval workflow involving one or more network components (e.g., a network component requesting approval and one or more approving network components).","In the present embodiment, there is no fixed collaborative approval workflow that is applied to all types of data sets or to all data sets of a particular type. Rather, an appropriate workflow is dynamically (and stochastically) chosen by an arrangement having the structure shown in  and operating in accordance with a workflow-replacing process as shown in .","With reference to , an arrangement  for handling data sets that are to be subjected to one or more stages of a collaborative workflow is illustrated. The arrangement  includes a provision unit , a determination unit , a random function unit  and a replacement unit . The individual units , ,  and  can belong to a single physical network component (and communicate directly with each other) or can be distributed across several individual network components (and communicate with each other via a computer network ).","The provision unit  provides the data set that is to be subjected to a status manipulating workflow. The data set provided by the provision unit  is already associated with an initial (or standard) workflow. The determination unit  determines if the data set provided by the provision unit  satisfies a set of one or more start conditions to trigger a random function query and provides the data set, via the provision unit , to the random function unit  if the random function query is triggered. The random function unit  then stochastically determines whether or not to assign a modified workflow to the data set. Should the random function unit  decide to assign the modified workflow (instead of the initial workflow) to the data set provided by the provision unit , it controls the replacement unit  such that the initial workflow is replaced with a modified workflow. Once the initial workflow has been replaced with a modified workflow, the data set is subjected to the modified workflow. On the other hand, if it has stochastically been determined not to assign a modified workflow to the data set, or if the data set does not satisfy any set of start conditions to trigger a random function query, the data set is subjected to the initial workflow.","The process of stochastically replacing the initial workflow with a modified workflow will now be described in more detail with reference to the process flow diagram  shown in . The process flow diagram  illustrates a technique for stochastically handling data sets generated by a system or process as described above (or otherwise), such as the shopping cart and confirmation data sets of . It will be appreciated by the skilled artisan from the following that the present invention may be utilized in any arrangement in which data sets are created that may be subjected to a status manipulating workflow, and in which there is benefit from reducing the number of data sets that must be routed to status manipulating network components (while at the time maintaining the integrity and quality of the status manipulations).","The method starts in step  with the provision of a data set to which an initial (or standard) workflow has been assigned depending on a particular set of start conditions satisfied by the data set. To this end various sets of start conditions are defined and each set of start conditions is associated with a particular initial workflow. The start conditions that are evaluated to assign a particular initial workflow to the data set are kept simple and may, for example, depend only on the particular data set type provided. In the example shown in , a first initial workflow may be provided for the data set type \u201cshopping cart\u201d and a second initial workflow may be provided for the data set type \u201cconfirmation\u201d. Keeping the start conditions such simple reduces the processing resources required to evaluate the start conditions and to assign, depending on the start conditions, an initial workflow to the data set. In the present embodiment, the initial workflow involves a local status manipulation stage that does not require any routing of the data set to other network components (or network addresses). Accordingly, the initial workflow, if not replaced by a modified workflow, helps to reduce network traffic as the status manipulation does not involve any routing processes.","Once an initial workflow has been assigned to the data set in step , it is determined (in step ) if parameters associated with (e.g., included in) the data set trigger a random function query process. Specifically, it is determined if the data set satisfies one or more further start conditions (that will in general be different from the start conditions evaluated when assigning the initial workflow to the data set in step ). The start conditions evaluated in step  may include the initial workflow assigned to the data set in step , a workflow event (e.g., if the data set has been or will be saved, etc.), a data set type, a data set sub type and\/or one or more threshold values relating to values included in the data set.","If it is determined in step  that the data set provided in step  satisfies any one predefined set of start conditions, it is decided to trigger a random query, and a stochastic flag included in the data set is set in step . If, on the other hand, it is determined in step  that the data set does not satisfy any predefined set of start conditions, the stochastic flag is not set (or remains un-initialized).","From step  or, if no random function query process is triggered, from step , the method proceeds with an optional step  in which the data set may be processed further. If no further processing is required, step  may be omitted and the method may continue directly with step . In step  it is determined if the stochastic flag of the data set is set. If the stochastic flag is not set, the data set is subjected to the initial workflow in step .","If, however, it is determined in step  that the stochastic flag is set, the data set is provided to the random function process (step ). In the random function process (step ) it is stochastically determined by a random function whether or not to assign a modified workflow to the data set. To this end, one or more stochastic parameters associated with particular the start conditions already evaluated in step  are retrieved. The stochastic parameters retrieved by the random function may be a single percentage value indicative of the percentage with which the initial workflow is to be replaced with a modified workflow.","After the one or more stochastic parameters have been retrieved, the random function starts a random generator and compares a random value output by the random generator with the one or more stochastic parameters to stochastically determine whether or not to assign a modified workflow. If, for example, the stochastic parameter is chosen within a range of 0 to 1 (0.1, for example, indicating that for ten percent of all data sets the initial workflow is to be replaced by a modified workflow), and if the random generator generates random values in the range between 0 and 1, it is determined to replace the initial workflow with a modified workflow if the random value output by the random generator lies in the range between 0 and 0.1. If, on the other hand, the random value lies in the range above 0.1, the initial workflow is not replaced. In this case no modified workflow need to be assigned to the data set and the method continuous with step  in which the data set is subjected to the initial workflow.","If it is stochastically determined in step  that a modified workflow need to be assigned to the data set, the method continuous with step . In step  a modified workflow is determined for the data set dependent on the start conditions satisfied by this data set. As explained above, these start conditions were already evaluated in step . After the appropriate modified workflow associated with the start conditions evaluated in step  has been determined and assigned to the data set, the method continues with step . In step  the data set is subjected to the modified workflow that has been assigned to the data set in step .","The skilled artisan will appreciate that the stochastic parameters utilized by the random function in step  are fixed but may be adjustable. For example, the percentage range indicative of the probability that the initial workflow will be replaced with the modified workflow may be adjusted such that the number of data sets subjected to the initial workflow or to a particular modified workflow fulfills a certain condition (e.g., does not exceed or fall below a predefined value during a predefined time interval).","The skilled artisan will appreciate further that it is not required that the start conditions initiating the stochastic process are evaluated in each of steps ,  and . Instead, an identifier pointing to the particular set of start conditions satisfied by the data set evaluated in step  (or to the modified workflow assigned to these particular conditions) may be associated with (e.g., written in a data field of) the data set in step . This identifier may then be used in step  to retrieve the one or more stochastic parameters assigned to the start conditions and in step  to identify the modified workflow that is to be assigned to the data set using, for example, a look-up table similar to that shown in . As shown in  (that will be explained in more detail below), the identifier may, for example, be one of the consecutive numbers assigned to the individual sets of start conditions (i.e., , , ,  or  in the embodiment shown in ).",{"@attributes":{"id":"p-0097","num":"0096"},"figref":["FIG. 7","FIG. 7","FIGS. 4 to 6"]},"The initial workflow includes three individual stages, a first processing stage, a first status change stage, and a second processing stage. The individual stages of the initial workflow are all performed by one and the same computer network component. The single status change stage is configured such that the status information is automatically manipulated. This could mean in the above embodiments that in the standard workflow the approval status is automatically changed from \u201cpending approval\u201d to \u201capproved\u201d, so that any dialogue-type communications can be omitted and the data set can quickly traverse the individual stages of the standard workflow.","The modified workflow includes five stages, two local processing stages, a routing stage, a remote status change stage as well as a (local or remote) third processing stage. In the routing stage, the data set is routed to a remote network component for status manipulation purposes (if appropriate together with a status manipulation request). At the remote network component, status manipulation processes are performed. This status manipulation processes may include an automatic status change (e.g., from \u201cpending approval\u201d to \u201capproved\u201d). Alternatively, a semi-automatic status change process involving dialogue-type communications and user input may be performed.","The second modified workflow shown in  involves six individual stages, including two routing stages and two remote status change stages. The routing stages may performed in series (as shown in ) or in parallel. During the two routing stages the data set is sent to the same as to different network components for status change purposes as explained above.","Obviously, the second modified workflow causes more network traffic than the first modified workflow, whereas the standard workflow does not cause any network traffic. Additionally, the standard workflow occupies less processing resources than any of the modified workflows. Accordingly, the standard workflow is, from a technical point of view, the preferred workflow. However, the standard workflow has the drawback that no detailed review intervention with respect to the data set to be approved takes place. For this reason, the standard workflow is stochastically replaced by one of the first and second modified workflow to ensure that errors like wrong data input and the like can statistically be detected. Compared to the situation that only modified workflow  and\/or modified workflow  are implemented, the stochastic combination of the initial workflow with any one of the modified workflows on the average decreases system occupancy and network traffic.",{"@attributes":{"id":"p-0102","num":"0101"},"figref":["FIG. 8","FIG. 6","FIG. 8","FIG. 9"],"b":["620","680","690"]},"Although embodiments of the present invention have been illustrated in the accompanying drawings and described in the foregoing description, it will be understood that the invention is not limited to the embodiments disclosed. The invention is capable of numerous rearrangements, modifications and substitutions without departing from the spirit of the invention as set forth and defined by the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Further details, embodiments, modifications and enhancements of the present invention may be obtained from consideration of the following description of various illustrative embodiments of the invention in conjunction with the drawings, in which:",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
