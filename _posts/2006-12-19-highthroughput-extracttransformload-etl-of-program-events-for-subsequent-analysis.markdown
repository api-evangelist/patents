---
title: High-throughput extract-transform-load (ETL) of program events for subsequent analysis
abstract: An event tap associated with a server, such as a Web server, at a machine can transform a server event into a tuple, select a database node for the tuple, and place the tuple in a queue for that database node, and then flush the queue periodically directly into database nodes. The use of an event tap can thus reduce the computational burden on the database while keeping the server event data in the database relatively fresh.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08849746&OS=08849746&RS=08849746
owner: Teradata US, Inc.
number: 08849746
owner_city: Dayton
owner_country: US
publication_date: 20061219
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["COPYRIGHT NOTICE","FIELD OF THE INVENTION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records, but otherwise reserves all copyright rights whatsoever.","The present invention relates to extracting program events from running programs and placing a record of these events in a database for subsequent processing.","Extracting program events from running programs and placing a record of these events in a database for subsequent processing can be particularly difficult when the events occur at a very high rate.","The running program can be of any type. An example is a server (such as a Web server) that processes requests from clients. Events can be the arrival of such requests, as well as the completion of the servicing of requests. Events could be anything else, such as a failure being encountered, a change of condition in system resource availability, etc.","For example, consider a large Internet service that uses a farm of Web servers to expose their content to end users. Such Web farms can have hundreds or thousands of individual Web servers. Every time a user views a particular page, an event is triggered. Such an Internet service would like to record these events, in order to analyze them (also known as clickstream analysis).","Moreover, if additional attributes are recorded along with the event, then the quality of the analysis can increase. Analyzing clickstreams can convey extremely valuable information that can be used in determining user demographics and preferences, tracking usage metrics for products and marketing campaigns by various attributes (type, country, etc.). Executives can track growth trends for the Web site as a whole, while individual business units can drill down and track their specific programs and products on predefined user segments. For such analysis to be effective, additional information must be recorded with each click (e.g., information about the user, how long the processing took, etc.)","Several approaches have been proposed to solve this challenge. For example, the logs generated by the server of interest (e.g., the Web server) can be harvested and processed. Another approach is to instrument the responses returned to end users in a way that will cause the Web browsers of those end users to automatically report events (e.g., tagging Web pages with active code). And finally, there is the approach of extracting the events directly from the running server.","In the log-processing approach logging is turned on in the server (such as a Web server, application server, database server, any other kind of server) and the resulting logs are then collected. These logs are then parsed and interpreted, and either deposited in a database or some other form of repository. The process of taking these logs and placing them into a repository is often called ETL (Extract-Transform-Load).","One drawback of the server-processing approach is that it can lead to the data in the database being insufficiently current for the data analytics. For example, it may take a significant period of time for the logs to be obtained and processed; during this time, the data in the logs will be unavailable for analysis and the value of the data reduces as its freshness drops.","Conventional Web analytics companies often use a \u201cWeb beacon\u201d technique to capture traffic data (formerly known as the \u201cWeb bug\u201d approach). This approach requires modifying the production code of a Web property to insert into the Web pages of interest a small 1\u00d71 pixel image or some JavaScript code that carries information about the particular page view. The URL of the pixel (or the JavaScript) points to the servers of the Web analytics company, where information about the initial request is logged. The analysis of the logged data happens through online interfaces that generate Web analytics reports.","Although the above model is currently used at many small and medium size Web sites, it presents significant limitations for use in large scale environments that have stringent requirements for freshness, availability, and visibility into user behavior. Conventional Web analytics companies often struggle at top Web Sites: loading and analyzing the clickstream data can become unacceptably slow, the amount of history is often small and customers have to compromise either data detail or time horizon. The end result is that large scale Web analytics become very expensive due to the nonlinear increase in the cost of these systems, reaching many millions of dollars per year for a large site.","The problem here is that, on one hand, there is increased inefficiency in the event collection process. For the event to be recorded, some information is embedded in the result sent to the end user; the end user then automatically acts on that information and sends information to yet another service (in some sense, another event). Typically, a browser automatically fetches the Web beacon and generates an HTTP request to the Web analytics service provider, which then records it. This costs time, processing power, and network bandwidth.","Another fundamental limitation of Web beacons is that they cannot capture requests for non-HTML content, such as images, streaming media, PDFs, etc. With media content becoming increasingly more important for Web properties, this limitation has a serious impact on the value of the analytics solution.","The direct event extraction approach can consist of placing a special piece of code in the server that witnesses the various events, and then extracting the event directly from there to the target repository.","The main challenge in direct event extraction is that the database on the receiving end of these events must be able to sustain the high rates at which events are generated. For example, a service with 3,000 Web servers can receive 3,000,000 clicks per second at peak time, which means that at least 3,000,000 events must be extracted and inserted into a database every second. If only 1 KB of data is collected for each click, then aggregate data bandwidth will exceed 3 Gigabytes\/sec. In this example, a database would have to be capable of performing an impractical 3,000,000 transactions per second if each event were directly provided to the database.","Embodiments of the present invention can use event taps at a server to transform, buffer and load server events into a database in an efficient manner. This can reduce the burden on the database while keeping the server event data in the database relatively fresh.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1","b":["101","104","101"]},"The database representation, such as a tuple, can be of a format for storing in a database .","The database  can be a distributed database. In one embodiment, a distributed database  can be clustered. The distributed database  can use software such as Postgres-R or C-JDBC. In one example, a Beehive, produced by Aster Data Systems Inc., of Redwood City, Calif., can be used.","Loading events into a database  through a single point of entry does not scale, therefore methods can be used to assign tuples to database nodes , , ,  and  directly. A tuple can be assigned to a specific database node. For example, information related to the tuple or server event can be hashed or used in another type of algorithm to produce an ID of the database node. The tuple can be placed in a queue  corresponding to that database node . In the example of , queue  is associated with database node , queue  is associated with database node , queue  is associated with database node , queue  is associated with database node , and queue  is associated with database node . In this way, the tuples can be distributed to the different database nodes , , ,  and .","The queues , , ,  and  can accumulate tuples for a certain period of time and then be sent to the respective database nodes , , ,  and . In one embodiment, the period can be a minute or less. In one example, the period can be less than 30 seconds. In one embodiment, the period of time is not predetermined. Alternately, the flushing of queues can be triggered by any type of relevant event, such as the queue filling up to a predetermined level, for example 80%.","The queues , , ,  and  can overflow to local storage  if a database node becomes unavailable. The local storage  can be any type of memory, such as a hard disk. On a failure of a database node, the tuples can be sent to another database node. For example, if database node  fails, the tuples that would be assigned to database node  can be reassigned to other database nodes such as one or more of database nodes , ,  and . The database , or other software, can keep track of where tuples are stored.","The server , such as a Web server, can have an event interceptor  to provide the events to the event tap . The event tap  can be comprised of software elements to process the events for the database . The event tap  can include a transform stage  to transform events intercepted by event interceptor into a database representation, such as a tuple. Partition stage  can determine which database node should receive the database representation. Load stage  can store the database representations into queues , , ,  and  and load batches of the database representations to the database nodes , , ,  and  at the appropriate time.","The event tap can be on one or multiple machines. For example, different stages of the event tap can be on different machines.","In one example, the load stage  could reside on a separate server on the same Local Area Network (LAN) as the server. This separate load stage can be running on hardware customized for the application (rather than for the server). The separate load stage can also aggregate data from the multiple servers, thus leading to a hierarchical system. The network bandwidth between Web servers and external load stage servers may be high, whereas the bandwidth between load stage servers and the database might be low (thus, the load stage servers can act as an aggregator).",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 1","b":["104","105","107","101","102","103","118","118"]},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIGS. 2A-2D"},"In the example of , the event tap  receives an \u201cevent h\u201d. Transform stage  converts the \u201cevent h\u201d into a database representation \u201ctuple h\u201d. Partition stage  determines the database node (and queue in load stage ) for database representation \u201ctuple h\u201d. In this case, \u201ctuple h\u201d is destined for database node  in database , and so is queued in queue  of load stage .","In the example of , a batch  of database representations (including \u201ctuple h\u201d) is sent from queue  to database node . The batching of the transfers to the database nodes reduces the number of update transactions the database must perform (reduction is according to the batching factor, and can be as arbitrarily high (e g., 1,000\u00d7 or even 10,000\u00d7) and thus can help the system scale for use with very large server farms. The queues of the load stages can transfer batches in a staggered manner so that the tuple loads are spread out over time and database  is not overloaded with operations\/transactions at any given time.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 2C","b":["218","220","222","201"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 2D","b":["218","218","224","210","218"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 3","b":["302","304","306","308","308","310","312"]},"A number of functions can use the stored data. They can include marketing campaign analysis , cost structure analysis , service analytics , bot detection , and fraud detection . The functions can use SQL or some other query language to make use of the stored event data.","A single, central repository for all data used in analytics can be used, such as a Beehive, produced by Aster Data Systems Inc., of Redwood City, Calif. Event data can be captured from live systems (such as Web servers); additional data can be uploaded via standard mechanisms (such as Open Database Connectivity (ODBC)) from other databases.","Described below is one detailed example of the capture, transformation, partition, and loading of data from live Web servers (Microsoft Internet Information Services\u2122 (IIS\u2122) in this example). The same model can carry over to other types of live systems in which events occur at a very high rate (like RFID scanning devices in a warehouse, etc.)","The design described can maximize the efficiency of data extraction and transformation in a way that leverages the resource availability at typical large-scale Internet services: direct extraction of the events from the Web servers, transformation into database tuples on the fly, and direct insertion into database nodes, such as Beehive worker nodes. This can be referred to as intravenous loading since events can go straight to the database.","There can be four distinct phases in this process.\n\n","The first step can be implemented in an event interceptor that resides within the Web server program.","The purpose of the event interceptor can be to capture request\/response events in the Web server and relay them to the event tap. The event tap can reside on the Web server hardware or an external hardware; the individual stages of the event tap can also be split so as to reside on different hardware. For this example, it is assumed that the entire business application runs in ASP.NET on the Web server.","The event interceptor for IIS\u2122 6.0 can be an Internet Server Application Programming Interface (ISAPI) filter deployed in the IIS\u2122 Web server. It can run within the Web server process or outside the server process; as such, its functionality can be kept to a minimum to ensure robustness.","The interceptor can be activated every time an HTTP (or HTTPS) request is received by IIS\u2122, as well as when the response is sent back to the user. The event interceptor can therefore see every HTTP (or HTTPS) request, not just individual user clicks (one click can result in a large number of HTTP\/HTTPS requests, as the browser fetches the various elements that constitute the displayed HTML page).","ISAPI is an API for the IIS\u2122 Web server that allows programmers to develop Web-based applications that run faster than conventional Common Gateway Interface (CGI) programs. IIS\u2122 exposes a set of notifications (events) that ISAPI filters can register for; when IIS\u2122 triggers such notifications, the ISAPI filter dynamic link library (DLL) is invoked (callback style). In IIS\u2122, ISAPI filters run outside the IIS\u2122 process, so they can't crash it.","A filter can get activated upon a request receipt\/response. There are several types of input the event interceptor can use including: server variables, response parameters, application-specific fields, and cookies.","For server variables, ISAPI filters can call GetServerVariable and read information needed about the request.","The following information about the incoming request can be extracted using this mechanism (other fields can be accessed as well, as required by the application):\n\n","ISAPI filters can receive notification immediately prior to the Web server sending the response headers to the client. The filters can then inspect, modify, or add headers that the client receives as part of the response to the client's original request.","The ISAPI filter can register for the SF_NOTIFY_LOG event, and extract the following fields from the HTTP response,\n\n","The business application can communicate with the event tap by passing it the custom values, so the application can instruct the tap what to write into the database. For example, for application specific fields, the business application tier (such as ASP.NET or ColdFusion) can pass custom values to the interceptor, through custom HTTP headers: the application can set the header to a value, and then the ISAPI filter can extract this custom header (via the HTTP_<HeaderName> variable). After extracting this header, the ISAPI filter can discard it from the response, so it is not received by end users. Through this mechanism, we can obtain the following fields:\n\n","Cookies can provide another way to obtain information; there may be a number of cookies that are of interest to the event interceptor (the cookie is extracted using GetServerVariable): COOKIE_A and COOKIE_B.","Each individual event can be relayed to the event tap using a FIFO (First In, First Out) Inter-Process Communication (IPC) mechanism. On Windows, there are at least 3 choices, mailslots, named pipes, and sockets. The choice of mechanism can depend largely on the customers preferences. Regular Berkeley style sockets (through the Winsock interface) can allow the interceptor code to be platform independent thus being portable to UNIX based platforms using Apache or similar Web servers. Another embodiment for an Apache server can use the Apache module system.","The event interceptor need not have any configuration file, as the names of the fields to be extracted can be hardcoded in the event interceptor. The code can then be updated whenever new fields need to be extracted using the methods described above. While this may appear to be cumbersome, it is roughly equivalent in effort to updating a configuration file and distributing it to the Web servers.","In one embodiment, a configuration file with a few parameters, such as which server variables to extract, which fields of the cookies to extract, etc., can also be used.","Two mechanisms can be used for detecting the failure of the interceptor. IIS\u2122 itself and the metrics collected from the event tap. The interceptor itself need not perform any detection.","The interceptor can be replaced or restarted along with IIS\u2122, when this is required.","Updates to the filter can be pushed out in the same manner in which Web server configuration changes are pushed out.","The event tap can be a daemon (service on Windows) whose purpose is to drain a queue of events arriving from an extraction interceptor (as described in the previous section). In a typical deployment, this daemon\/service can be part of the standard Web server installation; this service can be running at all times on every Web server.","The general function of the event tap can be to perform:\n\n","The functions can be performed in the same process.","The event tap can receive information about each HTTP event as it occurs, encapsulated in an HttpEvent structure. It can then decide to which worker the incoming HttpEvents must go, batch them up, and periodically load the batches into the database workers nodes.","Processing within the event tap can occur in three stages:\n\n","The transformation stage can turn an HttpEvent into a Tuple.","There need be no explicit API to the event tap. Since it is a daemon, it can be pulling its own input from the FIFO queue where the event interceptor deposits it.","Upon startup, the event tap service can open a FIFO listening endpoint and receive events in this FIFO.","The daemon\/service can read from the FIFO in a nonblocking manner. If, for some reason, the FIFO disappears, it can reestablish the FIFO and wait for the interceptor to reconnect. Note that the event tap need not restart Web servers in order to restart interceptors.","The general structure of the transformation mapping can be:",{"@attributes":{"id":"p-0070","num":"0089"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<MAPPING>"]},{"entry":[{},"\u2003<FUSEACTION>action_1<\/FUSEACTION>"]},{"entry":[{},"\u2003<TRANSFORMATION>"]},{"entry":[{},"\u2003\u2003<FIELD>field_id<\/FIELD>"]},{"entry":[{},"\u2003\u2003<TABLE>table_name<\/TABLE>"]},{"entry":[{},"\u2003\u2003<COLUMN>column_name<\/COLUMN>"]},{"entry":[{},"\u2003\u2003<TYPE>data_type<\/TYPE>"]},{"entry":[{},"\u2003\u2003<PARTITION>string_hash<\/PARTITION>"]},{"entry":[{},"\u2003\u2003<\/TRANSFORMATION>"]},{"entry":[{},"\u2003\u2003<TRANSFORMATION>"]},{"entry":[{},"\u2003\u2003..."]},{"entry":[{},"\u2003\u2003<\/TRANSFORMATION>"]},{"entry":[{},"\u2003..."]},{"entry":[{},"<\/MAPPING>"]},{"entry":[{},"<MAPPING>"]},{"entry":[{},"\u2002<FUSEACTION>action_2<\/FUSEACTION>"]},{"entry":[{},"\u2002..."]},{"entry":[{},"\u2002<\/MAPPING>"]},{"entry":[{},"<MAPPING>"]},{"entry":[{},"\u2003<FUSEACTION>none<\/FUSEACTION>"]},{"entry":[{},"\u2003..."]},{"entry":[{},"<\/MAPPING>"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"A mapping describes which fields of the HttpEvent to transform and how given the fuseAction (or other method identifier) associated with that event. If the HttpEvent carries no fuseAction, then the last segment (marked as \u201cnone\u201d fuseAction) can be used to do the mapping. For the generic example shown above, if the fuseAction field of an incoming HttpEvent was action1, then the transformer can generate a tuple that contains the field_id element of the HttpEvent in the position corresponding to column column_name in table table_name, of type data_type.","The transformation stage can directly invoke the Partition stage and pass it a Tuple object.","The partition state can decide where (for example, which database node worker as expressed through a workerId) to place a given tuple. In one example, a simple hash of the workerId can be done.","The Partition stage can receive a Tuple object from the Transform stage.","This stage can use the partition information from the incoming Tuple to determine how to partition the data. The Transform stage sets this property for the attributes in the Tuple object based on the configuration file. For example, if we have",{"@attributes":{"id":"p-0076","num":"0095"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<MAPPING>"]},{"entry":[{},"\u2003<FUSEACTION>action<\/FUSEACTION>"]},{"entry":[{},"\u2003<TRANSFORMATION>"]},{"entry":[{},"\u2003\u2003<FIELD>sessionId<\/FIELD>"]},{"entry":[{},"\u2003\u2003<TABLE>facts_table<\/TABLE>"]},{"entry":[{},"\u2003\u2003<COLUMN>column_1<\/COLUMN>"]},{"entry":[{},"\u2003\u2003<TYPE>unsigned integer<\/TYPE>"]},{"entry":[{},"\u2003<\/TRANSFORMATION>"]},{"entry":[{},"\u2003<TRANSFORMATION>"]},{"entry":[{},"\u2003\u2003<FIELD>username<\/FIELD>"]},{"entry":[{},"\u2003\u2003<TABLE>table_X<\/TABLE>"]},{"entry":[{},"\u2003\u2003<COLUMN>column_2<\/COLUMN>"]},{"entry":[{},"\u2003\u2003<TYPE>varchar<\/TYPE>"]},{"entry":[{},"\u2003\u2003<PARTITION>string_hash<\/PARTITION>"]},{"entry":[{},"\u2003\u2003<\/TRANSFORMATION>"]},{"entry":[{},"\u2003\u2003<\/MAPPING>"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{},"sub":["\u2014","\u2014"]},"The Partitioner can perform the requisite computation and pass the resulting workerId along with the Tuple to the Load stage.","The algorithm to determine how partitioning occurs (eg., stringhash above) can be a black box to the Transform stage. This algorithm can be provided externally. For one version of the Loader, hash-partitioning can be done; other versions can use more sophisticated partitioning algorithms, depending on query workload. On exemplary algorithm is given in the patent application \u201cSYSTEM AND METHOD FOR JOIN PARTITIONING FOR LOCAL COMPUTABILITY OF QUERY OVER SHARED-NOTHING CLUSTERS\u201d, now U.S. Pat. No. 8,156,107 B2, incorporated herein by reference.","The purpose of the loading stage can be to place batches of collected tuples into worker databases.","The load stage can\n\n","Periodically, the tuple batches can be sent to workers using an open or proprietary library that is specific to the database. Alternatively, one could use open protocols, such as ODBC or JDBC. In one embodiment, once a transmission succeeds, a tuple batch is not used again.","The period of transmission can be chosen with a random distribution between 5 to 15 seconds; the uniform distribution ensures that loads do not synchronize to overload the workers.","There may be instances in which the destination worker is temporarily not available. In this case, the tuple batches can be written to local disk until the worker becomes available again. The Load stage can maintain a separate file for each table at each worker for these purposes.","On occasion, a worker node may be inaccessible for longer than it is intended to keep data at the Web server (e.g., 10 minutes). The effect of this longer inaccessibility is that many events may accumulate in the tap's queues (in memory and\/or on disk) and exhaust available space, as well as the fresh data not being available in the database for analysis. In this case, the Load stage can failover the loading to another worker or a set of workers. In the simplest case, the insertion of tuples can be done to the ((workerId+1) mod n)th worker, where n is the number of total workers; if that worker is not available, then the ((workerId+2) mod n)th worker can be used and so on. The tuples can also be distributed uniformly across all the available workers.","The failedover batches can be written to specially named child tables of the target relations. This allows for easy subsequent identification (with a simple SQL query) and wholesale movement to the proper worker node, once that node recovers.","If a customer chooses to trade some CPU cycles for network bandwidth, then it is possible for the Loader component to compress the tuple batches. With freely available compression, a seven to ten reduction in size can be achieved which results in a corresponding reduction in network bandwidth utilization; with custom application-specific methods, compression rations as high as 300\u00d7 can be achieved. On the receiving side, the data can then be decompressed and inserted into the database.","There are two external side effects for the load stage:\n\n","Disk space can be suitably managed, to ensure proper coexistence with all the other applications running on the same host (most notably IIS\u2122). If running low on disk, the failover algorithm described above can trigger sooner than the timebased threshold.","An exemplary configuration file can be of the form:",{"@attributes":{"id":"p-0090","num":"0114"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"<CONFIG> <MIN_WORKER_IP>10.0.4.1<\/MIN_WORKER_IP>"},{"entry":"\u2003<MAX_WORKER_IP>10.0.4.26<\/MAX_WORKER_IP>"},{"entry":"\u2003<DB_NAME>Beehive<\/DB_NAME>"},{"entry":"\u2003<DB_USER>aster<\/DB_USER>"},{"entry":"\u2003<FAILOVER_POLICY>next_worker<\/FAILOVER_POLICY>"},{"entry":"\u2003<MIN_XMIT_PERIOD_SEC>5<\/MIN_XMIT_PERIOD_SEC>"},{"entry":"\u2003<MAX_XMIT_PERIOD_SEC>15<\/MAX_XMIT_PERIOD_SEC>"},{"entry":"\u2003<HEARTBEAT_PERIOD>30<\/HEARTBEAT_PERIOD>"},{"entry":"<\/CONFIG>"},{"entry":"<MAPPING>"},{"entry":"..."},{"entry":"<\/MAPPING>"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The ISAPI filter, event tap, and configuration file can be deployed on the Preboot Execution Environment (PXE) boot server that is frequently used in large Web farms (for management reasons). Often, IIS\u2122 is restarted by the Network Operations Center (NOC) every time new code is pushed. Whenever the configuration file is changed, it can be pushed out to the Web servers via the customer's preferred mechanism (e g., over CIES). The Load tap service can then be restarted remotely.","Changes to the configuration file can be infrequent.\n\n","Information about the status of the event taps and the progress of loading can be relayed to a central system manager or NOC over regular network connections; such periodic status updates can also count as liveness updates, assuring the human administrator that the system is running well and within parameters. In one embodiment, Logging and Monitoring information can be relayed to the system manager regarding the progress of loading; this can be implicitly a liveness update as well. In one embodiment, at least every 30 seconds, the event tap can provide information on:\n\n","This information can be exposed to the NOC through a standard Web-based interface exported through a system management console.","The system can rely on an updated \u201cseconds since last restart\u201d field of the monitoring update to determine whether the service is up or down. If down, it can then be restarted.","In reaction to the service being down, it can be redeployed by pushing out a code change and restarting the service. Recovery of the event tap can be done via restart.","In one embodiment, the event tap is able to:\n\n","Assuming 150 HTTP requests\/sec to be an average serving rate per Web server with 1 KB of data collected per request, then each server produces 13 GB of event data per day, which can easily be accommodated on the Web servers local storage.","The event tap can be designed to sustain the production of 1,000 tuples\/sec, corresponding to the peak load on the Web server, and insertion of such tuples into the worker DBs without needing to touch disk. Given that tuples are batched, latency is not a concern, as long as it does not exceed the application specific freshness requirements (eg., on the order of minutes or hours for Web analytics).","The foregoing description of preferred embodiments of the present invention has been provided for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise forms disclosed. Many embodiments were chosen and described in order to best explain the principles of the invention and its practical application, thereby enabling others skilled in the art to understand the invention for various embodiments and with various modifications that are suited to the particular use contemplated. It is intended that the scope of the invention be defined by the claims and their equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE FIGURES","p":[{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIGS. 2A-2D"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 3"}]},"DETDESC":[{},{}]}
