---
title: Probabilistic offload engine for distributed hierarchical object storage devices
abstract: A method and system having a probabilistic offload engine for distributed hierarchical object storage devices is disclosed. According to one embodiment, a system comprises a first storage system and a second storage system in communication with the first storage system. The first storage system and the second storage system are key/value based object storage devices that store and serve objects. The first storage system and the second storage system execute a probabilistic algorithm to predict access patterns. The first storage system and the second storage system execute a probabilistic algorithm to predict access patterns and minimize data transfers between the first storage system and the second storage system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09152648&OS=09152648&RS=09152648
owner: SCALITY S.A.
number: 09152648
owner_city: Paris
owner_country: FR
publication_date: 20101209
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The present application claims priority to U.S. Provisional Patent Application Ser. No. 61\/285,019, filed Dec. 9, 2009, which is fully incorporated by reference herein.","The field of the present system and method relates generally to computer storage systems. In particular, the present method and system are directed to a probabilistic offload engine for distributed hierarchical object storage devices.","As storage needs increase, solutions have to be found to drive the cost of storage down while maintaining ease of management. Prior solutions move complex storage management into dedicated storage systems. This saves application servers from embedding storage disks directly, and avoids potential inconveniences such as disk failure, data loss, data reconstruction, etc. This also enables economies of scale by managing a shared pool of storage resources more efficiently. Typical technologies include: SAN, Storage Area Networks where storage is centralized into large dedicated proprietary storage cabinets that export their storage capacity in the form of block device volumes, and NAS, Network Attached Storage where medium-sized storage devices export their disks as network file systems. Object stores that do not follow the centralized architecture design can be deployed on large clusters of generic servers, pushing fault tolerance on the software stack rather than onto dedicated storage hardware.","Because SAN technology is block-based, as opposed to file-based, and slices storage capacity into monolithic volumes, solutions derived from this technology cannot perform storage optimization based on the concept of files or objects. These solutions manipulate small, anonymous binary blobs called blocks with no metadata attached to them. Improvements such as thin provisioning, i.e., over-allocation of storage space for each volume to minimize the need for growing existing volumes have evolved. They, however, do not solve the problem at an architectural level and do not solve the underlying issues. For example, most file systems behave poorly with thin provisioning because the file systems assume that they have infinite space so, they do not reuse past blocks and waste space that cannot be reclaimed online, and they require scheduled maintenance down time.","A method and system having a probabilistic offload engine for distributed hierarchical object storage devices is disclosed. According to one embodiment, a system comprises a first storage system and a second storage system in communication with the first storage system. The first storage system and the second storage system are key\/value based object storage devices that store and serve objects. The first storage system and the second storage system execute a probabilistic algorithm to predict access patterns. The first storage system and the second storage system execute a probabilistic algorithm to predict access patterns and minimize data transfers between the first storage system and the second storage system.","The above and other preferred features, including various novel details of implementation and combination of elements, will now be more particularly described with reference to the accompanying drawings and pointed out in the claims. It will be understood that the particular methods and circuits described herein are shown by way of illustration only and not as limitations. As will be understood by those skilled in the art, the principles and features described herein may be employed in various and numerous embodiments without departing from the scope of the invention.","It should be noted that the figures are not necessarily drawn to scale and that elements of similar structures or functions are generally represented by like reference numerals for illustrative purposes throughout the figures. It also should be noted that the figures are only intended to facilitate the description of the various embodiments described herein. The figures do not delineate every aspect of the teachings described herein and do not limit the scope of the claims.","A method and system having a probabilistic offload engine for distributed hierarchical object storage devices is disclosed. According to one embodiment, a system comprises a first storage system and a second storage system in communication with the first storage system. The first storage system and the second storage system are key\/value-based object storage devices that store and serve objects. The first storage system and the second storage system execute a probabilistic algorithm to predict access patterns and minimize data transfers between the first storage system and the second storage system.","Object stores are reemerging and are placing emphasis on metadata and file awareness in order to allow for intelligence in storage solutions, including file access patterns and domain-specific metadata that can be utilized to implement per-file classes of storage. For example, an e-mail platform using an object store instead of a volume-based approach adds metadata declaring a message as legitimate, undesired, or high priority. The object store uses the metadata to change classes of storage appropriately. For example, the system may maintain one copy of illegitimate messages or keep high-priority messages in a cache for faster access.","The present system and method leverage object access patterns and metadata to achieve an intelligent hierarchical storage management process that automatically moves data between high-cost and low-cost object stores. Working at the object level instead of the block level, allows the linking together of storage systems that are loosely coupled and that do not share the same protocols or underlying storage technologies.","The present system and method provide a distributed replication-based storage front end acting as a caching layer and a probabilistic offload engine and an information dispersal-based storage back-end acting as a long-term, high-capacity storage layer. The present system leverages high-performance characteristics such as IOPS (IO operation per second) and throughput of replication-based storage. The present system benefits from lower cost, low-capacity overhead, and the flexibility of information dispersal solutions. The present system is transparent to the using application.","The present system relates to a device that can be seen as an HSM (hierarchical storage management) device or a cache device between a first layer called the Tier-1 and a secondary layer called the Tier-2. When configured as an HSM device, Tier-1 is the front layer and Tier-2 is the back layer. Data is off-loaded (or evicted) from Tier-1 to Tier-2 and uploaded from Tier-2 to Tier-1. Data can be probabilistically prefetched from Tier-2 to Tier-1. When configured as a cache device, Tier-1 is the cache layer and Tier-2 is the backing store layer. Data is evicted from Tier-1 to Tier-2 or replaced from Tier-1 (removed because already present on Tier-2). Moving data from Tier-2 to Tier-1 populates the cache. Data can be also probabilistically prefetched to the cache.","In the following description, for purposes of explanation, specific nomenclature is set forth to provide a thorough understanding of the various inventive concepts disclosed herein. However, it will be apparent to one skilled in the art that these specific details are not required in order to practice the various inventive concepts disclosed herein.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 1","b":["101","103","104","102","108","106","103","107","109","111","110","114","116","113","115","103","113","115","104","105","112","108","114","116","111","110","117"]},"Accessor  accesses Tier-1 with a REST (Representational State Transfer) protocol that supports three basic operations: GET, PUT, DELETE. This protocol is bridged to various other protocols required by applications such as HTTP, HTTPS (Secure Hypertext Transfer Protocol), WebDAV (Web-based Distributed Authoring and Versioning), or FUSE (File system in User Space). Accessor  can be a message storing platform, Web server and other service that requires storage of a very large number of objects.","Tier-1 acts as a cache layer and has to be fast. Accordingly, Tier-1 is equipped with memory and fast local disks. Memory is suited for caching a maximum number of objects (typically through the file system cache), and the disk provides a maximum number of I\/O operations, maximum throughput, and very low latency (for example, 15K RPM, 73 GB disks). Tier-1 is based on a suitable replication-based storage cluster. A replication-based storage cluster is a set of storage nodes where applications store different backups of the same data. Each one of these backups is called a replica. Replication-based systems are fast because no attempt is made to compress and disperse objects. Instead, for ensuring data safety, objects are replicated. Unit operations of Tier-1 are PUT, GET, and DELETE, which respectively save objects, retrieve objects, and delete objects. Such a Tier-1 cluster could be implemented by using a consistent hashing ring, for example but not limited to, a Chord based network as described in \u201cChord: A Scalable Peer-to-peer Lookup Service for Internet Applications\u201d by Ion Stoica, Robert Morris, David Karger, M. Frans Kaashoek, Hari Balakrishnan herein incorporated by reference.","Tier-2  can be any storage technology: SAN\u2014Storage Area Network; Dispersed Storage Systems that might embed low-cost SATA disks; iSCSI; NFS; or other distributed storage systems (e.g., a consistent hashing ring or a Chord-based storage system) but is usually composed of much less expensive disks of larger capacity. Generally, Tier-2 storage systems  modifies an object's content to increase disk usage efficiency, (e.g., with compression) or to increase data safety, by dispersion (with IDA\u2014Information Dispersal Algorithms). Unit operations of Tier-2  are PUT, GET, and DELETE and are implemented according to secondary storage media. For example, when secondary storage is mounted as an iSCSI or an NFS volume, PUT, GET, and DELETE operations are mapped to traditional POSIX file system operations. PUT, GET, and DELETE are particularly well mapped to Dispersed Storage Systems operations.","Both of these systems have scalability issues: Tier-1 is fast but wastes disk space; Tier-2 has high capacity but is generally slow. The present system bridges the two systems by using the present probabilistic and non-probabilistic algorithms along with synchronization protocols. As a result, to increase storage performance, nodes are added to Tier-1. To increase storage capacity, nodes are added to Tier-2. Their integration is seamless for accessor  and applications , which will see infinite storage capacity. Although this method is presented for sake of simplicity between one Tier-1 and one Tier-2, any number of storage layers from Tier-n to Tier-n+1 may be used. Accessors typically communicate with Tier-1, but any number of Tiers can be chained together and remain transparent to the application.","Objects are used for an application's persistent data storage. For example, office and multimedia applications that save the current work\/state of the user may do so using objects. Historically these data were directly stored as named files on the local disks of the application computers. These files were stored in directories belonging to file hierarchies installed on the local disks. Now applications and storage need not reside on the same disks nor on the same computer. The historical naming conventions are not necessary anymore, nor is it required to store files in directories. For example, files could be indexed with numbers (keys) in a database and an application with a specific connector (for example, using HTTP\u2014Hypertext Transfer Protocol or any other suitable protocols) could fetch files directly with key\/value database methods. Also, because each application decides the binary data structure of the file and relies on the fact that it will retrieve exactly the same binary information as the time it stored it, the file can be seen as an opaque binary object by the various system components used for saving the file on persistent storage. The historical concept of a named file is not necessary for an application to access its persistent data.","The storage systems used for storing objects bound to keys are often named key\/value store systems, and applications use keys to store and fetch object values (content). The goal of key\/value store systems is to achieve the best performance in terms of data availability, access speed, and safety. Because key\/value store systems view the entire content of objects, it is possible to perform transformations on them. For example, CRCs (Cyclic Redundant Checks), replication, compression, encryption, dispersion, packing, etc. may be performed.","A datum is identified with a unique tag (a key) and is bound to two objects: one data object and one additional metadata object that composes a 3-tuple (tag, datum, metadata) henceforth called a chunk. Metadata is a set of property (or a vector of variates) annotated X, which properties are annotated X{name of property}, such as datum access time: X{atime}; datum modification time: X{mtime}; metadata change time: X{ctime}; datum size: X{size}; chunk version: X{version}; chunk archive id: X{archid}; chunk archived version: X{archversion}; current status: X{status}. The special property X{status} can take a combination of the following values: \u201cdeleted,\u201d \u201carchived,\u201d \u201ccached.\u201d \u201cDeleted\u201d means a chunk is scheduled for physical deletion. \u201cArchived\u201d means datum could be removed from Tier-1 but datum is present in Tier-2 with X{archversion} equal to X{version}. \u201cCached\u201d means datum is present both in Tier-1 and Tier-2 (\u201ccached\u201d implies chunk is \u201carchived\u201d). Cached chunks may be chunks with \u201ccached\u201d status, and archived chunks may be chunks with \u201carchived\u201d status. The present system also includes support for additional objects bound to a tag and can be expanded to an n-tuple: (tag, obj1, obj2, objn) where obj1 is data, obj2 is metadata, obj3 is e.g., user metadata, etc.","The offload engine ensures object synchronization between Tier-1 and Tier-2. If a datum object of a chunk is requested on Tier-1 and it is present on Tier-2 (because it has been previously off-loaded) then the offload engine fetches it from Tier-2 transparently. If a re-write occurs on a chunk in a Tier-1 corresponding datum object in Tier-2, an update may also occur. If a chunk deletion occurs on Tier-1, then the corresponding objects in Tier-2 (if they exist) are also deleted.","The offload engine ensures synchronization between all replicas of chunks (in Tier-1) including all replicas that have the same content. For example, if a datum object of a chunk has been evicted to Tier-2, then other replicas shall be notified and they will update their own metadata. Due to various system failures, there might be some differences in various objects among the replicas of a chunk, for some period of time. The present system, however, ensures that objects content is reconciled.","For ensuring synchronization, the metadata object of chunks remains in Tier-1. Even if the metadata object is a few bytes, Tier-1 nodes are able to keep a very large number of objects (of the order of magnitude of a billion per node). The present system ensures such an order of magnitude, for example, by using a database with ACID\u2014Atomicity, Consistency, Isolation, Durability properties.","Typically a system administrator will specify an eviction ratio (for example, 30%) that ensures that 70% of Tier-1's disk space is being used. To satisfy this requirement on a distributed system with nodes having possibly various disk spaces, a probabilistic algorithm is used. The offload engine also includes non-probabilistic algorithms to satisfy other requirements. For example, one requirement may be that all new datum objects entered in Tier-1 shall be off-loaded on Tier-2 in a limited period of time. In such a case, the offload engine uses queues. The system administrator is able to configure the type of operations of the storage system.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 2","b":["102","201","202","203","102","204","205","206","207","208","209","210"]},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 3","b":["102","102","301","302","303","102","304","305","306","307","308","309","310","311"]},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 4","b":["102","401","402","408","102","403","404","405","406","407","409","410","411","412","413"]},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 5","b":["102","501","502","508","102","503","502","504","505","506","507","502","509","510","511","512","513","514"]},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 6","b":["102","601","602","603","102","604","605","606","607","608","102","609","610","611"]},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 7","b":["102","701","702","703","102","704","705","706","707","708","709","102","710","711","712"]},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 8","b":["102","801","802","803","102","804","805","806","807","808","809","810","811","812","102","813","814","815"]},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 12","b":["1201","1202","1203","102","1204","1205","1206","1207","1208"]},"To manage disk space, when disk space becomes full (or reaches a predetermined ratio) Tier-1 starts off-loading data to Tier-2, and when disk space is underutilized, Tier-1 prefetches or caches data from Tier-2. When dealing with a huge number of objects, it is impossible to correlate metadata; instead a probabilistic approach is used.","If the most recent data were kept, if data access was roughly uniform, and if the bounds (atimemin, atimemax) of the access time variate X{atime} are known, it would be easy to estimate the probability that the datum would remain in Tier-1. Eviction ratio is the percentage of data to evict from the disks of Tier-1.",{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 18","b":"1801"},"For each window the total size of chunks in a window is maintained",{"@attributes":{"id":"p-0058","num":"0057"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["s","W"]},"mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"0"},"mi":"n"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"X","mo":"\u2062","mrow":{"msub":{"mrow":{"mo":["{","}"],"mi":"size"},"mi":"i"},"mo":"."}}}}}},"br":{},"sub":["WT ","WT","W"],"b":"1802"},"Once the window is constituted, chunks composing the window are sorted by their fair-values . The choice of the operation to perform on chunks is determined by using an ECDF\u2014Empirical Cumulative Distribution Function\u2014based upon the window W: If the window is large enough it accurately represents the average access patterns of all chunks contained in the storage system. Let Xi be random chunks taken over the total chunks of the system, and X{size}i be their size, then",{"@attributes":{"id":"p-0060","num":"0059"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"ECDF","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"v"}},{"mrow":[{"mo":["(",")"],"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"X","mo":"\u2062","mrow":{"msub":{"mrow":{"mo":["{","}"],"mi":"size"},"mi":"i"},"mo":"\u00b7","mrow":{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["X","i"]},"mo":"\u2264","mi":"v"}}}}}}},{"mo":["(",")"],"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"X","mo":"\u2062","msub":{"mrow":{"mo":["{","}"],"mi":"size"},"mi":"i"}}}}],"mo":"\/"}],"mo":"="}}},"br":{},"sub":"i"},{"@attributes":{"id":"p-0061","num":"0060"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["s","W"]},"mo":"\u00b7","mi":"evictionthreshold"},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"0"},"mi":"j"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"X","mo":"\u2062","msub":{"mrow":{"mo":["{","}"],"mi":"size"},"mi":"i"}}}],"mo":"\u2248"}}},"br":{},"b":"1804"},"Once fvdiscr is computed, the archive process starts processing other chunks on the system. The off-loader process iterates all the chunks Xi of the system and computes their fair-value fvi  and compares it to the discriminant value fvdiscr . If fvi is less than fvdiscr, then the chunk is evicted to Tier-2 (or replaced) . If fvi is approximately equal to fvdiscr, it leads to a status quo or a noop (no operation). In this case the chunk status remains unchanged . If fvi is greater than fvdiscr, then the chunk is kept on Tier-1 . The same window is reused for some number of chunks (chosen empirically) . After some time (also chosen empirically) the window is reconstituted .","The fair-value is a floating point indicator that provides an approximate decision on an operation to apply on a chunk. For example: \u22123 or less=off-load right now, \u22122=should probably be off-loaded, \u22121=may be off-loaded, 0=neutral, 1=seems to be wise to keep it, 2=should probably be kept, 3 or more=no offload. It is computed with the following calibration function:",{"@attributes":{"id":"p-0064","num":"0063"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["fv","i"]},"mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"c","mo":"=","mn":"0"},"mi":"C"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["w","c"]},"mo":"\u00b7","mrow":{"msub":{"mi":["calibrate","c"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["X","i"]}}}}}}}},"br":{},"sub":"c "},"One of the most important variates involved in the computation of the fair-value is the CRF\u2014Combined Recency and Frequency\u2014described in LRFU and stored in the X{crf} variate. It is a floating point value calculated from access patterns of the chunk. The more recently and the more frequently the chunk is used, the higher this value will be. It uses an exponential approach to keep track of the history of access. It is possible to specify the weight of frequency over recency in a CRF calculation by specifying the time in seconds when an access will lose half of its importance. An access being this old will have half of its initial significance. An access being twice this old means it has a quarter of its initial significance, etc.). With curtime corresponding to the current time, for each chunk Xi a fair-value calibration is computed based upon an actuation of the CRF at curtime:",{"@attributes":{"id":"p-0066","num":"0065"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["curcrf","i"]},"mo":"=","mrow":{"msup":{"mi":"\u2147","mrow":{"mrow":[{"mo":"-","mfrac":{"mrow":{"mi":"ln","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"},"mi":"\u03bb"}},{"mo":["(",")"],"mrow":{"mi":"curtime","mo":"-","mrow":{"mi":"X","mo":"\u2062","msub":{"mrow":{"mo":["{","]"],"mi":"atime"},"mi":"i"}}}}],"mo":"\u00b7"}},"mo":["\u00d7","\u2062"],"mi":"X","msub":{"mrow":{"mo":["{","}"],"mi":"crf"},"mi":"i"}}}}},"br":{}},{"@attributes":{"id":"p-0067","num":"0066"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"X","mo":"\u2062","msub":{"mrow":{"mo":["{","}"],"mi":"crf"},"mi":"i"}},{"mrow":{"msup":{"mi":"\u2147","mrow":{"mrow":[{"mo":"-","mfrac":{"mrow":{"mi":"ln","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"},"mi":"\u03bb"}},{"mo":["(",")"],"mrow":{"mi":"curtime","mo":"-","mrow":{"mi":"X","mo":"\u2062","msub":{"mrow":{"mo":["{","]"],"mi":"atime"},"mi":"i"}}}}],"mo":"\u00b7"}},"mo":["\u00d7","\u2062"],"mi":"X","msub":{"mrow":{"mo":["{","}"],"mi":"crf"},"mi":"i"}},"mo":"+","mn":"1."}],"mo":"\u2190"}}},"br":{},"sub":"i "},"The function crftofv( ) is the calibration function calculated from the CRF and is designed to transform the CRF as follows: a CRF of 100 will generate an indication of 3 (meaning no offload), a CRF of 0.18 will generate an indication of 0 (neutral), and a CRF of 10^-8 will generate an indication of \u22123 (offload right now). A scale is chosen for log(CRF) to be equivalent to log(number of hits) for a big CRF and log(log(CRF)) to be equivalent to log(age) for a small CRF (since the CRF is decreasing exponentially with time), hence the formula:",{"@attributes":{"id":"p-0069","num":"0068"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"crftofv","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"crf"}},{"mfrac":{"mn":"1","mi":"\u03b3"},"mo":"\u00b7","mrow":{"mi":"ln","mo":"\u2061","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"msup":{"mi":"\u2147","mrow":{"mi":["\u03b3","crffairmin"],"mo":"\u00b7"}},"mo":"+","mrow":{"mrow":{"mo":["(",")"],"mrow":{"msup":[{"mi":"\u2147","mrow":{"mrow":{"mi":["\u03b3","crffair"],"mo":"."},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}},{"mi":"\u2147","mrow":{"mi":["\u03b3","crffairmin"],"mo":"."}}],"mo":"-"}},"mo":"\u00b7"}}}},{"mtd":{"msup":{"mi":"\u2147","mrow":{"mi":"\u03b3","mo":"\u00b7","mrow":{"msub":{"mi":["log","base"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mi":"crf","mrow":{"mi":"crfval","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}}}}}}}]}}}}],"mo":"="}}},"br":{}},"The function sizetofv( ) is a calibration function computed to take the chunk size into account with the idea that small chunks shall be kept in Tier-1 while big chunks shall be evicted as usual. The function is designed to perform as follows: a size of 10 KB will generate an indication of 3 (meaning no offload); a size of 400 KB will generate an indication of 0 (neutral); a size of 4.5 MB will generate an indication of \u22122 (should probably be off-loaded).","Scale is chosen to be \u2212log(size), hence the formula: sizeiofv(size)=(sizefair2\u2212sizefair1)\u00b7(ln(X{size}\/sizeval1))\/(ln(sizeval2\/sizeval1)) where (sizeval1,sizefair1) and (sizeval2,sizefair2) are matching tuples.","Other calibration functions that influence the fair-value may be by some statistical behavior analysis done upstream of the storage. It is possible to detect some usage patterns, e.g., to improve service to some VIP users by systematically keeping their files in Tier-1, or to never keep files with a specific marker in Tier-1 (e.g., files stored for pure archival purpose, etc.).",{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 9","b":["102","901","902","909","903","904","905","906","907","908","910","911","912","913","914","915"]},{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 10","b":["1001","1002","1003","1004","1005","1006","1007","1008","1009","1010","1011","1012","1013","1014","1011","1015"]},{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 11","b":["1101","1102","1103","1104","1105","1106","1107","1108","1109","1110","1111","102","1112","1113","1114","1115","102","1116","1117","1118"]},"In HSM mode, write back and read back modes are used. Datum objects are removed from Tier-1 once they have been off-loaded to Tier-2 and removed from Tier-2 when they have been uploaded to Tier-1. In cache mode, write cache and read cache are used. Datum objects are always kept in Tier-2 and could be or not be in Tier-1. It is possible to combine some operation modes. For example, in a message store deployment, a combination of queued write cache and probabilistic write back modes is used. All new messages are backed up on Tier-2 after, for example, 24 h, but additionally a background process will empty or populate the cache depending on available disk space and users' needs.","When an operation fails, the behavior will be different according to the type of operation. In the case of a write through or a write cache mode, Tier-1 PUT will fail. In other modes\u2014for example, queued write cache, queued write back, or probabilistic write back\u2014accessor  has no further information on the behavior of the overall operation. The chunk is stored locally in a queue on Tier-1, and any operation on the chunk is retried until it is successful on Tier-2.","Tier-1 can gracefully handle the write load when Tier-2 is unavailable. Typically, for a message store system it can be a few days. This delay depends on write load and available disk space on Tier-1 nodes. If data is no more present in Tier-1 (archived), data won't be available for reading during Tier-2 downtime. As a result of the software architecture, recent objects (messages, documents) will be available. As a result of LRFU, popular objects will remain available.","Generally, Tier-2 systems are more efficient with large chunks, (e.g., when storing electronic mail messages). Average sizes might be 50 KB, but an efficient size for a Dispersed Storage System would realistically be around 4 MB. For this reason, the present system includes a mechanism for packing chunks. Instead of chunks being sent directly to Tier-2, they are sent to a temporary queue that will be packaged into various file formats (UNIX tar archive, itself optionally packed using popular compression format, e.g., GZIP, LZMA) and finally sent. In this case, the accessor confides deterministic control of the chunk stored on Tier-1, using in queue write cache, queue write back, and probabilistic write back modes. Failures that occur when putting archives on Tier-2 are retried. For each pack file (archive) that is created, a specific information chunk named \u201carchive chunk\u201d is created in the Tier-1. This is useful to keep track of archives. Tier-1 does not directly delete chunks from Tier-2 but logs delete operations into the \u201carchive chunk.\u201d Archives are relocated when too many chunks are marked as deleted within an archive chunk.","The present system also addresses the problem of multiple data centers, which is crucial in the context of professional offerings over the Internet, especially for Internet service providers and large Web merchants. They require that storage systems survive one or more data center crashes. In the present system, Dispersed Storage Systems are used to store information on Tier-2. The storage is naturally dispersed, rack aware, and data center aware; metadata information is replicated on the Tier-1.",{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 14","b":["102","1401","1402","1403","1404","1405","1406","1407","1408","1409","1410","1411","1412","1413","1414","1415","1416"]},"Consistent hashing ring based storage systems address the problem of scalability by spreading the load among a huge number of servers, especially with Chord based storage systems, a sophisticated overlay routing protocol over a consistent hashing algorithm.","According to one embodiment, a consistent hashing ring used as a storage device uses a transactional approach that guarantees ACID properties on the object store. Failover capability guarantees data availability when a storage node fail.","The use of consistent hashing makes it possible not to disrupt the network topology when adding or removing nodes, reducing data movement. The current approach of tiered storage improves the usage of consistent hashing. If due to hashing, a Tier-1 node is more heavily loaded than others, then its eviction threshold will also be higher than the others.","When re-writing data is overridden, the variates X{version} is incremented. While putting, the system's behavior is similar as for a new chunk. Version reconciliation is done by accessor  when reading all the metadata of a chunk (through reserve calls), or by a rebuild mechanism.",{"@attributes":{"id":"p-0086","num":"0085"},"figref":"FIG. 16","b":["1601","1602","1603","1604","1605","1606"]},{"@attributes":{"id":"p-0087","num":"0086"},"figref":"FIG. 15","b":["1501","1502","1503","1504","1505"]},"In the context of a mutable object store and when proxies are set, reserve operations perform a CHECK_LOCAL in all cases even if the chunk is present on the storage node, because a chunk with more recent X{version} could reside on the proxy node. In the same manner, storage nodes sending GET_LOCAL operations update their data when they detect a more recent version on the proxy.","The \u201coriginal\u201d replicas (numbered 0) of chunks are treated for off-loading. When replica 0 is missing, it will be rebuilt and off-loaded later. When a chunk is off-loaded, the variates X{version} is incremented. This implies replicas will be rebuilt with new metadata particularly X{archid} and X{archversion} for fetching data on Tier-2.",{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 13","b":["1303","1301","1302","1304","1305","1306","1307","1308","1309"]},{"@attributes":{"id":"p-0091","num":"0090"},"figref":"FIG. 17","b":["1701","1702","1703","1704","1705","1706","1","2","1707","1708","1709","1710","1711"]},"Some portions of the detailed descriptions are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to convey most effectively the substance of their work to others skilled in the art. An algorithm is here, and generally, conceived to be a self-consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually\u2014though not necessarily\u2014these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like.","It should be borne in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussion, it is appreciated that throughout the description, discussions utilizing terms such as \u201cprocessing\u201d or \u201ccomputing\u201d or \u201ccalculating\u201d or \u201cdetermining\u201d or \u201cdisplaying\u201d or the like refer to the action and processes of a computer system, or similar electronic computing device, that manipulates and transforms data represented as physical (electronic) quantities within its registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission, or display devices.","Some embodiments of the invention also relate to apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes, or it may comprise a general-purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer-readable storage medium, such as, but not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, or any type of media suitable for storing electronic instructions, and each coupled to a computer system bus.","The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general-purpose systems may be used with programs in accordance with the teachings herein, or it may prove convenient to construct more specialized apparatus to perform the required method steps. The required structure for a variety of these systems will appear from the description below. In addition, the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.","Reference in the specification to \u201cone embodiment\u201d or \u201can embodiment\u201d means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus, the use of the phrase \u201cin one embodiment\u201d in various places throughout the specification does not necessarily always refer to the same embodiment. Likewise, the use of the phrases \u201cin another embodiment\u201d and \u201cin an alternate embodiment\u201d in various places throughout the specification does not necessarily always refer to the same embodiment.","A method and system having a probabilistic offload engine for distributed hierarchical object storage devices have been disclosed. It is understood that the embodiments described herein are for the purpose of elucidation and should not be considered to limit the subject matter of the disclosure. Various modifications, uses, substitutions, combinations, improvements, and methods of productions without departing from the scope or spirit of the present invention would be evident to a person skilled in the art."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF FIGURES","p":["The accompanying drawings, which are included as part of the present specification, illustrate the currently preferred embodiment of the present invention and, together with the general description given above and the detailed description of the preferred embodiment given below, serve to explain and teach the principles of the present invention.",{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 18"}]},"DETDESC":[{},{}]}
