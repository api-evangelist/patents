---
title: System and method for a hierarchical Bayesian-map approach for solving inverse problems
abstract: A method of reconstructing an image of an object, the method including: determining, by a plurality of sensors, a waveform based on the object, wherein the plurality of sensors view the object from a plurality of directions; determining, by a pre-processing module, a plurality of measurements of the object using the waveform, wherein the plurality of measurements are arranged in a vector form; determining, by an option module, a sampling matrix, a dictionary, and a noise factor, wherein the sampling matrix represents a geometric arrangement of the plurality of sensors, and the dictionary is pre-selected by the option module; estimating, by an estimation module, a coefficient vector using the measurements, the sampling matrix, and the noise factor; and reconstructing, by a reconstruction module, the image, using the coefficient vector and the dictionary.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09613439&OS=09613439&RS=09613439
owner: The United States of America, as represented by the Secretary of the Navy
number: 09613439
owner_city: Washington
owner_country: US
publication_date: 20151016
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["GOVERNMENT INTEREST","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The embodiments described herein may be manufactured, used, and\/or licensed by or for the United States Government without the payment of royalties thereon.","Technical Field","The embodiments herein relate to imaging, and more particularly to reconstructing images using one or more sensors.","Description of the Related Art","Imaging refers to a class of inverse problems wherein the central objective is to form the image of an object or scene of interest that is typically being sensed by one more sensors each furnishing complementary but correlated sources of information, and each of which is potentially contaminated by noise and distortion. What distinguishes this from the more general class of inverse and regression problems is that images originating from typical empirical sources (such as natural images) have a special structure that makes it possible to inject informed prior models into the inference process that can enhance the quality of the reconstructed image. Accordingly, a wide variety of analytical and statistical approaches have proliferated over the past several decades in diverse imaging applications such as radar, medical, and astronomical imaging.","In view of the foregoing, an embodiment herein provides a method of reconstructing an image of an object, the method comprising: determining, by a plurality of sensors, a waveform based on the object, wherein the plurality of sensors view the object from a plurality of directions; determining, by a pre-processing module, a plurality of measurements of the object using the waveform, wherein the plurality of measurements are arranged in a vector form; determining, by an option module, a sampling matrix, a dictionary, and a noise factor, wherein the sampling matrix represents a geometric arrangement of the plurality of sensors, and the dictionary is pre-selected by the option module; estimating, by an estimation module, a coefficient vector using the measurements, the sampling matrix, and the noise factor; and reconstructing, by a reconstruction module, the image, using the coefficient vector and the dictionary.","The estimating the coefficient vector may comprise computing, by a first variable module: a first variable, using a pre-selected non-linear factor; and a multi-scale Gaussian tree structure, using a quad-tree decomposition of the image, the sampling matrix, the dictionary, and the measurements. Estimating the coefficient vectors may further comprise: estimating, by a parameter module, a structural parameter based on a parent-child relationship for each node in the tree structure; repeating, by a loop module: the computing of the first variable and the multi-scale Gaussian tree structure, and the estimating of the structural parameter, across the tree structure, until the structural parameter is lower than a first pre-selected threshold. The estimating the coefficient vectors may thrther comprise: computing, by a second variable module, a second variable based on the first variable, the sampling matrix, a variable selection operator, and a second pre-selected threshold; and computing, by a coefficient module, the coefficient vector based on a Hadamard product of the first variable and the second variable.","Estimating the coefficient vector may comprise: initializing, by the estimation module, x=|h(\u03a8y)| and n=0, wherein xis an initial approximation of a temporary parameter, h is a nonlinear factor, \u03a8 is the sampling matrix, y is a vector comprising the measurements, and n is a loop counter; calculating, by the estimation module, a descent direction d; determining, by the estimation module, a step size \u03bb; and computing, by the estimation module, x=x+\u03bbd, wherein xis an napproximation for the temporary variable and xis an (n+1)approximation for the temporary variable.","The method may further comprise: incrementing, by the estimation module, the loop counter n; computing, by the estimation module, x*, by repeating the calculating the descent direction d, the determining the step size \u03bb, the computing x, and the incrementing the loop counter n until a norm of a steepest descent vector is smaller than a pre-selected threshold, wherein x* is a temporary variable. The method may further comprise: computing, by the estimation module, z*=h(x*); calculating, by the estimation module, =diag(S[z*]) and \u039b=diag (z*), where",{"@attributes":{"id":"p-0011","num":"0010"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["S","\u03bb"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}}},{"mo":"{","mrow":{"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mrow":{"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":">","mi":"\u03bb"}}]},{"mtd":[{"mn":"0"},{"mrow":{"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":"\u2264","mi":"\u03bb"}}]}]},"mo":";"}}],"mo":"="}}}},"br":{},"sup":["\u22121","T","\u22121","\u22121","\u22121","\u22121","T","\u22121 ","m ","n ","n ","d\u00d7n "],"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00002","he":"3.22mm","wi":"3.56mm","file":"US09613439-20170404-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00003","he":"2.79mm","wi":"2.46mm","file":"US09613439-20170404-P00002.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00004","he":"2.79mm","wi":"2.46mm","file":"US09613439-20170404-P00002.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00005","he":"2.79mm","wi":"2.12mm","file":"US09613439-20170404-P00003.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00006","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00004.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00007","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00005.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00008","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00006.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}],"sub":["v","L","u","L","R ","v"]},"Another embodiment herein provides an imaging device comprising: a plurality of sensors configured to generate a waveform based on an object; a pre-processor configured to determine a plurality of measurements using the waveform, wherein the plurality of measurements are arranged in a vector form; and a central imaging device comprising: an option module configured to determine a sampling matrix, a pre-selected dictionary, a pre-selected non-linear factor, a first pre selected threshold, a second pre-selected threshold, and a noise factor, wherein option module determines the sampling matrix using a geometric arrangement of the plurality of sensors; an estimation module configured to estimate a coefficient vector using the plurality of measurements, the sampling matrix, and the pre-selected dictionary; and a reconstruction module configured to reconstruct an image of the object, using the coefficient vector and the pre-selected dictionary.","The estimation module may further comprise: a first variable module configured to: compute a first variable using a pre-selected non-linear factor; and determine a multi-scale Gaussian tree structure using a quad-tree decomposition of the electronic source image model, the sampling matrix, the pre-selected dictionary, and the measurements. The estimation module may further comprise: a parameter module configured to determine a structural parameter using a parent-child relationship for each node in the multi-scale Gaussian tree structure; and a loop module configured to control operation of the first variable module and the parameter module across the multi-scale Gaussian tree structure until the structural parameter is lower than the first pre-selected threshold. The device may further comprise: a second variable module configured to determine a second variable using the first variable, the sampling matrix, the variable selection operator and the second pre-selected threshold; and a coefficient module configured to determine the coefficient vector using a Hadamard product of the first variable and the second variable.","The estimation module may be further configured to: initialize x=|h(\u03a8y)| and n=0, wherein xis an initial approximation of a temporary parameter, h is a nonlinear factor, \u03a8 is the sampling matrix, y is a vector comprising the measurements, and n is a loop counter; calculate a descent direction d; determine a step size \u03bb; and compute x=x+\u03bbd, wherein xis an napproximation for the temporary variable and xis an or (n+1)approximation for the temporary variable. The estimation module may be further configured to: increment the loop counter n; compute x* by repeating the calculating the descent direction d, the determining the step size \u03bb, the computing x, and the incrementing the loop counter n until a norm of a steepest descent vector is smaller than a pre-selected threshold. The estimation module may be further configured to: compute z*=h(x*); calculate =diag(S[z*]) and \u039b=diag(z*) where",{"@attributes":{"id":"p-0015","num":"0014"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["S","\u03bb"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}}},{"mo":"{","mrow":{"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mrow":{"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":">","mi":"\u03bb"}}]},{"mtd":[{"mn":"0"},{"mrow":{"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":"\u2264","mi":"\u03bb"}}]}]},"mo":";"}}],"mo":"="}}}},"br":{},"sup":["\u22121","T","\u22121","\u22121","\u22121","\u22121","T","\u22121 ","m ","n ","n ","d\u00d7n "],"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00010","he":"3.22mm","wi":"3.56mm","file":"US09613439-20170404-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00011","he":"3.22mm","wi":"3.56mm","file":"US09613439-20170404-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00012","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00007.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00013","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00008.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00014","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00009.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00015","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00010.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}],"sub":["v","L","u","L","R ","v"]},"Another embodiment provides a non-transitory program storage device readable by computer, tangibly embodying a program of instructions executable by the computer to perform a method for reconstructing an image of an object, the method comprising: detemining, by a plurality of sensors, a waveform based on the object, wherein the plurality of sensors view the object from a plurality of directions; determining, by a pre-processing module, a plurality of measurements of the object using the waveform, wherein the plurality of measurements are arranged in a vector form; determining, by an option module, a sampling matrix, a dictionary, and a noise factor, wherein the sampling matrix represents a geometric arrangement of the plurality of sensors, and the dictionary is pre-selected by the option module; estimating, by an estimation module, a coefficient vector using the measurements, the sampling matrix, and the noise factor; and reconstructing, by a reconstruction module, the image, using the coefficient vector and the dictionary.","Estimating the coefficient vector may comprise computing, by a first variable module a first variable, using a pre-selected non-linear factor; and a multi-scale Gaussian tree structure, using a quad-tree decomposition of the image, the sampling matrix, the dictionary, and the measurements. Estimating the coefficient vectors may further comprise: estimating, by a parameter module, a structural parameter based on a parent-child relationship for each node in the tree structure; repeating, by a loop module: the computing of the first variable and the multi-scale Gaussian tree structure, and the estimating of the structural parameter, across the tree structure, until the structural parameter is lower than a first pre-selected threshold. Reconstructing the image may further comprise using global compound Gaussian model as a statistical prior. Reconstructing the image may further comprise using hierarchical Bayesian maximum a posteriori and using global compound Gaussian model as a statistical prior.","These and other aspects of the embodiments herein will be better appreciated and understood when considered in conjunction with the following description and the accompanying drawings. It should be understood, however, that the following descriptions, while indicating preferred embodiments and numerous specific details thereof, are given by way of illustration and not of limitation. Many changes and modifications may be made within the scope of the embodiments herein without departing from the spirit thereof, and the embodiments herein include all such modifications.","The embodiments herein and the various features and advantageous details thereof are explained more fully with reference to the non-limiting embodiments that are illustrated in the accompanying drawings and detailed in the following description. Descriptions of well-known components and processing techniques are omitted so as to not unnecessarily obscure the embodiments herein. The examples used herein are intended merely to facilitate an understanding of ways in which the embodiments herein may be practiced and to further enable those of skill in the art to practice the embodiments herein. Accordingly, the examples should not be construed as limiting the scope of the embodiments herein.","The embodiments herein provide a Hierarchical Bayesian-MAP (Maximum a Posteriori) method for solving inverse problems. An embodiment herein reconstructs an image that is viewed from multiple directions by independent sensors, subject to a global Compound Gaussian (CG) prior placed on the signal to be estimated. An embodiment herein approaches this inverse problem in imaging based on a Hierarchical Bayesian-MAP (HB-MAP) formulation. An embodiment herein describes the basic inverse problem of multi-sensor (tomographic) imaging. Given the measurements recorded by the sensors, a problem may be reconstructing the image with a high degree of fidelity. An embodiment uses a Probabilistic Graphical Modeling extension of the CG distribution as a global image prior into a Hierarchical Bayesian inference procedure. In an embodiment, the global CG model incorporated within the HB-MAP inference procedure is used for solving inverse problems and imaging. The HB-MAP algorithm solves a difficult non-convex optimization problem. The Monte-Carlo simulations, described herein, show that that this approach works for over a broad range of conditions\u2014high and low sparsity cases\u2014whereas Comprehensive Sensing (CS) and sparsity based approaches work only for high-sparsity cases. An embodiment herein provides a way to utilize the global CG model which subsumes the Laplacian\u2014the basis of compressive sensing and many other statistical models\u2014for solving, difficult inverse problems such as imaging. An embodiment herein represents a numerical-technological advancement to realize the application of global CG models for imaging in practice. Embodiments herein can be used for radar imaging (SAR, ISAR etc.), medical imaging, and a broad class of inverse problems involving empirically derived data sources.","Referring now to the drawings, and more particularly to , where similar reference characters denote corresponding features consistently throughout the figures, there are shown preferred embodiments.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 1","b":["100","100","150","152","154","100","156","156","158","160","156"]},"An embodiment herein provides optimum image reconstruction conditioned on the aforementioned pre-processing operations. An effective forward model can be captured by the following linear system model:\n\n\u2003\u2003(1)\n\nwhere:\n\n","An embodiment herein solves equation (1) by estimating the coefficient vector c given the observed measurements y. The dictionary \u03a6, with respect to which the image is represented, is chosen a priori and can be, for example, but not limited to, any class of wavelet dictionaries. The dictionary can also be a member of a more general class of over-complete dictionaries. Embodiments herein can be applied to any type of sampling operator \u03a8, for example, but not limited to, the Radon transform which underlies some imaging applications. In practice, the matrix \u03a8 may be determined by both the transmitted waveform and the geometric arrangement of the sensors in space and time.","Different approaches may be used to solve for c in Eq. (1). For imaging applications, the traditional approach is the Filtered Back-projection (FBP) methodology (Deans) wherein the underlying dictionary \u03a6 includes Fourier atoms. A variety of Compressive-Sensing (CS)\/Sparsity-based-reconstruction approaches including Large-Scale Il-Regularized Least Squares (Il-Is), Orthogonal Matching Pursuit (OMP), Regularized Orthogonal Matching Pursuit (ROMP), Iterative signal recovery from incomplete and inaccurate samples (CoSaMP), and Bayesian Compressive Sensing (BCS) have been applied for this purpose. An embodiment herein encompasses CS and sparse reconstruction approaches and treat them as special cases.","From Eq. (1) an embodiment herein provides a Bayesian-Maximum a posteriori (MAP) estimate of c. The prefix \u201cBayesian\u201d emphasizes that probabilities in embodiments herein are assigned without a corresponding notion of sampling or frequency. Furthermore an embodiment herein produces covariance estimates which could be used to determine confidence intervals.","The Bayesian-MAP estimate of c is given as follows:",{"@attributes":{"id":"p-0041","num":"0046"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"msup":{"mi":"c","mo":"*"},"mo":["=","\u2062"],"mi":{},"mrow":{"mrow":{"msub":{"mi":["argmax","c"]},"mo":["\u2062","\u2062","\u2062"],"mi":"log","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["c","y"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"|"}}}}},"mo":"\u221d"}}},{"mrow":{"mi":"\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0","mo":"\u2062","mrow":{"mo":["(",")"],"mn":"2"}}},{"mrow":{"mi":"\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0","mo":"\u2062","mrow":{"mo":["(",")"],"mn":"2"}}}]},{"mtd":[{"mrow":{"mi":{},"mo":"\u2062","mrow":{"msub":{"mi":["argmax","c"]},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"mrow":[{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["y","c"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"|"}}}}},{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"c"}}}],"mo":"+"}}}}},{"mrow":{"mi":{},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"3"}}},{"mrow":{"mi":{},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"3"}}}]},{"mtd":[{"mrow":{"mo":["=","\u2062"],"mi":{},"mrow":{"msub":{"mi":["argmin","c"]},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":"y","mo":"-","mrow":{"mi":["\u03a8\u03a6","c"],"mo":"\u2062"}}},"mn":["2","2"]},"mo":"-","mrow":{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"c"}}}}}}}},{"mrow":{"mi":{},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"4"}}},{"mrow":{"mi":{},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"4"}}}]}]}}},"br":{},"img":{"@attributes":{"id":"CUSTOM-CHARACTER-00022","he":"3.22mm","wi":"3.56mm","file":"US09613439-20170404-P00016.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},"sub":"v"},"The distribution P(c) encapsulates the statistical prior knowledge about the scene structure. For the specific choice of a Laplacian (i.e. P(c)=exp(\u2212\u03bb\u2225c\u2225)), Eq. (2) reduces to the LASSO methodology or the Basis Pursuit methodology:\n\n2\/2}\u2003\u2003(5)\n","The Laplacian distribution is not sufficiently rich for modeling the statistics of wavelet coefficients of natural scenes when sensed by optical or radar sensors. In an embodiment herein, a probabilistic graphical modeling extension of the Compound Gaussian (CG) distribution is used as a candidate for P(c). This extension subsumes distributions such as, for example, but not limited to, the Laplacian, the generalized Gaussian, and the alpha-stable distribution.","The Bayesian-MAP estimation problem, under the CG modeling, lends itself to a Hierarchical Bayes formulation that can yield superior performance to traditional CS methodologies. In Bayesian statistics, a maximum a posteriori probability (MAP) estimate is a mode of the posterior distribution. The MAP can be used to obtain a point estimate of an unobserved quantity on the basis of empirical data. It is closely related to Fisher's method of maximum likelihood (ML), but employs an augmented optimization objective which incorporates a prior distribution over the quantity one wants to estimate.","In Eq. (1), c can be modeled as a random vector that can be decomposed into the following Hadamard product form:\n\n\u2003\u2003(6)\n\nsuch that:\n\ni) u\u02dc(0,P)\n\n",{"@attributes":{"id":"p-0046","num":"0052"},"figref":["FIG. 2","FIG. 1"],"b":["150","150","184","152","180","150","156","158","156","190","150","156","174","174"]},"The measurements  may be in a vector form. Imaging device  may also include options module  configured to determine a sampling matrix , a pre-selected dictionary , and a noise factor . Sampling matrix  can be based on a geometric arrangement of sensors  collecting data of an object . Imaging device  may further include estimation module  configured to estimate coefficient vector  based on measurements , sampling matrix , pre-selected dictionary , and noise factor .","Imaging device  may further include reconstruction module  configured to prepare, a reconstructed image  from the measurements . In an embodiment, reconstruction module  uses any of dictionary  and estimated coefficient vector  to generate the reconstructed image . In an embodiment, dictionary  may include at least one class of wavelet dictionaries. Sampling matrix  may include a sampling operator determined by the transmitted waveform  associated with measurements  and the geometric arrangement of the independent sensors . Reconstructed image  may be transmitted by an electrical communication module .",{"@attributes":{"id":"p-0049","num":"0055"},"figref":["FIG. 3","FIGS. 1 through 2"],"b":["165","167","169","167","213","211","209","165","209","165","201","203","213","233","173","161","174"]},"In an embodiment, the estimation module  may also include the parameter module  configured to determine a structural parameter  using a parent-child relationship for each node in the tree structure . The estimation module  may further include a loop module  configured to control operation of the first variable module  and the parameter module  across the tree structure  until the structural parameter  is lower than the first pre-selected threshold . Estimation module  may further include a second variable module  configured to determine a second variable  using the first variable , sampling matrix , variable selection operator , and the second pre-selected threshold . Estimation module  may also include a coefficient module  configured to determine coefficient vector  based on a Hadamard product of the first variable  and the second variable .","In an embodiment, estimation module  may be configured to (a) initialize x=|h(\u03a8y)| and n=0, where h is the non-linear factor , \u03a8\u03b5is the sampling matrix , y\u03b5are the measurements , and n is a loop counter; (b) calculating a descent direction d; (c) determining a step size \u03bb; (d) computing x=x+\u03bbd; (e) incrementing the loop counter n; (f) computing x* by repeating steps (b) through (e) until a norm of a steepest descent vector is smaller than the first pre-selected threshold ; (g) computing z*=h(x*); (h) calculating =diag(S|z*|) and \u039b=diag(z*), where",{"@attributes":{"id":"p-0052","num":"0058"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["S","\u03bb"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}}},{"mo":"{","mrow":{"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mrow":{"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":">","mi":"\u03bb"}}]},{"mtd":[{"mn":"0"},{"mrow":{"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":"\u2264","mi":"\u03bb"}}]}]},"mo":";"}}],"mo":"="}}}},"br":{},"sup":["\u22121","T","\u22121","\u22121","\u22121","\u22121","T","\u22121 ","m ","n "],"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00028","he":"3.22mm","wi":"3.56mm","file":"US09613439-20170404-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00029","he":"3.22mm","wi":"3.56mm","file":"US09613439-20170404-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00030","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00020.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00031","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00021.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}],"sub":["v","L","u","L","R ","v"],"b":["166","162"]},"In an embodiment, the reconstruction module  is further configured to reconstruct the image by calculating. I=\u03a6c* where I\u03b5is the reconstructed image, and \u03a6\u03b5is the pre-selected dictionary .",{"@attributes":{"id":"p-0054","num":"0060"},"figref":["FIG. 4","FIGS. 1 through 3"],"b":["400","402","400","174","180","156","156","163","180","404","400","173","161","166","156","165","173","161","166","406","400","162","174","173","161","166","167","162","408","400","162","161","400","174","162","161","169"]},{"@attributes":{"id":"p-0055","num":"0061"},"figref":["FIG. 5","FIGS. 1 through 4"],"b":["162","502","500","211","209","233","173","161","174","174","213","211","233","504","500","223","215","223"]},"At step , method  repeats steps  and  across the tree structure until the parameter is lower than the first pre-selected threshold . In an embodiment, the loop module  controls operation of the first variable module  and the parameter module  across the multi-scale Gaussian tree structure  until the structural parameter  is lower than the first pre-selected threshold . At step , method  computes the second variable  using the first variable , the sampling matrix , a variable selection operator, and the second pre-selected threshold . In an embodiment, the second variable module  determines the second variable , the sampling matrix , the variable selection operator, and the second pre-selected threshold . At step , method  computes the coefficient vector  using the Hadamard product of the first variable  and the second variable . In an embodiment, the coefficient module  computes the coefficient vector .",{"@attributes":{"id":"p-0057","num":"0063"},"figref":["FIG. 6","FIGS. 1 through 5"],"b":["602","600","173","174","604","600","606","600","608","600","604","606"],"sup":["0","\u22121","T","m\u00d7d ","m ","n ","n+1","n","n "],"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00034","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00024.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00035","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00025.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}]},"At step , method  may also compute z*=h(x*). At step , method  calculates =diag(S[z*]) and \u039b\u2212=diag(z*) where",{"@attributes":{"id":"p-0059","num":"0065"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["S","\u03bb"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}}},{"mo":"{","mrow":{"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mrow":{"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":">","mi":"\u03bb"}}]},{"mtd":[{"mn":"0"},{"mrow":{"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":"\u2264","mi":"\u03bb"}}]}]},"mo":"."}}],"mo":"="}}}},"br":{},"b":["612","600","614","600","167","602","614","600"],"sup":["\u22121","T","\u22121","\u22121","\u22121","\u22121","T","\u22121 ","m ","n "],"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00037","he":"3.22mm","wi":"3.56mm","file":"US09613439-20170404-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00038","he":"3.22mm","wi":"3.56mm","file":"US09613439-20170404-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00039","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00026.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00040","he":"3.22mm","wi":"2.46mm","file":"US09613439-20170404-P00027.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}],"sub":["v","L","u","L","R ","v"]},"At step , method  calculates I=\u03a6c* where I\u03b5is the reconstructed image and \u03a6\u03b5is the pre-selected dictionary . The pre-selected dictionary  can include at least one class of wavelet dictionaries. The sampling matrix  can include a sampling operator determined by a transmitted waveform associated with the measurements  and a geometric arrangement of the independent sensors. In an embodiment, reconstruction module  reconstructs the image at step  of method .",{"@attributes":{"id":"p-0061","num":"0067"},"figref":["FIG. 7","FIGS. 1 through 6"],"b":["233","233","11","13","15","11"],"br":[{},{},{},{},{}],"in-line-formulae":[{},{},{},{},{},{}],"i":["x","s","A","s","x","par","s","+B","s","w","s","P","s","A","s","P","par","s","A","s","+Q","s","P","s,t","s,s\u039bt","P","s\u039bt","t,s\u039bt"],"sub":["x","x","x","x"],"sup":["T","T","T"],"img":{"@attributes":{"id":"CUSTOM-CHARACTER-00043","he":"3.22mm","wi":"3.56mm","file":"US09613439-20170404-P00016.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}},"The statistics of wavelet coefficients can be modeled effectively by the CG model and related observations in sea-clutter and radar images, as shown in Eq. (6). Given Eq. (6) and property (ii), the covariance of a coefficient and its parent is as follows:\n\n(),(())]=\n\n[(())((()))]\u2299()(())]\n","The fact that the wavelet coefficients of images across scales tend to be decorrelated can be enforced by constraining the Gaussian field u to be corresponding white noise process across the multiscale tree. Furthermore, the variance of the wavelet coefficients across scales follows a self-similar structure. These properties can be accommodated by modeling:\n\n()=()\u00e7() \u00e7()\u02dc(0,1) such that: ()=2\n\nwhere, m(s) is the scale corresponding to node s, and \u03b3>0 is a constant. From Properties (i)-(iii) it follows that the variance of c is controlled by the u-field.\n","In spite of the above decorrelation across scales, the strong non-Gaussian local dependence of wavelet coefficients that is observed in natural images is captured by the tree dependency structure in the x (and correspondingly, via (i), the z) random field. Finally as mentioned above, the sparse structure of the wavelet coefficients is enforced by the non-linearity h.","In using the Graphical CG model for the purposes of solving Eq. (1), simplifying assumptions can be made: (1) A(s)=A\u00b7Iand B(s)=B\u00b7I\u2200s where, A,B\u03b5, and Idenotes the identity matrix of size d, and (2) the tree structure corresponding to x is homogeneous. From these assumptions, Eq. (7) can be written as:",{"@attributes":{"id":"p-0066","num":"0072"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["P","x"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"s"}},"mo":"=","mfrac":{"msup":{"mi":"B","mn":"2"},"mrow":{"mn":"1","mo":"-","msup":{"mi":"A","mn":"2"}}}}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}}}},"br":{},"sup":"2","sub":["x","d"]},"Though many different sparsity-inducing non-linearities h can be incorporated, in an embodiment herein, the following non-linearity can be useful in terms of analytical properties such as smoothness with respect to the sparsity controlling parameter \u03b1:\n\n()=\u221a{square root over ((\/\u03b1))}\u2003\u2003(10)\n","Eq. (10) shows that the sparsity level of the signal is inversely proportional to \u03b1. Thus two parameters, \u03b1 and \u03bc, control the properties of the Graphical CG distribution.","Given the CG model in Eq. (6), the pdf (probability density function) of the wavelet field c is given by:",{"@attributes":{"id":"p-0070","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"c"}},{"msubsup":{"mo":"\u222b","mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]},"mo":"\u2062","mrow":{"mfrac":{"mn":"1","mrow":{"msqrt":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}},"mo":["\u2062","\u2062"],"mrow":{"mo":["\uf603","\u2211","\uf604"]},"mi":"z"}},"mo":["\u2062","\u2062"],"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mo":"-","msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["c","z"],"mo":"\/"}},"mi":"H"}},{"msup":{"mo":"\u2211","mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mi":["c","z"],"mo":"\/"}}}],"mo":"\u2062"}}},{"mrow":[{"msub":{"mi":["P","z"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"z"}},{"mo":"\u2146","mi":"z"}],"mo":"\u00b7"}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"11"}}]}}}},"br":{},"sub":["z","z"]},"A statistical model with prior distribution \u03c0(\u03b8) is said to be hierarchical Bayes if it can be decomposed in terms of conditional distributions","\u03c0(\u03b8|\u03b8), \u03c0(\u03b8|\u03b8), . . . , \u03c0(\u03b8|\u03b8), and marginal \u03c0(\u03b8):\n\n\u03c0(\u03b8)=\u222b\u03c0(\u03b8|\u03b8)\u03c0(\u03b8|\u03b8) . . . \u03c0(\u03b8|\u03b8)\u03c0(\u03b8).\u2003\u2003(12)\n\nThe CG distribution inherently has a hierarchical structure in that conditioning on the latent variable z Gaussianizes the wavelet field c. A fully Bayesian non-parametric approach to statistical inference under a hierarchical Bayesian prior model involves drawing samples from the posterior distribution:\n\n()\u221d()()=()()()\u2003\u2003(13)\n\nvia Markov Chain Monte Carlo (MCMC) and other sampling methods. The intermediate estimation of the latent variable, the z-field, is referred to herein as Type-II estimation, whereas the estimation of the primary parameter of interest c is referred to herein as Type-I estimation.\n","An embodiment focuses on a particular family of prior distributions; i.e., the Graphical CG model described above. The embodiment performs inference by a sequence of MAP estimates starting with the latent variable:\n\n","An embodiment solves the optimization problem presented in Eq. (4) wherein a Graphical CG model is placed on the unknown coefficients c. The first step is to estimate the non-Gaussian component z (Type-II estimation), followed by the estimation of u (Type-I estimation). With respect to Type II estimation, given that z=h(x), it suffices to estimate the Multi-scale Gaussian Tree random process x. This can be performed by recourse to the Bayesian-MAP strategy:\n\nlog ()\u2003\u2003(14)\n\nlog ()+log ()\u2003\u2003(15)\n\nFrom Eq. (1) and Eq. (6):\n\n {tilde over (\u03a8)}(()\u2299)+where, {tilde over (\u03a8)}\u2261\u03a8\u03a6\n\n \u2003\u2003(16)\n\nwhere, A={tilde over (\u03a8)}H\n\n(())\n\nFrom Eq. (16):\n\n(;0+\u03a3)\n\n(0)\n\nwhere, (w;\u03bc,\u03a3) denotes a Gaussian with mean \u03bc and covariance matrix \u03a3. Thus Eq. (16) is equivalent to:\n\n()\u2003\u2003(17)\n\nwhere:\n\n()=(+\u03a3)+log (+\u03a3)\n\n+\u2003\u2003(18)\n","In an embodiment, two types of steepest descent approaches are considered: Gradient and Newton based steepest descent. The Gradient descent involves a first-order Taylor series expansion of the cost function Eq. (18) wherein only the Gradient vector of f has to be computed in each iteration. The Newton descent approach, which involves the second order Taylor approximation of f, in addition entails the calculation of the Hessian matrix. For Newton iterations, once the Hessian is calculated via equation, the closest psd (positive semi-definite) approximation to the Hessian is computed and used for calculating the descent direction as described above. Given a matrix X, an approximation to its closest psd can be calculated as follows:\n\n\u2003\u2003(19)\n\nwhere,\n\n","Performing the closest psd approximation of the Hessian matrix X=\u2207f(x), which effectively constrains the search direction to an elliptical ball defined by the matrix M, furnishes descent directions that can improve upon the gradient direction.","With respect to Type I estimation, let x* be the solution of Eq. (17) obtained via Type II estimation. Thus, the estimate of the non-Gaussian component of the unknown coefficient c is z*=h(x*). The goal of the Type-I estimation is to estimate the corresponding u field. The Bayesian-MAP strategy is used to generate the optimality criterion to solve:",{"@attributes":{"id":"p-0078","num":"0090"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"msup":{"mi":"u","mo":"*"},"mo":["=","\u2062"],"mi":{},"mrow":{"mi":"arg","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["max","u"]},"mo":"\u2062","mrow":{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["u","y"],"mo":"\u2758"}}}}}}}},{"mrow":{"mi":"\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0","mo":"\u2062","mrow":{"mo":["(",")"],"mn":"20"}}}]},{"mtd":[{"mrow":{"mo":["=","\u2062"],"mi":{},"mrow":{"mrow":[{"mi":"arg","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["max","u"]},"mo":"\u2062","mrow":{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["y","u"],"mo":"\u2758"}}}}}},{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"u"}}}],"mo":"+"}}},{"mrow":{"mi":{},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"21"}}}]},{"mtd":[{"mrow":{"mo":["=","\u2062"],"mi":{},"mrow":{"mrow":[{"munder":{"mrow":{"mi":["arg","min"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mi":"u"},"mo":["\u2062","\u2062"],"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":"y","mo":"-","mrow":{"msub":{"mi":"A","msup":{"mi":"x","mo":"*"}},"mo":"\u2062","mi":"u"}}},"mi":"T"},"mrow":{"munderover":{"mo":"\u2211","mi":"\u03c5","mrow":{"mo":"-","mn":"1"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mi":"y","mo":"-","mrow":{"msub":{"mi":"A","msup":{"mi":"x","mo":"*"}},"mo":"\u2062","mi":"u"}}}}},{"msup":{"mi":["u","T"]},"mo":["\u2062","\u2062"],"msubsup":{"mi":["P","u"],"mrow":{"mo":"-","mn":"1"}},"mi":"u"}],"mo":"+"}}},{"mrow":{"mi":{},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"22"}}}]}]}}},"br":[{},{},{},{}],"in-line-formulae":[{},{},{},{}],"sub":["L","v","R","L","v","L","R"],"sup":["T","\u22121","T","\u22121"],"i":["u=\u039b","y","=diag","z"]},"The sparse structure of z* can allow pruning the number of equations to be solved:\n\n({tilde over (\u03a8)}\u03a3{tilde over (\u03a8)}+\u039b\u03a3\u039b)\u039b\u03a3\u2003\u2003(24)\n\n=(S])\u2003\u2003(25)\n",{"@attributes":{"id":"p-0080","num":"0092"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["S","\u03bb"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mrow":{"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":">","mi":"\u03bb"}}]},{"mtd":[{"mn":"0"},{"mrow":{"mrow":{"mi":"z","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":"\u2264","mi":"\u03bb"}}]}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"26"}}]}}}}},"S is a variable selection operator with respect to threshold \u03bb. The threshold \u03bb is determined from the histogram of z*. The resulting Type-I estimation methodology can be summarized as follows:","1. Let z* be the solution of the Type-II estimation procedure given measurements y, sampling matrix \u03a8, and dictionary \u03a6","2. Calculate =diag(S[z*]) for a threshold \u03bb (in eq. (25)) and let \u039b=diag(z*)","3. Solve for u:\n\n\n\nwhere,\n\n({tilde over (\u03a8)}\u03a3{tilde over (\u03a8)}+\u039b\u03a3\u039b)\u039b\n\n\u03a3\n\n4. Return u*\n","The matrix  prunes out the rows corresponding to values of the z that are too small (as determined by threshold \u03bb).","The HB-MAP methodology can be summarized as follows:","1. Initialize parameters","2. Perform Type-II estimation to obtain z*, the MAP estimate of the z field","3. Given z* perform the approximate EM methodology to estimate the optimum parameter \u03bc","4. Iterate between steps (2)-(3) until convergence of \u03bc","5. Perform Type-I estimation to obtain u*","6. Return the optimum estimate of the image: I*=c*, where c*=z*\u2299u*","In addition to employing the Type-I and Type-II estimation procedures described above, the HB-MAP methodology also employs an approximate EM methodology that enables the refinement of parameter \u03bc that controls the non-Gaussian inter-scale dependencies between the wavelet coefficients. Let \u03bcbe the value of \u03bc in the kiteration, and let x*be the corresponding Type-II MAP estimate that solves (14). A 2order Taylor expansion of the cost function f about x*can be computed as follows:\n\n()\u2248(;\u03bc)+[\u2207(;\u03bc)]()\n\n+0.5(){\u2207(;\u03bc)}()\u2003\u2003(27)\n\n\u22480.5(){\u2207(;\u03bc)}()\u2003\u2003(28)\n\nsince \u2207f(x*;\u03bc)=0 by definition of the fact that x*is a local optimum point, and f(x*;\u03bc)\u22480 by assumption. Thus p(x|y,\u03bc)\u2248(x;x*,\u2207f(x*;\u03bc)).\n","The Q-function of the EM methodology is:\n\n(\u03bc;\u03bc)=\u2212[log (,\u03bc)]\u2003\u2003(29)\n\n(\u03bc;\u03bc)=2 log(2\u03c0)+1\/2 log ((\u03bc))\n\n+1\/2()(\u03bc)+1\/2((\u03bc)\u2207(;\u03bc))\u2003\u2003(30)\n","and the gradient function of Q is as follows:\n\n\u2207(\u03bc;\u03bc)=\n\n\u22121\/2(\u2207(\u03bc))((\u03bc))+1\/2(\u2207(\u03bc))(((\u03bc))()(\u03bc))+\n\n\u00bd(\u2207(\u03bc))(((\u03bc))\u2207(;\u03bc)(\u03bc))\u2003\u2003(31)\n\nThe optimum parameter \u03bc can be found as follows:\n\n\u03bc*=(\u03bc;\u03bc)\u2003\u2003(32)\n\nwhere Eq. (32) can be solved by a simple gradient descent by using the gradient expression given in Eq. (31).\n","The computationally most intensive part of the methodology is the calculation of the Hessian matrix and (to a lesser extent) the Gradient vector that is required in the steepest descent methodology (Type II estimate). Direct implementation of the Hessian matrix and Gradient vector equations without exploiting the sparse structure of the matrices could be computationally expensive due to the presence of massive tensor products resulting from Kronceker operations on high dimensional matrices. The computational bottleneck can be overcome as follows. The gradient vector is given by the following equation:\n\n\u2207()=2(\u03a8\u03a8)\u2003\u2003(33)\n\nwhere,\n\n=\u2207[{()()}]\u2003\u2003(34)\n\n(())\u2212[()()]\u2003\u2003(35)\n",{"@attributes":{"id":"p-0088","num":"0100"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["M","x"]},"mo":"=","mrow":{"mrow":[{"mrow":[{"msub":[{"mi":["A","x"]},{"mi":["P","u"]}],"mo":["\u2062","\u2062"],"msubsup":{"mi":["A","x","T"]}},{"munder":{"mo":"\u2211","mi":"\u03c5"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":"and","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"msub":{"mo":"\u2207","mi":"x"},"mo":"\u2062","mrow":{"msub":{"mi":["H","x"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}}],"mo":"+"},{"mo":"{","mrow":{"mrow":[{"mtable":{"mtr":[{"mtd":[{"mfrac":{"mrow":[{"mo":"\u2202","mrow":{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["x","i"]}}}},{"mo":"\u2202","msub":{"mi":["x","i"]}}]}},{"mrow":{"mi":"j","mo":"=","mrow":{"mrow":{"mi":"i","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"n","mo":"+","mn":"1"}}},"mo":"-","mi":"n"}}}]},{"mtd":[{"mn":"0"},{"mi":"else"}]}]},"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}},"msubsup":{"mi":["P","x"],"mrow":{"mo":"-","mi":"T"}}},{"mrow":{"msubsup":[{"mi":["P","x"],"mrow":{"mo":"-","mn":"1"}},{"mi":["M","x"],"mrow":{"mo":"-","mi":"T"}}],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"and"},"mo":"=","msubsup":{"mi":["M","x"],"mrow":{"mo":"-","mn":"1"}}}],"mo":"="}}],"mo":"="}}}}},"The following is a procedure for calculating the gradient in Eq. (33).","1. for i=1 to n","2. r=G(i,:)","3. index=find locations k where r(k)\u22600","4. g=0","5. for j=1 to |index|","6. k=index(j), k=mod(k,n), k=(k\u2212k)\/n","7. v={tilde over (\u03a8)}(k,:) v={tilde over (\u03a8)}(k,:)","8. g=g+vvec(vv)","9. endfor","10. endfor","11. g=g+2Px","12. Return g","The Hessian form can be expressed as follows:\n\n\u2207()=2\u2003\u2003(36)\n\nwhere,\n\n=\u2207[()]({tilde over (\u03a8)}{tilde over (\u03a8)})\u2003\u2003(37)\n\n=\u2207()]({tilde over (\u03a8)}{tilde over (\u03a8)})\u2003\u2003(38)\n\n()][(\u2207)]({tilde over (\u03a8)}{tilde over (\u03a8)})\u2003\u2003(39)\n\n()()[(\u2207)]({tilde over (\u03a8)}{tilde over (\u03a8)})\u2003\u2003(40)\n\nfurthermore,\n\n()\u2003\u2003(41)\n\n=()()\u2003\u2003(42)\n",{"@attributes":{"id":"p-0091","num":"0103"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":"Q","mn":"1"},"mo":"=","mrow":{"mrow":{"mo":"-","mrow":{"mo":"\u2061","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mo":["{","}"],"mrow":{"mrow":{"msup":{"mover":{"mi":"\u03a8","mo":"~"},"mi":"T"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msubsup":{"mi":["M","x"],"mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mi":"y"}}},"mo":["\u2062","\u2062"],"msup":{"mrow":{"mo":["(",")"],"mrow":{"msubsup":{"mi":["M","x"],"mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mi":"y"}},"mi":"T"},"mover":{"mi":"\u03a8","mo":"~"}}},"mo":"\u2297"}}},{"mtd":{"mrow":{"mo":["(",")"],"mrow":{"msup":{"mover":{"mi":"\u03a8","mo":"~"},"mi":"T"},"mo":["\u2062","\u2062"],"msubsup":{"mi":["M","x"],"mrow":{"mo":"-","mn":"1"}},"mover":{"mi":"\u03a8","mo":"~"}}}}}]}}}},"mo":"\u2062"}}},{"mrow":{"mo":["(",")"],"mn":"43"}}]}}}}},{"@attributes":{"id":"p-0092","num":"0104"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":"Q","mn":"2"},"mo":"=","mrow":{"mrow":{"mo":"\u2061","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"msub":{"mi":["K","nn"]},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"msup":{"mover":{"mi":"\u03a8","mo":"~"},"mi":"T"},"mo":["\u2062","\u2062"],"msubsup":{"mi":["M","x"],"mrow":{"mo":"-","mn":"1"}},"mover":{"mi":"\u03a8","mo":"~"}}},{"mo":["(",")"],"mrow":{"mrow":{"msup":{"mover":{"mi":"\u03a8","mo":"~"},"mi":"T"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msubsup":{"mi":["M","x"],"mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mi":"y"}}},"mo":["\u2062","\u2062"],"msup":{"mrow":{"mo":["(",")"],"mrow":{"msubsup":{"mi":["M","x"],"mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mi":"y"}},"mi":"T"},"mover":{"mi":"\u03a8","mo":"~"}}}],"mo":"\u2297"}}},"mo":"+"}}},{"mtd":{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mrow":{"msup":{"mover":{"mi":"\u03a8","mo":"~"},"mi":"T"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msubsup":{"mi":["M","x"],"mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mi":"y"}}},"mo":["\u2062","\u2062"],"msup":{"mrow":{"mo":["(",")"],"mrow":{"msubsup":{"mi":["M","x"],"mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mi":"y"}},"mi":"T"},"mover":{"mi":"\u03a8","mo":"~"}}},{"mo":["(",")"],"mrow":{"msup":{"mover":{"mi":"\u03a8","mo":"~"},"mi":"T"},"mo":["\u2062","\u2062"],"msubsup":{"mi":["M","x"],"mrow":{"mo":"-","mn":"1"}},"mover":{"mi":"\u03a8","mo":"~"}}}],"mo":"\u2297"}}}]}}},"mo":"\u2062"}}},{"mrow":{"mo":["(",")"],"mn":"44"}}]}}}},"br":{},"in-line-formulae":[{},{}],"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00085","he":"3.56mm","wi":"3.89mm","file":"US09613439-20170404-P00057.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00086","he":"2.79mm","wi":"1.78mm","file":"US09613439-20170404-P00058.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00087","he":"2.79mm","wi":"1.78mm","file":"US09613439-20170404-P00059.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}],"sub":["x","x","u","x","n","n","u","x"],"i":["H","P","H","I","}+{I","P","H"]},"A property that can enable efficient calculation of the above matrix products is to preserve sparsity of the intermediate matrices products calculated from left to right. First, by construction the matrices \u2207Hand \u2207Hare sparse. Given this, the following Hessian procedure can allow the sparsity of the intermediate matrix products to be preserved while producing the desired matrix products (for example, MN\u2200i,j).","1. {A\u03b5}are matrices to be multiplied; n=n","2. for i=1:n","3. r=A(i,:)","4. for j=1:k","5. r=prod(r,A)","6. end","7. D(i,:)=devec(r)*vec(N)","8. end","9. Return D","where, N is either Nor N(in Eq. (41-42)) and prod( ) refers to specialized matrix products that use algorithmic techniques similar to that in the gradient calculation algorithm.","In terms of flop count, the Gradient calculation takes O(n.S) and the Hessian calculation takes O(n.S) (where integer S depends on matrix P; for a block-diagonal matrix P, S is bounded by a small constant) on a single-core CPU (Central Processing Unit). Each of the iterations in the Gradient procedure and the Hessian procedure are independent of each other and thus can be performed in any order. This key property allows for parallel processing to be efficiently exploited in multicore CPU or GPU (Graphical Processing Unit) platforms.",{"@attributes":{"id":"p-0095","num":"0107"},"figref":["FIG. 8","FIGS. 1 through 7"],"b":["21","23","25"]},"Newton , Gradient Descent , and Perfect Knowledge  are performance results from execution of the embodiments herein. Line  corresponds to the Gradient descent iteration and line  corresponds to the Newton iteration. The simulation results show that the Gradient descent iteration and the Newton iterations both have the maximum MSE at 2 trials. Line  illustrates the Perfect Knowledge HB-MAP  corresponding to the case where the z-field is known exactly, as in simulated Monte-Carlo trials. Thus, the Perfect Knowledge HB-MAP procedure only applies the Type-I estimation to estimate the image. The performance of Perfect Knowledge HB-MAP is therefore a lower bound which no other methodology can surpass.","The threshold \u03bb that is used in the Type-I estimation procedure is determined in these experiments by the coordinate of the histogram of the estimated z field below which 0.1 of the samples is contained. Line  corresponding to Il-Is, line  corresponding to CoSaMP, line  corresponding to ROMP, and line  corresponding to BCS illustrate performance results from high sparsity-based convex optimization methodologies. Line  corresponding to Fourier illustrates performance results from a standard Fourier-based reconstruction. Simulated images have high-sparsity (i.e. \u03b1=0.2). The high sparsity case is more typical of natural images. The performance of the embodiments herein exceeds that of other options.",{"@attributes":{"id":"p-0098","num":"0110"},"figref":["FIG. 9","FIGS. 1 through 8"],"b":["21","23","25","27","29","31","33","35"]},{"@attributes":{"id":"p-0099","num":"0111"},"figref":["FIG. 10","FIGS. 1 through 9","FIG. 10"],"b":["45","51","46","47","49","53","55","43","41"]},{"@attributes":{"id":"p-0100","num":"0112"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0101","num":"0113"},"figref":["FIG. 11","FIGS. 1 through 10","FIG. 11","FIG. 10","FIG. 11"],"b":["63","61","41","62","65","67","69","71","73"]},"In an exemplary embodiment, the various modules described herein and illustrated in the figures, for example systems and devices illustrated in , are embodied as hardware-enabled modules and may be configured as a plurality of overlapping or independent electronic circuits, devices, and discrete elements packaged onto a circuit board to provide data and signal processing functionality within a special-purpose computer. An example might be a comparator, inverter, or flip-flop, which could include a plurality of transistors and other supporting devices and circuit elements. The modules that are configured with electronic circuits process computer logic instructions capable of providing digital and\/or analog signals for performing various functions as described herein. The various functions can further be embodied and physically saved as any of data structures, data paths, data objects, data object models, object files, database components. For example, the data objects could be configured as a digital packet of structured data. The data structures could be configured as any of an array, tuple, map, union, variant, set, graph, tree, node, and an object, which may be stored and retrieved by computer memory and may be managed by processors, compilers, and other computer hardware components. The data paths can be configured as part of a computer CPU that performs operations and calculations as instructed by the computer logic instructions. The data paths could include digital electronic circuits, multipliers, registers, and buses capable of performing data processing operations and arithmetic operations (e.g., Add, Subtract, etc.), bitwise logical operations (AND, OR, XOR, etc.), bit shift operations (e.g., arithmetic, logical, rotate, etc.), complex operations (e.g., using single clock calculations, sequential calculations, iterative calculations, etc.). The data objects may be configured as physical locations in computer memory and can be a variable, a data structure, or a function. In the embodiments configured as relational databases (e.g., such Oracle\u00ae relational databases), the data objects can be configured as a table or column. Other configurations include specialized objects, distributed objects, object oriented programming objects, and semantic web objects, for example. The data object models can be configured as an application programming interface for creating HyperText Markup Language (HTML) and Extensible Markup Language (XML) electronic documents. The models can be further configured as any of a tree, graph, container, list, map, queue, set, stack, and variations thereof. The data object files are created by compilers and assemblers and contain generated binary code and data for a source file. The database components can include any of tables, indexes, views, stored procedures, and triggers.","Some components of the embodiments herein can include a computer program product configured to include a pre-configured set of instructions stored in non-volatile memory, which when performed, can result in actions as stated in conjunction with the methods described above. For example components of  may include a computer program product. In an embodiment, imaging device  may include a computer program. In an embodiment, pre-processor module  may include a computer program. In an embodiment, options module  may include a computer program. In an embodiment, estimation module  may include a computer program. In an embodiment, reconstruction module  may include a computer program. In an embodiment, first variable module  may include a computer program. In an embodiment, parameter module  may include a computer program. In an embodiment, loop module  may include a computer program. In an embodiment, second variable module  may include a computer program. In an embodiment, coefficient module  may include a computer program. In an example, the pre-configured set of instructions can be stored on a tangible non-transitory computer readable medium or a program storage device. In an example, the tangible non-transitory computer readable medium can be configured to include the set of instructions, which when performed by a device, can cause the device to perform acts similar to the ones described here.","The embodiments herein may also include tangible and\/or non-transitory computer-readable storage media for carrying or having computer executable instructions or data structures stored thereon. Such non-transitory computer readable storage media can be any available media that can be accessed by a special purpose computer, including the functional design of any special purpose processor, module, or circuit as discussed above. By way of example, and not limitation, such non-transitory computer-readable media can include RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to carry or store desired program code means in the form of computer executable instructions, data structures, or processor chip design. When information is transferred or provided over a network or another communications connection (either hardwired, wireless, or combination thereof) to a computer, the computer properly views the connection as a computer-readable medium. Thus, any such connection is properly termed a computer-readable medium. Combinations of the above should also be included within the scope of the computer-readable media.","Computer-executable instructions include, for example, instructions and data which cause a special purpose computer or special purpose processing device to perform a certain function or group of functions. Computer-executable instructions also include program modules that are executed by computers in stand-alone or network environments. Generally, progran modules include routines, programs, components, data structures, objects, and the functions inherent in the design of special-purpose processors, etc. that perform particular tasks or implement particular abstract data types. Computer executable instructions, associated data structures, and progran modules represent examples of the program code means for executing steps of the methods disclosed herein. The particular sequence of such executable instructions or associated data structures represents examples of corresponding acts for implementing the functions described in such steps.","The techniques provided by the embodiments herein may be implemented on an integrated circuit chip (not shown). The chip design is created in a graphical computer programming language, and stored in a computer storage medium (such as a disk, tape physical hard drive, or virtual hard drive such as in a storage access network). If the designer does not fabricate chips or the photolithographic masks used to fabricate chips, the designer transmits the resulting design by physical means (e.g., by providing a copy of the storage medium storing the design) or electronically (e.g., through the Internet) to such entities, directly or indirectly. The stored design is then converted into the appropriate format (e.g., GDSII) for the fabrication of photolithographic masks, which typically include multiple copies of the chip design in question that are to be formed on a wafer. The photolithographic masks are utilized to define areas of the wafer (and\/or the layers thereon) to be etched or otherwise processed.","The resulting integrated circuit chips can be distributed by the fabricator in raw wafer form (that is, as a single wafer that has multiple unpackaged chips), as a bare die, or in a packaged form. In the latter case, the chip is mounted in a single chip package (such as a plastic carrier, with leads that are affixed to a motherboard or other higher level carrier) or in a multichip package (such as a ceramic carrier that has either or both surface interconnections or buried interconnections). In any case, the chip is then integrated with other chips, discrete circuit elements, and\/or other signal processing devices as part of either (a) an intermediate product, such as a motherboard, or (b) an end product. The end product can be any product that includes integrated circuit chips, ranging from toys and other low-end applications to advanced computer products having a display, a keyboard or other input device, and a central processor, and may be configured, for example, as a kiosk.","The embodiments herein can include both hardware and software elements. The embodiments that are implemented in software include but are not limited to, firmware, resident software, microcode, etc. Furthermore, the embodiments herein can take the form of a computer program product accessible from a computer-usable or computer-readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description, a computer-usable or computer readable medium can be any apparatus that can comprise, store, communicate, propagate, or transport the program for use by or in connection with the instruction execution system, apparatus, or device.","The medium can be an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system (or apparatus or device) or a propagation medium. Examples of a computer-readable medium include a semiconductor or solid state memory, magnetic tape, a removable computer diskette, a random access memory (RAM), a read-only memory (ROM), a rigid magnetic disk and an optical disk. Current examples of optical disks include compact disk-read only memory (CD-ROM), compact disk-read\/write (CD-R\/W) and DVD.","A data processing system suitable for storing and\/or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus. The memory elements can include local memory employed during actual execution of the program code, bulk storage, and cache memories which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.","Input\/output (I\/O) devices (including but not limited to keyboards, displays, pointing devices, etc.) can be coupled to the system either directly or through intervening I\/O controllers. Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems, cable modem and Ethernet cards are just a few of the currently available types of network adapters.","A representative hardware environment for practicing the embodiments herein is depicted in , with reference to . This schematic drawing illustrates a hardware configuration of an information handling\/computer system  in accordance with an exemplary embodiment herein. The system  comprises at least one processor or central processing unit (CPU) . The CPUs  are interconnected via system bus  to various devices such as a random access memory (RAM) , read-only memory (ROM) , and an input\/output (I\/O) adapter . The I\/O adapter  can connect to peripheral devices, such as disk units  and storage drives , or other program storage devices that are readable by the system. The system  can read the inventive instructions on the program storage devices and follow these instructions to execute the methodology of the embodiments herein. The system  further includes a user interface adapter  that connects a keyboard , mouse , speaker , microphone , and\/or other user interface devices such as a touch screen device (not shown) to the bus  to gather user input. Additionally, a communication adapter  connects the bus  to a data processing network , and a display adapter  connects the bus  to a display device  which may be embodied as an output device such as a monitor, printer, or transmitter, for example. Further, a transceiver , a signal comparator , and a signal converter  may be connected with the bus  for processing, transmission, receipt, comparison, and conversion of electric or electronic signals.","The foregoing description of the specific embodiments will so fully reveal the general nature of the embodiments herein that others can, by applying current knowledge, readily modify and\/or adapt for various applications such specific embodiments without departing from the generic concept, and, therefore, such adaptations and modifications should and are intended to be comprehended within the meaning and range of equivalents of the disclosed embodiments. It is to be understood that the phraseology or terminology employed herein is for the purpose of description and not of limitation. Therefore, while the embodiments herein have been described in terms of preferred embodiments, those skilled in the art will recognize that the embodiments herein can be practiced with modification within the spirit and scope of the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The embodiments herein will be better understood from the following detailed description with reference to the drawings, in which:",{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
