---
title: Motion-based device operations
abstract: Methods, program products, and systems of motion-based device operations are described. A mobile device can coordinate operations of a motion sensor and a proximity sensor. The mobile device can determine a gesture event using the motion sensor. The mobile device can determine a proximity event using the proximity sensor. The mobile device can use the gesture event and proximity event to confirm one another, and determine that the mobile device has moved in proximity to a target object following a specified gesture. Upon confirmation, the mobile device can perform a specified task.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08952895&OS=08952895&RS=08952895
owner: Apple Inc.
number: 08952895
owner_city: Cupertino
owner_country: US
publication_date: 20110603
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Overview of Motion-Based Device Operations","Operations of an Exemplary Gesture Recognition Subsystem","Exemplary Motion-Based Operations of a Mobile Device","Exemplary Mobile Device Architecture","Exemplary Operating Environment"],"p":["This disclosure relates generally to motion-based operations of a mobile device.","A mobile device can include a motion sensor that is configured to detect a motion of the mobile device. The motion sensor can measure movement and rotation of the mobile device in a two-dimensional or three-dimensional space and provide as an output a series of readings of the acceleration. Based on the acceleration readings, the mobile device can determine whether the device is or was in motion. The mobile device can use the motion to control various functions or application programs of the mobile device. For example, the mobile device can use the series of readings as an input to an application program. Based on the motion sensor readings, the application program can perform various tasks.","Methods, program products, and systems of motion-based device operations are described. A mobile device can coordinate operations of a motion sensor and a proximity sensor. The mobile device can determine a gesture event using the motion sensor. The mobile device can determine a proximity event using the proximity sensor. The mobile device can use the gesture event and proximity event to confirm one another, and determine that the mobile device has moved in proximity to a target object following a specified gesture. Upon confirmation, the mobile device can perform a specified task.","In general, in one aspect, motion-based device operations can include receiving program instructions configured to cause the mobile device to perform a task upon detecting that the mobile device has moved to a location proximate to an object. The operations can include obtaining a motion reading from one or more motion sensors of a mobile device; detecting a gesture event based on the motion reading, including determining that the motion reading indicates that the mobile device moves towards a target object in one or more specified fashion; detecting a proximity event, including obtaining a proximity reading from a proximity sensor of the mobile device, the proximity reading indicating that the mobile device is located proximate to an object; determining, based on the gesture event and the proximity event, that the mobile device has moved to the location proximate to the target object; and then performing a task in response.","Motion-based device operations can be implemented to achieve the following advantages. False positive rates of gesture recognition or proximity determination can be lowered compared to conventional mobile devices. When the mobile device moves in a manner that is similar to a specified gesture, the mobile device can designate the movement as the gesture after confirmation from a proximity sensor. An interrupted movement can be filtered out. Thus, for example, if a user moves a mobile device from a pocket to an ear, the mobile device need not activate a voice input function until the mobile device reaches the ear.","In addition, response time of a mobile device can be shortened, comparing to conventional mobile devices. A proximity sensor of a mobile device may need calibration before proximity detection. The mobile device can calibrate the proximity sensor before the mobile device reaches an object, based on motion sensor readings. Thus, when the mobile device reaches the object, the proximity sensor can be already calibrated. If a task requires a proximity sensor input, the proximity sensor can appear to respond almost instantaneously, from a user's point of view.","The details of one or more implementations of motion-based device operations are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of motion-based device operations will become apparent from the description, the drawings, and the claims.","Like reference symbols in the various drawings indicate like elements.",{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1","b":["100","100","100","118"]},"In the example shown, the initial position of mobile device  is a face-up position on table . Mobile device  is then picked up from a table and moved to a face, following motion path . Mobile device  can track motion path  using a motion sensor. The motion sensor can be configured to measure linear acceleration values, angular rate values, or both, of mobile device  on multiple axes (e.g., X, Y, Z or pitch, yaw, roll) and generate motion sensor readings. The motion sensor readings can include a time series of motion vectors corresponding to motion path .","Mobile device  can include gesture recognition subsystem . Gesture recognition subsystem  is a component of mobile device  that is configured to recognize a gesture from various motions. For example, a gesture of picking up mobile device  from an initial position and putting mobile device  near face  can be performed by a left hand or a right hand, quickly or slowly, with or without an interruption (e.g., an action of turning mobile device  for viewing a display before putting it near an ear). Gesture recognition subsystem  can recognize the gesture from these variations based on one or more motion patterns. Further details of the operations of gesture recognition subsystem  will be described below in reference to FIGS.  and A-B.","Mobile device  can include proximity detection subsystem . Proximity detection subsystem  is a component of mobile device  that is configured to detect a proximity event. Mobile device  can use the proximity event to confirm a recognized gesture and reduce false positives. A false positive is an occurrence that movement of mobile device is mistakenly recognized as a designated gesture. For example, when a mobile device is taken out of the pocket and put on a table, the mobile device can mistakenly determine that a gesture of picking up the mobile device is received. By employing one or more other sensors of mobile device , proximity detection subsystem  can detect a false positive when a condition of the mobile device is inconsistent with a normal consequence of the gesture. For example, mobile device  can identify a false recognition of a gesture of moving mobile device  to face  when, after the movement, a proximity sensor fails to detect face . Mobile device  can confirm the gesture when proximity detection subsystem  detects a proximity event shortly after or shortly before gesture recognition subsystem  recognizes the gesture (e.g., at time ).","Likewise, mobile device  can use a gesture detected by gesture recognition subsystem  to confirm a proximity event. For example, mobile device  may detect a proximity event when a user places a hand near a proximity sensor of mobile device , or places mobile device near an ear. Based on a gesture determined by gesture recognition subsystem , mobile device  can determine whether the proximity event is caused by the user placing mobile device  near the ear. Mobile device  can turn off a display screen when a gesture of putting the mobile device near an ear occurred approximately at the same time. Thus, mobile device  can avoid turning off the display screen when a user merely places a hand near the display screen.","Upon the confirmation of the gesture, mobile device  can perform various tasks. For example, mobile device  can deactivate a touch-screen input device, or activate a voice input device, or both. Based on characteristics of the confirmed gesture input, mobile device  can set the voice input device to various input modes.",{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 2","b":["100","100","202","202","100","206","100","110","206","220","220","220"]},"Mobile device  can include proximity detection subsystem  that is configured to confirm recognized gesture . If the recognized gesture  is a gesture that usually results in proximity between mobile device  and an object, proximity detection subsystem  can configure proximity sensor  to detect the proximity. Proximity sensor  can include a component of mobile device  that is configured to detect presence of a nearby object without physical contact between mobile device  and the object. When proximity detection subsystem  receives recognized gesture , proximity detection subsystem  can change an operating mode of the proximity sensor from a passive mode to an active mode. In the active mode, the proximity sensor can detect a nearby object (e.g., human face ) and produce proximity output . Proximity output  can be a binary value (e.g., \u201cyes\u201d or \u201cno\u201d) or a scale value indicating a likelihood that mobile device  is near an object, or indicating a distance between the mobile device and an object.","Based on proximity output , proximity detection subsystem  can determine whether to confirm recognized gesture . If proximity detection subsystem  confirms recognized gesture , proximity detection subsystem  can notify interface . Interface  can include an application programming interface (API) of a system function or an application program. Upon receiving the confirmation through interface , the system function or the application program can perform a task based on recognized gesture .",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 3","b":["202","110","110","206","110","308","308","110","206","308","206","308","206"]},"In some implementations, dynamic filtering subsystem  can apply a filtering threshold, which can be at least one of an acceleration value or an angular rate value. If a motion vector V exceeds the filtering threshold on at least one axis (e.g., axis X), dynamic filtering subsystem  can process a series of one or more motion vectors V . . . Vi that precede the motion vector V in time to generate a new motion vector V\u2032 for replacing motion vectors V . . . Vi. Dynamic filtering subsystem  can generate motion vector V\u2032 by calculating an average of vectors V . . . Vi. Thus, dynamic filtering subsystem  can create normalized motion sensor readings that has fewer items in the time series.","In addition, dynamic filtering subsystem  can be configured to select a portion of motion sensor readings  for further processing. The selection can be based on sliding time window . Motion sensor  can generate motion sensor readings  continuously. Dynamic filtering subsystem  can use the sliding window  to select segments of the continuous data, and generate normalized motion sensor readings  based on the selected segments.","Gesture recognition subsystem  can include motion identification subsystem . Motion identification subsystem  is a component of gesture recognition subsystem  that is configured to determine whether normalized motion sensor readings  matches a known motion pattern. Motion identification subsystem  can receive normalized motion sensor readings , and access motion pattern data store . Motion pattern data store  can include a storage device that stores one or more motion patterns . Each of motion patterns  can include a series of motion vectors and be associated with a sphere of influence (SOI) that defines an error margin. Motion identification subsystem  can compare the received normalized motion sensor readings  with each of the stored motion patterns , and recognize a gesture based on the comparison.","Comparing the received normalized motion sensor readings  with each of the stored motion patterns  can include a distance calculation. Motion identification subsystem  can include distance-calculating subsystem . Distance calculating subsystem  is a component of motion identification subsystem  that is configured to calculate a distance between normalized motion sensor readings  and each of the motion patterns . If the distance between normalized motion sensor readings  and a motion pattern P is within the radius of an SOI of the motion pattern P, motion identification subsystem  can identify a match and recognize gesture . Motion identification subsystem  can send the recognized gesture  to proximity detection subsystem . Further details of the operations of distance calculating subsystem  will be described below in reference to .",{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIGS. 4A-4B","FIG. 4A","FIG. 3"],"b":["311","311","402","402","402","311","402"],"sub":["x","y","z","i"]},"Distance calculating subsystem  (as described above in reference to ) can compare normalized motion sensor readings  to each of motion patterns , , and . The comparison can produce a match. If normalized motion sensor readings  matches at least one of motion patterns , , and , a gesture is tentatively recognized. The operations of comparison are described in further detail below in reference to .",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 4B","b":["318","318","311","206","206","206","318","410","311","311"],"i":["a","b","c"]},"In the example shown, normalized motion sensor readings  can include a time series of m normalized motion sensor readings RV() through RV(m). The motion pattern can include a time series of n motion vectors PV() through PV(n). In some implementations, the distance calculating subsystem  calculates the distance D(R, P) by employing directed graph . Directed graph  can include m\u00d7n nodes. Each node can be associated with a cost. The cost of a node (i, j) can be determined based on a distance between motion vectors RV(i) and PV(j). The distance can be a Euclidean distance, a Manhattan distance, or any other distance between two vectors in a multi-dimensional space.","Distance calculating subsystem  can add a directed edge from a node (i, j) to a node (i, j+1) and from the node (i, j) to a node (i+1, j). The directed edges between all nodes thus can form a grid, in which, in this example, multiple paths leads from the node (, ) to the node (m, n).","Distance calculating subsystem  can add, to directed graph , a source node S and a directed edge from S to node (, ), and target node T and a directed edge from node (m, n) to T. Distance calculating subsystem  can determine a shortest path between S and T, and designate the cost of the shortest path as the distance D(R, P) between R and P.","In some implementations, distance-calculating subsystem  can perform optimization on the comparing. Distance calculating subsystem  can perform the optimization by applying comparison thresholds  and . Comparison thresholds  and  can define a series of vector pairs between which distance-calculating subsystem  performs a distance calculation. By applying comparison thresholds  and , distance-calculating subsystem  can exclude those calculations that are unlikely to lead to a match. For example, a distance calculation between the first motion vector RV() in the normalized motion sensor readings  and a last motion vector PV(n) of a motion pattern is unlikely to lead to a match, and therefore can be omitted from the calculations.","Distance calculating subsystem  can compare the distance D(R, P) with a SOI associated with motion pattern P. If the distance is within the SOI, distance-calculating subsystem  can identify a match. A gesture can be tentatively recognized.",{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 5","b":["112","100","112","112","502","502","112","222","220","110"]},"To detect that mobile device  is in proximity to an object, proximity sensor  can emit an electromagnetic or electrostatic field and detect a change in the field. To detect the change, proximity sensor  can compare a reading of the field to a baseline. The baseline can be a reading of the electromagnetic or electrostatic field when no object is in detectable proximity of the proximity sensor. If an offset between the reading and the baseline satisfies a threshold, a proximity event can be detected.","Proximity sensor controller  can configure proximity sensor  to operate in a passive mode or an active mode. When proximity sensor  operates in a passive mode, proximity detection subsystem  can store a representation of the proximity event and (e.g., a timestamp of the occurrence of the proximity event) in proximity event cache . Proximity detection subsystem  can send a signal to interface  when a time difference between a timestamp of recognized gesture  and the timestamp of the occurrence of the proximity event is smaller than a threshold. When proximity sensor  operates in an active mode, proximity detection subsystem  can send a signal to interface  when proximity sensor  detects a proximity event.","Proximity sensor controller  can set proximity sensor  to passive mode by default. Proximity sensor controller  can set proximity sensor  to active mode when proximity sensor controller  receives recognized gesture  from gesture recognition subsystem . Proximity sensor controller  can set proximity sensor  back to passive mode when proximity detection subsystem  sends the signal to interface . Additionally, proximity sensor controller  can set proximity sensor  back to passive mode when, after a threshold time has passed since proximity sensor  is set to an active mode, proximity sensor  does not detect a proximity event.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIGS. 6A-6B","FIG. 6A"],"b":["602","2","604","1","2","1","606","2","3","2","1","608","2","1","3","2"]},{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIG. 6B","FIG. 6A"],"b":["1","622","2","624","1","2","1","626","627","2","3","628","2","1","2","1","630","3","608"]},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 7A","b":["700","100","702"]},"The mobile device can obtain () a motion reading from a motion sensor of the mobile device. While obtaining the motion reading from the motion sensor of the mobile device, the mobile device can determine a proximity baseline for the proximity sensor. Determining the proximity baseline for the proximity sensor of the mobile device can include setting the proximity sensor to a passive mode in which the proximity sensor generates one or more baseline readings, and determining the proximity baseline based on the baseline readings generated by the proximity sensor in the passive mode.","The mobile device can determine () that the motion reading indicates that the mobile device moves towards the object. Determining that the motion reading indicates that the mobile device moves towards the object can include comparing the motion reading to one or more pre-stored motion patterns, and determining that the mobile device is moving in a gesture towards the object based on a result of the comparing. The one or more pre-stored motion patterns can be associated with a gesture of moving the mobile device toward the object. Each pre-stored motion pattern can correspond to a manner of movement of the gesture.","In response to determining the motion reading indicates that the mobile device moves towards the object, the mobile device can obtain () a proximity reading from a proximity sensor of the mobile device. Obtaining the proximity reading can include setting the proximity sensor from the passive mode to an active mode in which the proximity sensor generates one or more readings for comparing with the proximity baseline. Determining that the motion reading indicates that the mobile device moves towards the object includes determining a motion beginning time. Setting the proximity sensor from the passive mode to the active mode occurs after a specified delay from the motion beginning time.","Based on the motion reading and the proximity reading, the mobile device can determine () that the mobile device has moved to the location proximate to the object. Determining that the mobile device has moved to the location proximate to the object can include determining that the proximity reading satisfies a specified proximity offset from the proximity baseline.","The mobile device can perform () the task according to the program instructions. Performing the task can include changing an input mode of the mobile device from the touch input mode to the speech input mode. Changing the input mode to the speech input mode includes configuring the mobile device to accept at least one of a speech command or a dictation.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 7B","b":["720","100","722"]},"The mobile device can receive () a recognized gesture from a gesture recognition subsystem of the mobile device. The mobile device can determine () whether the proximity sensor detected a proximity event within a threshold time period (e.g., 100 milliseconds) before receiving the recognized gesture.","If the mobile device determines that the proximity sensor detected a proximity event within a threshold time period before receiving the recognized gesture, the mobile device can confirm the proximity event. Upon confirmation, mobile device can perform () a task (e.g., changing an input mode to voice input mode). In addition to performing the task, the mobile device can set () the proximity sensor back to passive mode.","If the mobile device determines that the proximity sensor did not detect a proximity event within a threshold time period before receiving the recognized gesture, the mobile device can set () the proximity sensor to operate in an active mode. The mobile device can determine () whether the proximity sensor has detected a proximity event within a threshold time period (e.g., 100 milliseconds) after receiving the recognized gesture. If the proximity sensor has detected a proximity event within a threshold time period after receiving the recognized gesture, the mobile device can perform () the task. Otherwise, the mobile device can set () the proximity sensor to operate in passive mode.",{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 7C","b":["740","100","742"]},"The mobile device can obtain () a motion reading from one or more motion sensing devices of the mobile device. The motion sensing devices can include at least one of an accelerometer, a gyroscope, a magnetometer, a light sensor, or a gravimeter.","The mobile device can detect () a gesture event based on the motion reading. Detecting the gesture event can include determining that the motion reading indicates that the mobile device moves towards a target object in one or more specified fashions.","The mobile device can detect () a proximity event. Detecting the proximity event can include obtaining a proximity reading from a proximity sensor of the mobile device. The proximity reading can indicate that the mobile device is located proximate to an object. Detecting the proximity event can include setting the proximity sensor to operate in a passive mode in which a trigger of the proximity sensor causes an event notification of a proximity event. Detecting the proximity event can include detecting the proximity event when the proximity sensor operates in the passive mode.","The mobile device can determine (), based on the gesture event and the proximity event, that the mobile device has moved to the location proximate to the target object. Determining that the mobile device has moved to the location proximate to the target object can include determining that the mobile device has moved to the location proximate to the target object when the proximity event is detected within a threshold time period before detecting the gesture event, or when the proximity event is detected within a threshold time period after detecting the gesture event. Determining that the mobile device has moved to the location proximate to the target object can include setting the proximity sensor to switch from a passive mode to an active mode upon detection of the gesture event. When operating in the active mode, a trigger of the proximity sensor can cause an event notification of a proximity event, a turning off of a backlight of a display, or a turning off of a touch input of a touch-sensitive input device.","The mobile device can perform () the task according to the program instructions. The task can include turning off a touch-sensitive display screen and switching an input mode of the mobile device between touch input mode and voice input mode.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 8","b":["800","802","804","806","802","804","806","804","100"]},"Sensors, devices, and subsystems can be coupled to peripherals interface  to facilitate multiple functionalities. For example, motion sensor , light sensor , and proximity sensor  can be coupled to peripherals interface  to facilitate orientation, lighting, and proximity functions of the mobile device. Motion sensor  can include one or more accelerometers configured to determine change of speed and direction of movement of the mobile device. Location processor  (e.g., GPS receiver) can be connected to peripherals interface  to provide geopositioning. Electronic magnetometer  (e.g., an integrated circuit chip) can also be connected to peripherals interface  to provide data that can be used to determine the direction of magnetic North. Thus, electronic magnetometer  can be used as an electronic compass. Gravimeter  can be coupled to peripherals interface  to facilitate measurement of a local gravitational field of Earth.","Camera subsystem  and an optical sensor , e.g., a charged coupled device (CCD) or a complementary metal-oxide semiconductor (CMOS) optical sensor, can be utilized to facilitate camera functions, such as recording photographs and video clips.","Communication functions can be facilitated through one or more wireless communication subsystems , which can include radio frequency receivers and transmitters and\/or optical (e.g., infrared) receivers and transmitters. The specific design and implementation of the communication subsystem  can depend on the communication network(s) over which a mobile device is intended to operate. For example, a mobile device can include communication subsystems  designed to operate over a CDMA system, a WiFi\u2122 or WiMax\u2122 network, and a Bluetooth\u2122 network. In particular, the wireless communication subsystems  can include hosting protocols such that the mobile device can be configured as a base station for other wireless devices.","Audio subsystem  can be coupled to a speaker  and a microphone  to facilitate voice-enabled functions, such as voice recognition, voice replication, digital recording, and telephony functions.","I\/O subsystem  can include touch screen controller  and\/or other input controller(s) . Touch-screen controller  can be coupled to a touch screen  or pad. Touch screen  and touch screen controller  can, for example, detect contact and movement or break thereof using any of a plurality of touch sensitivity technologies, including but not limited to capacitive, resistive, infrared, and surface acoustic wave technologies, as well as other proximity sensor arrays or other elements for determining one or more points of contact with touch screen .","Other input controller(s)  can be coupled to other input\/control devices , such as one or more buttons, rocker switches, thumb-wheel, infrared port, USB port, and\/or a pointer device such as a stylus. The one or more buttons (not shown) can include an up\/down button for volume control of speaker  and\/or microphone .","In one implementation, a pressing of the button for a first duration may disengage a lock of the touch screen ; and a pressing of the button for a second duration that is longer than the first duration may turn power to mobile device  on or off. The user may be able to customize a functionality of one or more of the buttons. The touch screen  can, for example, also be used to implement virtual or soft buttons and\/or a keyboard.","In some implementations, mobile device  can present recorded audio and\/or video files, such as MP3, AAC, and MPEG files. In some implementations, mobile device  can include the functionality of an MP3 player. Mobile device  may, therefore, include a pin connector that is compatible with the iPod. Other input\/output and control devices can also be used.","Memory interface  can be coupled to memory . Memory  can include high-speed random access memory and\/or non-volatile memory, such as one or more magnetic disk storage devices, one or more optical storage devices, and\/or flash memory (e.g., NAND, NOR). Memory  can store operating system , such as Darwin, RTXC, LINUX, UNIX, OS X, WINDOWS, or an embedded operating system such as VxWorks. Operating system  may include instructions for handling basic system services and for performing hardware dependent tasks. In some implementations, operating system  can include a kernel (e.g., UNIX kernel).","Memory  may also store communication instructions  to facilitate communicating with one or more additional devices, one or more computers and\/or one or more servers. Memory  may include graphical user interface instructions  to facilitate graphic user interface processing; sensor processing instructions  to facilitate sensor-related processing and functions; phone instructions  to facilitate phone-related processes and functions; electronic messaging instructions  to facilitate electronic-messaging related processes and functions; web browsing instructions  to facilitate web browsing-related processes and functions; media processing instructions  to facilitate media processing-related processes and functions; GPS\/Navigation instructions  to facilitate GPS and navigation-related processes and instructions; camera instructions  to facilitate camera-related processes and functions; magnetometer data  and calibration instructions  to facilitate magnetometer calibration. The memory  may also store other software instructions (not shown), such as security instructions, web video instructions to facilitate web video-related processes and functions, and\/or web shopping instructions to facilitate web shopping-related processes and functions. In some implementations, the media processing instructions  are divided into audio processing instructions and video processing instructions to facilitate audio processing-related processes and functions and video processing-related processes and functions, respectively. An activation record and International Mobile Equipment Identity (IMEI) or similar hardware identifier can also be stored in memory . Memory  can include location instructions . Motion instructions  can be a computer program product that is configured to cause the mobile device to perform motion-based operations, including gesture recognition operations and gesture confirmation operations, as described in reference to .","Each of the above identified instructions and applications can correspond to a set of instructions for performing one or more functions described above. These instructions need not be implemented as separate software programs, procedures, or modules. Memory  can include additional instructions or fewer instructions. Furthermore, various functions of the mobile device may be implemented in hardware and\/or in software, including in one or more signal processing and\/or application specific integrated circuits.",{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 9","b":["900","902","902","910","912","914","916","918","914"],"i":["a ","b "]},"In some implementations, both voice and data communications can be established over wireless network  and the access device . For example, mobile device can place and receive phone calls (e.g., using voice over Internet Protocol (VoIP) protocols), send and receive e-mail messages (e.g., using Post Office Protocol  (POP3)), and retrieve electronic documents and\/or streams, such as web pages, photographs, and videos, over wireless network , gateway , and wide area network  (e.g., using Transmission Control Protocol\/Internet Protocol (TCP\/IP) or User Datagram Protocol (UDP)). Likewise, in some implementations, the mobile device can place and receive phone calls, send and receive e-mail messages, and retrieve electronic documents over the access device  and the wide area network . In some implementations, mobile device or can be physically connected to the access device  using one or more cables and the access device  can be a personal computer. In this configuration, mobile device or can be referred to as a \u201ctethered\u201d device.","Mobile devices and can also establish communications by other means. For example, wireless mobile device can communicate with other wireless devices, e.g., other mobile devices or , cell phones, etc., over the wireless network . Likewise, mobile devices and can establish peer-to-peer communications , e.g., a personal area network, by use of one or more communication subsystems, such as the Bluetooth\u2122 communication devices. Other communication protocols and topologies can also be implemented.","The mobile device or can, for example, communicate with one or more services  and  over the one or more wired and\/or wireless networks. For example, one or more motion training services  can be used to determine one or more motion patterns. Motion pattern service  can provide the one or more one or more motion patterns to mobile devices and for recognizing gestures.","Mobile device or can also access other data and content over the one or more wired and\/or wireless networks. For example, content publishers, such as news sites, Rally Simple Syndication (RSS) feeds, web sites, blogs, social networking sites, developer networks, etc., can be accessed by mobile device or . Such access can be provided by invocation of a web browsing function or application (e.g., a browser) in response to a user touching, for example, a Web object.","A number of implementations of the invention have been described. Nevertheless, it will be understood that various modifications can be made without departing from the spirit and scope of the invention. For example, each subsystem, component, or unit described above can include a hardware device, software instructions, or both."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIGS. 4A-4B"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIGS. 6A-6B"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 7A-7C"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
