---
title: Method and system for improving equity trade order acknowledgement times
abstract: A method and system for improving stock exchange equity trade order acknowledgment times including a network appliance (“trade accelerator”) in the sub-network of the trading platforms, having a specialized network flow processor with associated micro-code and a host processor running specialized software. Specialized network appliance software sensitive to trading protocols for communicating between trading platforms and exchange servers detects latency variations in trade order acknowledgments at the exchange and recommends to subscribing trading platforms a least latency trade order path.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08655769&OS=08655769&RS=08655769
owner: Cape City Command, LLC
number: 08655769
owner_city: Wilmington
owner_country: US
publication_date: 20120607
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATION","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["This application claims the benefit of U.S. Provisional Application No. 61\/611,928, filed Mar. 16, 2012.","The present invention relates in general to the electronic performance of equity trade transactions, and electronic methods and systems for analyzing network latency to quickly carry out such trades.","Due to popularity of high frequency algorithmic trading, reducing latency in order acknowledgment times is becoming important. The chances of filling trade orders are higher if the trade order reaches the exchange quicker. It is generally believed that profits are correlated with order fill rate so the greater the fill rate the greater the profits.","Several methods have been proposed to reduce the latency, including faster transmission lines, kernel bypass methods for transmission and reception of data at the trading engine, and physical co-location of the trading engine at the exchange facility. While such methods are very effective in getting the trade order across to the exchange very quickly, they do not take into consideration the latency introduced at the exchange itself due to heavy trading volumes. This latency serves to delay order acknowledgment times on certain exchange ports (also called flows) at certain times. The delays are temporal and random in nature. Trading engine software typically uses a \u2018round-robin\u2019 algorithm to distribute trade orders evenly across multiple exchange ports. However, this can increase order acknowledgment times on those exchange ports that have a heavy load on them particularly during busy periods.","Therefore, it would be beneficial to have improved systems and methods for reducing latency in order acknowledgment times, and especially systems and methods which take into consideration the latency introduced at the exchange itself.","This invention, which preferably includes a trade accelerator and a set of application programming interfaces (\u201cAPIs\u201d), solves or reduces the exchange latency problem by tracking order acknowledgment times and providing a \u2018least latency\u2019 path recommendation to the trading engine software. By using this recommendation, the trading engine is able to transmit trade orders to exchange servers that are relatively lightly loaded thereby obtaining faster order acknowledgment times.","In certain embodiments, the invention provides a method and system for improving stock exchange equity trade order acknowledgment times includes a network appliance (\u201ctrade accelerator\u201d) in the sub-network of the trading platforms, having a specialized network flow processor with associated micro-code, and a host processor running specialized software. Specialized network appliance software sensitive to trading protocols for communicating between trading platforms and exchange servers detects latency variations in trade order acknowledgments at the exchange and recommends to subscribing trading platforms a least latency trade order path. These recommendations can be used to identify and transmit trade orders to the least latency exchange server. Trading platform software uses APIs to subscribe to and receive recommendations. The network appliance adapts to the temporal nature of latency at exchange servers and adjusts recommendations in real time. Path latency between the trading platform and exchange servers and also latency introduced by heavy trading period server loads are taken into account.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 1","b":"101"},"With reference to the embodiment shown in , Trading engines  1 to \u2018m\u2019 submit trade orders to matching engines  1 to \u2018n\u2019 for execution. The trade accelerator  is preferably placed in the same sub-network as the trading engines  using a packet switching device (\u201cPacket Switch\u201d ), such as those which are known in the art. Placing the trade accelerator  in this sub-network increases its efficiency and accuracy. The packet switch  preferably has port-mirroring capability (also called SPAN or switched port analyzer capability). In , the matching engines  are also shown in the same sub-network as the trading engines . However, the matching engines  may instead be placed elsewhere, including anywhere on the internet. In such a case, a router is preferably placed in the same sub-network as the trading engines  establishing end-to-end connectivity between the trading engines  and matching engines  over the internet, or end-to-end connectivity between the trading engines  and matching engines  is otherwise established. In , a single trade accelerator  is shown working with \u2018m\u2019 trading engines  on the sub-network. However, multiple trade accelerators may be configured to work on the sub-network. The decision to use multiple trade accelerators depends primarily upon the number of matching engines  that are being accessed and the exchange communications protocols being used by the trading engines  to submit orders to matching engines .",{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 2","FIG. 2"],"b":["203","203","205","204","203","204","203","204","203","204","203","203","203","203","203"]},"In , assuming that the assigned communication flows  (shown as the thick lines between the trader\/brokers and the matching engines) are of equal bandwidth and latency, a trader\/broker company may explore a couple of options to ensure that its trades reach the ME  faster than its competitors. One way is to ensure that the TE  itself is fast. Another option is to use the assigned flows  such that their orders are spread evenly between the MEs . It is known for TEs  to use a \u2018round-robin\u2019 algorithm. With such a \u2018round-robin\u2019 algorithm, every TE transmits orders to the MEs in a round-robin fashion. While the \u2018round-robin\u2019 algorithm is simple, it may not be optimal for at least the reason that a given trader\/broker's TEs  lack knowledge about the size and number of orders being placed by competitors\u2014or by other TEs  belonging to the same company\u2014on the MEs . Especially during heavy trading periods, some MEs  may take slightly longer to accept a given trader\/broker's order. While the delay is likely to be temporal in nature, a one millisecond savings in order acceptance could potentially be worth $100 million a year to a brokerage firm due to competition between firms.","In an embodiment of the present invention, a trade accelerator works with TEs , preferably those within the same single sub-network (as shown for example in ) to provide recommendations on which ME  to send a trade order to. Thus, the known \u2018round-robin\u2019 algorithm need not be relied on. In an embodiment, MEs  that accept trade orders quicker are recommended more often than MEs  that exhibit a relative delay. Over time, the MEs  that were exhibiting delays may start to work quicker while other MEs  start to exhibit delays. A trade accelerator preferably detects these variations and preferably constantly adjusts its recommendations based on these variations. By using a trade accelerator, the standard \u2018round-robin\u2019 approach is preferably replaced by a superior \u2018least latency\u2019 approach that takes into consideration at least the order acceptance times of the different MEs and may additionally take into consideration the temporal nature of these deviations. A trade accelerator's overall effect from employing the \u2018least latency\u2019 approach may be to reduce order acceptance times for the TEs  (which are preferably in the same sub-network as the trade accelerator) making use of the trade accelerator.",{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 3","FIG. 6","FIG. 3","FIG. 6"],"b":["301","601","301","601","306","606","307","607","303","603","301","601","301","601","308","608","303","603","301","601","304","604","303","603","304","604","303","603"]},{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 3","FIG. 3"],"b":["301","301","308","308","308","304","307","308","301","304"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 6","b":["601","608","608","603","601","608","607"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIG. 4","FIG. 1"],"b":["411","410","412","411","102","409","411","411","410","410","415","412","413","414","410","411","410","413","411","413","410","413","414","411","413"]},"The preferable overall flow of the network processor micro-code is shown using the flow chart on . Once the network processor is initialized, configured and started up, it preferably either processes commands from the host processor or assembles socket level data flowing over the configured TCP flows. In this flow shown in , first initialization, such as NFP board initialization, occurs at step . Then flow parameters are received from the host processor at step . The ingress port is checked at step . A determination is made as to whether there is a protocol packet requiring processing at step . If so, it is processed at step . Otherwise, the PCI command channel is checked at step . A determination is then made as to whether there is a command from the host processor at step . If so, the command is processed at step . Otherwise, the process returns to step .",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIGS. 7A and 7B"},"In the process of , a packet such as an ivP4 packet is read at step . If the packet is fragmented, as determined at step , an attempt at reassembly is made at step . If it is determined at step  that this reassembly did not occur, then an error check is performed at step . If there was an error, then re-assembly is abandoned at step  and a new packet is read. In the absence of an error, the next packet is also read. If it is determined at step  that this reassembly was successfully accomplished, of if the packet was determined at step  not to be fragmented, then the packet's payload is checked at step . If the packet is determined to be a TCP packet (at step ) and on a configured TCP flow (at step ), then an attempt is made to re-assemble the TCP socket data at step . Otherwise, the next packet is read. After this attempt, a check is performed as to whether the re-assembly has been done at step . If so, the data is placed in a host queue at step  and then the next packet is read. Otherwise, a determination is made as to whether there has been an error in the reassembly of the socket data at step . If so, the socket data re-assembly process is abandoned at step , and then the next packet is read. Otherwise, the next packet is also read.","On the host processor side, with reference to , the software preferably executes on two processing threads after start-up, initialization and configuration (which includes downloading micro-code to the network processor). Initially, self-initialization is executed (step ), then NFP micro-code is loaded, and starting, initialization and configuration of NFP occurs (step ). Then, a packet processing thread and a command processing thread are started (step ). Then, once it is determined that a termination signal is received (steps  and ), NFP is stopped and termination occurs (step ). On one thread indications or responses coming from the network processor are processed. On the other thread connection requests and subsequent commands coming in from any external client are responded to. The commands preferably include or relate to subscription requests to receive flow rankings, flow management commands (for example, commands to start tracking a flow, to stop tracking a flow, and to reset a flow) and network processor control commands such as stop, start or reset. This is as shown in . In this figure, a self-initialization sequence is executed (step ). Then, the system listens for incoming connections (step ). Once a connect request is determined to be received (step ), the system connects to the client and parses a message (step ). If the message is determined to not comprise a valid command, then the system disconnects from the client (step ) and returns to listening for incoming connections (step ). Otherwise, the command is processed (step ) and a response is sent to the client (step ).",{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 10","FIG. 6","FIG. 10"],"b":["1040","1041","1042","1043","1044","1046","1047","1045","1048"]},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 11","b":["1150","1151","1152","1153","1156","1157"]},"A flow rankings activity can be triggered when a trade \u2018order acknowledgment\u2019 packet from an ME to a TE is detected (at step ) by the host processor on a configured flow and that particular order is currently being tracked by the host processor. Similarly a detected (at step ) trade \u2018order canceled\u2019 packet can also trigger a fresh flow rankings activity. Both types of messages are processed. (at steps  and , respectively). It is sometimes possible that the host processor may miss receiving trade\/cancel order requests or their corresponding acknowledgments. This is because, during heavy traffic conditions, the network switch may drop packets destined for the SPAN or mirrored ports. Any such mismatch (for example, receiving an order acknowledgment packet with the original trade order never having been received by the host processor) causes the host processor to discard the packet and decay out the pending order or order cancel. If the message is none of the four types listed above, it is ignored (at step ).",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 12","FIG. 12"],"b":["1250","1251","1252","1253","1254"]},{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 13","FIG. 13"],"b":["1350","1351","1352","1353","1354"]},"The trade accelerator is preferably used by executing the following steps:\n\n","According to one embodiment of the present invention, the disclosed systems and methods allow for delivery and configuration of flow rankings, such as TCP flow rankings, to subscribing TEs. In a further embodiment, a multicast message can carry the flow rankings, which can be a fixed-length message, and which can have reserved slots to carry flow rankings, such as on a per-subscription identifier basis. A subscription-identifier is a unique way for a stock exchange to identify a trading account. Each trader\/broker company may have one or more subscription identifiers on a stock exchange. A trader\/broker company may organize to trade on these subscription accounts over a unique set of TCP flows rented from the exchange (for example, all trades done under subscription identifier \u201cXYZ\u201d may travel on TCP flows \u201cNASD01\u201d to \u201cNASD04\u201d while all trades done under subscription identifier \u201cABC\u201d may travel on TCP flows \u201cNASD05\u201d to \u201cNASD08\u201d). In yet another embodiment, the trade accelerator reserves slots and\/or byte locations in the multicast message for a set of flows belonging to a particular subscription identifier. The TEs may be informed about the locations in the multicast message where flow ranking information will be available for the trading account that it will use to place trades. Each associated TCP flow may be identified by a unique flow identification number. This may be done as part of a SessionScheduler::init API functionality, for example as discussed above in connection with .","In one embodiment which may be understood as extending the previous example, the trade accelerator may inform a TE that ranking information related to subscription identifier \u201cXYZ\u201d will be available in multicast message byte locations , ,  and , thereby implying that the top ranked TCP flow associated with subscription identifier \u201cXYZ\u201d will be found in message byte location , the next in byte location  and the last ranked flow in message byte location . Further, the trade accelerator may assign unique TCP flow identifiers that will be used in the rankings message such as 6 for \u201cNASD01\u201d,  for \u201cNASD02\u201d,  for \u201cNASD03\u201d and 40 for \u201cNASD04\u201d. Once this bind is performed by the trade accelerator, the TE is ready to receive and process the multicast ranking message.","In certain embodiments, the trade accelerator may associate a logical TCP flow name such as \u201cNASD01\u201d with a unique address (such as an IPv4 address) and TCP port number which represents the exact exchange server destination to which a trade order will be delivered. This may be configured into the trade accelerator at start-up. Preferably, when the trade accelerator creates a flow rankings message, following the above example, if the flow rankings are \u201cNASD04\u201d, \u201cNASD01\u201d, \u201cNASD03\u201d and \u201cNASD02\u201d then in the rankings message, byte location  will contain 40, byte location  will contain 6, byte location  will contain 25 and byte location  will contain 10.","By using such methods as are described herein for reporting rankings, multiple groups of trading accounts tied to associated groups of TCP flows may be supported.","While the invention has been particularly shown and described with reference to the embodiments thereof, those skilled in the relevant art will understand that changes in form and detail may be made to these embodiments without departing from the spirit and scope of the invention. For example, although the invention has been shown with respect to particular financial products and trades, trading exchanges, and protocols, the present invention may also be used with respect to other financial products or trades, other trading exchanges, and with other protocols as well as with similar latency sensitive transactions outside of trading."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1","b":["101","102","103","104"]},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIGS. 7A and 7B"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 19"}]},"DETDESC":[{},{}]}
