---
title: Cache and index refreshing strategies for variably dynamic items and accesses
abstract: Many computing scenarios involve an item cache or index, comprising items corresponding to source items that may change without notice, rendering the item in the item cache or index stale. It may not be possible to guarantee the freshness of the items, but it may be desirable to reduce staleness in an efficient manner. Therefore, the refreshing of items may be prioritized by first predicting the query frequency of respective item representing the rate at which an item is retrieved from the item cache (e.g., by monitoring queries for the item), predicting an update frequency representing the rate at which the source item is updated by the source item host (e.g., by classifying the source item type), and computing a refresh utility representing the improvement in cache freshness achieved by refreshing the item. Respective items may then be prioritized for refreshing according to the computed refresh utilities.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09213780&OS=09213780&RS=09213780
owner: Microsoft Technology Licensing LLC
number: 09213780
owner_city: Redmond
owner_country: US
publication_date: 20090626
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Many computing scenarios may involve a cache configured to store an item cache comprising items corresponding to source items stored by one or more source item hosts. The cache might be configured, e.g., to store local versions of the source items; as a descriptor of the source items, such as metadata relating to respective source items; or as an index of the source items. In some of these scenarios, the source items may be variably dynamic, referring to the volatility of the presence and the content of items: some items may be static, other items may be updated infrequently, and other items may change frequently; and where some items are updated at a consistent frequency, while updates of other items are fluctuating or erratic. Respective source items may therefore change at the source item host, but with a variable frequency of changing. However, the cache may not be notified by the source item host when a source item changes, so some of the items in the cache may be stale, i.e., not necessarily reflecting the up-to-date version of the source item available at the source item host. The cache may endeavor to refresh respective items in the cache through a polling mechanism, e.g., requesting the corresponding source item from the source item host and refreshing the item in the cache with any changes since the previous refreshing of the item. However, the cache refreshing may involve considerable computing resources, such as a limited download capacity for receiving items from source item hosts that are accessible over a network. The challenge of refreshing caches also extends to the closely related challenge of maintaining a fresh index of a large-scale resource like the Worldwide Web, where a local index is used to support such services as search and retrieval.","This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.","Due to the scarcity of computing resources available for refreshing items in the cache, an allocation strategy may be employed to allocate refreshing resources for various items, such that items of higher priority may be refreshed before or more frequently than items of lower priority. This priority may be based, e.g., on at least two factors: a predicted query frequency of queries requesting the item, and a predicted update frequency of the source item by the source item host. The query frequency for an item and the update frequency of the source items may be predicted based on a real-time or an ongoing monitoring of queries and page changes. However, either quantity may be difficult to estimate for some future period. Such difficulties can arise because of context-sensitive variation in the queries and\/or page changes. Another challenge is that new items, i.e., items that have not been monitored in the past, may be created and thus come into existence, and predicted queries and update rates may not be available. One technique for predicting the query frequencies and\/or the update frequencies of particular items involves training and applying one or more probabilistic classifiers. Such classifiers can be developed for predicting queries and for content change. The probabilistic classifiers for each prediction can be developed to predict steady-state quantities and rates or to, more generally, consider and predict the dynamics of numbers of queries or item changes. Similarly, it is feasible to build classifiers of the update frequencies, including steady state and dynamics of the rate of change, of the source item (based on various factors, such as the nature of the content in the source item and the source item host) to identify a source item type, and then choosing an update frequency that is typical of source items of the identified source item type. Such probabilistic classifiers may be developed in many ways, including heuristically and through a machine learning technique, such as a neural network classifier or a Bayesian classifier.","If the query frequency for the items and the update frequency of the corresponding source items may be predicted, the items may be prioritized for refreshing, such that items of higher priority (items that are frequently requested in queries, and that correspond to source items that are frequently updated by the source item host) are refreshed more frequently than items of lower priority (items that are not requested by queries often, or that do not change often.) Items at the ends of the spectrum may be excluded from the refreshing mechanism (e.g., items that change so frequently that the item in the cache is almost never up-to-date may be excluded from the cache and simply retrieved from the source item host upon each query; conversely, source items that change very infrequently or that correspond to items that are very rarely queried may be rarely or not periodically refreshed.) The prioritization may be based on a utility model, where the resources available for refreshing items may be allocated in a manner that achieves a desirably high utility. This utility may be viewed, e.g., as the decrease in the odds that a query for an item from the cache may receive a stale version of the item. This computation may take into account the query frequency for the item (how many queries may be incorrectly fulfilled with a stale copy of the item from the item cache?) and the odds (in view of the predicted update rate and the date of the last refreshing) that the source item has been updated by the source item host since the corresponding item was last refreshed. The utility model may be devised based on allocating the refreshing resources to reduce these probabilities, and algorithms may rely on the utility model in choosing to allocate refreshing resources to different sets and types of items in the item cache.","To the accomplishment of the foregoing and related ends, the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects, advantages, and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.","The claimed subject matter is now described with reference to the drawings, wherein like reference numerals are used to refer to like elements throughout. In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident, however, that the claimed subject matter may be practiced without these specific details. In other instances, structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.","Many computing scenarios involve a caching of source items that may be stored at one or more source item hosts, where the source items may be updated by the source item hosts with varying frequencies. Some caches have a low tolerate any degree of \u201cstaleness,\u201d where the cached items may reflect out-of-date items available at the source item hosts; e.g., a memory cache providing rapid access to system memory or a storage device may depend on up-to-date items. However, for other types of caches, eliminating staleness may not be feasible, but reducing staleness may be desirable. These caches may endeavor to refresh items by polling the source item hosts, e.g., by periodically requesting an updated copy of the source item from the source item host and by propagating updates to the corresponding item in the item cache. As a first exemplary scenario, a web proxy may utilize these techniques in order to maintain the freshness of items stored in a proxy cache, which may be positioned between a user population (such as a local area network) and the internet to improve the efficient use of internet-facing bandwidth. For example, the user population may frequently request a particular set of web pages, and the proxy cache may reduce the redundant fetching of these web pages upon each request by automatically fetching the web page into the proxy cache and providing the cached web page to the users instead of the live page. While this technique may be helpful, the items in the proxy cache have to be maintained in order to avoid serving stale versions of the cached web pages to the users. As a second exemplary scenario, a web search engine may explore the pages or other items comprising a portion of the web (e.g., with a web crawler) and may store local representations of the discovered web pages in a local cache for use in providing search results for a search query. However, as the represented web pages change, the local representations may have to be refreshed in order to provide accurate web search results.",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1","b":["10","14","12","14","18","16","12","18","16","18","14","12","18","18","16","14","12","18","20","14","12","20","14","12","22","14","12","18","16","14","18","14","18","18","18","12","14"]},"In these and other scenarios, stale results, while not necessarily fatal to the operation of the item cache , are to be avoided by allocating cache refreshing resources  in a manner that reduces the probability of serving an out-of-date item. For example, the cache refreshing resources  may be allocated to refresh the items  in the item cache  based on various relevant factors. A first relevant factor is the query frequency for the item  in the item cache  (e.g., the frequency with which users request a particular source item , such as a web page, which may be expediently served from the item cache , or the frequency with which a particular query is executed against a database, such as by a data-driven application.) A higher query frequency implies a higher incurred penalty from serving a stale version of the item , which therefore warrants a higher refresh frequency. A second relevant factor is the frequency with which the source item  is updated by the source item host ; items  corresponding to source items  that are more frequently updated by the source item host  may be refreshed more frequently than items  corresponding to source items  that are less frequently updated by the source item host . Other factors may also be relevant to the manner of allocating the cache refreshing resources  applied to the item cache . For example, the refreshing of some items  may be more significant than the refreshing of other items ; e.g., the penalty of serving an old version of a news report in the item cache may be much higher than the penalty of serving an old version of an academic article in the item cache , even if both items  change at a similar frequency.","If the query frequency of items  and the update frequency of corresponding source items  may be determined or estimated, then a refresh utility for the item  may be selected. A cache refreshing policy may be selected in pursuit of many priorities, such as allocating resources to refresh the most frequently requested items ; maximizing the percentage of fresh items  in the item cache ; or most efficiently allocating the cache refreshing resources , such that the requests are only issued for source items  that are most likely to have been updated since the last refresh of the corresponding item . Depending on the selected priorities and the comparative significance thereof, the strategy for refreshing the item cache  may be configured to allocate the cache refreshing resources  that most efficiently promote these priorities, i.e., in order to achieve the most useful allocation of the cache refreshing resources . Therefore, the refresh strategies utilized in these techniques may involve using the predicted query frequency and update frequency of respective items  in order to devise a refreshing policy that achieves a high refresh utility, according to the selected set of priorities and the comparative significance thereof.","Based on this perspective, techniques may be developed to select an allocation of cache refreshing resources  in order to maximize the refresh utility of the item cache  achieved thereby. As a first example, models may be devised and applied that relate the predicted query frequencies and update frequencies of respective items to a computation of the refresh utility attributed to any particular resource, i.e., to the increase in the refresh utility achieved by refreshing a first item  as compared with refreshing a second item . This computation may vary according to different sets of priorities; e.g., the penalty of serving an out-of-date item  may be differently factored into the computation, as well as the significance of efficiency (i.e., is a penalty incurred if a refresh is attempted of an item  that is not out of date?)","These models may output many types of recommended cache refreshing strategies, such as a ranking of items  to be refreshed; as a recommended refresh frequency for respective items , i.e., the frequency with which the cache refresh resources  may advantageously refresh a particular item  based on its predicted query frequency and the predicted update frequency of the corresponding source item ; or as the resulting flux of the measured utility for a particular set of items  in the item cache . An alternative model might compute a refresh probability for respective items ; e.g., a cache refresh resource  may choose an item  randomly from the item cache  to be refreshed, where the probabilities of selecting various items  may be weighed according to the refresh utility that may be achieved if this item  is selected for refreshing. For example, items  of descending priority in refreshing may have computed refresh probabilities (respectively) of 75%, 20%, and 5%; and a random allocation of the cache refresh resources  among these items  that is probabilistically weighted in this manner may achieve a high degree of refresh utility for the item cache . This stochastic approach may be more advantageous than a simple selection, e.g., selecting items  in a strict order according to the respective query frequencies  and the update frequencies , because a stochastic model permits items  allows for an occasional refreshing of items  with a consistently low refresh utility. It may also be advantageous to compute an aggregated prediction of the freshness quality of the items  of an item cache  in a particular state. This aggregated refresh utility metric may be used, e.g., to tweak the refresh strategies or in order to improve the measurement of utility, or to compare the relative effectiveness of two or more cache refresh strategies.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 2","b":["30","40","14","12","32","14","36","18","16","32","14","34","34","14","36","30","14","36","38","36","18","14","12","36","18","18","36","14","12","40","14","14","40","42","40"]},"While a refresh frequency  may be computed (based on a computed refresh utility) in various ways for respective items , the availability of cache refreshing resources  may also be relevant. A comparatively ambitious selection of refresh frequencies may overwhelm an inadequate set of available cache refreshing resources , while an overly lax selection of refresh frequencies may leave some cache refreshing resources  idle while stale items  accumulate in the item cache . Therefore, instead of assigning refreshing frequencies to items  in the abstract, it may be advantageous to prioritize the refreshing of items  in the item cache . A prioritization of items  may enable an allocation of cache refreshing resources  first for the highest priority items , and then continuing through lower priority items  until the cache refreshing resources  are fully allocated.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 3","b":["50","14","12","14","12","18","16","18","14","50","14","12","14","18","12","14","18","12","14","12","14","12","14","14","14","14","14","12","18","22"]},"The prioritization of the items  in  may be utilized to allocate cache refreshing resources  in an efficient manner. For example, in , the item cache  might alternatively be serviced by a first cache refreshing resource set , comprising a smaller set of cache refreshing resources , or by a second cache refreshing resource set , comprising a comparatively larger set of cache refreshing resources. The first cache refreshing resource set  may be allocated to the refreshing of items  in the item cache  starting with the highest priority item  (shown at the top) and continuing downward. However, the first cache refreshing resource set  may only be sufficient to cover an allocation  over the first three items . The remaining items  might be handled in many ways; e.g., an additional low-frequency cache refreshing resource  might endeavor to refresh every item in the item cache  on a low-frequency basis (e.g., once an hour.) By contrast, the second cache refreshing resource set  might comprise enough resources for an allocation  covering all but the lowest priority item . It may be appreciated from an examination of  that sorting the items  in the item cache  according to priority may promote the efficient allocation of a cache refreshing resource thereover.",{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 4","b":["60","14","14","12","60","16","18","14","12","60","62","64","66","68","32","14","70","36","16","18","72","14","32","36","72","72","14","64","74","14","14","12","32","36","60","22","76"]},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 5","b":["80","12","14","82","82","22","14","22","14","22","82","84","86","14","14","18","16","82","80","86","88","14","12","32","14","36","18","16","14","32","36","92","14","94","18","14","18","96","14","32","36","86","90","14","88","86","14","12","14","18","16"]},"Still another embodiment involves a computer-readable medium comprising processor-executable instructions configured to apply the techniques presented herein. An exemplary computer-readable medium that may be devised in these ways is illustrated in , wherein the implementation  comprises a computer-readable medium  (e.g., a CD-R, DVD-R, or a platter of a hard disk drive), on which is encoded computer-readable data . This computer-readable data  in turn comprises a set of computer instructions  configured to operate according to the principles set forth herein. In one such embodiment, the processor-executable instructions  may be configured to perform a method of prioritizing a refreshing of items provided in response to queries and stored in an item cache, such as the exemplary method  of . In another such embodiment, the processor-executable instructions  may be configured to implement a system for prioritizing a refreshing of items provided in response to queries and stored in an item cache, such as the exemplary system  of . Many such computer-readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.","The techniques discussed herein may be devised with variations in many aspects, and some variations may present additional advantages and\/or reduce disadvantages with respect to other variations of these and other techniques. Moreover, some variations may be implemented in combination, and some combinations may feature additional advantages and\/or reduced disadvantages through synergistic cooperation. The variations may be incorporated in various embodiments (e.g., the exemplary method  of  and the exemplary system  of ) to confer individual and\/or synergistic advantages upon such embodiments.","A first aspect that may vary among embodiments of these techniques relates to the scenarios in which the techniques may be utilized. As a first variation, a web proxy may be positioned between a large body of users and the internet in order to detect web pages that are frequently requested by the users, to store a cached version of such web pages, and to provide the cached version of the web page upon request. The web proxy may therefore conserve network throughput by reducing redundant requests for a particularly popular web resource by a large number of users. However, because the set of pages requested by users is potentially unlimited, it may not be feasible to cache all requested pages. Moreover, even with a constrained set of frequently requested pages, it may not be possible to poll the sources of such web pages often enough to guarantee freshness, due to both the high frequency with which many pages may be updated and the limited computing and network resources that may be available for performing the refreshing. Therefore, the web proxy may have to allocate the refreshing resources across the set of items in the item cache in such a manner to reduce the incidence of stale pages provided to users. Accordingly, the techniques discussed herein may be adapted for use with the proxy cache; e.g., if the source items comprising web-accessible source items hosted by webservers, and the item cache  comprises a proxy cache, the techniques described herein may be configured to store in the proxy cache the web-accessible source items  that are frequently requested by the users, and to provide an item  from the item cache  that corresponds to a web-accessible source item  requested by a user.","As a second variation of this first aspect, the techniques discussed herein may be applied to a web search engine that discovers web resources (e.g., web pages, data provided by web services, or dynamic images hosted by webservers) on at least a portion of the web (e.g., a particular domain or LAN, or web pages on a particular topic, or the entire worldwide web.) The web search engine may comprise an item cache  of items  representing various web resources, such as web pages, that may be used to provide search results in response to queries submitted by users for web resources that match particular criteria. The items  in the item cache  might represent the content of the corresponding source items , or might represent metadata identified about such source items  (e.g., keywords, categories, and page rankings) that may facilitate the generation of query results. However, as the corresponding web resources stored by the webservers change, the items  in the item cache  may have to be refreshed in order to promote the use of up-to-date information about the web resources in preparing and providing query results. For example, a web page comprising a movie listing may change often, and the web search engine may frequently update the page or result set stored in the cache corresponding to the movie listing in order to include and position the movie listing page in the result set of queries that may include movie titles. Therefore, the techniques discussed herein may be utilized to maintain the item cache  of the web search engine; e.g., if the source items  comprising web-accessible source items , and if the source item hosts  comprising webservers hosting the web-accessible source items , then the item cache , representing the web search cache, may be configured to identify web-accessible source items  corresponding to web queries received from web users.","The techniques discussed herein may also be applied to maintain the freshness of cached items  other than web resources. As a third variation, a database server may be configured to answer many types of queries based on highly dynamic data, and certain queries may be frequently applied to the database. A database query cache might endeavor to store and refresh up-to-date results from a set of commonly executed queries, instead of redundantly applying each received query to the database. However, the set may be sufficiently large, or the processing of the queries may be so computationally expensive, that the query results might be refreshed only occasionally. The database query cache may therefore have to prioritize the refreshing of queries in order to achieve an efficient allocation of the computational resources available for promoting the freshness of the database query cache. As a fourth variation, a local data search engine might be devised to perform local data searches among the objects comprising a computing environment (e.g., files contained on a network file server), and a search cache may be used to store and provide rapid access to commonly executed queries at a reduced computational and network cost. However, the local data search engine may not be able to monitor all file accesses for updates that affect the results of such commonly executed queries, and may not be able to poll the file server quick enough to guarantee up-to-date results; therefore, the local data search engine might prioritize the refreshing of results for commonly executed queries. Those of ordinary skill in the art may devise many scenarios involving an item cache  storing items  to which the techniques discussed herein may be applied.","A second aspect that may vary among embodiments of these techniques relates to the manner of predicting the query frequency  of a particular item . Many predictive techniques may be utilized in this capacity. As a first variation, requests issued to various items  may be tracked over a period of time, such as by recording requests for particular web-accessible items  in a web access log. A query frequency  for a particular item  may then be predicted by computing a query frequency  for the item  based on the rate of queries detected during the tracking, such as by evaluating the web access log to identify a set of commonly requested web-accessible items . The set of query frequency predictions may then be aggregated, e.g., by generating an item query frequency set that maps items  to predicted query frequencies. The item query frequency set may then be utilized (e.g., by the query frequency predictor  illustrated in ) during the computation of the refresh utilities of various items . Query frequencies of particular items  may change over time (e.g., as user preferences and behaviors for visiting particular websites change), and if the query frequency set is not updated periodically, it may attribute overly high refresh utilities for items  that are no longer heavily requested, and overly low refresh utilities for items  that are now more heavily requested than before.","Other variations of this second aspect may also be compatible with the techniques discussed herein. As a second variation, the item cache  may itself identify query frequencies; e.g., a web proxy may track the rate of requests for particular items  in order to maintain the proxy cache, such as by evicting unused items  in order to make room for new items . The techniques discussed herein may consume the query frequency information generated by the item cache  and may use this information in order to compute the refresh utilities  of the items . As a third variation, another source of query frequency information may be utilized, e.g., a report by a web tracking service that tracks the popularity of various web-accessible items (such as web pages) as general user preferences of internet users change. This variation may be advantageous where the sources of queries change frequently, such as a web proxy servicing a public WiFi location with high turnover in the user population. As a fourth variation, the query frequencies may be determined analytically (e.g., by a code profiler of a data-driven application that automatically identifies queries that the application often applies to a database) and\/or heuristically (e.g., by a set of items identified by a network administrator that, based on the knowledge of the network administrator, are likely to be requested often by users.)","As a fifth variation, the prediction of query frequencies for an item  may be predicted through the development and application of a probabilistic classifier for queries made to items. Such a classifier may be developed by monitoring the frequencies of accesses of items  as well as multiple aspects of the content of the source items , such as link structure, anchor text, and such contextual factors as the topics and keywords of breaking news stories. Probabilistic classifiers may be developed to predict the dynamics of such frequencies of querying of respective items . For example, machine learning methods may be trained on data so as to learn to predict queries for an item  containing information on a breaking news story. The training data might include information from multiple cases, where each news story is formulated into a set of attributes about the story (e.g., relative location to populations of users, degree of catastrophe, celebrity, etc.), and data about the dynamics of the resulting query frequencies of such items . As one example, a trained classifier may predict that interest and thus frequencies of queries of an item  representing a news story tends to rise at the time of the breaking of the news story or a story about a related topic that has been determined to have dependencies with interest based on similar or analogous histories of dependency (with dynamics described, e.g., as a sigmoid function with specific predicted parameters), and then decay in interest with a parameterized function (e.g., an exponential decay after some plateauing, as captured by parameters describing the plateau and the half-life of the decay).This may be achieved, e.g., by training the probabilistic classifier to predict query frequencies of items  based on a training item set comprising items associated with known query frequencies, and subsequently applying the probabilistic classifier to an item  to predict the query frequency of the item. Those of ordinary skill in the art may devise many ways of predicting the query frequencies for the items  stored in the item cache  while implementing the techniques discussed herein.","A third aspect that may vary among embodiments of these techniques relates to the manner of predicting the update frequency  of a source item . This factor may be more difficult to predict than query frequencies  (e.g., because query frequencies may be predicted from the aggregated behaviors of a large group of users; while the update frequency  may vary widely from one source item  to another source item .) A first variation of this third aspect may be based on the concept that particular criteria may be identified regarding a particular source item , where such criteria that may be relevant in predicting the update frequency  of the source item . These criteria might be extracted, e.g., through an automated parsing of the source item  (e.g., a natural language parser that may attempt to identify the type of content in a web page), an examination of metadata associated with the source item  (e.g., looking at date attributes of the source item  to determine when it was first created or last updated), or an examination of other factors that might lead to criteria relevant to the prediction of the update frequency of the source item  (e.g., an identification of the type of entity that manages the source item .)",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 7","b":["110","114","36","18","110","18","18","18","18","18","18","18","18","114","18","114","36","18","18","36","18","36","36","18"]},"The exemplary scenario  of  involves two types of processing applied to the source items : an extraction of source item criteria  relating to the source items  that may be relevant in predicting the update frequency , and the prediction of the update frequency  based on the source item criteria . The extraction of the source item criteria  (as performed, e.g., by a criterion identifier ) may involve many types of analysis. As a first example, an analysis of text contents of source item  may reveal various properties, such as semantics, style, vocabulary, and complexity, that may be correlated with various source item criteria  (such as a type of content  present in a web page.) As a second example, if the source items  comprise a type of media object, various forms of media analysis may be utilized to extract criteria about the media object; e.g., image processing techniques may be utilized to determine whether an image comprising the source item  is a photograph, a drawing, a painting, or a computer rendering. As a third example, aspects of the source item  may be compared with a knowledge source to extract relevant source item criteria ; e.g., a database of websites that identifies types of owners of particular websites might be referenced to identify the type of owner of a particular source item  hosted by a referenced website. As a fourth example, metadata associated with the source item  may be examined to extract relevant source item criteria ; e.g., the date of creation or the date of last modification of a source item  may be examined to extract the age of the source item .","Once these source item criteria  have been extracted, the source item criteria  may be examined together to predict the update frequency , which may be based, e.g., on typical update frequencies  that have been previously predicted and\/or identified of source items  sharing some or all of the source item criteria  of the source item . As a first example, different criteria  may be associated with different correlative weights in predicting the update frequency; e.g., the age of a source item  may be more relevant to the update frequency  than a type of owner of the source item . Moreover, patterns of source item criteria  may be identified; e.g., the owner of a source item  may be more relevant to the predicted update frequency  if the content is a type of news than if the content is information. It may be appreciated that many information processing techniques may be used to perform the extraction of source item criteria  and the prediction of the update frequency  based thereupon, such as machine learning techniques, including expert systems, neural networks, genetic algorithms, and Bayesian classifiers; knowledge mining and statistical analyses; and heuristics extracted from such techniques or specified by an administrator.","As one such example, the update frequency  may be predicted by first classifying the source item  as a source item type according to at least one source item criterion , and then predicting the update frequency of the source item  based on typical update frequencies of source items of the selected source item type, such as may be heuristically specified or statistically measured.  illustrates an exemplary scenario  utilizing a particular embodiment of this analytic process to predict an update frequency  of a source item  according to several knowledge processing techniques. From the source item , several source item criteria  may be identified by applying a criterion identifier  formulated as a backpropagation neural network. This neural network might be devised, e.g., by providing a set of training data comprising exemplary source items , each having a known set of source item criteria  (e.g., probabilities that the exemplary source item  contains news content, informational content, or personal content; the probability that the owner of the source item  is a school, an individual, or another type of owner; etc.) The neural network  may be trained to provide acceptable output for the respective source item criteria  when provided the exemplary source items , and then may be applied to the source item  to extract source item criteria .","As the exemplary scenario  of  further illustrates, the extracted source item criteria  may be provided to an update frequency predictor . For example, the update frequency predictor  may be configured to predict the update frequency  of the item based on the extracted criteria . First, the criteria  may be evaluated to determine the source item type , such as by a source item type identifier . As one example, the source item type identifier  might comprise a Bayesian classifier system, which may be configured to classify the source item  according to the extracted source item criteria  as a source item type (e.g., a professional news site, a personal weblog, an image gallery, or an academically produced data source.) The Bayesian classifier system may be developed using a training data set comprising source item criteria  and known source item types , and may be configured to compute statistical correlations and weights of the source item criteria  to various source item types . The Bayesian classifier system may then prioritize the source item criteria  in an evaluative order, where each evaluation is selected to narrow the field of likely source item types  to a smaller set of more highly probable source item types  in view of previous evaluations. The Bayesian classifier system, once developed, may then be utilized as a source item type identifier  by applying it to the source item criteria  extracted from the source item  in order to identify the source item type  of the source item .","Once a source item type  is identified for the source item , the update frequency  of the source item  may be predicted based on the source item type . This prediction may be made, e.g., by the update frequency predictor , based on an update frequency set that identifies typical update frequencies of source items  of various source item types. For example, a review of professional news items may indicate that such items are updated at a high update frequency (e.g., once every ten minutes); that personal weblogs tend to be updated at a medium frequency (e.g., once every few hours); and that academically generated data sources tend to be updated at a low frequency (e.g., once every six months.) An update frequency set  may be derived that maps respective source item types to a typical update frequency  for source items  of the source item type. The update frequency set  may be generated automatically, e.g., by monitoring update frequencies  of some source items of known source item types and computing an average update frequency , and\/or heuristically, e.g., specified by an administrator based on personal knowledge. The update frequency set , once generated, may be used to predict the update frequency of the source item  by the source item host . Thus, in this exemplary scenario , the source item  is first evaluated by the criterion identifier  to extract source item criteria , which are then provided to the update frequency predictor , which first classifies the source item  as a source item type  by evaluating the source item criteria  by the Bayesian classifier system , and then predicts the update frequency  based on the update frequency set . However, the exemplary scenario  of  presents only one feasible combination of machine learning systems, statistical analyses, and heuristics that may predict the update frequency  of the source item . Those of ordinary skill in the art may devise many evaluative methodologies for predicting the update frequency  of the source item  while implementing the techniques discussed herein.","A fourth aspect that may vary among embodiments of these techniques relates to the computing of the refresh utility of the item , based on the predicted query frequency  of the item  and the predicted update frequency  of the source item . The refresh utility may be computed in many ways. As a first example, some computations may involve a comparatively simple implementation and a comparatively low computational intensity, whereas other computations of the refresh utility may present greater proficiency in the scheduling of refreshing of the items , such as by taking into account the other items  to be refreshed and the comparative penalties of serving stale versions of different items . As a second example, the refresh utility may be computed, e.g., as a refresh frequency representing an acceptable frequency of refreshing the item ; as a score indicating the urgency of refreshing the item  at a particular time; or as a prioritization of the items  of the item cache  (such as in the exemplary scenario  of .)","A particular variation of this fourth aspect involves computing the refresh frequency  of an item  according to the refresh utility, i.e., a measure of the utility achieved by allocating resources to refresh the item . It may be appreciated that the proficiency of the item cache  at any particular moment may be measured for each item  as the query frequency  and whether or not the version of the item  served from the item cache  is up-to-date. Inversely, for each item  (represented as i) and at any time point (represented as t), the cache penalty involved in using the item cache  (represented as penalty) may be viewed as the query frequency of the item  (represented as u) and whether or not the version of the item  served from the item cache  is stale (represented as cost, either comprising 1 if the item  is stale and 0 if the item is not stale):\n\npenalty\u00b7cost()\n\nThis penalty may also be measured over the entire set of items  in the item cache  (the items i enumerated from 1 to n), and over an entire period of time, according to the mathematical formula:\n\npenalty=\u03a3\u03a3\u00b7cost()\n\nThe efficiency of a particular allocation of cache refreshing resources  may be measured as the reduction in this penalty over time.\n","This mathematical formula may also be applied to measure the marginal value in updating a particular item  at a particular time point, i.e., as the achieved decrease in the overall penalty. This value measurement may then be utilized as a comparative determination of the utility in updating the item  to the overall freshness of the item cache . However, the cost may be difficult to determine as a binary value, since it is not necessarily known whether the version of an item  served from the item cache  is current. Instead, this cost may be estimated as a probability that the item  in the item cache  is out of date, based on the predicted update frequency  of the corresponding source item  and the last refreshing of the item . Thus, if the update frequency  (represented as u) may be predicted, a freshness probability that the item  (represented as c) may be computed to represent the probability that the source item  has not been updated by the source item host  since the item  was last refreshed (i.e., that the version of the item  in the item cache  is fresh at a particular time point.) In similar fashion, the decision of whether or not to refresh the item  at this time point may be expressed as a refresh probability, represented as p, that item i will be chosen for refreshing during the current time point (thereby reducing cto 0), and the probability that if item i is not chosen for updating (1\u2212p), the item is currently fresh, taking into account both the update frequency cand the current probable freshness of the item . Accordingly, the utility of refreshing an item may be expressed according to the mathematical formula:\n\n\u00b7(1)\u00b7(1)\n\nwhere xrepresents the utility during the next time point.\n","These observations may be utilized in computing the refresh utilities of particular items  in order to reduce this probability. For example, the refresh utility for a particular item  may be computed as the utility achieved (relative to the overall freshness of the item cache ) by refreshing the item . The refresh utility (such as the refresh frequency) of an item  may be computed based on the query frequency  of queries requesting the item , and also on the update probability of the source item  by the source item host , where the refresh probabilities are selected in order to yield a desirably high refresh utility. In one such embodiment, the refresh utility may be computed as a refresh probability for the item , representing the probability that the item  is to be chosen for refreshing by a cache refreshing resource  at time point t. This stochastic approach may permit an occasional refreshing of items  with a consistently low computed refresh utility, which might otherwise never be refreshed in some strictly deterministic approaches. Additionally, after at least one item  in the item cache  is refreshed, the refresh probabilities of respective items  may be recomputing based on the query frequencies  of queries requesting the items  and the update probability of the corresponding source items  by the source item hosts  (which may be higher for items  that have not been refreshed, and may be lower or 0 for items  that have been refreshed.) This iterative computation, use, and re-computation of the refresh utilities of respective items  may therefore promote the efficient allocation of the cache refreshing resources  to achieve a desirably high utility and a correspondingly low cache penalty. In particular, these views of the utility of cache refreshing may be expressed as an optimization problem, such as a refresh utility model.","One such expression is the mathematical formula:\n\nmax\u03a3(\u03a3)\n\nsuch that:\n\n\u03a3p\u22661,\n\np\u22670,\n\n0\u2266x\u22661,\n\nx=0, and\n\n\u00b7(1\u2212)\u00b7(1\u2212)+;\n\nwherein:\n","n represents the number of items in the item cache;","t represents a time point;","urepresents a query frequency of item i;","xrepresents a probability that source item i has been updated by the source item host at time t since the item was last refreshed;","crepresents a freshness probability comprising a probability that the source item i has not been updated by the source item host of source item i since the item i was last refreshed; and","prepresents a refresh probability of item i at time t.","However, this item subset may include one or more items  with a refresh probability less than zero, indicating that it is not helpful to refresh the item  in view of the other items  of the item subset. Moreover, the inclusion of this item may skew the computation of the Lagrange multiplier. Therefore, it may be helpful to select the item subset as a possible solution (i.e., as an acceptable set of items  with computed refresh probabilities) only if none of the items  of the item subset comprise a refresh probability less than zero. If not, the item(s)  added to the item subset during this iteration may be excluded from further consideration. Additionally, the aggregate utility of the item subset may be computed (i.e., as the achieved reduction in the cache penalty using the selected item subset), and the current item subset may be accepted as a possible solution only if the aggregate utility is better than the aggregate utilities computed for other item subsets. In this manner, a subset of items  may be identified, along with an acceptable set of refresh probabilities for a particular time increment, that produce an acceptable and advantageously high utility when applied to the refreshing of the item cache .","The mathematical formula presented above may be used as a model for calculating the refresh utilities of the items  in the item cache  by choosing appropriate probabilities (p) of updating respective items . However, choosing all such pvalues for all items  may present a difficult challenge in the field of linear programming, and some solutions, such as brute-forcing or heuristics-based selection of pvalues, may be inaccurate or prohibitively computationally intensive. However, the model may be reformulated in a few ways to produce techniques that are computationally feasible and acceptably accurate. In one useful reformulation, the goal function F(p, . . . ,p) may be computed according to the mathematical formula:",{"@attributes":{"id":"p-0062","num":"0061"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":"p","mn":"1"},"mo":",","mrow":{"mi":"\u2026","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"msub":{"mi":["p","n"]}}}}},{"munderover":{"mo":"\u2211","mi":"i","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mfrac":{"mrow":[{"msub":[{"mi":["u","i"]},{"mi":["p","i"]}],"mo":"\u2062"},{"msub":[{"mi":["p","i"]},{"mi":["c","i"]}],"mo":["+","-"],"mrow":{"msub":[{"mi":["p","i"]},{"mi":["c","i"]}],"mo":"\u2062"}}]}}],"mo":"="}}},"br":{},"sub":"i"},"A first technique based on these models involves a set-based approach, wherein an initially small subset of items  may be selected. For the items  of the item subset, a Lagrange multiplier may be computed to model the achievable utility of the subset in view of the query frequencies  and the freshness probabilities (predicted in view of the update frequencies  of the corresponding source items .) After the Lagrange multiplier is computed for the item subset, refresh probabilities may be computed for the items  of the item subset, based on the Lagrange multiplier as well as the respective query frequency  and the update frequency . The items  in the resulting item subset include refresh probabilities based on the aggregate achievable utility for the selected subset of items. Specifically, the exemplary useful reformulation of F(p, . . . ,p) may be computed according to the mathematical formula:",{"@attributes":{"id":"p-0064","num":"0063"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["p","i"]},"mo":"=","mfrac":{"mrow":[{"msqrt":{"mfrac":{"mrow":{"msub":[{"mi":["u","i"]},{"mi":["c","i"]}],"mo":"\u2062"},"mi":"\u03bb"}},"mo":"-","msub":{"mi":["c","i"]}},{"mn":"1","mo":"-","msub":{"mi":["c","i"]}}]}}}},"br":{},"sub":["i","i"]},{"@attributes":{"id":"p-0065","num":"0064"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"\u03bb","mo":"=","mrow":{"msup":{"mrow":{"mo":["(",")"],"mfrac":{"mrow":[{"munderover":{"mo":"\u2211","mi":"i","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mfrac":{"msqrt":{"mrow":{"msub":[{"mi":["u","i"]},{"mi":["c","i"]}],"mo":"\u2062"}},"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msub":{"mi":["c","i"]}}}}},{"mn":"1","mo":"+","mrow":{"munderover":{"mo":"\u2211","mi":"i","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mfrac":{"msub":{"mi":["c","i"]},"mrow":{"mn":"1","mo":"-","msub":{"mi":["c","i"]}}}}}]}},"mn":"2"},"mo":"."}}}},"br":{},"b":["14","14","14","14","14","14","14","12"]},{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 9","b":["130","132","134","136","138","14","12"]},"In the first pseudocode block , a function is provided that accepts two arrays referencing the items  of the item cache : a first array that indexes the items  according to the predicted query frequencies  thereof (represented as {right arrow over (u)}) and a second array that indexes the items  according to the freshness probabilities of the items  in the item cache , based on the predicted update frequencies  of the corresponding source items  (represented as {right arrow over (c)}.) The function begins by sorting the arrays according to a ratio of the query frequency  to the freshness probability. A high ratio is indicative of an item  that is of comparatively higher value to refresh, and a lower ration is indicative of an item  of comparatively lower value. The function then endeavors to choose subsets of items  and to compute refresh probabilities therefor that may produce an aggregate high refresh utility. For example, an item subset may be selected and the items  thereof sorted according to the",{"@attributes":{"id":"p-0068","num":"0067"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"msub":[{"mi":["u","i"]},{"mi":["c","i"]}]}}},"br":{},"b":["134","136","14","136","14","138","14","14","14"]},"While the first technique (and the first exemplary algorithm) figure may generate an acceptable solution, some inefficiencies may arise in at least two aspects. First, the items  that present an unacceptable",{"@attributes":{"id":"p-0070","num":"0069"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"msub":[{"mi":["u","i"]},{"mi":["c","i"]}]}}},"br":{},"b":["1","14"]},{"@attributes":{"id":"p-0071","num":"0070"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"msub":[{"mi":["u","i"]},{"mi":["c","i"]}]}}},"br":{}},"A second technique based on these models may therefore be devised that, in contrast with the set-building process of the first technique and the exemplary algorithm  of , is formulated as a set-reducing technique. According to this second technique, the entire set of items  may be considered, and unhelpful items  (those having an unacceptable",{"@attributes":{"id":"p-0073","num":"0072"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"msub":[{"mi":["u","i"]},{"mi":["c","i"]}]}}},"br":{},"b":"14"},{"@attributes":{"id":"p-0074","num":"0073"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"msub":[{"mi":["u","i"]},{"mi":["c","i"]}]}}},"br":{}},{"@attributes":{"id":"p-0075","num":"0074"},"figref":["FIG. 10","FIG. 9"],"b":["140","142","14","12"]},"In the first pseudocode block , a function is provided that accepts two arrays referencing the items  of the item cache : a first array that indexes the items  according to the predicted query frequencies  thereof (represented as {right arrow over (u)}) and a second array that indexes the items  according to the freshness probabilities of the items  in the item cache , based on the predicted update frequencies  of the corresponding source items  (represented as {right arrow over (c)}.) The function begins by forming an item subset comprising all of the items  of the item cache . A Lagrange multiplier may be computed over the items  of the item subset, based on the query probabilities of the items  and the update probabilities of the corresponding source items , such as according to the second pseudocode block  of . The refresh probabilities of the items  in the item subset may then be computed using the Lagrange multiplier, such as according to the third pseudocode block  of . The item subset may then be examined for at least one item  having a refresh probability less than zero. If any such items  are identified, these items  are removed from the item subset; the Lagrange multiplier and refresh probabilities may be recomputed; and the item subset may be retested for items  having a refresh probability less than zero. This iterative testing, removing, and recomputing may continue until no further items  having a refresh probability less than zero are included in the item subset. The item subset may then be selected as the solution, wherein the refresh probabilities computed for the items  of the item subset may be used to allocate the cache refresh resources . By removing items  that have unacceptable",{"@attributes":{"id":"p-0077","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"msub":[{"mi":["u","i"]},{"mi":["c","i"]}]}}},"br":{},"b":["14","140","130"]},"The first technique (illustrated by the first exemplary algorithm ) and the second technique (illustrated by the second exemplary algorithm ) are devised to provide accurate solutions. However, these techniques may involve significant computational resources, especially if the item set is large (e.g., an item cache  utilized by a web search engine may contain billions of items .) Therefore, in some scenarios, it may be desirable to compute the refresh utilities and the refresh probabilities in an approximated manner, thereby reducing the computational resources involved in the computation of resource probabilities in exchange for a modest (and perhaps small or negligible) reduction in accuracy.","A third technique may therefore be devised that approximates the allocation of refresh probabilities based on the improvement in the aggregate refresh utility that may be achieved thereby. In particular, the allocation of refreshing may be modeled as a gradient descent problem involving an iterative and incremental allocation of the refresh probabilities. Each allocation may be selected by computing the derivative flux in the refresh utility of each item  (i.e., the marginal improvement in refresh utility) if a refresh probability increment were allocated to it, based on the query frequency, the update frequency, and the refresh probability that has already been allocated to the item . The item  featuring the maximum derivative flux may be allocated a refresh probability increment from the allocatable refresh probability, which is reduced by the refresh probability increment. The gradient descent selection may continue until the allocatable refresh probability has been exhausted, and the cache refresh resources  may be deployed according to the refresh probabilities allocated among the items .",{"@attributes":{"id":"p-0080","num":"0079"},"figref":"FIG. 11","b":["150","152","154","14","14","12"]},"In the first pseudocode block , a function is provided that accepts two arrays referencing the items  of the item cache : a first array that indexes the items  according to the predicted query frequencies  thereof (represented as {right arrow over (u)}) and a second array that indexes the items  according to the freshness probabilities of the items  in the item cache , based on the predicted update frequencies  of the corresponding source items  (represented as {right arrow over (c)}.) The function also accepts the number of iterations to be performed in the gradient descent (represented as N), wherein higher values of N result in a finer-grained allocation of the refresh probabilities and produce a more accurate result, but involve more computational resources to complete. The first pseudocode block  begins by computing the refresh probability increment (represented as \u03b5) and initializing the items  with a zero refresh probability. The derivative flux may then be computed for the items , as expressed in the second pseudocode block . Next, the refresh probability increments may be iteratively allocated by choosing the item  with the highest derivative flux, allocating a refresh probability increment to the item , and recomputing the derivative flux for the item  if an additional refresh probability increment were added to it. (It may be appreciated that the items  having a disadvantageous",{"@attributes":{"id":"p-0082","num":"0081"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"msub":[{"mi":["u","i"]},{"mi":["c","i"]}]}}},"br":{},"b":["14","22","14","12"]},"In view of the foregoing discussion of predicting the query frequencies , predicting the update frequencies , and computing the refresh utilities of the items  of the item cache , a more detailed appreciation of an exemplary embodiment of these techniques may be appreciated.  presents the components of one such embodiment utilized in an exemplary scenario  featuring a refreshing of items  in an item cache  that correspond to source items  stored by various source item hosts  that operates according to the techniques discussed herein. In order to allocate a set of cache refreshing resources  to preserve the freshness of the item cache , a set of refresh probabilities  may be computed for the respective items  of the item cache . For example, an item  may be evaluated by a query frequency predictor , which may comprise a query history analyzer  that compares the item  to a query history  (e.g., an item request log) to determine the rate at which the item  has recently been requested, and which may output a query frequency  predicted for the item . Also, the source item  corresponding to the item  may be evaluated by an update frequency predictor , which may first evaluate the contents of the source item  by a criterion identifier , such as a backpropagation neural network trained to identify criteria  of various source items . The criterion identifier  by output a set of criteria , which may be provided to a source item type identifier , such as a Bayesian classifier system, which may be trained to identify the source item type  of a source item  based on criteria  extracted therefrom. After the source item type identifier  identifies the source item type  of the source item , the source item type  may be compared against an update frequency set , which maps source item types  to typical update frequencies  thereof. The update frequency predictor  may therefore select and output the update frequency  predicted for the source item . The predicted query frequencies  and the predicted update frequencies  of the various items  in the item cache  may then be evaluated to predict the refresh utilities thereof, e.g., by applying the first pseudocode block  of  to produce a set of refresh probabilities . These refresh probabilities  may then be used by the cache refreshing resources  to prioritize the refreshing of the items  according to the relative refresh utilities thereof. While this exemplary scenario  features one implementation utilizing some of these concepts, those of ordinary skill in the art may devise many such implementations that embody the techniques discussed herein.","A fifth aspect that may vary among embodiments of these techniques relates to additional features that may be added to implementations to present additional advantages and\/or reduce disadvantages. A first variation of this fifth aspect relates to additional factors that might be considered while computing the refresh utilities of various items , such as may be included in the computation of the respective refresh utilities or in the prioritization of the items . As a first example, it may be appreciated that different source items  may embody comparatively different penalties for staleness. A source item  that features time-sensitive information, such as breaking news or stock information, may incur a comparatively high penalty if an out-of-date item  is served from the item cache , while a source item  that features non-time-sensitive information, such as an academic article or an encyclopedic entry, might incur a comparatively low penalty. Thus, it might be advantageous to prioritize the refreshing of a time-sensitive item  over a non-time-sensitive item , even if the latter exhibits a higher query frequency  and update frequency  than the former. Therefore, the prioritization of refreshing items  may be based in part on an update value of respective items , representing the incremental value of providing an updated item  over an out-of-date item . For example, for respective source items , an update value may be predicted, and the computing of the refresh utility of an item  may be based in part on the update value. As one technique for achieving the predicting of the update value, an update frequency set , such as in , might be configured to output a predicted update value along with the predicted update frequency  for respective source item types .As a second example of this first variation, the prioritizing might be based (alternatively or additionally) on a refresh cost associated with refreshing a particular item . In some scenarios, refreshing a first item  may be more costly than refreshing a second item , such as where the first item  is much larger and consumes more time and\/or bandwidth to refresh, or where a charge is assessed for refreshing the first item  (e.g., in a mobile agent scenario.) Per-item refresh costs may therefore be attributed to various items , and these refresh costs may be included in the computation of refresh utilities.","As a second variation of this fifth aspect, additional features may pertain to the use of the computed refresh utilities in the actual refreshing of the items . In one set of embodiments of these techniques, the prioritization of the items  may be computed and provided to other resources of the computer , such as a set of cache refreshing resources  that may be included in the item cache . However, in other embodiments, after the refresh utility is computed, a refresh frequency  may be computed for various items  based on the refresh utilities, and the items  may be refreshed according to the refresh frequencies . As in the exemplary scenario  of , if the computer  comprises a cache refreshing resource set comprising cache refreshing resources  that are configured to refresh items  in the item cache , these resources may be allocated based on respective refresh utilities of the items .The computation of the refresh utilities may also be used to demonstrate the value and efficiency of the refreshing of the item cache . For example, an aggregate refresh utility of the items  stored in the item cache  may be computed in view of a particular cache refreshing resource set (e.g., by using the dual summation computation provided above to measure the reduction in the cache penalty achieved by the cache refreshing resource set.) Moreover, these computations may be useful in configuring the cache refreshing resource set to achieve a refresh utility proportional to the computing resources consumed thereby. For example, the differential aggregate refresh utility achievable by a first cache refreshing resource set as compared with a second cache refreshing resource set. This computation may be useful, e.g., for evaluating improvements in the performance of the item cache  if more or fewer resources are allocated to the cache refreshing resource set.","As a third variation of this fifth aspect, the computed refresh utility may be computed in relation to perceptions of quality of the item cache . In several examples presented herein, such as the exemplary scenario  of , the utility of refreshing an item  in the item cache  is discussed with relation to the penalty of serving a stale item from the item cache . However, in some scenarios, the item cache  might not serve items  directly in response to queries, but may generate various types of query results based on the versions of the items  stored in the item cache , e.g., reports, charts, summaries, or mathematical aggregations of all or selected sets of items . The quality of these query results may vary based on the freshness of the items  stored in the item cache . Therefore, it may be more practical to measure the quality of the item cache  according to the quality of a query result applied to the item cache , and to apply embodiments of these techniques to promote the measured quality of the query result, instead of endeavoring to reduce the penalty of serving stale versions of items  from the item cache . For example, an embodiment of these techniques may be configured to compute a query quality metric of the item cache indicating a quality of at least one query result generated in response to a query applied to the item cache, and to prioritize the refreshing of the items based on the refresh utilities in order to improve the query quality metric of the item cache. The prioritizing may be adjusted, e.g., by a learning function that tests various sets of update frequencies  and identifies corresponding improvements (or lack of improvements) in the resulting query quality metrics. Moreover, if the quality of such query results of the item cache  is measurable, it may be advantageous to compare the differential improvement in this quality with the cost of more aggressive refreshing the item cache  (e.g., by a cache refreshing resource set ), and to select an advantageous item cache refreshing strategy that achieves a desirably high measured quality with an economical allotment of cache refreshing resources .","One exemplary scenario wherein this variation might be utilized involves a caching of items relating to web pages that are index by a search engine. According to the techniques discussed herein, the search engine might be configured to update the items  in the item cache  representing the search index of the search engine in order to maintain the freshness of search results. The search engine may query the item cache  for items  matching a particular search query, but may also utilize the item cache  to rank such items , e.g., according to the predominance of particular keywords in the web page or the credibility of the web page. In this manner, the search engine may utilize the item cache  not only for per-item queries, but also for search queries that compute rankings of items  as well as generating particular search results relating thereto. Moreover, these search engine results and rankings may change over time as the indexed web pages and interrelations thereof change. For example, a particular website may be identified as a more or less reliable source of information about particular topics (e.g., if many other sources begin linking to and referencing the website as an authoritative source of information on some topics); thus, even if the contents of the website have not changed, a fresh item cache  might rank results identifying the website higher. However, a per-item refreshing strategy may result in an undesirably large amount of refreshing, particularly if the size of the item cache  is large. Moreover, such aggressive refreshing may not generate proportional utility in the form of improved search engine results; i.e., an overly aggressive per-item refreshing strategy may not yield discernibly improved search engine results. Instead, it may be possible to assess the quality of a search engine result generated by the search engine (with reference to the item cache ), involving an evaluation of various aspects, such as the freshness of the per-item results and the currency of the rankings of such results. Moreover, it may be possible to adjust the refreshing strategy of the item cache  in view of the resulting quality of the search engine results generated therefrom.",{"@attributes":{"id":"p-0088","num":"0087"},"figref":"FIG. 13","b":["170","12","14","18","16","170","12","14","12","174","172","174","176","174","12","176","178","174","14","12","12","178","174","180","36","12","178","182","178","174","182","12","12","172","12","174","176","178","180","180","36","178"]},"Although the subject matter has been described in language specific to structural features and\/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as example forms of implementing the claims.","As used in this application, the terms \u201ccomponent,\u201d \u201cmodule,\u201d \u201csystem\u201d, \u201cinterface\u201d, and the like are generally intended to refer to a computer-related entity, either hardware, a combination of hardware and software, software, or software in execution. For example, a component may be, but is not limited to being, a process running on a processor, a processor, an object, an executable, a thread of execution, a program, and\/or a computer. By way of illustration, both an application running on a controller and the controller can be a component. One or more components may reside within a process and\/or thread of execution and a component may be localized on one computer and\/or distributed between two or more computers.","Furthermore, the claimed subject matter may be implemented as a method, apparatus, or article of manufacture using standard programming and\/or engineering techniques to produce software, firmware, hardware, or any combination thereof to control a computer to implement the disclosed subject matter. The term \u201carticle of manufacture\u201d as used herein is intended to encompass a computer program accessible from any computer-readable device, carrier, or media. Of course, those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.",{"@attributes":{"id":"p-0092","num":"0091"},"figref":["FIG. 14","FIG. 14"]},"Although not required, embodiments are described in the general context of \u201ccomputer readable instructions\u201d being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media (discussed below). Computer readable instructions may be implemented as program modules, such as functions, objects, Application Programming Interfaces (APIs), data structures, and the like, that perform particular tasks or implement particular abstract data types. Typically, the functionality of the computer readable instructions may be combined or distributed as desired in various environments.",{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIG. 14","FIG. 14"],"b":["190","192","192","196","198","198","194"]},"In other embodiments, device  may include additional features and\/or functionality. For example, device  may also include additional storage (e.g., removable and\/or non-removable) including, but not limited to, magnetic storage, optical storage, and the like. Such additional storage is illustrated in  by storage . In one embodiment, computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage  may also store other computer readable instructions to implement an operating system, an application program, and the like. Computer readable instructions may be loaded in memory  for execution by processing unit , for example.","The term \u201ccomputer readable media\u201d as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory  and storage  are examples of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, Digital Versatile Disks (DVDs) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .","Device  may also include communication connection(s)  that allows device  to communicate with other devices. Communication connection(s)  may include, but is not limited to, a modem, a Network Interface Card (NIC), an integrated network interface, a radio frequency transmitter\/receiver, an infrared port, a USB connection, or other interfaces for connecting computing device  to other computing devices. Communication connection(s)  may include a wired connection or a wireless connection. Communication connection(s)  may transmit and\/or receive communication media.","The term \u201ccomputer readable media\u201d may include communication media. Communication media typically embodies computer readable instructions or other data in a \u201cmodulated data signal\u201d such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.","Device  may include input device(s)  such as keyboard, mouse, pen, voice input device, touch input device, infrared cameras, video input devices, and\/or any other input device. Output device(s)  such as one or more displays, speakers, printers, and\/or any other output device may also be included in device . Input device(s)  and output device(s)  may be connected to device  via a wired connection, wireless connection, or any combination thereof. In one embodiment, an input device or an output device from another computing device may be used as input device(s)  or output device(s)  for computing device .","Components of computing device  may be connected by various interconnects, such as a bus. Such interconnects may include a Peripheral Component Interconnect (PCI), such as PCI Express, a Universal Serial Bus (USB), firewire (IEEE 1394), an optical bus structure, and the like. In another embodiment, components of computing device  may be interconnected by a network. For example, memory  may be comprised of multiple physical memory units located in different physical locations interconnected by a network.","Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example, a computing device  accessible via network  may store computer readable instructions to implement one or more embodiments provided herein. Computing device  may access computing device  and download a part or all of the computer readable instructions for execution. Alternatively, computing device  may download pieces of the computer readable instructions, as needed, or some instructions may be executed at computing device  and some at computing device .","Various operations of embodiments are provided herein. In one embodiment, one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media, which if executed by a computing device, will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further, it will be understood that not all operations are necessarily present in each embodiment provided herein.","Moreover, the word \u201cexemplary\u201d is used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as \u201cexemplary\u201d is not necessarily to be construed as advantageous over other aspects or designs. Rather, use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application, the term \u201cor\u201d is intended to mean an inclusive \u201cor\u201d rather than an exclusive \u201cor\u201d. That is, unless specified otherwise, or clear from context, \u201cX employs A or B\u201d is intended to mean any of the natural inclusive permutations. That is, if X employs A; X employs B; or X employs both A and B, then \u201cX employs A or B\u201d is satisfied under any of the foregoing instances. In addition, the articles \u201ca\u201d and \u201can\u201d as used in this application and the appended claims may generally be construed to mean \u201cone or more\u201d unless specified otherwise or clear from context to be directed to a singular form.","Also, although the disclosure has been shown and described with respect to one or more implementations, equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components (e.g., elements, resources, etc.), the terms used to describe such components are intended to correspond, unless otherwise indicated, to any component which performs the specified function of the described component (e.g., that is functionally equivalent), even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition, while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations, such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore, to the extent that the terms \u201cincludes\u201d, \u201chaving\u201d, \u201chas\u201d, \u201cwith\u201d, or variants thereof are used in either the detailed description or the claims, such terms are intended to be inclusive in a manner similar to the term \u201ccomprising.\u201d"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 14"}]},"DETDESC":[{},{}]}
