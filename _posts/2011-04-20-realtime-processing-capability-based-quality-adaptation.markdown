---
title: Real-time processing capability based quality adaptation
abstract: The quality of a media stream transmitted to a client device is dynamically adapted based on real-time availability of resources on the client device. Central processing unit resources, memory availability, buffer usage, graphics processing unit usage, etc., are continuously monitored to evaluate the ability of a device to handle media streams of particular quality levels. When it is determined that resources at a client device temporarily can not handle a high quality media stream, a lower quality stream is selected and provided to the client device without having to establish a new session.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08990351&OS=08990351&RS=08990351
owner: MobiTV, Inc.
number: 08990351
owner_city: Emeryville
owner_country: US
publication_date: 20110420
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","DESCRIPTION OF RELATED ART","DESCRIPTION OF EXAMPLE EMBODIMENTS","Overview","Example Embodiments"],"p":["The present disclosure relates to real-time processing capability based quality adaptation.","Video quality on a client device depends on a variety of factors. In some examples, client devices may receive media over networks that have varying transmission rates, bandwidth, latency, and reliability. Client devices may also have different processing, graphics, display, memory, and buffer capabilities. It is typically difficult to provide smooth playback in a variety of conditions and use cases.","Conventional techniques and mechanisms for presenting media on client devices such as mobile devices are limited. Consequently, it is desirable to provide improved techniques and mechanisms for improving media playback at a client.","Reference will now be made in detail to some specific examples of the invention including the best modes contemplated by the inventors for carrying out the invention. Examples of these specific embodiments are illustrated in the accompanying drawings. While the invention is described in conjunction with these specific embodiments, it will be understood that it is not intended to limit the invention to the described embodiments. On the contrary, it is intended to cover alternatives, modifications, and equivalents as may be included within the spirit and scope of the invention as defined by the appended claims.","For example, the techniques of the present invention will be described in the context particular streaming protocols. However, it should be noted that the techniques of the present invention apply to a variety of protocols. In the following description, numerous specific details are set forth in order to provide a thorough understanding of the present invention. Particular example embodiments of the present invention may be implemented without some or all of these specific details. In other instances, well known process operations have not been described in detail in order not to unnecessarily obscure the present invention.","Various techniques and mechanisms of the present invention will sometimes be described in singular form for clarity. However, it should be noted that some embodiments include multiple iterations of a technique or multiple instantiations of a mechanism unless noted otherwise. For example, a system uses a processor in a variety of contexts. However, it will be appreciated that a system can use multiple processors while remaining within the scope of the present invention unless otherwise noted. Furthermore, the techniques and mechanisms of the present invention will sometimes describe a connection between two entities. It should be noted that a connection between two entities does not necessarily mean a direct, unimpeded connection, as a variety of other entities may reside between the two entities. For example, a processor may be connected to memory, but it will be appreciated that a variety of bridges and controllers may reside between the processor and memory. Consequently, a connection does not necessarily mean a direct, unimpeded connection unless otherwise noted.","The quality of a media stream transmitted to a client device is dynamically adapted based on real-time availability of resources on the client device. Central processing unit resources, memory availability, buffer usage, graphics processing unit usage, etc., are continuously monitored to evaluate the ability of a device to handle media streams of particular quality levels. When it is determined that resources at a client device temporarily can not handle a high quality media stream, a lower quality stream is selected and provided to the client device without having to establish a new session.","A variety of mechanisms are used to deliver media streams to devices. In many instances, a media stream can not be played back smoothly at particular times on various devices. Networks may not deliver data at a constant rate. Network bandwidth, latency, throughput, and reliability may all vary depending on network conditions. Consequently, media players at client devices typically have buffers and buffer thresholds used to determine when playback begins or resumes. A large buffer having a high associated buffer threshold will take a long time to build but is tolerates adverse network conditions. A small buffer having a low associated buffer threshold will provide for quick initial playback but is difficult to maintain in many network circumstances. According to various embodiments, a content server selects a stream having a quality level appropriate for a device based on the buffer, network characteristics, resolution, device processor, etc. In particular embodiments, if network conditions do not allow delivery of a high quality stream, the content server selects a lower quality stream for transmission to the device.","However, the techniques and mechanisms of the present invention recognize that even when network conditions allow for sufficient data rates, the device itself may not have sufficient resources to playback a media stream. Although a device may technically meet specifications and have a sufficiently powerful processor, have sufficient memory, etc., dynamic changes in the device itself may render a device incapable of processing and playing a selected stream. For example, the device may be performing tasks such as performing background updates, running a virus\/malware scan, copying files, or running some other resource intensive application. The device may no longer have sufficient memory, bus bandwidth, or free processor cycles to perform playback adequately even if device specifications would be adequate.","Consequently, techniques and mechanisms are provided to evaluate not only available data transfer rates of the network but also the real-time decoding and rendering capabilities of a client device. Decoding and rendering capabilities of the client device are evaluated by continuously determining central processing unit and memory usage, as well as the rate of dropped frames at the decoder or render. In particular embodiments, the device may receive a media stream as required for smooth playback, but the device may not be able to decode or render media stream frames in time because it is simultaneously performing some other task. Consequently, a streaming server may dynamically switch to sending the device a lower quality stream that is less processor intensive.","According to various embodiments, a streaming server will only dynamically switch to a higher quality stream or will only transmit a high quality stream to a device if there is both available network bandwidth and sufficient dynamic processing resource availability on the client device itself. If the client device detects that it can not decode and render in real time, or if device processor usage or memory usage is too high, the streaming server will seamlessly switch to a lower quality feed, even if there is ample network bandwidth.","In particular examples, a client establishes a session such as a Real-Time Streaming Protocol (RTSP) session. A server computer receives a connection for a media stream, establishes a session, and provides a media stream to a client device. The media stream includes packets encapsulating frames such as MPEG-4 frames. The MPEG-4 frames themselves may be key frames or differential frames. The specific encapsulation methodology used by the server depends on the type of content, the format of that content, the format of the payload, and the application and transmission protocols being used to send the data. After the client device receives the media stream, the client device decapsulates the packets to obtain the MPEG frames and decodes the MPEG frames to obtain the actual media data.","Conventional MPEG-4 files require that a player parse the entire header before any of the data can be decoded. Parsing the entire header can take a notable amount of time, particularly on devices with limited network and processing resources. Consequently, the techniques and mechanisms of the present invention provide a fragmented MPEG-4 framework that allows playback upon receiving a first MPEG-4 file fragment. A second MPEG-4 file fragment can be requested using information included in the first MPEG-4 file fragment. According to various embodiments, the second MPEG-4 file fragment requested may be a fragment corresponding to a higher or lower bit-rate stream than the stream associated with the first file fragment.","MPEG-4 is an extensible container format that does not have a fixed structure for describing media types. Instead, MPEG-4 has an object hierarchy that allows custom structures to be defined for each format. The format description is stored in the sample description (\u2018stsd\u2019) box for each stream. The sample description box may include information that may not be known until all data has been encoded. For example, the sample description box may include an average bit rate that is not known prior to encoding.","According to various embodiments, MPEG-4 files are fragmented so that a live stream can be recorded and played back in a close to live manner. MPEG-4 files can be created without having to wait until all content is written to prepare the movie headers. To allow for MPEG-4 fragmentation without out of band signaling, a box structure is provided to include synchronization information, end of file information, and chapter information. According to various embodiments, synchronization information is used to synchronize audio and video when playback entails starting in the middle of a stream. End of file information signals when the current program or file is over. This may include information to continue streaming the next program or file. Chapter information may be used for video on demand content that is broken up into chapters, possibly separated by advertisement slots.","TCP is more widely used than UDP and networking technologies including switch, load balancer, and network card technologies are more developed for TCP than for UDP. Consequently, techniques and mechanisms are provided for delivering fragmented live media over TCP. Sequence information is also maintained and\/or modified to allow seamless client device operation. Timing and sequence information in a media stream is preserved.","Requests are exposed as separate files to clients and files should playback on players that handle fragmented MPEG-4. Live or near live, video on demand (VOD), and digital video record (DVR) content can all be handled using fragmentation.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 1","b":["101","103","105","107","101","111","101","101","121","103","113","105","115","107","117","103","105","107","123","125","127"]},"According to various embodiments, the decoder\/renderer delay  relates to packets or fragments that have been received by the client device but can not yet be processed by a decoder\/renderer. A decoder\/renderer may be a hardware or software decoder\/renderer that may be busy with other operations. Even though streaming data may arrive in time at the device, the decoder\/renderer may not be able to process the streaming data in time.",{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 2","b":["201","203","205","207","209","211","213"]},"According to various embodiments, if the client device determines that processor utilization, memory usage, decoder delay, and\/or decoder frame drops exceed a particular threshold at , the client device sends a signal to the streaming server to send a stream that uses less client device processing resources at . The stream that uses less client device processing resources may be a stream with a lower resolution, lower frame rate, a smaller number of colors, reduced audio quality, etc., or it may even be a stream encoded in a different manner. At , the content server sends the reduced quality stream even if network resources are sufficient to deliver the higher quality stream.","At , the client device monitors resource usage and sends a signal to a content server to possibly increase media stream quality if sufficient processing resources, memory resources, and decoder resources are available for a predetermined period of time. At , the content server can send a higher quality stream to the client device if both sufficient network resources are currently available and sufficient device resources are currently available.","In particular embodiments, data such as fragmented MPEG-4 packets are received at the client device. The content server may replace MPEG-4 fragments with higher or lower quality MPEG-4 fragments all while maintaining timing and sequence number information.","In some examples, if device resources are constrained, the stream is switched to a lower quality stream that allows playback of more content with fewer transmitted MPEG-4 fragments. Alternatively, if device resources are ample, the content server can begin transmitting a higher quality stream while maintaining a seamless user viewing experience. A content server can quality shift a stream based on dynamically determined client device resource usage",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 3","b":["301","305","309","305","321","309","309","305","309","309"]},"The fragment server  provides the caching layer with fragments for clients. The design philosophy behind the client\/server API minimizes round trips and reduces complexity as much as possible when it comes to delivery of the media data to the client . The fragment server  provides live streams and\/or DVR configurations.","The fragment controller  is connected to application servers  and controls the fragmentation of live channel streams. The fragmentation controller  optionally integrates guide data to drive the recordings for a global\/network DVR. In particular embodiments, the fragment controller  embeds logic around the recording to simplify the fragment writer  component. According to various embodiments, the fragment controller  will run on the same host as the fragment writer . In particular embodiments, the fragment controller  instantiates instances of the fragment writer  and manages high availability.","According to various embodiments, the client  uses a media component that requests fragmented MPEG-4 files, allows trick-play, and manages bandwidth adaptation. The client communicates with the application services associated with HTTP proxy  to get guides and present the user with the recorded content available.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 4","b":["401","403"]},"The fragment server  provides the caching layer with fragments for clients. The design philosophy behind the client\/server API minimizes round trips and reduces complexity as much as possible when it comes to delivery of the media data to the client . The fragment server  provides VoD content.","According to various embodiments, the client  uses a media component that requests fragmented MPEG-4 files, allows trick-play, and manages bandwidth adaptation. The client communicates with the application services associated with HTTP proxy  to get guides and present the user with the recorded content available.",{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 5"},"According to various embodiments, the fragment writer command line arguments are the SDP file of the channel to record, the start time, end time, name of the current and next output files. The fragment writer listens to RTP traffic from the live video encoders and rewrites the media data to disk as fragmented MPEG-4. According to various embodiments, media data is written as fragmented MPEG-4 as defined in MPEG-4 part 12 (ISO\/IEC 14496-12). Each broadcast show is written to disk as a separate file indicated by the show ID (derived from EPG). Clients include the show ID as part of the channel name when requesting to view a prerecorded show. The fragment writer consumes each of the different encodings and stores them as a different MPEG-4 fragment.","In particular embodiments, the fragment writer writes the RTP data for a particular encoding and the show ID field to a single file. Inside that file, there is metadata information that describes the entire file (MOOV blocks). Atoms are stored as groups of MOOF\/MDAT pairs to allow a show to be saved as a single file. At the end of the file there is random access information that can be used to enable a client to perform bandwidth adaptation and trick play functionality.","According to various embodiments, the fragment writer includes an option which encrypts fragments to ensure stream security during the recording process. The fragment writer will request an encoding key from the license manager. The keys used are similar to that done for DRM. The encoding format is slightly different where MOOF is encoded. The encryption occurs once so that it does not create prohibitive costs during delivery to clients.","The fragment server responds to HTTP requests for content. According to various embodiments, it provides APIs that can be used by clients to get necessary headers required to decode the video, seek to any desired time frame within the fragment and APIs to watch channels live. Effectively, live channels are served from the most recently written fragments for the show on that channel. The fragment server returns the media header (necessary for initializing decoders), particular fragments, and the random access block to clients. According to various embodiments, the APIs supported allow for optimization where the metadata header information is returned to the client along with the first fragment. The fragment writer creates a series of fragments within the file. When a client requests a stream, it makes requests for each of these fragments and the fragment server reads the portion of the file pertaining to that fragment and returns it to the client.","According to various embodiments, the fragment server uses a REST API that is cache friendly so that most requests made to the fragment server can be cached. The fragment server uses cache control headers and ETag headers to provide the proper hints to caches. This API also provides the ability to understand where a particular user stopped playing and to start play from that point (providing the capability for pause on one device and resume on another).","In particular embodiments, client requests for fragments follow the following format: http:\/\/{HOSTNAME}\/frag\/{CHANNEL}\/{BITRATE}\/[{ID}\/]{COMMAND}[\/{ARG}] e.g. http:\/\/frag.hosttv.com\/frag\/1\/H8QVGAH264\/1270059632.mp4\/fragment\/42. According to various embodiments, the channel name will be the same as the backend-channel name that is used as the channel portion of the SDP file. VoD uses a channel name of \u201cvod\u201d. The BITRATE should follow the BITRATE\/RESOLUTION identifier scheme used for RTP streams. The ID is dynamically assigned. For live streams, this may be the UNIX timestamp; for DVR this will be a unique ID for the show; for VoD this will be the asset ID. The ID is optional and not included in LIVE command requests. The command and argument are used to indicate the exact command desired and any arguments. For example, to request chunk  this portion would be \u201cfragment\/42\u201d.","The URL format makes the requests content delivery network (CDN) friendly because the fragments will never change after this point so two separate clients watching the same stream can be serviced using a cache. In particular, the headend architecture leverages this to avoid too many dynamic requests arriving at the Fragment Server by using an HTTP proxy at the head end to cache requests.","According to various embodiments, the fragment controller is a daemon that runs on the fragmenter and manages the fragment writer processes. We propose that it uses a configured filter that is executed by the Fragment Controller to generate the list of broadcasts to be recorded. This filter integrates with external components such as a guide server to determine which shows to record and the broadcast ID to use.","According to various embodiments, the client includes an application logic component and a media rendering component. The application logic component presents the UI for the user and also communicates to the front-end server to get shows that are available for the user and to authenticate. As part of this process, the server returns URLs to media assets that are passed to the media rendering component.","In particular embodiments, the client relies on the fact that each fragment in a fragmented MP4 file has a sequence number. Using this knowledge and a well defined URL structure for communicating with the server, the client requests fragments individually as if it was reading separate files from the server simply by requesting urls for files associated with increasing sequence numbers. In some embodiments, the client can request files corresponding to higher or lower bit rate streams depending on device and network resources.","Since each file contains the information needed to create the URL for the next file, no special playlist files are needed, and all actions (startup, channel change, seeking) can be performed with a single HTTP request. After each fragment is downloaded the client assesses among other things the size of the fragment and the time needed to download it in order to determine if downshifting is needed, or if there is enough bandwidth available to request a higher bitrate.","Because each request to the server looks like a request to a separate file, the response to requests can be cached in any HTTP Proxy, or be distributed over any HTTP based CDN.",{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 6","b":["607","605","605","603","603","601","601","603","605"]},"The fragment may be cached for a short period of time at caching layer . The mediakit  identifies the fragment number and determines whether resources are sufficient to play the fragment. In some examples, resources such as processing or bandwidth resources are insufficient. The fragment may not have been received quickly enough, or the device may be having trouble decoding the fragment with sufficient speed. Consequently, the mediakit  may request a next fragment having a different data rate. In some instances, the mediakit  may request a next fragment having a higher data rate. According to various embodiments, the fragment server  maintains fragments for different quality of service streams with timing synchronization information to allow for timing accurate playback.","The mediakit  requests a next fragment using information from the received fragment. According to various embodiments, the next fragment for the media stream may be maintained on a different server, may have a different bit rate, or may require different authorization. Caching layer  determines that the next fragment is not in cache and forwards the request to fragment server . The fragment server  sends the fragment to caching layer  and the fragment is cached for a short period of time. The fragment is then sent to mediakit .",{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 7","b":["700","701","703","711","715","701","701","701","711"]},"Particular examples of interfaces supports include Ethernet interfaces, frame relay interfaces, cable interfaces, DSL interfaces, token ring interfaces, and the like. In addition, various very high-speed interfaces may be provided such as fast Ethernet interfaces, Gigabit Ethernet interfaces, ATM interfaces, HSSI interfaces, POS interfaces, FDDI interfaces and the like. Generally, these interfaces may include ports appropriate for communication with the appropriate media. In some cases, they may also include an independent processor and, in some instances, volatile RAM. The independent processors may control such communications intensive tasks as packet switching, media control and management.","According to various embodiments, the system  is a fragment server that also includes a transceiver, streaming buffers, and a program guide database. The fragment server may also be associated with subscription management, logging and report generation, and monitoring capabilities. In particular embodiments, functionality for allowing operation with mobile devices such as cellular phones operating in a particular cellular network and providing subscription management. According to various embodiments, an authentication module verifies the identity of devices including mobile devices. A logging and report generation module tracks mobile device requests and associated responses. A monitor system allows an administrator to view usage patterns and system availability. According to various embodiments, the fragment server handles requests and responses for media content related transactions while a separate streaming server provides the actual media streams.","Although a particular fragment server is described, it should be recognized that a variety of alternative configurations are possible. For example, some modules such as a report and logging module and a monitor may not be needed on every server. Alternatively, the modules may be implemented on another device connected to the server. In another example, the server may not include an interface to an abstract buy engine and may in fact include the abstract buy engine itself. A variety of configurations are possible.","In the foregoing specification, the invention has been described with reference to specific embodiments. However, one of ordinary skill in the art appreciates that various modifications and changes can be made without departing from the scope of the invention as set forth in the claims below. Accordingly, the specification and figures are to be regarded in an illustrative rather than a restrictive sense, and all such modifications are intended to be included within the scope of invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The disclosure may best be understood by reference to the following description taken in conjunction with the accompanying drawings, which illustrate particular embodiments.",{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
