---
title: Methods, systems, and computer readable media for fast geometric sound propagation using visibility computations
abstract: Methods, systems, and computer program products for simulating sound propagation can be operable to define a sound source position within a modeled scene having a given geometry and construct a visibility tree for modeling sound propagation paths within the scene. Using from-region visibility techniques to model sound diffraction and from-point visibility technique to model specular sound reflections within the scene, the size of the visibility tree can be reduced. Using the visibility tree, an impulse response can be generated for the scene, and the impulse response can be used to simulate sound propagation in the scene.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08847965&OS=08847965&RS=08847965
owner: The University of North Carolina at Chapel Hill
number: 08847965
owner_city: Chapel Hill
owner_country: US
publication_date: 20111205
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["PRIORITY CLAIM","GOVERNMENT INTEREST","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application claims the benefit of U.S. Provisional Patent Application Ser. No. 61\/419,781, filed Dec. 3, 2010, the disclosure of which is incorporated herein by reference in its entirety.","This invention was made with government support under Grant No. W911NF-04-1-0088 awarded by Army Research Office, Grant Nos. OCI-0636208, IIS-0917040, and 0904990 awarded by National Science Foundation, and Grant No. W91CRB-08-C-0137 awarded by U.S. Army. The government has certain rights in the invention.","The subject matter disclosed herein relates generally to methods and systems for modeling sound propagation in a scene. More particularly, the subject matter disclosed herein relates to methods and systems for simulating sound propagation using geometric acoustic algorithms.","Sound rendering or auditory displays can augment graphical rendering and provide the user with an enhanced spatial sense of presence. Some of the driving applications of sound rendering include acoustic design of architectural models or outdoor scenes, walkthroughs of large CAD models with sounds of machine parts or moving people, urban scenes with traffic, training systems, computer games, etc. A key component in these applications is accurate computation of sound propagation paths, which takes into account the knowledge of sound sources, listener locations, the 3D model of the environment, and material absorption and scattering properties.","The propagation of sound in a medium is governed by the acoustic wave equation, a second-order partial differential equation. However, numerical methods that directly solve the acoustic wave equation can take tens of minutes even for simple rooms. Moreover, for numerical methods, the computation time grows as a fourth power of the maximum frequency simulated, and is proportional to the volume of the enclosed space. Hence they can only be used for small rooms and for low frequencies.","On the other hand, fast sound propagation methods are based on geometric acoustic (GA) algorithms, such as ray tracing or volumetric tracing. These geometric acoustics (GA) techniques are not as accurate as numerical methods in terms of solving the wave equation, and cannot easily model all kinds of propagation effects, but they allow simulation of early reflections at real-time rates. These methods work well in terms of handling specular reflections, and can take advantage of recent advances in real-time ray tracing methods and multi-core processors. However, current geometric propagation methods are either not fast enough for interactive applications or may not compute all propagation paths accurately. As a result, interactive applications such as computer games tend to use statically designed environment reverberation filters. Some games use ray tracing to estimate the size of a room and use this information to set parameters for a reverberation filter. Games also use precomputed visibility to determine if a source is out of line of sight from the listener. This is usually performed at a coarse level (i.e., visibility can be determined at a room-to-room level of detail using cell-and-portal visibility or ray shooting). If the source is not visible, a low-pass filter is usually applied to approximate diffraction effects. However the direction is the direct line from source to listener, which leads to very unnatural sound which seems to emanate from solid walls.","Accordingly, it would be desirable for an improved method and system for modeling sound propagation to allow for faster computation of sound propagation paths.","In accordance with this disclosure, methods, systems and computer readable media for simulating sound propagation in a scene are provided. In one aspect, a method for simulating sound propagation is provided. The method can comprise defining a sound source position within a modeled scene having a given geometry, constructing a visibility tree for modeling sound propagation paths within the scene, using a from-region visibility technique (e.g., with occlusion culling) to model sound diffraction within the scene and reduce the size of the visibility tree, using a from-point visibility technique (e.g., a conservative from-point visibility technique which performs occlusion culling) to model specular sound reflections within the scene and reduce the size of the visibility tree, using the visibility tree to generate an impulse response for the scene, and using the impulse response to simulate sound propagation in the scene.","In another aspect, a non-transitory computer readable medium is provided, the computer readable medium having stored thereon executable instructions that when executed by the processor of a computer control the computer to perform steps comprising defining a sound source position within a modeled scene having a given geometry, constructing a visibility tree for modeling sound propagation paths within the scene, using a from-region visibility technique (e.g., with occlusion culling) to model sound diffraction within the scene and reduce the size of the visibility tree, using a from-point visibility technique (e.g., a conservative from-point visibility technique which performs occlusion culling) to model specular sound reflections within the scene and reduce the size of the visibility tree, using the visibility tree to generate an impulse response for the scene, and using the impulse response to simulate sound propagation in the scene.","In a further aspect, a system for simulating sound propagation is provided. The system can comprise a fast geometric sound simulator for defining a sound position within a modeled scene having a given geometry, for constructing a visibility tree for modeling sound propagation paths within the scene, for using a from-region visibility technique (e.g., with occlusion culling) to model sound diffraction within the scene and reduce the size of the visibility tree, for using a from-point visibility technique (e.g., a conservative from-point visibility technique which performs occlusion culling) to model specular sound reflections within the scene and reduce the size of the visibility tree, and for using the visibility tree to generate an impulse response for the model. The system can further comprise a sound source for generating an input sound to the scene, wherein the sound simulator uses the impulse response to simulate a response of the scene to the input sound.","The subject matter described herein for simulating sound propagation in a scene can be implemented in software in combination with hardware and\/or firmware. In one exemplary implementation, the subject matter described herein can be implemented using a non-transitory computer readable medium having stored thereon executable instructions that when executed by the processor of the computer control the computer to perform steps. Exemplary computer readable media suitable for implementing the subject matter described herein include disk memory devices, chip memory devices, application specific integrated circuits, and programmable logic devices. In addition, a computer readable medium that implements the subject matter described herein may be located on a single device or computing platform or may be distributed across plural devices or computing platforms.","Although some of the aspects of the subject matter disclosed herein have been stated hereinabove, and which are achieved in whole or in part by the presently disclosed subject matter, other aspects will become evident as the description proceeds when taken in connection with the accompanying drawings as best described hereinbelow.","The present subject matter provides methods, systems and computer readable media for simulating sound propagation in a scene. In one aspect illustrated in , an exemplary implementation of the subject matter described herein is provided. Referring to , a sound source  may be any suitable application that receives user input for sound to be generated. The sound source  may be a game or any other application for which it is desirable to generate a sound. A sound simulator  implements the subject matter described herein for fast geometric sound simulation. Sound simulator  receives model parameters and generates the impulse response of a model as described above. When sound simulator  receives the input sounds from sound source , sound simulator  generates an output sound based on the fast computation method described below.","In addition to gaming, other applications of the subject matter described herein include architectural design and acoustic engineering for entertainment and other applications. In one implementation, sound simulator  may be implemented as middle-ware that resides between an application, such as sound source , and the underlying hardware that executes sound simulator  and sound source .","In one implementation, sound simulator  may be implemented using a non-transitory computer readable medium having stored thereon executable instructions that when executed by the processor of a computer control the computer to perform steps. Exemplary computer readable media for implementing the subject matter described herein include chip memory devices, disk memory devices, programmable logic devices, and application specific integrated circuits. In addition, a computer readable medium that implements the subject matter described herein may be located on a single device or computing platform or may be distributed across plural devices or computing platforms.","Regardless of the specific implementation, the present methods and systems can use visibility algorithms to accelerate GA methods used for computing specular reflections and edge diffraction. In particular, the methods and systems described herein can comprise two object-space visibility algorithms which can be used for fast GA computations. First, a point-based conservative visibility algorithm can improve the computation of specular reflections using an image-source method.","A second object-space visibility algorithm for fast GA computations can be an algorithm that computes visibility from a given edge in the model and is used to accelerate the performance of higher order finite-edge diffraction. In the context of geometric propagation, two main approaches exist for modeling edge diffraction: the Uniform Theory of Diffraction (UTD) and the Biot-Tolstoy-Medwin (BTM) model. UTD models diffraction around an infinite edge in terms of a single virtual point source on the edge. While this makes it fast enough to be useful in interactive applications, it is an approximate method and may only work well for models with very large edges in outdoor scenes. On the other hand, BTM models diffraction around finite edges in terms of many virtual point sources located along the edge. Although this makes the resulting approach more computationally intensive than UTD, it has been shown to be more accurate than UTD at low frequencies, where diffraction effects play an important role.","Significant time savings can be obtained through the use of these visibility algorithms on complex models.","Visibility Techniques","Visibility techniques have been studied in computer graphics, computational geometry, robotics and related areas for more than four decades. The basic goal of visibility algorithms is to compute a set of primitives that are visible from a given view-point or view-region. Visibility algorithms can be classified in different ways. One way is to classify them into from-point and from-region visibility. -show examples of from-point visibility where the circle S represents the view-point. From-point visibility is used in computer graphics for generating the final image from the eye-point based on rasterization or ray tracing. Other examples of applications of from-point visibility include hard shadow computation for point light sources.",{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIGS. 3","i":["a","c "],"b":"3"},"Given a view-point (v \u03b5 , from-point) or a view-region (v \u2282 , from-region), a set of geometry primitives (\u03a0), and a viewing frustum (\u03a6), which is a set of infinitely many rays originating in v, the goal of visibility techniques is to compute a set of primitives \u03c0  \u03a0 hit by rays in \u03a6. For example, in FIGS. -, the circle S corresponds to the viewpoint, and in -, the rectangle R corresponds to the view-region. The set of primitives is \u03a0={P, P, P, P, P, P} and the region shaded in light gray bounded by two arrows is spanned by rays in \u03a6, the viewing frustum. In -the visible set of primitives \u03c0={P, P} and in -the visible set of primitives \u03c0={P, P, P}. Note that the set it is called the potentially visible set (PVS). Depending on the properties of the computed PVS, visibility techniques can be further classified.","Object-Space Exact Visibility","Exact visibility techniques compute a PVS, \u03c0, hit by every ray in \u03a6 and every primitive in \u03c0is hit by some ray in \u03a6. Since every ray in \u03a6 is considered to compute visibility, these techniques are called object-space techniques. Moreover, these intersection computations are performed at the accuracy of the original model (e.g. IEEE 64-bit double precision arithmetic). The PVS computed by an object-space exact visibility algorithm is the smallest PVS which contains all the primitives visible from v. Many applications require exact visibility with object space precision. For example, accurate computation of soft shadows due to area light source in computer graphics requires the computation of exact visible area from all the points of the area light source to compute the contribution of the area light source at the point. Similarly, computing hard shadows due to a point light source requires accurate computation of visible portions of primitives from the point light source or aliasing artifacts may appear.",{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 2","i":"b ","b":["1","3","5","2","4","6","2","4","6"]},"Approaches based on Pl\u00fccker coordinates perform constructive solid geometry (CSG) operations in Pl\u00fccker space to compute exact visibility. Pl\u00fccker space is a six-dimensional space with certain special properties. In this approach, the view frustum and the primitives are represented in Pl\u00fccker space as CSG primitives and intersection computations are performed between the view-frustum and the primitives such that when the CSG intersection is transformed back into Euclidean space, it corresponds exactly to the visible primitives. The intersection between the view-frustum and primitives in Pl\u00fccker space requires complex operations. Thus, these techniques can be used to perform exact from-point visibility computations, but can be expensive and susceptible to robustness problems.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 3","i":"b ","b":["1","3","4","5","2","6"],"sup":["9","4"]},"Object-Space Conservative Visibility","Conservative visibility techniques compute a PVS, \u03c0, hit by at least every ray in \u03a6. In addition, however, the PVS, \u03c0, may contain primitives which are not hit by any ray in \u03a6. Thus, \u03c0is conservative in that it errs on the side of over-inclusion of primitives (i.e., \u03c0 \u03c0). Conservative from-point visibility algorithms are preferred for their computational efficiency and simplicity over exact algorithms. The two simple and widely used but highly conservative visibility techniques are view-frustum culling and back-face culling. They are used to trivially compute some of the hidden primitives.  illustrates these methods. In view-frustum culling, the primitives completely outside the view-frustum are marked hidden. In back-face culling, the primitives which are facing away from the view-point or view-region are marked as hidden. Conservative visibility is preferred in many applications mainly due to its ease of implementation and good performance improvement.","The choice between a conservative or an exact object-space algorithm is decided by the application on the basis of the trade-off between the overhead of extra visible primitives due to the conservative algorithm vs. the time overhead of the exact algorithm.",{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 2","i":"c ","b":["4","2","6"]},{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 3","FIG. 3"],"i":["c ","c "],"b":["2","1","5","1","5","6","6"]},"Regarding occluder selection, one option can be to simply use every primitive in the scene as an occluder, and use an occlusion culling algorithm that handles occluder fusion. In an ideal scenario, such an approach would result in a PVS that is as close as possible to \u03c0exact. However, the main issue with such an approach, which limits its practical application, is that the cost of occlusion culling is typically a function of the number of occluders. Most prior work on occluder selection uses heuristics based on distance, solid angles, or area of primitives. Although these methods compute a subset of \u03a0 to be used as occluders, they are unable to exploit the connectivity information of primitives to find any arbitrary set of connected triangles as occluders. If small occluders are combined into large occluders, the culling efficiency of the visibility algorithm can be improved.","Thus, the methods and system according to the present subject matter can use a from-region occluder selection algorithm which exploits the connectivity information between scene primitives whenever feasible. This approach is general and applicable to all kinds of models including \u201cpolygon soup\u201d models. No assumptions are made about the model or the connectivity of the polygons (e.g., in one implementation, the models can be assumed to be triangulated, but this is not a restriction imposed by the present algorithm). If the model connectivity information is given or can be extracted, this algorithm can exploit that information to compute large occluders formed by connected sets of primitives.","One algorithm that can be used to compute the occluders from a given region is shown generally in . In a first step , a query region R can be defined. Next, occluders can be chosen for query region R in a second step . In a third step , the occluders can be used to compute which primitives are hidden from R by the occluders. The set of primitives not hidden by the occluders can be defined as the potentially visible set for R in step .","The present technique can be viewed as a generalization of the conservative from-point visibility technique used in the FastV algorithm discussed above. As discussed above, FastV computes from-point visibility by constructing a cubical box around the query point R, then subdividing each of its faces into multiple quad patches Q (where the number of quad patches can be user-specified), and then constructing frusta FR from each quad patch q \u03b5 Q and R (see ). Each of these frusta can be used to compute which portions of the scene are visible from the query point that use the relevant patch as the viewport. Formally, for each q \u03b5 Q, the set of primitives p \u03b5 \u03a0 can be determined such that there exists a ray from R to some point on p which passes through q.","Given a frustum FR (defined by its corner rays), the FastV algorithm tries to compute a blocker for frustum FR. In the context of FastV, a blocker is defined as a connected set of triangles such that any convex combination of the corner rays of frustum FR intersects some triangle in the blocker. FastV traverses the scene hierarchy, and whenever a triangle T is found that intersects frustum FR, it uses the connectivity information associated with T to determine if some set of triangles connected to T can also be used as a blocker for frustum FR. It is possible that there may be no such triangles. Therefore, once the traversal is completed, FastV returns at most one blocker for frustum FR and zero or more connected sets of triangles in front of the blocker which do not completely block frustum FR.","Referring to , the frustum construction approach of FastV can be generalized to the from-region case (i.e., now R can be any convex region). A fattened oriented bounding box BB can be computed (where the amount of \u201cfattening\u201d can be user-specified) that encloses R and subdivide its faces into a user-specified number of quad patches Q. The next step is to determine the set of primitives p such that there exists at least one ray from some point r \u03b5 R to p which passes through q. Put another way, this step is intended to determine all points from which R is partially visible through q. This corresponds to the region in front of q and bounded by the set of separating planes constructed between R and q. Referring to , separating planes PLand PLcan be constructed between R and Q, and the frustum bounded by these planes can be traced and oriented such that Q is in the interior of the frustum. In this arrangement, O is a blocker for the separating frustum, and is used as an occluder for R.","Note that the separating planes can be oriented such that Q lies in the positive half-space (interior) defined by each separating plane s \u03b5 S. A separating frustum FR bounded by S can be constructed. The separating frustum need not be pyramidal. Rather, it is defined as the intersection of half-spaces bounded by the separating planes. View frustum culling techniques can be used to cull \u03a0 to f to estimate the PVS of R. However, this approach may compute a PVS \u03c0 such that there exist primitives p,p\u03b5\u03c0 where poccludes pfrom R, and the resulting PVS would be too conservative. Instead, FastV can be used to trace frustum FR as shown in . Those having skill in the art will recognize that if R is in fact a single point, the occluder selection algorithm reduces to FastV.","In one embodiment, all the rays that start on R and pass through q can be traced, and the set of primitives reached would approach \u03c0. However, tracing using FastV computes a subset of triangles visible from R through Q (i.e., computes \u03c0\u03c0). This subtle difference between the from-point and from-region case occurs because using FastV with a separating frustum for a region R is not guaranteed to find all geometry reachable by rays starting on R for a given frustum subdivision level, as is shown in . Therefore, after occluder selection, a conservative occlusion culling algorithm can be used to compute a superset of the exact PVS.","Tracing frustum FR using FastV can return a blocker for frustum FR. This blocker is a connected set of triangles such that any ray originating on R and passing through q intersects the blocker. Therefore, all blockers returned by FastV can be used as occluders. However, it is possible that FastV may be unable to find a blocker for frustum FR. In such a case, the connected sets of triangles computed by FastV during scene traversal can be used as occluders, as is shown in .","Given a set of occluders for R, the next step is to perform occlusion culling to compute the PVS of R. In one embodiment the umbra of an occluder o can be determined with respect to R. Unfortunately, the boundary of an exact umbra is bounded by curved surfaces. A common workaround is to compute a shadow frustum bounded by these curved surfaces and use it to determine a subset of triangles occluded by o (thus computing a superset of the exact PVS for R). The shadow frustum is bounded by the supporting planes between R and o and thus can be easily computed.","Although one particular algorithm is described above, any existing object-precision technique can be used for occlusion culling, as long as it guarantees that the resulting PVS is conservative. In the present implementation, a simple CPU-based frustum culling method can be used. For each occluder o, the shadow frustum SF of o from R can be computed, and all primitives behind o and completely contained in SF can be marked as occluded from R. Once all shadow frusta SF have been processed in this manner, the primitives not marked hidden are added to the PVS of R.","Although the above provided one method for identifying the PVS, it should be understood that many other algorithms have also been proposed for conservative from-region visibility. Several algorithms exist for performing occlusion culling with respect to shadow frusta, with different trade-offs and limitations. For example, some conservative algorithms operate in the dual space of rays, by dividing the scene into cells separated by portals and computing stabbing lines through portals.","Image-Space or Sample-Based Visibility","These approaches sample the set of rays in \u03a6 and compute a PVS, \u03c0, which is hit by only the finite set of sampled rays. Note that since \u03c0is computed for only a finite subset of rays in \u03a6, \u03c0 \u03c0. The choice of sampled rays is governed by the application. Sampling-based methods are widely used in graphics applications due to their computational efficiency and are well supported by current GPUs. Typically, during image generation, an image of a given resolution, say 1K\u00d71K pixels and only a constant number of rays per pixel are sampled to generate an image. Sampling based methods are extensively used in computer graphics for image generation. However, these methods can suffer from spatial and temporal aliasing issues and may require supersampling or other techniques (e.g. filters) to reduce aliasing artifacts.","An example of from-point sample-based visibility is shown in . Only a few rays are sampled and intersected with the geometric primitives to find the visible primitives. This could lead to spatial aliasing, as shown in . The primitive P is marked as hidden because it lies between two sampled rays even though it is visible from the view-point. Despite their short comings sample-based methods are widely used in computer graphics. Efficient implementation of sample-based visibility algorithms can be achieved on current graphics processing units (GPUs). The z-buffer algorithm is a standard sample-based visibility algorithm that is supported by the rasterization hardware in GPUs. Moreover, advanced support for sample-based visibility, such as from-point occlusion queries are also supported in GPUs. Also, sample-based ray shooting techniques have been used in computer graphics.","An example of from-region sample-based visibility is shown in . Similar to from-point visibility, the sampling in from-region algorithms introduces spatial aliasing. In this case, the primitive P is marked as hidden even though there exists at least one ray from the view-region that reaches the primitive P. Despite this omission, these methods are fast compared to exact and conservative from-region visibility algorithms and can easily be applied to complex models.","These methods have at least one important limitation, though. They sample a finite set of rays originating inside the view-region and thus compute only a subset of the exact solution (i.e., approximate visibility). Therefore, these methods are limited to sampling based applications such as interactive graphical rendering, and may not provide sufficient accuracy for applications where an accurate from-region solution is needed.","Geometric Acoustics and Visibility","New geometric sound propagation algorithms can be based on object-space conservative from-point and from-region visibility techniques. The present geometric sound propagation algorithms are based on the image source method. As originally formulated, the image source method can mainly simulate specular reflections. The most common methods include the image source method, ray tracing, and approximate volume tracing. Of these methods, the image source method is the most accurate, since it is guaranteed to not miss any specular propagation paths between the source and the listener. GA methods are also used for modeling diffuse reflections. The two main techniques of doing so are based on path tracing and radiosity.","Although it is considered relatively more difficult to model diffraction using GA methods (because diffraction involves sound waves bending around objects), it is possible to extend these methods to handle edge diffraction by introducing line or edge image sources. As noted above, the two most commonly used geometric models of diffraction are the Uniform Theory of Diffraction (UTD) and the Biot-Tolstoy-Medwin (BTM) model. The UTD model assumes infinite diffracting edges, an assumption which may not be applicable in real-world scenes (e.g., indoor scenes). However, UTD has been used successfully in interactive applications. BTM, on the other hand, deals with finite diffracting edges, and therefore is more accurate than UTD. It is much more complicated, however, and has only recently been used (with several approximations) in interactive applications.","The choice of visibility algorithm depends on the target application. For instance, room acoustics software requires accurate modeling of early specular reflections and edge diffraction, therefore, exact or conservative object-space visibility algorithms are most suitable. Similarly, for entertainment applications like games it might be possible to use sample-based visibility algorithms as temporal and spatial aliasing issues can be hidden by applying heuristics which reduce the accuracy of the simulation.","Another example is that the cost of computing the diffraction paths and IRs for double or triple diffraction for finite-edge diffraction using the BTM model could be so high that it might be worth looking into exact visibility approaches to compute the smallest PVS from an edge and thus minimize the path validation steps. The exact visibility algorithms are relatively expensive and it is hard to implement them robustly in 3D. However, the savings in the size of the visible set may result in improved overall performance.","Sample-Based Approaches","Due to their simplicity and efficiency, sampling based approaches are very popular in geometric acoustics, but the acoustic space has to be sampled densely to produce a robust solution. Since the sampling based approaches discretely sample the acoustic space, they introduce statistical errors and may miss critical early reflection paths. Many techniques like ray tracing, ray-frustum tracing, and other sample-based techniques have been applied to compute early specular reflection.","In addition, sample-based from-region visibility algorithms have not been used to accelerate finite-edge diffraction. Some recent techniques for sample-based from-region algorithms can be applied on simple scenes, but the impact of sampling needs to be carefully analyzed.","Object-Space Exact Approaches","The size of the visibility tree computed by exact object-space algorithms is guaranteed to be optimal. This improves the time taken by the path validation step since the number of potential paths to validate is the smallest. However, performing exact visibility to compute the visibility tree is compute intensive and may require a long time. Such methods have been applied for early specular reflection for limited scenes with a cell-and-portal structure. Applying these algorithms for early specular reflections for general scenes is computationally expensive and requires a robust implementation.","One possibility is to apply recently developed beam tracing algorithms for early specular reflection. Like sample-based approaches, no known exact object-space from-region has been applied to improve the finite-edge diffraction computation. It is possible to apply aspect graphs, visibility complex to compute from-region visibility from a diffracting edge. However, the computational complexity of such methods\u2014O(n) for aspect graphs and O(n) for the visibility complex, where n is the number of scene primitives\u2014makes them impractical for even the simple scenes. Moreover, these are global visibility algorithms and compute visibility from all points in the scene; they cannot be used to compute visibility from a given list of diffracting edges.","Object-Space Conservative Approaches","Given the computational complexity of exact approaches and aliasing issues with sampling-based approaches, conservative approaches offer an interesting alternative. Conservative approaches have lower runtime complexity as compared to the exact approaches and do not suffer from the aliasing errors that are common in sample-based approaches. The PVS computed by conservative approaches is larger than that computed by exact or sample-based visibility approaches, however, and therefore the size of visibility tree will be larger. Thus, the path validation step will take longer since there are more paths to validate. -compare different image-source methods. Given a sound source S and primitives (Ta, Tb, Tc, Td, and Te) the image source method shown in creates image-sources of S against all primitives in the scene. The beam tracing method shown in computes image-sources for only exactly visible triangles, Tb and Tc in this case. The accelerated beam tracing approach shown in computes image-sources for all triangles inside the beam volume (i.e., Tb, Tc, Td, and Te in this case). The present approach is shown in and computes image-sources for triangles Tb, Tc, and Td.","The main difference between these methods is in terms of which image sources they choose to compute. A na\u00efve image-source method computes image sources for all primitives in the scene. Beam tracing methods compute the image sources for exactly visible primitives from a source (or image source). Methods based on beam tracing, like accelerated beam tracing, compute image sources for every primitive inside the beam volume. The present approach, shown in , finds a conservative PVS from a source and computes the image sources for the primitives in the conservative PVS. The present approach is based on a conservative from-point and a conservative from-region algorithm to compute early specular reflection and finite-edge diffraction.","Accelerated Beam Tracing, a variant of beam tracing, has also been applied for early specular reflections. Regarding conservative visibility algorithms for finite-edge diffraction, only view-frustum culling has been applied and the present approach for reducing edge pairs for edge diffraction is the only known implementation which uses visibility algorithms for finite edge diffraction.","Sound Scattering","In the previous sections, discussion of accelerating early specular reflections and finite-edge diffraction by applying visibility techniques is presented. However, only modeling specular reflections and finite-edge diffraction is insufficient to accurately predict the acoustics of an environment. Sound scattering (i.e., interaction of sound waves with objects of size comparable to its wavelength), is important to accurately model room acoustics.","The geometric room acoustics can be generalized by an integral equation called the acoustic rendering equation (see Eq. 1 below).","The acoustic rendering equation can be seen as an extension of the rendering equation in computer graphics.",{"@attributes":{"id":"p-0079","num":"0078"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"L","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msup":{"mi":["x","\u2032"]},"mo":",","mi":"\u03c9"}}},{"mrow":[{"msub":{"mi":"L","mn":"0"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msup":{"mi":["x","\u2032"]},"mo":",","mi":"\u03c9"}}},{"msub":{"mo":"\u222b","mi":"S"},"mo":"\u2062","mrow":{"mrow":[{"mi":"R","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","\u03c9"],"mo":[",",","],"msup":{"mi":["x","\u2032"]}}}},{"mi":"L","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"x","mo":",","mfrac":{"mrow":[{"msup":{"mi":["x","\u2032"]},"mo":"-","mi":"x"},{"mo":["|","|"],"mrow":{"msup":{"mi":["x","\u2032"]},"mo":"-","mi":"x"}}]}}}},{"mo":"\u2146","mi":"x"}],"mo":["\u2062","\u2062"]}}],"mo":"+"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}}},"where L is final outgoing radiance, Lis emitted radiance, and R is the reflection kernel, which describes how radiance at point x influences radiance at point x\u2032:\n\n(\u2032,\u03c9)=\u03c1(\u2032,\u03c9)(\u2032)(\u2032)(\u2032)\u2003\u2003(2)\n","Here, \u03c1 is the BRDF of the surface at x, G is the form factor between x and x\u2032, V is the point-to-point visibility function, and P is a propagation term that takes into account the effect of propagation delays. The latter is unique to sound rendering as visual rendering algorithms neglect propagation delays due to the high speed of light. Also, depending on the BRDF (or scattering function) of a surface, different scattering properties of the surface (e.g., diffuse reflections) can be modeled.","Several methods have been developed to solve the acoustic rendering equation. Ray tracing is a popular geometric algorithm for acoustic modeling and can model specular and diffuse reflections easily. There has been much research in the computer graphics community to develop fast algorithms for ray tracing, such as by taking advantage of multi-core and many-core architectures, efficient scene hierarchies, and other acceleration techniques. Radiosity is another technique to model sound scattering. These algorithms operate by sampling the surface primitives and computing transfer operators which essentially encode the impulse response due to each sample at every other sample.","Visibility Acceleration","Solving the acoustic rendering equation requires the computation of visibility between two points, V(x,x\u2032). The visibility between two points ban be computed by shooting a ray from one point in the direction of the other. Hierarchies to organize scene geometry can be used to accelerate ray shooting and efficient handle scenes with moving geometries. Another possibility is to use from-region visibility data structures, like visibility complex or aspect graphs, to efficiently compute visibility between two points. These visibility algorithms are computation and memory intensive for large scenes. However, for small scene used in room acoustics it is might be feasible to apply from-region visibility data structures to accelerate sound scattering computations.","Sound Propagation Using Geometric Acoustics","To simulate sound propagation using GA methods, a point sound source, a CAD model with acoustic material properties, diffracting edges, and a listener position can be used to compute an impulse response (IR) of the acoustic space for the source and listener position. The IRs can be used to derive various acoustic parameters of a room. In , a CAD model (shown in top down view) consists of specular planes A to H and diffracting edges  to . The positions of source S and listener L are also shown.","To compute the IR, all the specular and diffraction propagation paths that reach the listener from the source can be computed. To do this, a two-step approach based on the image-source method can be used (see ). In a first step , inputs for the scene can be provided, such as scene geometry or source and listener positions. Based on these inputs, a second step  can comprise constructing a visibility tree VT(S,k) from source S up to a user-specified k orders of reflection, which can include the occluder selection steps discussed above with respect to . Note that only image sources for a source S (or image source) with respect to the triangles and\/or edges that are visible to S need to be computed. If S is a point source, for instance, this can involve from-point visibility computation. For example, regarding the image source IS of the source S about plane G in , only the image sources of IS about planes D, E, and F need to be computed for second order specular reflection from IS. If S is a line or an edge source, however, from-region visibility computation can be performed. Specifically, a from-edge visibility computation can be performed, which computes a superset of all the primitives that can be visible from any point on the edge. For example, as illustrated in , sound from a source S scatters in all directions upon encountering diffracting edge E. E itself is therefore the image source of S about E. The fact that the rays scatter in all directions from E implies that from region visibility is required to compute all geometry reachable by these rays.","For example, second order diffraction about the line source LS in can only occur with edges , , and . The visibility algorithms can be applied recursively for point and line image sources to construct the visibility tree. An example visibility tree for the configuration in -is shown in . Each path in VT(S,k) represents a potential path contributing to the IR. Each path consists of a sequence of (up to k) triangles and\/or edges that a ray starting from S reflects and\/or diffracts about as it reaches the listener at the position L. For example, S\u2192G\u2192E denote all specular paths from the source that bounces off planes G and then E. Similarly, S\u2192\u2192 denote all diffraction paths from the source that hit edge  and then edge .","To compute the final path from visibility tree, however, a listener position is required. Thus, in the second step, given a listener position L, a listener node can be attached to every node in the tree, and for each potential path in VT(S,k), it can be determined which of the propagation paths are valid. Thus, validating S\u2192G\u2192E\u2192L means finding a specular path from source that bounces off plane G and then plane E and then reaches the listener (). Similarly, validating S\u2192\u2192\u2192L means finding multiple paths from the source that hit edge  followed by edge  and then reach the listener (). It is possible that some of the paths are blocked by other primitives in the scene and may not contribute to the IR. The second step can be referred to as path validation.","Image Source Method","Alternatively, given a point source S and a listener L, ray shooting can be used to check if a direct path exists from S to L. The basic idea behind the image source method is as follows. For a specular reflector T (in the present case, a triangle), a specular path S\u2192T\u2192L exists if and only if a direct path exists from the image of S formed by T, to L, and this direct path also passes through T. In the absence of any visibility information, image sources need to be computed about every triangle in the scene. This process can be applied recursively to check for higher order specular paths from S to L, but the complexity can increase exponentially as a function of the number of reflections.","For a given source position, this process can be accelerated by applying from-point visibility techniques. It is noted that first order image sources only need to be computed about triangles visible to S. For a first-order image source S, second-order image sources only need to be computed for the triangles that are visible to Sthrough T, and so on for higher order image sources.","BTM Based Finite-Edge Diffraction","Analogous to how specular reflection about a triangle is modeled by computing the image of the source with respect to the triangle, diffraction about an edge is modeled by computing the image of the source with respect to the edge. The key idea is that the image source from a point source S with respect to diffracting edge E is that edge E itself. This means that image sources can now be points or line segments. It is further noted that the image of a point or line source Sabout a planar specular reflector T is obtained by reflecting Sacross the plane of T.","For a given edge source, the basic approach described above can be accelerated by applying from-region visibility techniques. Note that second-order diffraction image sources for an edge source Sneed to be computed for edges that are visible from S. Also, specular reflections of Sneed to be computed from triangles that are visible from S.","Results","Table 1 below summarizes the present results on early specular Tracing (ABT) algorithm, which is another conservative from-point visibility algorithm. Specular reflection results using the present methods and systems were obtained on models of complexity ranging from 438 triangles to 212K triangles. The performance on three benchmarks is also tested, and the timings for constructing the visibility tree is compared using both the present approach and ABT.",{"@attributes":{"id":"p-0093","num":"0092"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"70pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["Model","Triangles","Time (sec)","Speed Up (ABT)"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"70pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Room","\u2002438","0.16","10.1"]},{"entry":["Regular Room","1190","0.93","22.2"]},{"entry":["Complex Room","5635","6.50","11.8"]},{"entry":["Sibenik Cathedral","78.2K","72.00","\u2014"]},{"entry":["Trade Show","\u2009212K","217.60","\u2014"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Two additional complex benchmarks can be used with 80K and 212K triangles. It is believed that there is not any other implementation of the image source method that can handle models of such complexity in tractable time. The performance of the present visibility algorithm can also be compared with a fast beam tracing algorithm, with the size of the PVS computed by the present methods converging to within 1-10% of the exact from-point beam tracing PVS (see ). Thus, in terms of performance, the application of the present methods and systems is about 5-8 times faster on a single CPU core on the tested model as compared to conventional methods.","Table 2 below highlights the results on finite-edge diffraction. The performance of the present visibility tree construction step (using from-region visibility) is compared against visibility tree construction using only view-frustum culling (as applied in the MATLAB Edge Diffraction toolbox). The time required to build the visibility tree is compared as well as the size of the tree constructed for each approach.",{"@attributes":{"id":"p-0096","num":"0095"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"center"}}],"thead":{"row":{"entry":[{},"TABLE 2"]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Second order diffraction paths in tree","Path validation"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"49pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Scene","Triangles","Edges","Present method","MATLAB","Size reduction","Speedup"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"6","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"7","colwidth":"49pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Factory","170","146","4424","12570","2.84","1.93"]},{"entry":["Room","876","652","43488","181314","4.17","3.23"]},{"entry":["House","1105","751","133751","393907","2.95","13.74"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Table 3 below shows the breakdown of time spent in each step of the present algorithm. Specifically, Table 3 shows both the time spent in constructing a visibility tree (averaged over multiple source positions) and the time taken to compute the final IR (averaged over multiple source and listener positions.",{"@attributes":{"id":"p-0098","num":"0097"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"91pt","align":"center"}}],"thead":{"row":[{"entry":[{},"TABLE 3"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},"Scene","Visibility Tree (ms)","IR Computation (s)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"91pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Factory","141.0","23.9"]},{"entry":[{},"Room","747.6","10.4"]},{"entry":[{},"House","1045.6","24.3"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}]}},"br":{},"figref":"FIGS. 16","i":["a ","b "],"b":"16"},"Regarding occluder Selection for from-region visibility, running times of the present occluder selection step per triangle is presented in in Table 4. The table further reports the average size of each occluder (in terms of the number of triangles) returned by the occluder selection algorithm.",{"@attributes":{"id":"p-0100","num":"0099"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"center"}}],"thead":{"row":{"entry":[{},"TABLE 4"]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]},{"entry":[{},"Occluder Selection"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"91pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Scene","Triangles","Time (s)","Avg. triangles per occluder"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"91pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Floor","7.3K","0.12","6.0"]},{"entry":["Building","\u200969K","1.3","3.0"]},{"entry":["Soda Hall",{"sup":"\u2009"},"14.8","6.7"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Table 5 compares the total running time for from-region visibility (occluder selection and occlusion culling) and the resulting PVS sizes when our occlusion culling implementation is provided with occluders computed using three approaches: no occluder selection (i.e., using all primitives as occluders), area-ratio heuristics, and the present occluder selection algorithm based on tracing separating frusta.",{"@attributes":{"id":"p-0102","num":"0101"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"56pt","align":"center"}}],"thead":{"row":{"entry":[{},"TABLE 5"]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},{},{},"Tracing"]},{"entry":[{},"No Occluder","Area Ratio","Separating"]},{"entry":[{},"Selection","Heuristic","Frusta"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"8"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"8","colwidth":"28pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},"Time","PVS","Time","PVS","Time","PVS"]},{"entry":["Scene","Triangles","(ms)","Size","(ms)","Size","(ms)","Size"]},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"8"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"21pt","align":"char","char":"."}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"7","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"8","colwidth":"28pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Factory","170","15.2","64","14.9","64","11.5","69"]},{"entry":["Room","876","240","356","241.4","356","102","379"]},{"entry":["House","1150","192","209","112.2","261","90","350"]},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Regarding impulse responses, the methods and systems according to the present subject matter implement the line integral formulation of the BTM model for performing path validation and computing impulse responses. One parameter in the validation step is the number of samples each edge is divided into. A higher number of samples per edge results in more accurate evaluation of the BTM integral at a higher computational cost. through show impulse responses computed for diffraction about a simple double wedge for increasing numbers of samples per edge. Specifically, shows the impulse response with 1K samples per edge, shows the impulse response with 10K samples per edge, and shows the impulse response with 44K samples per edge. As can be seen from the figures, increasing the number of samples causes the IRs to converge to the reference IR computed by a reference method (MATLAB Edge Diffraction toolbox), which is shown in for comparison.","It is further noted that although the computational cost of the BTM model remains higher than that of the UTD model, those having skill in the art will recognize that the BTM model is more accurate than UTD model at low frequencies, where diffraction plays an important role. Furthermore, the UTD approach does not model the diffraction contributions in regions where the listener is in line-of-sight of the source, whereas the BTM approach does. At low frequencies, numerical methods can be used to capture diffraction effects, but the complexity scales with the volume of the scene, as opposed to BTM-based methods whose complexity scales with the number of diffracting edges. Moreover, combining a numerical acoustics algorithm with geometric acoustics techniques for high frequency simulations remains a challenging problem, whereas the BTM approach can easily be combined with the image source method to compute accurate diffraction effects.","The subject matter described herein for simulating sound propagation in a scene can be implemented using a non-transitory computer readable medium having stored thereon executable instructions that when executed by the processor of a computer control the computer to perform steps. Exemplary computer readable media suitable for implementing the subject matter described herein can include chip memory devices, disk memory devices, programmable logic devices, and application specific integrated circuits. In addition, a computer readable medium for implementing the subject matter described herein may be located on a single device or computing platform or may be distributed across plural devices or computing platforms.","The present subject matter can be embodied in other forms without departure from the spirit and essential characteristics thereof. The embodiments described therefore are to be considered in all respects as illustrative and not restrictive. Although the present subject matter has been described in terms of certain preferred embodiments, other embodiments that are apparent to those of ordinary skill in the art are also within the scope of the present subject matter."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The features and advantages of the present subject matter will be more readily understood from the following detailed description which should be read in conjunction with the accompanying drawings that are given merely by way of explanatory and non-limiting example, and in which:",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIGS. 2","i":["a","c "],"b":"2"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIGS. 3","i":["a","c "],"b":"3"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIGS. 8 and 9"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIGS. 10","i":["a","d "],"b":"10"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIGS. 12","i":["a","c "],"b":"12"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIGS. 14","i":["a ","b "],"b":"14"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIGS. 16","i":["a ","b "],"b":"16"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIGS. 17","i":["a","d "],"b":"17"}]},"DETDESC":[{},{}]}
