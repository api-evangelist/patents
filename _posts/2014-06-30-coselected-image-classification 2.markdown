---
title: Co-selected image classification
abstract: Co-selected images are labeled based on a topic score that is a measure of relevance of the co-selected image to a first topic to which a reference image belongs. The first topic to which the reference image belongs is identified based on a reference label associated with the reference image. The co-selected images are images that are selected for presentation subsequent to selection of the reference image during a user session. The co-selected images are identified based on selection data for user sessions in which the reference image was selected for presentation. The topic score is generated based on a frequency of selection of the co-selected image. Image search results for a second topic can be filtered to remove images that are labeled as belonging to the first topic or the image search results can be reordered to adjust the presentation positions at which images are referenced based on the topic to which the images belong.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09594826&OS=09594826&RS=09594826
owner: Google Inc.
number: 09594826
owner_city: Mountain View
owner_country: US
publication_date: 20140630
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The present disclosure relates to data processing, and in particular, image classification.","Users can locate images that are available on the Internet by submitting a search query to a search engine. The search query can be a text query that includes words describing image subject matter for which the user is attempting to locate. The search system identifies images that correspond to the subject matter and provides image search results that include references to the identified images. The images can be identified, for example, based on labels that are associated with the images and\/or text appearing near the images on the web pages with which the images are presented.","The identified images can be, for example, images that are presented with web pages. Many different categories of webpages can include images that are identified in response to a search query. For example, images are provided with webpages such as weblogs (\u201cblogs\u201d), social networking pages and newsgroups that can be published by many different individuals. Within a single domain (e.g., www.example.com) there can be thousands of webpages, many of which have different individual authors.","Due to the large number of different authors creating webpages located in the same domain, it can be difficult to classify images provided through the domain as belonging to a common topic. For example, within a single blog domain, users may publish blogs directed to topics ranging from sports, to politics, to parenting advice, or even explicit (e.g., pornographic) topics. Thus, if each image available through a common domain is classified as belonging to a common topic, the images may not be accurately classified.","Labels associated with the image and\/or text appearing near the image can inaccurately describe the subject matter of the image or be ambiguous among different topics. For example, an image of Babe Ruth appearing in a blog may be associated with the text \u201cThe Babe.\u201d While this text is relevant to the image, it is possible that the image could be of Babe Ruth, an actor playing Babe Ruth, a pig featured in a move titled \u201cBabe,\u201d or even explicit images.","Providing images that are less relevant to the topic of a user query can reduce the quality of image search results. This is particularly true when images including explicit content (e.g., pornography) are referenced in search results responsive to a query that is not directed to the explicit content. For example, search results responsive to a search query for \u201cBabe Movie\u201d including an explicit image can substantially reduce the quality of the search results for a user that is searching for images of Babe Ruth.","The quality of image search results can be enhanced when images are accurately classified, such that images that are not relevant to the user query can be filtered or otherwise suppressed.","An image classification system analyzes image selection data to classify and label images based on a topic to which a previously selected image belongs. These labels can then be used to filter image search results to remove references to images that are more relevant to a topic other than the topic to which a search query is directed. Additionally, the labels can be used to filter all images that are directed to a topic (e.g., explicit content), unless a user opts to have references to these images presented. The labels can also be used to adjust the presentation position at which images are referenced in image search results based on topics to which the images belong.","In general, one aspect of the subject matter described in this specification can be implemented in methods that include the actions obtaining a reference label for a reference image, the reference label being a label that specifies a first topic to which the reference image belongs; identifying, in a data processing system, user sessions during which the reference image was selected for presentation, each user session being a period for which selections of images are associated into a session set; identifying, in the data processing system, co-selected images for the reference image that were selected for presentation during the user sessions, a co-selected image being an image that is selected subsequent to selection of the reference image; for each co-selected image, generating, in the data processing system, a topic score based on a frequency of selection of the co-selected image for the reference image, the topic score representing a measure of relevance of the co-selected image to the first topic; and labeling co-selected images having topic scores that satisfy a threshold topic score as belonging to the first topic. This and other embodiments of this aspect include corresponding systems, apparatus, and computer program products.","These and other embodiments can optionally include one or more of the following features. The methods can further include the actions identifying, for a user session, a first time of selection for the reference image; identifying subsequent times of selection for co-selected images selected during the user session; and identifying, as co-selected images, only images having subsequent times of selection that are within a threshold time period relative to the first time of selection, wherein the user session has a session time period and the threshold time period is less than the session time period.","The topic score can be generated by obtaining initial topic scores for the co-selected images, each initial topic score being an initial relevance measure of the image to the first topic; obtaining co-selection data for the co-selected images, the co-selection data specifying selections of the co-selected images relative to selections of the reference image or other co-selected images; computing an updated topic score for the co-selected images based on a function of the initial topic scores and the co-selection data; determining whether a stop condition has occurred; when the stop condition has not occurred, computing additional updated topic scores based on the co-selection data and previously computed updated topic scores; when the stop condition has occurred, classifying the co-selected images based on the updated topic scores; and wherein the labeling is based on the updated topic scores.","Particular embodiments of the invention can be implemented to realize one or more of the following advantages. Topics to which unclassified images belong can be identified as belonging to reference topics based on co-selection data relative to a reference image for the reference topic. Images that are identified as belonging to a reference topic can be filtered from image search results. Images belonging to a reference topic can be selected for presentation at higher or, lower presentation positions in image search results relative to images that are not identified as belonging to the reference topic. Images can be labeled with a label corresponding to a reference topic based on co-selection data relative to a reference image for the reference topic. An image can be identified and labeled as a pornographic image based on subsequent selection of the images following selection of an image that has a high likelihood of being pornographic. Each image in a corpus of images can be categorized based on its selection relative to selections of reference images for reference topics.","The details of one or more embodiments of the invention are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the invention will become apparent from the description, the drawings, and the claims.","Like reference numbers and designations in the various drawings indicate like elements.","An image classification system analyzes image selection data to classify and label images based on a topic to which a previously selected image belongs. These labels can then be used to filter image search results to remove references to images that are more relevant to a topic other than the topic to which a search query is directed. Additionally, the labels can be used to filter all images that are directed to a topic (e.g., explicit content), unless a user opts to have references to these images presented.","An online environment in which search services are provided is described below. An image classification system that labels images based on selection data is described with reference to this online environment as a subsystem of a search system. However, the image classification subsystem can be implemented independent of the image search system.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 1","b":["100","110","100","104","106","110","100","104","106"]},"A web site  is one or more resources associated with a domain name and hosted by one or more servers. An example web site is a collection of web pages formatted in hypertext markup language (HTML) that can contain text, images, multimedia content, and programming elements, e.g., scripts. Each web site  is maintained by a publisher, e.g., an entity that manages and\/or owns the web site.","A resource is any data that can be provided by the web site  over the network  and that is associated with a resource address. Resources include HTML pages, word processing documents, and portable document format (PDF) documents, images, video, and feed sources, to name just a few. The resources can include content, e.g., words, phrases, images and sounds and may include embedded information (such as meta information and hyperlinks) and\/or embedded instructions (such as JavaScript scripts).","Each resource has an addressable storage location that can be uniquely identified. The addressable location is addressed by a resource locator, such as a universal resource locator (URL).","A user device  is an electronic device that is under control of a user and is capable of requesting and receiving resources over the network . Example user devices  include personal computers, mobile communication devices, and other devices that can send and receive data over the network . A user device  typically includes a user application, such as a web browser, to facilitate the sending and receiving of data over the network .","To facilitate searching of these resources, the search system  identifies the resources by crawling and indexing the resources provided by the publishers on the web pages . Data about the resources can be indexed based on the resource to which the data corresponds. The indexed and, optionally, cached copies of the resources are stored in an indexed cache .","The user devices  submit search queries  to the search system . In response, the search system  accesses the indexed cache  to identify resources that are relevant to the search query . The search system  identifies the resources in the form of search results  and returns the search results  to the user devices  in search results pages. A search result  is data generated by the search system  that identifies a resource that is responsive to a particular search query, and includes a link to the resource. An example search result  can include a web page title, a snippet of text or a portion of an image extracted from the web page, and the URL of the web page.","For a search of textual content, the search results are ranked based on scores related to the resources identified by the search results, such as information retrieval (\u201cIR\u201d) scores, and optionally a separate ranking of each resource relative to other resources (a \u201cpage rank\u201d score). In some implementations, the IR scores are computed from dot products of feature vectors corresponding to a search query  and a resource, and the ranking of the search results is based on relevance scores that are a combination of the IR scores and page quality scores. The search results  are ordered according to these relevance scores and provided to the user device according to the order.","For a search directed to images and that uses a text query as input, the search system  can combine the relevance score of a resource with a relevance feedback score of an image embedded in the resource. An example relevance feedback score is a score derived from a selection rate of an image when that image is referenced in a search result. These combined scores are then used to present search results directed to the images embedded in the resources.","The user devices  receive the search results pages e.g., in the form of one or more web pages, and render the pages for presentation to users. In response to the user selecting a link in a search result at a user device , the user device  requests the resource identified by the link. The web site  hosting the resource receives the request for the resource from the user device  and provides the resource to the requesting user device .","Search queries  submitted during user sessions are stored in a data store such as the historical data store . Selection data specifying actions taken in response to search results provided during the user sessions are also stored in a data store such as the historical data store . These actions can include whether a search result was selected and\/or a \u201cdwell time\u201d associated with the selection (i.e., a time period between the selection and a subsequent selection. The data stored in the historical data store  can be used to map search queries  submitted during user sessions to resources that were identified in search results  and the actions taken by users, e.g., an ordered list of resources that were selected for presentation during the user session.","A user session is a period during which data specifying actions taken with respect to resources are associated with a common session identifier. The period of a user session can be measured by time, a number of actions taken or some other delineation of user actions. For example, a user session can include user actions with respect to resources over a minute, an hour, a day, or any other time period. Similarly, a user session can include a threshold number of user selections of resources.","Each user session can be associated with a unique session identifier. The unique session identifier can be generated, for example, based on one or more of a user device identifier, a time indicator for the user session and other data indicative of the context of the user session (e.g., geographic region from which the user session originates). The user device identifier can be, for example, an anonymized identifier, such as a cookie that has been anonymized (i.e., an anonymized string of text that serves as an identifier for the user session) that is associated with a user device  to which the user session corresponds. Thus, actions occurring during a user session can be disassociated from the particular user device  from which the action originated.","Actions, such as selections of images, that occur during a particular user session are associated with the same unique session identifier. Additionally, each action occurring during the particular user session can be associated with additional time data indicating a time at which the action occurred. The time can be an absolute time, such as the Greenwich Mean Time at which the action took place, or a time relative to a start of the user session or a time relative to another user action.","User session data specifying the actions that occurred during each user session can be stored in a data store such as the historical data . The user session data can be used to identify images that were sequentially selected during a particular user session and identify images that belong to a common topic based on their sequential selection.","The search system  includes an image classification subsystem . In some implementations, the image classification subsystem  includes one or more processors configured to classify an image to a topic based on user session data. The image classification subsystem  analyzes the user session data to identify images that were selected subsequent to selection of a reference image. The reference image is an image that is pre-classified with a known topic, e.g., an image having a label that specifies a topic to which the reference image belongs. Images that are selected subsequent to selection of a reference image during a particular user session are referred to as co-selected images for the reference image.","The images selected by a user during a particular user session are generally more likely to belong to the same topic. Therefore, co-selected images for a reference image are more likely to belong to the same topic as the reference image than images that are not co-selected images for the reference image. For example, images that are co-selected images for a pornographic reference image are more likely to be pornographic images than images that are not co-selected images for a pornographic image. Similarly, images that are co-selected for a non-pornographic reference image are more likely to be non-pornographic images. Thus, images that are frequently co-selected images for a reference image or a set of reference images can be classified as belonging to the same topic as the reference image with a high degree of confidence.","In some implementations, the image classification subsystem  generates a topic score that represents the likelihood that a co-selected image belongs to the same topic as the reference image. The topic score for a co-selected image can be generated, for example, based on a frequency with which the image is co-selected with the reference image and a proximity of the co-selection (e.g., time or actions between the selections) of the image relative to selection of the reference image. Methods of generating a topic score are described with reference to  and , respectively.","Co-selected images having a threshold topic score are identified as belonging to the same topic as the reference image. The threshold topic score can be specified, for example, as an absolute topic score, or a highest N percentage of topic scores among other thresholds (e.g., images having a highest M topic scores).","The image classification subsystem  can label co-selected images that are identified as belonging to the same topic as the reference image with textual data corresponding to the topic. Alternatively, a topic flag represented by a data bit can be set indicating that the co-selected image belongs to the topic can be set and stored at a memory location associated with the co-selected image in the indexed cache . In turn, the co-selected image can be identified as a new reference image for the topic such that selection of other images subsequent to selection of the new reference image will be an indication that the other images also belong to the topic. This classification process can propagate through a corpus of images until a threshold number of the images or all of the images have been classified.","In some implementations, image search results  responsive to search queries  can be filtered or reordered for presentation based on the classification by the image classification system . For example, classification data (e.g., labels or topic flags) identifying the images that are identified as pornographic images can be made available to the search system . The search system  can use the classification data to analyze image search results responsive to a search query  to determine whether any of the images that are referenced by the image search results are pornographic images. References to pornographic images can be removed or presented at less prominent positions of the search results to increase the quality of the search results. Such modifications can be subject to user preferences.","Similarly, the image search results that are generated for a search query  can exclude or select images to reference in the image search results based on the label. For example, the search system  can use label data stored at a memory locations associated with the images in the indexed cache  to obtain images that are relevant to the search query . Images that are associated with a label that is more relevant to the search query  can be identified as more relevant to the search query  than images that are associated with images that are less relevant to the search query .","For example, if the image classification subsystem  labeled an image of Babe Ruth with the textual data \u201cbaseball,\u201d the image of Babe Ruth would be more relevant to a search query  for \u201cbaseball\u201d than a search query  for \u201cpig movie.\u201d Thus, a reference to the image of Babe Ruth could appear higher in image search results for \u201cbaseball\u201d and may not appear in image search results for the search query \u201cpig movie.\u201d",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 2","FIG. 1"],"b":["200","200","120"]},"A reference label is obtained for a reference image (). In some implementations, the reference label is a label that specifies a reference topic to which the reference image belongs. The reference label can be, for example, a textual label or a topic flag that is indicative of the reference topic. For example, a reference label corresponding to the reference topic may be represented by a data bit corresponding to the reference topic being set to a specified binary value. Alternatively, the reference label can be textual data corresponding to the reference label. For example, a pornographic image can be labeled with the text \u201cexplicit\u201d or \u201cpornographic.\u201d","In some implementations, human evaluators can identify a pornographic image and label the pornographic image with a reference label that identifies the image as a pornographic image. In other implementations, the pornographic image can be identified by a machine and labeled with a reference label accordingly. In turn, the reference label can be verified for accuracy by the evaluators.","Reference labels can be obtained from a data store storing labels corresponding to images, or generated based on data associated with the image. Labels for images can be generated using image processing techniques to determine whether visual characteristics of the image are indicative of a pornographic image and\/or textual analysis to determine whether text associated with the image is indicative of a pornographic image.","The reference labels for a reference image can be generated, for example, based on image processing techniques. In some implementations, visual characteristics (i.e., color and\/or texture) of an image can be compared to visual characteristics of images that have been previously labeled with the reference label or otherwise identified to belong to the topic represented by the reference label (e.g., identified as a pornographic image). For example, one method of identifying pornographic images is to identify a portion (e.g., number or percentage) of the pixels for the image that are \u201cskin pixels\u201d (i.e., pixels having a color value corresponding to a skin tone). When the portion of pixels exceeds a threshold, the image can be identified as a pornographic image and labeled with a reference label that corresponds to a pornographic topic.","The reference label can also be generated, for example, based on textual data located near the reference image on a web page with which the reference image is presented. For example, text appearing within a threshold number of pixels of the reference image can be analyzed to identify topics that may be relevant to the reference image. The reference label can also be generated based on other text that is associated with the reference image. For example, a reference label can be generated based on text that is included in a file name for the reference image, anchor text of a link to the image, or text that is explicitly associated with the reference image.","Text can be explicitly associated with a reference image by publishers to facilitate identification of the image as relevant to search queries for a particular topic. For example, a publisher can specify the text \u201cbaseball\u201d with an image of a baseball player to increase the likelihood that the image is identified in response to a search query including the term \u201cbaseball.\u201d","In some implementations, a reference label for a reference image is required to have a threshold likelihood of accurately describing the content of the reference image. The accuracy of a label for an image can be determined, for example, based on label feedback. Label feedback is data obtained from users that specifies a reference label for an image or provides a measure of relevance between a label and the reference image.","Label feedback can be received from a user that has been requested to label images or confirm existing labels for images. Alternatively, label feedback can be received from anonymous users that are provided images and requested to select topics to which the images are most relevant and\/or least relevant. For example, users can be provided with an image and a list of M topics. The users can select one of the M topics that is most relevant to the image or most accurately describes the content of the image. User selections of topics that are most relevant to the content of the image can be aggregated to determine the topic to which the image belongs. For example, if a threshold percentage of users selected a particular topic as being most relevant to the image, the particular topic can selected as the topic to which the image belongs.","Label feedback can also be analyzed to determine a likelihood that an existing label for the reference image is accurate. The likelihood that the existing label for the image is accurate can be based on a portion of user feedback that identifies the existing label as an accurate label for the image. For example, if a threshold percentage of the user feedback indicates that the existing label is an accurate label for the image, then the existing label can be identified as a reference label for the reference image. In turn, the reference image can be identified as belonging to the topic specified by the reference label.","In some implementations, the portion user feedback identifying the image as belonging to the topic specified by the reference image can be used as a measure of the strength of the reference image to the topic. For example, the likelihood that the label is accurate can be used as a probability that the image is a reference image belonging to the topic specified by the label. The likelihood that the image is a reference image can, in turn, be used as a weight identifying the strength of the image as a reference image for the topic specified by the label. The strength of the image as a reference image can be used when generating topic scores for other images, as discussed below with reference to .","A user session during which the reference image was selected for presentation is identified (). The user session during which the image was selected for presentation can be identified by identifying unique session identifiers that are associated with selection data for the reference image. For example, selection data stored in the historical data  of  can be obtained for the reference image. In turn, unique session identifiers associated with the selection data can be analyzed to identify a user session during which the reference image was selected for presentation. Generation of selection data for a user session is described in more detail with reference to .","Co-selected images for the reference image that were selected for presentation during the user session are identified (). In some implementations, the co-selected images can be identified based on selection data for images that are associated with the unique session identifier for the user session. For example, selection data in the historical data  of  that is associated with the unique session identifier for the reference image can be obtained. The selection data is analyzed to identify images that were co-selected with the reference image. For example, time data included in the selection data for an image can be analyzed to determine whether the image was selected for presentation prior to or subsequent to selection of the reference image. Images that were selected for presentation subsequent to the selection of the reference image are identified as co-selected images.","A determination is made whether the reference image was selected during another user session (). The determination can be made, for example, by determining whether selection data for the reference image is associated with another unique session identifier. The reference image can be identified as being selected during another user session when selection data for the reference image is associated with another unique session identifier. If the reference image was selected during another user session, co-selected images for the reference image that were selected for presentation during the user session are identified ().","When the reference image was not selected during another user session or after all additional user sessions have been identified, a topic score is generated for each co-selected image based on the selections of the co-selected images relative to selection of the reference image (). In some implementations, the topic score is a measure of relevance of the co-selected image to the topic. Each selection of a co-selected image subsequent to selection of the reference image increases the likelihood that the co-selected image is relevant to the reference image, and, therefore belongs to the same topic as the reference image. For example, a co-selected image that is selected more frequently following selection of the reference image than another co-selected image is likely more relevant to the same topic as the reference image than the less frequently selected co-selected image.","The likelihood that a co-selected image is relevant to the reference image can also be based on a dwell time associated with the selections of a co-selected image. For example, a co-selected image having a longer dwell time than another co-selected image is more likely relevant to the same topic as the reference image because the user spent more time viewing the co-selected image with the longer dwell time.","The likelihood that a co-selected image is relevant to the reference image can also be based on a proximity of the selection of the co-selected image to selection of the reference image. The proximity of selection can be measured in units of time, number of user actions, or any other delineation of a user session.","For example, a co-selected image that is the first image selected following selection of the reference image is more likely relevant to the same topic as the reference image than another co-selected image that is the fourth image selected following selection of the reference image. Therefore, the co-selected image selected first following selection of the reference image is more likely to belong to the same topic as the reference image than later selected co-selected images.","In some implementations, an image must be selected within a threshold time period relative to the selection of the reference image in order to be identified as a co-selected image. For example, when a duration of a user session is longer than the period within which subsequently selected images are identified as co-selected images, the threshold time period can be used to determine whether an image selected following selection of a reference image is a co-selected image for the reference image.","In some implementations, the topic score for a co-selected image can be the result of a function of the frequency and\/or proximity of the selections of the co-selected image relative to selection of the reference image. For example, the topic score can be a sum of the total selections for the co-selected image following selection of the reference image. Similarly, the topic score can correspond to a number of reference images relative to which the image is co-selected. For example, an image that is a co-selected image for ten reference images can have a topic score of \u201c10,\u201d while an image that is a co-selected image for five reference images can have topic score of \u201c5.\u201d","Each selection of the co-selected image can be weighted by a factor indicative of the proximity of the selection relative to selection of the reference image. For example, each selection can be weighted by the factor 1\/(selection number) such that selection of the co-selected image immediately following selection of the reference image will have a weight of 1 (i.e., 1\/1). Similarly, the second and third co-selected images following selection of the reference image will have weights of \u00bd and \u2153, respectively. The weight factor described is provided for example purposes. The weight factor can be any ratio or function of the proximity of co-selected image selection relative to selection of the reference image.","In some implementations, generation of the topic scores for the co-selected images can be facilitated by using weighted graph to map selections of co-selected images relative to selection of the reference image. The reference image and co-selected images are represented by nodes in the weighted graph and edges representing sequential selections of the co-selected images connect the nodes. Generation of a weighted graph is described in more detail with reference to .","Co-selected images having topic scores that satisfy a threshold topic score are labeled (). In some implementations, the threshold topic score is satisfied when the topic score meets or exceeds the threshold topic score. The threshold topic score can be specified, for example, as an absolute topic score, or a highest N percentage of topic scores among other thresholds (e.g., images having a highest M topic scores).","In some implementations, the co-selected images are labeled to identify the co-selected images as belonging to the same topic as the reference image. For example, textual data matching the reference label for the reference image can be associated with the co-selected images. Alternatively, a topic flag for the co-selected image can be set to identify the co-selected image as belonging to the same topic as the reference image. The label can be stored at a memory location associated with the co-selected image and made available for other systems or subsystems, such as a search system.",{"@attributes":{"id":"p-0074","num":"0073"},"figref":["FIG. 3","FIG. 3"],"b":["300","120","110","120","110","102"]},"A user session is generally initiated by a user device . For example, the user device  can submit an image search query or another request for search results over the network . The request can be associated with a unique session identifier and processed, for example, by the search engine . The search engine  provides the user device  with image search results  responsive to the search query. The image search results  include result images ---N that are references (e.g., thumbnails) to images that have been identified by the search system  as being relevant to the search query.","User session data identifying the search query and the images referenced by the image search results are associated with a unique session identifier for the user session and stored in the historical data . The user session data can include time data that indicates a time at which the user session was initiated (e.g., a time when the search query was received) and\/or a time at which the search results  were provided to the user device .","A user of the user device  can select one or more of the result images ---N from the image search results . Each selection of result images ---N generates a request for a resource location that is specified by the selected result image. For example, a selection of result image - can generate a request for a web page with which the image referenced by the result image - is presented. In turn, the web page can be provided to the user device  for presentation.","Each selection of a result image ---N is provided to the image search system  through the network as selection data . The selection data  includes data specifying the unique session identifier (e.g., ID1, ID2, . . . , ID3) that identifies the user session that corresponds to the selections. The selection data  also includes data identifying the images (e.g., IS11; IS12, . . . , IS1N) that were selected for presentation, for example, based on selections of image results ---N. The selection data  can further include time data specifying when each of the images were selected for presentation.","The selection data  is obtained by the search system  over the network  and stored at memory locations of the historical data  that are associated with the unique session identifier. Selection data  can be obtained for each user device  that requests images and over the duration of each user session. Thus, selection data for each image that is selected by user devices  during multiple user sessions is accessible from the historical data .","In some implementations, the image classification subsystem  uses the selection data to construct a weighted graph  to map aggregate selections of co-selected images relative to selections of a reference image. In turn, the weighted graph  can be used to classify co-selected images.",{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 4","b":["400","400","120","120","120","120","400","120","400"]},"The weighted graph  includes a reference node  that represents a reference image for which co-selected images are being identified. In some implementations, the reference node  represents an image that is identified as a pornographic image, for example, because the image is identified as belonging to a pornographic topic. The topic to which a reference image belongs can be identified, for example, based on a reference label or another topic indicator that is associated with the reference image, as discussed above with reference to .","The weighted graph  can include additional reference images  and . When the additional reference images  and  are identified and included in the weighted graph, co-selected images are identified for each of the reference images ,  and  and edges to co-selected images are weighted based on selections of the co-selected images relative to each of reference images. The additional reference images  and  can represent images that are also identified as belonging to the reference topic (e.g., pornographic images) or images that are identified as not belonging to the reference topic (e.g., not pornographic images).","The weighted graph also includes nodes - that represent co-selected images for the reference image. For example, each of the nodes - represent an image that is a co-selected image for the reference image .","Nodes representing sequentially selected images are connected by edges in the weighted graph. For example, edge  connects the node  to the node  representing sequential user selections of the reference image and the co-selected image represented by the node . Similarly, edge  represents sequential selection of the co-selected image represented by the node  subsequent to the selection of the co-selected image represented by the node .","The node from which an edge originates is referred to as the source node and the node at which the edge terminates is referred to as the destination node. Continuing with the example above, the source node for the edge  is the reference node  and the destination node is node . Similarly, node  is the source node for the edge , while node  is the destination node. Each edge in the weighted graph  is represented by an arrow that points to the destination node.","A bidirectional edge is indicative of reciprocal sequential selections of the images represented by the nodes. For example, the reference node  and node  are connected by a bidirectional edge . The bidirectional edge  is indicative of a user selection of the reference image, followed by selections of the co-selected image represented by node  and a second selection of the reference image. Alternatively, a pair of unidirectional edges can be used instead of a bi-directional edge.","Each of the edges can have a weight that is indicative of the number of sequential selections of the images represented by the source and destination nodes, respectively. For example, if the image represented by node  is selected 10 times following selection of the reference image, the edge  can have a weight corresponding to the ten selections.","The weight of an edge may be increased, for example, by a constant incremental amount in response to each identified selection or the weight may be increased based on a function of the number of selections. For example, the weight of an edge can correspond to the number of sequential selections of images represented by the source and destination nodes or the weight can be a logarithmic function or an exponential of the number of sequential selections.","Selection of a co-selected image immediately following selection of the reference image may be more indicative of an image that is relevant to the reference image than an image that is selected following selection of one or more other co-selected images. For example, node  represents a co-selected image that was selected following selections of the reference image  and the co-selected image represented by node . Therefore, the selection of the image represented by node  may be less indicative of the relevance of the image to the reference image  than the selection of the image represented by node  due to the intervening action of selecting the image represented by node .","In some implementations, the weight of each edge can be adjusted based on its proximity to the reference image. For example, edge weights can be boosted by a boost factor based on their proximity to the reference node . The boost factor can be highest, for example, for edges that connect the reference node  to nodes representing co-selected nodes , ,  and . The boost factor can be reduced for edges that are less proximate to the reference node , for example, based on a number of nodes between the edge and the reference node.","In some implementations, the weight of an edge or the amount by which an edge weight is increased in response to a selection can be based on a reference weight of the reference node for the co-selected image. The reference weights are factors that normalize or otherwise adjust the importance of an image selection following selection of the reference image. The reference weights can be based on an analysis of the label feedback for the reference images to determine the likelihood that the reference images are accurately identified as belonging to the reference topic.","For example, based on the label feedback, reference image  may be identified as a pornographic image with a probability of 0.7 (e.g., 70% of the label feedback identified reference image  as a pornographic image), while reference image  may be identified as a pornographic image with a probability of 0.6. Therefore, reference image  can be assigned a reference weight of 0.7, while reference image  can be assigned a reference weight of 0.6.","The reference weights can be used, for example, to adjust the incremental amount by which an edge weight to a co-selected image is increased. Adjusting the incremental amount by which an edge weight is increased based on the likelihood that the reference image belongs to the topic facilitates direct comparison of edge weights for co-selected images for different reference images having different likelihoods of belonging to the reference topic.","Continuing with the example above, reference image  has a higher likelihood of being a pornographic image than reference image . Therefore, selection of an image immediately following selection of reference image  is more indicative that the selected image is a pornographic image than selection of another image immediately following selection of reference image . Accordingly, a weight of an edge (e.g., ) for a co-selected image (e.g., ) for reference image  will increase more in response to a single selection than the weight of an edge (e.g., ) for a co-selected image (e.g., ) for reference image  in response to a single selection. These increases in edge weight are representative of the relative likelihood that each of these reference images  and  are accurately identified as pornographic images.","In some implementations, once a graph is constructed, each of the nodes is assigned an initial weight based on a machine process that identifies the likelihood that the image represented by the node belongs to the reference topic. The initial weights are then adjusted based on co-selection data.","As described above, the likelihood that each of the images belong to the reference topic can be determined based on analysis of the visual characteristics of the images, text associated with the image and other data indicative of the topic to which the image belongs. In these implementations, edges for which a node is a source can be weighted based on the reference weight of the node in a manner similar to that described above.",{"@attributes":{"id":"p-0098","num":"0097"},"figref":["FIG. 5","FIG. 1"],"b":["500","500","500","120"]},"A reference image is represented as a reference node in a weighted graph (). In some implementations, the reference image is an image that is identified as belonging to a reference topic. For example, the reference image can be an image that is identified as a pornographic image based on a reference label corresponding to a pornographic topic being associated with the reference image. The reference image can be identified, for example, from a data store storing images and labels corresponding to the image. Throughout the description of the process , nodes that represent images can be characterized by the same characteristics (e.g., reference labels and selection data) as the images that they represent. Therefore, nodes that represent the images and the images themselves are referred to interchangeably.","A user session, during which the reference image was selected, is identified (). In some implementations, the user session can be identified based on selection data for the reference image. For example, a selection of the reference image can be identified from selection data for the reference image. In turn, the unique session identifier that is associated with the selection data for the reference image can be used to identify other images having selection data associated with the same unique session identifier. The selection data for the reference image can be obtained, for example, from the historical data store .","Once the user session in which the reference image was selected has been identified, subsequent selections of co-selected images during the user session are identified (). As described above, the subsequent selections of co-selected images can be identified based on selection data associated with the same unique session identifier as the reference image. The selection data for a user session can include time data that specifies when selection of a co-selected image occurred relative to selection of the reference image. Therefore, the time data can be used to identify co-selected images as the images that were selected at times following selection of the reference image during a common user session.","For example, if the reference image was selected at 12:00 am on Jan. 1, 2009, then each image having selection data associated with the same unique session identifier as the reference image and having time data specifying another time that is later than 12:00 a.m., Jan. 1, 2009 is a co-selected image for the reference image.","In some implementations, only co-selected images that were selected within a threshold time period following selection of the reference image are identified as co-selected images for the reference image. The threshold time period facilitates use of selection data obtained for user sessions having a duration that is longer than the time period over which co-selected images are to be identified.","For example, selection data may have been obtained for a user session having a duration of an hour. However, in a particular application co-selection images may be defined as only those images that were selected within 10 minutes of the selection of the reference image. In this situation, the threshold time period can be used to determine whether an image selected during the one hour user session can be identified as a co-selected image for the reference image. For example, the time between selection of the image and selection of the reference image can be compared to the threshold time period. If the time between the relative selections is less than or equal to the threshold, the image is identified as a co-selected image for the reference image.","In some implementations, the selection data for a particular user session can include a list of images that were selected during the user session. The list can be ordered, for example, in the order in which the images were selected during the user session. Therefore, once selection of the reference image is identified in selection data for a user session, every image referenced after the reference image can be identified as a co-selected image.","A node representing the co-selected image is identified (). In some implementations, the node representing the co-selected image is defined in response to the first identified selection, for example, in a computer memory. In these implementations, after the node representing the co-selected image is defined in the computer memory, the node can be identified from the computer memory location at which the node is defined. For example, the node can be defined in the weighted graph in response to the initial identified selection and then identified in the weighted graph for subsequent identified selections of the co-selected image. In other implementations, each image in a corpus of images is initially represented by a node in the weighted graph, regardless of whether the image is a co-selected image.","When selections of the co-selected image are identified, the node can be identified, for example, based on a unique identifier (e.g., URL) corresponding to the co-selected image and associated with the node. For example, a unique image identifier can be generated for each co-selected image and associated with the image and its corresponding node. When a selection of the co-selected image is identified, the node that is associated with the unique identifier can be identified as representing the co-selected image. Each of the co-selected images are represented by independent nodes in the weighted graph and the nodes in a weighted graph can represent co-selected images for reference images during a single or multiple user sessions.","An edge weight is incremented for the co-selected image (). In some implementations, when the weighted graph is generated, the edge weight between each node can be initialized to zero (i.e., no edge exists between the nodes). Therefore, the first sequential selection of a co-selected image will generate an edge having a weight corresponding to one standardized unit (e.g., a weight of 1). Additional sequential selections the co-selected image will similarly increment the weight of the edge connecting the nodes by an incremental amount corresponding to the standardized unit. As described above, weight by which the edge weight is incremented can be adjusted based on a boost factor, a reference weight of a node or another factor for adjusting the relative importance of the selection for which the edge weight is being incremented.","A determination is made whether additional selections of co-selected images remain for the user session (). The additional selections can be selections immediately following selection of the reference image or selections subsequent to selections of other images. The additional selections can be identified, for example, based on the selections being associated with a unique session identifier that corresponds to the user session.","When additional selections of co-selected images remain for the user session, a node representing another co-selected image is identified (). When additional selections of co-selected images do not remain for the user session, an optional determination is made whether the reference image was selected during another user session (). Another selection of the reference image can be identified, for example, based on selection data for the reference image, as described above. When another selection of the reference image is identified, a subsequent selection of a co-selected image during the user session is identified (). When another selection of the reference image is not identified, the process  ends ().","Once a weighted graph is generated, it can be updated to represent additional selections of reference images and co-selected images for the additional reference images. The weighted graph can be updated periodically based on an update condition being satisfied. The update condition can be, for example, a specified amount of time, user actions, user sessions, or other measure since the last update.","Topic scores can be generated for co-selected images based on the edges that are connected to the nodes representing the images in the weighted graph. In some implementations, the topic score for a particular image can be a sum of edge weights that are connected to a node representing the image, as described with reference to . When the topic score for an image satisfies a threshold topic score, the image is labeled as belonging to the topic. In turn, the image can be identified as a new reference image and defined as such in the weighted graph.","In other implementations, a topic score can be iteratively generated for each of the images represented by nodes in the weighted graph until a stop condition occurs. The topic scores are iteratively generated to facilitate propagation of topic scores throughout the weighted graph, as described below.","The stop condition can occur, for example, when a change in the topic score for each of the images over one or more iterations is less than a threshold change (i.e., converges). In these implementations, the topic scores can be iteratively generated based on the likelihood that reference images and\/or other images belong to the reference topic and co-selection data for the images. The likelihood that each of the images belongs to the reference topic can be represented as a vector of topic scores. The initial topic scores can correspond, for example, to the reference weights described above.",{"@attributes":{"id":"p-0115","num":"0114"},"figref":"FIG. 6A","b":["600","600","602","600","604","602","600","702","702"],"i":["a","e"]},"The initial topic scores represent an initial likelihood that each of the images represented by the nodes identified in column  belongs to the reference topic. The topic scores can be values from 0.00 to 1.00, where an image having a topic score of 0.00 is an image that is known to not belong to the reference topic and an image having a topic score of 1.00 is an image that is known to belong to the reference topic.","In some implementations, each of the initial topic scores for images that are identified as belonging to the reference topic (i.e., reference images) can be initially set to 1.0, while the initial topic scores for other images are set to 0.0, or some other default value. Through the iterative process described below, final topic scores can be computed for each of the images that were not initially identified as belonging to the reference topic.","In other implementations, an initial topic score is specified for each of the images based on its initial likelihood of belonging to the reference topic. The initial likelihood that each of the images belong to the reference topic can be determined, for example, based on label feedback, image analysis techniques, and textual analysis techniques each of which is described above with reference to .","In some implementations, the co-selection data for images can define a co-selection matrix for images that were co-selected during one or more user sessions. For example, the co-selection data for each pair of images can be a value in an N\u00d7N co-selection matrix, where N is the number of images selected during the one or more user sessions.","The co-selection data for a pair of images can specify, for example, a sequential selection rate of the one of the images following selection of the other image or another selection metric for the pair of images (e.g. total sequential selections). The co-selection data can be directional or unidirectional. In some implementations, the co-selection data for a pair of images can correspond to the weight of an edge connecting the pair of nodes representing the images in a weighted graph.",{"@attributes":{"id":"p-0121","num":"0120"},"figref":["FIG. 6B","FIG. 2"],"b":["650","650","702","702","702","702"],"i":["a","e","a ","c"]},"The topic scores from table  and the co-selection data from the co-selection matrix  can be used to identify final topic scores for images that have been co-selected in one or more user sessions. For example, a product of the topic scores for the nodes and the co-selection matrix can be iteratively computed until the stop condition occurs.",{"@attributes":{"id":"p-0123","num":"0122"},"figref":["FIGS. 7A-7D","FIG. 1","FIGS. 7A-7D"],"b":["120","700","700"]},"Referring to , weighted graph  is generated by the image classification subsystem  including initial topic scores for the nodes -that correspond to the initial topic scores of . For example, the weighted graph  includes the initial topic scores of \u201c0.00\u201d and \u201c1.00\u201d for the nodes and , respectively. The nodes -each have initial topic scores of \u201c0.50.\u201d Similarly, the edges between each pair of nodes have weights corresponding to the co-selection data specified in the table.  of . Using these initial topic scores and co-selection data the image classification subsystem  can generate updated topic scores for each of the images that are represented by the nodes -, for example, based on a product of the initial topic scores and the co-selection data.","Referring to , the weighted graph  shows the updated topic scores for each of the nodes -after one iteration of the iterative topic score generation process. In this example, the topic scores of the nodes -are fixed at \u201c0.00\u201d and \u201c1.00\u201d respectively. The topic score of node is fixed at \u201c0.00\u201d because the image represented by node was initially identified as not belonging to the reference topic. The topic score for node is fixed at \u201c1.00\u201d because the image represented by the node was initially identified as belonging to the reference topic (i.e., a reference image for the reference topic).","The updated topic scores of the nodes -are now \u201c0.25,\u201d \u201c0.73,\u201d and \u201c0.53,\u201d respectively based, for example, on values of a vector resulting from the product of the co-selection matrix and the initial topic scores. The relatively high magnitude (\u201c0.7\u201d) of the co-selection data for the nodes and as compared to other nodes contributes to the updated topic score (\u201c0.25\u201d) of node being closer to the topic score of the node (\u201c0.00\u201d) than the initial topic score (\u201c0.5\u201d) for node . Similarly, the relatively high value (\u201c0.7\u201d) of the co-selection data for the nodes and as compared to other nodes gives the node a topic score (\u201c0.73\u201d) that is closer to the topic score of the node (\u201c1.00\u201d) than the topic scores of other nodes. The value (\u201c0.5\u201d) of the co-selection data for node and each of the nodes and is slightly higher than the value (\u201c0.4\u201d) of the co-selection data for node and each of the nodes and . Therefore, the updated topic score for node increases slightly towards the topic scores of nodes and ","In some implementations, the image classification subsystem  replaces the initial topic scores for the nodes -with the updated topic scores of . For example, the updated topic scores can be used to overwrite the initial topic score values that were stored in the table  of . The updated topic scores and the co-selection data are then used to generate additional updated topic scores for the nodes, for example, by computing a product of the updated topic scores and the co-selection data.","Referring to , the weighted graph  shows the updated topic score for the nodes -after two iterations of the iterative topic score generation process by the image classification subsystem . The updated topic score of the node has increased by \u201c0.01\u201d to \u201c0.26.\u201d The updated topic score of the node has increased by \u201c0.01\u201d to \u201c0.74.\u201d The updated topic score of the node has increased by \u201c0.01\u201d to \u201c0.54.\u201d In some implementations, the image classification subsystem  stops the iterative topic score generation when the change in each updated topic score between subsequent iterations is below a particular threshold, such as \u201c0.01.\u201d","Referring to , the weighted graph  shows the updated topic scores for the nodes -after four iterations of the iterative topic score generation process by the image classification subsystem . The updated topic score of the node has increased by \u201c0.01\u201d to \u201c0.75.\u201d The updated topic score of the nodes -have each converged within \u201c0.01\u201d following the fourth iteration. Therefore, the image classification subsystem  stops the iterative topic score generation process and outputs the topic scores for the images represented by the nodes -","Alternatively, the image classification subsystem can stop the iterative process after a threshold number of iterations. The threshold number of iterations can be a function, for example, of a number of nodes between two particular nodes in the weighted graph.",{"@attributes":{"id":"p-0131","num":"0130"},"figref":["FIG. 8","FIG. 1"],"b":["800","800","120"]},"Initial topic scores are obtained for a group of images (). In some implementations, the group of images include images that were co-selected during one or more user sessions. The initial topic score for each image is a value specifying of a likelihood that the image belongs to a reference topic. The initial topic scores can be obtained, for example, based on analysis of the images, text associated with the images and\/or label feedback data for the images, as described with reference to .","The initial topic scores can be specified for each of the images or a subset of the images. When initial topic scores are specified for each of the images, the values can be between \u201c0.00\u201d and \u201c1.00,\u201d where a value of \u201c0.00\u201d is indicative of an image that is known to not belong to the reference topic and a value of \u201c1.00\u201d is indicative of an image that is known to belong to the reference topic.","When initial topic scores are specified for a subset of the images, the subset of images can include only those images that are known to belong to the reference topic. For example, each of the images that is known to belong to the reference topic (i.e., a reference image for the reference topic), can have an initial topic value of \u201c1.00\u201d while every other image has an initial topic value of \u201c0.00.\u201d The initial topic scores can be used to define a vector of topic scores, where each initial topic score is a component of the vector.","Co-selection data for the group of images is obtained (). In some implementations, the co-selection data specifies a relative selection rate for each pair of images in the group of images. For example, if a particular image is selected eight times out of every 10 selections of another image, the relative selection rate for the particular image relative to the other image can be specified as \u201c0.8.\u201d The co-selection data can be obtained, for example, based on selection data for user session, as described with reference to . The co-selection data can be used to define a co-selection matrix, as described above with reference to .","Updated topic scores are computed for the group of images (). In some implementations, the topic score for each image is a result of a function of the topic scores and the co-selection data. For example, a product of a topic score vector and a co-selection matrix can be computed to generate a topic score vector that specifies updated topic scores for each of the images.","A determination is made whether a stop condition has occurred (). In some implementations, the stop condition occurs when changes to each of the updated topic scores is below a threshold change (i.e., the topic scores converge). The changes to the updated topic scores can be relative to the topic scores in one or more previous iterations. For example, the absolute change to each topic score over one iteration or a windowed average change over multiple iterations. In other implementations, the stop condition can be the completion of a threshold number of iterations, as described above.","When the stop condition has occurred, the group of images are classified based on the updated topic scores (). In some implementations, the images having at least a threshold topic score are classified as belonging to the reference topic. In other implementations, a threshold number of images having topic scores that are among a highest portion of topic scores are classified as belonging to the reference topic. The highest portion of topic scores can be, for example, an integer number of highest topic scores or a highest percentage of topic scores.","Images that are classified as belonging to the reference topic are associated with a label corresponding to the reference topic (). In some implementations, the label is textual data corresponding to the reference topic. For example, images that are identified as pornographic images can be associated with the text \u201cexplicit\u201d or \u201cpornographic.\u201d In other implementations, images that are identified as belonging to the reference topic can have a data flag set to a binary value indicating that the image belongs to the topic.","Several example values for nodes have been described above. For example, nodes representing images that belong to the reference topic can be assigned a value of \u201c1.0,\u201d while nodes representing images that do not belong to the reference class can be assigned an initial value of \u201c0.0.\u201d Additionally, nodes can be assigned a value that corresponds to the likelihood that the image represented by the node belongs to the reference topic. While these values have been provided for purposes of example, other values can be assigned to nodes that represent images. For example, nodes that represent images belonging to the reference topic can be assigned a value of \u201c1.0,\u201d while images that do not belong to the reference topic can be assigned a value of \u201c\u22121.0.\u201d Similarly, alternative values can be assigned to nodes representing a likelihood that the image belongs to the reference topic. The description above is equally applicable for any manner in which values are assigned to nodes.","Embodiments of the invention and all of the functional operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the invention can be implemented as one or more computer program products, i.e., one or more modules of computer program instructions encoded on a computer-readable medium for execution by, or to control the operation of, data processing apparatus. The computer-readable medium can be a machine-readable storage device, a machine-readable storage substrate, a memory device, a composition of matter effecting a machine-readable propagated signal, or a combination of one or more of them. The term \u201cdata processing apparatus\u201d encompasses all apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them. A propagated signal is an artificially generated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus.","A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.","The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).","Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio player, a Global Positioning System (GPS) receiver, to name just a few. Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.","To provide for interaction with a user, embodiments of the invention can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.","Embodiments of the invention can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the invention, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (\u201cLAN\u201d) and a wide area network (\u201cWAN\u201d), e.g., the Internet.","The computing, system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.","While this specification contains many specifics, these should not be construed as limitations on the scope of the invention or of what may be claimed, but rather as descriptions of features specific to particular embodiments of the invention. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.","Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.","Thus, particular embodiments of the invention have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6B"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIGS. 7A-7D"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
