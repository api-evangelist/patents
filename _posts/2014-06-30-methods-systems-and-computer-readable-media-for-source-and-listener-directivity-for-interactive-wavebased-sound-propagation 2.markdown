---
title: Methods, systems, and computer readable media for source and listener directivity for interactive wave-based sound propagation
abstract: Methods, systems, and computer readable media for supporting source or listener directivity in a wave-based sound propagation model are disclosed. According to one method, the method includes computing, prior to run-time, one or more sound fields associated with a source or listener position and modeling, at run-time and using the one or more sound fields and a wave-based sound propagation model, source or listener directivity in an environment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09560439&OS=09560439&RS=09560439
owner: The University of North Carolina at Chapel Hills
number: 09560439
owner_city: Chapel Hill
owner_country: US
publication_date: 20140630
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["PRIORITY CLAIM","GOVERNMENT INTEREST","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","REFERENCES"],"p":["This application claims the benefit of U.S. Provisional Patent Application Ser. No. 61\/841,910, filed Jul. 1, 2013; the disclosure of which is incorporated herein by reference in its entirety.","This invention was made with government support under Grant Nos. IIS-0917040, CMMI-1000579, and 0904990 awarded by the National Science Foundation and W911NF-10-1-0506 awarded by the Army Research Office. The government has certain rights in the invention.","The subject matter described herein relates to sound propagation. More specifically, the subject matter relates to methods, systems, and computer readable media for supporting source or listener directivity in a wave-based sound propagation model.","Sound propagation techniques determine how sound waves travel in a space and interact with the environment. In many applications, it is important to be able to simulate sound propagation in large scenes, such as games and training in both indoor and outdoor scenes, noise prediction in urban areas, and architectural acoustics design for buildings and interior spaces such as concert halls. Realistic acoustic effects can also improve the realism of a virtual environment. Acoustic phenomena such as interference, diffraction, and scattering for general scenes can only be captured by accurately solving the acoustic wave equation. The large spatial and frequency domain and accuracy requirement pose a significant challenge for acoustic techniques to be used in these diverse domains with different requirements.","Sound sources can be omnidirectional (e.g., radiating sound isotropically) or directional (e.g., radiating sound anisotropically). Most sound sources we come across in real life (e.g., ranging from human voices through speaker systems in televisions, radio, smartphones, machine noises in cars, aircrafts, helicopters, and musical instruments) are directional sources that have a specific directivity pattern. This directivity depends on the shape, size, and material properties of the sound source, as well as a complex interaction of the processes of vibration and sound radiation, resulting in varying directivity at different frequencies. Due to the non-uniform radiation of sound, directional sources have a significant impact on sound propagation and the corresponding acoustic response of the environments. Acoustic effects generated from directional sources are noticeable in everyday life: a person talking towards\/away from a listener, positioning of different types of musical instruments in an orchestra, good-sounding places (sweet spots) in front of television in the living room, aircraft, helicopter, or fire trucks in an urban environment.","Analogous to source directivities, listeners also have directivities. In other words, listeners do not receive sound in the same way from all directions. The human auditory system obtains significant directional cues from the subtle differences in sound received by each ear which are caused by the scattering of sound around the head. Listener directivity can be used to enhance a user's immersion in a virtual environment by providing the listener with cues corresponding to the directions the sound is coming from, and thereby enriching the experience.","Various techniques may be used in predicting or modeling sound propagation. Some techniques may involve assuming sound travels like rays (e.g., beams of lights). Other techniques may involve assuming sound travels like waves. However, current techniques are unable to efficiently support source or listener directivity in an interactive wave-based sound propagation model.","Accordingly, there exists a need for methods, systems, and computer readable media for supporting source or listener directivity in an interactive wave-based sound propagation model.","Methods, systems, and computer readable media for supporting source or listener directivity in a wave-based sound propagation model are disclosed. According to one method, the method includes computing, prior to run-time, one or more sound fields associated with a source or listener position and modeling, at run-time and using the one or more sound fields and a wave-based sound propagation model, source or listener directivity in an environment.","A system for supporting source or listener directivity in a wave-based sound propagation model is also disclosed. The system includes a processor and a sound propagation model (SPM) module executable by the processor. The SPM module is configured to compute, prior to run-time, one or more sound fields associated with a source or listener position and to model, at run-time and using the one or more sound fields and a wave-based sound propagation model, source or listener directivity in an environment.","The subject matter described herein can be implemented in software in combination with hardware and\/or firmware. For example, the subject matter described herein can be implemented in software executed by a processor. In one exemplary implementation, the subject matter described herein may be implemented using a computer readable medium having stored thereon computer executable instructions that when executed by the processor of a computer control the computer to perform steps. Exemplary computer readable media suitable for implementing the subject matter described herein include non-transitory devices, such as disk memory devices, chip memory devices, programmable logic devices, and application specific integrated circuits. In addition, a computer readable medium that implements the subject matter described herein may be located on a single device or computing platform or may be distributed across multiple devices or computing platforms.","As used herein, the terms \u201cnode\u201d and \u201chost\u201d refer to a physical computing platform or device including one or more processors and memory.","As used herein, the term \u201cmodule\u201d refers to hardware, firmware, or software in combination with hardware and\/or firmware for implementing features described herein.","The subject matter described herein discloses methods, systems, and computer readable media for supporting source or listener directivity in a wave-based sound propagation model. In accordance with some aspects of the present subject matter described herein, exemplary mechanisms, processes, or systems may be provided or supported for modeling time-varying, data-driven, or arbitrary source directivity and head-related transfer function (HRTF)-based listener directivity for interactive wave-based sound propagation in frequency domain. For example, a sound propagation modeling or simulation application in accordance with some aspects of the present subject matter described herein may support time-varying, data-driven source directivity based on spherical harmonic (SH) basis, where the source directivity can be dynamically modified at run-time. In some embodiments, the propagated sound fields due to SH sources may be precomputed, stored, and used to compute the total sound field at run-time.","In accordance with some aspects of the present subject matter described herein, an exemplary sound propagation modeling or simulation application may support a plane-wave decomposition based on pressure derivatives for modeling HRTF-based listener directivity to generate spatial sound in interactive applications, where the plane-wave decomposition may be performed in real-time compared to prior plane-wave decomposition methods which are offline.","In accordance with some aspects of the present subject matter described herein, an exemplary sound propagation modeling or simulation application may accurately simulate sound fields that include wave-phenomena such as scattering and diffraction and can also produce spatial sound cues that provide localization and immersion for interactive applications.","In accordance with some aspects of the present subject matter described herein, a general framework may be provided for integrating source and\/or listener directivities in any offline or online frequency domain wave-based propagation algorithm (e.g., a boundary element method or an interactive equivalent sources method).","In accordance with some aspects of the present subject matter described herein, a real-time and\/or memory efficient sound rendering system may use aspects described herein to provide realistic acoustic effects from directional sources and spatial sound in interactive applications.","Reference will now be made in detail to exemplary embodiments of the subject matter described herein, examples of which are illustrated in the accompanying drawing. Wherever possible, the same reference numbers will be used throughout the drawings to refer to the same or like parts.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 1","b":["102","102","102"]},"Node  may include a communications interface , a shared memory , and one or more processor cores . Communications interface  may be any suitable entity (e.g., a communications interface and\/or a data acquisition and generation (DAG) card) for receiving and\/or sending messages. For example, communications interface  may be interface between various nodes  in a computing cluster. In another example, communications interface  may be associated with a user interface or other entity and may receive configuration setting and\/or source data, such as audio information, for processing during a sound propagation model application.","In some embodiments, communications interface  or another component may be configured to identify or select a processor core  for processing or analysis and\/or information for storage. For example, communications interface  may receive information from another node in a cluster and may determine that a particular processor core  should process the received information. In another example, communications interface  may store information in shared memory  and the stored information may be retrieved later by an available processor core . Shared memory  may be any suitable entity (e.g., random access memory or flash memory) for storing sound propagation information, such as sound field data, pressure derivatives, plane-wave decomposition information, SH information, source audio information, and\/or other information. Various components, such as communications interface  and software executing on processor cores , may access (e.g., read from and\/or write to) shared memory .","Each of processor cores  represents any suitable entity (e.g., a physical processor, a field-programmable gateway array (FPGA), and\/or an application-specific integrated circuit (ASIC)) for performing one or more functions associated with sound propagation modeling. Processor cores  may be associated with a sound propagation model (SPM) module . For example, SPM module  or software therein may be executable by one or more processor cores .","SPM module  may be configured to use one or more techniques (e.g., geometric acoustic techniques and\/or numerical acoustic techniques) for modeling sound propagation in one or more environments. Existing techniques for modeling sound propagation can be broadly classified into geometric and wave-based techniques. Geometric techniques can handle arbitrary source and listener directivity for offline and interactive applications. However, due to their inherent assumption of rectilinear propagation of sound, modeling wave effects like diffraction and interference, using geometric techniques remains a significant challenge, especially at low frequencies. This becomes a limiting factor for simulating sources that have prominent directivity patterns at low frequencies (e.g. human voices).","In contrast with geometric techniques, wave-based techniques can accurately perform sound propagation at low frequencies, but their computational complexity increases significantly for high frequencies. There has been considerable interest in recent years in developing interactive wave-based sound propagation techniques for computer graphics. Current techniques for interactive applications have a high precomputation overhead and can only model source directivity during the offline computation. As a result, the source directivity is hard-coded into the final solution, and it is not possible to modify the directivity pattern at run-time for interactive applications (e.g., for a rotating siren, a person covering his\/her mouth, etc.). Additionally, integrating listener directivity into wave-based techniques requires a plane-wave decomposition of the sound field, which is computationally expensive for interactive applications.","In some embodiments, SPM module  may be configured to support source and\/or listener directivity for interactive wave-based sound propagation modeling. For example, SPM module  may be configured to model, using precomputed sound fields, sound propagation where a sound source's directivity can be dynamically modified during run-time, e.g., a moving ambulance with siren controlled by a user during a video game. In another example, SPM module  may be configured to model, using precomputed sound fields and related derivative values, sound propagation where a listener's directivity can be dynamically modified during run-time, e.g., a character controlled by a user moving through a virtual environment.","In some embodiments, SPM module  may be configured to precompute (e.g., prior to run-time or executing of a sound propagation model application) and store propagated sound fields or pressure fields due to spherical harmonic (SH) sources. Using these precomputed sound fields, SPM module  may compute a total sound field using a wave-based sound propagation technique at run-time, thereby allowing modeling of a source with a directivity that can be dynamically modified at run-time.","In some embodiments, a pressure field of an entire domain may be expressed to any order of accuracy by using pressure and its higher order derivatives at a single point.","In some embodiments, plane wave decomposition of a pressure field may be computed to any order of accuracy using pressure derivatives and SH decomposition. Computing plane wave decomposition of a pressure field using pressure derivatives and SH decomposition may be significantly faster and more memory efficient than conventional methods thereby allowing computation of spatial sound at run-time.","In some embodiments, SPM module  may be configured to compute listener directivity for any frequency-domain, wave-based sound propagation technique. For example, an exemplary method for computing listener directivity may include computing a plane-wave decomposition of the sound field around the listener, expressing plane-wave coefficients associated with the plane-wave decomposition in terms of an SH basis, and using pressure and its derivatives at a listener position to compute corresponding SH coefficients. The HRTF may also be expressed in the SH basis. At run-time, spatial sound may be computed as a dot product between the SH coefficients of the sound field and the HRTF. By computing a plane-wave decomposition using pressure and pressure derivatives, spatial sound may be modeled or simulated in real-time. In contrast, current plane-wave decomposition methods are performed offline.","In some embodiments, SPM module  may be configured to work in parallel with a plurality of processor cores  and\/or nodes . For example, a plurality of processor cores  may each be associated with a SPM module . In this example, each processor core  may perform processing associated with modeling sound propagation for a particular environment. In another example, some nodes  and\/or processing cores  may be utilized for precomputing (e.g., computing pressure or sounds fields due to SH sources) and other nodes  and\/or processing cores  may be utilized during run-time, e.g., to execute a sound propagation model application that utilizes precomputed values or functions.","In some embodiments, SPM module  may be configured to perform sound propagation modeling using any wave-based sound propagation technique, such as any technique that numerically solve or attempt to solve the acoustic wave equation. Exemplary wave-based sound propagation techniques usable by SPM module  may include a finite element method, a boundary element method, an equivalent source method, various spectral methods, or another frequency-domain wave-based technique.","It will be appreciated that  is for illustrative purposes and that various nodes, their locations, and\/or their functions may be changed, altered, added, or removed. For example, some nodes and\/or functions may be combined into a single entity. In a second example, a node and\/or function may be located at or implemented by two or more nodes.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 2","FIG. 2"],"b":["200","202"]},"At step , these pressure fields are encoded in basis functions (e.g. multipoles) and stored for runtime use.","At runtime, given a dynamic source directivity, a SH decomposition of its directivity is performed to compute the corresponding SH coefficients.","At step , the final pressure field is computed as a summation of the pressure fields due to SH sources evaluated at the listener position weighted by the appropriate SH coefficients.","At step , in order to incorporate dynamic listener directivity in wave-based techniques, an interactive plane-wave decomposition approach based on derivatives of the pressure field is utilized.","At step , acoustic responses for both ears are computed at runtime by using this efficient plane-wave decomposition of the pressure field and the HRTF-based listener directivity. In some embodiments, these binaural acoustic responses are convolved with the (dry) audio to compute the propagated spatial sound at the listener position.","In some embodiments, exemplary process  may be incorporated into the state-of-the-art boundary element method [Liu 2009] and the interactive equivalent source technique [Mehra et al. 2013]. In such embodiments, existing implementations of the state-of-the-art boundary element method and the interactive equivalent source technique may be computationally efficient up to a few kHz.","In some embodiments, exemplary process  or a runtime portion therein may be integrated with Valve's Source\u2122 game engine. Using this game engine, acoustic effects from both source and listener directivity on a variety of scenarios are demonstrable, such as people talking on the street, loudspeakers between buildings, a television in a living room, a helicopter in a rocky outdoor terrain, a bell tower in a snow-covered town, a rotating siren, a helicopter behind obstacles, and musical instruments in an amphitheater.","In some embodiments, results associated with exemplary process  may be validated by comparing these results to results computed analytically using the offline Biot-Tostoy-Medwin (BTM) technique [Svensson et al. 1999].","In some embodiments, exemplary process  enables accurate sound propagation for directional sources and can handle moving directional sources and a moving directional listener.","In contrast to conventional or known approaches, exemplary process  and\/or other aspects described herein include an approach that allows modifiable source directivity and HRTF-based listener directivity at runtime for interactive wave-based sound propagation.",{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 3","b":["300","300","300"]},"3 Source Directivity","In this section, aspects related to handling directional sources in a general frequency-domain wave-based sound propagation technique are presented as an overview. In one exemplary embodiment, a source formulation is presented that incorporates the complete radial and directional sound radiation from sources. Next, a far-field representation of this source formulation is discussed that can be used to efficiently handle data-driven, and rotating or time-varying source directivities. Based on the linearity of the Helmholtz equation, aspects of the present subject matter are provided that incorporates an exemplary source representation as described herein into a general frequency-domain wave-based propagation technique. In some embodiments, all the variables used in an exemplary approach, except the SH basis functions, positions and speed of sound are frequency dependent. For the sake of brevity these dependencies are not mentioned explicitly.","3.1 Source Formulation","The radiation pattern of a directional source can be expressed using the one-point multipole expansion [Ochmann 1995] as:",{"@attributes":{"id":"p-0058","num":"0057"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"s","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":[{"mi":"l","mo":"=","mn":"0"},{"mi":"L","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mrow":{"mo":"-","mi":"l"}},"mi":"l"},"mo":"\u2062","mrow":{"msub":{"mi":"b","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":["\u2062","\u2062"],"mrow":[{"msubsup":{"mi":["h","l"],"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":"\u03c0","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":["vr","c"],"mo":"\/"}}}},{"msub":{"mi":"Y","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["\u03b8","\u03d5"],"mo":","}}}]}}}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}},"br":[{},{}],"sub":["2","lm","lm"],"sup":["l","1"],"b":"1955"},"The selection of source representation for directional sources may be motivated by the measured directivity data that is currently available for real-world sources. Most available measurements has been collected by placing sources in an anechoic chamber and recording their directivity by rotating microphones every few degrees at a fixed distance from the source. Typically, these measurements are carried out at a distance of a few meters, which corresponds to the far-field for the frequencies emitted by these sources2. Keeping this in mind, a source representation that corresponds to the far-field radiation pattern of a directional source is selected. Under far-field approximation, h(z)\u2248le\/z where i=\u221a{square root over (\u22121)} resulting in the following source representation [Menzies 2007]:",{"@attributes":{"id":"p-0060","num":"0059"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"s","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mfrac":{"msup":{"mi":"\u2147","mrow":{"mrow":[{"mo":"-","mi":"\u21482\u03c0"},{"mi":["vr","c"],"mo":"\/"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mi":"r"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"l","mo":"=","mn":"0"},{"mi":"L","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mrow":{"mo":"-","mi":"l"}},"mi":"l"},"mo":"\u2062","mrow":{"msub":{"mi":"a","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2062","mrow":{"msub":{"mi":"Y","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["\u03b8","\u03d5"],"mo":","}}}}}}}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"2"}}]},{"mtd":[{"mrow":{"mrow":{"mrow":{"mo":"=","mrow":{"mfrac":{"msup":{"mi":"\u2147","mrow":{"mrow":[{"mo":"-","mi":"\u2148"},{"mi":["vr","c"],"mo":"\/"}],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mn":"2","mi":"\u03c0"}},"mi":"r"},"mo":"\u2062","mrow":{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["\u03b8","\u03d5"],"mo":"\/"}}}}},"mo":","},"mo":"\u2062","mstyle":{"mspace":{"@attributes":{"width":"3.9em","height":"3.9ex"}}}}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}]}}},"br":{},"sub":["lm","lm","lm","lm"],"sup":"l+1"},"The coefficients \u03b1of the source representation is computed from the D(\u03b8, \u03c6) as follows:","Analytical: Given an analytical expression for the directivity function D(\u03b8, \u03c6), the coefficients \u03b1can be computed by SH projection as follows:\n\n\u03b1=\u222b\u222b(\u03b8,\u03c6)(\u03b8,\u03c6)sin \u03b8\u2003\u2003(4)\n","This expression can be evaluated either symbolically or numerically, depending on D(\u03b8, \u03c6) [Green 2003].","Data-driven: Given the directivity function D(\u03b8, \u03c6) at sampled locations {(\u03b8,\u03c6)(\u03b8, \u03c6), . . . , (\u03b8, . . . , \u03c6)}, the spherical harmonic expansion can be fitted to this function in the least-square sense, by solving an over-determined linear system (n>L) to compute the coefficients a",{"@attributes":{"id":"p-0064","num":"0063"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":"Y","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["\u03b8","k"]},{"mi":["\u03d5","k"]}],"mo":","}}},"mo":"\u2062","msub":{"mi":"a","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}},{"mrow":{"mrow":{"mrow":{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["\u03b8","k"]},{"mi":["\u03d5","k"]}],"mo":","}}},"mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mi":"for"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mi":"k"},"mo":"=","mn":"1"}],"mo":"="},{"mi":"n","mo":";"}],"mo":[",","\u2062",","],"mi":"\u2026","mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}}}}},"An exemplary source formulation described herein and the corresponding spherical harmonic representation can handle both complex-valued and real-valued directivities. In case the directivity function is real-valued (as the widely available measured data is magnitude only), the real-valued SH basis [Green 2003] is used in the aforementioned expressions.","3.3 Frequency-Domain Sound Propagation","In this section, aspects related to an exemplary approach for incorporating the directional source representation in a general frequency domain, wave-based sound propagation technique are disclosed. The steps outlined below are repeated for frequency samples in the range [0; v], where vis the maximum frequency simulated.","Helmholtz equation: Sound wave propagation in the frequency-domain can be expressed as a boundary value problem using the Helmholtz equation:",{"@attributes":{"id":"p-0067","num":"0066"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"mrow":[{"msup":{"mo":"\u2207","mn":"2"},"mo":"\u2062","mi":"p"},{"mfrac":{"msup":[{"mi":"\u03c9","mn":"2"},{"mi":"c","mn":"2"}]},"mo":"\u2062","mi":"p"}],"mo":"+"},{"mn":"0","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":["in","\u03a9"]}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}}}},"br":[{},{}],"sup":["2 ","\u2212l2\u03c0\u03bdr\/c"],"sub":["lm","lm ","lm ","lm","lm","lm"]},{"@attributes":{"id":"p-0068","num":"0067"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"munder":[{"mrow":{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"msub":{"mi":"a","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2062","mrow":{"msub":{"mi":"s","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}}},"munder":{"mi":"\ufe38","mrow":{"mi":"s","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}},{"mrow":{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"msub":[{"mi":"a","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mi":"p","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":["\u2062","\u2062"],"mrow":{"mo":["(",")"],"mi":"x"}}}},"munder":{"mi":"\ufe38","mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}}}],"mo":"\u27f6"},"mo":"."}}}},"The pressure fields for elementary sources can be computed using any underlying numerical solver. In the case of interactive applications, this computation is performed during the preprocessing stage, and the resulting pressure field data is efficiently encoded and stored. This pressure field data completely defines the acoustic response to any directional source at the given position up to the SH approximation order. At runtime, the specified source directivity D(\u03b8,\u03c6) is decomposed into a spherical harmonic-based representation, using Equations (4) or (5), and the resulting weights aare used to compute the final acoustic response p(x) at listener position x, as described above.","Time-varying and rotating directivity: For a source with time-varying directivity, the spherical harmonic decomposition (5) of the source directivity function D(\u03b8, \u03c6) is computed at runtime at interactive rates using fast linear solvers as discussed in detail in Section 6. For the special case of a rotating directional source, the new SH coefficients after rotation can be computed by applying the SH rotation matrix to the original SH coefficients [Green 2003]. Section 6 describes an exemplary method for handling directivity for dynamic sources in further detail.",{"@attributes":{"id":"p-0071","num":"0070"},"figref":["FIG. 4","FIG. 4"],"b":"400"},"4 Listener Directivity","Aspects related to a fast and efficient method of computing listener directivity for any frequency-domain, wave-based sound propagation technique is disclosed herein. In one exemplary embodiment, the plane-wave decomposition of the sound field is computed around the listener, the plane-wave coefficients is expressed in terms of a SH basis, and the pressure and its derivatives at the listener position is used to compute the SH coefficients. The head-related transfer function (HRTF) is also expressed in the SH basis. At runtime, spatial sound can be computed as a dot product between the SH coefficients of the sound field and the HRTF.","4.1 Sound Field Decomposition Using Derivatives","In the frequency domain, the global sound field can be expressed as a superposition of pressure due to plane waves [Duraiswami et al. 2005]. This basis is also known as the Herglotz wave basis, with the basis functions centered at listener position x:\n\n\u03c8()=,\u2003\u2003(7)\n\nwhere s=(s; s; s) is the unit vector in the direction of plane wave propagation, k=2\u03c0v\/c is the wave number, v is the frequency, and c is the speed of sound. In terms of these basis functions, the total pressure at x can be determined by integrating over all directions:\n",{"@attributes":{"id":"p-0074","num":"0073"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mfrac":{"mn":"1","mrow":{"mn":"4","mo":"\u2062","mi":"\u03c0"}},"mo":"\u2062","mrow":{"msub":{"mo":"\u222b","mi":"S"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["\u03c8","s"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mi":"\u03bc","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"s"}},{"mo":"\u2146","mi":"s"}],"mo":["\u2062","\u2062"]}}}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"8"}}]}}}},"br":{}},{"@attributes":{"id":"p-0075","num":"0074"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mfrac":{"mn":"1","mrow":{"mn":"4","mo":"\u2062","mi":"\u03c0"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"msub":{"mi":"\u03b1","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2062","mrow":{"msub":{"mo":"\u222b","mi":"S"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["\u03c8","s"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"msubsup":{"mi":"Y","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"*"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"s"}},{"mo":"\u2146","mi":"s"}],"mo":["\u2062","\u2062"]}}}}}}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}}}},"br":[{},{}],"sub":["lm","lm","lm ","0","s","0"],"sup":["th ","th "]},{"@attributes":{"id":"p-0076","num":"0075"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"msub":{"mi":["Y","nq"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"s"}},{"mi":"A","mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mo":["(",")"],"mrow":{"mi":["a","b","c"],"mo":[",",","]}}},"mo":"\u2062","mrow":{"msub":{"mi":"\u0393","mrow":{"mi":["a","b","c"],"mo":[",",","]}},"mo":["\u2062","\u2062","\u2062"],"msubsup":[{"mi":["s","x","a"]},{"mi":["s","y","b"]},{"mi":["s","z","c"]}]}}}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"10"}}]}}}},"br":{}},{"@attributes":{"id":"p-0077","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["\u03b1","nq"]},"mo":"=","mrow":{"mi":"A","mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mo":["(",")"],"mrow":{"mi":["a","b","c"],"mo":[",",","]}}},"mo":"\u2062","mrow":{"msub":{"mi":"\u0393","mrow":{"mi":["a","b","c"],"mo":[",",","]}},"mo":["\u2062","\u2062"],"mfrac":{"mrow":{"mn":"4","mo":"\u2062","mi":"\u03c0"},"msup":{"mrow":[{"mo":["(",")"],"mi":"ik"},{"mi":["a","b","c"],"mo":["+","+"]}]}},"mrow":{"msup":{"mi":"p","mrow":{"mo":["(",")"],"mrow":{"mi":["a","b","c"],"mo":[",",","]}}},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"x","mn":"0"}}}}}}},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"11"}}]}}}},"br":{}},{"@attributes":{"id":"p-0078","num":"0077"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msup":{"mi":"p","mrow":{"mo":["(",")"],"mrow":{"mi":["a","b","c"],"mo":[",",","]}}},"mo":"=","mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2202","mrow":{"mi":["a","b","c"],"mo":["+","+"]}},"mo":"\u2062","mi":"p"},{"mrow":[{"mo":"\u2202","msup":{"mi":["x","a"]}},{"mo":"\u2202","msup":{"mi":["y","b"]}},{"mo":"\u2202","msup":{"mi":["z","c"]}}],"mo":["\u2062","\u2062"]}]},"mo":"."}}}},"br":{},"sub":"0"},"See Appendix A in supplementary text for proof, and Section 5 for details on calculating the derivatives p. The above result is used in Section 4.2 to compute the spatial sound at both ears as a dot product of SH coefficients of plane-wave decomposition of the sound field and HRTFs.","4.2 Sound Rendering Using HRTFs","The HRTF relates the pressure received at each ear of the listener to the pressure at a point positioned at the center of the listener's head, and accounts for scattering from the head. a SH decomposition of the left and right ear HRTFs are performed, H(s)=\u03a3\u03a3\u03b2Y(s) and H(s)=\u03a3\u03a3\u03b2Y(s). Similar to Rafaely et al. [2010], the pressure received at left and right ear (pand p) can be expressed as a dot product of the SH coefficients of the sound field and the HRTFs (see Appendix B in supplementary text for details).",{"@attributes":{"id":"p-0081","num":"0080"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["p","L"]},"mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"mn":"4","mo":"\u2062","mi":"\u03c0"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"msubsup":{"mi":["\u03b2","L"],"mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2062","msub":{"mi":"\u03b1","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}}}},{"msub":{"mi":["p","R"]},"mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"mn":"4","mo":"\u2062","mi":"\u03c0"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"msubsup":{"mi":["\u03b2","R"],"mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2062","mrow":{"msub":{"mi":"\u03b1","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"."}}}}}}],"mo":","}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}},"br":{}},"As shown in Section 5, pressure derivatives (equation 11) may be computed by differentiating the pressure basis functions analytically rather than using a finite difference stencil. Therefore, higher-order derivatives do not suffer from numerical instabilities, allowing the SH coefficients of the sound field to be computed to any desired order. Rafaely et al [2010] conducted a study on the effect of SH order on spatial perception. The results indicate that: a SH order of 1-2 is sufficient for spatial perception of frequencies up to 1 kHz; a SH order of 3 suffices up to 2 kHz; and a SH order of 3-6 suffices up to 8 kHz. Higher SH order results in better spatial resolution, but computing the higher-order derivatives also increases the computational cost. Therefore, the SH order may be determined based on a performance-accuracy trade-off.","4.4 Interactive Applications","Some aspects of the present subject matter allow spatial audio to be computed efficiently using two dot products (left and right ear) of complex-valued vectors. This enables the use of HRTF-based listener directivity for interactive wave-based sound propagation techniques as compared to previous approaches which are offline. Some aspects of the present subject matter also provide the flexibility of using individualized (user-specific) HRTFs without recomputing the simulation results. In one exemplary approach, only the SH coefficients of the individualized HRTFs need to be updated; the SH coefficients of the sound field remain the same. Additionally, some aspects of the present subject matter enable head-tracking for a moving and rotating listener at interactive rates by simplifying the head rotation computation using SH rotation matrices.",{"@attributes":{"id":"p-0084","num":"0083"},"figref":["FIG. 5","FIG. 5","FIG. 5"],"b":["500","502","500","502","500","502","500","502"]},"5 Wave-Based Sound Propagation","In this section, aspects associated with integration of an exemplary source and listener directivity representation described herein with frequency-domain wave-based sound propagation techniques are disclosed. In order to demonstrate that an exemplary directivity representation described herein can be incorporated in any frequency-domain wave-based technique, the exemplary directivity representation has been integrated with the state-of-the-art boundary element method [Liu 2009] and the interactive equivalent source method [Mehra et al. 2013].","5.1 Boundary Element Method (BEM)","The boundary element method is a standard numerical technique used for solving the 3D Helmholtz equation for accurate sound propagation in indoor and outdoor spaces. BEM transforms the Helmholtz equation into boundary integral equations and solves for pressure and velocity on the boundary, and thereby pressure at any point in the domain.","Simulation: Given an indoor or outdoor scene with source position y, the Helmholtz equation corresponding to the elementary spherical harmonic source s(x,y) is solved using BEM. This gives pressure q(z) and velocity v(z) on the domain boundary (z is a point on the boundary). This step is repeated for all the elementary sources",{"@attributes":{"id":"p-0088","num":"0087"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":"s","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mfrac":{"msup":{"mi":"\u2147","mrow":{"mrow":[{"mo":"-","mi":"\u21482\u03c0"},{"mi":["vr","c"],"mo":"\/"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mi":"r"},"mo":"\u2062","msub":{"mi":"Y","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":"="}}},"br":[{},{},{},{}],"sub":["lm","lm","S","lm","lm","lm"],"in-line-formulae":[{},{}],"i":["p","x","[G","x,z","q","z","F","x,z","z","dS","z","s","x,y"]},{"@attributes":{"id":"p-0089","num":"0088"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","z","\u03c9"],"mo":[",",","]}}},{"mfrac":{"mn":"1","mrow":{"mn":"4","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","d"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2062","msup":{"mi":"\u2147","mrow":{"mi":"\u2148","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":["wd","c"],"mo":"\/"}}}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0090","num":"0089"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mi":"d","mo":"=","mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":["x","z"],"mo":"-"}}}},{"mrow":{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","z"],"mo":","}}},"mo":"=","mfrac":{"mrow":[{"mo":"\u2202","mrow":{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","z","\u03c9"],"mo":[",",","]}}}},{"mo":"\u2202","mrow":{"mi":"n","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"z"}}}]}}],"mo":","}}},"br":{}},"For a source s(x, y) with directivity function D(\u03b8, \u03c6) placed at point \u03b3, the coefficients acorresponding to its spherical harmonic expansion are computed (Equations (4) and (5)). The final acoustic response (pressure field) to the directional source s(x, y) is computed as a linear combination of the pressure fields P(x) of the elementary sources S(x):",{"@attributes":{"id":"p-0092","num":"0091"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"msub":{"mi":"a","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":"p","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},"mo":"."}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"13"}}]}}}}},"Pressure derivative evaluation: In order to produce spatial sound at the listener position, the coefficients of the plane wave decomposition are determined using pressure and its first-order derivatives (Equations 9 and 11). The pressure is computed as shown above. The derivative of the pressure field due to elementary source \u2202p(x)\/\u2202x is computed by differentiating the functions involved analytically:",{"@attributes":{"id":"p-0094","num":"0093"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mrow":[{"mo":"\u2202","mrow":{"msub":{"mi":"p","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}},{"mo":"\u2202","mi":"x"}]},"mo":"=","mrow":{"mrow":[{"msub":{"mo":"\u222b","mi":"s"},"mo":"\u2062","mrow":{"mrow":[{"mo":["[","]"],"mrow":{"mrow":[{"mfrac":{"mrow":[{"mo":"\u2202","mrow":{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","z","\u03c9"],"mo":[",",","]}}}},{"mo":"\u2202","mi":"x"}]},"mo":"\u2062","mrow":{"msub":{"mi":"q","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"z"}}},{"mfrac":{"mrow":[{"mo":"\u2202","mrow":{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","z"],"mo":","}}}},{"mo":"\u2202","mi":"x"}]},"mo":"\u2062","mrow":{"msub":{"mi":"v","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"z"}}}],"mo":"-"}},{"mo":"\u2146","mrow":{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"z"}}}],"mo":"\u2062"}},{"mfrac":{"mrow":[{"mo":"\u2202","mrow":{"msub":{"mi":"s","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}},{"mo":"\u2202","mi":"x"}]},"mo":"."}],"mo":"+"}}}}},"The first-order derivative of the complete pressure field is computed as:",{"@attributes":{"id":"p-0096","num":"0095"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":{"mrow":[{"mo":"\u2202","mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}},{"mo":"\u2202","mi":"x"}]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"msub":{"mi":"a","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2062","mrow":{"mfrac":{"mrow":[{"mo":"\u2202","mrow":{"msub":{"mi":"p","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}},{"mo":"\u2202","mi":"x"}]},"mo":"."}}}}}},{"mrow":{"mo":["(",")"],"mn":"14"}}]}}}},"br":[{},{}]},"Equivalent source technique [Mehra et al. 2013] can perform interactive wave-based sound propagation in large outdoor scenes. This technique decomposes the global pressure field of a scene into local per-object sound fields and inter-object interactions, which are precomputed offline. The pressure field is computed by solving a global linear system consisting of per-object and inter-object interactions, and encoded efficiently as the strengths of equivalent sources. At runtime, the acoustic response at a moving listener is efficiently computed by performing a fast summation over all the equivalent sources.","Preprocessing: Assume a scene composed of K objects, A, A, . . . , A and source position y. During the preprocessing stage, the elementary SH source S(x,y) are expressed in terms of the incoming equivalent sources of these objects. Next, the global solve step is performed to compute the strengths of outgoing equivalent sources for all the objects (C)A, (C)A, . . . , (C)A. These outgoing equivalent source strengths represent an efficient encoding of the pressure field of the scene. This step is repeated for all the elementary sources",{"@attributes":{"id":"p-0099","num":"0098"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":"s","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mfrac":{"msup":{"mi":"\u2147","mrow":{"mrow":[{"mo":"-","mi":"\u21482\u03c0"},{"mi":["vr","c"],"mo":"\/"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mi":"r"},"mo":"\u2062","msub":{"mi":"Y","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0100","num":"0099"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"Precomputation cost."}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["ESM","air","surface","#objs.\/",{},"ESM-sim"]},{"entry":["scenes","volume","area","#srcs","# freq.\/L","(wall-clk)"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["Crowd","85m","\u2014","0\/1","250\/4","\u2014"]},{"entry":["Music","85m","\u2014","0\/1","250\/3","\u2014"]},{"entry":["Wall","85m","\u200271 m","1\/1","250\/3","165 min"]},{"entry":["Parallel","85m","142 m","2\/1","250\/3","195 min"]},{"entry":["Amphitheater","180m\u2002","220 m","1\/3","500\/4","305 min"]},{"entry":["Reservoir","180m\u2002","950 m","5\/2","500\/3","829 min"]},{"entry":["Christmas","180m\u2002","2952 m\u2002","5\/1","500\/3","894 min"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["BEM","air","surface",{},{},"BEM-sim"]},{"entry":["scenes","volume","area","#srcs","# freq.\/L","(wall-clk)"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["Empty room","24 m","\u200260 m","1","250\/4","\u200245 min"]},{"entry":["Furnished room","66 m","142 m","1","250\/4","700 min"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":"Abbreviations:"},{"entry":"\u201c#objs.\u201d number of ESM objects in the scene,"},{"entry":"\u201c#srcs\u201d number of directional sound sources,"},{"entry":"\u201c#freq.\u201d number of frequency samples in the range (0-1 kHz),"},{"entry":"\u201cL\u201d is the SH order, and"},{"entry":"\u201cESM-sim\u201d or \u201cBEM-sim\u201d is the total wall clock time to compute pressure fields using the ESM or BEM propagation techniques respectively."},{"entry":"The sound-propagation computations are performed in parallel for all the elementary SH sources for all the frequencies on a 64-node cluster with 8 cores per node."},{"entry":"\u2018Crowd\u2019 and \u2018Music\u2019 scenes have no precomputation time since only free-space propagation is performed."}]}}]}},"br":{},"sub":["lm","lm"]},{"@attributes":{"id":"p-0101","num":"0100"},"maths":{"@attributes":{"id":"MATH-US-00019","num":"00019"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"p","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"k"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msubsup":{"mrow":{"mo":["(",")"],"msub":{"mi":"C","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},"msub":{"mi":["A","j"]},"mi":"tr"},"mo":"\u2062","mrow":{"msubsup":{"mi":["\u03a6","out"],"msub":{"mi":["A","j"]}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}}},{"mrow":{"msub":{"mi":"s","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},"mo":"."}],"mo":"+"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"15"}}]}}}}},"The derivatives of the pressure field are computed as before (Equation 14). The derivative of the pressure field due to elementary source \u2202p(x)\/\u2202x is computed by analytically differentiating the functions involved: the equivalent source basis functions \u03a6(x) (as defined in [Mehra et al. 2013]) and the source field S(x).",{"@attributes":{"id":"p-0103","num":"0102"},"maths":{"@attributes":{"id":"MATH-US-00020","num":"00020"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":{"mrow":[{"mo":"\u2202","mrow":{"msub":{"mi":"p","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}},{"mo":"\u2202","mi":"x"}]},"mo":"=","mrow":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"k"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msubsup":{"mrow":{"mo":["(",")"],"msub":{"mi":"C","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},"msub":{"mi":["A","j"]},"mi":"tr"},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2202","mrow":{"msubsup":{"mi":["\u03a6","out"],"msub":{"mi":["A","j"]}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}},{"mo":"\u2202","mi":"x"}]}}},{"mfrac":{"mrow":[{"mo":"\u2202","mrow":{"msub":{"mi":"s","mrow":{"mi":["l","m"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}},{"mo":"\u2202","mi":"x"}]},"mo":"."}],"mo":"+"}}},{"mrow":{"mo":["(",")"],"mn":"16"}}]}}}}},{"@attributes":{"id":"p-0104","num":"0103"},"figref":"FIG. 6","b":["600","602","600","600","602"],"sup":["nd ","rd "]},"6 Implementation","In this section, details for an exemplary implementation of a listener directivity approach described herein is disclosed. In this exemplary implementation, a 64-bit FASTBEM implementation of the fast multipole boundary element method (www.fastbem.com) is used. For ESM, the preprocessing code is implemented in MATLAB. The runtime code is implemented in C++ and has been integrated with Valve's Source game engine. The timing results for the BEM and ESM precomputation are measured on a 64-node CPU cluster (Xeon 5560 processor nodes, 8 cores, 2.80 GHz, 48 GB memory). The precomputation for each frequency is performed in parallel over all the nodes of the cluster. The timing results of the exemplary runtime system are measured on a single core of a 4-core 2.80 GHz Xeon X5560 desktop with 4 GB of RAM and NVIDIA GeForce GTX 480 GPU with 1.5 GB memory. Acoustic responses are computed up to the maximum simulation frequency of 1 kHz.","Measurement data: The source directivity data used in the exemplary system is extracted from real-world measurement data provided by Meyers et al. [PTB 1978]. The data is magnitude only and averaged over the frequencies in each octave band and is provided for all the octave bands within the frequency range of the sound sources. SH order L=3 or 4 is used for the source representation, which gives less than 10-15% error (see ). Error is defined as",{"@attributes":{"id":"p-0107","num":"0106"},"maths":{"@attributes":{"id":"MATH-US-00021","num":"00021"},"math":{"@attributes":{"overflow":"scroll"},"msqrt":{"mfrac":{"mrow":[{"msub":[{"mi":["\u03a3","i"]},{"mi":["\u03a3","j"]}],"mo":["\u2062","\u2062"],"msup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mrow":[{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["\u03b8","i"]},{"mi":["\u03d5","j"]}],"mo":","}}},{"msub":{"mi":["D","SH"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["\u03b8","i"]},{"mi":["\u03d5","j"]}],"mo":","}}}],"mo":"-"}},"mn":"2"}},{"msub":[{"mi":["\u03a3","i"]},{"mi":["\u03a3","j"]}],"mo":["\u2062","\u2062"],"msup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["\u03b8","i"]},{"mi":["\u03d5","j"]}],"mo":","}}}},"mn":"2"}}]}}}},"br":[{},{},{},{}],"sub":"SH "},{"@attributes":{"id":"p-0108","num":"0107"},"figref":"FIG. 7","b":["700","700"]},"The BEM error tolerance and order of multipole expansion was set to 1% and 6, respectively. ESM error thresholds for scattering and interactive matrices are 15% and 1%, respectively. These error thresholds were chosen for interactive performance and can be reduced to achieve higher accuracy. The pressure fields produced by the two techniques agree within error of <5-10%. The offline BEM method has a much higher time and memory overhead, but the resulting pressure fields are more accurate.","7 Results","In Table 1, the cost of precomputing the pressure fields using BEM and ESM are shown. Since the computation for all sound sources, the elementary SH sources and different frequencies are independent, all these computations can be easily performed in parallel. Table 2 shows the runtime performance and memory requirements of the ESM technique for computing the acoustic response for arbitrary source directivity at a moving listener. For the case of dynamic source in parallel buildings, 30 sampled positions in the scene were selected. FASTBEM computes the acoustic response (pressure evaluation) for the empty room and the furnished room at the listener position in 3 and 5 seconds, respectively. The storage cost for the BEM pressure fields is 716 MB and 1.4 GB for the empty and furnished room, respectively. BEM has much higher memory requirement than the ESM (Table 4 in [Mehra et al. 2013]) since it captures the sound-field interactions close to the surface of the object. ESM, on the other hand, captures the sound-field interactions outside the object's offset surface. As stated above,  shows that, as the frequency of different sound sources grows higher, higher order terms in the SH representation are needed. As a general trend, sound source directivities become sharper (more prominent) with increasing frequency, requiring higher order SH basis functions.",{"@attributes":{"id":"p-0111","num":"0110"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"ESM runtime performance."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"56pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},{},"eval.","eval.","storage"]},{"entry":[{},{},"# eq.","(no spatial,","(spatial,","(total,"]},{"entry":["Scene","L","srcs","per src)","per src)","fixed + per src)"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["Crowd","4","\u2014","0.14 ms","0.34 ms","\u2014"]},{"entry":["Music","3","\u2014","0.14 ms","0.34 ms","\u2014"]},{"entry":["Wall","3","0.1M","12.6 ms","16.7 ms","(1 + 29) MB"]},{"entry":["Parallel","3","0.2M","17.9 ms","\u2002\u200924 ms","(2 + 58) MB"]},{"entry":["Amphitheater","4","0.1M","\u2002\u200914 ms","18.6 ms","(1 + 51) MB"]},{"entry":["Reservoir","3","0.8M","\u2002\u200986 ms","\u2009115 ms","(10 + 230) MB\u2003"]},{"entry":["Christmas","3","0.7M","90.6 ms","119.5 ms\u2002","(8 + 202) MB\u2002"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":"\u201cL\u201d is the SH order, and"},{"entry":"\u201c# eq. srcs\u201d number of equivalent sources (in millions)."},{"entry":"For each scene, the runtime performance \u201ceval.\u201d with and without spatial sound and the storage requirement \u201cstorage\u201d are shown."},{"entry":"Storage numbers indicate fixed cost for equivalent source positions and the total cost for storing their strengths for all elementary SH sources up to SH order L."},{"entry":"\u2018Crowd\u2019 and \u2018Music\u2019 scenes do not have any equivalent sources since only free-space propagation is performed."}]}}]}},"br":{}},"In a related video, auralizations are modeled for the various scenes listed in Table 2 with principles and\/or effects demonstrated described below. Parallel buildings and an empty living room: A comparison between the sound propagation for an omnidirectional source and a directional source is shown. Furnished living room: The sound propagation due to a television (a typical directional source) in the living room setting is shown and low-passing of diffracted sound behind doors is demonstrated.","Wall: Using an exemplary listener directivity approach described herein enables an listener to localize the direction of the sound source. Also, time-varying source directivity caused by the motion of an obstacle in front of the source is shown.","Reservoir (from Half-Life 2): An exemplary listener directivity approach described herein has been integrated with an existing game engine (Valve Source\u2122 game engine) to generate realistic acoustic effects from directional sources and listener.","Christmas town: The source directivity of bell tower and diffraction low-passing of sound behind houses are demonstrated.","Dynamic directional sources: To demonstrate source and listener directivity for dynamic sources and listeners, a helicopter flying between two parallel buildings and a moving player is demonstrated.","Amphitheater: Propagated sound due to directional sources at various locations around a real-world environment.","7.2 Validation","Source modeling: In the SH decomposition of the directivity function, no significant ringing was observed for the first four octave bands. For the last two octave bands, ringing was resolved by standard techniques (windowing the truncated SH coefficients using Lanczos sigma factors). SH-based source representation described herein converges to the measured directivity with increasing SH order, as shown in .\n\nSound propagation: In order to validate that an exemplary listener directivity approach described herein can correctly capture the effect of source directivity on sound propagation, validation experiments were performed against the Biot-Tolstoy-Medwin (BTM) method [Svensson et al. 1999]. This is an offline technique that provides a wideband reference solution with accurate diffraction in simple scenes and can incorporate source directivities. A data-driven SH-based directivity formulation described herein was integrated with the BTM Toolbox for MATLAB (www.iet.ntnu.norsvensson\/software\/index.html#EDGE). The BTM approach models edge diffraction by placing several secondary sources at positions sampled along the diffracting edges. Their intensities are determined only by the intensity of the sound source and the distance between the sound source and the secondary source. The strengths of each secondary source was scaled by the SH-approximated directivity function D(\u03b8, \u03c6), where (\u03b8, \u03c6) are determined by the direction vector from the source to the secondary source. BTM integral calculations were observed to be significantly slowed down due to the need to evaluate source directivity for each integration sample along each edge. BTM simulations were performed for musical instruments over three receiver positions and a fixed source position in the wall scene. Simulations for receivers 1, 2, and 3 took 57, 27, and 18 minutes, respectively. A supplementary video included receiver positions and auralizations.\n\n8 Conclusion and Future Work\n","The present subject matter discloses aspects related to incorporating modifiable source directivity and HRTF3 based listener directivity in a general frequency-domain wave-based sound propagation techniques. Some aspects disclosed herein can automatically model wave-effects from low frequency directional sources. Some aspects disclosed herein can handle analytical, data-driven, rotating or time-varying directivity at runtime. The present subject matter also discloses aspects related to an efficient method for performing spatial sound rendering at interactive rates.","In some embodiments, directional sources with sharp directivity patterns (delta functions) may be expensive to handle with our current approach since it would require a very high-order SH expansion. As such, other basis functions (such as wavelets) may be usable to handle sharp directivities.","Source formulation described herein can handle both near- and far-field sound radiation by directional sources (equation 1). In some embodiments, near-field directivity may require a set of dense measurements of complex frequency responses very close to the source at twice the Nyquist rate, which is currently unavailable. In such embodiments, near-field directivity may be determined when such a dataset becomes available in the future.","In some embodiments, hybridization of wave-based techniques with geometric approaches may be utilized to handle directional sources over the complete audible frequency range.","In some embodiments, support for artist-controlled directivity may be added, thereby allowing real-time feedback of the effect of directivity on propagated sound.","It will be appreciated that while magnitude-only directivity data may be used in some aspects of the present subject matter, aspects of the present subject matter can easily support complex data (e.g., magnitude and phase), which we plan to test in the future.",{"@attributes":{"id":"p-0120","num":"0119"},"figref":"FIG. 8","b":["800","800","110","108","102"]},"At step , one or more sound fields associated with a source or listener position may be computed prior to run-time. For example, SPM module  may be configured to precompute and store propagated sound fields or pressure fields due to SH sources.","In some embodiments, computing, prior to run-time, one or more sound fields associated with a source position may include using a one-point multipole method to represent a sound field radiated by a directional source and capturing directivity using spherical harmonic (SH) expansion.","In some embodiments, one or more precomputed sound fields may be associated with one or more elemental spherical harmonics sources located at the source position.","In some embodiments, one or more precomputed sound fields may represent one or more acoustic responses of the environment to any directivity at the source position.","At step , at run-time, source or listener directivity in an environment may be modeled using the one or more pressure fields and a wave-based sound propagation model. For example, SPM module  may compute a total sound field using a wave-based sound propagation technique at run-time, thereby allowing modeling of a source with a directivity that can be dynamically modified at run-time.","In some embodiments, run-time may occur when executing a sound propagation model application for the environment and precomputing may occur prior to run-time.","In some embodiments, modeling, at run-time and using the one or more sound fields and the wave-based sound propagation model, source or listener directivity in an environment may include generating, using the one or more sound fields, an acoustic response to an arbitrary time-varying or rotating directional source.","In some embodiments, modeling, at run-time and using the one or more sound fields and the wave-based sound propagation model, source or listener directivity in an environment may include performing a spherical harmonic (SH) decomposition of the source directivity, computing one or more SH coefficients corresponding to the SH decomposition, and computing an acoustic response of the environment, wherein the acoustic response is computed as a summation of the one or more sound fields evaluated at the listener position weighted by the one or more SH coefficients.","In some embodiments, computing an acoustic response using precomputed sound fields may involve convolving the acoustic response with source audio information to render the sound.","In some embodiments, acoustic responses for both ears may be computed using a head-related transfer function (HRTF).","In some embodiments, modeling, at run-time and using the one or more sound fields and the wave-based sound propagation model, source or listener directivity in an environment may include computing spatial sound as an inner product of spherical harmonic (SH) coefficients associated with an SH decomposition of the sound field and a head-related transfer function for a moving listener.","The disclosures of all of the references listed herein are hereby incorporated herein by reference in their entireties.\n\n","It will be understood that various details of the subject matter described herein may be changed without departing from the scope of the subject matter described herein. Furthermore, the foregoing description is for the purpose of illustration only, and not for the purpose of limitation, as the subject matter described herein is defined by the claims as set forth hereinafter."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Preferred embodiments of the subject matter described herein will now be explained with reference to the accompanying drawing, wherein like reference numerals represent like parts, of which:",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
