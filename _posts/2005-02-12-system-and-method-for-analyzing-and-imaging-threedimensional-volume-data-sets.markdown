---
title: System and method for analyzing and imaging three-dimensional volume data sets
abstract: A system and method is provided for analyzing and imaging three-dimensional volume data sets. In one embodiment of the invention, a ribbon section is produced which may include a plurality of planes projected from a polyline. The polyline may include one or more line segments preferably formed within a plane. The projected planes intersect the three-dimensional volume data set and the data located at the intersection may be selectively viewed. The polyline may be edited or varied by editing or varying the control points which define the polyline. In another embodiment of the present invention, a method is provided for quickly tracking a physical phenomena represented within the three-dimensional volume data set. A plurality of planes may be successively displayed in the three-dimensional volume data set from which points are digitized related to the structure of interest to create a spline curve on each plane. The area between the spline curves is interpolated to produce a surface representative of the structure of interest, which may for example be a fault plane described by the three-dimensional volume data set. In this manner, the user can more easily and effectively visualize and interpret the features and physical parameters that are inherent in the three-dimensional volume data set.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07098908&OS=07098908&RS=07098908
owner: Landmark Graphics Corporation
number: 07098908
owner_city: Houston
owner_country: US
publication_date: 20050212
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","STATEMENT REGARDING FEDERALLY SPONSORED RESEARCH","SUMMARY OF THE INVENTION","FEATURES AND ADVANTAGES","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS","Overview","SYSTEM DESCRIPTION","SYSTEN OPERATION AND RESULTS","CONCLUSION"],"p":["This application is a continuation of U.S. application Ser. No. 09\/936,682 filed on Sep. 17, 2001, now U.S. Pat. No. 7,006,085 which is a continuation and claims the benefit of PCT Application Ser. No. PCT\/US00\/29835 filed on Oct. 30, 2000.","Not applicable.","1. Field of the Invention","The present invention relates generally to imaging of three-dimensional (\u201c3D\u201d) volume data sets. More particularly, the present invention relates to fast visualization and analysis of structures within 3D volume data sets.","2. Background of the Invention","Many fields of endeavor require the analysis and imaging of three-dimensional (\u201c3D\u201d) volume data sets. For example, in the medical field, a CAT (computerized axial tomography) scanner or a magnetic resonance imaging (MRI) device is used to produce a \u201cpicture\u201d or diagnostic image of some part of a patient's body. The scanner or MRI device generates a 3D volume data set that needs to be imaged or displayed so that medical personnel can analyze the image and form a diagnosis.","Three-dimensional volume data sets are also used in various fields of endeavor relating to the earth sciences. Seismic sounding is one method for exploring the subsurface geology of the earth. An underground explosion or earthquake excites seismic waves, similar to low frequency sound waves, that travel below the surface of earth and are detected by seismographs. The seismographs record the time of arrival of the seismic waves, both direct and reflected waves. Knowing the time and place of the explosion or earthquake, the time of travel of the waves through the interior can be calculated and used to measure the velocity of the waves in the interior. A similar technique can be used for offshore oil and gas exploration. In offshore exploration, a ship tows a sound source and underwater hydrophones. Low frequency (e.g., 50 Hz) sound waves are generated by, for example, a pneumatic device that works like a balloon burst. The sounds bounce off rock layers below the sea floor and are picked up by the hydrophones. In this manner, subsurface sedimentary structures that trap oil, such as faults, folds, and domes, are \u201cmapped\u201d by the reflected waves. The data is processed to produce 3D volume data sets that include a reflection or seismic amplitude datavalue at specified (x, y, z) locations within a geographic space.","A 3D volume data set is made up of \u201cvoxels\u201d or volume elements. Each voxel has a numeric value for some measured or calculated property, e.g., seismic amplitude of the volume at that location. One conventional approach to generating an image of a 3D volume data set is to cross-section the 3D volume data set into a plurality of two-dimensional (\u201c2D\u201d) cross-sections or slices. The image of the 3D volume data set is then built as a composite of the 2D slices. For example, the image of the 3D volume data set is generated by stacking the 2D slices in order, back-to-front, and then composited into a complete image. The user sees the image being built layer by layer as the composite grows. Although the user can see the internal organization or structure of the volume as the composite image grows, the traditional slice and composite technique is typically slow, particularly when very large 3D volume data sets are being used. Additionally, the slice and composite technique clutters the user's field of view with extraneous information, and interferes with the user's ability to accurately visualize and interpret features inherent in the 3D volume data set.","Computer software has been developed specifically for imaging 3D seismic data sets for the oil and gas industry. Examples of such conventional computer programs include VoxelGeo, available from Paradigm Geophysical, Houston, Tex., SeisWorks and EarthCube, available from Landmark Graphics Corporation, and IESX, available from GeoQuest. Such conventional computer programs have numerous deficiencies that preclude a user from quickly and accurately visualizing and interpreting features inherent in a 3D seismic data set. Conventional computer programs for visualizing and interpreting 3D seismic data operate on the full 3D volume of seismic data. Consequently, every time a change is made, such as a change to the transparency or opacity settings, the full 3D volume of seismic data must be processed, and the image re-drawn. Even when such programs are run on highly efficient graphics supercomputers, the delay or lag in re-drawing the image is perceptible to the user. For a 3D volume containing 500 megabytes of seismic data, it can take on the order of 30\u201345 seconds for conventional programs to re-draw the complete image (frame rate of 0.03 to 0.02 frames per second, respectively). During the 30\u201345 second delay time, the mind of the user loses focus on the feature of interest, making it difficult to completely and properly analyze the seismic data.","Some conventional 3D seismic interpretation programs provide the capability to visualize and interpret a piece of the full 3D volume of seismic data. The user identifies the coordinates of the selected piece via a menu command. An image of the selected piece is drawn. The selected piece can then be rotated if desired, at that location. However, to look at a different piece of the full 3D volume of seismic data, such as to follow a geologic feature that has been tentatively identified, the image must be interrupted, a new location or coordinates for the different piece is entered, and a new image is drawn containing the different piece. The interruption in the displayed image makes it difficult for the user to visualize any continuity between the two pieces of the full 3D volume of seismic data that have been imaged. This impedes the user's ability to interpret and identify the geologic features that are inherent in the full 3D volume of seismic data. Additionally, even though only a piece of the full 3D volume of seismic data is being visibly displayed, conventional 3D seismic interpretation programs continue processing the full 3D volume of seismic data to draw the image, thereby slowing the display of the image to the user.","Conventional 3D seismic interpretation programs provide the capability to \u201cauto pick\u201d and identify points that satisfy a voxel selection algorithm. However, these programs typically iterate through the full 3D volume of seismic data to identify the points that satisfy the voxel selection algorithm. This is time consuming even on a high speed graphics supercomputer. Additionally, conventional 3D seismic interpretation programs do not provide the capability to directly delete from the collection of picked voxels. The only way to \u201celiminate\u201d points from the collection of picked voxels using conventional 3D seismic interpretation programs is to repeatedly adjust the selection criteria for the voxel selection algorithm until the points to be eliminated fall outside of the selection criteria for the displayed points that satisfy the voxel selection algorithm. Each time the selection criteria is adjusted, the image must be interrupted. This iterative process is time consuming, and interferes with the visualization process of the user.","Thus, there is a need in the art for a system and method for imaging 3D volume data sets that overcomes the deficiencies detailed above. Particularly, there is a need for a system and method that re-draws images of large 3D volume data sets in response to user input at a rate sufficiently fast that the user perceives an instantaneous or real-time change in the image, without perceptible delay or lag. There is a need for a system and method that allows a user to interactively change the displayed image in a continuous manner, without interruption or perceptible delay or lag. Such a system and method would allow a user to more quickly and accurately interpret and identify features inherent in 3D volume data sets.","The present invention is directed to a system and method for analyzing and imaging 3D volume data sets using a 3D sampling probe and other interactive tools. In one aspect of the invention, a method and computer program is provided which may be stored on a storage means for imaging a three-dimensional volume data set comprising a plurality of voxels where each voxel comprises a three-dimensional location and a dataword. The dataword may be representative of a physical phenomena, e.g., an amplitude signal related to a particular position within a geobody. The method may comprise steps such as creating at least one three-dimensional sampling probe, wherein the three-dimensional sampling probe is the same size or a subset of the three-dimensional volume data set. The three-dimensional sampling probe has a probe face plane and an opposing probe face plane. Other steps may include producing a plurality of control points in the probe face plane such that the plurality of control points define one or more lines on the probe face plane, and extending a ribbon section from the one or more lines on the probe face plane toward the opposing probe face plane. An edge of the ribbon section is preferably formed by the one or more lines. Another step of the method may include selectively imaging datawords representative of the physical phenomena at three-dimensional locations which intersect the ribbon section and the three-dimensional sampling probe.","The method may further comprise steps of editing the plurality of control points on the probe face plane to thereby redefine the one or more lines, and extending a correspondingly redefined ribbon section from the one or more lines on the probe face plane toward the opposing probe face plane. The step of editing may further comprise functions such as deleting one or more of the plurality of control points, changing a location of one or more of the plurality of control points, and adding one or more control points to the plurality of control points.","In a preferred embodiment, the ribbon section is perpendicular to the probe face plane and the ribbon section may extend from the probe face plane to the opposing probe face plane. The one or more lines forming the edge of the ribbon section may be edited through the plurality of control points to construct a plurality of open straight lines or a closed line geometrical figure, if desired The ribbon section is preferably comprised of a plurality of planes. The ribbon section may or may not be parallel with respect to each of a plurality of side faces of the probe.","In another embodiment of the present invention related to tracking a particular physical phenomena, such as a geological fault, the method may comprise the steps of positioning the probe face plane at a first position within the three-dimensional volume data set and forming a first set of control points on the probe face plane for tracking a physical phenomena described by the three-dimensional volume data set. Another step may include interpolating between the first set of control points to define a first spline curve. Other steps may include moving the probe to a second position within the three-dimensional volume data set, forming a second set of control points on the probe face plane for tracking the physical phenomena and interpolating there between such that the second set of control points define a second spline curve. Another step may include interpolating a three dimensional surface between the first spline curve and the second spline curve which is representative of the physical phenomena.","The method further permits displaying the interpolated surface where the surface intersects the first set of control points and the second set of control points. It is an advantage of the present invention that the first spline curve, second spline curve and subsequent spline curves are curvilinear.","Additional steps may include the reiterative process of moving the probe to a third position within the three-dimensional volume data set, forming a third set of control points on the probe face plane for tracking the physical phenomena, interpolating between the third set of control points to define a third spline curve, and interpolating between the first spline curve, the second spline, and the third spline curve for further defining the three dimensional surface representative of the physical phenomena.","If desired, the method may further comprise steps such as editing the respresentive control points on the probe face plane at respective positions of the probe. Moreover, the method may include displaying a curvilinear connection (\u201cv curves\u201d) between respective control points at respective positions of the probe. Another step may include displaying the spline curves and the v-curves on the three dimensional surface. The spline curves and the v-curves form a three dimensional grid also representative of the physical phenomena. The grid includes a plurality of intersections between the spline curves and the v-curves. The method may further comprise editing the current set of control points on the probe face plane, thereby reshaping the surface and grid between the current spline curve and the prior spline curve.","Preferably the method may also include steps such as selecting one of the plurality of intersections to thereby reposition the probe face plane to pass through the selected intersection. The method also comprises selecting one of the sets of control points to thereby reposition the probe face plane to pass through the selected set of control points.","Stated another way, an embodiment of the method may comprise steps such as positioning the probe face plane at a plurality of positions within the three-dimensional volume data set, forming a set of control points at each of the plurality of probe face plane positions such that each set of control points defines a related spline curve, repositioning the probe face plane and interpolating between the plurality of spline curves to form a three dimensional surface representative of the physical phenomena.","It is a feature of the present invention that a ribbon section through a 3D sampling probe can be created, redrawn, edited, and moved quickly and conveniently by creating a plurality of lines that are then projected through the 3D sampling probe. The lines may be drawn at angles offset from the coordinate system, such as an x, y, z or Cartesian coordinate system, of the 3D sampling probe.","It is another feature of the present invention that structures in a 3D data volume set, such as for instance geological structures, can be quickly mapped by selecting points of interest at a plurality of locations in the 3D sampling probe, which points may then be interpolated to produce a grid or surface related to the structure. The grid may be quickly edited and the probe may be moved to various points on the surface by selecting grid intersections.","It is yet another feature of the present invention that, as a user interactively moves a 3D sampling probe through a 3D volume date the image on the surfaces of the 3D sampling probe is re-drawn \u201con the fly\u201d so that the user perceives the image changing in real-time with movement of the 3D sampling probe. Similarly, as a user interactively moves a 3D sampling probe through a 3D volume data set, the 3D sampling probe is volume rendered with varying degrees of transparency \u201con the fly\u201d so that the user perceives the image changing in real-time with movement of the 3D sampling probe.","It is a further feature of the present invention that a user can interactively change the shape or size of a 3D sampling probe so that the image on the surfaces of the 3D sampling probe is re-drawn \u201con the fly\u201d so that the user perceives the image changing in real-time with the change in shape or size of the 3D sampling probe. Similarly, a user can interactively change the shape or size of a 3D sampling probe so that the 3D sampling probe is volume rendered with varying degrees of transparency \u201con the fly\u201d so that the user perceives the image changing in real-time with the change in shape or size of the 3D sampling probe.","It is yet a further feature of the present invention that a user can interactively rotate a 3D sampling probe so that the image on the surfaces of the 3D sampling probe is re-drawn \u201con the fly\u201d so that the user perceives the image changing in real-time with the rotation of the 3D sampling probe. Similarly, a user can interactively rotate a 3D sampling probe so that the 3D sampling probe is volume rendered with varying degrees of transparency \u201con the fly\u201d so that the user perceives the image changing in real-time with the rotation of the 3D sampling probe.","It is yet a further feature of the present invention that an eraser 3D sampling probe can be created and manipulated by the user to directly delete from an image selected points that fall within a certain datavalue range.","It is an advantage of the present invention that a user can manipulate a 3D sampling probe to interactively traverse a 3D volume data set to continuously follow and image a feature.","It is a further advantage of the present invention that a user can interactively change the displayed image in a continuous manner, without interruption or perceptible delay or lag. This allows a user to more quickly and accurately interpret and identify features inherent in 3D volume data sets.","It is yet a further advantage of the present invention that the 3D sampling probes can be interactively re-shaped by the user to match the shape of geologic features, thereby enabling the user to better visualize and define the extent of geologic features.","A still further advantage of the present invention is that it can be used to visualize and interpret large volumes of 3D seismic data. The present invention can be used to quickly and accurately identify drilling sites. The present invention can advantageously be used to sharply reduce 3D seismic project cycle times, to boost production from existing wells, and to locate additional reserves.","The present invention is directed to a system and method for analyzing and imaging three-dimensional (\u201c3D\u201d) volume data sets using a 3D sampling probe. 3D volume data sets comprise \u201cvoxels\u201d or volume elements. Each voxel is a sample or point within a volume. Each voxel can be expressed in the form (x, y, z, datavalue) where \u201cx, y, z\u201d identifies the 3D location of the point within the volume, and \u201cdatavalue\u201d is the value of some measured or calculated attribute or physical parameter at the specified point within the volume. For example, a 3D volume data set suitable for use with the present invention is 3D seismic data. Each voxel in a 3D seismic data can be expressed as (x, y, z, amplitude), with amplitude corresponding to the amplitude of reflected sound waves at the specified (x, y, z) location.","Any form of information that can be expressed in the voxel form (x, y, z, datavalue) is suitable for use with the present invention In addition to seismic data, examples from the oil and gas industry include information from closely spaced well logs, gravity and magnetic fields, remote sensing data, and sidescan sonar image data. Other geologic or physical information could also include temperature, pressure, saturation, reflectivity, acoustical impedance, and velocity.","Another application for the present invention is for mining. For example, the present invention can be used to visualize and interpret geologic and geophysical data to locate mining sites, to locate and track deposits to be mined, or to locate and track geologic features such as faults that would affect mining operations. The present invention also has application for clean up of toxic, hazardous, or other types of waste. For example, the present invention can be used to visualize and interpret data representing the geographic extent and distribution of the waste at a particular site. Such visualization and interpretation is useful for prioritizing clean up at various sites, and for developing a clean-up plan for a particular site.","The present invention can also be used with information outside of the oil and gas industry. For example, the present invention can be used for analyzing and imaging in the medical field, where the datavalue element of the voxel is obtained from a CAT (computerized axial tomography) scanner or a magnetic resonance imaging (MRI) procedure.","By way of explanation and example, the present invention will be described in detail below using 3D seismic data as the 3D volume data set. It is to be understood, however, that the present invention is not limited in any way to the use of 3D seismic data.","The present invention is particularly useful as a visualization tool for interpreting 3D seismic data. As used herein, the term \u201cvisualization\u201d refers to the construction of a three-dimensional picture in the user's mind of physical or geologic features or physical parameters that are inherently present in 3D volume data sets. Such physical features or parameters are typically not apparent from conventional means of processing 3D data sets, such as scanning a series of cross-sections of the 3D volume data set, because of the mental reconstruction that needs to take place in order for a user to mentally \u201cpicture\u201d the three-dimensional feature. Because of this mental reconstruction, it is difficult to communicate and share among users the same 3D image. For example, the same 3D mental image of the terrain will not necessarily be present in the mind of every person that reads or analyzes a two-dimensional (\u201c2D\u201d) contour map of that terrain. Through the use of 3D computer graphics, users can visualize, and communicate and share, the same 3D image of 3D volume data sets. By visualizing 3D seismic data, a team of geologists, geophysicists, and engineers can interpret the visualized data to make exploration and production decisions, such as drilling locations and well paths.","To accomplish the visualization function, the present invention uses the computer graphics techniques of texture mapping and volume rendering. By \u201ctexture map\u201d is meant wrapping or mapping a 2D picture or image onto a 2D or a 3D object. For example, a photograph of a person can be texture mapped onto a coffee cup.","The term \u201cvolume rendering\u201d or \u201cvolume imaging\u201d refers to drawing a three-dimensional object in a manner that conveys to a viewer the three-dimensional nature of the object, even though the viewer may be looking at a two-dimensional display or screen. Computer graphics technology makes use of coloring, lighting, and shading techniques to convey to the mind of the viewer what is high or low, behind or in front, light or dark, etc. The perspective or viewpoint can be changed so that the viewer can see all sides of the 3D object. Volume rendering typically includes some type of transparency\/opacity (opacity=1\u2212transparency) control so that certain parts of the 3D object are more transparent, thereby allowing a viewer to \u201csee through\u201d outer surfaces of an object and view its internal structures.","The present invention enables fast visualization and analysis of very large 3D volume data sets through the use of a \u201csampling probe\u201d, also referred to herein as a \u201cprobe\u201d or \u201cprobe object\u201d. As explained in more detail below, the sampling probes of the present invention have numerous attributes, one of which is that they are typically created as a 3D sub-volume of the whole 3D volume data set to be visualized and analyzed.","A number of sampling probes can be created, shaped, sized, and moved interactively by the user within the whole 3D volume data set. The intersection of the sampling probe with the whole 3D volume data set is texture mapped onto the surfaces of the sampling probe, or volume rendered with varying degrees of transparency within the sampling probe. As used herein, the term \u201cinteractive\u201d or \u201cinteractively\u201d refers to changing or re-drawing an image in response to user input at a rate sufficiently fast that the user perceives an instantaneous or real-time change in the image, without perceptible delay or lag. In practice, a frame rate of at least about 10 to 15 frames per second is sufficient to achieve interactive imaging as described herein. For example, as the user moves the sampling probe, such as by \u201cclicking and dragging\u201d with a \u201cmouse\u201d, the user perceives the texture on the surfaces of the sampling probe changing in \u201creal-time\u201d with movement of the sampling probe. As the sampling probe changes shape, size, or location, there is no user-perceivable delay or lag in imaging the texture, or, with varying degrees of transparency, volume-rendered attributes. In this manner, the user can interactively move the sampling probes through the whole 3D volume, and more easily and effectively visualize and interpret the features and physical parameters that are present within the geographic space represented by the whole 3D volume data set.","The present invention may be implemented using hardware, software or a combination thereof, and may be implemented in a computer system or other processing system. One embodiment of a software or program structure  for implementing the present invention is shown in . At the base of program structure  is an operating system . Suitable operating systems  include, for example, the UNIX\u00ae operating system, or Windows NT\u00ae from Microsoft Corporation, or other operating systems as would be apparent to one of skill in the relevant art.","Menu and windowing software  overlays operating system . Menu and windowing software  is used to provide various menus and windows to facilitate interaction with the user, and to obtain user input and instructions. Menu and windowing software  can include, for example, Microsoft Windows\u2122, X Window System\u2122 (registered trademark of Massachusetts Institute of Technology), and MOTIF\u2122 (registered trademark of Open Software Foundation Inc.). As would be readily apparent to one of skill in the relevant art, other menu and windowing software could also be used.","A basic graphics library  overlays menu and windowing software . Basic graphics library  is an application programming interface (API) for 3D computer graphics. The functions performed by basic graphics library  include, for example, geometric and raster primitives, RGBA or color index mode, display list or immediate mode, viewing and modeling transformations, lighting and shading, hidden surface removal, alpha blending (translucency), anti-aliasing, texture mapping, atmospheric effects (fog, smoke, haze), feedback and selection, stencil planes, and accumulation buffer.","A particularly preferred basic graphics library  is OpenGL\u00ae, available from Silicon Graphics, Inc. (\u201cSGI\u201d), Mountain View, Calif. The OpenGL\u00ae API is a multiplatform industry standard that is hardware, window, and operating system independent. OpenGL\u00ae is designed to be callable from C, C++, FORTRAN, Ada and Java programming languages. OpenGL\u00ae performs each of the functions listed above for basic graphics library . Some commands in OpenGL\u00ae specify geometric objects to be drawn, and others control how the objects are handled. All elements of the OpenGL\u00ae state, even the contents of the texture memory and the frame buffer, can be obtained by a client application using OpenGL\u00ae. OpenGL\u00ae and the client application may operate on the same or different machines because OpenGL\u00ae is network transparent. OpenGL\u00ae is described in more detail in the OpenGL\u00ae Programming Guide (ISBN: 0-201-63274-8) and the OpenGL\u00ae Reference Manual (ISBN: 0-201-63276-4), the entirety of both of which are incorporated herein by reference.","Visual simulation graphics library  overlays basic graphics library . Visual simulation graphics library  is an API for creating real-time, multi-processed 3D visual simulation graphics applications. Visual simulation graphics library  provides functions that bundle together graphics library state control functions such as lighting, materials, texture, and transparency. These functions track state and the creation of display lists that can be rendered later.","A particularly preferred visual simulation graphics library  is IRIS Performer, available from SGI in Mountain View, Calif. IRIS Performer supports the OpenGL\u00ae graphics library discussed above. IRIS Performer includes two main libraries, libpf and libpr, and four associated libraries, libpfdu, libpfdb, libpfui, and libpfutil.","The basis of IRIS Performer is the performance rendering library libpr, a low-level library providing high speed rendering functions based on GeoSets and graphics state control using GeoStates. GeoSets are collections of drawable geometry that group same-type graphics primitives (e.g., triangles or quads) into one data object. The GeoSet contains no geometry itself, only pointers to data arrays and index arrays. Because all the primitives in a GeoSet are of the same type and have the same attributes, rendering of most databases is performed at maximum hardware speed. GeoStates provide graphics state definitions (e.g., texture or material) for GeoSets.","Layered above libpr is libpf, a real-time visual simulation environment providing a high-performance multi-process database rendering system that optimizes use of multiprocessing hardware. The database utility library, libpfdu, provides functions for defining both geometric and appearance attributes of 3D objects, shares state and materials, and generates triangle strips from independent polygonal input. The database library libpfdb uses the facilities of libpfdu, libpf, libpr to import database files in a number of industry standard database formats. The libpfui is a user interface library that provides building blocks for writing manipulation components for user interfaces (C and C++ programming languages). Finally, the libpfutil is the utility library that provides routines for implementing tasks such as MultiChannel Option support and graphical user interface (GUI) tools.","An application program that uses IRIS Performer and OpenGL\u00ae API typically carry out the following steps in preparing for real-time 3D visual simulation:","1. Initialize IRIS Performer;","2. Specify number of graphics pipelines, choose the multiprocessing configuration, and specify hardware mode as needed;","3. Initialize chosen multiprocessing mode;","4. Initialize frame rate and set frame-extend policy;","5. Create, configure, and open windows as required; and","6. Create and configure display channels as required.","Once the application program has created a graphical rendering environment by carrying out steps 1 through 6 above, then the application program typically iterates through a main simulation loop once per frame.","7. Compute dynamics, update model matrices, etc.;","8. Delay until the next frame time;","9. Perform latency critical viewpoint updates;","10. Draw a frame.","A 3D sampling probe program  of the present inventions overlays visual simulation graphics library . Program  interacts with, and uses the functions carried out by, each of visual situation and graphics library , basic graphics library , menu and windowing software , and operating system  in a manner known to one of skill in the relevant art.","3D sampling probe program  of the present invention is preferably written in an object oriented programming language to allow the creation and use of objects and object functionality. A particularly preferred object oriented programming language is C++. In carrying out the present invention, program  creates one or more probe \u201cobjects\u201d. As noted above, the probe objects created and used by program  are also referred to herein as sampling probes or probes. Program  manipulates the probe objects so that they have the following attributes.","A probe corresponds to a sub-volume of a larger 3D volume. Particularly, a probe defines a sub-set that is less than the complete data set of voxels for a 3D volume data set. A probe could be configured to be equal to or coextensive with the complete data set of voxels for a 3D volume data set, but the functionality of the present invention is best carried out when the probe corresponds to a sub-volume and defines a sub-set that is less than the complete data set of voxels for a 3D volume data set. For example, a 3D volume data set of seismic data can contain from about 500 MB (megabytes) to about 10 GB (gigabytes) or more of data. A 2,500 square kilometer geographic space of typical 3D seismic data contains about 8 GB of data. A probe of the present invention for a 500 MB seismic data set would preferably contain about 10\u201320 MB of data.","By using probes that are a sub-volume of the larger 3D volume, the quantity of data that must be processed and re-drawn for each frame of an image is dramatically reduced, thereby increasing the speed with which the image can be re-drawn. The volume of a three-dimensional cube is proportional to the third power or \u201ccube\u201d of the dimensions of the three-dimensional cube. Likewise, the quantity of data in a 3D volume data set is proportional to the third power or \u201ccube\u201d of its size. Therefore, the quantity of data in a sub-volume of a larger 3D volume will be proportional to the \u201ccubed root\u201d (\u221a) of the quantity of data in the larger 3D volume. As such, the quantity of data in a probe of the present invention will be proportional to the \u201ccubed root\u201d (\u221a) of the quantity of data in the 3D volume of which it is a sub-volume. By only having to process the sub-set of data that relates to the sub-volume of the probe, the present invention can re-draw an image in response to user input at a rate sufficiently fast that the user perceives an instantaneous or real-time change in the image, without perceptible delay or lag.","The probes of the present invention can be interactively changed in shape and\/or size, and interactively moved within the larger 3D volume. The outside geometry or surfaces of a probe can be interactively drawn opaque or texture mapped while the probe is being changed in shape and\/or size or while the probe is being moved. The probe can be drawn or volume rendered with varying degrees of transparency while the probe is being changed in shape and\/or size or moved, thereby revealing the internal structures or features of the probe.","The 3D sampling probes of the present invention can have any shape, including rectangular shapes having one or more right angles and non-rectangular shapes having no right angles. The 3D sampling probes of the present invention can have orthogonal or perpendicular planes as outer surfaces (e.g., squares and rectangles), parallel planes as outer surfaces (e.g., parallelograms), or curved outer surfaces (e.g., spheres, ovals, or cylinders). The present invention is not limited to 3D sampling probes of any particular shape. The 3D sampling probes of the present invention can have arbitrary shapes, such as the shape of a geologic feature identified by a user. For example, as a user moves the 3D sampling probe through a 3D volume of seismic data, a geologic feature may be visualized and identified by the user. The 3D sampling probe can be interactively re-shaped by the user to match the shape of the geologic feature, thereby enabling the user to better visualize and define the extent of that geologic feature.","A probe can be used to cut into another probe, and the intersection of the two probes can be imaged. A probe can be used to highlight data in accordance with a seed selection algorithm. A probe can also be used to \u201cerase\u201d or delete data in accordance with a seed de-selection algorithm. These attributes will be explained in more detail below.",{"@attributes":{"id":"p-0091","num":"0090"},"figref":"FIG. 2","b":["110","110","210","220","230","240","210","220","212","220","230","222","210","230","214","210","240","216"]},"Voxel data from data volume  is transferred to VSM  via data pathway . VSM  transfers data to GPM  via data pathway . Data volume  stores the 3D volume data set in a manner well known to one of skill in the relevant art. For example, the format for data volume  can consist of two parts, a volume header followed by the body of data that is as long as the size of the data set. The volume header typically contains information, in a prescribed sequence, such as the file path (location) of the data set, size, dimensions in the x, y, and z directions, annotations for the x, y, and z axes, annotations for the datavalue, etc. The body of data is a binary sequence of bytes, one or more bytes per data value, that can be ordered in the following manner. The first byte is the datavalue at volume location (x, y, z)=(0,0,0). The second byte is the datavalue at volume location (1,0,0), the third byte is the datavalue at volume location (2,0,0), etc. When the x dimension is exhausted, then the y dimension is incremented, and finally the z dimension is incremented. The present invention is not limited in any way to a particular data format for data volume .","User Interface Module  handles the user interface to receive commands, instructions, and input data from the user. UIM  interfaces with the user through a variety of menus through which the user can select various options and settings, either through keyboard selection or through one or more user-manipulated input devices, such as a \u201cmouse\u201d, or a 3D pointing device. UIM  receives user input as the user manipulates the input device to move, size, shape, etc. a 3D sampling probe.","The primary functions carried out by UIM  will now be described. UIM  inputs from the user the identification of one or more 3D volume data sets (represented by data volume ) to use for imaging and analysis. When a plurality of data volumes are used, the datavalue for each of the plurality of data volumes represents a different physical parameter or attribute for the same geographic space. By way of example, a plurality of data volumes could include a geology volume, a temperature volume, and a water-saturation volume. The voxels in the geology volume can be expressed in the form (x, y, z, seismic amplitude). The voxels in the temperature volume can be expressed in the form (x, y, z, \u00b0 C.).","The voxels in the water-saturation volume can be expressed in the form (x, y, z, % saturation). The physical or geographic space defined by the voxels in each of these volumes is the same. However, for any specific spatial location (x, y, z), the seismic amplitude would be contained in the geology volume, the temperature in the temperature volume, and the water-saturation in the water-saturation volume.","UIM  inputs from the user information to create one or more 3D sampling probes. Such information includes size, shape, and initial location of the probe. Such information can also include imaging attributes such as color, lighting, shading, and transparency (or opacity). By adjusting opacity as a function of datavalue, certain portions of the data volume are more transparent, thereby allowing a viewer to see through surfaces. An exemplary opacity curve  is shown in . Opacity curve  illustrates opacity (1-transparency) as a function of datavalue. As would be readily apparent to one skilled in the art, datavalues with greater opacity (less transparency) will mask the imaging or display of datavalues with lower opacity (more transparency). Conversely, datavalues will less opacity and greater transparency will permit the imaging or display of datavalues with greater opacity and lower transparency.","UIM  receives input from the user for sizing and shaping the 3D sampling probes. As described in more detail below, in a preferred embodiment of the present invention, the user changes the shape and\/or size of a probe by clicking onto \u201csizing tabs\u201d on the probe, and making changes in the dimensions of the probe in one or more directions. UIM  receives input from the user to move the position or location of a 3D sampling probe within the data volume. In a preferred embodiment, a user manipulates a mouse to \u201cclick\u201d onto a surface of the probe to be moved, and then moves the mouse to move the probe throughout the geographic space defined by the data volume.","UIM  receives input from the user to carry out \u201cauto picking\u201d processes. In an auto picking process, data points (voxels) are selected based upon a selection algorithm. In a preferred embodiment, the selection algorithm is based upon a seed point within the 3D data volume. The selection algorithm then selects data points that: (i) satisfy the selection criteria or algorithm (e.g., have a datavalue within a specified filter range); and (ii) have a connectivity with or are connected to the seed point. Through UIM , the user is prompted to identify a seed point within the 3D volume, and to identify a filter range of datavalues used by the selection algorithm to \u201cpick\u201d the selected points. Preferably, the seed point is within one of the 3D sampling probes.","UIM  also receives input from the user regarding the content of the displayed image. For example, the user can preferably select the content of the displayed image. The content of the displayed image could include only the 3D sampling probe, i.e., its intersection with the 3D volume. Additionally, the 3D sampling probe could be displayed either with or without a bounding box that defines the outer geometry of the probe. Alternatively, the displayed image could include the 3D sampling probe, as well as the data that occupies the background xz, yz, and xy planes, and\/or the data that occupies the 3D volume outside of the 3D sampling probe(s) being displayed.","To carry out the foregoing functions, UIM  sends a request to Volume Sampling Module  to load or attach those 3D volume data sets identified by the user. UIM  communicates via pathway  with Graphics Processing Module  that carries out the display and imaging.","The primary functions carried out by GPM  will now be described. GPM  processes data for imaging of 3D sampling probes with the color, lighting, shading, transparency, and other attributes selected by the user. To do so, GPM  uses the functions available through basic graphics library  and visual simulation graphics library  described above. The user can select (through UIM ) to display only the one or more 3D sampling probes that have been created. Alternatively, the user can select to display one or more 3D sampling probes, as well as the 3D data volume outside of the probes, i.e. voxels within the 3D volume that do not intersect any of the 3D sampling probes that are being displayed. 3D sampling probes that are being displayed are referred to herein as \u201cactive probes\u201d.","GPM  processes the re-shaping and move requests that are received by UIM  from the user. GPM  draws the re-shaped 3D sampling probe in accordance with the user-selected attributes (color, lighting, shading, transparency, etc.). As the user inputs a change in shape for a 3D sampling probe, the image with selected attributes is re-drawn sufficiently fast to be perceived as real-time by the user. Similarly, GPM  draws the 3D sampling probe in the new position or location in accordance with the user-selected attributes (color, lighting, shading, transparency, etc.). As the user moves the 3D sampling probe through the 3D volume, the image of the 3D sampling probe with selected attributes is re-drawn sufficiently fast to be perceived as real-time by the user.","GPM  processes \u201cauto picking\u201d requests that are received by UIM . GPM  will image selected points within the 3D volume in accordance with the selection algorithm. Alternatively, GPM  will \u201cerase\u201d selected points within the 3D volume in accordance with the selection algorithm.","To carry out the foregoing functions, GPM  communicates via pathway  with UIM  so that the information requested by the user is imaged or displayed with the selected attributes. GPM  obtains the needed data from data volume  by sending a data request via pathway  to Volume Sampling Module (VSM) .","The primary function of VSM  is to extract the appropriate data from data volume  at the request of GPM . VSM  receives requests for data from GPM  via pathway . VSM  extracts the required data from data volume  and transfers the data to GPM  via data pathway  for processing and display. VSM  also receives instructions from UIM  via pathway  to load or attach the 3D data volumes identified by the user.","Turning now to , a flow diagram  illustrating one embodiment for implementing the present invention is shown. A start up or initialization process is shown in a step . In step , the user specifies the one or more data volumes () to be used. The specified 3D volume data sets are loaded from disk into main memory (a description of hardware suitable for carrying out the present invention will be described in more detail below). A default 3D sampling probe is created, and drawn. The default 3D sampling probe is a sub-volume of the specified 3D volume(s) of arbitrary size and shape. The present invention is not limited to any particular size or shape for the default 3D sampling probe.","By way of example of the present invention, the default 3D sampling probe can be a square (having equal dimensions in the x, y, and z directions). To draw the square default 3D sampling probe, the bounding geometry is first drawn with one edge of the bounding geometry located on the z axis. Data is then extracted from data volume  by VSM  to draw the image of the intersection of the square default 3D sampling probe with the 3D volume (data volume ). Particularly, data is extracted that corresponds to the intersection of the square default 3D sampling probe with the 3D volume in the xz, yz, and xy planes. This data is then sent by VSM  to GPM  so that it can be texture mapped onto the planes of the bounding box to provide an image of the square default 3D sampling probe.","In one embodiment of the present invention, the data that occupies the background xz, yz, and xy planes themselves, as well as the data that occupies the 3D volume outside of the default 3D sampling probe, are also imaged or displayed (in addition to the default 3D sampling probe) during start up step . Alternatively, start up step  can be carried out so that the data that occupies the background xz, yz, and xy planes, or the data that occupies the 3D volume outside of the default 3D sampling probe, is not displayed or imaged. Preferably, the present invention is carried out so that the user can selectively display, or not display, the data that occupies the background xz, yz, and xy planes, as well as the data that occupies the 3D volume outside of the active probes.","In a step , UIM  is waiting to respond to user input or request. User input is received through a user input device suitable for use with a computer, including but not limited to, a keyboard, mouse, joystick, trackball, rollerball, roller point, or other type of suitable pointing device, etc. Preferably, the user input device comprises a mouse or other similar device that enables the user to \u201cclick\u201d on a particular displayed image, and \u201cdrag\u201d that displayed image to another location. Such a user input device allows a user to move and re-shape displayed probes. Such a user input device also allows a user to activate drop-down menus, and to select the various options for the color, shading, lighting, and transparency attributes. A keyboard can also be used for entering information relating to the selected attributes.","Reference numeral  refers generally to a plurality of functions that can be carried out by the present invention. These functions can be carried out individually or simultaneously, depending upon input from the user. For example, a probe can be moved (function ) and rotated (function ) simultaneously. While the functions identified by reference numeral  are being carried out, the image of the 3D sampling probes is being re-drawn sufficiently fast to be perceived as real-time by the user. Each of the functions identified by reference numeral  will now be described.","If a user wants to change the default probe, then function  is carried out. The steps for carrying out function  are shown in  by way of flow diagram connector A. In a step , the changes to the default probe are input by UIM  from the user. For example, the changes to the default probe can be to the shape or size, the location, or the attributes such as color, shading, lighting, and transparency.","In a step , UIM  sends a request to GPM  to draw the changed default probe. In a step , GPM  requests data for the changed default probe from VSM . In making this request, GPM  would invoke function  if it was necessary to move the default probe, function  to re-shape the default probe, and functions  or  to rotate the default probe. The foregoing functions will be described in more detail below.","The data that will be extracted from data volume  by VSM  in response to the request made by GPM  in step  will depend upon attributes that have been selected by the user. If the opacity settings selected by the user are such that all datavalues are opaque, then the data extracted by VSM  will be limited to the surfaces of the changed default probe. Because of the selected opacity, it will not be possible for the user to see inside the changed default probe, so only the data corresponding to the surfaces or outside of the changed default probe will be extracted by VSM . In a step , GPM  processes the data extracted by VSM  for the surfaces of the changed default probe, and draws the changed default probe by texture mapping onto the surfaces in accordance with the attributes selected by the user. By extracting only the data that can be seen by the user, the image of the changed default probe can be drawn more quickly because less data needs to be processed, i.e., the data corresponding to the \u201cinside\u201d of the changed default probe is not processed.","Alternatively, if the opacity settings selected by the user are such that some of the datavalues are opaque and some of the datavalues are transparent, then the data extracted by VSM  will include the data corresponding to the entire volume of the changed default probe. Because of the selected opacity and transparency, it will be possible for the user to see inside the changed default probe, so data corresponding to the entire volume of the changed default probe will be extracted by VSM . In such a situation, GPM  processes the data extracted by VSM  in step , and draws the changed default probe by volume rendering in accordance with the attributes selected by the user.","If a user wants to create additional probes, then function  is carried out. The present invention is not limited to any particular number of active probes. The steps for carrying out function  are shown in  by way of flow diagram connector A. In a step , the shape, size, location, attributes, etc. for the additional probes are input by UIM  from the user. In a step , UIM  sends a request to GPM  to draw the additional probes.","In a step , GPM  requests data for the additional probes from VSM . In a manner similar to that described above for changing the default probe, the data that is extracted from 3D or data volume  by VSM  will depend upon the opacity selected by the user for the additional probes. If the opacity settings selected by the user are such that all datavalues for the additional probes are opaque, then the data extracted by VSM  will be limited to the surfaces of the additional probes. Alternatively, if the opacity settings selected by the user for the additional probes are such that some of the datavalues are opaque and some of the datavalues are transparent, then the data extracted by VSM  will include the data corresponding to the entire volumes of the additional probes. In this manner, the additional probes can be drawn more quickly by minimizing the quantity of data that must be processed.","In a step , GPM  processes the data extracted by VSM  for the additional probes, and draws the additional probes in accordance with the attributes selected by the user, either by texture mapping onto the surfaces of the additional probes, or by volume rendering the entire volume of the additional probes.","If a user wants to move a probe, then function  is carried out. The steps for carrying out function  are shown in  by way of flow diagram connector A. In a step , the new location for the probe is input by UIM  from the user. In a preferred embodiment of the present invention, the user inputs the new location of the probe by clicking a mouse or other type of suitable user input device to snap a pointer onto a surface of the probe to be moved. The user changes the location of the probe by moving the mouse or other suitable user input device in any direction, thereby dragging the probe along a trajectory.","In a step , UIM  sends a move request to GPM  to draw the probe at the new location. GPM  requests data for the new location of the probe from VSM . In a manner similar to that described above the data that is extracted from data volume  by VSM  will depend upon the opacity selected by the user for the probe being moved. If the opacity settings selected by the user are such that all datavalues for the probe being moved are opaque, then the data extracted by VSM  will be limited to the surfaces of the probe being moved. Alternatively, if the opacity settings selected by the user for the probe being moved are such that some of the datavalues are opaque and some of the datavalues are transparent, then the data extracted by VSM  will include the data corresponding to the entire volume of the probe being moved. In this manner, the probe can be drawn at its new location more quickly by minimizing the quantity of data that must be processed.","In a step , GPM  processes the data extracted by VSM  for the probe being moved, and draws the probe at its new location in accordance with the attributes selected by the user, either by texture mapping onto the surfaces of the probe being moved, or by volume rendering the entire volume of the probe being moved.","As the user moves the probe, for each new location of the probe, steps  through  are repeated at a rate sufficiently fast that the user perceives the image of the probe, with texture mapping or volume rendering as appropriate, changing in \u201creal-time\u201d with movement of the probe. The image is being re-drawn at a frame rate sufficiently fast to be perceived as real-time by the user.","If a user wants to re-shape a probe, then function  is carried out. As used herein, the term \u201cre-shape\u201d refers to any change in dimension of a 3D sampling probe in any direction. The shape of a 3D sampling probe can be changed, or re-shaped, for example, by changing the size in one or more directions, such as by changing a square probe into a rectangular probe by increasing the size of the probe in the x direction, and decreasing the size of the probe in the y direction. As another example, the shape of a 3D sampling probe can be changed by changing the shape from spherical to rectangular. As yet another example, a square 3D sampling probe (equal dimensions in the x, y, and z directions) can be re-shaped in accordance with the present invention to be a larger or smaller square-shaped probe by changing the size equally in each of the x, y, and z directions. The re-shaped probe also has a square shape, but as a larger or smaller square.","The steps for carrying out function  are shown in  by way of flow diagram connector A. In a step , the new shape and\/or size for the probe is input by UIM  from the user. In a preferred embodiment of the present invention, the user inputs the new shape of a probe by clicking a mouse or other type of suitable user input device to snap a pointer onto a \u201csizing tab\u201d of the probe to be re-shaped. As used herein, a \u201csizing tab\u201d refers to a designated area on a surface of the probe. Such a designated area is preferably displayed in a color that is different from the colors being used to display the features or physical parameters of the 3D volume data set. When the pointer is snapped to the sizing tab, manipulation of the mouse or user input device changes the dimensions or proportions of the surface on which the sizing tab is located. When the desired size or shape is reached, the user again clicks the mouse or user input device to release the pointer from the sizing tab. Sizing tabs are illustrated in . The sizing tabs are the small dark squares that appear on the surfaces of the probes, along the bounding geometry of the probes. The location of the sizing tabs is not limited to the bounding geometry of the probes. The user changes the shape of the probe by clicking the mouse or other suitable user input device onto a sizing tab, moving the mouse until the surface being changed has the desired shape, and then releasing the mouse from the sizing tab. This process can be repeated, if necessary, using other sizing tabs on the probe until the probe is re-shaped to the desired shape.","It would be readily apparent to one of skill in the relevant art how to implement such a sizing tab for re-shaping the probes of the present invention. It is to be understood, however, that the present invention is not limited to the use of sizing tabs for re-shaping probes, and other suitable methods can be used. For example, the user could select from a number of pre-set shapes (e.g., squares, rectangle, cylinders, spheres) by activating a drop-down menu, or by scrolling through the shapes by repeatedly clicking a mouse.","In a step , UIM  sends a re-shape request to GPM  to draw the re-shaped probe. In a step , it is determined whether more data is needed to draw the re-shaped probe. For example, if the re-shaped probe is of a shape and size that \u201cfits inside\u201d the existing probe, then no more data is needed, and processing continues at a step . Alternatively, if the re-shaped probe is of a shape and size that falls at least partially outside of the existing probe, then, in a step , GPM  requests the data needed for the re-shaped probe from VSM . In a manner similar to that described above, the data that is extracted from 3D or data volume  by VSM  will depend upon the opacity selected by the user for the probe being re-shaped. If the opacity settings selected by the user are such that all datavalues for the probe being re-shaped are opaque, then the data extracted by VSM  will be limited to the surfaces of the probe being re-shaped. Alternatively, if the opacity settings selected by the user for the probe being re-shaped are such that some of the datavalues are opaque and some of the datavalues are transparent, then the data extracted by VSM  will include the data corresponding to the entire volume of the probe being re-shaped. In this manner, the probe can be drawn with its new shape more quickly by minimizing the quantity of data that must be processed.","In step , GPM  processes the data extracted by VSM  for the probe being re-shaped, and draws the probe with its new shape in accordance with the attributes selected by the user, either by texture mapping onto the surfaces of the probe being re-shaped, or by volume rendering the entire volume of the probe being re-shaped.","As the user changes the shape of the probe, steps  through  are repeated at a rate sufficiently fast that the user perceives the image of the probe, with texture mapping or volume rendering as appropriate, changing in \u201creal-time\u201d with the changing shape of the probe. The image is being re-drawn at a frame rate sufficiently fast to be perceived as real-time by the user.","If a user wants to rotate a probe in 3D space, then function  is carried out. In function , the 3D orientation, which is the same for both the 3D volume and the probe, is changed, thereby rotating the 3D volume and the probe in space. The steps for carrying out function  are shown in  by way of flow diagram connector A. In a step , the new 3D orientation for the 3D volume and the probe is input by UIM  from the user. In a preferred embodiment of the present invention, the user inputs the new orientation by clicking a mouse or other type of suitable user input device to snap a pointer onto an axis of the probe to be rotated. Manipulation of the mouse or user input device changes the orientation of that axis. When the desired orientation is reached, the user again clicks the mouse or user input device to release the pointer from the axis. It would be readily apparent to one of skill in the relevant art how to implement such a change in orientation. It is to be understood, however, that the present invention is not limited to changing the orientation in this manner. For example, the user could select from a number of pre-set rotations (e.g., rotate 90\u00b0 to the left or right; rotate 45\u00b0 to the left or right, etc.) by activating a drop-down menu, or by scrolling through the rotations by repeatedly clicking a mouse.","In a step , UIM  sends a request to rotate in 3D space to GPM  to draw the rotated probe. In a step , GPM  requests data for the rotated probe from VSM . In a manner similar to that described above, the data that is extracted from 3D or data volume  by VSM  will depend upon the opacity selected by the user for the probe being rotated. If the opacity settings selected by the user are such that all datavalues for the probe being rotated are opaque, then the data extracted by VSM  will be limited to the surfaces of the probe being rotated. Alternatively, if the opacity settings selected by the user for the probe being rotated are such that some of the datavalues are opaque and some of the datavalues are transparent, then the data extracted by VSM  will include the data corresponding to the entire volume of the probe being rotated. In this manner, the probe can be drawn with its new orientation more quickly by minimizing the quantity of data that must be processed.","In step , GPM  processes the data extracted by VSM  for the probe being rotated, and draws the probe with its new orientation in accordance with the attributes selected by the user, either by texture mapping onto the surfaces of the probe being rotated, or by volume rendering the entire volume of the probe being rotated.","As the user rotates the probe in 3D space, steps  through  are repeated at a rate sufficiently fast that the user perceives the image of the probe, with texture mapping or volume rendering as appropriate, changing in \u201creal-time\u201d with the changing orientation of the probe. The image is being re-drawn at a frame rate sufficiently fast to be perceived as real-time by the user.","If a user wants to rotate a probe while it is fixed in 3D space, then function  is carried out. In function , the 3D orientation of the probe is rotated independently of the 3D orientation of the 3D volume, thereby rotating the probe while it is fixed in the 3D space defined by the orientation of the 3D volume. In this manner, the background planes for an active probe can be displayed in a fixed orientation, and the active probe can be rotated within the background planes.","The steps for carrying out function  are shown in  by way of flow diagram connector A. In a step , the new 3D orientation for the probe is input by UIM  from the user. In a preferred embodiment of the present invention, the user selects the option to rotate while fixed in space, for example, from a \u201cdrop-down\u201d menu. The user then inputs the new orientation for the probe by clicking a mouse or other type of suitable user input device to snap a pointer onto an axis of the probe to be rotated. Manipulation of the mouse or user input device changes the orientation of that axis. When the desired orientation is reached, the user again clicks the mouse or user input device to release the pointer from the axis. It would be readily apparent to one of skill in the relevant art how to implement such a change in orientation. It is to be understood, however, that the present invention is not limited to changing the orientation in this manner. For example, the user could select from a number of pre-set rotations (e.g., rotate 90\u00b0 to the left or right; rotate 45\u00b0 to the left or right, etc.) by activating a drop-down menu, or by scrolling through the rotations by repeatedly clicking a mouse.","In a step , UIM  sends a request to rotate while fixed in space to GPM  to draw the rotated probe. In a step , GPM  requests data for the rotated probe from VSM . In a manner similar to that described above, the data that is extracted from 3D or data volume  by VSM  will depend upon the opacity selected by the user for the probe being rotated. If the opacity settings selected by the user are such that all datavalues for the probe being rotated are opaque, then the data extracted by VSM  will be limited to the surfaces of the probe being rotated. Alternatively, if the opacity settings selected by the user for the probe being rotated are such that some of the datavalues are opaque and some of the datavalues are transparent, then the data extracted by VSM  will include the data corresponding to the entire volume of the probe being rotated. In this manner, the probe can be drawn with its new orientation more quickly by minimizing the quantity of data that must be processed.","In step , GPM  processes the data extracted by VSM  for the probe being rotated, and draws the probe with its new orientation in accordance with the attributes selected by the user, either by texture mapping onto the surfaces of the probe being rotated, or by volume rendering the entire volume of the probe being rotated.","As the user rotates the probe while it is fixed in space, steps  through  are repeated at a rate sufficiently fast that the user perceives the image of the probe, with texture mapping or volume rendering as appropriate, changing in \u201creal-time\u201d with the changing orientation of the probe. The image is being re-drawn at a frame rate sufficiently fast to be perceived as real-time by the user.","If a user wants to carry out an \u201cauto picking\u201d process, then function  is carried out. The steps for carrying out function  are shown in  by way of flow diagram connector A. In a step , a seed point within the data set of the 3D volume, and a selection criteria based on datavalues, are input by UIM  from the user. Preferably the seed point is within the data set of voxels that defines a probe. As described below, such a probe is referred to herein as a seed 3D sampling probe or an eraser 3D sampling probe. However, the seed point can be within the data set of voxels that defines the 3D volume, outside of an active probe. In a preferred embodiment of the present invention, the user selects the option to execute an auto picking process, for example, from a \u201cdrop-down\u201d menu. The user then selects the seed point by clicking a mouse or other type of suitable user input device to snap a pointer onto the desired seed point. The selection criteria can be input, for example, by graphically selecting a range, or by keying in specific numerical values. It would be readily apparent to one of skill in the relevant art how to input from the user a seed point and filter range of datavalues.","In a step , UIM  sends an auto picking request to GPM  to draw the rotated probe. In a step , GPM  requests selected points to image from VSM . The selected points are those that are connected to the seed point, and that have a datavalue within the selection criteria.","In step , GPM  processes the data extracted by VSM  to draw the selected points. The selected points are preferably highlighted by being drawn in a color different from those used to depict the features or physical parameters of the 3D volume data set. Alternatively, step  can be carried out to \u201cerase\u201d or delete from the image the selected points.","In a similar manner, auto picking function  can be used to \u201cerase\u201d or de-select points. For example, an eraser 3D sampling probe is defined, such as by invoking function  to create an additional probe. A \u201cde-selection\u201d criteria based on datavalues is defined. Points previously selected by an auto picking operation that satisfy the de-selection criteria are identified as candidates for de-selection. As the eraser 3D sampling probe moves through the 3D volume, the de-selected points are deleted from the image, and the image is re-drawn sufficiently fast to be perceived as real-time by the user.","Once auto picking function  is initiated by the user, it can be carried out simultaneously with, for example, move function . In this manner, as the user moves the probe, steps  through  (and steps  through ) are repeated at a rate sufficiently fast that the user perceives the image of the probe, with the selected points, changing in \u201creal-time\u201d with the changing location of the probe. As the probe is moved, the selected points can be highlighted by being drawn in a suitable color, thereby having the auto-picking 3D sampling probe function as a \u201chighlighter\u201d as it moves through the 3D volume. Alternatively, as the probe is moved, points previously selected by an auto picking operation can be \u201cerased\u201d or deleted from the image, thereby having the probe function as an \u201ceraser\u201d or eraser 3D sampling probe as it moves through the 3D volume. In either embodiment, the image is being re-drawn at a frame rate sufficiently fast to be perceived as real-time by the user.","If a user wants to create a \u201cribbon section,\u201d then function  is performed. The steps necessary for performing function  are described further below in reference to  and by way of block diagram connector A in .","If a user wants to create a \u201c3D surface\u201d representative of a physical phenomena found within a 3D volume data set, then function  is performed. The steps necessary for performing function  are described further below in reference to  and by way of block diagram connector A in .","In any event where a user desires to carry out one or more of the functions described above such as more probe (), re-shape probe (), create a ribbon section () and create a 3D surface (), each function can be performed independent of, or in connection with, one or more of the other functions.","With reference now to , one embodiment of a computer system suitable for use with the present invention is shown. A graphics supercomputer  contains one or more central processing units (CPU) or processors . Supercomputer  contains a random access memory (RAM)  that can be accessed by processors . Supercomputer  also contains one or more graphics modules  that also access RAM . Graphics modules  execute the functions carried out by Graphics Processing Module , using hardware (such as specialized graphics processors) or a combination of hardware and software. A user input device  allows a user to control and input information to graphics supercomputer .","A particularly preferred graphics supercomputer is an Onyx2 Infinite Reality system, available from Silicon Graphics, Inc., Mountain View, Calif., configured with eight processors, three graphics pipelines, 16 GB of main memory, and 250 GB of disk memory. Such a graphics supercomputer has a scalable, high-bandwidth, low-latency architecture to provide high speed rendering on multiple graphics pipelines. Graphics supercomputers from other vendors, such as Hewlett-Packard Company of Palo Alto, Calif. or Sun Microsystems of Mountain View, Calif. could also be used.","The graphics data forming the image to be displayed is sent from graphics supercomputer  to a multiple-screen display system  for projection onto a screen . In the embodiment shown in , three projectors are used. From the perspective of a user viewing the image on screen , the three projectors include a left projector , a center projector , and a right projector . Although three projectors are shown, the present invention is not limited to the use of any particular number of projectors.","Projector  has a projection field on screen , shown generally at , between a point  and a point . Projector  has a projection field on screen , shown generally at , between a point  and a point . Projector  has a projection field on screen , shown generally at , between a point  and a point . Projection fields  and  have an overlap region , between points  and . Similarly, projection fields  and  have an overlap region , between points  and . The image to be displayed is divided into three (left, center, and right) over-lapping sub-images. By simultaneously projecting the three over-lapping sub-images, the field-of-view to the user is increased over that available, for example, on a monitor or through the use of just one projector. As an example, use of the three over-lapping sub-images shown in  increases the field-of-view to approximately 160\u00b0. Overlap regions  and  are each approximately 5.3\u00b0. Multiple-screen display system  accounts for overlap regions  and  in a well-known manner to edge-blend the images of the three projectors to form one seamless image on screen . Suitable display and projector systems are available from SEOS, London, England, such as the Barco projector units.",{"@attributes":{"id":"p-0149","num":"0148"},"figref":["FIG. 13","FIG. 13","FIG. 13","FIGS. 15 and 16","FIG. 13"],"b":["1210","1212","1214","1216","1216","1320","1320","1320","1320","110","1330","1332"]},"A computer system capable of carrying out the functionality described herein is shown in more detail in . Computer system  includes one or more processors, such as processor . Processor  is connected to a communication bus . Various software embodiments are described in terms of this exemplary computer system. After reading this description, it will become apparent to a person skilled in the relevant art how to implement the invention using other computer systems and\/or computer architectures.","Computer system  also includes a main memory , preferably random access memory (RAM), and can also include a secondary memory . Secondary memory  can include, for example, a hard disk drive  and\/or a removable storage drive , representing a floppy disk drive, a magnetic tape drive, an optical disk drive, etc. Removable storage drive  reads from and\/or writes to a removable storage unit  in a well known manner. Removable storage unit , represents a floppy disk, magnetic tape, optical disk, etc. which is read by and written to by removable storage drive . As will be appreciated, removable storage unit  includes a computer usable storage medium having stored therein computer software and\/or data.","In alternative embodiments, secondary memory  may include other similar means for allowing computer programs or other instructions to be loaded into computer system . Such means can include, for example, a removable storage unit  and an interface . Examples of such can include a program cartridge and cartridge interface (such as that found in video game devices), a removable memory chip (such as an EPROM, or PROM) and associated socket, and other removable storage units  and interfaces  which allow software and data to be transferred from removable storage unit  to computer system .","Computer system  can also include a communications interface . Communications interface  allows software and data to be transferred between computer system  and external devices. Examples of communications interface  can include a modem, a network interface (such as an Ethernet card), a communications port, a PCMCIA slot and card, etc. Software and data transferred via communications interface  are in the form of signals  that can be electronic, electromagnetic, optical or other signals capable of being received by communications interface . Signals  are provided to communications interface via a channel . Channel  carries signals  and can be implemented using wire or cable, fiber optics, a phone line, a cellular phone link, an RF link and other communications channels.","In this document, the terms \u201ccomputer program medium\u201d and \u201ccomputer usable medium\u201d are used to generally refer to media such as removable storage device , a hard disk installed in hard disk drive , and signals . These computer program products are means for providing software to computer system .","Computer programs (also called computer control logic) are stored in main memory  and\/or secondary memory . Computer programs can also be received via communications interface . Such computer programs, when executed, enable computer system  to perform the features of the present invention as discussed herein. In particular, the computer programs, when executed, enable processor  to perform the features of the present invention. Accordingly, such computer programs represent controllers of computer system .","In an embodiment where the invention is implemented using software, the software may be stored in a computer program product and loaded into computer system  using removable storage drive , hard drive  or communications interface . The control logic (software), when executed by processor , causes processor  to perform the functions of the invention as described herein.","In another embodiment, the invention is implemented primarily in hardware using, for example, hardware components such as application specific integrated circuits (ASICs). Implementation of such a hardware state machine so as to perform the functions described herein will be apparent to persons skilled in the relevant art(s).","In yet another embodiment, the invention is implemented using a combination of both hardware and software.","The operation and results of the present invention will now be described, using a data volume  that contains seismic data (datavalues representing seismic amplitudes). The user specifies the particular seismic data volume to be used, which is loaded from disk into main memory. A default 3D sampling probe is drawn. The user specifies the colors to be used for the seismic amplitudes. The degree of transparency can also be selected. The three probes shown in  are all opaque, with the intersection of the probes and the seismic data volume texture mapped onto the surfaces of the probes. One of the probes is displayed with the bounding geometry shown; the other two probes are displayed without the bounding geometry.",{"@attributes":{"id":"p-0160","num":"0159"},"figref":["FIG. 15","FIG. 15"]},{"@attributes":{"id":"p-0161","num":"0160"},"figref":["FIG. 16","FIG. 15","FIG. 16","FIG. 16","FIG. 16"]},"A third active probe is shown in . The third probe is displayed with the bounding geometry shown. The third probe is volume rendered with varying degrees of transparency so that the user can see through the outer surfaces of the probe and view geologic features within the third probe. As shown in , the third probe is volume rendered partially within the 3D sub-section of the data probe that has been cut away by the cut probe.","The third volume-rendered probe shown in  also contains selected points that have been selected through a seed picking process (function ). The selected points have been imaged in a manner to highlight them for the user. The selected points are shown in  as connecting points. The seed point is illustrated in  by the darker sphere.",{"@attributes":{"id":"p-0164","num":"0163"},"figref":"FIG. 17","b":["1710","1712","1714","1710","1716","1718","1720"]},"The control points may be used to produce a plurality of line segments such as line segments , , and , which collectively are referred to as polyline  which is like a polygon but may or may not be closed. Therefore, the line segments may form an open or closed line so that a single or multiple cookie planes may be produced. In a preferred embodiment, the area of data display, i.e. the cookie planes, is projected along a direction perpendicular to the probe face plane and the data displayed may extend to an opposing face of the probe referred to as the \u201copposing probe face plane.\u201d After creating a ribbon section, the user may use the mouse controls or keyboard to select, move, drag, or grab the control points to edit the ribbon section  in real time and display different data from the 3D volume data set along the cookie planes  and . In addition to editing the ribbon section  to view different data from the 3D volume data set within the probe, the entire ribbon section  and probe may be simultaneously moved to a different position in order to view different data from the 3D volume data set outside the boundaries of the probe at its prior position. Active control point  is preferably high-lighted or colored differently as compared to the other control points to indicate control point  is in an active state for operations such as moving, deleting, or otherwise editing as discussed further below. Control points may be inserted or deleted after the initial ribbon section construction. The ribbon section geometry and orientation may also be saved for future work sessions.",{"@attributes":{"id":"p-0166","num":"0165"},"figref":"FIG. 18","b":["1810","1822","1728","1822","1824","1810"]},"Cookie manager  manages the user input data supplied by probe . Cookie manager  distributes the data, e.g. control points add, move, and delete as appropriate to both polyline module  and cookie plane module . For some types of data, such as inserting a control point, cookie manager  receives data from polyline module  and passes the data to cookie plane module .","Polyline module  manages data related to polyline  and the associated control points in conjunction with polymarker module  and polystate module . Polyline  is mainly provided for visual reference. Polyline module  in conjunction with polystate module  manages the state of the control points. For instance, in the active state, a control point can be moved or deleted. The active control point, such as active control point  is preferably highlighted. The control points may be enlarged or decreased in size for easier viewing. Polymarker module  provides visual context such as highlighting or varied colors, for the control points so that an operator knows which point is in the active state for moving, deleting, and otherwise editing. Polymarker module  also may provide text such as the location indication adjacent active control point .","Cookie plane module  provides textured geometry, which may for instance be lithography-related for geological data, to the surface of the cookie planes such as cookie planes  and . Cookie state module  monitors the state of the cookie planes so that in the active state one or more cookie planes can be moved or otherwise edited whereas in the inactive state no changes are made.","During operation of system , probe module  may notify cookie manager  that an event has taken place, e.g., a marker deletion, i.e., a control point deletion. Cookie manager  then notifies polyline module  which deletes the marker or control point and joins up the two surrounding lines into one line and notifies the polymarker module to remove the deleted marker from the list of polymarkers maintained by polymarker module . Cookie manager  and cookie plane module then convert the two planes into one.",{"@attributes":{"id":"p-0171","num":"0170"},"figref":"FIG. 19","b":["1902","1904","1906","1908","1910","1910","1910","1912","1912","1912"]},"Thus, one embodiment of the invention disclosed by  provides a method of rapidly constructing a three-dimensional surface or fault found within a 3-D volume data set. In a preferred embodiment, 3-D probes, as discussed above, are used. The method involves constructing a plurality of spline curves, such as spline curve  on the probe face  which may be interactively constructed when visualizing the data displayed on probe face . Spline curve  is interpolated using an algorithm created in the same way as spline curves , , and  are interpolated. Spline curves and v-curves , , and , are produced to form a grid. The grid outlines the three dimensional surface .","For construction of the initial spline curve, such as for instance spline curve , the user digitizes control points, such as control points , ,  and  on the probe face . Markers are produced at these control points and spline curve  is interpolated between the control points , ,  and . Control points , ,  and  may be moved within probe face , thereby interpolating a new spline curve . Once the probe face  is selected, the other probe surfaces are made transparent for ease of operation. Additionally, the selected probe face  may be made opaque in order to view surface  through the probe face .","The user then moves the probe face to  to another position and selects new control points. The user may easily move back and forth between previously created spline curves by selecting grid intersections such as intersection  or . As additional spline curves are created, the v-curves may also be smoothly and quickly interpolated using another algorithm. The user preferably creates a plurality of spline curves in the same manner, and interpolation of surface  is immediately displayed at real time frame rates as discussed here above.","The user may stop the probe and move one or more control points, such as control points , ,  and  to adjust the position of the respective spline curve such as spline curve . All other spline curve, such as spline curves , , and  remain the same while surface  is smoothly interpolated between the current spline curve  on the probe face  and the prior spline curve . The remainder of the surface  remains the same unless the user moves the prove face  to another spline curve such as  and proceeds to edit the same thereby reshaping the surface  between the current spline curve  on the probe face place  and the prior spline curve .","Additional spline curves may be added between existing spline curves if desired. By selecting grid intersections such as grid intersections  or , or by selecting control points on the probe face, such as control points , ,  and , the user may quickly move the probe face  back and forth as desired. Once a grid intersection is selected, the user may move the respective control points within the probe face  that will be displayed as indicated in , and surface  with its spline curves and v-curves will follow interactively. The spline curves and the v-curves may or may not be displayed depending on preference of the user. Preferably, only one probe face  is displayed at a time for clarity.",{"@attributes":{"id":"p-0177","num":"0176"},"figref":["FIG. 20","FIG. 19","FIG. 19"],"b":["2000","2000","1810","2018","2012","2014","2010","1914","2010","2016","1912","2016","2020","2022","2024","2020","2020","2022","2024"]},"By using the system and method of the present invention, geologists and geophysicists can more quickly and accurately visualize and interpret 3D seismic data. This sharply reduces 3D seismic project cycle time, boosts production from existing fields, and finds more reserves.","While various embodiments of the present invention have been described above, it should be understood that they have been presented by way of example only, and not limitation. Thus, the breadth and scope of the present invention should not be limited by any of the above-described exemplary embodiments, and should be defined in accordance with the spirit of the invention including the following claims and their equivalents."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE FIGURES","p":["The present invention is described with reference to the accompanying drawings. In the drawings, like reference numbers indicate identical or functionally similar elements. Additionally, the left-most digit(s) of a reference number identifies the drawing in which the reference number first appears.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":["FIG. 18","FIG. 17"]},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 20","FIG. 19"]}]},"DETDESC":[{},{}]}
