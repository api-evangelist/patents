---
title: Determining reliability of electronic documents associated with events
abstract: A method of determining reliability of electronic documents associated with an event occurring in connection with a computing device may comprise, with a processor, composing a number of search queries based on text included in an event message, searching for a number of electronic documents via a network, said searching performed based on the composed search queries, and ranking the electronic documents identified by said searching based upon an indication of reliability in addressing the event associated with the event message, in which, ranking the electronic documents comprises applying a content source ranking criteria.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09002830&OS=09002830&RS=09002830
owner: Hewlett-Packard Development Company, L.P.
number: 09002830
owner_city: Houston
owner_country: US
publication_date: 20100712
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","DETAILED DESCRIPTION","Example 1","Example 2"],"p":["As computing devices and systems, and their associated software and middleware component grow in complexity, the generation of events within the computing devices and systems proportionally increase. Events may be described as an occurrence of significance within a computing device or system, and may include completion or failure of an operation, or the change in state of a process within a computing device or system. Thus, events may reflect normal behavior as well as abnormal behavior (errors and outages) within computing devices and systems.","Events are used to alert a user of the current status of the computing devices or systems, and to help troubleshoot problems that may affect performance of the computing devices and systems. These events are often manifested by hardware and software in text form as messages provided to a user.","It is apparent that errors encountered while operating the computing devices or systems are also prevalent in view of the growth in computing technology. This situation is compounded by the fact that these computing devices and systems are continually inundated by viruses, malware, spyware, and other foreign files that slow or halt the computing device's ability to perform processes or otherwise function in an intended manner.","Throughout the drawings, identical reference numbers designate similar, but not necessarily identical, elements.","The various embodiments of the principles described herein provide for a system that automatically collects, ranks, and associates electronic documents describing events, the issues and problems these events represent, and procedures to resolve the events from the various electronic document sources. The various embodiments of the principles described herein may be provided over any kind of network, including an intranet and the Internet. A knowledge database may be compiled based on the ranking and association of electronic documents and events to help users resolve issues faster.","In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the present systems and methods. It will be apparent, however, to one skilled in the art that the present apparatus, systems, and methods may be practiced without these specific details. Reference in the specification to \u201can embodiment,\u201d \u201can example\u201d or similar language means that a particular feature, structure, or characteristic described in connection with the embodiment or example is included in at least that one embodiment, but not necessarily in other embodiments. The various instances of the phrase \u201cin one embodiment\u201d or similar phrases in various places in the specification are not necessarily all referring to the same embodiment.","As used in the present specification and the appended claims, the term \u201cevent\u201d is meant to be understood broadly as any occurrence of significance within a computing device, computing system or associated peripherals, software, firmware, and middleware. Events may include completion or failure of an operation, or the change in state of a process within a computing device or system. Thus, events may reflect normal behavior as well as abnormal behavior (errors and outages) within a computing devices and related systems.","As used in the present specification and the appended claims, the term \u201celectronic document\u201d is meant to be understood broadly as any machine-readable collection of data or one or more objects that represent human-readable information. A electronic document may include, for example, a word processing document, an ADOBE\u00ae portable document file (PDF), a product manual, a discussion string presented on an online forum, a technology support page, a hypertext document, and combinations thereof, among others. These electronic documents may be located at various sources, for example, online forums, blogs, chat rooms, social networks, wikis, an intranet, an internet, the Internet, a memory device, and a knowledge database, among others.","When errors occur in computing devices and systems, the hardware and associated software often display the above-described message to a user that a particular error has occurred. Often, these messages are specific to the type of error encountered. In order to alleviate the encountered error, the user may be inclined to search for a solution to the error. Several potential sources for a solution to the errors encountered exist.","The computing devices and systems and their associated software and peripherals may be sold with product manuals or offer these manuals via the Internet. These product manuals may prove to be helpful in resolving these errors. Further, some major computer manufacturers and software developers provide resources on their respective Internet websites to resolve errors encountered while operating the computing devices and systems. For example, such Internet websites may include MICROSOFT's\u00ae online support page found at http:\/\/support.microsoft.com, MICROSOFT's\u00ae Developer Network found at http:\/\/msdn.microsoft.com\/en-us\/default.aspx, and HEWLETT-PACKARD's\u00ae Support and Troubleshooting webpage found at http:\/\/welcome.hp.com\/country\/us\/en\/support_task.html?pageDisplay=support.","Other sources for solutions to errors encountered in connection with computing devices and systems may include secondary resources. These secondary resources may include the results of discussions or other communications posted on online forums, blogs, chat rooms, social networks, among others. However, it is often time consuming to search for solutions to errors encountered during operation of the computing devices and systems. Further, often times, a user may find a relevant source that discusses the error, but fails to provide a solution. This situation is often encountered when a user searches the above-described secondary resources.","The above resources are located in various decentralized electronic document corpora, and are, therefore, difficult to navigate to and access. Further, when a electronic document is found that may be pertinent to a resolution of the event, a user may find that ultimately, the electronic document was misleading in its resolution, unclear, or did not provide a resolution at all even though it had mentioned the issue surrounding the event.","Turning now to , a diagram of an illustrative system () for associating electronic documents with events, according to one embodiment of principles described herein, is depicted. The system () may include a computing device (), a knowledge database (), and a number of servers (). A network () may be provided so that each of the computing device (), knowledge database (), and server () may electronically communicate. The computing device () may be, for example, any programmable electronic device that receives, stores, and processes data, and outputs the processed data. Thus, the computing device () may be a personal computer, a laptop computer, a desktop computer, a personal digital assistant (PDA), a cellular phone including a smart phone, and a server, among others.","The computing device () may include a processor () for processing instructions of a computer program or other forms of software, and memory (). The memory () may be any volatile or non-volatile memory device including, for example, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor data storage device, a computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, and a portable compact disc read-only memory (CD-ROM), among others.","The memory () stores software () that may be any combination of computer code executable or otherwise processable by the processor (). The software () may include, for example, system software, application software, programming software, middleware, and firmware, among others.","The computing device () may also include a number of peripherals (). The peripherals () may be attached to the computing device () in order to provide a user of the computing device () a greater range of input and output devices. The peripherals () may include, for example, a keyboard, a mouse, a display device, a printer, an image scanner, and a webcam, among others. As stated above, events may occur not only within the computing device () per se, but also in connection with the peripherals () as well. In this manner, the principles described herein may relate to events encountered during the use of the peripherals () as well.","The computing device () may also include a network port () that electronically connects the computing device () with other devices and systems via a network (). The network port () may be any type of hardware, software, or any combination of hardware and software that provides for the transmission of data to and from a device located on a network to the computing device ().","The computing device () may also include a composer (), a searcher (), and a ranker (). These elements work assist in providing association events that occur on the computing device () with electronic documents or other sources of information used to address the events. The composer (), searcher (), and ranker () may exist within the computing device () as hardware, software, or any combination of hardware and software. The function and role of the composer (), searcher (), and ranker () in associating events with electronic documents will be discussed in more detail below.","The system () also includes a network (). The network may be any intranet or internet used to provide communication between two or more computing devices. For example, the network () may be a wide area network, a local area network, a wireless network, a virtual private network, and the Internet, among others. In one exemplary embodiment, the network () is the Internet where access to a vast array of private, public, academic, business, and government networks ranging from local to global scale provides a user with an almost unlimited amount of information resources and services, including the hypertext documents of the World Wide Web (WWW).","The network () provides the computing device () with communication to any number of servers () and a knowledge database (). The servers () may be any number of computing devices located on the network (), and from which the computing device () may obtain information, including electronic documents relating to events, as will be described in more detail below. The knowledge database (), like the memory () of the computing device (), may be any volatile or non-volatile memory device including, for example, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor data storage device, a computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, and a portable compact disc read-only memory (CD-ROM), among others. The knowledge database () stores ranked results of electronic documents that have been associated with events, as will be discussed in more detail below. The knowledge database () may exist as a stand-alone device on the network (), as a device within a server (), or as a part of the computing device ().","Turning now to , a flowchart showing an illustrative method for associating electronic documents with events using the computing device (), the network (), the servers (), and the knowledge database (), according to one embodiment of principles described herein, is depicted. The method depicted in  begins with the manifestation and detection of an event (Step ). The events are text messages displayed by the computing device () when any occurrence of significance within a computing device, computing system or associated peripherals, software, firmware, and middleware takes place. Events may include completion or failure of an operation, or the change in state of a process within a computing device or system, and, thus, may reflect normal behavior as well as abnormal behavior (errors and outages) within a computing devices and systems.","Once the computing device () detects the occurrence of an event, the composer () of the computing device () takes as input, the text of the event (or, in the case of several events, the group of events), and creates a set of search queries (Step ) for the searcher () to search. In one exemplary embodiment, the set of search queries may be ranked, and may range from queries that are constrained to include all words in the text of the event in sequence as they appear in the event message to any number of words within the event message in any order. Thus, the constraints are reduced in subsequent queries. Removal of constraints within the search queries may include, for example, allowing flexibility in word ordering, removal of words that contain numbers or special characters, substitution of words for other words with similar meanings (synonym stemming), substitution of a word with that words root terms (word stemming), and removal of words from the queries, among others.","For example, a common event message encountered in computing systems states, \u201cWindows could not start because the following file is missing or corrupt: <Windows root>\\system32\\hal.dll. Please re-install a copy of the above file.\u201d The underlying error related to this event message occurs if, for example, the Default value in the [Boot Loader] section of the Boot.ini file is missing or invalid or the operating system (e.g. WINDOWS\u00ae XP\u00ae) is not installed in the location specified in the Boot.ini file. However, it will be appreciated that this error message, although common, is simply an example. Any computer error and its associated event message may be applied in the embodiments of principles described herein.","Once the computing device receives the event message, \u201cWindows could not start because the following file is missing or corrupt: <Windows root>\\system32\\hal.dll. Please re-install a copy of the above file,\u201d the composer () composes a number of search queries. The first search query may be constrained to include all words in the text of the event in sequence as they appear in the event message as discussed above. Thus, the first search query will state, \u201cWindows could not start because the following file is missing or corrupt: <Windows root>\\system32\\hal.dll. Please re-install a copy of the above file.\u201d Subsequent search queries may include the following:\n\n","Next, the searcher () performs and collects the search results (Step ). In one exemplary embodiment, the searcher () goes through the set of queries composed by the composer (), and, starting from the most restrictive (the first query), passes it to a number of search engines. The search engines may be any program that accepts a search request and returns a list of electronic documents to the user relevant to the search request. In one exemplary embodiment, the search engine is the GOOGLE\u00ae search engine utilizing the GOOGLE\u00ae search engine application programming interface (API). However, other search engines may include, for example, the BING\u00ae search engine, the ASK.COM\u00ae search engine, and the YAHOO! SEARCH\u00ae search engine, among others.","In addition to a search performed over the Internet (e.g., a search for technical websites, user forums, etc.), in another exemplary embodiment, the search engine may comprise a search performed over any type of network, including a private network. Thus, searcher () may search an intranet for internal knowledge articles, MICROSOFT\u00ae SHAREPOINTS\u00ae documents, wikis, and online product documentation, among others, to find data that pertains to the events. In yet another exemplary embodiment, the searcher () may perform a search within a memory device, including the memory () of the computing device () or the knowledge database (). In still another exemplary embodiment, the searcher () may perform a search within a combination of the above sources.","The searcher () collects the search results from each query. In one exemplary embodiment, the searcher () collects the results of each search in their preliminary ranked order. For example, if the searcher () used the GOOGLE\u00ae search engine, then the results would be preliminarily ranked by the searcher () based on the ranking provided by the GOOGLE\u00ae search engine. The searcher () may stop searching when a predetermined amount of results are returned (e.g., 20 electronic documents). This predetermined amount of results may be user definable, defaulted, or defined by the computing device ().","Next, the ranker () applies ranking criteria to the search results provided by the searcher () (Step ). More specifically, the ranker () goes over the set of search results, computes rank scores based on a number of criteria, and combines the different rank scores using weighting of importance. In one exemplary embodiment, the ranker () computes rank scores based on a quality of information (QOI) ranking criteria. In another exemplary embodiment, the ranker () computes rank scores based on a content source ranking criteria. In yet another exemplary embodiment, the ranker () computes rank scores based on a content relevancy ranking criteria. Finally, in yet another exemplary embodiment, the ranker () computes rank scores based on a combination of these ranking criteria. Each of these ranking criteria will now be discussed in more detail.","First, the quality of information (QOI) ranking criteria ranks electronic documents based on the quality of information of the electronic document.  is a flowchart showing an illustrative ranking method using quality of information (QOI) ranking criteria, according to one embodiment of principles described herein. QOI ranking measures how fit certain data is for use by quantifying whether the correct information is being used to make a decision or to take a certain action. The method described in  begins by extracting attributes of the various electronic documents included in the search results performed by the searcher () (, Step ; , Step ). The electronic document attributes may include attributes that are innate to the data source and are context-free such as the date of creation of the electronic document and completeness of the electronic document. The electronic document attributes may also include attributes that are content-specific, which must be extracted from the unstructured text data within the data source. It is the latter type of attributes that pose the biggest research challenge due to their elusive and unstructured nature.","The extraction of attributes from the electronic documents may be performed by the processor () executing an application program capable of searching for and finding attributes in the electronic documents. The application program may include, for example, a data scraping application capable of extracting data from human-readable output. The data scraping application may include screen scraping, web scraping, web crawling, and report mining applications.","In order to find the QOI of, for example, user forum threads, both the above-described innate and content-specific attributes may be extracted. The attributes may include, for example, the following list, among others:\n\n","In one exemplary embodiment, \u201canswered\u201d threads may be ranked higher due to their high utility. Some online forums provide for a user of poster to mark the thread as \u201canswered\u201d or \u201cnot answered.\u201d However, many online forums do not provide this option. In one exemplary embodiment, it is possible to determine whether a thread was answered or not based on the other attributes extracted from the thread. For example, it may be determined that the thread was answered if the last post in the forum included the phrase \u201cthank you,\u201d or a derivation thereof. Other attributes listed above may be used in a similar fashion to determine if the thread was answered.","Thus, whether a forum thread was answered or not may be inferred from the attributes extracted from the electronic document. In one exemplary embodiment, the above exemplary list of attributes may be ranked and weighted in order to give the most important attributes a higher weight. In another exemplary embodiment, the function mapping between the attributes and whether the thread was answered or not is learned using labeled examples (examples that provide for labeling of the thread as \u201canswered\u201d or \u201cnot answered\u201d). Classifiers may be learning classifiers that infer attributes that are not available in all threads of an online forum (e.g., answered\/not answered). Classifiers may be produced that may be used to label any new thread using the extracted attributes and the learned function. In some forums, the labels (answered\/not answered) may simply be extracted. In those online forums that do not provide for labeling a thread as answered or not answered, the label may be inferred using the classifiers that are learned.","Some electronic documents such as online forums do have labels provided by the users or posters of the forum as to whether a thread is answered or not. Other online forums do to provide this functionality. Learning classifiers based on examples from online forums that do provide the functionality of providing answers may be used on any other online forum that does not provide the users or posters with the ability to mark their questions as answered. In this way, since the labels are available, no human intensive labor is required in classifying those online forum threads that are not labeled as answered or not answered.","The learning result from one internet domain's online forum may be applied to other domains' online forums. To test the ability to classify forum threads, for example, as \u201canswered\u201d or \u201cnot answered,\u201d threads from two different public forums were gathered: an ORACLE\u00ae online forums (5500 threads), and an IBM\u00ae online forum (1200 threads), extracting 10 quality related attributes. These sites were chosen because they provide a label to each thread on whether the original poster's question was answered or not. Decision tree classifiers on the threads from the different sites were trained. The classifiers on the threads from the same site (using cross validation) and from the different site were tested. The results are shown in Table 1 below.",{"@attributes":{"id":"p-0042","num":"0061"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Classification accuracy on IBM\/Oracle forums"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"84pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Test",{}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"91pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Train","Oracle","IBM"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},"Oracle","90%","85%"]},{"entry":[{},"IBM","79%","97%"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}]}}},"Table 1 demonstrates that while the accuracy is reduced when transferring a classifier from one forum to another, it remains high, validating the generalization of the classifiers. Further, it has been determined that the utility supported scraping HEWLETT-PACKARD\u00ae (HP\u00ae) online forums, as well as those of IBM\u00ae and ORACLE\u00ae.","As discussed above, in some online forums, whether an original poster's question in the thread was \u201canswered\u201d or \u201cnot answered\u201d may be marked by the original poster. However, even in online forums where this is possible, many threads can be inaccurately designated, leading to a problem of \u201cnoisy\u201d results in determining QOI. This is caused by the fact that marking a thread as \u201canswered\u201d is a manual operation that must be performed by the original poster when and if his question is answered. Often, an original poster will find their question answered in the thread, but neglect to indicate (e.g. via checking a box) the thread as \u201canswered.\u201d Therefore, while threads that were designated as \u201canswered\u201d tend to always, in practice, have the answers in them, those that were left as \u201cunanswered\u201d may, at times, include the answers to the original poster's question. This may create \u201clabel noise\u201d within a search for reliable electronic documents. Thus, the examples gleaned from online forums that do have the labels must be handled carefully and not trusted completely.","In order to alleviate the issue of label noise, an ensemble-classifier training algorithm may be utilized to help identify and remove misclassified labels. The below ensemble-classifier training algorithm may utilize a concept of majority vote wherein different classifiers vote on whether or not the training sample is correctly labeled. The votes are tallied accordingly. This alleviates possibilities of over-fitting by one or more classifiers. The algorithm is described as follows:",{"@attributes":{"id":"p-0046","num":"0065"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Algorithm 1: Ensemble classification method for"},{"entry":"handling noisy labels:"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"For every sample"]},{"entry":[{},"\u2003For every classifier"]},{"entry":[{},"\u2003\u2003Classify sample with classifier"]},{"entry":[{},"\u2003\u2003If given label equals classified labels, return 1"]},{"entry":[{},"\u2003\u2003Else return \u22121"]},{"entry":[{},"\u2003Aggregate results of all classifiers for each sample"]},{"entry":[{},"\u2003If result > 0 (i.e. majority of classifiers classified sample correctly),"]},{"entry":[{},"\u2003add sample to new training data"]},{"entry":[{},"\u2003If result < 0 (i.e. majority of classifiers misclassified sample),"]},{"entry":[{},"\u2003discard training sample."]},{"entry":[{},"Train all classifiers with new training data"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The above algorithm may be extended and improved by changing the step that discards training samples. If a majority of classifiers misclassified the sample, there is a good chance that if its label is flipped, it would then be correctly classified. Rather than discarding training samples that were voted as having been misclassified, their labels may be flipped and added back into the new training set, thus boosting correct classification without throwing out any samples.","Next, the processor () ranks the electronic documents based on the extracted attributes extracted from electronic documents (Step ). For the purposes of ranking user forum threads, or other electronic documents, one of the main QOI attributes may be whether a thread was considered as having been answered, since these would be the results subsequent posters would find most helpful in resolving their experienced event. Thus, in one exemplary embodiment, the processor () may be configured to assign classifiers to the electronic documents that denote whether the question was actually answered, and thus should be ranked higher as a useful electronic document.","The above revised algorithm was tested on datasets with a varying amount of artificially placed \u201cnoisy labels\u201d in order to determine how robustly the revised algorithm performs. For each dataset, between 10% and 40% of the labels were randomly flipped so that they became noisy prior to classifier training. The classification accuracy results of running both methods for each of five noise levels appear in Table 2 below:",{"@attributes":{"id":"p-0050","num":"0069"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Classification accuracy results"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"% Noise"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Method","0%","10%","20%","30%","40%"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["No noise filter","0.7794","0.7527","0.7341","0.6877","0.6464"]},{"entry":["Ensemble filter","0.7813","0.7681","0.7488","0.7237","0.6912"]},{"entry":["Ensemble flip filter","0.7805","0.7680","0.7499","0.7258","0.6940"]},{"entry":["No noise","0.7794","0.7794","0.7794","0.7794","0.7794"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}]}}},"Based on the results, the following observations may be noted: (1) the ensemble method is robust to different noise percentages; (2) flipping the noisy labels improves the classification ability; (3) multiple flip iterations do not improve results; (4) less restrictive classifiers (nearest neighbor\/decision trees) were more sensitive to label noise; and (5) false negatives (left-over noisy samples) have more detrimental effect compared to false positives (non-noisy samples with low weights).","In one exemplary embodiment, a modified version of the ensemble-classifier training algorithm with weighted samples may be provided to iteratively reduce mislabeled samples' weights. This embodiment has demonstrated better performance with higher levels of noise in the data. However, this exemplary embodiment was less robust to low level of noise. Given that the level of noisy labels in the data is unknown, it may be more effective to utilize the ensemble-classifier training algorithm with the flipping mechanism in the present system.","The ranker () may also apply ranking criteria to the search results provided by the searcher () (Step ) by computing rank scores based on a content source ranking criteria, as discussed above.  is a flowchart showing an illustrative ranking method using content source ranking criteria, according to one embodiment of principles described herein. In addition to leveraging information regarding the source of the event within the computing device (), many types of events may be queried for each system or subsystem of the computing device () to rank different sources of electronic documents, such as forum domains, internal knowledge databases, and any general internet domain. In this manner, many search queries may be performed based on a large set of events from the same system or subsystem source (e.g., ORACLE\u00ae database). When searching the internet and intranet, among other sources, there are many sources of electronic documents (e.g., HP\u00ae, IBM\u00ae, and ORACLE\u00ae technology forums) that may be more or less relevant to the types of events encountered in a given system or device (e.g., the computing device (, )). For example, an IBM\u00ae forum site may be less relevant compared the ORACLE\u00ae technology forum site if the events come from a system running an ORACLE\u00ae database or other ORACLE\u00ae product. In this manner, the sources of electronic documents may be ranked in a weighted manner based on the type of events being queried.","The source of the events is sometimes known (e.g., APACHE\u00ae software, ORACLE\u00ae database, SUN MICROSYSTEMS\u00ae JAVA server platform, MICROSOFT\u00ae WINDOWS\u00ae operating system, etc). Further, it may also be known that a group of events came from the same type of system or subsystem of the computing device (). In one exemplary embodiment, the processor () provides, as input, a set of events provided from the same system or subsystem (Step ). The steps of creating a set of search queries (, Step ), and performing and collecting the search results (, Step ) may then be performed for each event being analyzed as described in . Next, a number of the top search results (K search results) for each query may be collected, and each results' rank (\u201ci\u201d) may be determined (Step ). In one exemplary embodiment, K may be, for example, the top fifty (50) search results. However, any number of search results may be included. Further, the number of the top search results (K) may be user definable, may be a default number, or a combination of these.","Next, the processor () extracts the domain name for each search result (Step ). All of the results may be collected, and, in the case of internet search, the origin domain may be extracted from the various sources (Step ). Next, it is determined that if the origin domain does not appear in a higher ranking result, the inverse of the rank (1\/i), in one exemplary embodiment, is added to previous counts (Step ). Generally, any monotonically decreasing function may be used to rank each domain in the search result. For example, in addition to the inverse of the rank as described above, exponential or log functions may also be used in ranking each domain in the search result.","Finally, each domain may then be ranked based on the above weighting calculations to produce a weighted list of domains from most appearances to least appearances (Step ). Thus, list of domains that reflects a weighted sum of a number of appearances throughout multiple searches may be achieved. Content source ranking may work as demonstrated in Algorithm 2, as follows:",{"@attributes":{"id":"p-0057","num":"0076"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Algorithm 2: Content Source Ranking"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"Input: Set of events E from the same subsystem source (e.g., Oracle DB"},{"entry":"events)"},{"entry":"Initialize DomainHash as Hashtable of domain names"},{"entry":"For each event in E do the following:"},{"entry":"\u2003Run the composer to create a set of queries"},{"entry":"\u2003Run the searcher on each query"},{"entry":"\u2003Collect the top K search results for each query with its search"},{"entry":"\u2003result rank i"},{"entry":"\u2003For each search result in their ranked order (i=1,...,K)"},{"entry":"\u2003\u2003CurrentDomain \u2190 Domain name from the full URL (e.g.,"},{"entry":"\u2003\u2003hp.com)"},{"entry":"\u2003\u2003If the CurrentDomain did not appear in a higher rank"},{"entry":"\u2003\u2003\\\\ Add the inverse rank of the domain in the current search"},{"entry":"\u2003\u2003to previous counts"},{"entry":"\u2003\u2003\u2003Domain Hash(CurrentDomain) += 1\/i;"},{"entry":"Extract RankedList with weight of domains from DomainHash"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"To demonstrate the results of the content source ranking, tests were ran on two types of logs. The first log was a WINDOWS\u00ae log containing mainly multiple printer events. The second log was a combination of log events from multiple components of HP\u00ae software's Business Availability Center (BAC) software, including HP\u00ae events, JAVA\u00ae events, JBOSS\u00ae events, APACHE\u00ae events, database events, etc.). The top eight results, with their rank are shown in Table 3 below.",{"@attributes":{"id":"p-0059","num":"0078"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 3"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Source ranking results"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Printer log events","BAC log events"]},{"entry":[{},"source ranking","source ranking"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1.","hp.com","119.157375","hp.com","59.369148"]},{"entry":["2.","ibm.com","65.521497","microsoft.com","51.931098"]},{"entry":["3.","microsoft.com","43.811642","eggheadcafe.com","36.795678"]},{"entry":["4.","oracle.com","42.549713","experts-exchange.com","33.695516"]},{"entry":["5.","apache.org","36.819445","forums.techarena.in","25.293438"]},{"entry":["6.","sun.com","28.664713","pcreview.co.uk","14.205668"]},{"entry":["7.","scribd.com","25.912615","tech-archive.net","14.055154"]},{"entry":["8.","jboss.org","25.084923","soft32.com","13.247566"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"As demonstrated in Table 3, above, \u201chp.com\u201d ranks at the top in both cases, with enterprise related sites ranked high in the case of BAC logs, and consumer related technology help sites in the case of the printer logs. The scores within the ranking are shown. The scores indicate that there is a quick drop in rank between the first rank and the eighth rank.","The system (), and, particularly, the processor () of the computing device () may then perform a content relevancy ranking in which the relevancy of each electronic document to the events that were part of the query are computed (, Step ). The relevancy computation includes the edit distance between the events and the electronic document by determining how much of the event text actually appeared in the electronic document, where in the electronic document the searched text appeared, and by whom the text was provided by (e.g., if it is a forum, was it written by the user with the problem?). Additional attributes making up relevance are determined by the creation date of the electronic document, determining whether it is still relevant to the version of the system, subsystem, and\/or software which created the event (e.g., events from an ORACLE\u00ae 8 may be less relevant to an event generated by a system with ORACLE\u00ae 10).","In one exemplary embodiment, the relevancy may be determined by calculating the Levenshtein distance between the text of the event message and the text of the electronic document found in the search. The Levenshtein distance is a metric for measuring the amount of difference between two sequences (i.e. the event text and the text in the electronic document). The Levenshtein distance may be expressed in code as follows:",{"@attributes":{"id":"p-0063","num":"0082"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"int LevenshteinDistance(char s[1..m], char t[1..n])"]},{"entry":[{},"\u2003{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ d is a table with m+1 rows and n+1 columns"]},{"entry":[{},"declare int d[0..m, 0..n]"]},{"entry":[{},"for i from 0 to m"]},{"entry":[{},"\u2003d[i, 0] := i \/\/ deletion"]},{"entry":[{},"for j from 0 to n"]},{"entry":[{},"\u2003d[0, j] := j \/\/ insertion"]},{"entry":[{},"for j from 1 to n"]},{"entry":[{},"{"]},{"entry":[{},"\u2003for i from 1 to m"]},{"entry":[{},"\u2003{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if s[i] = t[j] then"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2003d[i, j]",":= d[i\u22121, j\u22121]"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"else"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2003d[i, j]",":= minimum"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2003("]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"d[i\u22121, j] + 1,","\/\/ deletion"]},{"entry":[{},"d[i, j\u22121] + 1,","\/\/ insertion"]},{"entry":[{},"d[i\u22121, j\u22121] + 1","\/\/ substitution"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2003)"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003}"]},{"entry":[{},"}"]},{"entry":[{},"return d[m,n]"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"Finally, the scores attributed from one or more of the above described quality of information (QOI) ranking criteria, content source ranking criteria, and content relevancy ranking criteria may be combined to create a master ranked results list (, ). The results of the various ranking methods may be combined in three steps. First, the search engine returns a ranked list of results. In one exemplary embodiment, the initial implementation may use the GOOGLE\u00ae search API, and therefore the ranking is based on the GOOGLE\u00ae search engine. Second, for each search result, the domain may be extracted, and the GOOGLE\u00ae rank of the electronic document with the source ranking position (weighted by the source rank weight) may be averaged. This produces a new ordering of the search results. Lastly, when the results are forum threads, the order of the results may be changed based on the quality of information measures giving highest weight to whether there is an answer or not, and lower weights to the other quality measures, as described above. The ranked results, together with all of the separate ranking measures may then be stored in the knowledge database () (, Step ). This gives the flexibility to re-rank the order based on inputs from users on the quality of the search results, giving higher or lower weights to the various ranking measures.","The preceding description has been presented only to illustrate and describe embodiments and examples of the principles described. This description is not intended to be exhaustive or to limit these principles to any precise form disclosed. Many modifications and variations are possible in light of the above teaching."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings illustrate various embodiments of the principles described herein and are a part of the specification. The illustrated embodiments are merely examples and do not limit the scope of the claims.",{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
