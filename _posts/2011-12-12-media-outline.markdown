---
title: Media outline
abstract: Disclosed is a method for presenting an interactive media presentation, the method including presenting media section descriptions with a selectable time code and a description; presenting a media controller and including a displayed time line with one or more selectable time points; upon playing a media item, advancing a time indicator along the time line in accordance with a playback position of the media item and featuring the media section description corresponding to the playback position in the media item.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09280905&OS=09280905&RS=09280905
owner: Inkling Systems, Inc.
number: 09280905
owner_city: San Francisco
owner_country: US
publication_date: 20111212
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["COPYRIGHT NOTICE","BACKGROUND","DETAILED DESCRIPTION","Creating Media Outlines","Example Client Device","Modules, Components and Logic","Electronic Apparatus and System","Example Machine Implementation","Additional Notes and Examples"],"p":["A portion of the disclosure of this patent document contains material that is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure, as it appears in the Patent and Trademark Office patent files or records, but otherwise reserves all copyright rights whatsoever. The following notice applies to the software and data as described below and in the drawings that form a part of this document: Copyright Inkling Systems, Inc., All Rights Reserved.","Teaching students about audio, visual, or audio-visual media (as may be done in film or music classes) may be challenging as traditional textbooks are not adapted to drawing a student's attention to certain aspects of the media in an efficient and contextual manner. Traditional textbooks typically provide a description of the media that is unconnected to the media itself. This approach relies on the student to infer the associations between the description and the media and to access such content in the appropriate sequence and context.","Disclosed in some examples are systems, methods, and machine-readable media that provide for a media outline that guides users through a media presentation and various points of interest in that media presentation. The media outline features descriptions of particular sections of the media as the particular section of that media is being played back. These media section descriptions present notes, commentary, or supplemental information that may relate to the particular media section that is currently playing. The media and the particular media section descriptions may be linked such that advancing the playback of the media to a particular playback time features the media section description for the particular section of media corresponding to that particular playback time. Similarly, users may select any of the different media section descriptions and doing so may advance the media playback to the beginning of the associated section in the media.","Turning now to , a type of media outline, a listening outline , is shown. The title of the work, \u201cLOREM IPSUM\u201d is displayed at . In some examples, for purposes of the media outline, the media may be subdivided into a plurality of media sections. Each media section may have a time code that indicates the position within the media at which the section begins. Each media section may also have a media section description that describes the media during that section. The media of  is divided into three sections and the three corresponding media section descriptions , , and  are shown enclosed by dotted boxes for clarity purposes (e.g., the dotted boxes may not be displayed). Time codes , , and  indicate the beginning playback position of the associated media sections that correspond to the respective media section descriptions , , and .","Media controller  is shown with a control button  for initiating various media playback functionality (e.g., play\/pause\/rewind\/fast-forward or the like), a time line , and a time indicator  which slides along the time line  as a visual indication of the playback position of the media file. The position of the time indicator  along time line  serves as a visual indication of the playback position of the media relative to the entire length of the media as expressed by the position of the time indicator  relative to the length of the time line . Thus, for example, when the time indicator  is halfway between the start and end of the time line , the playback position of the media is halfway between the beginning and the end of the media.","Media controller  may also display a current playback position expressed as a time elapsed and a total time as shown at . Time indicator  may be slidable by a user across time line  to advance (or to rewind) the playback position of the media.","Media controller  may also display a number of selectable time points, such as selectable time points  and  which are selectable points along time line  which correspond to the various time codes , , and . Similar to the position of the time indicator , time points  and  are positioned on the time line  as a visual indication of the playback position of the beginning of the media sections relative to the entire length of the media as expressed by the position of time points  and  relative to the length of the time line . Thus a time point which is exactly halfway through the media will be placed halfway between the beginning and the ending of the time line . Note that the time point that corresponds to time code  is hidden by time indicator . Selecting one of the time codes , , or , or one of the time points ,  (or the time point hidden by time indicator ) changes the playback position of the media file to the particular time indicated by the time code and the time indicator to the associated time point, and the corresponding media description may be featured to indicate that it is currently being played. For example, selecting time code  (\u201c0:22\u201d) or the associated media section description  may advance the media playback to 22 seconds, advance the time indicator  to time point , and feature media section description . Selecting one of time points  and  may also cause the media to advance to the corresponding time and feature the appropriate media description. For example, selecting time point  may cause the media playback to advance to 1:31, the time indicator  to advance to time point , and cause the media section description  to be featured.","The appropriate media description is also featured as the media is played when the playback position advances past the start of a media description time code (, , and ). Thus for example, in the listening outline of , media section description  has a time code of 0:00 and will be featured first. If a user were to tap the control button  to begin playing the media, the time indicator  would begin advancing along the time line  as the media is played. Once the media gets to an elapsed time of zero minutes 22 seconds (corresponding to the time code  and the time point ), the media section description  will be featured. As the media file continues playing and finally reaches a time elapsed of 1:31 (and consequentially the time indicator  reaches time point ), the media section description  will be featured. The order of the media section descriptions may be based upon an order of the media sections which may be based upon the time codes, and the duration of the media section described by a media section description defined by the difference between the time code of the current media section description and the time code of the next media section description.","Featuring a media section description , , or  may include repositioning it in a prominent portion of the screen such as the middle, an upper third, or the like. Featuring may also include changing font size, font color, font style, font type, and highlighting the text within the media section. In other examples, the time codes , , and  may also be featured. Additionally, featuring a media section description may also include placing a time code button  next to the currently featured media section description.","In some examples, featuring a media section description may include displaying a previously un-displayed media section description. For example, if the media is video, the media section description may be displayed overlaid on the video only when the media section it describes is currently playing. In addition, in some examples, there may be too many media section descriptions to properly fit on the screen at one time, so the media section descriptions may be scrollable, and featuring the media section description may include automatically scrolling the media section description so as to be visible.","A media section description may include one or more descriptions of the contents of a portion of the media and may include text, graphics, video, and\/or audio. In , the media section description includes a description of what is happening in the media portion at  (e.g., \u201cOPENING\u201d, \u201cSECOND VERSE,\u201d and \u201cTHIRD VERSE\u201d) and the lyrics of the media portion. Other media descriptions may include lyrics in multiple languages such as a first language (e.g., Latin) and a second language (e.g., English), musical staff notation, guitar tablature, chord diagrams, or the like. In examples in which musical notation is displayed, the individual musical notes may be highlighted as they are played. In still other examples, the media section description may include other media. For example, a listening outline such as the one shown in  may have media section descriptions which consist of a series of videos of the various performers playing the section of media. Thus for example, a particular media section may be a flute solo and the description may be a video of the performance of the flute solo. The next section may feature the cello section prominently and the video may show the cello performance. These videos may be featured by centering them on the screen and automatically beginning playback of the video.","While  shows a media outline for audio, one skilled in the art with the benefit of the present disclosure will appreciate that video and audio-video may also be used. In examples in which video is displayed, the video may be displayed separately from the plurality of media descriptions. For example, the video may be displayed in a box below the media section descriptions. In other examples, the media section descriptions may be overlaid on top of the video as the video is played. In these examples, the media section descriptions may have temporal and spatial components that may specify when the description is displayed, and where on the video it is displayed.","Turning now to , a high-level description of a method  for displaying a media outline is shown. At operation , a plurality of media section descriptions are presented to a user. At operation , a media controller is presented to the user. At operation , time codes indicating the beginning playback position of the various media sections may be presented next to the media section description. In some examples, there may be more media section descriptions than can fit on a single screen, in which case the user may scroll to see the remaining presented media section descriptions, or the user may simply play the media and the media descriptions may automatically scroll as a result of playback of the media. If a user initiates a playback state (e.g., by pressing the play button), playback of the media may begin at operation . The time indicator may then be advanced as the playback progresses at operation . As the playback position advances to a new media section, the appropriate media section description may be featured at operation . If the user selects a time code or selects a time point, then the media may be advanced to that playback time at operation  and the new media section description may be featured if the playback time changed the playback of the media to a new media section at operation .","Turning now to , an example client application stack  which may implement one or more of the media outlines is shown. Operating system  may include a set of functions that manage the computer hardware resources of the client device on which the client application stack  executes. Example client devices include any computing device capable of presenting the media outline to a user and displaying or playing the media file. Examples include an IPAD\u00ae, IPHONE\u00ae, or IPOD\u00ae, all developed by Apple Computer, Inc., of Cupertino Calif.; a XOOM\u00ae tablet developed by Motorola, Inc., of Schaumberg Ill.; laptop computers, desktop computers, or the like. The operating system  provides various functions and services to upper layers in the application stack  through operating system application programming interfaces (APIs) . Example operating systems include ANDROID\u00ae or CHROME\u00ae, both developed by GOOGLE, Inc., of Mountain View Calif.; IOS\u00ae or MAC OSX\u00ae, developed by Apple; LINUX\u00ae, developed by an open source effort; and WINDOWS\u00ae, developed by Microsoft, Inc., of Redmond Wash., or the like. An API is a particular set of rules and specifications implemented as software that components of the software stack can follow to communicate with each other. For example, an application program can use APIs provided by the operating system to communicate with the audio driver component of the operating system. An API can be created for applications, libraries, operating systems, etc., and may include specifications for routines, data structures, object classes, function calls, and protocols. The OS APIs  may be used by the core application  to receive user input, cause the media outline to be displayed, and for media playback.","Core application  represents the user-level executable which presents the media outline. In some examples, the core application  may present many different types of content. For example, the core application  may be software which presents an electronic book or textbook which may display many different types of content as part of the electronic book or textbook, including one or more media outlines.","The core application  may be responsible for loading, displaying, and updating the media controller, displaying the various media section descriptions, controlling media play, and featuring the appropriate media section descriptions at the appropriate time. Because the core application  may display types of content other than media outlines (e.g., images), each different type of content may be described in part by a first markup file  such as an XML markup file. While markup files are described herein, it will be appreciated by one skilled in the art with the benefit of Applicants' disclosure that any machine-readable file format may be utilized. This first markup file  may inform the core application  that the content to be displayed is a media outline (as opposed to other types of content) and may also contain pointers to the media (e.g., such as a file path or a network address from which the file may be downloaded or streamed) and to a second markup file , such as a Hyper Text Markup Language (HTML) file. The second markup language file  may contain the various media section descriptions and the time codes on which the associated media sections begin. The second markup language file  may also contain links to one or more scripts such as scripts .","Markup rendering engine  may be used by core application  to render the second markup language file  and may be any layout engine capable of being used by an application such as core application  to display web content and implement basic browser features such as following clicked links. An example markup rendering engine is WEBKIT\u00ae developed by Apple Computer, Inc., and others. WEBKIT\u00ae provides functions for interpreting and rendering markup, and other APIs provided by the operating system use those functions to provide, e.g., markup viewer classes (which when instantiated produce a markup viewer object ) to display web content in on-screen windows or locations and which implement basic browser functionality.","The media  may be stored in a media file in any format capable of storing digital audio data on a computer system. Example formats include those defined by the various Moving Picture Experts Group (MPEG) standards such as MPEG-1, MPEG-2, and MPEG-4, Apple Lossless (m4a), Windows Media Audio (wma), and the like. In other examples, the media may be streamed from a streaming server over a network such as the Internet.","The second markup language file  may contain an association of the time codes to the media section descriptions. Scripts , linked from the second markup file  and executed by markup viewer object , may search the second markup language file  for these associations, present the time codes as part of the media outline, and visually associate the time codes with the media section descriptions (e.g., through placement in proximity to the media section descriptions or through arrows between the time codes and the descriptions). In some examples, these associations may utilize special markup tags within the second markup language file . For example, special tags with a time code may bracket the media section description associated with that time code. For example:","\u201c<time_begin=0:22> this is a description of a media section <\/time_begin>\u201d","In this example, the markup viewer object  may not render the media section descriptions as it may skip over the unrecognized markup. Therefore, the script may pull the description from the tags and cause it to be displayed in the markup viewer object  (as well as presenting the various time codes along with the descriptions). In other examples, the media section description may be associated with the various time codes in other ways. For example, a proximity to a series of time code tags may be used:","\u201c<time_begin=0:22><\/time_begin>\u201cthis is a description of a media section\u201d","In this example, once the script  encounters a time code tag pair (\u201c<time_begin=><\/>\u201d) then the text from that point until the next time code tag pair may be associated with the time code in the time code tag pair. In these examples, the markup viewer object  may still render the media section descriptions as it may ignore the time code tags and render the descriptions normally. One skilled in the art with the benefit of Applicant's disclosure will appreciate that other ways of associating time codes to the media section descriptions are possible. For example, separate files may be used that may associate the media section descriptions with time codes. In other examples, the media itself may have metadata which identifies the various media sections and also may have metadata which associates that media section with a media section description. In yet other examples, the media itself may contain metadata which contains, or links to, the media section descriptions.","Turning now to  while still referencing the components of , at operation , the core application  may respond to one or more user inputs detected by the operating system  and communicated to core application  through operating system application programming interface (API) . One or more such user inputs include an indication that a user wishes to display certain content represented by first markup file . The first markup file  may include an indicator that the content is a media outline and provide links to the second markup file  and the media . The core application  utilizes the markup rendering engine  to create a markup viewer object  at operation  to load and display the second markup file  containing the media section descriptions at operation . At operation , the core application  also registers a callback function which the markup rendering engine  calls if an attempt is made to navigate away from the second markup file  (e.g., a link is clicked on). As the HTML is rendering, one or more scripts  may be executed based upon instructions in the second markup file . Script(s)  may display the various time codes (e.g., , , and  from ) and make them user-selectable at operation . At operation , the core application  may present to the user the media controller (such as media controller  of ).","Turning now to , a method  of media playback is shown. Upon a user input which starts the media playback (e.g., pressing the play button on the media controller  of ), the core application  () may instruct the operating system  through the OS API  to begin playback of the media  at operation . Through the OS API , the core application  may periodically determine the current playback position in order to update the position of the time indicator  on the time line  (both of ) at operation . The core application  may keep a list of all the media sections, the time codes on which they begin, and the current highlighted media section. By comparing the current playback position to the time codes, the client application may determine if a new media section should be highlighted at operation . If a new media section should be featured, the client application may create a script (such as a JavaScript) and cause the script to be executed by the markup viewer object  at operation . The script may utilize the Document Object Model (DOM) to cause the proper media section description to be featured at operation . The script may also update the time code button  () to indicate the correct, featured, section description. If at operation  it is determined that a new media section should not be featured, the method returns to operation .","Turning now to , a method  of responding to user input on the time line (such as time line  of ) according to some examples is shown. At operation , the operating system  () registers a user input indicating the user has adjusted the time indicator  () to a new playback time, or selected one of the time points  or  () on the time line . At operation  the core application  () updates the time indicator  to a new position on the time line  corresponding to the position the user selected and updates the media playback position using OS API calls. If a new media section description is to be featured based upon the updated playback position of the media file, the client application may then create a script file (e.g., such as a JavaScript file) at operation  and send it to the markup viewer for execution. The script file contains instructions to feature the proper media section description based on the current playback position. At operation  the script uses the DOM to feature the current media section description and to feature the appropriate time code (e.g., such as moving the time code button  of ).","Turning now to , a method  of responding to user input by selecting the time codes associated with the media section descriptions according to some examples is shown. At operation  the user selects a time code or a media section description. In some examples, the time codes displayed in the media section descriptions may be hyperlinks used to provoke the callback function that the client application registered to receive from the markup viewer object  (). The links may not link to real markup pages, but instead the link itself may contain information that is then passed to the core application  through the use of the callback function which informs the core application  that a particular time code was selected. The purpose of the callback function is to give the application that created the markup viewer object  (in this case core application ) approval over whether or not the markup viewer object  may change the markup page displayed. The core application  may deny the request (keeping the second markup language file  displayed), and may read the information in the URL of the callback to ascertain which media section description to feature and to update the media playback position through a call to the operating system API  and update the time indicator  on the time line  (of ).","At operation  the markup display executes the call to the callback function in the core application . The core application  receives the callback at operation  and denies the request at operation . At operation  the core application  uses the API to request the operating system  advance the media playback to the time code clicked on.","Continuing now onto , the core application  may then create a script at operation  which may be sent to the markup viewer for execution. At operation , the script uses the DOM to feature the current media section description and to update the time code highlighting (e.g., such as moving the time code button ).","Note that in some other examples, after clicking on the time code, a script executing in the markup viewer may perform the actions of the script created at operation  such that operations  and  may no longer be necessary.","In some examples, users may interact with the media section descriptions. For example, a user may add notes to a portion of the media section description. Notes may contain text, graphics, links, video, audio, or the like. These notes may be shared with other users or a group of users who may also view the notes when viewing the media outline. Other users may also add comments to the note and start a discussion thread about the media section description. A discussion in some examples may be a series of one or more notes or questions about a particular topic posted by one or more interactive content users, educators, content creators, or other authorized users. A discussion may appear entirely within a single note, as a series of notes, a stack of notes and the like.","Another example interaction is a content highlight. A content user may highlight a portion of the media section description. The highlighted portion may then be shown contrasted against the rest of the media section description. For example, if the content portion is text, the text may be displayed with a yellow background to highlight this text portion. These highlights may be shared with other users or a group of users. Various interactions may be described in greater detail in U.S. patent application Ser. No. 13\/213,994 entitled \u201cOBJECT ORIENTED APPLICATIONS\u201d to Charles MacInnis, filed on Aug. 19, 2011 which is hereby incorporated by reference in its entirety. Any such interactions may be integrated within the media outline.","Yet another example interaction may be an indication that another user is viewing the media outline or a particular media section description. A visual indication of presence is described in U.S. patent application Ser. No. 12\/731,656 to MacInnis entitled \u201cSYSTEM AND METHODS FOR READING LOCATION AWARENESS\u201d which is hereby incorporated herein in its entirety. The interaction may include showing what media outlines and\/or particular media section descriptions other users or other users in a particular group (e.g., class, social network, friends, and the like) in your geolocation or near your geolocation are currently or have been viewing or interacting with.","In some examples, these interactions may be displayed with the media section description when the media section description to which it is associated is visible, but in other examples the interactions may only be displayed when the media section description with which it is associated is displayed.","Turning now to , an example system  for creating and editing media outlines is shown. The system may include a client side component  and a creation service component . Creation service component  may be accessed by the client side component  over network . Creation service component  may be or include one or more computer servers. Network  may be any means of allowing client and creation service components  and  to communicate and may include a Local Area Network (LAN), a Wide Area Network (WAN), portions of the Internet, or the like. Creation service component  may include an operating system  that may include a set of functions that manage the computer hardware resources  of the creation service component . The operating system  may provide various functions and services to upper layers in the application stack through operating system application programming interfaces (APIs) . The OS APIs  may be used by the web application server  to receive communication from the client side component .","Application server  provides to client side component  a series of markup pages, scripts, and other executable programs comprising an editing application  to the client side component  for execution on the client side. The editing application , when executed by the client side, provide tools for the creation and editing of media outlines. For example, these tools (when executed by the client side component) may provide a WYSIWYG (What You See Is What You Get) editing interface to create and edit the media outlines. A WYSIWYG editor refers to an application in which content (text and graphics) displayed onscreen during editing appears in a form closely corresponding to its appearance when printed or displayed as a finished product. Application server  also provides facilities to store and manage created media outlines. Storage of media outlines may be done through the use of any data storage means (e.g., hard-drives, distributed file systems, databases, or the like) such as data store .","Client side component  receives the editing application  over network  in response to a request sent from client side component to access the editing application . Markup rendering engine  utilizes hardware  and client operating system  (through OS APIs ) to execute the editing application . For example, the editing application  may include one or more HTML and JavaScript files, which when loaded and rendered by the markup rendering engine  may provide the editing interface to edit the media outlines.","Once the editing application  is executing, the user may specify one or more existing media outlines to edit, or create one or more new media outlines. If an existing media outline is selected, client side component may request the media outline components from server side component , which may send the media outline (comprising the first and second markup language files , , and the media files ) to the client side component over network .","Editing application  may consist of a simple form to input desired changes to the media outline, or may consist of a WYSIWYG representation of the media outline with which the user interacts, or the like. For example, the user may select a media description that is visually represented (either as markup or as a rendered portion of a web page) and visually indicate in a WYSIWYG manner that the selected media description should be associated with a desired time code. This time code may be entered directly into the editing application  or it may be selected from a pre-populated list presented by the editing application . Users may also create one or more media descriptions and specify the time codes for each. Once the media description is successfully associated with a time code by the user, the user may choose to save their progress. Any created or updated media section descriptions are formatted as appropriate and saved to the second markup file (or equivalent)  and any time codes may be associated with those descriptions as previously described.","Upon saving a new media outline, or changes to an existing media outline, the client side component  may communicate these changes to the application server  via the network , which processes this information, changes the creation service component's record of the authoring data if appropriate, and communicates information regarding the success or failure back to the editing application . In some examples, the media outline may be explicitly saved by the user, but in other examples, the editing application  may automatically save changes to the media outline from time to time.","While the above examples utilized a web-based editing application  which communicates with creation service component  across a network  to create media outlines, one skilled in the art with the benefit of Applicants' disclosure will appreciate that a non web-based application may be used to create and edit media outlines. Additionally, while the above examples utilized storage at the creation service component , it will also be appreciated by one skilled in the art with the benefit of Applicants' disclosure that local storage on the client might be used instead. Additionally, while the above examples utilized a web-based editing application  which allowed for editing on the client side component  with changes being saved at the creation service component , in some examples, the client application  may exist partially on the creation service component  such that the client application  may convey one or more user inputs across network . These user inputs may be used by the portion of client application  running on the creation service component  which may then give effect to those inputs. For example, a desired change to the media file may be communicated from client application  across network . This desired change may be processed by the creation service component , which may then send an indication of whether the change was accepted or not.","The application which displays the media outlines may be executable on various client devices. Client devices may include any electronic device capable of processing, displaying, and updating the media outline. Examples of electronic devices include desktop computers, laptop computers, server computers, cellphones, smart phones, tablet computers, computer game consoles, portable computer gaming consoles, media players, portable media players, other mobile devices, and the like.  shows one example of such a device in the form of an electronic device . Processor  may control the overall functions of the electronic device  such as running applications and controlling peripherals. Processor  may be any type of processor, including Reduced Instruction Set Computing (\u201cRISC\u201d), Complex Instruction Set Computing (\u201cCISC\u201d), Very Long Instruction Word (\u201cVLIW\u201d), Minimal Instruction Set Computer (\u201cMISC\u201d), One Instruction Set Computer (\u201cOISC\u201d), and the like. Processor  may be or include a Digital Signal Processor (DSP). Processor  may communicate with RF receiver  and RF transmitter  to transmit and receive wireless signals such as cellular, Bluetooth, and Wi-Fi signals. Processor  may use short term memory  to store operating instructions and to help in the execution of the operating instructions (e.g., such as the temporary storage of calculations and the like.) Processor  may also use non-transitory storage  to store and read instructions, files, and other data that requires long term, non-volatile storage.","RF receiver  and RF transmitter  may send signals to the antenna . RF transmitter  contains all the necessary functionality for transmitting radio frequency signals via antenna  given a baseband signal sent from processor . RF transmitter  may contain an amplifier to amplify signals before supplying the signal to antenna . RF transmitter  and RF receiver  are capable of transmitting and receiving radio frequency signals of any frequency, including microwave frequency bands (0.3 to 70 GHz), which include cellular telecommunications, WLAN, and WWAN frequencies. Oscillator  may provide a frequency pulse to both RF receiver  and RF transmitter .","Electronic device  may include a battery  or other power source with associated power management process or module . Power management module  distributes power from the battery  to the other various components. Power management module  may also convert the power from battery  to match the needs of the various components. Power may also be derived from alternating or direct current supplied from a power network.","Processor  may communicate and control other peripherals, such as LCD display  with associated touch screen sensor . Processor  causes images to be displayed on LCD display  and receives input from the touch screen sensor  when a user presses on the touch-screen display. In some examples, touch screen sensor  may be a multi-touch sensor capable of distinguishing and processing gestures.","Processor  may receive input from a physical keyboard . In other examples, the electronic device  may utilize a touch screen keyboard using LCD display  and touch screen sensor . Processor  may produce audio output and other alerts that are played on the speaker . Speaker  may also be used to play voices (in the case of a voice phone call) that have been received from RF receiver  and been decoded by processor . Microphone  may be used to transmit a voice for a voice call conversation to processor  for subsequent encoding and transmission using RF transmitter . Microphone  may also be used as an input device for commands using voice processing software. Accelerometer  provides input on the motion of the device  to processor . Accelerometer  may be used in motion-sensitive applications. Bluetooth module  may be used to communicate with Bluetooth-enabled external devices. Video capture device  may be a still or moving picture image capture device or both. Video capture device  is controlled by processor  and may take and store photos and videos, and may be used in conjunction with microphone  to capture audio along with video. USB port  enables external connections to other devices supporting the USB standard and charging capabilities. USB port  may include all the functionality to connect to, and establish a connection with, an external device over USB. External storage module  may include any form of removable physical storage media such as a flash drive, micro SD card, SD card, Memory Stick, and the like. External storage module  may include all the functionality needed to interface with these media.","Certain embodiments are described herein as including logic or a number of components, modules, or mechanisms. Modules or components may constitute either software modules (e.g., code embodied (1) on a non-transitory machine-readable medium or (2) in a transmission signal) or hardware-implemented modules. A hardware-implemented module is a tangible unit capable of performing certain operations and may be configured or arranged in a certain manner. In example embodiments, one or more computer systems (e.g., a standalone, client or server computer system) or one or more processors, including processor , may be configured by software (e.g., an application or application portion) as a hardware-implemented module that operates to perform certain operations as described herein.","In various embodiments, a hardware-implemented module may be implemented mechanically or electronically. For example, a hardware-implemented module may comprise dedicated circuitry or logic that is permanently configured (e.g., as a special-purpose processor, such as a field programmable gate array (FPGA) or an application-specific integrated circuit (ASIC)) to perform certain operations. A hardware-implemented module may also comprise programmable logic or circuitry (e.g., as encompassed within a general-purpose processor or other programmable processor) that is temporarily configured by software to perform certain operations. It will be appreciated that the decision to implement a hardware-implemented module mechanically, in dedicated and permanently configured circuitry, or in temporarily configured circuitry (e.g., configured by software) may be driven by cost and time considerations.","Accordingly, the term \u201chardware-implemented module\u201d should be understood to encompass a tangible entity, be that an entity that is physically constructed, permanently configured (e.g., hardwired) or temporarily or transitorily configured (e.g., programmed) to operate in a certain manner and\/or to perform certain operations described herein. Considering embodiments in which hardware-implemented modules are temporarily configured (e.g., programmed), each of the hardware-implemented modules need not be configured or instantiated at any one instance in time. For example, where the hardware-implemented modules comprise a general-purpose processor configured using software, the general-purpose processor may be configured as respective different hardware-implemented modules at different times. Software may accordingly configure a processor, for example, to constitute a particular hardware-implemented module at one instance of time and to constitute a different hardware-implemented module at a different instance of time.","Hardware-implemented modules may provide information to, and receive information from, other hardware-implemented modules. Accordingly, the described hardware-implemented modules may be regarded as being communicatively coupled. Where multiple of such hardware-implemented modules exist contemporaneously, communications may be achieved through signal transmission (e.g., over appropriate circuits and buses) that connect the hardware-implemented modules. In embodiments in which multiple hardware-implemented modules are configured or instantiated at different times, communications between such hardware-implemented modules may be achieved, for example, through the storage and retrieval of information in memory structures to which the multiple hardware-implemented modules have access. For example, one hardware-implemented module may perform an operation, and store the output of that operation in a memory device to which it is communicatively coupled. A further hardware-implemented module may then, at a later time, access the memory device to retrieve and process the stored output. Hardware-implemented modules may also initiate communications with input or output devices, and may operate on a resource (e.g., a collection of information).","The various operations of example methods described herein may be performed, at least partially, by one or more processors that are temporarily configured (e.g., by software) or permanently configured to perform the relevant operations. Whether temporarily or permanently configured, such processors may constitute processor-implemented modules that operate to perform one or more operations or functions. The modules referred to herein may, in some example embodiments, comprise processor-implemented modules.","Similarly, the methods described herein may be at least partially processor-implemented. For example, at least some of the operations of a method may be performed by one or more processors or processor-implemented modules. The performance of certain of the operations may be distributed among the one or more processors, not only residing within a single machine, but deployed across a number of machines. In some example embodiments, the processor or processors may be located in a single location (e.g., within a home environment, an office environment or as a server farm), while in other embodiments the processors may be distributed across a number of locations.","The one or more processors may also operate to support performance of the relevant operations in a \u201ccloud computing\u201d environment or as a \u201csoftware as a service\u201d (SaaS). For example, at least some of the operations may be performed by a group of computers (as examples of machines including processors), with these operations being accessible via a network (e.g., the Internet) and via one or more appropriate interfaces (e.g., Application Program Interfaces (APIs)).","Example embodiments may be implemented in digital electronic circuitry, or in computer hardware, firmware, software, or in combinations of them. Example embodiments may be implemented using a computer program product, e.g., a computer program tangibly embodied in an information carrier, e.g., in a machine-readable medium for execution by, or to control the operation of, data processing apparatus, e.g., a programmable processor, a computer, or multiple computers.","A computer program may be written in any form of programming language, including compiled or interpreted languages, and it may be deployed in any form, including as a stand-alone program or as a module, subroutine, or other unit suitable for use in a computing environment. A computer program may be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communication network.","In example embodiments, operations may be performed by one or more programmable processors executing a computer program to perform functions by operating on input data and generating output. Method operations may also be performed by, and apparatus of example embodiments may be implemented as, special purpose logic circuitry, e.g., a field programmable gate array (FPGA) or an application-specific integrated circuit (ASIC).","The computing system may include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In embodiments deploying a programmable computing system, it will be appreciated that both hardware and software architectures require consideration. Specifically, it will be appreciated that the choice of whether to implement certain functionality in permanently configured hardware (e.g., an ASIC), in temporarily configured hardware (e.g., a combination of software and a programmable processor), or a combination of permanently and temporarily configured hardware may be a design choice. Below are set out hardware (e.g., machine) and software architectures that may be deployed, in various example embodiments.",{"@attributes":{"id":"p-0071","num":"0070"},"figref":["FIG. 10","FIG. 9"],"b":["10000","10024"]},"The example computer system  includes a processor  (e.g., a Central Processing Unit (CPU), a Graphics Processing Unit (GPU) or both), a main memory  and a static memory , which communicate with each other via a bus . The computer system  may further include a video display unit  (e.g., a Liquid Crystal Display (LCD) or a Cathode Ray Tube (CRT)). The computer system  also includes an alphanumeric input device  (e.g., a keyboard), a User Interface (UI) controller  (e.g., a mouse), a disk drive unit , a signal generation device  (e.g., a speaker) and a network interface device  (e.g., a transmitter).","The disk drive unit  includes a machine-readable medium  on which is stored one or more sets of instructions  and data structures (e.g., software) embodying or used by any one or more of the methodologies or functions illustrated herein. The instructions  may also reside, completely or at least partially, within the main memory  and\/or within the processor  during execution thereof by the computer system , with the main memory  and the processor  also constituting machine-readable media.","The instructions  may further be transmitted or received over a network  via the network interface device  using any one of a number of well-known transfer protocols (e.g., HTTP, Session Initiation Protocol (SIP)).","The term \u201cmachine-readable medium\u201d should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and\/or associated caches and servers) that store the one or more sets of instructions . The term \u201cmachine-readable medium\u201d shall also be taken to include any medium that is capable of storing, encoding, or carrying a set of instructions for execution by the machine and that cause the machine to perform any of the one or more of the methodologies illustrated herein. The term \u201cmachine-readable medium\u201d shall accordingly be taken to include, but not be limited to, solid-state memories, and optical and magnetic medium.","Disclosed in some examples is a method for presenting an interactive media presentation, the method includes presenting a plurality of media section descriptions, each media section description comprising a selectable time code and a description; presenting a media controller selectable between a playback state and a non-playback state and including a displayed time line with one or more selectable time points; responsive to a user initiating the playback state, playing a media item and advancing a time indicator along the time line in accordance with a playback position of the media item and featuring the media section description corresponding to the playback position in the media item.","Disclosed in another example is a system for presenting an interactive media presentation, the system including an output module configured for: presenting a plurality of media section descriptions, each media section description comprising a selectable time code and a description; presenting a media controller selectable between a playback state and a non-playback state and including a displayed time line with one or more selectable time points; responsive to a user initiating the playback state, playing a media item and advancing a time indicator along the time line in accordance with a playback position of the media item and featuring the media section description corresponding to the playback position in the media item.","Disclosed in yet another example is a machine-readable medium that stores instructions which when performed by a machine, cause the machine to perform certain operations. In some examples the operations include presenting a plurality of media section descriptions, each media section description comprising a selectable time code and a description; presenting a media controller selectable between a playback state and a non-playback state and including a displayed time line with one or more selectable time points; responsive to a user initiating the playback state, playing a media item and advancing a time indicator along the time line in accordance with a playback position of the media item and featuring the media section description corresponding to the playback position in the media item.","A method of creating a media outline comprising: creating a plurality of media section descriptions and associating each of the plurality of media section descriptions with a time code, each media section description describing a different section of an associated media file, the associated media section starting at the time code.","The method of the previous example, comprising creating the media section descriptions using a web-based editor downloaded from a creation service across a network.","The method of the previous examples, wherein the media section descriptions are associated with the time codes using the web-based editor.","The method of the previous examples, wherein the media outline is stored on a data store across a network.","The method of the previous examples, wherein the media section descriptions and the associations between the media section descriptions are stored in a markup file.","The method of the previous examples, wherein the association between the media section descriptions and the time codes comprises a markup tag.","A system for creating a media outline comprising: an editor interface configured to present a user interface to allow a user to create a plurality of media section descriptions and associate each of the plurality of media section descriptions with a time code, each media section description describing a different section of an associated media file, the associated media section starting at the time code.","The system of the previous example, wherein the editor interface is downloaded from a creation service across a network.","The system of the previous examples, wherein the media outline is stored on a data store across a network.","The system of the previous examples, wherein the media section descriptions and the associations between the media section descriptions are stored in a markup file.","The system of the previous examples, wherein the association between the media section descriptions and the time codes comprises a markup tag.","The above detailed description includes references to the accompanying drawings, which form a part of the detailed description. The drawings show, by way of illustration, specific embodiments in which the disclosure can be practiced. These embodiments are also referred to herein as \u201cexamples.\u201d Such examples can include elements in addition to those shown or described. However, the present inventors also contemplate examples in which only those elements shown or described are provided. Moreover, the present inventors also contemplate examples using any combination or permutation of those elements shown or described (or one or more aspects thereof), either with respect to a particular example (or one or more aspects thereof), or with respect to other examples (or one or more aspects thereof) shown or described herein.","All publications, patents, and patent documents referred to in this document are incorporated by reference herein in their entirety, as though individually incorporated by reference. In the event of inconsistent usages between this document and those documents so incorporated by reference, the usage in the incorporated reference(s) should be considered supplementary to that of this document; for irreconcilable inconsistencies, the usage in this document controls.","In this document, the terms \u201ca\u201d or \u201can\u201d are used, as is common in patent documents, to include one or more than one, independent of any other instances or usages of \u201cat least one\u201d or \u201cone or more.\u201d In this document, the term \u201cor\u201d is used to refer to a nonexclusive or, such that \u201cA or B\u201d includes \u201cA but not B,\u201d \u201cB but not A,\u201d and \u201cA and B,\u201d unless otherwise indicated. In this document, the terms \u201cincluding\u201d and \u201cin which\u201d are used as the plain-English equivalents of the respective terms \u201ccomprising\u201d and \u201cwherein.\u201d Also, in the following claims, the terms \u201cincluding\u201d and \u201ccomprising\u201d are open-ended, that is, a system, device, article, or process that includes elements in addition to those listed after such a term in a claim are still deemed to fall within the scope of that claim. Moreover, in the following claims, the terms \u201cfirst,\u201d \u201csecond,\u201d and \u201cthird,\u201d etc. are used merely as labels, and are not intended to impose numerical requirements on their objects.","Method examples described herein can be machine or computer-implemented at least in part. Some examples can include a computer-readable medium or machine-readable medium encoded with instructions operable to configure an electronic device to perform methods as described in the above examples. An implementation of such methods can include code, such as microcode, assembly language code, a higher-level language code, or the like. Such code can include computer readable instructions for performing various methods. The code may form portions of computer program products. Further, in an example, the code can be tangibly stored on one or more volatile, non-transitory, or non-volatile tangible computer-readable media, such as during execution or at other times. Examples of these tangible computer-readable media can include, but are not limited to, hard disks, removable magnetic disks, removable optical disks (e.g., compact disks and digital video disks), magnetic cassettes, memory cards or sticks, random access memories (RAMs), read only memories (ROMs), and the like.","The above description is intended to be illustrative, and not restrictive. For example, the above-described examples (or one or more aspects thereof) may be used in combination with each other. Other embodiments can be used, such as by one of ordinary skill in the art upon reviewing the above description. The Abstract is provided to comply with 37 C.F.R. \u00a71.72(b), to allow the reader to quickly ascertain the nature of the technical disclosure. It is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. Also, in the above Detailed Description, various features may be grouped together to streamline the disclosure. This should not be interpreted as intending that an unclaimed disclosed feature is essential to any claim. Rather, inventive subject matter may lie in less than all features of a particular disclosed embodiment. Thus, the following claims are hereby incorporated into the Detailed Description, with each claim standing on its own as a separate embodiment, and it is contemplated that such embodiments can be combined with each other in various combinations or permutations. The scope of the embodiments of the invention should be determined with reference to the appended claims, along with the full scope of equivalents to which such claims are entitled."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["In the drawings, which are not necessarily drawn to scale, like numerals may describe similar components in different views. Like numerals having different letter suffixes may represent different instances of similar components. The drawings illustrate generally, by way of example, but not by way of limitation, various embodiments discussed in the present document.",{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 7A"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 7B"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
