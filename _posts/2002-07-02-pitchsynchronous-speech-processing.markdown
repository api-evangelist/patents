---
title: Pitch-synchronous speech processing
abstract: Pitch-synchronous speech processing invention involves two main steps: 1) divide the speech into pitch periods, or into pseudo pitch periods for unvoiced speech, where the breaks occur, for example, at the first zero-crossing preceding each glottal pulse for voiced speech and at any arbitrary point for unvoiced speech, and 2) compute the log-magnitude of the Discrete Fourier Transform (DFT) of each pitch-period waveform, and interpolate each log-magnitude spectrum to a common regular grid which can accommodate the spectrum of a waveform having the longest pitch period anticipated.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=H0002172&OS=H0002172&RS=H0002172
owner: The United States of America as represented by the Secretary of the Air Force
number: H0002172
owner_city: Washington
owner_country: US
publication_date: 20020702
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["STATEMENT OF GOVERNMENT INTEREST","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["The invention described herein may be manufactured and used by or for the Government for governmental purposes without the payment of any royalty thereon.","The present invention relates generally to synthetic speech systems and more specifically to a pitch synchronous method of transforming speech into vectors for speech processing.","Signal processing for speech, speaker, or language recognition, or for other speech applications, generally consists of a pre-processing step that reduces the speech to a series of vectors, on per time interval, where that interval is typically chosen to lie between five and twenty msec, and successive intervals may overlap. The most commonly used vector representation is the mel cepstrum, which is the Discrete Fourier Transform (DFT) of the logarithm of the non-uniformly low-pass filtered sampled magnitude of the spectrum of that speech segment. The non-uniform filtering and sampling provide roughly constant Q for each channel. A typical output vector might have twenty-eight scalar elements.","The task of processing speech into preprocessing vectors is alleviated, to some extent, by the systems disclosed in the following U.S. Patent, the disclosures of which are incorporated herein by reference:\n\n","The Stadin is interesting as it is for a powered roller skating system using speech recognition sensors and synthesized speech data processing.","The best reference is the Eberman patent which shows a computerized speech processing system with speech signals stored in a vector codebook and processed to produce corrected vectors.","Generally, speech processing includes the following steps. In a first step, digitized speech signals are partitioned into time-aligned portions (frames) where acoustic features can generally be represented by linear predictive coefficient (LPC) \u201cfeature\u201d vectors. In a second step, the vectors can be cleaned up using environmental acoustic data. That is, processes are applied to the vectors representing dirty speech signals so that a substantial amount of the noise and distortion is removed. The cleaned-up vectors, using statistical comparison methods, more closely resemble similar speech produced in a clean environment. Then in a third step, the cleaned feature vectors can be presented to a speech processing engine which determines how the speech is going to be used. Typically, the processing relies on the use of statistical models or neural networks to analyze and identify speech signal patterns.","In an alternative approach, the feature vectors remain dirty. Instead, the pre-stored statistical models or networks which will be used to process the speech are modified to resemble the characteristics of the feature vectors of dirty speech. This way a mismatch between clean and dirty speech, or their representative feature vectors can be reduced.","By applying the compensation on the processes (or speech processing engines) themselves, instead on the data, i.e., the feature vectors, the speech analysis can be configured to solve a generalized maximum likelihood problem where the maximization is over both the speech signals and the environmental parameters.","The present invention is an alternate method and means for performing this first step of transforming speech into a standard series of vectors where each vector represents the sampled magnitude of the spectrum of one pitch period for voiced speech or one pseudo pitch period for unvoiced speech. The subsequent speech processing steps can then be performed with these new vectors as inputs.","The present invention is an alternate method and means for performing the first step of transforming speech into a standard series of vectors where each vector represents the sampled magnitude of the spectrum of one pitch period for voiced speech or one pseudo pitch period for unvoiced speech. The subsequent speech processing steps can then be performed with these new vectors as inputs, provided these subsequent steps are adapted to the new vectors with suitable training protocols and data.","The invention involves two main steps:\n\n","The present invention is a speech processing system and process for transforming speech into a standard series of vectors where each vector represents the sampled magnitude of the spectrum of one pitch period for voiced speech or one pseudo pitch period for unvoiced speech. The subsequent speech processing steps can then be performed with these new vectors as inputs, provided these subsequent steps are adapted to the new vectors with suitable training protocols and data. A block diagram of the proposed process is illustrated in FIG. .","The process of  has two main steps:\n\n","The process of  begins as acoustic data is processed for silence detection  to determine which part of the data stream has speech or silence. The speech sequence is converted into a stream of windows of LW speech samples each. The length LW should be comparable to the duration of a syllable. A given window is said to contain speech if its average power exceeds a suitably chosen threshold POW_TH and is otherwise classified as silence, e.g. POW_TH may equal the noise variance per sample.","Once the portion of the data stream containing speech is flagged the pitch estimator  can process the flagged data stream.","The pitch estimation component is illustrated in FIG. . The input data used to estimate the pitch is the stream of classified speech\/silence windows, and the minimum and maximum anticipated pitch period, P_MIN and P_MAX respectively. A register of length K=\u250c2P_MAX\/LW\u2510 LWis sequentially filled with samples from a contiguous sequence of windows containing speech until the capacity of the buffer is reached or a silence window is found on the input stream. Then the following operations are performed on the retrieved speech segment:\n\n","The speech segments are segmented further into pitch periods as follows.\n\n",{"@attributes":{"id":"p-0023","num":"0051"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"parameter values used to generate the example discussed below."},{"entry":"The symbol [*] denotes rounding to the nearest integer. The"},{"entry":"sampling rate was F_s = 48000 samples sec."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Parameter","Value"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},"POW_TH","1000",{}]},{"entry":[{},"LW","[16 * F_s\/1000]"]},{"entry":[{},"P_MIN","[1.4 * F_s\/1000]"]},{"entry":[{},"P_MAX","[25 * F_s\/1000]"]},{"entry":[{},"P_DEF","[6 * F_s\/1000]"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}]}},"ul":{"@attributes":{"id":"ul0011","list-style":"none"},"li":{"@attributes":{"id":"ul0011-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0012","list-style":"none"},"li":"7. If the current speech segment is declared as voiced the following rules are used to determine the start of the current pitch period.\n        \n        "}}}},"This procedure is repeated until the end of the current speech segment is reached.  shows the segmentation into pitch periods and pseudo pitch periods of a speech segment 100 msec long, where the breaks are indicated by asterisks.","For each pitch period or pseudo pitch period the N-point DFT is computed with N equal to the length of the period in question and the log-magnitude of each transform coefficient is computed. Finally, each log-magnitude spectrum is linearly interpolated to a common regular grid with frequency resolution 1\/P_MAX.","One example of the invention illustrated the pitch-synchronous spectral representation of the sentence \u201cThe little blankets lay around on the floor.\u201d as delivered by a female speaker. The speech was sampled at a rate of F_s=48000 samples\/sec with 16-bit resolution. The values of the parameters used to generate this example are listed in Table 1.","While the invention has been described in its presently preferred embodiment it is understood that the words which have been used are words of description rather than words of limitation and that changes within the purview of the appended claims may be made without departing from the scope and spirit of the invention in its broader aspects."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0014","num":"0025"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0026"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0016","num":"0027"},"figref":"FIG. 3"}]},"DETDESC":[{},{}]}
