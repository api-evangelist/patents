---
title: Method and apparatus for providing motion library
abstract: A method and an apparatus for providing a motion library, adapted to a service end device to provide a customized motion library supporting recognition of at least one motion pattern for a user end device. At least one sensing component disposed on the user end device is determined. At least one motion group is determined according to the determined sensing components, wherein each motion group comprises at least one motion pattern. The at least one motion pattern is selected and a motion database to is queried to display a list of the motion groups corresponding to the selected motion patterns and the motion groups are selected from the list. The motion patterns belonging to the motion groups are selected to re-compile the customized motion library, which is provided for the user end device, so as to enable the user end device to recognize the selected motion patterns.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08847880&OS=08847880&RS=08847880
owner: Cywee Group Ltd.
number: 08847880
owner_city: Taipei
owner_country: TW
publication_date: 20110621
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DESCRIPTION OF THE EMBODIMENTS"],"p":["This application is a continuation-in-part application of and claims the priority benefit of a prior application Ser. No. 12\/647,397, filed on Dec. 25, 2009, now pending. The prior application Ser. No. 12\/647,397 claims the priority benefit of U.S. provisional application Ser. No. 61\/225,555, filed on Jul. 14, 2009. The entirety of each of the above-mentioned patent applications is hereby incorporated by reference herein and made a part of this specification.","1. Field of the Invention","The present invention generally relates to a method and an apparatus for motion recognition, and more particularly, to a method and an apparatus for providing a customized motion library supporting recognition of motion patterns.","2. Description of Related Art","Nowadays, Virtual Reality Motion Sensing (VRMS) technique has become a mainstream in the game field. Through the detection of motion sensors disposed on a game controller, the motion or gestures performed by the user, even the positions or angles of the user can be precisely recognized. The recognition result is further applied to game control, thus providing users with reality to interact with the game, namely, a somatosensory game.","To support the recognition of complex motion, various motion sensors including a G-sensor, a gyro sensor, and a magnetic sensor are adopted to respectively detect the acceleration, angular velocity, and direction of a movement of the device. The parameters generated by the motion sensors are referred to a previously defined motion library, so as to recognize the motion performed by the user.","For example,  is a schematic diagram illustrating a conventional method for recognizing user motion in a somatosensory game. Referring to , a game developer usually takes use of ordinary motion applications (APIs) (step S), such as sensor data GetSensorData( ) Euler angle GetEulerAngle( ) rotation matrix GetRotMatrix( ) quaternion output GETQuat( ) gravity output GetGravity( ) and linear acceleration output GetLinearAcc( ) to recognize the motion performed by the user. Whenever a motion is performed on a device, a plurality of parameters are generated by the motion sensors of the device and input to a recognition engine  for calculation (step S). Finally, a motion of a forehand smash is recognized according to the output of the motion applications (step S) and a recognition result indicating the forehand smash is output to execute a corresponding game operation (step S).","However, each of the motion applications may involve in complicated mathematical calculation. To deal with the recognition of various motion performed by the user, plenty of APIs have to be used and complicated calculation has to be carried out, which expends large sum of system resource and consumes plenty of time. Further, the motion patterns to be recognized have to be defined in advance by the manufacture and cannot be changed by the user, which is inconvenient for the user.","Accordingly, the present invention is directed to a method for providing a motion library, in which a motion library supporting the recognition of user-defined motion patterns is re-compiled in a service end device and provided for a user end device, so as to enable the user end device to recognize the motion patterns performed thereon.","The present invention provides a method for providing a motion library, adapted to a service end device to provide a customized motion library supporting recognition of at least one motion pattern for a user end device. First, at least one sensing component disposed on the user end device is determined. Next, at least one motion group is determined according to the determined sensing component, wherein each motion group comprises at least one motion pattern. Next, a motion database is queried to display a list of the motion groups corresponding to the determined sensing components and the motion groups are selected from the list. Then, one or a plurality of the motion patterns corresponding to the selected motion groups are selected. Finally, the motion patterns belonging to the motion groups are selected to re-compile the customized motion library and the customized motion library is provided for the user end device so as to enable the user end device to recognize the selected motion patterns.","The present invention provides an apparatus for providing a motion library, which comprises a storage module, a communication module, a determination module, an input module and a processing module. The storage module is configured to store a motion database, which records at least one motion library required for recognizing at least one motion pattern. The communication module is configured to connect with a user end device. The determination module is configured to determine at least one sensing component disposed on the user end device, and determine at least one motion group according to the determined at least one sensing component, wherein each motion group comprises at least one motion pattern. The input module is configured to receive a selecting operation of one or a plurality of the at least one motion pattern. The processing module is configured to query a motion database to display a list of the motion groups corresponding to the determined sensing components, selects the motion groups from the list, and selects the motion patterns belonging to the corresponding motion group to re-compile a customized motion library. Finally, the processing module provides the customized motion library for the user end device so as to enable the user end device to recognize the selected motion patterns.","The present invention provides a user with a flexibility to freely select favorite gestures or motion for operating functions of a device, in which a customized motion library supporting the recognition of the selected motion is re-compiled remotely and provided for the device. Accordingly, once the user performs the pre-selected motion on the device, the device may have a quick response and execute the function desired by the user.","Reference will now be made in detail to the present preferred embodiments of the invention, examples of which are illustrated in the accompanying drawings. Wherever possible, the same reference numbers are used in the drawings and the description to refer to the same or like parts.","Current portable electronic devices such as smart phones, or personal digital assistants (PDA) are usually equipped with various motions sensors, which provide the possibility to monitor all kinds of movements of the device. Those movements are classified and defined as a plurality of motion patterns in the present invention and used as a user input for executing a device function or perform a device operation.","Since the motion library always changes in accordance with the number and type of motion patterns to be recognized, in the present invention, a customized motion library is re-compiled in a service end device according to the motion patterns selected by the user and provided for the user end device. Accordingly, the user end device is enabled to recognize the selected motion patterns. The re-compiled motion library may be downloaded and installed in the user end device, or stored in the service end device; either of the two scenarios may support the recognition of motion patterns. Accordingly, embodiments are respectively given below for further illustration.",{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIG. 2","FIG. 2"],"b":["200","210","220","230","240","210","211","212","213","214","215","216","220","221","230","240","240","241","242","243","244","245","246","247","248","249"]},{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 3","FIG. 3","FIG. 2"],"b":["200","300","210","200","217","200","300","320","250","300"]},{"@attributes":{"id":"p-0039","num":"0038"},"figref":["FIG. 4","FIG. 4"],"b":["420","410","410"]},"In detail, when the user end device  connects with the service end device  through network, the service end device  may execute a function of checking sensing component and software and accordingly transmit a checking command to the user end device  (step S). Accordingly, the user end device  returns sensor data of the sensing components disposed therein. Then, the service end device  picks up the motion groups comprising motion patterns that can be recognized by the sensing components according to the result of sensing component check (step S). The service end device  receives a selecting instruction from the user so as to select the motion group and its corresponding motion patterns (step S) and accordingly compiles the selected motion group and its corresponding motion patterns to a customized motion library (step S). Finally, the user end device  downloads the customized motion library or a mapping tool with the customized motion library loaded therein to install (step S). Accordingly, when the user end device  receives a motion input from the user, it may recognize the motion pattern corresponding to the motion input according to the customized motion library and transmits the input operation to the interactive media (e.g. game, UI, etc.) so as to perform the input operation.",{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 5","FIG. 5"],"b":["10","20","10","11","12","13","20","10","20"]},"The service end device  comprises a storage module , a communication module , a determination module , an input module , and a processing module . The storage module  is, for example, a flash memory, a hard disk, or other similar storage devices, and is used for storing a motion database, which records at least one motion library required for recognizing the motion patterns. The communication module  is, for example, a wired or a wireless network-connecting module that is configured to connect with the user end device . The determination module  is configured to determine the sensing components (i.e. G-sensor , gyro sensor  and magnetic sensor ) disposed on the user end device  and to determine at least one motion group according to the determined sensing components, wherein each motion group comprises at least one motion pattern. The input module  is, for example, a keyboard, a mouse, or a touch pad, and is configured to receive a selecting operation of one or a plurality of the at least one motion pattern. The processing module  is configured to query the motion database so as to determine at least one motion pattern recognizable by the sensing components and obtain the at least one motion library required for recognizing the motion patterns.","In detail, the processing module  is, for example, configured to query the motion database stored in the storage module  to display a list of the motion groups corresponding to the selected motion patterns, select the motion groups from the list, select the motion patterns belonging to the corresponding motion groups to re-compile a customized motion library, and provide the customized motion library for the user end device, so as to enable the user end device to recognize the selected motion patterns.","The aforesaid determination module  and processing module  are, for example, computer programs comprising a plurality of instructions to be executed by a central processing unit (CPU), programmable microprocessor, digital signal processor (DSP), programmable controller, application specific integrated circuit (ASIC), or other similar devices disposed in the service end device , which is not limited in the present embodiment.","In detail,  is a flowchart illustrating a method for providing a motion library according to one embodiment of the present invention. Referring to both  and , the service end device  re-compiles a customized motion library according to the motion patterns selected by a user and accordingly provides a customized motion library for the user end device  to install. As a result, whenever a user performs one of the pre-selected motion patterns on the user end device , the type of motion pattern is recognized and an operation corresponding to the recognized motion pattern is executed. Detailed steps of the motion library providing method of the present embodiment are described below with reference to aforesaid elements of system .","First, the determination module  determines at least one sensing component disposed on the user end device  (step S). In one embodiment, when the user end device  connects with the service end device  and requests for a motion library, the determination module  of the service end device  automatically detects the sensing components disposed on the user end device  by sending a plurality of checking commands to the user end device  and receiving the sensor data returned by the user end device , and accordingly determines the types of the sensing components. In another embodiment, the determination module  may receive a selecting instruction of the user from the user end device  and accordingly determine the types of the sensing components.","Next, the determination module  determines at lease one motion group according to the determined sensing components (step S), wherein each motion group comprises at least one motion pattern. In detail, the determination module  may query the motion database stored in the storage module  to find the motion groups containing the motion patterns that can be recognized by the detection of the sensing components configured in the user end device .","Then, the processing module  queries the motion database stored in the storage module  to display a list of the motion groups corresponding to the determined sensing components and selects the motion groups from the list (step S).","Next, the input module  receives an operation for selecting one or a plurality of the at least one motion pattern corresponding to the selected motion groups from the user (step S), so as to select the motion patterns to be recognized.","In an embodiment, the service end device  may further comprise a motion database creating module (not shown), which is configured to previously measure a plurality of parameters generated when the sensing components recognize each of the at least one motion pattern, and record the parameters in the motion database as the motion library corresponding to the motion pattern, so as to create the motion database.","Then, the processing module  selects the motion patterns belonging to the corresponding motion group to re-compile a customized motion library (step S). Wherein, the processing module  may obtain the motion libraries required for recognizing the motion patterns, and re-compile the customized motion library based on the obtained motion libraries. The customized motion library is re-compiled by, for example, training a motion model through a recognition algorithm.","In detail,  is a block diagram of a processing module for re-compiling the customized motion library according to one embodiment of the present invention and  is a flowchart illustrating a method for re-compiling the customized motion library according to one embodiment of the present invention. Referring to both  and , the processing module  of the present embodiment is further divided into a retrieving unit , a converting unit , a training unit  and a compiler . Detailed steps of the re-compiling method of the present embodiment are described below with reference to aforesaid elements of processing module .","First, the retrieving unit  retrieves a plurality of motion trajectory data defined in the motion patterns selected from the selected motion groups and from the motion patterns corresponding to the selected motion groups (step S), and then the converting unit  converts the motion trajectory data into a plurality of motion vectors (step S). Next, the training unit  trains a motion model of the converted motion vectors through a recognition algorithm, so as to obtain a plurality of training parameters of the motion model corresponding to the selected motion patterns (step S). Finally, the compiler  inputs the training parameters into a recognition system and compiles the training parameters into the customized motion library (step S). The customized motion library defines a plurality of sets of training parameters, including strengths and rotations of the motion detected by the motion sensors that are corresponding to the selected motion patterns and used for recognition algorithms.",{"@attributes":{"id":"p-0054","num":"0053"},"figref":["FIG. 9","FIG. 9"],"b":["900","900","1","2","900"]},"It is noted herein that the filename extension of the motion library downloaded to the user end device may vary in accordance with the header file (e.g. Function 1, Function 2, Function 3, etc.) of the application, the operating system (e.g. Windows, Android, Linux, etc.) and the CPU architecture (e.g. x86, ARM, etc.) of the user end device. After the service end device executes the function of checking sensing component and software, it re-compiles corresponding motion library with filename extension such as \u201c.dll\u201d, \u201c.jar\u201d, \u201c.so\u201d, etc, and sends the corresponding header files to the user end device if necessary.","It is noted herein that the motion library described above may be loaded to a mapping tool, which is then downloaded to the user end device, so as to enable the user end device to perform motion recognition. To be specific, the service end device may provide the mapping tool for the user end device, so as to map the motion pattern recognized by the user end device to an input operation of an input device of the user end device. Accordingly, the user end device may perform the input operation of the input device.",{"@attributes":{"id":"p-0057","num":"0056"},"figref":["FIG. 10","FIG. 10"],"b":["1000","1000","1","2","1000"]},{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIG. 11","FIG. 11"],"b":["1120","1130","1100","1100","1100","1110","1100","1120","1100","1100","1120","1130","1130"]},{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIG. 12","FIG. 12"],"b":["122","122","121","121"]},"In detail, when the user end device  connects with the service end device  through network, the service end device  may execute a function of checking sensing component and software and accordingly transmit a checking command to the user end device  (step S). Accordingly, the user end device  returns sensor data of the sensing components disposed therein. Then, the service end device  picks up the motion groups comprising motion patterns that can be recognized by the sensing components according to the result of sensing component check (step S ). The service end device  receives a selecting instruction from the user so as to select the motion group and its corresponding motion patterns (step S) and accordingly compiles the selected motion groups and its corresponding motion patterns to a customized motion library (step S). Then, the user end device  loads the customized motion library to a mapping tool and runs the mapping tool (step S).","Accordingly, when the user end device  receives a motion input from the user, it transmits the motion input to the service end device  and then the service end device  maps the recognized motion pattern of the user end device to an input operation of an input device of the user end device by using the mapping tool and transmits the input operation of the input device to the user end device . Finally, the user end device  transmits the input operation to the interactive media so as to perform the input operation.","In detail, the service end device  re-compiles a customized motion library according to the motion patterns selected by a user and accordingly executes the customized motion library. As a result, whenever a user performs one of the pre-selected motion patterns on the user end device , the movement of the user end device  is detected by each of the at least one sensing component of the user end device and interpreted by the service end device  by using the customized motion library, so as to recognize the motion pattern performed on the user end device .",{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 13","FIG. 13"],"b":["1311","131","1310","1322","1320","1320","1321","1320","1310","1310","1311","1320","1322","1322"]},"To sum up, through the downloading of motion library provided in the method of the first scenario, game developers may re-download their own application. After statistically re-loading (re-compiling) or dynamically re-loading (without re-compiling) the application, the function of motion recognition can be obtained without the need to additionally develop algorithms for motion recognition, which is convenient for the game developers. In addition, the motion library originally installed in the mobile phone may be updated with the motion library of latest version through aforesaid method.","Further, through the downloading of mapping tool provided in the method of the first scenario, an ordinary user may obtain a motion recognition result to correspond to the input of existing devices such as keyboard, mouse, joystick, or touch panel, so as to interact with existing games. The user may directly apply the mapping tool to any other input device for motion recognition and mapping.","On the other hand, through the on-line mapping tool provided in the method of the second scenario, the motion performed by the user on the user end device can be converted into corresponding signals of keyboard, mouse, joystick, or touch panel, so as to provide the user with ease to interact with existing games. Through the on-line mapping tool, there is no need to download mapping tool with different versions for all games, which saves the storage cost. Further, since the database for motion recognition and comparison are stored in the service end device, the storage cost is also reduced.","Further, the on-line mapping tool provided in the method of the second scenario may only transmit a calculation result to the user end device without transformation of the mapping tool. Accordingly, the developers of the user end device may use the calculation result for other applications, which is useful for the content developers.","In an example of the first scenario,  and  illustrate an example of re-compiling a customized motion library according to one embodiment of the present invention. The present embodiment assumes the device motion selected by a user are tennis motion under a motion group of tennis. Referring to , the motion group of tennis comprises eight tennis motion, namely, up drive, down drive, left drive, right drive, forehand cut, backhand cut, forehand lob, and backhand lob. Then, referring to , in the re-compiling process of motion library, a plurality of motion pattern trajectory data defined in the motion patterns of the eight tennis motion (shown in coordinate diagram ) are retrieved from the motion libraries corresponding to the tennis motion (step S). Then, the motions patterns are converted into a plurality of motion vectors  (step S). The motion vectors  are input to a motion model and the motion model are trained through a recognition algorithm (step S), so as to obtain a plurality of training parameters of the motion model corresponding to the tennis motion (step S). Finally, the training parameters are compiled into a customized motion library (step S).","To install the customized motion library in the user end device, the customized motion library may be either directly sent to the user end device  by the service end device  or indirectly sent to the user end device  by an intermediary device disposed between the service end device  and the user end device . The intermediary device may be a computer in the client end, and the user may use the computer to download the customized motion library and then install the customized motion library in the user end device  through the computer. After the customized motion library is installed in the user end device , each of the selected motion patterns performed on the user end device  can be recognized through the comparison of the parameters of motion sensors.","For example,  illustrates an example of recognizing a motion pattern according to one embodiment of the present invention. Referring to , after the customized motion library is installed in the user end device, when a user performs a motion of forehand cut on the device, a movement of the device is detected by the motion sensors (step S). Meanwhile, the user end device  determines whether the outputs of G-sensor and gyro sensor exceed a preset threshold and accordingly determines whether to activate the recognition (step S). If the outputs exceed the preset threshold, the user end device transforms the outputs into a motion pattern (as the black arrow shown in coordinate diagram ) (step S), and converts the motion pattern into a plurality of motion vectors  (step S). The motion vectors  are input to the previously installed customized motion library, so as to execute the recognition process (step S).","It is noted herein that, in the recognition process, a strength and a rotation of the motion are respectively calculated according to the detected outputs and are input into the customized motion library for recognition, in which the strength is an accumulation of acceleration variations within a period of time in 3D space and the rotation is an accumulation of angular velocity variations within a period of time in 3D space. Finally, the motion of forehand cut is recognized (step S).","It is noted herein that when the user selects the motion patterns to be used, he\/she may respectively apply each of the selected motion patterns to a device operation of the user end device. Accordingly, when the motion pattern performed by the user is recognized, the user end device may further execute a device operation corresponding to the motion pattern. In detail, the user end device may detect a motion thereof by using the sensing components and accordingly generating outputs. Then, the user end device interprets the outputs by using the installed customized motion library, so as to recognize the motion pattern performed thereon. Finally, the user end device executes the device operation corresponding to the motion pattern.","To perform the recognition process remotely, the customized motion library is stored in the service end device, such that the recognition of the motion patterns performed on the user end device can be realized through on-line calculation by the service end device. In detail, when a user performs a motion pattern on the user end device, a plurality of outputs are generated by the sensing components and are sent to the service end device. Accordingly, the service end device interprets the outputs obtained by each of the sensing components to recognize the motion pattern performed on the user end device. Finally, the recognition result is sent back to the user end device, so as to enable the user end device to recognize the motion pattern.","For example,  illustrates an example of recognizing a motion pattern according to one embodiment of the present invention. Referring to , after the customized motion library is stored in the service end device, when a user performs a motion of forehand cut on the device, a plurality of outputs are generated by the motion sensors (step S) and sent to the service end device (step S). Then, the service end device determines whether the outputs of G-sensor and gyro sensor exceed a preset threshold and accordingly determines whether to activate the recognition process (step S). If the outputs exceed the preset threshold, the user end device transforms the outputs into a motion pattern (the black arrow shown in coordinate diagram ) (step S), and converts the motion pattern into a plurality of motion vectors  (step S). The service end device further inputs the motion vectors  to the previously stored customized motion library to execute the recognition process (step S). Finally, a recognition result of the forehand cut is obtained (step S) and sent back to the user end device, so as to enable the user end device to recognize the motion of forehand cut (step S).","Similarly, when the user selects the motion patterns to be used, he\/she may respectively apply the selected motion patterns to a device operation of the user end device. Accordingly, when the motion pattern performed by the user is recognized, the user end device may further execute a device operation corresponding to the motion pattern.","It is noted herein that, in the present embodiment, all the motion patterns are classified into a plurality of motion groups and motion types, each of the motion groups may contain one or a plurality of motion types or motion patterns, and each of the motion types may contain one or a plurality of motion patterns. A motion menu comprising all of the motion groups may be displayed for the user to select the desired motion patterns. It is noted herein that, in the present embodiment, the device motion are classified into three layers including motion group, motion type and motion pattern, but is not limited thereto. Persons skilled in the art may classify the device motion in two or more layers so as to help the user to precisely select the motion patterns to be recognized.","For example,  is an example of a motion menu according to one embodiment of the present invention. The present embodiment is adapted to the system for providing a motion library as described in the previous embodiment. Referring to  and , the service end device  classifies the motion patterns in the motion database into a shooting group, a car racing group, a flight group, a fight group, a sports group and a special group. Each motion group may contain one or more motion types and each motion type further contains one or more motion patterns. For example, the sports group contains tennis type, basketball type, bowling ball type, baseball type and golf type, in which the tennis type further contains eight motion patterns including up drive, down drive, left drive, right drive, forehand cut, backhand cut, forehand lob, and backhand lob.","Based on aforesaid classification, a user may select one or a plurality of motion patterns under different motion groups or different motion types and accordingly the service end device  re-compiles a customized motion library based on the motion libraries in accordance with the selected motion patterns under the corresponding motion groups or motion types.","For example,  and  illustrate an example of re-compiling a customized motion library according to one embodiment of the present invention. The present embodiment is adapted to the processing module  of the service end device  as described in the previous embodiment, in which it is assumed the motion patterns selected by a user are eight tennis motion under a tennis type of a sports group plus a circle-in-air motion under a special group (as shown in ). Referring to  and , in the re-compiling process, the retrieving unit  retrieves motion patterns of the eight tennis motion and the circle-in-air motion, as shown in the coordinate diagram , from the motion libraries corresponding to the tennis motion and the circle-in-air motion (step S). Then, the converting unit  converts the motions patterns into a plurality of motion vectors  (step S). Then, the training unit  inputs the motion vectors  to a motion model and trains the motion model through a recognition algorithm (step S), so as to obtain a plurality of training parameters of the motion model corresponding to the tennis motion (step S). Finally, the compiler  compiles the training parameters into a customized motion library (step S).",{"@attributes":{"id":"p-0080","num":"0079"},"figref":["FIG. 19","FIG. 24","FIG. 19"],"b":["1900","1910","1920","1930","1910"]},"Referring to , if only a G sensor is detected, the motion groups and motion types that can be identified by the G sensor are queried from the motion database and listed in the motion pattern check area , so as to be selected by the user. The G sensor motion list  comprises shooting group, fight group, special group and sports group, in which the shooting group further comprises motion types including a cursor shooting type and a first-person shooting type, and the fight group further comprises motion types including boxing type and fencing type. A check box is further displayed in front of each motion group such that the user can select favorite motion groups used for device operation.","Referring to , if a G sensor and a Gyro sensor are detected, a G sensor plus Gyro sensor motion list  is displayed in the motion pattern check area , so as to be selected by the user. The G sensor plus Gyro sensor motion list  comprises shooting group, car racing group, flight group, fight group, special group and sports group, in which the shooting group comprises cursor shooting type and first-person shooting type, the fight group comprises boxing type and fencing type, and the sports group comprises tennis type, basketball type, bowling type, baseball type and golf type. A check box is further displayed in front of each motion group such that the user can select favorite motion groups used for device operation. It is noted herein that, compared to the G sensor motion list  of , since a Gyro sensor is further used, the motion groups or motion types that are listed in the G sensor plus Gyro sensor motion list  are also increased.","Referring to , a G sensor and a Gyro sensor are also detected, and a G sensor plus Gyro sensor motion list  is displayed in the motion pattern check area , so as to be selected by the user. Besides the motion groups and motion types, the G sensor plus Gyro sensor motion list  further displays eight different kinds of motion patterns under the tennis type whenever the user selects the item of tennis type. Check boxes are further displayed aside the motion patterns such that the user can select favorite motion patterns used for device operation. It is noted herein that, the UI for providing the motion library of the present embodiment comprises three layers for selection, that are, motion group, motion type and motion pattern, in which the user may select desired motion patterns under the same or different motion types or motion groups for compiling the motion library. However, the number of layers to be displayed and selected is not limited herein, the list may contain two layers or any number of layers greater than two layers.","Referring to , after the user selects the motion groups, motion types and motion patterns to be used and presses the confirm button, a motion library corresponding to the selected motion groups, motion types and motion patterns is built and a dialog  for selecting the output of the motion library is displayed in the user interface , in which the dialog comprises an option of library only and an option of mapping tool. If the user selected the option of library only, corresponding motion libraries with filename extension like \u201c.so\u201d, \u201c.jar\u201d or \u201c.etc\u201d are downloaded from the service end device to the user end device.","On the other hand, referring to , a dialog  for selecting the output of the motion library is displayed in the user interface . If the user selected the option of mapping tool application, the motion library having filename extension such as \u201c.so\u201d, \u201c.jar\u201d or \u201c.etc\u201d is loaded to a mapping tool and a procedure for setting the mapping tool transformation is processed.","Referring to , if three motion patterns (i.e. the left drive , forehand cut  and forehand lob ) are selected by the user, they are respectively converted into corresponding keyboard keys (i.e. character key \u201cA\u201d, control key \u201cCtrl\u201d and space key \u201cSpace\u201d) and used for setting the mapping tool transformation.","To sum up, based on aforesaid method, a user may combine any motion patterns under various motion groups or motion types and apply those motion patterns to various device operations. A service end device in a remote end automatically re-compiles a customized motion library according to the selected motion patterns and provides the same for the device of the user, such that once the user performs the pre-selected motion on the device, the motion can be recognized either directly by the device itself or indirectly by the service end device, thus accelerating the recognition of motion and providing flexibility for the user to choose desired motion and define operations corresponding to the motion.","It will be apparent to those skilled in the art that various modifications and variations can be made to the structure of the present invention without departing from the scope or spirit of the invention. In view of the foregoing, it is intended that the present invention cover modifications and variations of this invention provided they fall within the scope of the following claims and their equivalents."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings are included to provide a further understanding of the invention, and are incorporated in and constitute a part of this specification. The drawings illustrate embodiments of the invention and, together with the description, serve to explain the principles of the invention.",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 14A","FIG. 14B"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 18A","FIG. 18B"]},{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 19","FIG. 24"]}]},"DETDESC":[{},{}]}
