---
title: Web server in-kernel interface to data transport system and cache manager
abstract: A HTTP request is sent to a web server. A HTTP request including HTTP request data is received. A connection identifier is associated with the HTTP request. The receiving and associating steps are repeated for one or more HTTP requests. The connection identifier and the associated HTTP request data for the one or more HTTP requests are then sent in a single stream to the web server (e.g., HTTP process). When a HTTP request including HTTP request data are processed by a web server, the HTTP request data and an associated connection identifier are received. HTTP response data associated with the HTTP request data is obtained. The HTTP response data and the connection identifier are then sent.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07028091&OS=07028091&RS=07028091
owner: Sun Microsystems, Inc.
number: 07028091
owner_city: Santa Clara
owner_country: US
publication_date: 20000831
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["This invention is related to U.S. Pat. No. 6,668,279, filed on Feb. 25, 2000, naming Bruce W. Curtis as inventor, and entitled \u201cUSER LEVEL WEB SERVER IN-KERNEL NETWORK I\/O ACCELERATOR.\u201d That application is incorporated herein by reference in its entirety and for all purposes.","This invention is related to U.S. patent application Ser. No. 09\/513,328, filed on Feb. 25, 2000, naming Bruce W. Curtis as inventor, and entitled \u201cUSER LEVEL WEB SERVER CACHE CONTROL OF IN-KERNEL HTTP CACHE.\u201d That application is incorporated herein by reference in its entirety and for all purposes.","1. Field of the Invention","The present invention relates generally to computer software. More particularly, the present invention relates to methods and apparatus for providing an in-kernel interface to a web server.","2. Description of Related Art",{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 1","b":["104","104","104","100","102","104","100","102","104","104"]},"Within the web server , HTTP requests that are received are processed by a HTTP daemon . The HTTP daemon  is a program that runs continuously on the web server  and exists for the purpose of handling HTTP requests. The HTTP daemon  forwards the received HTTP requests to other programs or processes as appropriate. Thus, each web server has a HTTP daemon  that continually waits for requests to come in from Web clients and their users. Once a file (i.e., HTTP response data) is obtained (e.g., from an associated web server cache memory ), the data is transmitted by the daemon  to the client  or  that requested the data. In addition, the web server cache  is often used to store HTTP response data. As an alternative to cache memory, the HTTP daemon  may have other storage media associated with it. Such media, for example, can include a hard drive.","HTTP requests are typically initially handled by a kernel  that is responsible for forwarding the requests from the client  or  to the HTTP daemon . The kernel  is the essential central part of a computer operating system, the core that provides basic services for all other parts of the operating system. Typically, a kernel includes an interrupt handler that handles all requests or completed I\/O operations that compete for the kernel's services, a scheduler that determines which programs share the kernel's processing time in what order, and a supervisor that actually gives use of the computer to each process when it is scheduled. The kernel  may also include a manager of the operating system's memory address spaces, sharing these among all components and other users of the kernel's services. A kernel's services are requested by other parts of the operating system or by applications through a specified set of program interfaces sometimes known as system calls. The kernel  also provides services such as buffer management, message routing, and standardized interfaces to protocols which enable data to be routed between clients ,  and a server .","As it applies to handling server\/client communications, the kernel structure consists of three layers: a socket layer , a protocol layer , and a device layer . The socket layer  supplies the interface between the HTTP daemon  and lower (protocol and device) layers, the protocol layer  contains protocol modules for communication, and the device layer  contains device drivers that control network devices. Thus, a server and client process may communicate with one another through the socket layer . More particularly, a socket file system  (SOCKFS) is associated with the socket layer  and is adapted for managing the socket layer .","Conventional Unix network input\/output is provided through the use of a file descriptor opened on a socket. A \u201csocket\u201d is a method for communication between a client program and a server program in a network. A socket is defined as \u201cthe endpoint in a connection.\u201d Sockets are created and used with a set of programming requests or \u201cfunction calls\u201d sometimes called the sockets application programming interface (API). A file descriptor is typically an integer that identifies an open file within a process which is obtained as a result of opening the file. In other words, a separate socket is required for each network connection. Thus, as shown, each network connection corresponding to a client request has an associated socket layer  and protocol layer , which may send data via a network interface card  via a transmission medium  to one or more clients , . Each socket has its own socket data structure. Since a separate file descriptor is opened on a socket for each network connection, in-kernel resources are unnecessarily consumed. Moreover, there are limits to the number of file descriptors that may be opened at a particular instant in time.","STREAMS is a general, flexible programming model for Unix system communication services. STREAMS defines standard interfaces for character input\/output (I\/O) within the kernel, and between the kernel and the rest of the UNIX system. The mechanism consists of a set of system calls, kernel resources, and kernel routines. STREAMS enables the creation of modules to provide standard data communications services. A STREAMS module is a defined set of kernel-level routines and data structures. From the application level, modules can be dynamically selected and interconnected. No kernel programming, compiling, and link editing are required to create the interconnection. STREAMS provides an effective environment for kernel services and drivers requiring modularity. STREAMS parallels the layering model found in networking protocols.","A stream is a data path that passes data in both directions between a STREAMS driver in kernel-space and a process in user space. An application creates a stream by opening a STREAMS device. When a STREAMS device is first opened, the stream consists of only a stream head and a STREAMS driver. A STREAMS driver is a device driver that implements the STREAMS interface. A STREAMS device driver exists below the stream head and any modules. It can act on an external I\/O device, or it can be an internal software driver, called a pseudo-device driver. A stream-head is the end of the stream nearest the user process. It is the interface between the stream and the user process. The STREAMS device driver transfers data between the kernel and the device. STREAMS enables the manipulation of the modules on a stream.","In order for the TCP protocol layer to communicate with the HTTP daemon, a new stream is typically created for each connection. Since a stream is associated with a single connection, the stream does not include identifying information that identifies the connection. On the contrary, since a separate stream is opened for each connection, such identifying information is stored in association with the connection (e.g., by the TCP protocol layer and by the SOCKFS). This private state which uniquely identifies the connection includes information such as a remote IP address, a remote port, a local IP address, and a local port. It is important to note that since such identifying information is not included in the stream, data for only a single connection may be sent in the stream. As a result, multiple streams must be created in order to transmit HTTP request data from a client to the HTTP daemon. Since it is difficult to pre-create such streams, this stream creation is preferably performed dynamically. However, numerous steps must be performed before data can be sent in a data stream.",{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 2","FIG. 2"],"b":["202","204","206","208","202","210","204","204","212","206","206","214","204","216","202","216","202","218","204","220","206","206","222","204","224","202"]},"The present invention enables HTTP requests to be transmitted to a web server while minimizing memory and processing resources. Similarly, HTTP response data is sent in a compatible and efficient manner from the web server to the requesting client.","In accordance with one aspect of the invention, a HTTP request is sent to a web server. A HTTP request including HTTP request data is received. A connection identifier is associated with the HTTP request. The receiving and associating steps are repeated for one or more HTTP requests. The connection identifier and the associated HTTP request data for the one or more HTTP requests are then sent in a single stream to the web server (e.g., HTTP process).","In accordance with another aspect of the invention, a HTTP response including HTTP response data received from a web server is processed. HTTP response data and an associated connection identifier are received from a HTTP process. A stream is created. The HTTP response data and the associated connection identifier are then sent in the stream.","In accordance with another aspect of the invention, a HTTP request including HTTP request data are processed by a web server. HTTP request data and an associated connection identifier are received. HTTP response data associated with the HTTP request data is obtained. The HTTP response data and the connection identifier are then sent.","In the following description, numerous specific details are set forth in order to provide a thorough understanding of the present invention. It will be apparent, however, to one skilled in the art, that the present invention may be practiced without some or all of these specific details. In other instances, well known process steps have not been described in detail in order not to unnecessarily obscure the present invention.","In the following described embodiment, HTTP request and response data are transferred between a HTTP daemon (i.e., web server) and a network cache accelerator. Moreover, the present invention may be implemented using any appropriate mechanism (e.g., Remote Procedure Call mechanism) for communicating between an application and an in-kernel module. For instance, the present invention may be applicable in a Unix system and makes use of the Unix notion of the filesystem as a universal name space. In addition, the present invention may implement a Remote Procedure Call (RPC) mechanism which has built in support for multi-threading. The present invention may be implemented on any system which includes an application and a kernel. For instance, the invention may be applicable to a system having a kernel and an application transport protocol layer (e.g., FTP) which is data intensive.",{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 3","FIG. 3"],"b":["100","102","302","302","304","305","306","307","305","308","306","310","312","306"]},"The NCA file system  preferably stores the HTTP request data and associated connection identifier for the HTTP requests. The HTTP daemon  obtains the HTTP request data from the NCA file system . The connection identifier is preferably maintained as private information between the NCA and the NCAFS to enable the present invention to be used with any web server. In other words, the web server need not be modified to accommodate the present invention.","Next, a method implemented by the HTTP daemon  is invoked and the HTTP daemon  returns a HTTP response (or portion thereof) and\/or directives to control information that is stored in the in-kernel cache  or control the transmission of information to a client  or . This information is sent to the NCA . More particularly, the HTTP daemon  provides an object containing the HTTP response and\/or directives to the NCA file system . The NCA file system  obtains the object, provides the connection identifier in the object, creates a new stream, and sends this object to the NCA  via the newly created stream. It is important to note that the new stream may be created while the web server  is processing the request. The NCA  may then obtain the HTTP response and\/or directives from the object so that it may determine how to manage the transmission and\/or storage of response data received from the HTTP daemon . In this manner, the HTTP daemon  may manage information that is stored, modified and\/or purged from the in-kernel cache  as well as control information that is transmitted to the clients  and .",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 4","b":["400","402","404","406","400","408","400","402","410","402","412","404","414","418","402","402","420","404"]},"The HTTP daemon  then prepares the response . As shown at , the NCAFS establishes a stream to send the HTTP response prepared at . More particularly, the stream may be established in parallel with steps  and . Once the response is prepared at , the response is sent to the NCAFS at . At  the NCAFS  then sends the response and associated connection identifier over the stream established at .","In accordance with one embodiment, the connection identifier is sent to the HTTP daemon with the HTTP request as well as from the HTTP daemon with the HTTP response. More particularly, when the HTTP daemon  accepts the connection as shown at , a new file descriptor is returned to it. It then \u201creads\u201d the HTTP request on this new file descriptor. In accordance with the present invention, a segment of private information is attached to this new file descriptor. More particularly, the private information includes a connection identifier associated with the HTTP request. The private information is intended to be shared by the NCA and the NCAFS to identify the HTTP request and therefore need not be obtained or examined by the web server. When the HTTP daemon sends the HTTP response to the NCAFS at , this \u201cwrite\u201d is performed on this same file descriptor on which the \u201cread\u201d was performed. In this manner, the NCAFS may obtain the connection identifier related to that connection from the private information such that the HTTP response may be associated with the previously sent HTTP request.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 5","b":["502","504"]},"Once the web server is set up, HTTP requests may be sent to the web server. Similarly, once the HTTP requests are processed by the web server, HTTP responses may be sent to the requesting clients. Processing of HTTP requests and responses will be described in further detail below with reference to  and , respectively.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 6","FIG. 5"],"b":["602","604","606","602","604","608","610","612"]},"When the HTTP process receives the connection indication for a HTTP request, the HTTP process accepts the connection and sends a read command at block . In response, the HTTP request data associated with the connection identifier received from the HTTP process is obtained at block . The obtained HTTP request data and the associated connection identifier is then sent to the HTTP process at block . If it is determined at block  that there are more HTTP requests, the process repeats at block . Otherwise, the process ends at block .",{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 7","b":["702","703","704","706","708"]},"As described above, the NCA  and the HTTP daemon  communicate through sending an object.  is a block diagram illustrating an exemplary data type that may be transported in accordance with an embodiment of the invention. More particularly, in accordance with one embodiment, the data transport module  and the HTTP daemon  both transmit a HTTP request-response object. The information that may be provided in the HTTP request-response object is illustrated generally in . A HTTP request-response object  is shown to identify the data stream through an identifier ID  between the data transport module and the HTTP daemon. In addition, the HTTP request-response object  may transmit either a HTTP request or a HTTP response. More particularly, a HTTP_OP field  indicates whether the object is transmitting request or response data. In addition, the HTTP_OP field  may also indicate that an error message is being transmitted. A FIRST field  indicates whether this is the first block of data in a set of request or response data. A MORE field  indicates whether more request or response data is to follow for the associated HTTP request or response, respectively.","In accordance with one embodiment, the HTTP request-response object  also transmits information that can modify the flow of data between the data transport module and the HTTP daemon as well as the flow of data to the client. A PREEMPT field  may be set to preempt data flow from the data transport module to the HTTP daemon as well as to preempt data flow from the HTTP daemon to the data transport module. In addition, data transport information  may specify HTTP request data or HTTP response data that is to be transmitted to the client in accordance with the HTTP_OP field . More particularly, the data transport information  may include HTTP request\/response DATA  (e.g., byte stream), a DIRECT field  that identifies data (e.g., file, shared memory segment, previously cached object) that is directly accessible by the data transport module. Thus, this data need not be transported by the object from the HTTP daemon to the data transport module. In addition, the DIRECT TYPE  (e.g., file, shared memory segment, previously cached object) of the directly accessible data  may be specified in order to enable the data to be subsequently accessed by the data transport module. Finally, a TRAILER  field may be used to include encapsulation information such as whether the response needs to be encapsulated prior to being transmitted to the client or indicate a method of encapsulation.","Caching attributes  (i.e., cache control indicators) may be provided in the HTTP request-response object  by the HTTP daemon in order to manage information that is stored in the HTTP cache as well as to control transmission of the response data. As shown, the set of exemplary caching attributes  includes an advisory state , a nocache state , a CTAG , and an advise state . The advisory state  indicates whether the cache manager  must communicate with the HTTP daemon  in order to determine whether response data can be transmitted to a client that has sent a HTTP request. In addition, the nocache state  indicates whether the HTTP response and associated data are to be stored in the in-kernel HTTP cache . The CTAG  is a unique identifier associated with a HTTP response that enables the response to be associated with multiple HTTP requests in the HTTP cache. The advise state  may be provided by the HTTP daemon  in response to a HTTP request from the cache manager  as well as independently without receiving a request from the cache manager . The advise state  indicates an action to be taken with the response data and may specify a variety of actions, including but not limited to, modifying, storing, or flushing data from the in-kernel HTTP cache as well as controlling the response data that is transmitted to a client that has submitted a HTTP request. Moreover, although the advise state  and the advisory state  are shown as separate states, they may be implemented as a single field. In addition, the HTTP daemon  may optionally provide response data in data field  in the HTTP request-response object.","In accordance with one embodiment, the NCA and the HTTP daemon exchange information through sending a HTTP request-response object in which the information is provided. Although the data transport module and HTTP daemon transmit the same type of object (e.g., HTTP request-response object), the data transport module and the HTTP daemon may transmit the information in a variety of formats. Accordingly, the HTTP request-response object is merely illustrative and other mechanisms for storing and transmitting data between the data transport module and the HTTP daemon are contemplated.","Through the use of the present invention, the transmission of data that is provided in a HTTP request is accelerated. This is accomplished, in part, through enabling efficient use of resources such as the CPU (e.g., threads) through providing HTTP request data for multiple HTTP requests in a single stream. As described above, the HTTP request data for each HTTP request is identified through a unique connection identifier.","The present invention may be implemented on any suitable computer system.  illustrates a typical, general-purpose computer system  suitable for implementing the present invention. The computer system may take any suitable form.","Computer system  or, more specifically, CPUs , may be arranged to support a virtual machine, as will be appreciated by those skilled in the art. The computer system  includes any number of processors  (also referred to as central processing units, or CPUs) that may be coupled to memory devices including primary storage device  (typically a read only memory, or ROM) and primary storage device  (typically a random access memory, or RAM). As is well known in the art, ROM acts to transfer data and instructions uni-directionally to the CPUs , while RAM is used typically to transfer data and instructions in a bi-directional manner. Both the primary storage devices ,  may include any suitable computer-readable media. The CPUs  may generally include any number of processors.","A secondary storage medium , which is typically a mass memory device, may also be coupled bi-directionally to CPUs  and provides additional data storage capacity. The mass memory device  is a computer-readable medium that may be used to store programs including computer code, data, and the like. Typically, the mass memory device  is a storage medium such as a hard disk which is generally slower than primary storage devices , .","The CPUs  may also be coupled to one or more input\/output devices  that may include, but are not limited to, devices such as video monitors, track balls, mice, keyboards, microphones, touch-sensitive displays, transducer card readers, magnetic or paper tape readers, tablets, styluses, voice or handwriting recognizers, or other well-known input devices such as, of course, other computers. Finally, the CPUs  optionally may be coupled to a computer or telecommunications network, e.g., an internet network or an intranet network, using a network connection as shown generally at . With such a network connection, it is contemplated that the CPUs  might receive information from the network, or might output information to the network in the course of performing the above-described method steps. Such information, which is often represented as a sequence of instructions to be executed using the CPUs , may be received from and output to the network, for example, in the form of a computer data signal embodied in a carrier wave.","In accordance with the present invention, the web server and associated software may run on the CPUs . Similarly, web pages and associated information may be stored in data storage devices , , and .","Although illustrative embodiments and applications of this invention are shown and described herein, many variations and modifications are possible which remain within the concept, scope, and spirit of the invention, and these variations would become clear to those of ordinary skill in the art after perusal of this application. For instance, the present invention is described as being implemented in a web server. However, the present invention may be used in other contexts. Moreover, the above described process blocks are illustrative only. Therefore, the implementation of the cache manager, the data transport module, the NCA file system and HTTP daemon may be performed using alternate process blocks as well as alternate data structures. Accordingly, the present embodiments are to be considered as illustrative and not restrictive, and the invention is not to be limited to the details given herein, but may be modified within the scope and equivalents of the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The invention, together with further advantages thereof, may best be understood by reference to the following description taken in conjunction with the accompanying drawings in which:",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
