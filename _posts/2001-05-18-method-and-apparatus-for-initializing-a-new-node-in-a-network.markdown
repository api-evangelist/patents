---
title: Method and apparatus for initializing a new node in a network
abstract: A method for initializing a new node in a network. The network has multiple nodes arranged in a virtual tree format. The new node is a node of the tree, and each node of the tree has a set of attributes and a set of rolled up attributes to identify each node. A query is automatically sent to the nodes to determine what contents to download. The contents are then stored as block files in the nodes. The query contains the set of attributes and rolled up attributes for the new node. The query receives replies from a subset of the nodes that have the contents needed for the new node. Each reply identifies what subset of the block files is available and the performance characteristics of that replying node. Then the desired contents from the subset of the block files from nodes that are least congested is downloaded.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06857012&OS=06857012&RS=06857012
owner: Intel Corporation
number: 06857012
owner_city: Santa Clara
owner_country: US
publication_date: 20010518
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This application is a continuation of U.S. application Ser. No. 09\/681,644, filed on May 15, 2001, entitled \u201cMethod and Apparatus For Large Payload Distribution in a Network,\u201d which claims the benefit of U.S. Provisional Application No. 60\/266,286, filed on Oct. 26, 2000, entitled \u201cLarge Payload Delivery Networks Having Integrated Content Management Services,\u201d the specification of which is herein incorporate by reference.","This invention relates to the field of content delivery. More specifically the invention relates to delivering large payloads (i.e., files) closer to users in a network environment.","Content delivery in a network environment involves sending information (e.g., in the form of a file) from a content provider to multiple content servers which may serve their content to multiple users residing at various destinations on the network. The content provider generally puts the information that is to be distributed onto a computer connected to a network. This computer is often referred to as a content server. Any client-server or peer-to-peer communication protocols may be applied for a content server to further transfer the information to a group of content servers in the same or different networks that are assigned to serve the information. The source content server is usually called the origin server. The information resides in a file on a content server and is available to users of the network. When users request access to the information, the contents of the file are delivered from any of the content servers that are assigned to serve the content to the requesting users using the desired file transfer protocol (i.e., method of transfer). A content server may receive the information from an origin server before any user request, or it may retrieve the information from an origin server upon user request. A content server may be assigned to serve information from multiple origin servers, and an origin server may forward only part of its information to a set of content servers. The owner of the content servers is usually called content delivery network (CDN) provider. In a network such as the Internet, for example, a user may access the network via an Internet Service Provider (ISP) connecting through a central office (CO) of a telephone company or a head end (HE) of a cable company. Thus, the ISP acts as the user's gateway to the Internet. Examples of ISPs include America On Line\u2122 (AOL\u2122) and Earthlink\u2122. Some telephone companies and cable companies are also ISPs. ISPs may interconnect to each other's network, they may connect to a backbone provider, telephone company's network, cable company's network, or any private or public network. Backbone providers provide high bandwidth connectivity for ISPs, enterprise, etc. Through the ISP, CO, or HE, the user may access services (e.g., data) available from content providers from any content servers in the network.","Various types of data (i.e., information) may be transmitted over a network. For example, when a user desires access to web pages, text documents, application programs, static images, audio, video, or any other type of data available from a remote content server, the contents of the files containing the desired data (i.e., information) must then be delivered to the user from the content server. Files containing web pages and text documents are generally small compared to some other file types, such as files containing video or multimedia data. Therefore, transferring a web page from a content server in a remote location, such as Australia, to a user in United States may take less than a few seconds. However, transferring a video file, for example, may take minutes to hours depending on the size of the video file and the speed of the users connection. Such transfers place a huge demand on the network that may result in lost data. For example, when data is sent across the Internet the receiving system may not receive all of the data transmitted from the content server. This is because the data packets (data is generally transferred in packets) may pass through some routers where some packets may be dropped due to congestion. The receiving system notifies the server of the missing data so that it may resend the data. In some cases, dropped packets can slow or halt the delivery of content because if many servers keep resending data to their clients, the routers get even more congested and thus more dropped packets.","Network-based content delivery that relies on a single source to simultaneously distribute various types of information to multiple remote locations may, depending on the size of files being transferred, encounter network-loading problems around the server or the server itself may be over tasked. For example, since transferring a small file (e.g., a web-page) usually takes only a few seconds, the massive distribution of a small file from one source to thousands of destination locations may not create large impact on the network traffic near the source. Transferring a large file (i.e., a large payload), in contrast, can take tens of minutes to hours. If the distribution of such payloads relies on a single source, the network performance near the source, and the subsequent delivery of content, could degrade severely and become unacceptable.","Therefore, while it may be acceptable to rely on a single source to distribute small files (e.g., web pages, text, or small images), the potential for server and\/or network overload calls for using multiple sources to distribute large files to multiple clients.","The fast-paced expansion of the broadband industry has fueled the push for rich media (e.g., full length movies, video, or other types of multimedia data). Broadband technology brings high-speed connection capabilities for content delivery to remote users hence large payloads can be transferred faster. Also, broadband technology makes it possible to send audio and\/or video data using streaming media whereby the data is sent in streams for real-time playback, for example. Thus, the quality of rich media at the user's terminal, more than that of any other type of information, is now more dependent on the performance capabilities of the delivery technology. In order to minimize delivery delays, network congestion, and other related problems, some systems attempt to locate content on server systems that are located in close proximity to, i.e., a few hubs of connections away from the end-users. These server locations approximately define the concept known as the \u201cedge\u201d of the network. For example, the Internet service providers are in close proximity to the end-user thus may be regarded as being at the edge of the network. When servers are placed in such locations, the servers are said to be at the edge of the network. End-user systems that are configured to obtain content from network nodes located at the edge of the network are therefore beyond the edge of the network (a.k.a. last mile). However, it is important to note that systems located beyond the edge of the network are still coupled to the network and capable of communicating with the server computers located at the edge. Placing content at the edge of the network is advantageous because it can reduce the latency in servicing users located beyond the edge. Current approaches for delivering large payloads to the \u201cedge\u201d consist of mirroring or caching. These approaches and the limitations inherent in each approach will now be discussed in detail so as to give the reader an understanding of the advancements made by the invention.","Caching","A simple example of caching is web caching. In its simplest form, web caching involves a cache appliance located between a client user and an origin server such that data fetched once from the origin server is saved in the cache device (appliance) to service subsequent requests for the same data. An illustration of caching is shown in , for example. A client user at browser  in Local Area Network (LAN)  desiring to obtain data available from origin server  enters the Universal Resource Locator (URL) address of the desired data into browser . LAN  may be an ISP's network, for example. The request is forwarded to cache appliance , which is an HTTP (Hyper Text Transport Protocol) proxy server in this illustration. The proxy server which may, for example, be owned by the ISP is typically located at the ISP's local network. Like any other server, proxy servers (cache appliance)  and  are computers with local processing and memory. A subset of that memory is known as the proxy cache. Cache is generally used as temporary storage for frequently used information. Note that, although only one cache appliance is shown in each ISP's local area network of , an actual implementation may have more than one cache appliance in an ISP's local area network.","Proxy server (i.e., cache appliance)  processes the request received from client at browser  and searches its cache (i.e., memory) for the requested data, if the data is not available in its cache, proxy server  forwards the request to origin server  via network router . In this illustration, network router 's sole purpose is to forward requests to origin server . Origin server  is an HTTP server with single TCP\/IP (Transmission Control Protocol\/Internet Protocol) connection path  to client user at browser .","Origin server  services the request and forwards the requested data to cache appliance . Upon receipt of the data, cache appliance  may save the data in its local cache memory and also forwards it to browser . The data is said to be cached in HTTP proxy (cache appliance) . A subsequent client user at browser  desiring the same data gets their request serviced by HTTP proxy server (cache appliance)  without the request being forwarded to HTTP server . However, users  and  at LAN  requesting the same data would have their initial request serviced by HTTP server  because users  and  are not connected through HTTP proxy  which has the data cached in memory. Instead, HTTP proxy  would perform the same processes as discussed above for HTTP proxy  to obtain and cache the data in its memory. Thus, proxy servers  and , which are said to be at the edge of the network, are populated upon user demand.","Once the data is cached in HTTP proxy  and , origin server  would not need to service requests for the same data from users connecting through HTTP proxy servers  and . By caching the data at various proxy servers closer to the users, delivery of content is distributed thereby reducing the load around the network server. However, caching is only good for delivering static content data that is fixed in memory such as static web pages. Caching does not work for dynamic information such as services (e.g., functions, transactions, etc.), streaming media, or any other type of dynamic information.","The HTTP protocol is well known to those of ordinary skill in the arts; therefore software to perform the caching function at HTTP proxy servers  and  is readily available. However, this is not the case with streaming media because different providers of streaming servers use differing protocols to transmit data to the recipient player (e.g., a browser).  is an illustration of a typical streaming server connection to a player.","In contrast to HTTP TCP\/IP connections to the browser, Streaming server  is connected to player  via three connection paths. Path  is the Real-Time Streaming Protocol (RTSP) connection. RTSP is a protocol that provides for control over delivery of data with real-time properties such as audio and video streams. RTSP contains a description of media data and provides playback controls such as play, rewind, fast-forward, and pause to player . Playback may be done with an offset so that a player can start receiving the data from a specified point. For example, when player  rewinds, a different offset, corresponding to the desired playback position, is sent to streaming server  and incoming data is sent through path  starting from the new offset. Path  utilizes the Real-Time Transport Protocol (RTP) and may contain the data being played back. The third connection, path , utilizes the RTP Control Protocol (RTCP) and it may provide flow control of the data.","Caching does not work well for streaming media because the various providers of streaming servers use differing intelligence to compute the data being sent over connection  as a function of the offset and the flow control. Moreover, server providers do not follow a common standard, therefore placing a cache appliance between streaming server  and player  would not be readily feasible unless the intelligence, which in today's implementation is in the streaming server, is included either in the streams of information being sent over the connection paths, or if the cache appliance contains the intelligence used by every streaming server provider. Thus, existing systems do not currently provide a viable way to cache streaming media data. Also, since caching is usage based, when content is not cached the proxy will need to fetch the content hence there is a potential for misses and there is no guarantee of quality.","Despite these limitations, caching has advantages such as ease of growth because a new cache appliance can be added anywhere and it will be up and running; a cache appliance can be shared by different content providers; and a cache appliance is very lightweight (i.e., does not require special configuration) and thus easier to manage.","Mirroring","Mirroring is a scheme for providing content-delivery to users at the \u201cedge\u201d of the network that addresses many of the limitations of centralized systems by replicating content to the edge of the network, thereby minimizing the distance between where content is requested and where it is served. In so doing, mirroring saves network bandwidth as compared to delivery to multiple users from one centralized source. The fundamental principles underlying mirroring includes central control of content and the network, efficient distribution of content to the servers at the edge of the network, and automatic redirection of content requests from a user to a local edge server.","In mirroring, file servers are placed throughout the network (e.g., Internet), close to where the content requests originate. This principle mirrors some of the functionality of caches, but with distinct differences. In particular, these file servers work together in a centrally controlled collaborative fashion to ensure overall network performance. Like a cache, content is replicated from the origin server to the server only once, regardless of the number of times the content is served. However, mirroring provides greater content control. By pre-populating the server, the content will be available for fast delivery to the user, eliminating cache misses and increasing the hit rate. Mirroring, in combination with caching, delivers a better-integrated solution with the benefits of both approaches.","One URL applies to all the servers in a mirroring implementation. When a browser requests the URL, the system determines a local delivery server based on: geographical and network location; presence of content; and current status of server (both availability and load).",{"@attributes":{"id":"P-00022","num":"00022"},"figref":"FIG. 3","b":["300","301","308","3","301","302","308","301","302","308"]},"Unlike caching, where the content must be static (i.e., does not change with time), mirroring works well for non-static data such as transactions because transaction data can be synchronized from the master server (e.g., FS ) to the file servers at the edge of the network (e.g., FS -). The various methods of replicating data to file servers at the edge may include broadcast, a transmission from the master server to all listening file servers in the network; anycast, a transmission to the nearest group of servers; unicast, a transmission to a specific receiver; and multicast, a transmission to multiple specific receivers (a more detailed discussion of multicasting is discussed below). Once content is delivered at the edge, a user at browser  requesting access to content is automatically routed to the geographically closest server (e.g., server ) that is able to service that request.","Mirroring also works well for streaming media. Streaming servers can be attached to any of file servers - to provide service closest to where it is needed. For example, by attaching a streaming server  to file server  a user at player , in the geographic vicinity of file server , can playback streaming media data without much latency. Thus, in mirroring implementations, streaming servers can be attached to any of the file servers to overcome the limitations of caching. However, current methods suffer significant disadvantages, for example, a large object such as video that is popular may create a hotspot on a disk because of repeated access to the content and because disk input\/output bandwidth is limited. Moreover, the large object needs to be fully transferred to either the application server or the cache appliance before satisfaction of an end-user client request for the data may commence thereby creating potential latency issues.","Mirroring, also, can be very expensive due to scalability issues, storage limitations, management costs, and inadequate load balancing. Scalability issues arise from the need to store entire large files, such as video, within a storage media. Therefore, new storage must be added to all the file servers in the network when available storage is inadequate for storing a particular large file. Since all the file servers in the network must maintain the same file configuration, upgrading all the file servers in the mirroring environment could prove to be very expensive. Additionally, new file servers brought into the network would need to be configured to conform to all other file servers in the network.","Adding more storage requires rack space for mounting the new storage devices. Rack space is usually limited and sometimes expensive. Moreover, as storage capacity increases, more system administration functions (e.g., backup) are needed to manage the configuration. Since cost of system administration is expensive and rack space is limited, mirroring suffers.","Content Distribution Using Multicast","Multicast is simultaneous communication between a single sender and multiple selected receivers on a network.  is an illustration of a distribution network that uses multicast technology to push information to multiple content servers on a network.","The source provider uploads the large payload (e.g., video file, image data, or any other file having a size significant enough to strain network resources) onto the root server  which may be, for example, a content server located in Los Angeles. The root server may also be referred to as the origin server. Root server  subsequently multicasts the video data to multiple servers (e.g., servers  through ) that are at the second level of the network server tree, usually in differing geographical locations. For example, server  may be located in San Diego, server  in San Jose, and server  in San Francisco. After receiving the video data, servers  through  will multicast the video data to servers in the next level of the server tree. For example, server  multicasts the data to servers  through , server  multicasts the data to servers  through , and server  multicasts the data to servers  through . In this illustration, each server multicasts to three other servers, however, most implementations involve multicast to more than three servers (e.g., ten servers).","After the video data is distributed amongst servers  through , the video data becomes available from multiple servers that are located in different geographical localities on the network. This distribution method pushes content to the edge into a mirroring type architecture where user requests may be serviced from one of multiple servers, usually from the geographically closest server. Multicasting the entire large payload file may still cause congestion due to insufficient capacity on a particular communication link; network equipment congestion due to processing speed of networking equipment; server congestion due to data processing speed of the server; and latency in the network due to the time associated with the data traveling over long distances.","Load Balancing","Load balancing is the task of distributing the network load and the processing load to a cluster of servers to improve system performance, while simultaneously increasing the reliability of the service provided by the servers. A load balancer is often implemented as either a switch or a router and called a load balancing switch or a load balancing router respectively. A load balancer's network interface, the Virtual IP address (VIP), serves as a virtual external interface for the server cluster. Each server in a cluster has both an internal (local IP address) and an external (IP address) network interface. Most load balancers provide a feature called Network Address Translation (NAT), which translates VIP to a local IP address, which are useable on the Internet. A load balancer accepts all data packets addressed to its VIP, and distributes them equally to the most available servers.","A load balancer maintains a state table (e.g., what server is servicing what client), so that data packets of a persistent session flow to and from the same client and server end points. Many load balancers have a configurable \u201csticky\u201d feature that distributes data packets from a client to the same server that the client was previously connected to. The \u201csticky\u201d feature allows a server to intelligently prepare for possible future requests from its clients.","Load balancers can typically operate in either a \u201cregular\u201d (i.e., non-transparent) mode or a \u201ctransparent\u201d mode. The difference between \u201cregular\u201d mode and \u201ctransparent\u201d mode lies in the management of inbound and outbound data flow. In \u201cregular\u201d mode, all inbound traffic to and outbound traffic from the server cluster passes through the load balancer. In \u201ctransparent\u201d mode, outbound traffic from the server cluster bypasses the load balancer by flowing directly through an IP router. The \u201ctransparent\u201d mode can be extremely important for a network of servers delivering large amounts of data, as it reduces the overall load on the load balancing router and thus improves network performance. When a load balancer is operating in \u201ctransparent\u201d mode, it does not translate the destination IP in the inbound packets from clients to its server cluster. An IP router must be connected both to the load balancer and the server cluster to do this. The servers in the server cluster are then configured with a loop back interface using the IP address of the load balancer and with a default route to the IP router.","Most load balancers provide either a remote or local Application Programming Interface (API) or scripts to manage their load balancing tasks. In general, current technology uses a round-robin approach (i.e., the next server in the queue services the next client) to load balance a cluster of available servers. This may mean that servers are allocated tasks even if they don't have available bandwidth.","Therefore, there is a need to address the cost, scalability, and load-balancing issues associated with large payload delivery to the edge of the network. However, before discussing the present invention, a general overview of how files are handled in different operating systems is presented.","File Configuration on Computer Systems","The overall structure in which files are named, stored, organized and accessed in an operating system is referred to as a \u201cfile system\u201d. In the UNIX operating system, for example, each directory can be mounted with a file system. If a directory \/X is mounted with file system Y, any storage I\/O (Input\/Output) request within the sub-tree \/X is forwarded to the file system Y. For example, opening of a file \/X\/foo.txt causes the open request to be forwarded to the corresponding \u201copen\u201d routine in file system Y.","Contemporary operating systems, such as Unix and Windows, support \u201cstackable file systems\u201d. A stackable file system is a file system that is built on top of another file system. For example, if a stackable file system F is built above file system K, and if directory \/X is mounted with F, then opening of a file \/X\/foo.txt causes the open request to go to file system F. File system F processes the request and it may or may not generate a request to file system K. In the Windows operating system environment, a stackable file system is called a file filter. A file filter can be placed on any directory. Any I\/O access to a directory that has a file filter causes a corresponding file filter routine to be executed. A file filter may or may not send any request to the underlying file system.","A distributed file system is one in which files may be located on multiple servers connected over a local or wide area network. A distributed file system can be implemented using any one of several well-known network file system protocols, e.g., the Common Internet File System (CIFS) and Sun Microsystems, Inc.'s Network File System (NFS) protocol. CIFS is based on the standard Server Message Block (SMB) protocol widely in use by personal computers and workstations running a wide variety of operating systems. The CIFS protocol supports a number of file sharing and representation features, such as: file access, file and record locking, safe caching, read-ahead, and write-behind, file change notification, protocol version negotiation, extended attributes, distributed replicated virtual volumes, and server name resolution. NFS, like CIFS, is intended to provide an open cross-platform mechanism for client systems to request file services from server systems over a network. The NFS protocol provides transparent remote access to shared files across networks because it is designed to be portable across different machines, operating systems, network architectures, and transport protocols. NFS\u2032 portability is achieved through the use of Remote Procedure Call primitives (RPC primitives) that are built on top of system implementations that use the External Data Representation standard (XDR). The RPC primitives provide an interface to remote services. A server supplies programs (e.g., NFS), each program including a set of procedures. The combination of a server's network address, a program number, and a procedure number specifies a specific remote procedure to be executed. XDR uses a language to describe data formats. The language can only be used to describe data; it is not a programming language. NFS Implementations exist for a wide variety of systems. NFS mount protocol allows the server to hand out remote access privileges to a restricted set of clients and to perform various operating system-specific functions that allow, for example, attaching a remote directory tree to a local file systems.","The above examples illustrate the limitations and problems associated with current systems for distributing large files. Because of these problems there is a need for a method and apparatus that utilizes a more effective means for delivering large payloads.","An embodiment of the invention provides an improved mechanism for distributing large files throughout a computer network and delivering such files to an end-user system. When the invention is implemented it provides multiple users with a way to obtain access to large payload files without overburdening network resources. If, for example, a user wishes to download a large file such as a video file an embodiment of the invention provides a way to deliver that video file to the requesting user without putting a strain on the network. The system accomplishes this by breaking the large file into multiple portions and storing those portions in locations (e.g., nodes) distributed throughout the network. The portions stored throughout the network are distributed utilizing a flow optimization technique that provides for the intelligent management of large data files. Thus, the portions of large data file are stored in locations that minimize the amount of time it takes to deliver the portion to the end-user system. These locations are referred to by those of ordinary skill in the art as the edge of the network.","Each node at the edge of the network embodying aspects of the invention is configured to appear as if it has the large file stored locally when portions of the file are really stored on other nodes located throughout the network. This greatly increases the virtual storage capacity of each network node without consuming system resources. When the end-user system issues a request for content (e.g., a large data file) the request is routed to the nearest node and the system delivers the requested content to the node in manner that maximizes data transfer efficiency while minimizing bandwidth consumption. The end result is that each network node has access to numerous large data files without having to store each of those data files locally.","In one embodiment of the invention, the system is optimized so that large payload files can be distributed across existing networks (including the Internet and corporate intranets) using a transport layer network overlay to push content to the edge of the network. Specifically, the embodiments of the invention improve large payload delivery performance, scalability, reliability, and availability.","As mentioned above, one embodiment of the invention breaks the large payload files into multiple portions. This may be accomplished by selectively partitioning the large payload file into blocks that are replicated and distributed to a plurality of distribution stations (a.k.a. nodes) at the edge of the network. Each distribution station is configured to determine how much of the content to save locally, based on information such as usage, popularity, etc. The content provider defines what distribution stations are qualified to function as distribution stations and may also define other distribution criteria. Distribution stations in the network manage storage and transfer content (e.g., portions of large payload files) and other information to one another. Different pieces of a large payload file may be available from different nodes, however, when a user requests access to the large payload file, for example, through an application server (e.g., a streaming server), a virtual file control system creates an illusion that the entire file is present at the connected node. However, since only selective portions of the large payload file may actually be resident at that node's storage at the time of request, the distribution stations may download the non-resident portions of the file as the application server is servicing the user. The download of the non-resident blocks may be in parallel and usually from the least congested nodes. The entire process is transparent to the user.","The required portions of the requested file are received and reassembled in real-time using one or more associated file servers called the virtual file control system server. The virtual file control system provides the reassembled file to the application server servicing the client. The virtual file control system can be implemented either as a stackable file system, as a proxy file server using an underlying network file system such as NFS or CIFS, a storage-area network (SAN), or direct attached storage, or as a combination of these methods. Whichever implementation is used, the virtual file control system obtains the content from the underlying file systems.","Scalable content delivery network stations are geographically dispersed to the edge of the network in order to optimally service end-user client systems that are located beyond the edge. End-user client requests for data are automatically serviced at the nearest least congested station. In one or more embodiments of the invention, the scalable content delivery network is integrated into existing services at the Internet's edge to take advantage of these services (e.g., the Application Servers in some embodiments of the current invention might be Streaming Servers in operation within a service provider's existing base of systems).","In one or more embodiments, new nodes may be added to the network without service interruption. As the new nodes are added, they learn from other nodes in the network what content they should have and download the required content, in a desired amount, onto their local storage from the nearest and least congested nodes. Thus, a node could be added to the network and it would be up and running after self-initialization.","In one or more embodiments, the portions and amount of a large payload file maintained at each node depends on the available storage, popularity of the content, distribution criteria by the content provider, etc. Thus, least likely to be used blocks of a large payload file may be pruned (i.e., deleted from local storage) to make room for other highly desirable content. However, although the least likely to be used blocks of a file are pruned, the entire content of a large payload file may be maintained at a node in the scalable content delivery network, so long as the content provider wants the content to remain in the network.","An embodiment of the invention provides an improved mechanism for distributing large files (referred to as large payloads) throughout a computer network and delivering such files to an end-user system. In the following description, numerous specific details are set forth to provide a more thorough description of embodiments of the invention. It will be apparent, however, to one skilled in the art, that the invention may be practiced without these specific details. In other instances, well known features have not been described in detail so as not to obscure the invention.","When the invention is implemented in accordance with one embodiment of the invention it provides end-user systems with a way to access large payload files without overburdening the network utilized by the end-user system to transmit data. In one embodiment of the invention, the system accomplishes this by breaking the large payload file into multiple portions and storing those portions in locations (e.g., nodes) distributed throughout the network. The portions stored throughout the network are distributed utilizing a flow optimization technique that provides for the intelligent management of the large payload files. Thus, portions of the large payload file are stored in locations that minimize the amount of time it takes to deliver the portion to the end-user system. These locations minimize the latency associated with delivering the file to the end-user system and are referred to herein as the edge of the network.","Each node at the edge of the network embodying aspects of the invention is configured to appear as if it has the large payload stored locally when portions of the file are really stored in on other nodes located throughout the network. This greatly increases the virtual storage capacity of each network node without consuming system resources. When the end-user system issues a request for content (e.g., a large payload) the request is routed to the nearest node and the system delivers the requested content to the node in manner that maximizes data transfer efficiency while minimizing bandwidth consumption. The end result is that each network node has access to numerous large data files without having to store each of those data files locally. Thus, one or more embodiments of the present invention provide efficient methods and apparatuses for delivering a large payload to the edge of a network without the cost, scalability, load balancing, and other issues associated with prior art methods of content delivery.",{"@attributes":{"id":"P-00078","num":"00078"},"figref":"FIG. 5","b":["500","505","510","520","520","520"]},{"@attributes":{"id":"P-00079","num":"00079"},"figref":"FIG. 5","b":["530","550","570","501","530","570","540","500","530","550","500","550"]},"Network Edge  generally may be far from network core . However, the distance (i.e., path latency) between the core and the edge may not be uniform and may vary considerably for a given CPC or EUC. One embodiment of the present invention places a plurality of Distribution Centers (DC) A-I for maintaining large payloads at the edge of the network thereby resolving the latency issue. Large payload content from a content provider is pushed from one distribution center to other distribution centers at the edge of the network. An end-user seeking access to a large payload is serviced (via an application server) from the nearest distribution center containing the desired content. By distributing content to the end-user (e.g., at EUC ) via a plurality of Application Servers  and distribution centers  at the edge, path latency is minimized. Thus, large payload distribution involves obtaining a large payload file from a content provider and geographically placing such file at the distribution centers which are at or as close to the edge of the network as possible.","The distribution centers A-I in SCDN  of  are virtually arranged in the form of a tree as illustrated in , for example. This virtual tree arrangement is primarily used for communication of control information amongst the nodes of the scalable content delivery network. Data downloads can be performed from any node in the network having the desired data, preferably the nearest node (distance-wise). Nodes A through I of  represent DC A through I, respectively. The nodes are arranged in a logical order. For example, assuming node B represents Europe-England, then logical child nodes in Europe might be Europe-France (e.g., node D) and Europe-Germany (e.g., node E), and a child node of Europe-France might be Europe-Italy (e.g., node H). In this example where the left side of the tree represents Europe, the right side may represent Asia. Node A is the root node and may represent a central control station, for example. In one or more embodiments, each node in the tree has a unique attribute set representing the name of the node. The attribute set for a node is stored in the node and can be represented in any convenient data structure. For example, the attribute set can be represented as a variable bitmap (a bitmap is the binary representation of an object, e.g., a number). Each node also contains a representation of the attribute set of each of the node's children, grand children, great grandchildren, etc. (i.e., all nodes emanating from that node as a root node lineal descendants). This representation is called the \u201cRolled Up Set of Attributes\u201d and any convenient data structure can be used for it. Thus the rolled up attribute of a node is the representation of the rolled up attribute of its children. For example, a \u201cRolled Up Bitmap\u201d, which is a combination of the rolled up attribute bitmaps of all the node's children, may be used. A \u201cRolled Up Bitmap\u201d may be defined as the \u201cbinary OR\u201d (a.k.a. Bitwise OR) of the rolled up attributes of the node's children.  is an illustration of the attribute bitmap and rolled up bitmap, in accordance with an embodiment of the present invention. Bitmaps , , , , , and  use 16 bits for illustration purposes but since the bitmaps are variable, they may vary as needed to identify each node and provide other necessary information.","Bitmap  representing the attribute set for node B of  has, as its identification, bits ,  and  set to 1 and all other bits set to 0. Bit  may be set because node B is a child node of A, for example, bit  may be set to represent Europe, and bit  set to represent England. Bitmap  representing the attribute set for node D of , a child node of B, has bits , , and  set to 1 and all other bits set to 0. Bit  may represent France, for example. Bitmap  representing the attribute set for node E of , also a child node of B, has bits , , and  set to 1 and all other bits set to 0. Bit  may represent Germany, for example. Bitmap  representing the attribute set for node H of , a child node of D, has bits , , and  set to 1 and all other bits set to 0. Bit  may represent Italy, for example. As discussed previously, the rolled up bitmap for node D (e.g., ) would be the attribute bitmap of node H (since H does not have any children) and the rolled up bitmap of node B (e.g., ) is the binary OR of Bitmaps , , and . The result of the binary OR is that all the bits set in Bitmaps , , and  are also set in Rolled Up Bitmap  (i.e., bits , , , , and ).","Content management server  may be connected to any node on the tree. Thus, although a content management server and a distribution center may not be collocated, the content management server gives the content provider a vehicle to upload large files (e.g., video) to the distribution centers. In one embodiment, the content management server is a computer that processes the content provider's large payload file for distribution in the network. In another embodiment, the content management server may, for example, be a subset of tools (e.g., machine independent objects) that allows upload of content to the network; thus, the tools may be shipped from a server to the content providers client's computer for processing and distribution of the large payload file in the network. After a content provider loads the large payload file into the content management server, the CMS may process the file and forward it to the distribution center.","A simplified layout of a distribution center is illustrated in  in accordance with one embodiment of the present invention. Distribution center  comprises control unit , one or more Virtual File Control System , one or more distribution server , and a plurality of storage devices (e.g., -). Control unit  is the network manager for the distribution center; its functions are further discussed in a later section. Application servers - (e.g., streaming servers, FTP servers, and media players), which are not part of distribution center , are shown connected to the virtual file control system  in this illustration to provide visibility on how end-user clients access large payload files stored in the SCDN. The components of distribution server  may not be collocated in the same node. For example, VFCS  may be located with the application servers (e.g., -), and the control unit (e.g., CU ) may be located elsewhere such as with VFCS . Thus, it is not necessary for all components of distribution center  be collocated at an SCDN node.","A content provider uploads a large payload file to a single content management server using content publishing and management tools running on a content provider client system. After receiving the file, the CMS processes the file and breaks it down, if required, into track files (a.k.a. linear files). A linear file comprises a file that maintains the order associated with the substance (i.e., substantive content) of the file. If, for example, the linear file contained a movie, the beginning of that file would include the beginning portions of the movie. Similarly, the middle and end portions of the movie would be located at the middle and end of the linear file. Linear files are desired because it is easier to reassemble such files using linear superposition, for example. Some media files are non-linear, that is, they contain multiple tracks such that the first part of the movie, for example, is not stored in the beginning of the file. After breaking the file down to linear (i.e., track) files, the CMS transfers the file to the distribution server it is connected to. The distribution server further breaks the track files down to block files, as desired for storage. The block files may subsequently be stored in local storage locations -, for example. A file distribution protocol (e.g., FDP) command is subsequently used to distribute (i.e., replicate) the file, or selected portions thereof, to other distribution server nodes within the scalable content delivery network. For initial replication, the entire block files need not be stored in all nodes however a master copy may be maintained completely in one node (typically the originating node). The FDP includes commands to facilitate file transfers and manipulations within the SCDN. The size of the blocks affects the performance of both content distribution and content delivery and is discussed later in this document.","The Virtual File Control System (VFCS)  is able to piece the original (large payload) file back together from the block files. As will be explained later, all the blocks of the large payload file need not be stored at one distribution center, however, the entire file is available within the SCDN. When an end user connects to application server  (e.g., a streaming server), the VFCS creates a virtual appearance that the entire file is available at that node. For example, assuming only fifteen percent of a two-gigabyte file is stored in storage -, the VFCS makes streaming server  think that the entire two gigabytes is available at the location. Thus, streaming server  may start playing the file. As the file is being played, VFCS communicates with DS to locate and retrieve the remaining portions of the file from other nodes in the network.","Decomposing Large Files","A large payload file is divided into blocks in a number of steps, the exact process depending on whether or not it is a linear file or a non-linear file. Using a movie file for example, the file is linear if the first 10% of the movie is located approximately within the first 10% of the file, the next 10% within the next 10% of the file, and so on. In contrast, a movie file in which the first 10% of the movie is located somewhere other than in the beginning of the file is considered to be a non-linear file.","Example linear and non-linear file structures are illustrated in FIG. . Data format  may represent the mpeg format, for example, which is linear because it contains audio\/video data multiplexed together throughout the file in a single track, starting from the beginning. Note that each subdivision in the various formats represent a track hence formats - each contains multiple tracks. As shown, format  is non-linear because it contains header information in the first track of the file, followed by meta information in the next track, then video information in the third track, then meta information in the fourth track, a first audio channel in the fifth track, a second audio channel in the sixth track, and then some control information at the end. Thus, the beginning of a movie formatted for format  would not reside in the beginning of the file. Formats  and  are representations of other possible non-linear media data formats. For example, format  may have data formatted such that the file contains header information in the beginning, then some 56K encoding for formats such as mpeg, followed by 128K encoding information. Other media format  may contain header information, followed by index information, followed by video, and finally audio information. All these and other non-linear files need to first be converted to linear files for compatibility with the replication algorithm discussed later in this specification.",{"@attributes":{"id":"P-00090","num":"00090"},"figref":["FIG. 9","FIG. 10"],"b":["950","930","900","910","920","1000","1000","1010"]},"Referring back to , the Linear Track Files  or the Linear Large Payload File  (which is also a linear track file) are (is) transmitted by the CMS over the network to a DS that it is connected to. The files may be transmitted in accordance with a File Distribution Protocol (FDP), discussed below. The files from the CMS are input to a DS-based Blocking Process , which produces Block Files . The Block Files  are subsequently stored in the local storage of the DS. After processing, the content may be downloaded by other distribution servers in the network. Generally, there need not be a direct relationship between the size of the files transferred over the network and the block files stored in the local storage system of the DS.","Blocking process  breaks down the track files into smaller, manageable units, as shown in block  of FIG. . The blocking process produces the multiple block files H, V, A, A, and C (collectively referred to as  in FIG. ). Block files may contain data overlaps or offsets (e.g., shift). For example, block file Vmay contain some part of the Header track, and so on. The only requirement for the block files in one or more embodiments of the invention is that the beginning of each track is contained in the first block file created for that track, for example, the beginning of Audio Ch is contained in Aand the beginning of Audio Ch is contained in A, etc. Other embodiments may simply breakdown the large payload file (i.e., non-linear) directly into block files without first going through the demultiplexing process (e.g., block ) thus each block file may contain overlapping tracks. Breaking down the large payload file into blocks makes it possible to distribute the block files into different storage devices and to add more storage devices when needed without impacting system performance. Thus, for example, more storage devices may be added to the distribution center () without a need to move files around or reconfigure other nodes as in the prior art. For example, different blocks may be located at different nodes of the SCDN hence on different storage devices. The smaller block files makes it possible to support multiple application servers (e.g., streaming servers) at the same time, thereby increasing access bandwidth. For example, multiple block files of a large payload file can be downloaded in parallel. Fast forward and fast reverse by a user is also possible without the entire file being first downloaded onto the streaming server.","Reconstructing Large Payload File From Block Files",{"@attributes":{"id":"P-00094","num":"00094"},"figref":["FIG. 11","FIG. 10"],"b":["1100","110","1110","1110","1150","1110","1120","1120","1130","1140"],"sub":["1","2","3","4"]},"The File Distribution Protocol (FDP)","The FDP Protocol defines the file management primitives necessary to transfer, store, and manipulate content provider files and file metadata stored in the network. Such primitives include commands that upload, distribute, deliver, modify, and delete files. The FDP commands result in one or more packets being transferred between appropriate servers in the network. It will be evident to those of ordinary skill in the art that the command names and protocol implementation described herein are used for convenience and that other commands or protocols may be added, subtracted, or substituted so long as they result in efficient and reliable transfer of files within the network.","\u201cPut\u201d: A content provider uses content management applications running on a Content Provider Client system to upload a file (content) and file metadata (data related to the management of the files being stored, transferred, and manipulated in the network) onto a Content Management Server (CMS). The CMS breaks the file into linear track files and then issues a \u201cput\u201d command to a DS that will eventually distribute the content in the network. In one embodiment, the CMS is connected to a DS at an SCDN node. The CMS sends a \u201cput\u201d command to the DS for each of the track files. In effect, the \u201cput\u201d command is a \u201cpush\u201d action, pushing a track from a CMS to a DS. A \u201cput\u201d command may include four packets, for example: \u201cput\u201d, \u201cput_response\u201d, \u201cput_chunk\u201d, and \u201cput_ack\u201d. The \u201cput\u201d packet tells the receiving DS to get ready to receive a track file. The \u201cput_response\u201d packet is a packet issued by the DS to indicate to the CMS whether or not the DS needs to receive the track file, and if it needs it, where to begin the transmission. This packet may be useful in the situation when a communication session is broken after part of a track file has been transferred and the CMS needs to re-transfer the remainder part of the file. Once the DS communicates to the CMS where to begin transferring a track file, the CMS may issue a \u201cput_chunk\u201d packet along with the actual track file. The DS may respond with a \u201cput_ack\u201d packet when the entire track file is received to indicate successful transmission. After receiving the track file, the DS divides the linear track files into block files, stores the block files in local storage, and updates the file metadata to reflect the track, block, and location information.","\u201cDistribute\u201d: After all of the tracks have been pushed to the DS, the CMS may issue \u201cdistribute\u201d packets directing the DS to distribute the file to other nodes in the network. For example, the CMS may issue one \u201cdistribute\u201d packet per track file with each packet containing the content provider's distribution criteria. The distribution criteria, for example, may specify which nodes in the network should have the content. The \u201cdistribute\u201d command may include two packets, for example: \u201cdistribute\u201d and \u201cdistribute_ack\u201d. The DS may acknowledge receipt of the \u201cdistribute\u201d command and track file by issuing a \u201cdistribute_ack\u201d packet to the CMS.","\u201cReplicate\u201d: In response to the \u201cdistribute\u201d command, the DS may issue \u201creplicate\u201d packets to its neighbors. Each neighbor that satisfies the distribution criteria specified by the content provider may issue a command (such as the \u201cget\u201d packet described below) to one or more DS in the distribution path to pull a portion of the file into its local storage. The \u201creplicate\u201d packet starts from the DS where the track files have been pushed. The \u201creplicate\u201d packet acts as a notification to a DS that it may need to pull (i.e., replicate) certain block files from any of the issuing DS into its local storage. The receiving DS may acknowledge the notification by issuing a \u201creplicate_ack\u201d packet and thereafter, it assumes the responsibility of pulling the block files from the issuing DS when it is ready. A DS further notifies its neighbor nodes to determine if they should pull part or the entire file by issuing \u201creplicate\u201d packets to them. A DS may issue a replicate request to its descendent nodes if the rolled up attribute matches the content distribution criteria.","\u201cGet\u201d: A DS that needs to pull files from another DS may issue a \u201cget\u201d command, for example. The \u201cget\u201d command may include four types of packets: \u201cget\u201d, \u201cget_response\u201d, \u201cget_chunk\u201d, and \u201cget_ack\u201d. For example, the \u201cget\u201d packet may be used to initiate a pull, and the \u201cget_response\u201d packet may be used to report the status of the station and transfer file metadata as needed. The \u201cget_chunk\u201d packet may be used to transfer file data and the \u201cget_ack\u201d packet may be used to acknowledge the end of the \u201cget\u201d sequence and report status. A DS may decide on the size of the file to pull based on: (1) its storage availability; (2) location of the station in the network map; (3) the content's popularity; (4) the truncate-able or non-truncate-able characteristic of the file; and, (5) the bandwidth allowance. A DS may issue \u201cget\u201d command sequences in response to a \u201creplicate\u201d request and a \u201csearch_reply\u201d request.","\u201cPrepare\u201d: A \u201cprepare\u201d command may include two packets, for example: \u201cprepare\u201d and \u201cprepare_ack\u201d. The node's VFCS may issue a \u201cprepare\u201d packet to a DS to pull the non-resident portions of a file for an Application Server. The DS may use the \u201cprepare_ack\u201d packet to acknowledge that it has received the \u201cprepare\u201d packet and that it will perform \u201cprepare\u201d as soon as possible.","\u201cSearch\u201d: When the DS can process the \u201cprepare\u201d request, it may issue a \u201csearch\u201d command to locate the missing portions of a file. A \u201csearch\u201d command may include three packets, for example: \u201csearch\u201d, \u201csearch_ack\u201d, and \u201csearch_reply\u201d. A DS servicing a \u201cprepare\u201d command issues a \u201csearch\u201d packet to initiate a search among its neighbors for the non-resident portions of the file. Each neighbor may issue a \u201csearch_ack\u201d packet indicating that it has received the \u201csearch\u201d request. The \u201csearch_ack\u201d packet is not an acknowledgement that the DS has portions of the requested file. A node that has a portion of the required file may issue a \u201csearch_reply\u201d packet. The \u201csearch_reply\u201d packet may include information such as the portion of the searched file residing in the station, the network condition of the station, and the load of the station's DS cluster. A DS in the initiating DS cluster receives \u201csearch_reply\u201d packets and may select appropriate remote DS nodes based on the information in the \u201csearch_reply\u201d packets to download the missing portions of the file. A DS in the initiating DS cluster may issue \u201cget\u201d command, for example, to one or more stations (i.e., selected SCDN nodes) to download the missing content.","\u201cRemove\u201d: The \u201cremove\u201d command may include two packets such as \u201cremove\u201d and \u201cremove_ack\u201d. The nodes Control Unit may issue a \u201cremove\u201d command to the DS to remove certain blocks. The pruning process, which is described later, uses the \u201cremove\u201d command. A \u201cremove\u201d packet is a notification to a DS that certain blocks have to be removed. The DS may subsequently issue a \u201cremove_ack\u201d packet to acknowledge that it will eventually remove the indicated blocks when ready.","\u201cClean\u201d: The \u201cclean\u201d command may include two packets, \u201cclean\u201d and \u201cclean_ack\u201d. The CMS may issue a \u201cclean\u201d or similar packet to notify a DS located at the same node that it needs to remove a certain file. The DS issues a \u201cclean_ack\u201d or similar packet to acknowledge that the file will eventually be removed when ready. Following the path used during the \u201creplicate\u201d command (available in the distribution criteria for the file), the DS issues a \u201cclean\u201d or equivalent command to its neighboring nodes requesting deletion of the file and its related file metadata from all the stations in the SCDN.","\u201cInfo\u201d: The \u201cinfo\u201d command may include two packets such as \u201cinfo\u201d and \u201cinfo_ack\u201d. The CMS issues an \u201cinfo\u201d packet to transfer content provider metadata (data related to management of the content providers using the SCDN) or file metadata to a DS. The packet may be used to add, delete, and modify attributes of certain content providers or files. When a DS receives content provider information, it modifies the table where content provider metadata is stored within an SCDN node, issues the \u201cinfo_ack\u201d packet to the requester (CMS or DS), and then issues \u201cinfo\u201d command to all its neighbors except the requestor. An \u201cinfo\u201d packet that contains content provider information is propagated throughout the entire SCDN. An \u201cinfo\u201d packet that contains file metadata is propagated based on the distribution criteria for that file. When a CMS sends an \u201cinfo\u201d packet of a file metadata along with the distribution criteria of the file to a DS, the receiving DS modifies its database containing the file metadata, issues \u201cinfo_ack\u201d packet to the requestor (CMS or DS), and then issues \u201cinfo\u201d packet to those neighbors satisfying the distribution criteria (i.e., those that received distribution of the file during the \u201creplicate\u201d command). This process continues until the database containing the file metadata in all the stations satisfying the distribution criteria are updated.","\u201cLearn\u201d: The \u201clearn\u201d command may be issued by a Control Unit's learning agent and may be used when a DS is added to the SCDN and its local storage needs to be initialized, or when the station's attribute changes, or with network configuration changes, or during recovery from a failure. The DS receiving the \u201clearn\u201d command propagates the \u201clearn\u201d command to all its neighbors except the requestor. The \u201clearn\u201d packet carries the attributes of the originating station. Each DS receiving a \u201clearn\u201d packet determines if its station has files that satisfy the learning station's attributes, if so, it issues \u201creplicate\u201d to a DS in the learning station to pull the relevant files.","\u201cFetch\u201d: The \u201cfetch\u201d command may be used by the Control Unit's learning agent while learning in active mode. The \u201cfetch\u201d command may include two types of packets: \u201cfetch\u201d and \u201cfetch_ack\u201d. In active learning mode, the learning agent obtains a list of media files to be learned, their associated content provider, and the assigned station of the content provider's CMS. During this time, the file metadata for these media files are not ready in the local station and thus the DS does not have the information to conduct a search and download the files. The learning agent issues a \u201cfetch\u201d packet to a local DS along with the content's origination station. The DS in turn issues a \u201cfetch_info\u201d packet to a DS of the assigned station of the content provider's CMS. After the DS obtains the file metadata for the desired media file, it stores the information into the database containing the file metadata and returns \u201cfetch_ack\u201d to the learning agent. The learning agent may subsequently proceed to issue \u201cprepare\u201d commands to download the media file.","\u201cFetch_info\u201d: \u201cFetch_info\u201d includes two packets, \u201cfetch_info\u201d and \u201cfetch_info_block\u201d. Each \u201cfetch\u201d command has encoded within it the identification of a particular media file and a particular DS guaranteed to have the media file. In response to a \u201cfetch\u201d command, a DS issues \u201cfetch_info\u201d to the DS station identified in the \u201cfetch\u201d. The remote DS may reply with \u201cfetch_info_block\u201d, which contains the information necessary to enable the local DS to save the media, track, and block metadata information into the local metadata database.","\u201cStop\u201d: The \u201cstop\u201d command may include two packets such as \u201cstop\u201d and \u201cstop_ack\u201d. The \u201cstop\u201d command is used to shutdown a DS. When a DS receives a \u201cstop\u201d packet, it immediately replies with \u201cstop_ack\u201d and depending on the termination requirement, the DS may shutdown immediately or shutdown after it completes all the jobs it is executing.","Distributing Large Payload Files","To distribute a file, a content provider sets specific distribution criteria for that file. After the distribution server (DS) stores the uploaded large payload file as blocks, the content provider requests, through the content management server, that the DS distribute the file to other nodes in the SCDN, i.e., to push the content to the edge of the network. The distribution is in accordance with specific distribution criteria set by the content provider and may use the file distribution protocol (FDP) previously described. The distribution criteria may specify regions (e.g., Europe), specific nodes, and other information as desired by the content provider to control distribution of the content. For example, the distribution criteria may include information found in the nodes attribute or rolled up attribute bitmap.","The file distribution proceeds as follows: (1) The DS responds to the content provider's request to distribute a large payload file by sending a notification (i.e., a distribution request) to its neighbors to announce the existence and the distribution criteria of the file; (2) \u201cQualified\u201d neighbors (i.e., those that meet the criteria) download several portions of the file during this initial distribution process; (3) The notification is then passed on from neighbor to neighbor, but not back to the neighbor from which the distribution request is received; (4) Each neighbor performs steps 2 and 3 until it encounters a leaf node or a \u201cterminating\u201d node. Thus, the distribution of the file in the network is done in stages.","Every node that receives a distribution request passes the request to all its neighbors except to the \u201crequesting\u201d node (i.e., the node from which it received the request). A terminating node is one where neither the node's attribute bitmap nor its rolled up bitmap match the distribution criteria and where the distribution request cannot be sent to the node's parent. For any node whose attribute bitmap matches the content provider's distribution criteria for the file, a portion of file is downloaded from the nearest neighbors in the distribution path that has the portion to be downloaded. Once downloaded, a DS stores the file locally as blocks spread over different storage volumes as shown in , blocks -. In spreading the file over several storage volumes, the Input\/Output (I\/O) load is distributed across the volumes and thus increasing the overall performance of the DS during content distribution and content delivery. For purposes of the invention, the storage volumes can be any collection of storage devices, e.g., disk arrays attached to a server, RAID (Redundant Array of Independent Disks) systems, or Network Attached Storage (NAS)), or Storage Area Network (SAN).",{"@attributes":{"id":"P-00114","num":"00114"},"figref":"FIG. 13","b":["570","530","570","570"]},"During normal operation, a Distribution Server sends FDP commands, such as replicate, info, search, and clean commands that are forwarded to all or part of the network, through other Distribution Servers in the immediate neighbor stations in its control path. For example, when a Distribution Server receives an FDP command such as replicate or info, it sends the command to its neighbor DSs based on the FDP distribution criteria. In the situation when one of the neighbor stations is failed, the DS keeps the job in its job queue, and repeatedly retries until the job is successfully completed. At the same time, the DS temporarily assumes the role of the DS in the failed station by forwarding the FDP command to the neighbor DSs of the failed station.","The FDP uses the content provider's distribution criteria to direct the distribution of the large payload file in whole or in part to all nodes in the network meeting the provider's distribution criteria. A distribution request can start from any node in the tree, and traverses up and down the tree until it reaches a leaf node or arrives at a terminating node. For any node having the appropriate attributes, the file is partially downloaded from the nearest neighbors that meet specific performance criteria if those neighbors contain the portion of the file to be downloaded. The nearest neighbor when downloading content is not necessarily the nearest in the virtual tree but nearest in terms of distance. This prevents massive transfers from the node at which the file is initially uploaded. Moreover, the staging nature of the distribution prevents excessive demands on the network around the initial node (e.g., node B). By delivering smaller blocks and only a partial file this delivery method reduces network load. Additionally, because the distribution requests stop progressing through the SCDN when they arrive at a \u201cterminating\u201d node, the present invention prevents unnecessary distribution request packets from flooding the network.","Accessing Large Payload Files","An end-user may request access to a large payload file (e.g., a movie) via an interface, such as a Web-browser, on the end-user's client system. The request is forwarded to an appropriate Application Server (i.e., one that is closer to the end-user and with bandwidth to service the request) that will provide the file to the end-user, e.g., a Streaming Server for delivering large video files, or an FTP Server for delivering large, media rich documents, or any media player that is capable of mounting the VFCS as its remote file system in order to have access to content in the SCDN. The application server is in the network and thus may be connected to the nearest node of the SCDN. The SCDN node's storage volumes (i.e., cache memory) may contain some, none, or all of the blocks of the end-user's requested file. If either additional or the full content of the file is needed at the Application Server, the SCDN node's VFCS communicates with a local DS to issue a search request, on behalf of the Application Server, to all the DS's neighbors to locate the needed (non-resident) portions of the file.","For example, assume the requested large payload file is 10 Gbytes in length, corresponding to a total of 20 blocks of 500 Mbyte storage (i.e., if each block is 500 Mbyte). Further, assume only 6 such 500 Mbyte blocks reside locally within the SCDN node. Even though only 3 G bytes of the requested file are actually stored in the SCDN node's storage system, the entire file \u201cappears\u201d to exist locally to the Application Server via the VFCS. At the request of the VFCS, the non-resident portions of the file are pulled from different distribution servers in the SCDN and stored locally as the Application Server streams the file to the end-user. Portions of the file might be retrieved from several distribution servers concurrently. Typically, data received over the SCDN are stored as blocks in the shared Storage (e.g. local storage volumes). The VFCS assembles and multiplexes the stored block files into the 10 GByte file in real time so the Application Server can use it (e.g., stream the file to the end-user).","To locate the non-resident portions of the file, a DS in a cluster of DSs issues a search request that traverses the SCDN tree, starting from its neighbor nodes. The search request may include the distribution criteria of the requested file and a time-to-live counter. A time-to-live counter may, for example, specify that the search request need only traverse two hubs of the SCDN from the requesting node. When a neighbor node receives and evaluates the search request, the node may decrement the counter, for example. A search request terminates when it encounters a leaf node, a \u201cterminating\u201d node or the time-to-live counter is zero (i.e., where the search request includes a counter). Where the missing data is not located and the time-to-live counter reaches zero, i.e., if it is included in the search request, the search request continues by traversing the SCDN nodes in the reverse path of the initial distribution process. A node replies directly to the requesting DS if the requested part of the file exists in that node. Nodes not having any portion of the requested file do not reply. A reply also includes the performance status of the node that sends the reply and the portions of the file available. When the requesting DS cluster receives reply packets from any nodes in the SCDN indicating that they contain part or all of the requested file, the DSs in the cluster download the missing content from those nodes that are least congested and stores it locally in the distribution server's shared storage volumes. Thus, as the application server is providing the data to the end-user, the distribution servers are obtaining the remainder of the file from other nodes and there is no break in the communication between the application server and the VFCS.","As discussed earlier, a large payload file is broken down into portions (e.g., block files) and distributed throughout the SCDN. Thus, when nodes that contain portions of the file are found through the search request, a cluster of DSs can download portions of that file in parallel from multiple nodes, especially from those nodes that are currently the least congested. The initiating DS cluster decides, based on the performance information in the reply packets, where to download (i.e., \u201cpull\u201d) missing content so as to minimize the latency and bandwidth demands on other distribution server nodes.","Content portions are pulled from the appropriate distribution servers and assembled in real-time for the end-user by the VFCS, running on one or more VFCS Servers. The VFCS enables the Application Servers to view the distributed storage volumes that exist in the SCDN as a single, large virtual file system.","Retrieving Non-Contiguous File Segments","From one perspective, each stored block in the system storage of an SCDN node corresponds to a contiguous segment of a large payload file (e.g., a contiguous interval of movie). For example, the segments that comprise a movie, if viewed one after the other from the first segment to the last segment, would result in viewing the entire movie. Since the same content portions (i.e., segments) are located at several different nodes in the SCDN, non-contiguous segments of a file (e.g., non-contiguous portions of a film) can be retrieved independently and in parallel. This has several important side effects. For example, since a DS can obtain needed content portions from several different distribution servers, the reliability and availability of the SCDN are significantly increased. Additionally, the end-user can efficiently access segments of a large payload \u201cout-of-order\u201d, e.g., fast-forwarding of a movie can be realized without actually having to download all of the portions of the film that are not actually viewed. Importantly, pruning (freeing the storage used by some blocks for use by other blocks) can be done at the \u201cblock level\u201d (versus the entire \u201cfile level\u201d) based on specific content provider policies, e.g., pruning can be based on usage patterns. Usage of the content can also be rated at the block level.","Block Size and File Distribution","The size of the blocks affects the performance of both content distribution and content delivery. Several important factors are considered in determining a block size: 1) Ethernet MTU (Maximum Transmission Unit) size, 2) the size of the physical units of storage, 3) the time required to transfer a block (which is related to the network bandwidth), and 4) the shortest acceptable period to be skipped in response to a fast forward or rewind command during content delivery (this is called the minimum flash interval).","Several goals come into play in determining the block size. One goal is to maximize space usage within an MTU, which would make content distribution more efficient. Another goal is to minimize congestion at the distribution nodes. Another important goal for determining block size is to prevent storage fragmentation, since fragmentation degrades file system performance, again consistent with achieving the other goals.","Block sizes that are too big or too small can affect performance. Consider the fast forward command, for example. If the block size were too big, server response to fast forward requests during a download would be sluggish, as the server has to finish downloading the particular block file before it can process such requests. Conversely, if the block size were too small, fast forwarding to the end of the block would be very quick. If the block size is within the minimum flash interval, another distribution server can respond to fast forward requests by retrieving the block containing the target content.","Based on the above criteria, assumptions made about the physical network that supports the SCDN, and assumption relating to the size of the flash interval and minimizing network congestion, the block size in a one embodiment may be 256 Kbytes, for example. It will be evident to those of ordinary skill in the art that the block size could change when one or more of the assumptions change and that the value may be implementation and application specific.","Additionally, the block size in the storage of a delivery network does not have to be a constant. Each DS in the network may have its own setting depending on the specific nature of the storage devices and its network condition. Each file may have a different block size.","The number of blocks distributed to a qualified node during the initial file distribution phase is determined by a number of factors, including the distance from the originating DS (i.e., where the file was uploaded) to the node, the front and back end bandwidth of the node (the current network conditions), predicted network conditions, the history usage information of the node, a \u201cpopularity\u201d index set by the content provider, as well as the storage available at that node to the content provider.","Scalability and Adaptability Learning and Pruning","A SCDN in accordance with an embodiment of the present invention is highly scalable. For example, when a new node is added to the SCDN, it downloads the initial content it needs by employing one of several different adaptable initialization processes. In one embodiment of the invention, an \u201cAuto-initialization\u201d process is used. When a node is added to an SCDN, it is given a set of attributes. In the auto-initialization process, as soon as the node is connected to the network, it issues an FDP \u201cLearn\u201d or similar request to all its neighbors. The node encodes its attributes in the learn request. The neighbors offer content, consistent with the new node's attributes, to it for downloading. The neighbors then pass on the new nodes learn request to all of their neighbors, which take similar action. Thus, the new node's learn request traverses the entire network and all the nodes in the network respond to the learn request if they have contents appropriate for the new node. The new node collects all the information, downloads the necessary initial contents, and is now a functioning element of the SCDN.","An example of this auto-initialization process will be discussed in the context of , which illustrates new node J added to the SCDN. A learn request is initiated by node J as soon as it is connected to the SCDN. It issues the learn request, which contains its attribute bitmap, to all its neighbors.","In this example, there is only one immediate neighbor, node G. When node C receives the \u201clearn\u201d request, it compares node J's attribute bitmap to the distribution criteria of its own content. Node G replies to node J if it has any appropriate content for node J to download. Node G then passes the learn request to all its neighbors (i.e., Nodes I and C) other than node J, the initiating node. Each node to which the request is passed likewise evaluates the learn request, conditionally replies, and propagates the request in accordance with the foregoing. The learn request terminates when it encounters a leaf node or a \u201cterminating\u201d node.","As the learn request traverses the SCDN, all the nodes respond to node J if they have contents that node J should have. Finally, node J collects all the response information and downloads the necessary initial contents from the nodes that can most optimally supply them. Node J is now available to service content delivery requests.","There are additional situations in which learning and adaptation processes may be used in other embodiments of the invention. For example, as a large payload file is accessed, VFCS serves the content to Application Servers (such as Streaming Servers), while it also communicates with distribution servers to pull missing content portions from other locations. As more and more content portions are downloaded to satisfy end-user requests, the storage space for each content provider must be carefully monitored. Based on storage availability and usage information collected by VFCS, a pruning process could be used to remove certain blocks of media files. The policy associated with the pruning process should address: (1) when to prune, (2) how much to prune, and (3) which blocks to prune. After pruning, a server's storage system may contain entire media files or non-contiguous segments of files that are accessed frequently by local users. Additionally, the content provider might be apprised that more storage or more Distribution Servers, Application Servers, or VFCS Servers should be added to the network.","Scalable Content Delivery Network with Stations",{"@attributes":{"id":"P-00139","num":"00139"},"figref":["FIG. 14","FIG. 5"],"b":["1400","500","500","1410","1420"]},"As in the earlier embodiments, the stations of SCDN  are organized in a logical virtual tree structure in which each node in the tree has a set of attributes. Thus, each Station has an attribute set that is stored in the node and can be represented in any convenient data structure, e.g., the attribute set can be represented as an attribute bitmap. Furthermore, each Station (i.e., node) also contains a representation of the rolled up attribute set of each of the station's child-Stations. This representation is called the \u201cRolled Up Set of Attributes\u201d and any convenient data structure can be used for it, e.g., a \u201cRolled Up Bitmap\u201d, which may be the defined as the \u201cbinary OR\u201d combination of all rolled up attribute bitmaps from the child-Stations. The distribution servers within a Distribution Server Cluster use the attribute bitmap to distribute and route portions of large payload files and they use the aggregated rolled-up attribute bitmap to terminate unnecessary propagation of messages. One of the Stations in an SCDN is designated the \u201cCentral Station\u201d. The Central Station holds an attribute database table that matches text strings to bit positions, e.g., a reference table. Central Station  is not necessarily a data repository for all content but may contain some or all the content.","In one or more embodiments of the present invention, an SCDN station (a.k.a. \u201cData Center\u201d) may be configured as shown in FIG. . Station  includes a Distribution Server Cluster (DSC) , an Application Server Cluster (ASC) , a Control Unit (CU) , a shared Storage System , a Storage Switch , and Intra-Station Control related Switch . The distribution server cluster  communicates with storage system  through storage switch  using communication links  and . The application server cluster  communicates with storage system  through storage switch  using communication links  and . The control unit , distribution server cluster , and application server cluster  all communicate through intra-station control related switch , which communicates with storage switch . The control unit has its local storage system . The various components will be discussed in more detail later in this specification.",{"@attributes":{"id":"P-00142","num":"00142"},"figref":["FIG. 16","FIG. 16","FIG. 14"],"b":["14","505","1605","1","1605","1610","1","1650","1640","1630","1620","1650"]},"As shown, end-user client systems (e.g., EUC  and EUC ), generally access or provide email, web-pages, and other Internet-based resources, via Telecom Access Facility  or via connection through subsidiary portions of corporate networks . CPCs (e.g., ) generally upload content via connections within a corporate network, although access via a telecom access facility is also common.","The station specific local network  may include one or more hubs, switches, or routers that interface the station components to the network within the facility where the station is located. The exact configuration of station specific local network  is a function of the scale of the station configuration (i.e., the number of each particular kind of server and the number of storage volumes), the various traffic flows expected for each station component, and the particular details of the facility where the station is located. While the station is shown at co-location facility , this is merely illustrative, as the station could be located anywhere within the larger network.","Distribution Server Clusters","A Distribution Server Cluster (DSC) provides, among other things, system fault tolerance and scalability.  is an illustration of a distribution server cluster configuration. DSC  includes a plurality of Distribution Servers - through -N (collectively, ) and a Load Balancer . The distribution servers, , access data (e.g., Block Files) on Storage Volumes - through -V (collectively, ) in the shared Storage System  via Switch . A DS (e.g., DS -) in the distribution server cluster may issue a request (e.g., a search request) to a DS of a neighbor station via requests that are components of Outbound Traffic . Similarly, a DS of a neighbor station may issue a request (e.g., a learn request) to a DS within DSC  via requests that are components of Inbound Traffic . The Load Balancer  dispatches the Inbound Traffic  to one of the distribution servers - through -N. Load Balancer  may be implemented as a load balancing router in various topological combinations with a standard router and may also handle the outbound DS Traffic (e.g., ).","Each DS treats its requests (search, learn, etc.) as jobs to be executed. The jobs are stored and managed in Job Queues - through -N (collectively, ) in the memory (e.g., random access memory) of each respective server. Job Queue Images - through -N (collectively, ) corresponding respectively to Job Queues - through -N, are stored in a database in the Storage System . As discussed below, the station's Control Unit (CU)  manages this and a number of other databases in Storage System . Note that the database containing Job Queue Image  is mapped onto Storage Volumes  merely for convenience in making the illustration. It should be apparent to those of ordinary skill in the art that the Job Queue Image database and other SCDN-related databases may be mapped onto any available Storage Volumes.","Each DS periodically registers a \u201cheartbeat\u201d in a Control Unit database and, periodically, they watch for each other's heartbeat. During startup (e.g., power-up), the distribution servers in a DSC vote for a \u201cMaster Server\u201d. If, for example, DS -, misses h heartbeats, where h is a configurable parameter, it is assumed that DS - is no longer functioning. The Master Server then re-distributes the jobs associated with DS - to the active (i.e., living) distribution servers within the DSC. If the Master Server ceases to function, all the living distribution servers vote for a new Master Server. The new Master Server then re-distributes the previous Master server's orphaned jobs, if any exist.","In the event that the Control Unit's database is no longer accessible, the distribution servers function as usual except that their job queues are mirrored to the local storage of each individual server machine. During this time, it could happen that either a DS's job queue database cannot be accessed or a DS crashes. If either event occurs, the server machine would eventually need to be re-started. It would then read and recover all the jobs saved in its local file system prior to the failure.","Application Server Clusters","An Application Server Cluster (ASC) provides, among other things, services to the end-user (e.g., streaming a full-length movie to an end-user's client system), while providing system fault tolerance and scalability.  provide three illustrative embodiments of the application server cluster. Across all three embodiments, ASC  includes Load Balancers  and , a plurality of Application Servers - through -M (collectively ), and a plurality of VFCS Servers - through -L (collectively ). The application server clusters provide fault-tolerant and scalable system performance. For example, if one of the Application Servers fail or if one of the VFCS Servers fail, one of the other existing Application Servers or VFCS Servers, respectively, will process the requests. Similarly, if more system performance is required, the Application Servers, VFCS Servers, or storage capacity of the Storage System can be increased as required.",{"@attributes":{"id":"P-00152","num":"00152"},"figref":["FIG. 18A","FIG. 18A"],"b":["1520","15","1810","1840","1530","1540","1820","1830","1810","1840","1820","1830"]},"An end-user requests a large payload file using a standard interface (such as a web browser) that is running on the end-user's client machine. As a result, a service request for the file is sent to an ASC and arrives at Load Balancer . The inbound data packets for the service request are forwarded by Load Balancer  to one of the Application Servers , e.g., Application Server - (an arbitrary illustrative one of - through -M). Application Server - issues a request for the required data to Load Balancer . Load Balancer  selects one the of station's VFCS Servers , e.g., VFCS - (an arbitrary illustrative one of - through -L), to handle the request and forwards the data packets from Application Server - to VFCS -. Assuming all of the requested data is present in Storage System , VFCS - processes the request by accessing the data in Storage System  via Switch  and sends data and response back to Application Server - via Load Balancer .","When Application Server - establishes a session with VFCS -, Load Balancer  continues to forward data back and forth between Application Server - and VFCS -. If Load Balancer  supports the previously described (i.e., in the background section) \u201csticky\u201d feature and the \u201csticky\u201d feature is turned \u201con\u201d, data from Application Server - may continue to be directed to VFCS - beyond the current session, if VFCS - remains available (i.e., if Load Balancer  does not allocate VFCS - to another Application Server). When VFCS - becomes unavailable, Load Balancer  directs data packets from Application Server - to another VFCS Server, e.g., VFCS - (another arbitrary illustrative one of - through -M). VFCS - processes the request from Application Server - and sends response data packets to Application Server - via Load Balancer . Data packets from Application Server - are sent back to the client via Load Balancer . Just like Load Balancer , Load Balancer  maintains a persistent session between the end-user's client system and Application Server -. Load Balancer  may also provide the \u201csticky\u201d feature.","When a new request from a different end-user client system arrives at Load Balancer  of the ASC, Load Balancer  forwards the new request to an available Application Server, e.g., Application Server - (another arbitrary illustrative one of - through -M). Application Server - processes the request and in turn makes a data request to one of the station's VFCS Servers via Load Balancer , e.g., VFCS - (another arbitrary illustrative one of - through -L). Load Balancer  then forwards the data packets from Application Server - to VFCS -. VFCS - processes the request from Application Server - and sends responses back to Application Server - via Load Balancer . Application Server - sends responses to the new end-user client system via Load Balancer .",{"@attributes":{"id":"P-00156","num":"00156"},"figref":["FIG. 18B","FIG. 18B","FIG. 18B"],"b":["1520","15","1520","1810","1","1810","1810","1820","1825","1830","1835","1840","1","1840","1840","1840","1530","1540","1820","1830","1825","1835","1810","1840","1820","1830","1825","1835","1830","1835","1810","1840"]},"The present embodiment leverages the fact that the outbound traffic from both the VFCS Servers  and the Application Servers  of the application server cluster is significantly higher than the inbound traffic. As shown in , the outbound traffic is sent to Router  and Router  and Load Balancer  and Load Balancer , while the inbound traffic is sent to the load balancers and not the routers. By separating the inbound and outbound traffic, this embodiment contributes to network performance improvement.","An end-user requests a large payload file using al standard interface (such as a web browser) that is running on the end-user's client machine. As a result, a service request for the file is sent to an ASC and arrives at Load Balancer . The inbound data packets of the service request are forwarded by Load Balancer  to one of Application Servers , e.g., Application Server - (an arbitrary illustrative one of - through -M). Application Server - issues a request for the required data to Load Balancer . Load Balancer  selects one of VFCS Servers , e.g., VFCS - (an arbitrary illustrative one of - through -L), to handle the request and forwards the data packets from Application Server - to VFCS -. Assuming all of the requested data is present in Storage System , VFCS - processes the request by accessing the data in Storage System  via Switch  and sends the data and a response back to Application Server - via Router .","When Application Server - establishes a session with VFCS -, Load Balancer  continues to send data from Application Server - to VFCS -. If Load Balancer  supports the \u201csticky\u201d feature and that feature is turned \u201con\u201d, data from Application Server - may continue to be directed to VFCS - beyond the current session, so long as VFCS - remains available (i.e., if Load Balancer  does not allocate VFCS - to another Application Server). The data from VFCS - to Application Server - flows through Router . Router  forwards data packets it receives from VFCS - to Application Server -. Application Server - sends data packets to the end-user client system via Router .","When a new request from a different end-user client arrives at Load Balancer  of the ASC, Load Balancer  forwards the new request to an available Application Server, e.g., Application Server - (another arbitrary illustrative one of - through -M). Application Server - processes the request and in turn issues a data request to one of the VFCS Servers via Load Balancer , e.g., VFCS - (another arbitrary illustrative one of - through -L). VFCS - processes the request from Application Server - and sends data back to Application Server - via Router . Application Server - sends response data back to the end-user client system via Router .",{"@attributes":{"id":"P-00161","num":"00161"},"figref":["FIG. 18C","FIG. 18B"],"b":["1520","15","1825","1810","1840","1835"]},"Inbound client data packets flow through Router  to Load Balancer . Load Balancer  then dispatches the inbound traffic to the Application Servers via Router . All outbound traffic flows through Router  to the end-user client system. Inbound traffic to the VFCS Servers flows from Router  to Load Balancer  and Load Balancer  dispatches the inbound traffic to the VFCS Servers via Router . VFCS Server outbound traffic flows through Router  to the corresponding Application Servers. Again, Load Balancer  and Load Balancer  may be the same physical unit, and Router  and Router  may be the same physical unit. Also, Application Server  and VFCS server  may be contained in the same physical unit thereby eliminating one of load balancers  and  and routers  and . Thus, a configuration according to an embodiment of the present invention eliminates load balancer , router , and combines application server  with VFCS server .","The embodiment of  requires the least hardware. Moreover, it requires a load balancer with enough capacity to handle both inbound and outbound traffic cluster. The embodiments of  have obvious advantages for clusters with heavy outbound traffic and lower inbound traffic. Both require two small capacity load balancers. In the embodiment of , the inbound and outbound traffic is split between the load balancers and routers, while in the embodiment of , the inbound and outbound traffic goes through the routers, which use the load balancers as a resource. For application server clusters with heavy two-way traffic, smaller capacity load balancers and routers are desired such as in the embodiments of . The embodiments of  may be configured using load balancers that can operate in transparent mode.","The Virtual File Control System (VFCS) Protocol and VFCS Servers","How a VFCS Server processes an Application Server's file request if all of the requested data is present in the Station's Storage System was discussed in the immediately preceding section. What a VFCS Server does if all of the requested data is not present in the Station's Storage System is now discussed in the context of FIG. .","Assuming that VFCS - is processing requests for Application Server -. If either additional or the full content of the requested file is needed by Application Server -, VFCS - seeks the assistance of a distribution server in the Station's distribution server cluster (e.g., ) to retrieve the missing content. This communication may be accomplished using intra-station data communication over a path that includes Intra-Station Control-Related Switch , data communications path  between Load Balancer  and Switch , and data communications path  between VFCS Servers  and Switch . It will be evident to those of ordinary skill in the arts that the path just described is merely illustrative and that many other means for accomplishing the required communication may be used.","VFCS -'s request to the DSC is input to the Load Balancer . The load balancer (e.g., ) then selects an available distribution server, e.g., DS - (an arbitrary illustrative one of - through -N), to service the request. DS - issues a search request as a component of Outbound DS Traffic, on behalf of the Application Server -, to each of its neighbor Stations to locate and download the needed portions of the file. This searching and downloading process has been described above.","When DS - receives reply packets from the neighboring Stations indicating that they contain part of or the entire requested file, distribution servers  in DSC  will download the missing content from those Stations that are least congested and stores it locally in Storage System  via Switch . VFCS - then processes Application Server -'s request by accessing the data in Storage System  via Switch  and sends data and response back to Application Server - via Load Balancer .","The Content Repository of an SCDN station may include several storage volumes (see FIG. ). During access of a content file via VFCS , if the VFCS detects that all the block files that make up the requested content file are not available locally, it signals the DSC  via an FDP prepare command to download the missing portions from other SCDN nodes. A DS in the DSC  issues an FDP search command to DSs in its neighbor nodes in attempts to locate and download the missing block files from the least congested stations. As the block files are downloaded, the metadata of the content file is updated to register the existence of the block files in the local storage volumes.","In the event of failure of local storage volumes, data resident in the local storage volumes that are destroyed are treated as if they are missing by the VFCS. Hence, when a storage volume is destroyed, and access to some block files of a content file is requested, the VFCS will detect that the block files are not accessible and signal the DSC that the block files are missing via the FDP prepare or similar command. A DS in the DSC simply assumes that the block files do not exist locally under this situation, thus it searches for the missing blocks in the SCDN network. When the missing data is located, the DSs in the DSC download the missing blocks and then update the file metadata accordingly. Over time, block files on destroyed storage volumes are automatically recovered and stored in the good storage volumes.","In order to achieve the VFCS functions described in this and previous sections, the VFCS can be implemented either as a stackable file system, as a proxy file server using an underlying network file system such as NFS or CIFS, or as a storage area network, or direct attached storage, or as a combination of these methods. One such implementation in which VFCS is a proxy file server using the NFS protocol as an underlying network file system protocol is described.","One of the main tasks of the VFCS is to reassemble block files in real time before sending them back to an Application Server such that the Application Server thinks that file I\/O is done on a single file. In one embodiment of the invention, the Application Server may use the NFS protocol to communicate with the VFCS. In the NFS Protocol, a NFS client needs to obtain the file handle for the root of a file system before the file can be accessed remotely. A NFS client uses the NFS \u201cmount\u201d protocol to obtain a \u201cfile handle\u201d from a remote physical file system. The NFS mount protocol allows the server to hand out remote access privileges to a restricted set of clients and to perform various operating system-specific functions that allow, for example, attaching a remote directory tree to a local file system.","The VFCS enables the Application Servers to view the distributed storage volumes that exist within the SCDN stations as a single, large, distributed virtual storage system via the VFCS distributed virtual file system. While the VFCS does not actually provide the Application Servers with direct (physical) access to the real disk files, each VFCS Server may do an NFS mount in such a way that the Application Server it is serving perceives the VFCS distributed virtual file system as being physically mounted on the VFCS. To achieve this, each VFCS Server acts as both NFS server and NFS client at the same time when performing a single file I\/O request for an Application Server. Each VFCS Server has to support the NFS mount protocol when its role is as an NFS server and it must do an NFS mount as a client when accessing files from the station's Storage System devices, such as NAS devices. Thus, there are two different \u201cmount\u201d operations supported in VFCS to achieve file I\/O transparently with respect to the Application Servers.","VFCS Server File System Overview","When each VFCS Server is initialized during its startup procedure, a VFCS mount daemon initializes a locally instantiated (private to each VFCS Server) \u201cFile System\u201d via the NFS mount procedure. The file system does not necessarily exist physically on any attached storage devices. In an illustrative embodiment, a private file system exists in the main memory (e.g., some variant of Dynamic Random Access Memory) of each VFCS Server. Each VFCS server's private file system uses a \u201cVFCS name space\u201d that is identical across all the VFCS Servers. That is, each VFCS Server references the files held in the shared System Storage using a common hierarchy and naming protocol. More specifically, every file in each VFCS server's private file system tree has a common and unique locator (path name) and handle. This common VFCS name space allows each file mounted at the station to have a unique content locator (filename) associated with it. This allows the same filename to be used by all of the station's VFCS Servers with identical result. Thus all of the VFCS Servers within a Station have equal access to the entire collection of large payload files that are mounted at the Station. Whenever an Application Server invokes its VFCS Client (i.e., a VFCS access routine running on the Application Server) to mount the distributed virtual VFCS, the root file handle of the distributed virtual VFCS file system in the station's Storage System is returned. This root file handle is then used to access large payload files in the distributed virtual VFCS. Because all of the station's VFCS Servers access the identical VFCS name space, any VFCS Server could use the root handle. In the event a VFCS Server crashes, the VFCS Client (running on the Application Server) retries accessing the requested file using the root file handle. Transparent to the Application Server, the retry request is routed to a different VFCS Server. The file handle thus offers a persistence feature across all of the VFCS Servers in that it can survive crashes of one or more individual VFCS Servers.","Station Control Unit and Data Repository",{"@attributes":{"id":"P-00177","num":"00177"},"figref":["FIG. 20","FIG. 20"],"b":["1410","1550","2000","1550","1550","2050","2060","2070","2080","2000","2010","2030","2040","1530"]},"The Control Unit's Service Management Subsystem  manages the station's DSs and VFCS Servers. The Resource Management Subsystem  supports SCDN network and service configurations and log and usage data roll up activities. Learning Subsystem  supports auto-initialization, incremental content learning, and other adaptive methods for management and control of the station. Storage Management Subsystem  monitors cluster storage usage, supports content rating and pruning, and notifies the CMS of the storage usage of each content provider. Service Management Subsystem  monitors and controls services based on threshold settings, issues SNMP (Simple Network Management Protocol) traps, export Enterprise MIB (management information bases), and export history, statistics, and event data. It will be evident to those of ordinary skill in the art that the functions described herein are used for convenience and that other functions may be added, subtracted, or substituted so long as they result in efficient and reliable control and management of the SCDN station.","Control Subsystems of the Station Control Unit","Resource Management Subsystem  includes a Configuration Server, a Resource Manager, and a Content Usage Statistics Rollup Agent. The Configuration Server supports the configuration of the Station, i.e., the initialization and maintenance of the configuration data in the Network Resource Repository.","The Configuration Server of the Central Station allows the configuration of an attribution table for the SCDN. This configuration data is also maintained in Network Resource Repository . Using  as an illustration, when a new station (e.g., Station J) is created and configured, the Resource Manager of Station J notifies the Resource Manager of its parent station (e.g., Station G) and the Resource Manager of the Central Station to update their topology maps and roll up the attributes of Station J. The Resource Manager of Station G updates its partial topology, notifies its DSs of the new station, and sends its neighbor station's (e.g., Stations C and I) Resource Managers the same data. All Resource Managers within a two-hub, for example, vicinity of Station J update their partial topology map and notify their DSs. The Resource Manager of Station G then rolls up the attributes of Station J to the Resource Manager of the parent of Station G. In the successive roll-ups that follow, the attributes of Station J would reach all the way to the SCDN's root station.","When the Resource Manager of the Central Station receives a new station notification, it adds the new station to its SCDN network topology. The Central Station keeps a full copy of the SCDN network topology. Only the Central Station owns the SCDN attribute table; thus, its Resource Manager responds to queries regarding entries in this table.","When attributes of Station H are changed, the attributes are rolled all the way up to SCDN's root station through the chain of Resource Managers. The Resource Manager of Station H also invokes its local Learning Agent to update the local content in accordance with its new attributes.","In the event of changes to the IP address of the Control Unit of Station H, or the IP address of the primary DS of Station H, or the IP address of the DSs \u201cLoad Balancing Router of Station H, the Resource Manager of Station H would notify all neighboring stations\u201d Resource Managers to update their Network Resource Repository. These Resource Managers would in turn notify their neighbors of the changes. The propagation of the changes may terminate after two-hubs.","A Resource Manager manages the local Network Resource Repository data, communicates with other Resource Managers to update the data, and distributes the configuration data to the local services, such as the DSs and VFCS Servers. A Content Usage Statistics Rollup Agent periodically rolls up Content Service and Content Usage to the relevant Content Management Server.","The Learning Subsystem  provides adaptive methods of station management and control. Learning occurs when the attributes of a station changes, which includes the creation of a new station. Learning can also be used to recover content due to storage failure. Learning is performed by the Learning Agent in the Learning Subsystem and is invoked by the Resource Manager. In one embodiment of the invention, there are two different learning modes active and passive, content learning includes two phases the discovery phase and the content modification phase.","In Active mode, during the discovery phase, a Learning Agent queries all Content Management servers in the network for a list of contents to be downloaded or deleted as a result of the attribute changes. The Learning Agent locates the Content Management Servers from the Content Provider Data Table in the Content Repository. For a new station, the Learning agent gets the Content Provider Data Table from its SCDN parent node and saves the table into the Content Repository of the new station. During the content modification phase, which follows the discovery phase, the Learning agent deletes unnecessary content by issuing remove requests to a local DS for the specific media files to be removed. To add content, the Learning agent iterates through the content list it obtained during the discovery phase, and for every file in the list, it issues an FDP \u201cfetch\u201d or similar request to the DSs in Station H. For each file, a DS in Station H issues a \u201cfetch_info\u201d or similar packet to the DSs of the assigned station of the appropriate content provider's CMS. This is done to retrieve each file's metadata. A DS in Station H then issues an FDP search or similar request to each of its neighboring DSs to locate the file. Whenever a DS in the network, for example a DS in Station D, receives a search request for a file, the DS passes the request to all its qualified neighbors (e.g., Station B). If the requested file exists at Station D, the DS in Station D issues an FDP type \u201csearch_reply\u201d to the DSs in Station H. A DS at Station H then issues FDP \u201cget\u201d to download the content. A search request may yield multiple \u201csearch_reply\u201d commands being sent to the learning station. Each \u201csearch_reply\u201d includes the service and network load of the searched Station D. The DSs at Station H download each file from the least \u201cbusy\u201d station(s). A file may be downloaded from multiple locations in parallel. The FDP protocol includes a priority tag. The Learning Agent may control its learning speed by adjusting the priority tag in the prepare request. The Learning Agent may also control its fetch request rate. One advantage of active learning is that the content learning table can be manually created to direct a Learning Agent to delete or download content. As the DSs download new files, the Learning Agent picks up the history log from the local DSs and determines when learning has been completed.","In the passive learning mode, during discovery phase, the Learning Agent issues a learn request to the DSs at every neighboring stations. The learn request includes the old and new attributes of the learning station. Every station forwards the learn request to its own neighbors, such that the learn request would propagate through the entire network. Upon receiving a learn request, a DS at a given Station (e.g., B) examines the old and new attributes of the learning Station (e.g., H), and obtains a list of necessary media files for Station H from Station B's local storage. For each media file in the list, a DS at Station B issues an FDP \u201creplicate\u201d or similar request to the DSs at Station H. Station H collects the list of necessary content, figures out what it needs to delete and what it needs to download. During the content modification phase in the passive mode, based on the list of content it obtained during the discovery phase, the DS cluster in Station H issues \u201cremove\u201d command to itself to remove unnecessary content, and \u201cget\u201d commands or similar request to the DSs in the Station where the \u201creplicate\u201d request was issued (e.g., B) to download portions of the file. A DS may yield the processing of learn requests to other more important requests. The learn request may result in the issuance of the \u201creplicate\u201d notification for the same media file from one or more stations, by downloading a file from multiple locations, the DS is preventing congestion of any particular node in the network.","The Storage Management Subsystem  includes a Storage Management Agent as its primary component. The Storage Management Agent 1) monitors the total local storage availability and the storage availability of a content provider; 2) adjusts the \u201cpopularity\u201d index of a file; 3) determines a storage safety threshold for each content provider; 4) schedules content pruning; 5) computes pruning amount; 6) removes the least likely to be used blocks of a file; and 7) reports storage usage information and shortage warnings to Content Management servers.","The content provider, through a Content Management application, sets the initial \u201cpopularity\u201d index of a file. This initial value serves as a prediction of the likelihood of the file to be accessed in the near future. The DSs rely on the \u201cpopularity\u201d index, along with storage availability, location of station, and network environment, to decide on what portions of a file, the initial block size, and the number of blocks that is output to local storage by the blocking process  (FIG. ).","The Storage Management Agent uses the VFCS Server history log data and data in the File Metadata Database to determine a reasonable storage safety threshold, adjusts the \u201cpopularity\u201d index of a file, and identifies the least likely to be used blocks. A storage safety threshold is the minimum amount of free storage each content provider must reserve at all times. Based on storage availability and the DS activities, the Storage Management Agent determines the total amount of data to be pruned for each content provider and schedules the deletion of the least likely to be used blocks.","When content pruning rate for a content provider exceeds a certain limit, the Storage Management Agent issues an RPC call (Remote Procedure Call) to notify the Content Management Application server to which the content provider is assigned. The Content Management Application prevents a content provider from uploading any new content when the content provider's storage is low.","In one embodiment of the invention, the Service Management Subsystem  includes the following components: History Log Handler, Statistics Handler, Event Handler, Threshold Monitor, Trap Agent, SNMP (Simple Network Management Protocol) stack, Presentation Agent, and Service Agreement Policy Agents. A History Log Handler and a Statistics Handler collect statistics and task\/transaction logs from the local devices and Servers, and save all log and statistic information into the History and Statistics Repository. While a station is learning, a History Log Handler forwards all the file download records to the Learning Agent to notify the agent of the download status. This handler also forwards the inbound and outbound data transfer information recorded from local DSs to the Content Provider Storage Usage Table. The Content Usage and Statistics Database is also updated by the Statistic Handler.","An Event Handler saves received events into the Event Data Repository . The events stored may originate from any of the DSs, VFCS Servers, control units, or any other devices in the station. Depending on the event class and the severity of a problem, the Event Handler may report the event to the Trap Agent. The Threshold Monitor constantly compares various threshold settings against current readings collected by the Statistics Handler. If a threshold is reached, the Threshold Monitor forwards alarms to the Trap Agent. The Trap Agent receives events and alarms from the Event Handler and Threshold Monitor. It logs the events and alarms and forwards them to the Presentation Agent and SNMP Trap Agent to notify operators. The Presentation Agent distributes program objects (e.g., Java applets) to the Service Management application and to the end-user's browser. The applets channel threshold settings, performance data, network topology, usage log, and events from data repositories to network operators.","Data from the History and Statistics Repository and Event Repository can be either pushed to, or pulled from, a Presentation Agent. Service Agreement Policy Agents retrieve data from History and Statistics Repository and feed the information to a Service Agreement Policy Server, where business agreement and policy (such as guaranteed quality of service per customer) can be enforced.","Network Resource Repository of a Station","The Network Resource Repository  contains network and station configuration data. The network configuration data may include the topology of partial or the entire network and a complete attribute table. This data is created and updated by Resource Management Subsystem .","The station configuration data includes the IP addresses of all the devices, station attribute, rolled up attributes, load balancing configurations, database configuration, routing configuration, statistic data collection interval, heartbeat interval, local storage volumes and their configuration, etc. The configuration data is created and updated by Resource Management Subsystem .","History and Statistics Repository of a Station","The History and Statistics Repository  stores data gathered by the Service Management Subsystem. This data repository includes 1) history logs of the devices, 2) server and network statistics, 3) the content provider usage table, and 4) the content usage and statistic table. The foregoing data collections contain information obtained from many sources, including: the DSs, VFCS Servers, Application Servers, Learning Subsystem , load balancers, and Storage Management subsystem .","Learning Subsystem  uses the history information to interpret the state of learning.","Service Management Subsystem  evaluates statistics information and compares it to a user-defined resource-usage threshold to decide whether to send a notification to an operator via the management console, or turn services on or off as configured by the operators.","Storage Management Subsystem  uses the history logs from DSs and VFCSs to determine when, what, and how much content to prune.","The content provider usage table is generated by Storage Management Subsystem  from data gathered by Service Management Subsystem . The data roll up function provided by Resource Management Subsystem  rolls up a copy of this same information to the assigned Content Management Server of each content provider.","The content usage and statistics table data is gathered by Application Server usage log parsers and forwarded to the Control Unit's database by Service Management Subsystem . A copy of this same information is rolled up to the assigned Content Management Server of each content provider by the roll up function provided by Resource Management Subsystem .","Event Resource Repository of a Station","Event Resource Repository  includes data sets that support events (e.g., notification, warning, and error message), job queue, server heartbeat, and server registry data. The server registry data includes the Server ID, service type, etc. The Service Management Subsystem gathers the notification, warning, and error messages from a variety of local sources, including the DSs, VFCS servers, the Resource Management Subsystem, the load balancers, the Learning Subsystem, and the Storage Management Subsystem. Station \u201cevents\u201d are organized into different categories, and notifications are generated and forwarded to the management console in accordance with station configuration data. Service Management subsystem  relies on the heartbeat table to determine if a server is functioning. The DSs use the server registry, heartbeat table, and job queue to load-balance their server cluster, and to monitor one another for fault-tolerance. Service Management Subsystem  uses the server registry and heartbeat table to monitor the services in the station, it shutdown during power failure and restart services upon server failure.","Content Repository of a Station","Content Repository  includes Content Provider Information, File Distribution Criteria of the media files residing locally, File Metadata, and the content blocks. The content provider information includes the content provider's account information, assigned Content Management Server, reserved storage, number of media files, etc. The File Metadata includes the media file's attributes, information on how the media file is divided into block files, and the indexes in the local storage volumes for its block files. The content repository  may span multiple local storage volumes. For example, content blocks of a media file are distributed across multiple storage volumes. The Content repository is also called the Shared Storage System.","There are multiple storage volumes in the shared Storage System  (FIG. ). These volumes contain a number of important databases illustrated in  such as: The Content Provider Data Table, File Distribution Criteria Table, the File Metadata Database, and the content block files. These databases are stored independently and may be mapped arbitrarily anywhere within shared Storage System . The Content Provider Data Table and File Distribution Criteria Table also exist in each Content Management Server system. The tables in the Content Management Server only include the data of the content providers that are assigned to that CMS. The Content Provider Data Table at each station includes the information of all the content providers of the SCDN, and the File Distribution Criteria Table includes only the media files that are replicated to the station.","Only the DSs, VFCS Servers, and the SMS  can access the Storage System. The DSs can read and write to the shared Storage System; however, the VFCS Servers and the SMS  can only access it in a read-only mode. The Learning Agent also writes to the Storage System when it creates the initial Content Provider Data Table during the Learning Agent's initialization phase.","The Content Provider Data Table includes information such as content provider account information, the content provider assigned Content Management Server address, reserved storage, content provider's policy server, etc.","File Distribution Criteria Database includes the distribution criteria for each content file.","Block files contain the actual content for each content file. A hashed key which is a combination of the content provider ID, media file ID, track ID, and block number is used to define the path name of the block files for accelerated data access.","The File Metadata Database","The File Metadata Database holds file metadata related to the block files which includes content provider ID, initial popularity index, block size, actual usage rating, media size, attributes, minimum retained size, access time stamps, track file indices, block file indices, storage volume indices, etc.","As indicated, the file metadata specifies the block size used for its associated file. All blocks in the file are the same size, except for the last block, which will be smaller unless the file (if the file is a linear file) or the last track (if the file is a non-linear file) happens to be of a size that is an exact multiple of the block size.","The file metadata also includes information to construct a block's actual location. Since blocks can be distributed across multiple storage devices within the Storage System, there may be multiple block storage path roots. Within each storage path root, a block's location and file name are deterministic. A series of subdirectories is created to ensure that a limited number of files and subdirectories are contained within a given directory.","Distribution servers communicate with one another and the Content Management application in order to transfer large payload files in the SCDN. The DSs modify entries in the File Metadata Database when they add or remove blocks in the shared Storage System. A sequence server, which serves essentially as a lock manager, may be used to synchronize access to the file metadata database by multiple DSs, VFCS servers, storage managers, etc., to prevent possible race (e.g., conflict) condition. VFCS servers use information in the File Metadata Database to assemble and multiplex appropriate blocks into files for the Application Servers. The Storage Management Subsystem watches the available shared storage, the content provider's reserved storage, and the usage logs. It initiates the removal of less popular content to make room for more popular and new content when available storage is running low. It does this by instructing the DS to remove some of their associated blocks that are least likely to be used. It accesses the File Metadata Database to determine how many and which blocks it will request to be deleted.","The particular implementation of the Content Repository depends on the host environment. For example, it could be a traditional RDBMS (relational database management system) or it could be a collection of flat files in directories. For performance and reliability reasons, one embodiment of the invention uses flat files in directories to implement the Content Repository. Tables are implemented as either a single file with fixed-length records, or as separate files for each record. Using a single file has performance advantages when reading a complete list of records or when searching records when the record ID is not known. Using separate files has performance advantages when accessing a record via a known record ID. The Content Provider Data Table, File Distribution Criteria Table, and File Metadata Database are stored in a directory whose path is known to the interface that the DSs, VFCS Servers, and the SMS  use to access the file metadata stored therein.","Station Operation and Data Flow","Examples of Station operation and data flow are given in the context of . In conjunction with these figures, several interactions between the Application Servers, VFCS Servers, and the Distribution Servers will be identified below:",{"@attributes":{"id":"P-00223","num":"00223"},"figref":"FIG. 21A"},{"@attributes":{"id":"P-d0e6801","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Station Interactions in "}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Reference #","Interaction Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["2101A","Incoming request to Load Balancing and Routing Function"]},{"entry":[{},"1820 and 1825 from end-user"]},{"entry":["2101B","Request delivered to selected AS within AS<1..M> 1810"]},{"entry":["2101C","Application Server request delivered to Load Balancing and"]},{"entry":[{},"Routing Function 1830 and 1835"]},{"entry":["2102","Load Balancing and Routing Function 1830 and 1835"]},{"entry":[{},"selects one of the VFCS Servers, e.g., VFCS 1840-1 (an"]},{"entry":[{},"arbitrary illustrative one of 1840-1 through 1840-L), and"]},{"entry":[{},"passes the request to it."]},{"entry":["2103","VFCS 1840-1 requests a DS, via Load Balancer 1720, to"]},{"entry":[{},"\u201cprepare\u201d the file"]},{"entry":["2104A","VFCS 1840-1 begins retrieving data from the shared"]},{"entry":[{},"storage."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-00224","num":"00224"},"figref":"FIG. 21B"},{"@attributes":{"id":"P-d0e7037","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Station Interactions in "}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Reference #","Interaction Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["2104A","VFCS 1840-1 assembles and multiplexes the blocks"]},{"entry":[{},"retrieved from Storage System 1530 into a file in real time."]},{"entry":[{},"(Whenever a block is required, i.e., either now or in the"]},{"entry":[{},"future, the VFCS signals the DS of this fact. VFCS 1840-1"]},{"entry":[{},"then polls the File Metadata Datatbase until the fact that the"]},{"entry":[{},"required block has been stored in the Storage System has"]},{"entry":[{},"been indicated.)"]},{"entry":["2104B","VFCS 1840-1 passes data for the Application Server"]},{"entry":[{},"through Load Balancing and Routing Function 1830 and"]},{"entry":[{},"1835."]},{"entry":["2104C","Load Balancing and Routing Function 1830 and 1835"]},{"entry":[{},"returns data originating from VFCS 1840-1 to the"]},{"entry":[{},"Application Server. (The Application Server continues to"]},{"entry":[{},"request data from VFCS 1840-1 until the entire file has"]},{"entry":[{},"been returned or VFCS 1840-1 fails.)"]},{"entry":["2104D","The Application Server passes data for the end-user"]},{"entry":[{},"through Load Balancing and Routing Function 1820 and"]},{"entry":[{},"1825."]},{"entry":["2104E","Load Balancing and Routing Function 1820 and 1825"]},{"entry":[{},"returns data originating from the Application Server to the"]},{"entry":[{},"end-user."]},{"entry":["2105","Load Balancer 1720 selects an available DS, e.g., DS"]},{"entry":[{},"1710-1 (an arbitrary illustrative one of 1710-1 through"]},{"entry":[{},"1710-N), and forwards the request from VFCS 1840-1 to"]},{"entry":[{},"DS 1710-1."]},{"entry":["2106A","DS 1710-1 issues a search request for the missing portions"]},{"entry":[{},"and locates the most available DSs."]},{"entry":["2106B","Multiple DSs in DS cluster 1710 download missing portions"]},{"entry":[{},"from multiple remote DSs in parallel."]},{"entry":["2107","DSs 1710 create or update related File Metadata Database"]},{"entry":[{},"information as appropriate for the downloaded portions,"]},{"entry":[{},"and save the downloaded portions as blocks. The blocks"]},{"entry":[{},"are stored across multiple storage volumes."]},{"entry":["2108A","As VFCS 1840-1 returns data to the Application Server,"]},{"entry":[{},"VFCS 1840-1 logs the usage information into a Usage Log"]},{"entry":[{},"database in CU Local Storage 2005."]},{"entry":["2108B","The VFCS 1840-1 access to the CU Local Storage is via"]},{"entry":[{},"Switch 1515."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-00225","num":"00225"},"figref":"FIG. 21C"},{"@attributes":{"id":"P-d0e7538","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 3"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Station Interactions in "}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Reference #","Interaction Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["2109","The Storage Management Subsystem within the Control"]},{"entry":[{},"Unit 1550 retrieves the file usage information."]},{"entry":["2110A","Via Switch 1515, the Storage Management Subsystem"]},{"entry":[{},"retrieves the Content Provider data, and reads the shared"]},{"entry":[{},"storage availability of the File Metadata Database."]},{"entry":["2110B","The Storage Management Subsystem receives the data from"]},{"entry":[{},"the Switch 1515 and uses the Content Provider data to"]},{"entry":[{},"identify the content provider's storage reservation."]},{"entry":["2111","Based on the storage availability, content provider's storage"]},{"entry":[{},"reservation, media file usage information, and media file's"]},{"entry":[{},"storage occupancy, the Storage Management Subsystem"]},{"entry":[{},"instructs DS, via Load Balancer 1720, to remove the least"]},{"entry":[{},"likely to be used blocks. The Storage Management"]},{"entry":[{},"Subsystem also updates the file's popularity level. The"]},{"entry":[{},"Storage Management Subsystem has multiple pruning"]},{"entry":[{},"engines that it can apply based on the storage and network"]},{"entry":[{},"traffic situation."]},{"entry":["2112","The request from Storage Management Subsystem arrives"]},{"entry":[{},"at Load Balancer 1720, which selects an available DS, e.g.,"]},{"entry":[{},"DS 1710-2 (another arbitrary illustrative one of 1710-1"]},{"entry":[{},"through 1710-N)."]},{"entry":["2113","DS 1710-2 removes blocks from the specified files and"]},{"entry":[{},"updates the File Metadata Database appropriately"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-00226","num":"00226"},"figref":"FIG. 21D"},{"@attributes":{"id":"P-d0e7874","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 4"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Station Interactions in "}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Reference #","Interaction Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["2114A","When a new content provider is added to Content"]},{"entry":[{},"Management application database, or when the content"]},{"entry":[{},"provider's information changes, the Content Management"]},{"entry":[{},"application sends an \u201ccontent provider info\u201d packet to all"]},{"entry":[{},"the stations in the SCDN. Load Balancer 1720 receives this"]},{"entry":[{},"packet."]},{"entry":["2114B","The DS load balancer of each station selects a DS and"]},{"entry":[{},"forwards the \u201cinfo\u201d packet to that particular DS."]},{"entry":["2114C","The selected DS updates or adds the content provider"]},{"entry":[{},"information into the Content Provider Data Table."]},{"entry":["2114D","DS sends information packet to all its other neighbors"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-00227","num":"00227"},"figref":"FIG. 21E"},{"@attributes":{"id":"P-d0e8084","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 5"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Station Interactions in "}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Reference #","Interaction Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["2115A","When a new file is uploaded to the SCDN, the Content"]},{"entry":[{},"Management application issues \u201cput\u201d request along with the"]},{"entry":[{},"file targeted to a DS of its assigned station. Load Balancer"]},{"entry":[{},"1720 receives this put request."]},{"entry":["2115B","The DSC's load balancer of the assigned station selects a"]},{"entry":[{},"DS and forwards the put request to that particular DS."]},{"entry":["2115C","The DS selected by the DSC's load balancer divides the"]},{"entry":[{},"received portions into blocks and saves the blocks into it"]},{"entry":[{},"shared storage and creates entries into the File Metadata"]},{"entry":[{},"Database. (The Content Management application then"]},{"entry":[{},"issues a \u201cdistribution\u201d request to distribute the file in"]},{"entry":[{},"accordance with the FDP protocol.)"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-00228","num":"00228"},"figref":"FIG. 21F"},{"@attributes":{"id":"P-d0e8301","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 6"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Station Interactions in "}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Reference #","Interaction Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["2116A","The Content Management Application connected to the"]},{"entry":[{},"assigned station associated with a CMS issues a"]},{"entry":[{},"\u201cdistribution\u201d request to distribute a file in accordance with"]},{"entry":[{},"the FDP protocol. The DSC's Load Balancer 1720 of the"]},{"entry":[{},"assigned Station (i.e., ) receives this distribution"]},{"entry":[{},"request."]},{"entry":["2116B","The DSC's load balancer of the assigned station selects a"]},{"entry":[{},"DS and forwards the distribution request to that particular"]},{"entry":[{},"DS."]},{"entry":["2116C","Upon receiving the distribution request, the Station's DS"]},{"entry":[{},"issues \u201creplicate\u201d request packets to its neighbor stations,"]},{"entry":[{},"initiating delivery of content portions to the balance of the"]},{"entry":[{},"SCDN in accordance with the FDP protocol."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-00229","num":"00229"},"figref":"FIG. 21G"},{"@attributes":{"id":"P-d0e8533","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 7"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Station Interactions in "}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Reference #","Interaction Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["2116D","Load Balancer 1720 receives a replicate request"]},{"entry":["2116E","The DSC's load balancer of the station selects a DS and"]},{"entry":[{},"forwards the replicate request to that particular DS."]},{"entry":["2116F","The DS issues a \u201cget\u201d request to retrieve the content from"]},{"entry":[{},"multiple stations in the distribution path."]},{"entry":["2116G","Upon retrieval of the content, the DS creates relevant"]},{"entry":[{},"entries in the Distribution Data database and the File"]},{"entry":[{},"Metadata Database."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"VFCS File System Implementation and Initialization","Each VFCS Server maintains a private file system that implements a distributed virtual file system. This distributed virtual file system provides the illusion to an Application Server (AS) that the VFCS Server locally holds as a contiguous atomic whole the content file that the AS desires, when in fact the content is generally stored in blocks across multiple volumes across a network of stations. Furthermore, portions of the content may be in transit from other nodes of the SCDN. Each VFCS Server file system implements only a skeletal tree structure and additional file metadata components are added on an as-needed and just-in-time basis. Important to the understanding of the present section, these additional components are only added at the particular VFCS Server where they are required. In the remaining discussion of this section, matters are described from the perspective of each VFCS Server. Unless otherwise indicated, the behavior described is independent of the existence of any other VFCS Servers.","The distributed VFCS File System may be implemented in a number of ways. In one embodiment of the invention, it is represented by a Unix VNODE structure in which a node is either a directory or a file. Each VNODE has a unique identifier that represents either a content provider or a content vendor file in the SCDN. A specific content provider file can only be retrieved using a file path that is encoded with its content provider's name.","The root directory of the VFCS server's private file system contains a list of the names of each content provider and a subdirectory for each content provider. Each content provider subdirectory contains a list of that provider's files. When its private file system is initialized, the VFCS Server accesses the list of the content provider names in order to initialize the content provider directories. However, the content provider's content files are not initialized when the VFCS Server is initialized. Rather, they are populated upon an Application Server request for the content files or notification from the DS or sequence server as popular new contents arrive. This process is referred to herein as \u201cselective and dynamic initialization\u201d. In accordance with the invention, the particular elements selected for initialization and the time at which they are initialized (at initialization time or at run time) are selected based on system performance concerns.","The VFCS Server maintains several caches in its main-memory, typical examples include:\n\n","The VFCS Server periodically checks the Content Provider Data Table and the File Metadata Database to determine if entries in either have changed and, if so, updates its caches appropriately. The periodic check could also be realized by a notification mechanism initiated by a DS or sequence server to notify all of the VFCS Servers when any entries have changed, such as when a new file is uploaded or when an old file has been pruned (discarded) to save storage space. When an Application Server attempts to access a file for which the file metadata information is not in cache, the VFCS Server verifies that the file is not accessible from the SCDN before returning an error indication, \u201cfile not found\u201d.","In one embodiment of the invention, the VFCS may maintain caches such as:\n\n","In an ideal environment where there is unlimited memory, performance could be maximized by pre-populating the VFCS server's private file system with the information necessary to support an AS request to any file stored at the station. However, in the more general limited memory scenario, \u201cselective and dynamic initialization\u201d and \u201cselective and dynamic caching\u201d are done as described previously to achieve the best possible performance. The VFCS Server reads the Content Provider Data Table and the File Metadata Database from the shared System Storage  during its initialization process and caches portions of this data in its main-memory. Upon servicing a request by an AS for a specific content provider file, the VFCS Server will augment its private file system to include the particular file's attributes. The VFCS Server obtains the additional file attribute information from the file metadata that was cached during the VFCS server's initialization. The additional file-specific information is maintained in the VFCS server's private file system until the server restarts or when memory is low and the file has not been accessed for a long period of time.","VFCS Initialization Procedure",{"@attributes":{"id":"P-00247","num":"00247"},"figref":"FIG. 22","b":["2201","2202","1","2","2203","2204","2205","2206","2207"]},"VFCS continues to build the file system Cache during run time when files are accessed. When an Application Server accesses a specific file, for example, \/export \/cp_nameJ\/file_nameX, the VFCS Server servicing the request looks up file_name in the content provider file_name list, creates a VFCS_VNODE for the corresponding file in both \/export\/cp directory, and obtains the list of block files for the file. At the same time, the VFCS Server issues a \u201cprepare\u201d request packet to a DS via the DSC Load Balancer. After the DS downloads the requested content portions, stores the portions as blocks, updates the File Metadata Database to reflect this; and after the VFCS polls the File Metadata Database and recognizes the blocks are present in the Storage System; the VFCS Server reads, assembles, and multiplexes them and sends the content to the requesting Application Server. Each VFCS Server performs read-ahead caching to improve performance.","VFCS File Access Procedure",{"@attributes":{"id":"P-00250","num":"00250"},"figref":"FIG. 23","b":["2301","2305","2302","2302","2303","2304","2304","2305"]},"In operation , the VFCS File Server checks to see if there are any blocks for the requested file in the Pre-Fetch (transient) Block Cache. If there are no such blocks, the VFCS Server proceeds to operation  where it reads blocks associated with the requested file from the station's Storage System, sends a \u201cprepare\u201d request packet to the station's DSC to repopulate the missing blocks, performs a read ahead, and then proceeds to operation . However, if there are one or more blocks for the requested file in the Pre-Fetched Blocks Cache, the VFCS Server proceeds directly to operation  from .","In operation , the VFCS Server assembles and multiplexes the blocks and forwards the data to the Application Server. VFCS may perform read-ahead caching to improve performance. Furthermore, the VFCS Server does packet spoofing to ship data directly from back-end storage to front-end application without buffer copying.","When initialized, the VFCS File System contains a root node and the Content Provider directories in the first two layers of the VFCS File System tree. The third level of the VFCS File System tree contains the content provider file directories and is populated dynamically. If a content provider's file's metadata is not in cache when the file is requested by an Application Server, the VFCS Server must read the file's metadata from the File Metadata Database, cache this information, and then create and attach a VNODE for the file in the VFCS File System's VNODE tree. Once a file is attached to the VFCS File System, the VFCS Server sends a \u201cprepare\u201d request packet to a local DS, and performs \u201cread ahead\u201d operations until it reaches the end of the file.","The number of pre-fetched blocks a VFCS Server caches depends on the local memory availability in the VFCS Server. The third layer of the VFCS File System may be pruned and the Pre-fetched Blocks Cache may be flushed when memory is running low. Depending on memory availability, the VFCS Server may cache a complete or partial set of these directories. With limited memory, it caches the file metadata for only the most frequently accessed files and then updates the cache regularly based on the recent usage information.","To support a specific number of content providers, say XCP, a specific Y number of content provider files, say YF, and a number of concurrent users, say ZU, each with N number of pre-fetched blocks for best possible performance, a VFCS Server is configured with a memory size using the following formula:","Memory Size in Mbytes=(VFCS Server OS Memory Requirement)+(VFCS Server Runtime Memory Requirement)+XCP*(Memory Required for each Content Provider Name Cache)+YF*(Memory Required for each File Name Cache)+(1+XCP+YF)*(Size of VNODE tree)+ZU*N*(Block Size)","Content Publishing and Management and Other System-Related Tools","The Content Management Applications are suite of tools that allow: (1) the owner of an SCDN (i.e., a service provider) to manage content provider accounts and (2) the content providers to manage their files in the SCDN. The tools access and update data distributed throughout the SCDN. Content Management Applications cause data or request packets to be routed to the appropriate SCDN station(s).","Content Management Applications execute in a Client\/Server paradigm, i.e., a client running on a Content Provider Client System is used to invoke a Content Management Application that executes either on: (1) a Content Management Server (CMS); (2) a combination of the CMS and the Content Provider Client System using program objects such as applets and servlets; or any combination thereof.","There may be one or more CMSs in an SCDN. In addition to typical resources such as processor and memory, each CMS has its own local storage devices on which various content management related databases are stored.","Each Content Provider uses a specific CMS. The service provider assigns the CMS used by a Content Provider to a specific Station. What this means is that the assigned Station processes the CMS requests that result from the execution of the Content Management Applications by that Content Provider. In one embodiment, one of the DSs in the assigned station's DSC is selected by its load balancer to process the CMS's request. In addition to data related to Content Management Applications being stored on the CMS's local storage devices, other such data is selectively stored in either the station's Storage System or the station's Control Unit's local storage devices.","Each Content Provider may be assigned to only one CMS; however, more than one Content Provider may be assigned to the same CMS. Furthermore, a CMS may only be assigned to a Station where the Content Provider can upload files into the SCDN. When a Content Provider is assigned to a CMS, the CMS propagates the Content Provider information and the IP address of the CMS to the entire SCDN via its assigned DS using an FDP \u201cinfo\u201d packet, for example. A Content Usage Statistics Rollup Client (a component of the associated station's Resource Management Subsystem) connects to the CMS to roll up storage and content usage information for each content provider. The Content Management Server also uses the FDP \u201cinfo\u201d packet to propagate changes in the Content Provider Data Table.","Various Content Management Applications are used for entering and managing content provider information, the content's meta information, and the actual content. Applications are also used to retrieve usage information and performance statistics of the storage system and content.","Content Management Application Tools","The Content Management Applications include tools that may be located on the CPC, the CMS, and the SCDN stations. These tools may be in the form of program objects, e.g., Java applets. Some typical tools are presented below with reference to FIG. .","The Content Provider Management Client is a tool that provides User Interface for content providers and operators to update content provider information that is stored in the Content Provider Table in the CMS system.","Content Provider Management Server is a tool that manages the Content Provider Data Table and sends information packets to the SCDN via a DS in its assigned station. The DS creates its own Content Provider Data Table in the station's Storage System.","The Content Management Client is a tool that provides a User Interface for content providers to upload and delete their content, check storage usage, reserve storage, check content usage, etc.","The Content Management Server is a tool that acts as a bridge between the Content Management Client tool and the distribution server. It communicates with a DS in its assigned station using the FDP protocol (e.g., using the \u201cput\u201d, \u201cdistribute\u201d, and \u201cclean\u201d commands). When the Content Management Client tool uploads a new file, the Content Management Server tool distributes (i.e., injects) the file into the SCDN via its assigned DS using FDP \u201cput\u201d and \u201cdistribute\u201d packets. Content Management Server saves content provider information, and content distribution criteria in its database. While content is distributed to the SCDN, the DSs involved in processing the distribution request store information related to the files and their constituent portions in the File Distribution Criteria Database and the File Metadata Database. The files and their constituent blocks are stored in the content repository distributed in the SCDN, also by DS involved in processing the request. The Content Management Server uses the FDP \u201cclean\u201d packet to remove a file from an SCDN. When a DS in the SCDN receives a \u201cclean\u201d packet, it removes the relevant information from File Distribution Criteria Database, File Metadata Database, and the actual content blocks from the content repository.","The Content Usage Statistic Rollup Client is a tool that is implemented in the Control Unit of every Station. It forwards the content usage information from the History and Statistics Repository to the Content Usage Statistic Rollup Server tool at the CMS system, where the content provider is assigned. The Content Usage Statistic Rollup Server tool receives usage and statistic data and saves the data into Usage and Statistic Database.","The assigned station's Control Unit's Storage Management Subsystem periodically forwards the content provider storage usage from the content data repository to the Content Provider Storage tool agents. A Content Provider Storage tool agent only receives storage usage of the content providers assigned to its Content Management Server, it stores the storage usage data into the Content Provider Storage Usage Table.","A Billing tool and a Statistics tool are provided to export information from the Usage and Statistics Database and the Usage and Statistics Database so both service and content providers can customize invoice statements and other communications with their customers.","Illustration of the Database Contents",{"@attributes":{"id":"P-00274","num":"00274"},"figref":"FIG. 24","b":["20","2410","2411","2401","2402","2403","1","2"]},{"@attributes":{"id":"P-d0e9137","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"1 CMS 2410 is assigned to Station 2401"]},{"entry":[{},"2 CMS 2411 is assigned to Station 2403."]},{"entry":[{},"3 CPC-1 is assigned to CMS 2410"]},{"entry":[{},"4 CPC-2 is assigned to CMS 2411"]},{"entry":[{},"5 CPC-1 owns Content C1 (hereinafter simply referred to as C1)"]},{"entry":[{},"6 CPC-2 owns Content C2 (hereinafter simply referred to as C2)"]},{"entry":[{},"7 C1 has been distributed to Station 2401 and Station 2402"]},{"entry":[{},"8 C2 has been distributed to Station 2403 and Station 2402."]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Given these assumptions, in this example, for CMS , we have:",{"@attributes":{"id":"P-d0e9267","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Content Provider Database includes CPC-1"]},{"entry":["2","Content Provider Usage Database includes storage usage of CPC-1 at"]},{"entry":[{},"Station 2401, Station 2402, and Station 2403"]},{"entry":["3","File Distribution Criteria Database includes Distribution Criteria of"]},{"entry":[{},"C1"]},{"entry":["4","Content Usage and Statistics Database includes C1's usage"]},{"entry":[{},"information from Station 2401, Station 2402, and Station 2403"]},{"entry":["5","Since C1 is not distributed to Station 2403, there will be no record"]},{"entry":[{},"from Station 2403"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"For CMS , we have:",{"@attributes":{"id":"P-d0e9418","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Content Provider Database includes CPC-2"]},{"entry":["2","Content Provider Usage Database includes storage usage of CPC-2 at"]},{"entry":[{},"Station 2401, Station 2402, and Station 2403"]},{"entry":["3","File Distribution Criteria Database includes Distribution Criteria of"]},{"entry":[{},"C2"]},{"entry":["4","Content Usage and Statistics Database includes C2's usage"]},{"entry":[{},"information from Station 2401, Station 2402, and Station 2403"]},{"entry":["5","Since C2 is not distributed to Station 2401, there will be no record"]},{"entry":[{},"from Station 2401"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"For Station , we have:",{"@attributes":{"id":"P-d0e9569","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Content Provider Database includes CPC-1 and CPC-2 because"]},{"entry":[{},"content provider data is replicated to the entire SCDN"]},{"entry":["2","Content Provider Usage Database includes storage usage of CPC-1"]},{"entry":[{},"and CPC-2 at Station 2401"]},{"entry":["3","File Distribution Criteria Database includes Distribution Criteria"]},{"entry":[{},"of C1"]},{"entry":["4","File Metadata Database includes C1's file metadata"]},{"entry":["5","Data Blocks includes C1's content"]},{"entry":["6","Content Usage and Statistics Database includes C1's usage"]},{"entry":[{},"information at Station 2401"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"For Station , we have:",{"@attributes":{"id":"P-d0e9733","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00012","num":"00012"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Content Provider Database includes CPC-1 and CPC-2"]},{"entry":["2","Content Provider Usage Database includes storage usage of CPC-1"]},{"entry":[{},"and CPC-2 at Station 2402"]},{"entry":["3","File Distribution Criteria Database includes Distribution Criteria of"]},{"entry":[{},"C1 and C2"]},{"entry":["4","File Metadata Database includes C1 and C2's file metadata"]},{"entry":["5","Data Blocks includes C1 and C2's content"]},{"entry":["6","Content Usage and Statistics Database includes C1 and C2's usage"]},{"entry":[{},"information at Station 2402"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"For Station , we have:",{"@attributes":{"id":"P-d0e9887","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00013","num":"00013"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Content Provider Database includes CPC-1 and CPC-2"]},{"entry":["2","Content Provider Usage Database includes storage usage of CPC-1"]},{"entry":[{},"and CPC-2 at Station 2403"]},{"entry":["3","File Distribution Criteria Database includes Distribution Criteria of"]},{"entry":[{},"C2"]},{"entry":["4","File Metadata Database includes C2's file metadata"]},{"entry":["5","Data Blocks includes C2's content"]},{"entry":["6","Content Usage and Statistics Database includes C2's usage"]},{"entry":[{},"information at Station 2403"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"Out of Band Signaling and Control","In one embodiment of the invention, plug-in modules are provided at each Distribution Node for the Application Servers to use and locate the \u201cOut-of-Band\u201d signals. The plug-in modules can invoke remote control modules for access control and value-added services. By providing such an infrastructure, the distribution network allows content providers to control their content at the edge of the network, and provide dynamic value added services.","Access control includes authentication and licensing by region, number of concurrent access, by user, etc. Value added services include dynamic localized and targeted advertisement insertion, dynamic preview and trailer insertions, and more. The \u201cOut-Of-Band\u201d signal also serves as a notification to content providers."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"P-00050","num":"00050"},"figref":"FIG. 1"},{"@attributes":{"id":"P-00051","num":"00051"},"figref":"FIG. 2"},{"@attributes":{"id":"P-00052","num":"00052"},"figref":"FIG. 3"},{"@attributes":{"id":"P-00053","num":"00053"},"figref":"FIG. 4"},{"@attributes":{"id":"P-00054","num":"00054"},"figref":"FIG. 5"},{"@attributes":{"id":"P-00055","num":"00055"},"figref":"FIG. 6"},{"@attributes":{"id":"P-00056","num":"00056"},"figref":"FIG. 7"},{"@attributes":{"id":"P-00057","num":"00057"},"figref":"FIG. 8"},{"@attributes":{"id":"P-00058","num":"00058"},"figref":"FIG. 9"},{"@attributes":{"id":"P-00059","num":"00059"},"figref":"FIG. 10"},{"@attributes":{"id":"P-00060","num":"00060"},"figref":"FIG. 11"},{"@attributes":{"id":"P-00061","num":"00061"},"figref":"FIG. 12"},{"@attributes":{"id":"P-00062","num":"00062"},"figref":"FIG. 13"},{"@attributes":{"id":"P-00063","num":"00063"},"figref":"FIG. 14"},{"@attributes":{"id":"P-00064","num":"00064"},"figref":"FIG. 15"},{"@attributes":{"id":"P-00065","num":"00065"},"figref":"FIG. 16","b":"14"},{"@attributes":{"id":"P-00066","num":"00066"},"figref":"FIG. 17"},{"@attributes":{"id":"P-00067","num":"00067"},"figref":"FIGS. 18A-18C"},{"@attributes":{"id":"P-00068","num":"00068"},"figref":"FIG. 19"},{"@attributes":{"id":"P-00069","num":"00069"},"figref":"FIG. 20"},{"@attributes":{"id":"P-00070","num":"00070"},"figref":"FIGS. 21A through 21G"},{"@attributes":{"id":"P-00071","num":"00071"},"figref":"FIG. 22"},{"@attributes":{"id":"P-00072","num":"00072"},"figref":"FIG. 23"},{"@attributes":{"id":"P-00073","num":"00073"},"figref":"FIG. 24","b":"20"},{"@attributes":{"id":"P-00074","num":"00074"},"figref":"FIG. 25"}]},"DETDESC":[{},{}]}
