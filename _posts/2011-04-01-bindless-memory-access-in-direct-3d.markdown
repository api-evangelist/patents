---
title: Bindless memory access in direct 3D
abstract: One embodiment of the present invention sets for a method for accessing data objects stored in a memory that is accessible by a graphics processing unit (GPU). The method comprises the steps of creating a data object in the memory based on a command received from an application program, transmitting a first handle associated with the data object to the application program such that data associated with different graphics commands can be accessed by the GPU, wherein the first handle includes a memory address that provides access to only a particular portion of the data object, receiving a first graphics command as well as the first handle from the application program, wherein the first graphics command includes a draw command or a compute grid launch, and transmitting the first graphics command and the first handle to the GPU for processing.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09251551&OS=09251551&RS=09251551
owner: NVIDIA Corporation
number: 09251551
owner_city: Santa Clara
owner_country: US
publication_date: 20110401
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION","Bindless Memory Access in Direct 3D"],"p":["This application claims benefit of U.S. provisional patent application entitled \u201cBindless Memory Access\u201d,\u201d filed on Apr. 5, 2010 and having Ser. No. 61\/321,090.","1. Field of the Invention","The present invention relates generally to accessing texture objects and image objects in GPU memory and, more specifically, to a bindless texture and image application programming interface (API) for Direct 3D (D3D).","2. Description of the Related Art","Direct 3D treats graphics concepts like textures, vertex buffers, shaders, constant buffers, and the like as opaque \u201cobjects\u201d without exposing, to an application that references the objects, address details of the objects within a memory. Typically, the application binds such objects together and into a fixed set of hardware \u201cunits,\u201d e.g., texture units, vertex streams, constant buffer slots, or the like, through, e.g., API calls, without ever being aware of or having access to a physical address of the objects within the memory. Between the execution of graphics commands, e.g., Draw( ) commands, application programs frequently require access to different objects. In turn, the API is required to bind such new objects to the set of hardware units, which is costly. For example, significant processing overhead is introduced by requiring a driver to iterate a plurality of pointers per object to validate that the objects are properly located within the memory. As a result, a substantial bottleneck has developed in modern 3D graphics processing.","As the foregoing illustrates, what is needed in the art is a mechanism for accessing data objects without causing a graphics driver bottleneck.","One embodiment of the present invention sets forth a method for accessing data objects stored in a memory that is accessible by a graphics processing unit (GPU). The method comprises the steps of creating a data object in the memory based on a command received from an application program, transmitting a first handle associated with the data object to the application program such that data associated with different graphics commands can be accessed by the GPU, wherein the first handle includes a memory address that provides access to only a particular portion of the data object, receiving a first graphics command as well as the first handle from the application program, wherein the first graphics command includes a draw command or a compute grid launch, and transmitting the first graphics command and the first handle to the GPU for processing.","One advantage of the disclosed method is that the GPU driver does not have to operate on the data objects each time they are used.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1","b":["100","100","102","104","110","150","160","170","102","110","104","102","110","110","150","104","102","150","102","150","104","150","110","102","110","102","104","150","102","160","160","150","150","160","170"]},"The system memory  includes an application program , application data , a GPU driver  and GPU driver data . The application program  generates calls to a graphics API in order to produce a desired set of results, typically in the form of a sequence of graphics images. The application program  also transmits one or more shading programs to the graphics API for processing within the GPU driver . The high-level shading programs are typically source code text of high-level programming instructions that are designed to operate on one or more shaders within the GPU . The graphics API functionality is typically implemented within the GPU driver .","The GPU local memory  includes a set of machine code shader programs , a buffer object memory , texture  and frame buffer . The machine code shader programs  are transmitted from the GPU driver  to GPU local memory . The machine code shader programs  may include, without limitation, the machine code vertex shader program, the machine code geometry shader program, the machine code fragment shader program, or any number of variations of each. The buffer object memory  includes a uniform storage buffer , a texture buffer  and a vertex buffer . The uniform storage buffer  stores one or more uniform variables, also called \u201cuniforms.\u201d A uniform variable is held constant during a given invocation of the associated shader but may be altered between invocations. The texture buffer  stores data elements typically organized in one-dimensional arrays. The vertex buffer  stores data elements describing the position and other attributes of vertices provided as inputs to the vertex shader .","The GPU local memory  includes texture  and frame buffer . The frame buffer  includes at least one two-dimensional surface that is used to drive the display . The frame buffer  may include more than one two-dimensional surface so that the GPU  can render to one two-dimensional surface while a second two-dimensional surface is used to drive the display . Data stored within the texture  and the frame buffer  is typically accessed with the assistance of application specific hardware that provides for a dimensional access view of the data. For example a two-dimensional surface may be addressed with the assistance of a hardware unit that transposes a horizontal and vertical surface location into a physical memory address that corresponds to the location.","The GPU  includes a vertex shader , a geometry shader  and a fragment shader  and a memory management unit (MMU) . As is well-known, the vertex shader  receives a sequence of one or more sets of vertex attributes, where each set of vertex attributes is typically associated with one vertex and one or more vertices are associated with a geometric primitive. The vertex shader  processes the vertex attributes, performing such operations as evaluating the vertex's position relative to the viewer and evaluating lighting equations to determine each vertex color. The vertex shader  may also use data from the buffer object memory  in the GPU local memory . For example, the vertex shader  may use data from the uniform storage buffer  or the texture buffer . The machine code vertex shader program executes on the vertex shader , imparting specific processing behavior according to specific requirements and specifications of the application program . The geometry shader  receives sets of processed vertices from the vertex shader . The geometry shader  performs per-primitive operations on vertices grouped into primitives such as triangles, lines, strips and points emitted by the vertex shader , enabling functionality such as shadow volume generation and procedural synthesis. The machine code geometry shader program executes on the geometry shader , imparting specific processing behavior according to specific requirements and specifications of the application program . A fixed-function rasterizer (not shown) that is situated between the geometry shader  and the fragment shader  scan converts an individual geometric primitive into a set of fragments with interpolated vertex attributes. The fragment shader  processes the fragments, each containing fragment data, which may include raster position, depth or interpolated vertex attributes, such as texture coordinates, opacity, and other relevant per-pixel data, to produce final pixel values. The final pixel values are stored in the frame buffer  by a fixed-function raster operations unit (not shown) that also performs operations such as depth and stencil tests as well as any blending of the final pixel values with values currently stored in the frame buffer. The machine code fragment shader program executes on the fragment shader , resulting in specific processing behavior according to specific requirements and specifications of the application program . The display  is an output device capable of emitting a visual image corresponding to an input data signal. For example, the display may be built using a cathode ray tube (CRT) monitor, a liquid crystal display, or any other suitable display system. The input data signal to the display  is typically generated by scanning out the contents of one or more frames of image data that is stored in the frame buffer .",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 2","b":["200","200","112","118","118","150","150"]},"The high-level shader programs transmitted by the application program  may include a high-level vertex shader program, a high-level geometry shader program and a high-level fragment shader program. Each of the high-level shader programs is transmitted through an API to the compiler\/linker  within the GPU driver . The compiler\/linker  compiles the high-level shader programs  into assembly language program objects.","Under shader programming model , domain-specific shader programs, such as high-level vertex shader program, high-level geometry shader program, and high-level fragment shader program, are compiled using a common instruction set target, supported by unified instruction set architecture (ISA) library . With the common instruction set, application developers can compile high-level shader programs in different domains using a core set of instructions having the same syntax and consequently should expect faster compile times for such shader programs. One example of this common ISA is supported by the Unified Instruction Set Architecture (\u201cISA\u201d) developed by NVIDIA Corporation, Santa Clara, U.S.A.","Compiler\/linker , which includes code generator  and unified ISA library , provides cross-domain linking capabilities. Specifically, compiler\/linker  translates the high-level shader programs designated for different domains (e.g., the high-level vertex shader program, the high-level geometry shader program, and the high-level fragment shader program), which are written in high-level shading language, into distinct compiled software objects in the form of assembly code. Further, instead of sending these compiled objects of assembly code individually to separate GPU microcode assemblers (not shown), compiler\/linker  also \u201clinks\u201d the compiled assembly code to generate a single compiled\/linked program object, also in the form of either assembly code or machine code. To link multiple compiled objects from different domains (also referred to as to \u201crendezvous\u201d), compiler\/linker  needs to reconcile the use of symbols across the domains. Specifically, there are generally two types of symbols, the first type being defined or exported symbols, and the second type being undefined or imported symbols. The first type of symbols broadly refers to functions or variables that are present in one compiled object (e.g., vertex shader assembly code) and should be made available for use by other compiled objects (e.g., geometry shader assembly code and\/or fragment shader assembly code). The second type of symbols broadly refers to functions or variables that are called or referenced by one compiled object (e.g., vertex shader assembly code) but are not internally defined within this compiled object.","The program objects are transmitted to the GPU microcode assembler , which generates machine code programs, including a machine code vertex shader program, a machine code geometry shader program and a machine code fragment shader program. The machine code vertex shader program is transmitted to a vertex processing unit  for execution. Similarly, the machine code geometry shader program is transmitted to a primitive processing unit  for execution and the machine code fragment shader program is transmitted to a fragment processing unit  for execution.","Shader programs can also be transmitted by the application program  via assembly instructions . The assembly instructions  are transmitted directly to the GPU microcode assembler  which then generates machine code programs, including a machine code vertex shader program, a machine code geometry shader program and a machine code fragment shader program, as previously described herein.","A data assembler  and the vertex processing unit  function as the vertex shader  of . The data assembler  is a fixed-function unit that collects vertex data for high-order surfaces, primitives, and the like, and outputs the vertex data to vertex processing unit . The data assembler  may gather data from buffers stored within system memory  and GPU local memory  as well as from API calls from the application program  used to specify vertex attributes. The vertex processing unit  is a programmable execution unit that is configured to execute a machine code vertex shader program, transforming vertex data as specified by the vertex shader programs. For example, vertex processing unit  may be programmed to transform the vertex data from an object-based coordinate representation (object space) to an alternatively based coordinate system such as world space or normalized device coordinates (NDC) space. The vertex processing unit  may read vertex attribute data directly from the GPU local memory  via the buffer load mechanism described below. The vertex processing unit  may read texture map data as well as uniform data that is stored in GPU local memory  through an interface (not shown) for use in processing the vertex data. The vertex shader  represents the vertex processing domain of the GPU .","A primitive assembler  and the primitive processing unit  function as the geometry shader . A second primitive assembler (not shown) may be included subsequent to the primitive processing unit  in the data flow through the GPU . The primitive assembler  is fixed-function unit that receives processed vertex data from vertex processing unit  and constructs graphics primitives, e.g., points, lines, triangles, or the like, for processing by primitive processing unit . The primitive processing unit performs well-known, fixed-function viewport operations such as clipping, projection and related transformations on the incoming vertex data. In the GPU , the primitive processing unit  is a programmable execution unit that is configured to execute machine code geometry shader program to process graphics primitives received from the primitive assembler  as specified by the geometry shader program. For example, in addition to well-known viewport operations, the primitive processing unit  may be programmed to subdivide the graphics primitives into one or more new graphics primitives and calculate parameters, such as plane equation coefficients, that are used to rasterize the new graphics primitives. The primitive processing unit  may read data directly from the GPU local memory  via the buffer load mechanism described below. Additionally, the primitive processing unit  may read texture map data that is stored in GPU local memory  through an interface (not shown) for use in processing the geometry data. The geometry shader  represents the geometry processing domain of the GPU . The primitive processing unit  outputs the parameters and new graphics primitives to a rasterizer . The rasterizer  is a fixed-function unit that scan-converts the new graphics primitives and outputs fragments and coverage data to the fragment processing unit .","The fragment processing unit  performs the functions of the fragment shader  of . The fragment processing unit  is a programmable execution unit that is configured to execute machine code fragment shader programs to transform fragments received from rasterizer  as specified by the machine code fragment shader program . For example, the fragment processing unit  may be programmed to perform operations such as perspective correction, texture mapping, shading, blending, and the like, to produce shaded fragments that are output to a raster operations unit . The primitive processing unit  may read data directly from the GPU local memory  via the buffer load mechanism described below. Additionally, the fragment processing unit  may read texture map data as well as uniform data that is stored in local memory  through an interface (not shown) for use in processing the fragment data. The raster operations unit  optionally performs fixed-function computations such as near and far plane clipping and raster operations, such as stencil, z test and the like, and outputs pixel data as processed graphics data for storage in a buffer in the GPU local memory , such as the frame buffer .",{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 3","FIG. 1","FIG. 1","FIG. 2"],"b":["152","154","156","200"]},"The vertex shader  executes the machine code vertex shader program in order to process a stream of vertex attributes  received from the vertex buffer  or a vertex buffer unified memory  via the data assembler . The vertex attributes  received from the vertex buffer unified memory  are attached to a vertex state set in an application context of the application program . The vertex shader  may access data from additional sources, such as uniform data  from the uniform storage buffer  and texture data  from the texture buffer  or texture . The vertex shader results  are transmitted to the geometry shader , which processes the vertex shader results  according to the machine code geometry shader program. The geometry shader  may access data from additional sources, such as uniform data  from the uniform storage buffer  and texture data  from the texture buffer  or texture . The geometry shader results  are transmitted to the fragment shader . The fragment shader  executes the machine code fragment shader program in order to process the geometry shader results . The fragment shader  may access data from additional sources, such as uniform data  from the uniform storage buffer  and texture data  from the texture buffer  or texture . The output of the fragment shader  includes a stream of shaded pixels  that are written to the frame buffer .","In addition, each of the vertex shader , the geometry shader  and the fragment shader  may retrieve data from and write data to buffer objects (illustrated as shader load\/stores ) stored within the buffer object memory  via the buffer load\/store mechanism . Similarly, each of the vertex shader , the geometry shader  and the fragment shader  may retrieve texture data and write texture data to image units stored within texture memory  via the image load\/store mechanism .","As will be familiar to someone skilled in the art, Direct3D implementations also support a compute pipeline in addition to the graphics pipeline described above. Instead of a pipeline of shader stages intermixed with fixed-function stages, a compute pipeline is a single compute shader stage. Just as an application program launches work to the graphics pipeline using a Draw command, it launches work to the compute pipeline with a Dispatch command. A Dispatch command initiates execution of a grid of threads on the compute shader unit, and each thread executes a machine code compute shader. The feature set of compute shader and graphics shaders are nearly uniform; it is understood that unless explicitly excluded, any feature of graphics shaders is also available to compute shaders. The features of the present invention apply to both graphics and compute shaders.","In some implementations, the compute pipeline may be implemented by the graphics driver by translating the compute shader to a fragment shader , configuring the graphics pipeline to use a trivial vertex shader  and geometry shader , and render a quad such that the number of fragments rasterized and executed by the fragment shader  is the desired number of compute threads.","The present invention provides a technique for allowing shaders to read from and write to buffer resources (e.g., vertex buffers), shader resource views (e.g., read-only portions of texture resources), and unordered access view (e.g. read-write portions of texture resources) through an unlimited number of anonymous access points (hereinafter referred to as \u201chandles\u201d). The handle includes or refers to an address within the GPU local memory  and allows the shader to directly access data stored at the address. The present invention also adds a small data buffer that can be read by shaders and updated at very high frequency, e.g., per pipeline invocation, with minimal overhead. This data buffer is used to pass one or more handles and other information needed by the shaders to determine which resources to use.",{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIG. 4","FIGS. 1-3"],"b":"160"},"The method  begins at step , where the GPU driver  receives a request from the application program  to create a texture object in the GPU local memory . At step , the GPU driver  creates the data object based on the request received from the application program . At step , based on the request received from the application program , the GPU driver  returns a handle associated with only a portion of the data object\u2014i.e., a resource view\u2014created in the GPU local memory . At step , the GPU driver  receives a request from the application program  to make the data object resident such that the portion of the data object is guaranteed to be accessible to the GPU . In response, at step , the GPU driver  locks the data object in the GPU local memory .","At step , a shader engine in the GPU , such as the vertex shader , performs one or more graphics commands on the portion of the resident data object, e.g., a graphics draw command. At step , the GPU driver  receives a request from the application program  to make the data object non-resident. In response, at step , the GPU driver  unlocks the data object in the GPU local memory . When the data object is made non-resident, the data object can no longer be accessed by a shader engine in the GPU .","In one embodiment of the present invention, the handle associated with a data object is also a CPU address within a CPU address space. In another alternate embodiment, the handle is a 64-bit unsigned integer. In yet another alternate embodiment, the handle is a high-level language pointer that points to the corresponding data object in the GPU local memory .",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 5","FIGS. 1-3"]},"The method  begins at step , where the GPU driver  transmits handles associated with resource views of data objects received from the application program  to the GPU . Importantly, the GPU driver  does not have to access the data objects within the driver data  to transmit the handles to the GPU . At step , the GPU driver  receives a draw command from the application  and, in response, at step , transmits the draw command to the GPU  for further processing.","At step , the GPU  retrieves the portions of the data objects associated with the handles from the GPU local memory . Note that, in some cases, the handle may not refer to a data object but to a different resource view handle, thereby providing an indirection technique that can be used to easily reference groups of portions of data objects. At step , the GPU  processes the draw command received from the GPU driver  based on the data retrieved from the GPU local memory .","Extensions to Direct 3D Shading Language and related APIs to support the foregoing techniques are discussed below. Persons skilled in the art will appreciate that the information in this section should be considered in conjunction with the Direct3D 11 specification. These changes are pure additions to the D3D API and shading language\u2014not modifications or removals of existing functionality. Advantageously, bindless memory accesses can be intermixed with bound memory accesses, even for the same resource within the same shader invocation, thereby providing backward compatibility.","As described above, to perform bindless reads of a resource view, the resource view is associated with a handle that applications retrieve and make available to shaders. Shaders are then able to use this handle with the various existing texture and load instructions. Before accessing a resource view, the application informs the GPU driver  that the resource view is in use.","Texture instructions (e.g., sample*, Id*, gather4*) are extended to support bindless ShaderResourceView and SamplerState objects. The identifiers for these objects are opaque implementation-defined handles. In D3D high-level shading language (HLSL), the existing object types are extended to support construction from these handles, but otherwise behave exactly like their bound counterparts.","Additionally, a new memory read is introduced, and avoids a typical two-step read (first descriptor, then data) and associated overhead when data is read via bound resource views. The handle is the address (in the GPU local memory  address space) of the buffer contents. In HLSL, these are exposed as C-style pointers, and data is read directly without bounds checking, format conversion, or other processing. In addition to the performance advantages described herein, pointers allow simple representation of linked data structures (lists, trees, graphs, etc.) in buffers with non-homogenous contents, or across multiple buffers.","In one embodiment, both GPU local memory  addresses and handles are 64-bit. Some implementations, however, may not use all 64 of the bits. The value zero is reserved to indicate invalid addresses and handles. The resource view handles and sampler state handles are organized as follows:",{"@attributes":{"id":"p-0048","num":"0047"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef UINT64 D3Dxx_SHADER_RESOURCE_VIEW_GPU_HANDLE;"},{"entry":"D3Dxx_SHADER_RESOURCE_VIEW_GPU_HANDLE"},{"entry":"ID3DxxShaderResourceView::GetGPUHandle( );"},{"entry":"typedef UINT64 D3Dxx_SAMPLER_GPU_HANDLE;"},{"entry":"D3Dxx_SAMPLER_GPU_HANDLE ID3DxxSamplerState::"},{"entry":"GetGPUHandle( );"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"Handles for resource view and sampler state objects are opaque references to implementation-defined data structures that encompass both the data and state such as format, size, and the like. Handles are constant for the lifetime of the object. Mapping a USAGE_DYNAMIC resource for WRITE_DISCARD does not invalidate the handle of any resource views of a data object\u2014that is, implementations must be able to change the data referred to by the resource view without changing the identity of the resource view itself.","Buffer GPU addresses are organized as follows:",{"@attributes":{"id":"p-0051","num":"0050"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef UINT64 D3Dxx_BUFFER_GPU_ADDRESS;"},{"entry":"D3Dxx_BUFFER_GPU_ADDRESS ID3DxxBuffer::GetGPUAddress( );"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The address returned by ID3DxxBuffer::GetGPUAddress( ) command is the address of the actual buffer data in the GPU local memory  address space. The address of a buffer is constant for its lifetime, except in the case of USAGE_DYNAMIC buffers, where mapping a dynamic buffer for WRITE_DISCARD makes the previous address invalid for any subsequent pipeline invocations.","This call is not supported and will return zero for structured buffers and USAGE_STAGING buffers. Structured buffers have an opaque and possibly non-linear layout, and therefore the address cannot be manipulated with predictable results. However, a handle may be modified before being passed to a shader, and offsets from a base address of the handle can be added in either host or shader code.","Binding changes give explicit indications of when and how resources will be used by the pipeline, and these events may be used to ensure the data is resident in GPU-accessible memory, i.e., GPU local memory . Bindless accesses require a new mechanism to communicate this information and are organized as follows:",{"@attributes":{"id":"p-0055","num":"0054"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["#define D3Dxx_PIN_ACCESS_READ","0x00000001"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"void ID3DxxDeviceContext::PinResources(UINT Access, UINT NumResources,"},{"entry":"ID3DxxResource * const * ppResources);"},{"entry":"void ID3DxxDeviceContext::UnpinResources(UINT NumResources, ID3DxxResource"},{"entry":"* const * ppResources);"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"The commands PinResources( ) and UnpinResources( ) increment and decrement a reference count, and the resource is pinned as long as the count is non-zero. Unpinning a resource that is not pinned results in an error and does not decrement the reference count. When a resource is bound, it is implicitly pinned, though without affecting the pin reference count.","While pinned to a context, pipeline invocations from that context can safely perform bindless accesses of the resource, either directly for buffers or indirectly through resource views. Unpinning a resource does not cause the data object associated therewith to be evicted from memory, but rather makes the data object eligible for eviction if the underlying memory manager requires the memory for, e.g., different data objects. Each (context, resource) pair is associated with a pinned state, and being pinned on one context does not imply that other contexts can safely use bindless accesses with the resource. This per-context pinned state implies that, when a shared resource is pinned for some context on one device, it is not automatically pinned for any other device\u2014in the same or a different process\u2014which has a reference to it.","Pinning a resource is orthogonal to other features that allow partial residency, such as a per-resource MinLOD clamp or sparse textures. More specifically, when pinned, any part of the resource made accessible through those features is available and, when unpinned, no parts of the resource are available. Sampler state objects do not correspond to a significant amount memory, and, as a result, residency control of sampler state objects is unnecessary and they are always available.","When a resource becomes pinned, the implementation performs the same hazard and coherence resolution tasks when binding a resource or view to the graphics pipeline. Attempts to pin a resource for read access while it is bound for write access will be ignored, as will attempts to bind the resource for write access while it is pinned for read access. After a resource becomes unpinned, subsequent uses (either bound or bindless) are automatically ordered and coherent with those performed before the resource is unpinned. While pinned, a resource may be modified or read without a binding change using \u201cblit\u201d API commands such as CopyResource. As with bound resources, these are automatically ordered and coherent with bindless reads from prior and subsequent pipeline invocations.","Pinning does not interact significantly with Map synchronizations. Only USAGE_DYNAMIC resources can be both pinned and mapped. Supported map types on dynamic resources include DISCARD and NOOVERWRITE. Performing a DISCARD map on a pinned dynamic resource\u2014in addition to changing the address of the resource but not the identity of any views thereof\u2014retains the pin count of the resource. NOOVERWRITE mappings are not synchronized and have no effect on pinning or the resource address.","Changes to high-level shading language include a new uintptr_t type which can represent a handle. This type has the same size and alignment as doubles (that is, 64-bit size and alignment). This type can be used in place of a uint2 for memory reads and writes, for example as the return type of TextureXX<uint2>::Load( ) or as the value operand to RWByteAddressBuffer::Store2( ).","Currently in HLSL, object declarations corresponding to resource view and sampler state objects must be declared at a global scope within an application program. When the declaration is in function scope, it must be explicitly initialized from a uintptr_t value. Both constructor and assignment syntax are supported. For example:",{"@attributes":{"id":"p-0063","num":"0062"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["uintptr_t mytex_handle = GetTextureHandle( );","\/\/ application-defined"]},{"entry":["Texture2D<float4> mytex(mytex_handle);","\/\/ constructor syntax"]},{"entry":["Texture2D<float4> mytex = mytex_handle;","\/\/ assignment syntax"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"The object does not have to be initialized at declaration, but using an object that the compiler cannot prove has been initialized results in a compile-time error. Outside of function scope, the declaration corresponds to a well-defined memory location and the initialization from uintptr_t can be performed implicitly. That is, the memory location is treated as a uintptr_t for layout purposes, but the object is created automatically from a handle stored at that location. For example:",{"@attributes":{"id":"p-0065","num":"0064"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["struct Object {",{}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"56pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Texture2D<float4> diffuse_tex;",{}]},{"entry":[{},"\/\/ ...",{}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["};",{}]},{"entry":["cbuffer cb : register(b0) {",{}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"56pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"StructuredBuffer<Object> objects;","\/\/ c[0][0].xy"]},{"entry":[{},"SamplerState diffuse_sampler;","\/\/ c[0][0].zw"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["};",{}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"float4 main(float2 texcoord: TEXCOORD, uint objid: OBJID): SV_Target0 {"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"210pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"return objects[objid].diffuse_tex.Sample(diffuse_sampler, texcoord);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["}",{}]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"Here, the StructuredBuffer object is initialized from a uintptr_t stored in c[0][0].xy, the diffuse_tex Texture2D object is initialized from a uintptr_t stored at byte offset objid*sizeof(Object) within the objects buffer, and the diffuse_sampler object is initialized from uintptr_t stored in c[0][0].zw.","Bindless objects are associated with a GetHandle( ) method which returns the uintptr_t value that was used to initialize the bindless object. Attempting to use an object initialized from an invalid handle produces undefined results. For new classes of errors, such as initializing from a handle that does not correspond to any object, undefined behavior may result in a \u201cdevice removal\u201d error.","Typically, D3D does not allow indexed texture access where the index might diverge within a pipeline invocation. This restriction would significantly decrease the utility of bindless texture access, e.g., within a ray tracing application. Accordingly, this restriction is lifted for both dynamically-indexed bound texture access and bindless texture access. In pixel shaders, derivatives are still calculated from texture coordinates within a pixel quad, even if each thread in the quad is accessing a different texture. Calculating the LOD from the derivatives is performed on a per-thread basis using the dimensions of the texture accessed by that thread.","Bindless access to buffer contents may be performed via C-style pointers, with some restrictions. Pointer arithmetic is allowed, using the same rules as C. Pointers may be dereferenced using the unary \u201c*\u201d operator, the \u201c->\u201d operator, and the array operator.","Pointers are declared and initialized similarly to resource view and sampler state declarations. When declared in a well-defined memory location, they are automatically initialized with the value stored therein. When declared in local scope, they can be initialized and assigned from uintptr_t values. A pointer can be copied to a uintptr_t value using explicit constructor syntax:",{"@attributes":{"id":"p-0071","num":"0070"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"const float* data = \/*...*\/;"},{"entry":"uintptr_t ptr = uintptr_t(data);"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"Dereferencing a pointer which does not fall within any pinned buffers causes undefined behavior, potentially including an error of \u201cdevice removal.\u201d No bounds-checking is performed, except that data belonging to another device will never be read or modified. Dereferencing a valid but unaligned pointer follows the same rules as unaligned addresses with byte-addressable buffers. The address-of operator (&) is supported in cases where it maps to simple arithmetic on an existing pointer value. Advantageously, the address of a field within a structure may be obtained. The \u201caddress-of\u201d operator does not require new support. In a function, the operand to the address-of operator must be known to be valid without considering the calling context, e.g., this code is not valid even though if fully in-lined it would be valid:",{"@attributes":{"id":"p-0073","num":"0072"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"void f(int x) {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},"const int* y = &x; \/\/ error: x not known"]},{"entry":[{},{},"\/\/ ..."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"\/\/ ..."]},{"entry":[{},"const int* z = ...;"]},{"entry":[{},"f(z[0]);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"Two new intrinsics are also added to support data structure manipulation: sizeof( ) and offsetof( ). These behave as in C, and are resolved at compile time. The uintptr_t type in HLSL is mapped to two components of a vector, using the same rules as doubles.","In the Direct3D intermediate shader language, bindless texture and sampler accesses use syntax similar to bound textures and samplers. A new operand type and corresponding human-readable name (\u2018th\u2019 and \u2018sh\u2019 here, where \u2018h\u2019 means handle) are implemented to distinguish the two cases. For example:",{"@attributes":{"id":"p-0076","num":"0075"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ load objects handle"},{"entry":"mov r0.zw, cb[0][0].xy"},{"entry":"\/\/ read diffuse_tex handle from objects buffer"},{"entry":"Id_structured(structured_buffer, stride=8)(mixed,mixed,mixed,mixed) \\"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"r0.x, v1.x, l(0) th[r0.zw].xxxx"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"Id_structured(structured_buffer, stride=8)(mixed,mixed,mixed,mixed) \\"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"r0.y, v1.x, l(4), th[r0.zw].xxxx"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ load diffuse_sampler handle"},{"entry":"mov r0.zw, cb[0][0].zw"},{"entry":"\/\/ read color from diffues_tex using diffuse_sampler"},{"entry":"sample(texture2d)(float,float,float,float) \\"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"r0.xyzw, v0.xyxx, th[r0.xy].xyzw, sh[r0.zw]"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ output result"},{"entry":"mov o0.xyzw, r0.xyzw"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"Bindless buffer reads use a new Id_pointer instruction:","Id_pointer dst0[.mask], srcByteAddress.swizzle","This instruction reads from one to four 32-bit components from memory as determined by the dst0 mask. The post-swizzle \u201c.xy\u201d components of srcByteAddress include the address to begin reading from (least-significant bits in the .x component, most-significant in the .y component, as with doubles).","Pipeline parameters are a new API feature that allows a small fixed amount of data to be changed extremely frequently, e.g., per draw call, with minimal overhead. The graphics and compute pipelines each get independent parameter data. The graphics pipeline parameters are visible to all shader stages. By significantly constraining the total size of the fixed amount of data, assuming high-frequency changes, and eliminating support for binding, pipeline parameters can be optimized.","Pipeline parameters are set through two new APIs, one for each pipeline:",{"@attributes":{"id":"p-0082","num":"0081"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u2003\u2003void SetDrawParameters(UINT StartOffset, UINT NumParameterBytes, void*"},{"entry":"\u2003\u2003pParameterData)"},{"entry":"\u2003\u2003void SetDispatchParameters(UINT StartOffset, UINT NumParameterBytes, void*"},{"entry":"\u2003\u2003pParameterData)"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The parameter data size is fixed by the API. The parameters \u201cStartOffset\u201d and \u201cNumParameterBytes\u201d cannot exceed this fixed data size. Contents of the parameter buffer before StartOffset or after StartOffset+NumParameterBytes are unmodified by these calls. Pipeline parameter variables are declared at global scope with a \u201cparameter\u201d keyword acting as a storage location qualifier. They support register binding syntax for manual layout of the parameter buffer, e.g. \u201cparameter const Mesh* mesh : register(p0)\u201d. Any parameter variables not manually bound are packed into the parameter buffer using the same rules as constant buffers. Reflection APIs are updated to allow discovery of the parameter variable locations.","Because the same parameter data is visible to all shader stages, shaders will need to use the same declarations to get sensible results. The HLSL compiler thus considers all parameter declarations, whether used or not, when assigning locations to parameter variables.","The extension adds new sources of unrecoverable errors, which result in a non-specific \u201cdevice removal\u201d error. To alleviate this issue, the ReportErrorCb callback is modified to accept additional details about device removal errors. This could be exposed to applications through similar changes to the existing ID3DxxDevice::GetDeviceRemovalReason( ) API. This information will be used during development rather than on end-user systems, so consistent reporting between implementations is not required. The error types are as follows:",{"@attributes":{"id":"p-0086","num":"0085"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"210pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["#define D3DxxDDI_DEVICE_REMOVED_REASON_UNKNOWN",{},"0x00000000"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"#define D3DxxDDI_DEVICE_REMOVED_REASON_ACCESS_VIOLATION"},{"entry":"0x00000001"},{"entry":"#define D3DxxDDI_DEVICE_REMOVED_REASON_MEM_OVERCOMMIT"},{"entry":"0x00000002"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"210pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["#define D3DxxDDI_AV_ACCESS_TYPE_UNKNOWN","0x00000000"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"210pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["#define D3DxxDDI_AV_ACCESS_TYPE_SAMPLER_REFERENCE",{},"0x00000001"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"210pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["#define D3DxxDDI_AV_ACCESS_TYPE_BUFFER_READ","0x00000002"]},{"entry":["#define D3DxxDDI_AV_ACCESS_TYPE_BUFFER_WRITE","0x00000004"]},{"entry":["#define D3DxxDDI_AV_ACCESS_TYPE_SRV_DATA_READ","\u20020x00000008"]},{"entry":["#define D3DxxDDI_AV_ACCESS_TYPE_SRV_REFERENCE","\u20030x00000010"]},{"entry":["#define D3DxxDDI_AV_ACCESS_TYPE_UAV_DATA_READ","\u20020x00000020"]},{"entry":["#define D3DxxDDI_AV_ACCESS_TYPE_UAV_DATA_WRITE","\u20030x00000040"]},{"entry":["#define D3DxxDDI_AV_ACCESS+TYPE_UAV_REFERENCE","\u20030x00000080"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"type struct D3DxxDDI_DEVICE_REMOVED_DETAILS"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"UINT Reason;"]},{"entry":[{},"union"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},"struct AccessViolation"]},{"entry":[{},{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"238pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},{},"UINT64 FaultAddress;"]},{"entry":[{},{},{},"UINT AccessType;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},{},"};"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"};"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} D3DxxDDI_DEVICE_REMOVED_DETAILS;"},{"entry":"void SetErrorCb(D3DxxDDI_HRTCORELAYER, HRESULT,"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"5","colwidth":"182pt","align":"left"}},{"@attributes":{"colname":"6","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"7","colwidth":"42pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},{},{},"const D3DxxDDI_DEVICE_REMOVED_DETAILS*);",{},{}]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}}]}}},"When the error type is ACCESS_VIOLATION, the AccessType includes a mask of the access types that may have caused the violation. The difference between REFERENCE and DATA_{READ,WRITE} access types is that REFERENCE implies that the fault happened accessing the view descriptor itself, while a DATA error means the fault occurred while accessing the contents of the underlying resource. More than one error type is allowed in case different API-level access-types are implemented using the same hardware features. The FaultAddress is within proximity to the faulting access, or zero if the address cannot be reliably determined.","One embodiment of the invention may be implemented as a program product for use with a computer system. The program(s) of the program product define functions of the embodiments (including the methods described herein) and can be contained on a variety of computer-readable storage media. Illustrative computer-readable storage media include, but are not limited to: (i) non-writable storage media (e.g., read-only memory devices within a computer such as CD-ROM disks readable by a CD-ROM drive, flash memory, ROM chips or any type of solid-state non-volatile semiconductor memory) on which information is permanently stored; and (ii) writable storage media (e.g., floppy disks within a diskette drive or hard-disk drive or any type of solid-state random-access semiconductor memory) on which alterable information is stored.","Another embodiment of the invention may be implemented as a program product deployed for use over a network. In such an embodiment, the program product may be accessed via a web browser.","The invention has been described above with reference to specific embodiments. Persons skilled in the art, however, will understand that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The foregoing description and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["So that the manner in which the above recited features of the present invention can be understood in detail, a more particular description of the invention, briefly summarized above, may be had by reference to embodiments, some of which are illustrated in the appended drawings. It is to be noted, however, that the appended drawings illustrate only typical embodiments of this invention and are therefore not to be considered limiting of its scope, for the invention may admit to other equally effective embodiments.",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4","b":"160"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
