---
title: Dynamically loading graph-based computations
abstract: Processing data includes: receiving units of work that each include one or more work elements, and processing a first unit of work using a first compiled dataflow graph () loaded into a data processing system () in response to receiving the first unit of work. The processing includes: analysis to determine a characteristic of the first unit of work; identifying one or more compiled dataflow graphs from graphs stored in a data storage system () that include at least some that were compiled for processing a unit of work having the determined characteristic; loading one of the identified compiled dataflow graphs into the data processing system () as the first compiled dataflow graph (); and generating one or more output work elements from at least one work element in the first unit of work.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08875145&OS=08875145&RS=08875145
owner: Ab Initio Technology LLC
number: 08875145
owner_city: Lexington
owner_country: US
publication_date: 20110615
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND","SUMMARY","DESCRIPTION"],"p":["This application claims priority to U.S. Application Ser. No. 61\/355,129, filed on Jun. 15, 2010, incorporated herein by reference.","This description relates to dynamically loading graph-based computations. Complex computations can often be expressed as a data flow through a directed graph (called a \u201cdataflow graph\u201d), with components of the computation being associated with the vertices of the graph and data flows between the components corresponding to links (arcs, edges) of the graph. The components can include data processing components that receive data at one or more input ports, process the data, and provide data from one or more output ports, and dataset components that act as a source or sink of the data flows. A system that implements such graph-based computations is described in U.S. Pat. No. 5,966,072, EXECUTING COMPUTATIONS EXPRESSED AS GRAPHS.","In a general aspect, a method for processing data in a data processing system using compiled dataflow graphs stored in a data storage system includes: receiving multiple units of work that each include one or more work elements; and processing a first unit of work using a first compiled dataflow graph loaded into the data processing system in response to receiving the first unit of work. The first compiled dataflow graph has been compiled into data structures representing a first dataflow graph that includes nodes representing data processing components connected by links representing flows of work elements between data processing components. The processing includes analyzing the first unit of work to determine a characteristic of the first unit of work; identifying one or more compiled dataflow graphs from multiple compiled dataflow graphs stored in the data storage system that include at least some compiled dataflow graphs that were compiled, before the first unit of work was received, for processing a unit of work having the determined characteristic of the first unit of work; loading one of the identified one or more compiled dataflow graphs into the data processing system as the first compiled dataflow graph; and generating one or more output work elements from at least one work element in the first unit of work using the first dataflow graph.","Aspects can include one or more of the following features.","The multiple units of work correspond to different contiguous sets of one or more work elements within a flow of received work elements.","The multiple units of work correspond to different batches of one or more work elements within different respective received files.","The loading further includes retrieving data structures representing the first dataflow graph from the first compiled dataflow graph and loading the retrieved data structures into a second dataflow graph.","The second dataflow graph was running before the first unit of work was received.","Loading the retrieved data structures into the second dataflow graph includes embedding the first dataflow graph within a containing component of the second dataflow graph that is configured to provide a first process to execute the data processing components in the first dataflow graph.","The containing component of the second dataflow graph is further configured to provide a second process to monitor execution of the data processing components in the first dataflow graph.","The second process, in response to detecting a failure of at least one data processing component in the first dataflow graph to correctly process a given work element, interrupts execution of the first dataflow graph without interrupting execution of the second dataflow graph.","The second process, in response to detecting a delay of at least one data processing component in the first dataflow graph in processing the first unit of work, suspends execution of the first dataflow graph without interrupting execution of the second dataflow graph and embeds a third dataflow graph within the containing component of the second dataflow graph to process a second unit of work received after the first unit of work.","The containing component of the second dataflow graph is further configured to provide a first application programming interface that the first process uses to communicate with a second process that accesses a library for a first remote database.","The containing component of the second dataflow graph is further configured to provide a second application programming interface that the first process uses to communicate with a third process that accesses a library for a second remote database different from the library for the first remote database.","The containing component of the second dataflow graph is further configured to provide a third application programming interface that is compatible with multiple components of the second dataflow graph.","The containing component of the second dataflow graph is further configured to translate application calls using the third application programming interface into application calls using a selected one of the first or second application programming interface based on which of the first or second remote database is being accessed.","Loading the retrieved data structures into the second dataflow graph includes embedding the first dataflow graph within a containing component of the second dataflow graph, the embedding including: connecting a flow of input work elements received from a link connected to an input of the containing component to an input of the first dataflow graph, and connecting the generated one or more output work elements to a link connected to an output of the containing component.","The first dataflow graph includes a first component that includes at least one output link connected to an input of a second component, instructions to provide the input work elements to the second component when the first dataflow graph is embedded within the containing component, and instructions to provide work elements from a storage location to the second component when the first dataflow graph is not embedded within the containing component.","The first dataflow graph includes a third component that includes at least one input link connected to an output of a fourth component, instructions to provide the generated one or more output work elements from the output of the fourth component to the output of the containing component when the first dataflow graph is embedded within the containing component, and instructions to provide the generated one or more output work elements from the output of the fourth component to a storage location when the first dataflow graph is not embedded within the containing component.","The first dataflow graph includes multiple interface components that each include instructions for sending work elements between the first dataflow graph and the containing component when the first dataflow graph is embedded within the containing component, and instructions for sending work elements between the first dataflow graph and a storage location when the first dataflow graph is not embedded within the containing component.","Each of the interface components identifies a different corresponding input or output port of the containing component to which the first dataflow graph is connected when the first dataflow graph is embedded within the containing component.","The method further includes, after generating the one or more output work elements, unloading the retrieved data structures representing the first dataflow graph from the second dataflow graph.","The method further includes buffering work elements that are in units of work that arrive after the first unit of work arrives and before the unloading of the retrieved data structures representing the first dataflow graph.","The method further includes loading a second compiled dataflow graph loaded into the data processing system, the second compiled dataflow graph having been compiled into data structures representing a second dataflow graph.","Loading one of the identified one or more compiled dataflow graphs into the data processing system as the first compiled dataflow graph includes embedding the first dataflow graph within a first containing component of a third dataflow graph, and loading the second compiled dataflow graph into the data processing system includes embedding the second dataflow graph within a second containing component of the third dataflow graph.","The second compiled dataflow graph is loaded into the data processing system in response to receiving the first unit of work.","The second compiled dataflow graph is loaded into the data processing system in response to receiving a second unit of work after the first unit of work.","The method further includes processing a second unit of work after processing the first unit of work, using a second compiled dataflow graph loaded into the data processing system in response to receiving the second unit of work, the second compiled dataflow graph having been compiled into data structures representing a second dataflow graph, the processing including: analyzing the second unit of work to determine a characteristic of the second unit of work; identifying one or more compiled dataflow graphs from the multiple compiled dataflow graphs stored in the data storage system that were compiled, before the second unit of work was received, for processing a unit of work having the determined characteristic of the second unit of work; loading one of the identified one or more compiled dataflow graphs into the data processing system as the second compiled dataflow graph; and generating one or more output work elements from at least one work element in the second unit of work using the second dataflow graph.","Loading one of the identified one or more compiled dataflow graphs into the data processing system as the first compiled dataflow graph includes embedding the first dataflow graph within a containing component of a third dataflow graph, and loading one of the identified one or more compiled dataflow graphs into the data processing system as the second compiled dataflow graph includes embedding the second dataflow graph within the containing component of the third dataflow graph.","Analyzing the first unit of work includes reading an identifier for a compiled dataflow graph included within a work element of the first unit of work.","Identifying the one or more compiled dataflow graphs includes matching the identifier to identifiers associated with the one or more compiled dataflow graphs.","Analyzing the first unit of work includes identifying one of multiple predetermined types characterizing a work element of the first unit of work.","Identifying the one or more compiled dataflow graphs includes determining that dataflow graphs corresponding to the one or more compiled dataflow graphs are configured to process a work element characterized by the identified type.","Analyzing the first unit of work includes identifying a property of content included within a work element of the first unit of work.","Identifying the one or more compiled dataflow graphs includes determining that dataflow graphs corresponding to the one or more compiled dataflow graphs are configured to process a work element that includes content having the identified property.","Analyzing the first unit of work includes determining one or more values associated with the first unit of work that are designated as values for a first set of one or more parameters of the first dataflow graph.","Identifying the one or more compiled dataflow graphs includes determining that the identified one or more compiled dataflow graphs were compiled into data structures representing the first dataflow graph with the first set of one or more parameters bound to respective values that match the determined one or more values associated with the first unit of work.","Loading one of the identified one or more compiled dataflow graphs into the data processing system as the first compiled dataflow graph includes binding a second set of one or more parameters to respective values determined based at least in part on the first unit of work.","The second set of one or more parameters includes at least one parameter whose value includes the name of an input source for providing input work elements or output source for receiving output work elements.","The first set of one or more parameters includes at least one parameter whose value determines whether one or more components are to be included in the data structures representing the first dataflow graph when the data structures are compiled into the first compiled dataflow graph.","The first set of one or more parameters includes at least one parameter whose value determines a transformation to be applied to work elements that are processed by a component that is included in the data structures representing the first dataflow graph when the data structures are compiled into the first compiled dataflow graph.","The method further includes, before the first unit of work is received, compiling the first compiled dataflow graph from data structures representing the first dataflow graph with the first set of one or more parameters bound to respective values.","The method further includes storing the first compiled dataflow graph in the data storage system and associating the stored first compiled dataflow graph with information indicating the respective values that were bound to the first set of one or more parameters.","In another aspect, in general, a data processing system for processing data using compiled dataflow graphs stored in a data storage system includes: an input device or port configured to receive multiple units of work that each include one or more work elements; and at least one processor configured to process a first unit of work using a first compiled dataflow graph loaded into the data processing system in response to receiving the first unit of work. The first compiled dataflow graph has been compiled into data structures representing a first dataflow graph that includes nodes representing data processing components connected by links representing flows of work elements between data processing components. The processing includes analyzing the first unit of work to determine a characteristic of the first unit of work; identifying one or more compiled dataflow graphs from multiple compiled dataflow graphs stored in the data storage system that include at least some compiled dataflow graphs that were compiled, before the first unit of work was received, for processing a unit of work having the determined characteristic of the first unit of work; loading one of the identified one or more compiled dataflow graphs into the data processing system as the first compiled dataflow graph; and generating one or more output work elements from at least one work element in the first unit of work using the first dataflow graph.","In another aspect, in general, a data processing system for processing data using compiled dataflow graphs stored in a data storage system includes: means for receiving multiple units of work that each include one or more work elements; and means for processing a first unit of work using a first compiled dataflow graph loaded into the data processing system in response to receiving the first unit of work. The first compiled dataflow graph has been compiled into data structures representing a first dataflow graph that includes nodes representing data processing components connected by links representing flows of work elements between data processing components. The processing includes analyzing the first unit of work to determine a characteristic of the first unit of work; identifying one or more compiled dataflow graphs from multiple compiled dataflow graphs stored in the data storage system that include at least some compiled dataflow graphs that were compiled, before the first unit of work was received, for processing a unit of work having the determined characteristic of the first unit of work; loading one of the identified one or more compiled dataflow graphs into the data processing system as the first compiled dataflow graph; and generating one or more output work elements from at least one work element in the first unit of work using the first dataflow graph.","In another aspect, in general, a computer-readable medium stores a computer program for processing data in a data processing system using compiled dataflow graphs stored in a data storage system. The computer program includes instructions for causing a computer to: receive multiple units of work that each include one or more work elements; and process a first unit of work using a first compiled dataflow graph loaded into the data processing system in response to receiving the first unit of work. The first compiled dataflow graph has been compiled into data structures representing a first dataflow graph that includes nodes representing data processing components connected by links representing flows of work elements between data processing components. The processing includes analyzing the first unit of work to determine a characteristic of the first unit of work; identifying one or more compiled dataflow graphs from multiple compiled dataflow graphs stored in the data storage system that include at least some compiled dataflow graphs that were compiled, before the first unit of work was received, for processing a unit of work having the determined characteristic of the first unit of work; loading one of the identified one or more compiled dataflow graphs into the data processing system as the first compiled dataflow graph; and generating one or more output work elements from at least one work element in the first unit of work using the first dataflow graph.","Aspects of the invention can include one or more of the following advantages.","A data processing system that uses dataflow graphs can be configured in different ways to process an input flow of data made up of individual work elements. Each work element can represent a separate unit of work, or a series of multiple work elements can represent a unit of work. The techniques described herein can be used for a variety of configurations of such a system. Some configurations may be more appropriate for units of work within the data flow that have certain characteristics. In some cases, one or more work elements in a unit of work are provided to a dataflow graph for processing as a batch (e.g., a batch of work elements consisting of records within the same input file), where the dataflow graph passes data flows of work elements from one or more input ports to one or more output ports for a single batch at a time. The series of \u201coutput work elements\u201d provided from the output port(s) of downstream components (and optionally stored in dataset components) represent results of processing the series of \u201cinput work elements\u201d provided to the input port(s). In one form of batch processing, the dataflow graph starts up when the first input work element of a batch is ready and terminates after the last output work element has been provided. In another form of batch processing, the dataflow graph continues running from one batch to the next while making sure that the last output work element from the previous batch is output before the first input work element from the next batch is processed. In this latter form of batch processing, there may be a continuous stream of work elements segmented into units of work each consisting of one or more work elements that represent a batch. Some of the techniques described herein show how to dynamically load a given dataflow graph in response to detecting a predetermined characteristic associated with a received unit of work. In some cases the characteristic is based on the content of the unit of work (e.g., format of a file), and in some cases the characteristic is based on parameter values associated with the unit of work (e.g., a parameter determining whether a particular conditional component is to be included), as described in more detail below.","In some configurations, a data processing system may execute dataflow graphs to process batches of data such that a dataflow graph runs for a relatively short period of time (e.g., on the order of seconds) to process a given batch of data. If many small batches are processed by selected dataflow graphs (e.g., selected from a collection of dataflow graphs), performance can be improved significantly if the execution time of a selected dataflow graph is not dominated by \u201cstartup time\u201d (the time it takes for the graph to be loaded and ready to start processing the batch of data from initiation of the graph). For example, if the startup time of a dataflow graph is about five seconds and it takes about five seconds to process the batch of data, then only half the execution time is used for useful data processing. In some cases, this low ratio of processing time to execution time may not impact overall efficiency if the batches are arriving infrequently (e.g., every few minutes in this example). However, if batches are arriving relatively frequently (e.g., every few seconds in this example), then startup time can significantly affect overall efficiency. Performance can be improved by moving some of the tasks that would have been performed during the startup time into an earlier compilation phase, as described herein.","In some configurations, a data processing system may execute dataflow graphs to process a continuous flow of data such that a dataflow graph runs continuously processing a series of work elements in a flow of data. The work elements can be divided into units of work consisting of one or more of the work elements, and each unit of work may need to be processed by a different dataflow graph as a batch. Performance can be improved significantly if the different dataflow graphs are dynamically loaded into a running container graph on demand (e.g., as opposed to keeping all of the different dataflow graphs running independently, or combining them into a single large dataflow graph). For example, the units of work may consist of a single message of a given type. Some types of messages may be more frequent than others. So, by loading the appropriate dataflow graph to handle a given type of message (instead of running all the dataflow graphs for all the different types of messages concurrently), the resources that would have been used to keep the more infrequently used dataflow graphs running can be freed for other purposes. Additionally, keeping the dataflow graphs separate instead of combining them into a large dataflow graph provides the modularity that enables easy design of custom dataflow graphs for different types of messages and facilitates a developer's understanding of the entire system upon inspection of the container graph. A developer can easily change how some types of messages are handled by changing the corresponding dataflow graph, and can easily add or remove dataflow graphs as messages types are added or removed.","The techniques described herein can be used to compile different customized versions of dataflow graphs that can be loaded dynamically at run time with appropriate parameter values for processing a received batch of data. In some implementations, the compiled dataflow graphs can be used as \u201cmicrographs\u201d that can be dynamically loaded (and unloaded) into (and out of) a containing dataflow graph while that containing dataflow graph is running. The micrograph provides an efficient way to process different units of work within a continuous flow of data as a batch while the continuous flow of data is being processed by the dataflow graph. In some cases, micrographs are loaded as subgraphs within a containing dataflow graph using a specialized component for loading the micrograph, as described in more detail below. Techniques for compiling dataflow graphs (including micrographs) enable some of the startup procedures to be performed ahead of time while still allowing flexibility at run-time by selecting among different compiled versions of a dataflow graph in response to a received batch of data (including a unit of work within a flow of data).","Other features and advantages of the invention will become apparent from the following description, and from the claims.","1 Overview",{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 1","b":["100","100","101","104","105","106","104","104"]},"The pre-execution module  is configured to perform various tasks in preparation for executing dataflow graphs and other executable programs such as compiling dataflow graphs, storing\/loading compiled dataflow graphs to\/from a data storage system  accessible to the execution environment , or resolving parameter values and binding the resolved values to parameters. In some cases, the pre-execution module  performs tasks (e.g., loading compiled dataflow graphs) in response to data from the data source . Storage devices providing the data source  may be local to the execution environment , for example, being stored on a storage medium connected to a computer running the execution environment  (e.g., hard drive ), or may be remote to the execution environment , for example, being hosted on a remote system (e.g., mainframe ) in communication with a computer running the execution environment , over a remote connection.","The execution module  uses the compiled dataflow graphs generated by the pre-execution module  to generate output data, which can be provided back to the data source  and\/or stored in the data storage system . The data storage system  is also accessible to a development environment  in which a developer  is able to design dataflow graphs. Data structures representing the dataflow graphs can be serialized and stored in the data storage system .","The execution module  can receive data from a variety of types of systems of the data source  including different forms of database systems. The data may be organized as records having values for respective fields (also called \u201cattributes\u201d or \u201ccolumns\u201d), including possibly null values. When reading data from a data source, an executing dataflow graph may include components that handle initial format information about records in that data source. In some circumstances, the record structure of the data source may not be known initially and may instead be determined after analysis of the data source. The initial information about records can include the number of bits that represent a distinct value, the order of fields within a record, and the type of value (e.g., string, signed\/unsigned integer) represented by the bits.","Referring to , an example of a dataflow graph  that is executed by the execution module  allows data from an input data source  to be read and processed as a flow of discrete work elements. Different portions of the computations involved with processing the work elements are performed in components ,  that are represented as the vertices (or nodes) of the graph, and data flows between the components that are represented by the links (or arcs, edges) of the graph, such as the link  connecting components  and . A system that implements such graph-based computations is described in U.S. Pat. No. 5,566,072, EXECUTING COMPUTATIONS EXPRESSED AS GRAPHS, incorporated herein by reference. Dataflow graphs made in accordance with this system provide methods for getting information into and out of individual processes represented by graph components, for moving information between the processes, and for defining a running order for the processes. This system includes algorithms that choose interprocess communication methods (for example, communication paths according to the links of the graph can use TCP\/IP or UNIX domain sockets, or use shared memory to pass data between the processes).","The process of preparing an uncompiled dataflow graph for execution involves various stages. An uncompiled representation of the dataflow graph is retrieved along with any parameters associated with the dataflow graph that provide values used in the compilation process. During a static parameter resolution phase, static parameters (whose values are designated for resolution before run-time) are resolved and the resolved values are bound to the static parameters. In some cases, in order to resolve the values of the static parameters, calculations are performed to derive certain values (e.g., metadata values, as described in U.S. Publication No. 2006\/0294150 entitled \u201cMANAGING METADATA FOR GRAPH-BASED COMPUTATIONS,\u201d incorporated herein by reference). Some parameters may be designated as dynamic parameters that are left unresolved to be resolved later at or just before run-time. Components designated as conditional components are removed from the graph (e.g., by being replaced by a dataflow link) if a predetermined condition is not met (or is met), for example, based on a static parameter value. During the compilation phase, data structures representing the dataflow graph, including its components and links, to be used during execution are generated. Compiling can also include compiling embedded scripts in scripting languages into bytecode or machine code. At run-time, any dynamic parameters associated with the dataflow graph are bound to resolved values, and the data structures of the compiled dataflow graph are launched by starting one or more processes, opening any needed files (e.g., files identified by dynamic parameters), and\/or linking any dynamic libraries. The processes also perform tasks to set up data flows represented by the links (e.g., allocating shared memory, or opening TCP\/IP streams). In some cases, the data structures are configured to execute multiple components in a single process, as described in U.S. Publication No. US 2007\/0271381 entitled \u201cMANAGING COMPUTING RESOURCES IN GRAPH-BASED COMPUTATIONS,\u201d incorporated herein by reference.","Dataflow graphs can be specified with various levels of abstraction. A \u201csubgraph\u201d which is itself a dataflow graph containing components and links can be represented within another containing dataflow graph as a single component, showing only those links which connect the subgraph to the containing dataflow graph. In some cases, subgraphs are used to hide the components and links of a containing dataflow graph within the development environment , but the data representing the components and links are already integrated within the containing dataflow graph. In some embodiments, subgraphs are not initially included in a containing dataflow graph, but are later derived from a \u201cmicrograph\u201d that starts as a compiled dataflow graph that includes the data structures representing the components and links to be loaded into the containing dataflow graph, as described in more detail below.","Referring again to , the dataflow graph  is able to accept a continuous flow of input data from a data source, which in this example is represented by the dataset component . The flow of data is continuous in the sense that, even though it may wax and wane during the operation of the dataflow graph , the flow of data does not necessarily have a distinguishable beginning or end, for example, a flow of credit card transactions or orders received in entry systems. Additionally, the dataflow graph  is able to provide a continuous flow of output data to an output data repository, which in this example is represented by the dataset component . Some dataflow graphs are designed for execution as continuous dataflow graphs that process continuous flows of data for an indefinite period of time, and some dataflow graphs are designed for execution as batch dataflow graphs that begins execution to process a discrete batch of data and then terminates execution after the batch has been processed. The data processing components  and  of a dataflow graph may contain a series of instructions, a sub-graph, or some combination thereof.","In some arrangements, a specialized component  may load a micrograph , which is a specialized kind of subgraph configured to be retrieved dynamically and embedded within a containing dataflow graph. A micrograph can be dynamically embedded with a containing component of the containing dataflow graph, such as the specialized component . In some arrangements, a micrograph  is derived from a data flow graph that was previously compiled and stored in the data storage system . In some arrangements, a micrograph  remains in an un-compiled form when loaded from the data storage system . For example, instead of loading a compiled dataflow graph, the specialized component  may initiate a graph compilation procedure to enable the dataflow graph containing the specialized component  to be able to execute micrographs that have been compiled just before use. The graph compilation procedure may be performed external to the specialized component , or internal to the specialized component . In some arrangements, the micrograph  is serialized prior to being stored in the data storage system . In general, serialization is a process by which a dataflow graph, in a compiled or uncompiled representation, is translated into a binary stream of zeroes and ones so that the dataflow graph is in a form that can easily be stored in persistent memory or in a memory buffer. In implementations in which fast loading of micrographs is desirable, typically the dataflow graph is serialized in a compiled representation with data structures and stored in the data storage system , so that the serialized compiled dataflow graph can be easily retrieved and the data structures de-serialized and loaded dynamically at run-time. Compilation is the process by which a computer program, including a program expressed as a dataflow graph, is prepared to be executed by a computer. Compilation may result in the generation of machine code, or instructions ready to be executed on a computer, or in intermediate code which is executed by a virtual machine executing on a computer, for example, Java byte code. In the case of dataflow graphs, compilation includes generation of data structures representing the components and links of the dataflow graph in a form ready to be executed on a computer.","Data flowing through the dataflow graph  along the incoming link  of the specialized component  is temporarily stored in a buffer while the specialized component  loads the micrograph  and integrates the micrograph  into the dataflow graph . Similarly, the data flow is allowed to accumulate in a buffer while a micrograph is detached and unloaded from the dataflow graph . In some arrangements, a detached micrograph may remain loaded in memory to be accessed later (for example, using a caching mechanism).","The buffering can be configured to use a flow control mechanism that is implemented using input queues for the links providing an input flow of work elements to a component. This flow control mechanism allows data to flow between the components of a dataflow graph without necessarily being written to non-volatile local storage, such as a disk drive, which is typically large but slow. The input queues can be kept small enough to hold work elements in volatile memory, typically smaller and faster than non-volatile memory. This potential savings in storage space and time exists even for very large data sets. Components can use output buffers instead of, or in addition to, input queues. When two components are connected by a flow, the upstream component sends work elements to the downstream component as long as the downstream component keeps consuming the work elements. If the downstream component falls behind, the upstream component will fill up the input queue of the downstream component and stop working until the input queue clears out again.","In some arrangements, the micrograph  is executed on a scheduled basis by a scheduling process, as part of a batch dataflow graph, or from the command line, and is not necessarily loaded into a specialized component of a containing dataflow graph. Alternatively, a scheduler can use a specialized component to launch a micrograph for batch processing by sending a message to a queue that provides a continuous flow of messages to a running dataflow graph containing a specialized component that will load the appropriate micrograph in response to the message from the queue.","2 Specialized Component","Referring to , in one embodiment, a specialized component  is configured to accept multiple inputs , ,  and deliver multiple outputs , , , and . The inputs include data inputs , , and a control input . The outputs include data outputs , , , and a status output . The control input  accepts an identifier of a micrograph  to run (e.g., within a received control element), and optionally a set of parameters used to run the micrograph . In general, the specialized component  may accept zero or more flows of input work elements over respective data input ports, such as data inputs , . The status output  produces a status record which includes exit status and tracking information from the execution of the micrograph . Additionally, the specialized component produces zero or more flows of output work elements over respective data output ports, such as data outputs , , and . In one embodiment, the specialized component  produces one status record and accepts one control record during a normal execution.","The control input  can receive a series of multiple control elements that each identifies a corresponding micrograph to be loaded. Each control input element is associated with a different subset of work elements in the flow(s) of work elements received over the data input(s) that represent a unit of work to be processed by the identified micrograph. In some cases, the control element identifying the micrograph is generated based on analyzing one or more work elements in the unit of work to select the appropriate micrograph to process that unit of work. In some cases, the control element identifying the micrograph and the work elements representing the unit of work to be processed by the identified micrograph are received independently and are matched to each other using any of a variety of techniques. For example, the control element identifying the micrograph is received first and the work elements representing the unit of work to be processed by the identified micrograph are determined by matching a key value appearing in at least one work element of a unit of work to a corresponding control element (e.g., just the first work element in the unit of work, or every work element in the unit of work). Alternatively, work elements called \u201cdelimiter work elements\u201d can function as delimiters that separate different sequences of work elements belonging to the same unit of work. Alternatively, the specialized component  is configured to receive a predetermined number of work elements to belong to successive units of work to be associated with respective control elements.","The micrograph  can be selected from a collection of micrographs that have been designed to be compatible with the specialized component . For example, the number of input ports and output ports of the micrograph  may match the number of input ports and output ports of the specialized component . In this example, the micrograph  has two input ports and three output ports, which could be located on two different components of the micrograph  that are configured to receive input flows and three different components of the micrograph  that are configured to provide output flows. Alternatively, multiple input or output ports of the micrograph  could be located on the same component.","In some embodiments, the specialized component  monitors the micrograph  for predefined conditions and may respond to those conditions. For example, the specialized component  may use a separate process to monitor the process that executes the components of the micrograph  to determine if the latency during execution of the micrograph  exceeds a maximum threshold or for a timeout condition. In response, the specialized component  may respond to the condition by, for example, loading a second instance of the micrograph . Similarly, error conditions are monitored. In response to detecting an error condition, the specialized component  may log the error, redirect the unit of work based on the error condition, and, if necessary, may restart a micrograph  and report the error via the status output . The restarting of the micrograph  does not need to interrupt any other components of the containing dataflow graph in which the specialized component  is contained.","In some embodiments, the specialized component  analyzes the data flow on an input port to determine which micrograph  to execute. In other embodiments, the name or other identifying information of the micrograph  to run is supplied to the specialized component  as part of the data flow. In still other embodiments, the information identifying the micrograph  is supplied through the control input  of the specialized component .","The specialized component  loads the micrograph  from the data storage system , embeds the micrograph  into the dataflow graph containing the specialized component , as described in more detail below, and allows the micrograph  to process the data flow.","When the operation is complete, the specialized component  removes the micrograph . In some embodiments, the specialized component  may store the micrograph  in a micrograph cache stored in a storage location from which it is relatively more easily accessible than from the data storage system , for later access. In some embodiments, the specialized component  may buffer the incoming data while the micrograph  is being loaded, integrated, and removed.","3 Micrograph Structure","Referring to , an example of micrograph  includes data processing components , , , and  which perform operations on input work elements in data flows arriving at one or more input ports linked to upstream components, and produce output work elements in data flows leaving one or more output ports linked to downstream components. The micrograph  also includes components A, B and A, B, C that are configured to facilitate the process of embedding the micrograph  into the specialized component , called \u201cinterface components.\u201d Interface components also enable the micrograph to be run as an independent dataflow graph that does not need to be embedded into a specialized component to run.","Interface components are used to connect a micrograph to the ports of the containing specialized component. Embedding a micrograph into a specialized component involves determining how to pair each interface component with the correct port of the specialized component. Input interface components (A, B) have an output port, and output interface components (A, B, C) have an input port. When an input interface component is paired with an input port of the specialized component, a dataflow link is generated between that input port and the port to which the output port of the input interface component is linked. Similarly, when an output interface component is paired with an output port of the specialized component, a dataflow link is generated between the port to which the input port of the output interface component is linked and that output port.","The correct pairing of interface components with their respective specialized component input and output ports can be determined as follows. The interface components and the ports of the specialized component can optionally be labeled with identifiers. If there is a match between an identifier assigned to an input\/output port of the specialized component and an identifier assigned to an input\/output interface component, then that port and that interface component will be paired. Matches between identifiers can be exact, or inexact (e.g., finding a match between some prefix or postfix of an identifier). In one pairing procedure, after exact matches are determined, interface components with numeric suffixes are matched to ports with matching numeric suffixes (e.g., an \u201cout1\u201d port of a specialized component will be paired with a \u201cMicrograph Output-1\u201d interface component).","When a micrograph is executed outside of a specialized component (e.g., in response to a command from the development environment  for testing purposes) the interface components provide the functionality of dataset components, providing a source or sink of work elements in a data flow over the link connected to the interface component's output or input port. The appropriate functionality is determined based on whether the micrograph has been embedded within a specialized component. The interface components each include instructions for sending work elements between the micrograph and the specialized component when the micrograph is embedded within a specialized component, and instructions for sending work elements between the micrograph and a storage location when the micrograph is not embedded within a specialized component. The storage location can be a file that is read to provide input work elements or written to receive output work elements.","In some embodiments, the micrograph  is configured by placing certain constraints on the functionality of the data processing components that can be included in the micrograph (in this example, components , , , and ). For example, in some embodiments, the data processing components , , , and  of the micrograph  may be required to be able to be run within a single process (e.g., by being folded into a single process as described in more detail in U.S. Publication No. 2007\/0271381, incorporated herein by reference). In some embodiments, a micrograph does not support subscriber components that receive data from a subscribed source (such as a queue). In some embodiments, a micrograph may be required to be configured as a batch dataflow graph. In some embodiments, any transactional operations executed by the micrograph  must fit into a single transaction. In other embodiments, the transactional aspects of the micrograph , for example checkpoints, transactional context, and multi-phase commits is controlled through a control input .","In dataflow graph processing, the continuous flow of data can affect traditional transactional semantics. A checkpoint operation involves storing sufficient state information at a point in the data flow to enable the dataflow graph to restart from that point in the data flow. If checkpoints are taken too often, performance degrades. If checkpoints are taken too infrequently, recovery procedures in the case of a transactional failure become more complex and resource intensive. A transactional context may be used to inform the micrograph that its operations are part of a larger transaction. This transaction may be a larger transaction encompassing multiple components acting against a single data source, or may include information necessary to coordinate the transaction across multiple data source, for example, in a two phase commit operation.","4 Micrograph Management","Referring to , in one embodiment, a specialized component  may have more than one micrograph loaded into a cache accessible to the specialized component (e.g., stored in a local memory) at a time. In this example, one micrograph  is connected into the dataflow graph that includes the specialized component . The input  of the specialized component  is connected by a link to the input  of the micrograph  and the output  of the micrograph  is connected by a link to the output  of the specialized component . The input  and output  of the micrograph  represent input and output interface components, for example, or any other mechanism for embedding a micrograph into a specialized component.","The cache storing the other micrographs , , , and  can be located in the same memory that stores the connected micrograph . In some embodiments, the micrographs , , , , and  are able to execute as threads within the same process that runs the specialized component , or as child processes of that process. Alternatively, the micrographs , , , , and  may be executed within the same main thread of that process. In some embodiments, the specialized component  runs multiple copies of the micrographs , , , , and . In some embodiments, the specialized component  uses the copy of a selected micrographs that is stored in the cache before accessing the original micrograph stored in the data storage system  unless that copy is marked as \u201cdirty\u201d (indicating that there has been a change in the original micrograph). When a copy of the selected micrograph is not in the cache, the specialized component  loads the micrograph from the data storage system . In some embodiments, the selected micrograph is indicated (e.g., by an entry in the cache) as being in an \u201coffline\u201d state, indicating that the selected micrograph is currently unavailable (e.g., the micrograph may be in the process of being modified by a developer). In response, the specialized component can indicate an error in loading the selected micrograph, or can load a substitute micrograph (e.g., a different micrograph that has similar capabilities).","Referring to , in one scenario, a single specialized component  has multiple micrographs , , and  integrated into the data flow at the same time. The input port  of the specialized component  is connected to the inputs , ,  of the micrographs , , and , respectively, using a partition component  that partitions work elements from an input data flow into multiple data flows. The outputs , , and  of the micrographs are connected to the output  port of the specialized component , using a component  (called a \u201cgather component\u201d) that gathers work elements from multiple data flows and merges them into a single output data flow. In this configuration, the specialized component  is able to route the incoming data to the micrographs , , and . For example, when the components are separate copies of identical micrographs, the specialized component  may utilize load balancing algorithms (e.g. round robin, least utilized, etc. . . . ) when performing the partitioning.","Referring to , in another scenario, a dataflow graph  includes multiple specialized components, enabling flexible combinations of micrographs to be arranged in a highly customizable container dataflow graph. In this example, work elements from a dataset component  (which may represent a batch of input data or a continuous stream of input data) are first processed by a data processing component  (e.g., to reformat the work elements) and then sent over a link  to the first specialized component . In response to detecting a particular type of work element, the component  loads a micrograph  configured for processing work elements of the detected type. The processed output work elements from the first specialized component  are then sent to a second specialized component , which loads a micrograph . In this arrangement, the micrograph  that is selected for loading into the second specialized component  can depend on results of the first selected micrograph . Resulting output work elements are sent to a dataset component . A large number of combinations of different micrographs can be dynamically loaded using specialized components in strategic locations within a dataflow graph. In this simple example, if there are 10 different possible micrographs that can be loaded into the first specialized component  and 10 different possible micrographs that can be loaded into the second specialized component , there are as many as 100 different dataflow graphs that can be dynamically constructed on demand while a data flow is being processed, with potentially much fewer resources needed compared to partitioning a dataflow to 100 different running dataflow graphs, and with potentially much faster latency compared to starting up one of 100 different dataflow graphs for each unit of work.","5 Pre-Processing and Post-Processing","A specialized component can include other components in addition to the components within the loaded micrograph. Referring to , in one embodiment, the specialized component  includes pre-processing before the micrograph is executed, and post-processing after the micrograph is executed (represented in the figure as pre-processing component  and post-processing component  surrounding the micrograph ). Pre and post processing activities may pertain to, for example, transaction management. In some embodiments, each micrograph  represents a separate transaction, in which case the pre-processing may start a transaction and the post processing may end the transaction. In other embodiments, the micrograph  may represent a checkpoint in a longer transaction. For example, the micrograph  may be part of a longer transaction using a two phase commit protocol. Such a transaction may be processed using multiple different micrographs or multiple executions of the same micrograph, for example.","The pre-processing component  may load the micrograph  from a data store (not shown) and potentially store the loaded micrograph in a data cache for later access or access a loaded version of the micrograph from an in memory cache (not shown) and integrate it into the specialized component . The post-processing component  may remove a loaded micrograph  from its integration with the data flow of the specialized component . A variety of other pre and post processing functions can be performed including, for example, pre-processing by preparing records within a data flow for processing by the micrograph  (e.g., reformatting the records), and post-processing by preparing records received from the micrograph  for processing by components connected to the output of the specialized component  (e.g., by reformatting the records).","6 Database Connection Management","Referring to , in some scenarios, different components are required to be able to access different types of databases. For example, component  is required to access a database  provided by one vendor, while another component  is required to access a database  provided by another vendor. Generally, a component  will access a database  by accessing a library  integrated into the component, for example, a library supplied by the vendor of the database . Similarly, component  will access the database  by accessing another library  integrated into the component, for example, a library provided by the vendor of database . Libraries can be compiled into a particular component, or can be dynamically linked to a particular component.","Referring to , a specialized component  can include multiple different micrographs , , and . In this example, micrograph  is embedded within the specialized component , and micrographs  and  are loaded into an accessible cache to be dynamically embedded as necessary. Some of the micrographs may access one database  and other micrographs may access another database . Traditionally, accessing the two databases may require a library  to support the first database  and another library  to support the other database  to be integrated with the specialized component . Integrating multiple different database libraries can lead to an increased size in the binaries associated with the specialized component , as well as unpredictable behavior if one library  supplied by a vendor is incompatible with another library  supplied by the different vendor. For example, incompatibilities may include conflicting symbol names or different compilation models.","One method of avoiding incompatibilities and\/or decreasing the size of the binaries is to remove the libraries from the specialized component and, instead, have them accessed by a separate computer process from a process executing the specialized component. Referring to , the database libraries  and  are removed from the specialized component  (e.g., not compiled or dynamically liked to the component ). Micrograph components , , and  access the databases ,  by accessing the libraries ,  over a client\/server interface. In order to access the libraries , , the specialized component  uses an integrated client stub  which communicates with a paired server stub  running in an external process using inter-process communication. For example, the external processes and the specialized component  may exchange data by accessing a shared memory segment. Similarly, to access the external process running the server stub , the specialized component  uses another integrated client stub  which communicates with the server stub  running in an external process using inter-process communication.","The server stub  integrates with the database library  in order to provide access to the database . Similarly, the server stub  integrates with the database library  in order to provide access to the database . Generally, the client stubs ,  have a smaller memory footprint than the database libraries ,  and therefore allow the specialized component to use less memory resources. Additionally, because the database libraries have been moved out of the specialized component , there is no risk of incompatibility between the database libraries , .","Referring to , in some embodiments, the client stubs ,  and server stubs ,  are configured to closely reflect the respective application programming interfaces (APIs) of the database libraries , . In order to isolate the micrographs , , and  from differences in library APIs, an abstraction layer  is integrated into the specialized component . The abstraction layer  provides multiple different components within a micrograph that may need to access different databases with a single API with which to perform standard database actions independent of differences between the database libraries for those databases. In some embodiments, the abstraction layer  translates the requests from the components of the micrographs into specific calls to the library-specific APIs of the client stubs , . In some embodiments, the abstraction layer  passes requests from the micrograph components as generic calls, and each client stub is configured to perform the translation from generic calls into the library-specific calls to that respective server stub's APIs.","7 Compilation and Parameters","Referring to , in one embodiment, a dataflow graph compilation and execution system  includes a dataflow graph compiler , a parameter analyzer , a dataflow graph loader , and a dataflow graph execution engine . The compiler  processes uncompiled dataflow graphs, including micrographs, from an un-compiled dataflow graph data store  based on parameters in parameter sets from a parameter set data store . The value associated with a given parameter can determine any of a variety of characteristics of a dataflow graph. The compiler  compiles the dataflow graphs using values from a parameter set to generate a compiled dataflow graph. The compiled dataflow graph is stored in a compiled dataflow graph data store . The data stores  and  can be hosted, for example, within the data storage system . The compiler , parameter analyzer , and loader  can be implemented, for example, as part of the pre-execution module . The execution engine  can be implemented as part of the execution module .","The parameter set data store  contains sets of parameters and each parameter set can be associated with a dataflow graph. A parameter set includes a group of parameter elements. These elements contain the name of a parameter and an expression that when evaluated (e.g., by performing computations, and in some cases, by finding values of other referenced parameters) are resolved into a value that is bound to the parameter. Each uncompiled dataflow graph can be associated with one or more parameter sets. Some parameters can affect the compilation process. For example, some parameters can affect whether certain conditional components are included in a compiled version of a dataflow graph. Some parameters can affect the loading and launching of a compiled dataflow graph. For example, the value of a parameter can be a path to a file stored on a computer, or the name of a storage location to be associated with a dataset component (e.g., a storage location representing a table in a database) that contains input data or is the target for output data. The value of a parameter can determine how many ways parallel a given component needs to run. The value of a parameter can determine whether a data flow of a link between components crosses a boundary between different processors and\/or computers running the linked components, and if so, causing a TCP\/IP flow to be allocated rather than a shared memory flow. In some scenarios, the values of the parameters may be dependent upon other parameters. For example, the name of a currency conversion lookup file may be dependent upon a parameter which specifies a date.","In general, a parameter is bound to a value according to rules for parameter scoping based on contexts. A given parameter can have one value in a first context and a different value in another context. A parameter can be bound to a value during compilation (e.g., by the compiler  if the parameter could affect the compilation process), at run-time (e.g., when the loader  loads the compiled dataflow graph data structures into memory for the execution engine ), while the dataflow graph is being executed (e.g., delaying a parameter that provides a file name from being resolved until just before the file is read or written), or, in some cases, a combination of different times. The value of a parameter can be defined, for example, by a user over a user interface (e.g., in response to a prompt), defined from a file, included in a data source, or defined in terms of another parameter in the same context or in different context. For example, a parameter can be imported from a different context (e.g., a parameter evaluated in the context of a different component) by designating the parameter to have a \u201csame as\u201d relationship to another parameter.","Parameters for a dataflow graph can be bound before any input data has been received such as during compilation (e.g., by the compiler ). Such parameters that are bound before or during compilation of a dataflow graph are called \u201cstatic parameters.\u201d Parameters for a dataflow graph can also be bound in response to receiving new input data such as just before run-time (e.g., by the loader  in response to receiving a new batch of data or an initial unit of work within a flow of data), or during run-time (e.g., by the execution engine  in response to loading a new micrograph to handle a new unit of work within a flow of data). Such parameters that are bound after compilation of the dataflow graph and closer to run-time are called \u201cdynamic parameters.\u201d In some cases, dynamic parameters do not need to be re-evaluated for each new batch of data or unit of work within a flow of data. Static parameters are typically evaluated while a graph is being compiled and can affect the compiled dataflow graph. However, static parameters can also be evaluated at run-time if, for example, compilation does not occur until run-time. Because dynamic parameters are evaluated at run-time and may contribute to the overall latency of starting up a dataflow graph, dynamic parameter evaluation can, in some embodiments, be optimized by limiting the capabilities of dynamic parameters. For example, dynamic parameters may be limited to specific data types (e.g. strings), they may not be referenced within certain expressions, and may have more restricted bindings (e.g., not referenced directly or indirectly by a \u201csame as\u201d binding.) However, in other embodiments, dynamic parameters may not be restricted in their functionality and are utilized just like other parameters.","There are various ways to enable the compiler  to distinguish between static and dynamic parameters during the compilation process. One technique uses a flag or special syntax for dynamic parameters in a parameter set, signaling to the compiler that the dynamic parameter should be left unbound. Another technique separates static and dynamic parameters of a parameter set in into different subsets, and only providing the subset of static parameters to the compiler . The subset of dynamic parameters are then provided to the loader  at run-time. Even though the compiler  does not bind the dynamic parameters to resolved values, the compiler  can still be configured to check dynamic parameters (e.g., for illegal syntax or other errors) during compilation. A given expression may include both static and dynamic parameter references. For example, a static directory name parameter can be resolved by the compiler , but a dynamic file name parameter can be left unresolved and the compiler  can preserve the unresolved dynamic parameter reference during the compiling process because it is recognized as a dynamic parameter.","In some scenarios, the existence or value of a parameter may affect the topology and\/or connectivity of components within a dataflow graph. A parameter may indicate that the operations performed by one or more components are not to be executed during a particular execution of the graph. This may be especially relevant when the same dataflow graph is used on two different data sources. For example, one data source may be in a first format (e.g., UTF-8) and another source may contain text in a second format that uses different encodings for at least some characters. A dataflow graph that processes both data sources may need to convert text in the second format into the UTF-8 format. However, when accessing a UTF-8 data source, no conversion would be necessary. A parameter could be used to inform the dataflow graph that the data is already in UTF-8 format and that a conversion component may be bypassed. In some arrangements, the exclusion of a conditional component based on a parameter value may result in the conditional component being removed and replaced with a dataflow in the compiled dataflow graph. Additional description of conditional components can be found in U.S. Pat. No. 7,164,422, incorporated herein by reference.","Referring again to , the compiler  obtains an uncompiled dataflow graph from the uncompiled dataflow graph data store . The compiler  obtains the parameter set that is to be used for compiling the dataflow graph from the parameter set data store . In some cases, multiple different parameter sets could be used for a given dataflow graph, and for each parameter set, the graph compiler  is able to compile a corresponding version of the uncompiled dataflow graph. Each compiled version of the dataflow graph may include or exclude some components or other executable statements based on the values of the parameters in the parameter set. The compiled dataflow graph is associated with the bound parameter values from the parameter set that was used to generate the compiled dataflow graph, for example, when the compiled dataflow graph is serialized. The compiled dataflow graph is associated with the parameter values from the associated parameter set using any of a number of different mechanisms (e.g., a lookup table, a foreign key to primary key relationship in a database, etc. . . . ). The compiled dataflow graph data store  can be implemented, for example, using any file system or database capable of read and write operations.","During dataflow graph execution (at \u201crun-time\u201d), data enters the system from an input data source . The input data source  can include a variety of individual data sources, each of which may have unique storage formats and interfaces (for example, database tables, spreadsheet files, flat text files, or a native format used by a mainframe). The individual data sources can be local to the system , for example, being hosted on the same computer system (e.g., a file), or can be remote to the system , for example, being hosted on a remote computer that is accessed over a local or wide area data network.","The parameter analyzer  and loader  enable a dataflow graph to be quickly loaded from a stored compiled dataflow graph, avoiding the potentially lengthy compilation process, while still allowing flexibility at run-time by selecting among different compiled versions of a dataflow graph in response to a received input data. The parameter analyzer , in response to receiving input data from the input data source , analyzes the input data, and potentially other values that may not be known until run-time, to determine values for one or more parameters (potentially including both static parameters and dynamic parameters) to be used with a target dataflow graph. The target dataflow graph is an uncompiled dataflow graph that has been compiled into different versions stored in the compiled dataflow graph data store  using different respective parameter sets. The loader  compares any values of static parameter provided by the parameter analyzer  with any values of those same parameters that may have been used to generate any of the compiled versions of the target dataflow graphs to find a match. If the loader  finds a match in the static parameters, then the loader  can resolve and bind the dynamic parameters, and load the resulting dataflow graph to be launched by the execution engine . If the loader  does not find a match in the static parameters, the loader  can route the input data to an error processor (not shown), or the loader  may have a version of the target dataflow graph available which is capable of handling different possible parameter values as a non-optimized default. Alternatively, the loader can initiate the compiler  to compile a new version of the target dataflow graph with the appropriate static parameter values. In these cases, compilation can be done on the fly as needed. The first time a target dataflow graph is run, compilation is done at run-time and the resulting compiled dataflow graph with bound static parameters is saved. Then the next time the target dataflow graph is run, it is only recompiled if a compiled version with the desired static parameter values is not found.","For example, for a parameter set including parameters A, B, C (with A and B static, and C dynamic), consider a first compiled version of a target dataflow graph that has been compiled using A=True and B=False, and a second compiled version of the same target dataflow graph that has been compiled using A=True and B=True. If the parameter analyzer  determines that a received unit of work is to be processed using the target dataflow graph with A=True, B=True, and C=True, then the second compiled version can be loaded and the dynamic parameter C is bound by the loader . If the parameter analyzer  determines that a received unit of work is to be processed using the target dataflow graph with A=False, B=True, and C=True, then a new version of the target dataflow graph is compiled by the compiler  with A=False, B=True and the dynamic parameter C is bound by the loader . The newly compiled version can also be stored in the compiled dataflow graph data store  for later use.","The loader  loads the selected compiled dataflow graph into a memory accessible to the graph execution engine  to be executed to process the flow of input data from the input data source . In some embodiments, the function of the loader  is performed by a specialized component in a running dataflow graph and the loaded dataflow graph is a micrograph embedded into the specialized component. The loader  may access a previously loaded version of the selected compiled dataflow graph which remains cached in memory (after determining that the appropriate static parameter values were used) without necessarily needing to access the compiled dataflow graph data store . The loaded dataflow graph is then executed by the execution engine . Once the input data has been processed by the target dataflow graph, the dataflow graph may either be unloaded from the system, or may be cached for later access.","In general, compilation of a dataflow graph is the process by which the graph is transformed into an executable format. The executable format can be in a platform specific form (e.g., machine code) or in an intermediate form (e.g., byte code). In some embodiments, the compiler  resolves the static parameters, traverses the dataflow graph, and reduces it to a set of data structures that are prepared to be executed. The transformation from a dataflow graph, which is represented as vertices and links, to machine code may include several steps. One of these steps can include dynamic code generation where the dataflow graph is transformed into a third generation programming language (e.g. C, C#, C++, Java, etc. . . . ). From the third generation language, machine readable code or byte code can be generated using a standard compiler.","In some embodiments, whether a parameter is treated as a static parameter or a dynamic parameter is not determined until compilation. Parameters that are evaluated and their values hard coded into the compiled dataflow graph area treated as static parameters. Whereas, dynamic parameters are generally not evaluated at compile time, but are instead evaluated during graph loading or execution. As described above, the values determined by the parameter set are used for the purposes of preparing different compiled versions of dataflow graphs for fast loading and execution at run-time. In the case where the value of the parameter from the parameter set definitively defines the only possible value that is valid for the compiled graph, the value is coded into the compiled dataflow graph, and the parameter is treated as a static parameter. In other cases, where the value of the parameter from the parameter set provides a range of possible values, the parameter may not be evaluated at compile time as a static parameter, but instead may be evaluated at load-time or run-time as a dynamic parameter.","Also during the compilation process the compiler may optimize the dataflow graph, for example, by eliminating unnecessary executable statements. For example, dataflow graphs may contain conditional components. Conditional components may include a series of executable statement which are either included in or excluded from the compiled dataflow graph based on the value of one of more parameters. Conditional components can be used for a variety of purposes, such as graph optimization or specialization. For graph optimization, an application may omit processing or creation of datasets if values from them will not be used, thus allowing the graph to run more efficiently. For graph specialization, an application might condition the production of several different output datasets based on the level of detail desired, or allow execution of one of several optional portions of a graph.","The approaches described above can be implemented using software for execution on a computer. For instance, the software forms procedures in one or more computer programs that execute on one or more programmed or programmable computer systems (which is of various architectures such as distributed, client\/server, or grid) each including at least one processor, at least one data storage system (including volatile and non-volatile, non-transitory memory and\/or storage elements), at least one input device or port, and at least one output device or port. The software may form one or more modules of a larger program, for example, that provides other services related to the design and configuration of computation graphs. The nodes and elements of the graph can be implemented as data structures stored in a computer readable medium or other organized data conforming to a data model stored in a data repository.","The software is provided on a storage medium, such as a CD-ROM, readable by a general or special purpose programmable computer or delivered (encoded in a propagated signal) over a communication medium of a network to the computer where it is executed. All of the functions are performed on a special purpose computer, or using special-purpose hardware, such as coprocessors. The software is implemented in a distributed manner in which different parts of the computation specified by the software are performed by different computers. Each such computer program is preferably stored on or downloaded to a storage media or device (e.g., solid state memory or media, or magnetic or optical media) readable by a general or special purpose programmable computer, for configuring and operating the computer when the storage media or device is read by the computer system to perform the procedures described herein. The inventive system may also be considered to be implemented as a computer-readable storage medium, configured with a computer program, where the storage medium so configured causes a computer system to operate in a specific and predefined manner to perform the functions described herein.","A number of embodiments of the invention have been described. Nevertheless, it will be understood that various modifications is made without departing from the spirit and scope of the invention. For example, some of the steps described above may be order independent, and thus can be performed in an order different from that described.","It is to be understood that the foregoing description is intended to illustrate and not to limit the scope of the invention, which is defined by the scope of the appended claims. Other embodiments are within the scope of the following claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF DRAWINGS","p":[{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 9A"},{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 9B"},{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
