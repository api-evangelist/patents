---
title: Deleting data stream overload
abstract: In one embodiment, a system of an embodiment of the invention may evaluate data quality in a data stream to suggest one or more actions to be performed to improve the data quality in the data stream. Further, the system of the embodiment of the invention may evaluate each suggested action to determine how the suggested action may impact the data quality in the data stream if performed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08180914&OS=08180914&RS=08180914
owner: SAP AG
number: 08180914
owner_city: Walldorf
owner_country: DE
publication_date: 20090717
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["The invention relates generally to data stream processing, and, more specifically, to deleting overload in data streams.","As most data stream sources exhibit bursty data rates, data stream management systems must recurrently cope with overloads that exceed the average workload to a considerable degree. To guarantee low-latency processing results, load has to be shed from the stream, when data rates over-stress system resources. There exist numerous load shedding strategies to delete excess data. However, there may be consequent data loss that may lead to incomplete and\/or inaccurate results during the ongoing stream processing.","Typical data stream sources provide potentially high arrival rates (such as, transactions in financial markets and production monitoring events), but sufficient resources may not be available for the required workload of numerous queries. For example, the critical resources during stream aggregations are computational power and stream bandwidth, while joins suffer from limited memory capacity. Furthermore, data streams tend to have dramatic peak overloads in data volume for temporary timeframes (for example, evening web traffic, high event rates during critical states in production processes, and so on). In some instances, it is impractical or impossible to provide resources to fully handle such a peak load. However, accurate data stream processing is most critical in such situations of high and bursty data load.","A system and method to delete overload in a data stream to maximize the data quality of processing results are described.","In one embodiment, a method to analyze tuples in a data stream and delete tuples from the data stream based on quality information obtained from the tuples is presented.","In one embodiment, tuples in a data stream may be deleted based on the value of one quality dimension as a priority over other quality dimensions.","In one embodiment, potential load shedding actions may be tested to evaluate which out of a set of possible load shedding actions is to be performed.","Embodiments of systems and methods for deleting overload in a data stream are described herein. In the following description, numerous specific details are set forth to provide a thorough understanding of embodiments of the invention. One skilled in the relevant art will recognize, however, that the invention can be practiced without one or more of the specific details, or with other methods, components, materials, etc. In other instances, well-known structures, materials, or operations are not shown or described in detail to avoid obscuring aspects of the invention.","Reference throughout this specification to \u201cone embodiment\u201d or \u201cthis embodiment\u201d means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus, the appearances of the phrases \u201cin one embodiment\u201d or \u201cin this embodiment\u201d in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures, or characteristics may be combined in any suitable manner in one or more embodiments.","Embodiments may be used in systems for collecting and processing data in the form of data streams. Such systems may periodically experience overloads which may result in inaccurate processing of results because of the inability of a system to process overloads. A data stream may be a real-time, continuous, ordered (implicitly by arrival time or explicitly by timestamp) sequence of data items, collected with a certain stream rate over a given period of time. In one embodiment, the quality of data in a data stream may be analyzed to determine which parts of the data in the data stream to retain and which parts to delete. By deleting parts of the data in the data stream, overload on system resources is reduced. Also, by retaining data of higher quality, the result of the processing of the data stream may be improved, that is, the resulting processed data will be of better quality. Quality of data being processed by an application or system of an embodiment can be measured to determine, among other things, the utility of the data for specific applications, data use scenarios and so on. Various data quality dimensions may be applicable to various circumstances depending on applications and\/or data use scenarios. Examples of data quality dimensions include timeliness, completeness, confidence, accessibility, readability, and so on.","Data quality may represent metadata information that describes the utility of any data item or any set of data items for a specific use scenario. A data quality of a data item or a set of data items may be described by a set of data quality dimensions each describing a specific data quality aspect, such as accuracy, confidence, completeness, timeliness, added-value, relevancy, accessibility, readability, and so on. To measure a data quality of a data item or a set of data items, the respective data quality dimensions have to be measured. For example, the completeness of a set of data items constitutes the ratio of available recorded data items in a database or data stream in comparison with real world data information. In another example, accuracy may describe the difference between a recorded data item in a database or data stream and the real world information represented by this data item, such that the accuracy may describe typing errors or sensor measurement errors.","A system processing streaming data may be configured with specific instructions to be applied to the processing of data in the event of an overload. An operator is typically an operation used in the processing of data. In other words, data processing is the process of applying a set of operators to data in a certain sequence. Some exemplary operators include selection, projection, join, interpolation, aggregation, and so on. Some operators may have attributes and some may not.","A data stream may include a continuous stream of m tuples \u03c4, that may have n attribute values Afor all 1\u2266i\u2266n and a timestamp t. A tuple is a data item in a data stream. A tuple may include raw data and metadata about the raw data. The metadata in the tuple may include various measurements such as, but not limited to, a timestamp, measurements for quality dimensions of the tuple, and so on.","To determine if an overload exists in the system, system resources may be compared to the workload of incoming data streams and queries. To overcome an overload some portions of the data stream may need to be deleted, that is some tuples may be deleted and some tuples may be preserved. Deleting tuples from a data stream is also referred to as \u201cload shedding\u201d or \u201cload shedding action\u201d. To determine which tuples are to be kept, and which tuples are to be deleted from a data stream (that is, load shedding is to be performed), tuples in the data stream may be rated according to some criteria.","In one embodiment, tuples may be rated according to data quality information included in metadata in the tuples. In one embodiment, load shedding may be performed based on data quality information. In the embodiment, tuples of lower data quality are discarded with a higher probability than tuples of high quality. Thus, more high quality tuples may remain in the data stream and the data quality of processing results (that is, processed data after the processing of the data stream completes) is improved and the data loss due to discarding overload tuples may be compensated. For example, aggregations are more precise and join result sets are more complete. In one embodiment, by rating tuples according to their quality and discarding tuples with less quality than a specified value, the quality of the data resulting from the processing of the data stream may be improved.",{"@attributes":{"id":"p-0029","num":"0025"},"figref":["FIG. 1","FIG. 1"],"b":["102","104","106"]},"In one embodiment, tuples may be rated according to a total data quality value. A total data quality value may be, for example, an aggregated value of monitored data quality dimensions. In another embodiment, there may be a need to improve a specific data quality dimension. In such an embodiment, a data quality dimension to be improved may take precedence before other data quality dimensions and tuples in the data stream may be rated according to the value of the quality dimension that needs to be improved (i.e. the one that takes precedence). In another embodiment, there may be a set of criteria for improving the data stream and a check may be performed to determine if the goals for the improvement of the data quality in the data stream can be achieved.",{"@attributes":{"id":"p-0031","num":"0027"},"figref":["FIG. 2","FIG. 2"],"b":"202"},"In one embodiment, the data stream may be split in consecutive, non-overlapping data quality windows and data quality information may be aggregated for the data quality window, i.e. a set of data quality information describing the quality of a set (window) of data items of a data stream may be averaged to compute the window-wise data quality. In another embodiment, the window-wise data quality used for a quality-driven load shedding may be computed as the maximum or minimum of the data quality information of the data items of this respective window. Thus, the data quality volume transferred in the data stream is reduced and the evaluation performance of data quality information for a quality-driven load shedding is improved. A data stream may be split in data quality windows according to various criteria, for example, a count of data stream tuples or a time interval. In some embodiments, the size of a data quality window may be constant and in some embodiments the size of a data quality window may change over time.","A major challenge during the load shedding based on data quality information is posed by the fact, that a straight-forward ordering of data items in a data stream according to their data quality information blocks the continuous data stream processing and transfer. To order the data items all data items with their data quality information are required, which is not the case in data stream applications. Therefore, other methods have to be found to evaluate the data quality of a data item and derive the appropriate load shedding activity of retaining or deleting the data item. One embodiment may use the data quality distribution of all data items in the data stream that have been processed in the past.","The use of the data quality distribution allows the determination of an acceptance threshold for the data quality of the current data item. The acceptance threshold may be defined as the inverse cumulative distribution function at the point of the required load shedding rate, i.e. the amount of data items that have to be deleted from the data stream given in the required load shedding rate determines the acceptance threshold of the data quality. In one embodiment, the data quality distribution may be described by a histogram of all incoming data quality values. In another embodiment, the data quality distribution may be assumed to be a normal distribution and may be described by the mean value and variance value of the incoming data quality values.","At process block , the mean value and the variance value of the data quality distribution of tuples processed so far are updated. The data quality distribution may represent the frequency of occurrence of data quality values of tuples processed in the data stream. With these updated values and a load shedding rate, at block , a threshold for acceptance is computed. The threshold for acceptance is updated for each current tuple, as the mean value and the variance value and the load shedding rate change with each tuple processed in the stream. The load shedding rate may be calculated as the ratio of tuples remaining in the stream and the total number of tuples. To determine if an overload exists, system resources are compared to the workload of all incoming data streams and queries. The threshold for acceptance may be used to appraise tuples in the data stream according to their data quality. The threshold for acceptance may separate tuples with high quality that are to be kept in the stream and low quality tuples that are to be deleted. At process block , a value representing the total data quality of the tuple is calculated","At process block , a probability to delete the tuple is calculated based on the distance between the threshold for acceptance and the total data quality of the tuple. At process block , a Bernoulli sampling is performed with the calculated probability to execute the required load shedding and to discard the tuple if it is of low quality. In one embodiment, the Bernoulli probability p=d>(\u03b8,b), where \u03b8 is the total data quality of the tuple and b is the computed threshold for acceptance, may be computed from the sigmoid quality distance:\n\n(\u03b8, )=\u22120.5\u00b7tan ()+0.5.\n\nSuch a choice of distance may provide a sampling probability p\u21921 when \u03b8<<b and a small sampling probability p\u21920 if b<<\u03b8. The case where b=\u03b8 maybe modeled with p=0.5.\n",{"@attributes":{"id":"p-0037","num":"0033"},"figref":"FIG. 3","sub":["i ","i","i"]},{"@attributes":{"id":"p-0038","num":"0034"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"\u03b8","mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"mo":["\uf603","\uf604"],"mi":"Q"}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"i","mo":"=","mn":"1"},{"mo":["\uf603","\uf604"],"mi":"Q"}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["weight","i"]},"mo":"\u00b7","mrow":{"mfrac":{"mrow":[{"msub":{"mi":["q","i"]},"mo":"-","mrow":{"mi":"\u03bc","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["q","i"]}}}},{"mi":"\u03c3","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["q","i"]}}}]},"mo":"."}}}}}}},"br":{},"figref":["FIG. 3","FIG. 2"],"b":["302","304","306","308","310","210"],"sub":["1","2","|Q|","1 ","2 ","1","2","1","2"]},"In one embodiment, deleting data overload in a data stream may focus on improving the data quality dimension completeness of the resulting data after the processing of the data stream. This embodiment may be used to improve the completeness of the result set of a data stream join, where a memory capacity of the storage to store the incoming data stream tuples, that be will joined, is restricted. Thus, the data quality dimension completeness is prioritized and tuples and a data stream are analyzed to determine if the values of the data quality dimension of each tuple is higher or lower than a desirable value. To improve the data quality dimension completeness, tuples may be evaluated according to the value of their completeness. A threshold for acceptance with a focus on completeness may be computed. In one embodiment, it is the goal of a system processing the data stream to improve completeness. The system may have a storage (with a restricted memory capacity) to store tuples with a completeness higher than the computed threshold for acceptance. If a tuple has a value in the data quality dimension completeness higher than the threshold for acceptance, it is stored to the storage and the tuple that has the lowest completeness in the storage is deleted. If a tuple has a value in the data quality dimension completeness lower than the threshold for acceptance, it is deleted. Thus, over time, the storage may store the tuples with the highest completeness.",{"@attributes":{"id":"p-0040","num":"0036"},"figref":["FIG. 4","FIG. 4"],"b":["402","404","408","412","410"]},"In another embodiment, the data quality of the resulting data after the processing of the data stream may be improved by evaluating the outcome of a potential deletion of a tuple. It is necessary to evaluate the outcome because deleting or keeping a tuple may affect the resulting data quality of the resulting data after the data stream is processed. For example, deleting a tuple may lead to a better data quality of the resulting data after the data stream is processed, if the tuple has values in the quality dimensions lower than the average of the data stream or deleting it might have a positive impact on the error introduced by the information loss due to load shedding, i.e. deleting it might decrease the variance of the data items in the data stream. In another example, if a tuple has high data quality values or keeping it might have a positive impact on the error introduced by the information loss due to load shedding, i.e. keeping it might decrease the variance of the data items in the data stream, it may be beneficial to preserve the tuple in the data stream and thus improve the data quality of the resulting data after the data stream is processed. Therefore, the two potential outcomes are evaluated so that a decision can be made about which of the two options is better for the resulting data quality of the resulting data after the data stream is processed.",{"@attributes":{"id":"p-0042","num":"0038"},"figref":["FIG. 5A","FIG. 5A"],"b":["502","1","1","504","2","2","506","1","2","1","2","508","1","2","510","512"]},{"@attributes":{"id":"p-0043","num":"0039"},"figref":"FIG. 5B","b":["514","516"],"sub":["j+1","j+1","j","j+1 ","LS ","LS","LS "]},"Thus, the lower and upper bounds of this interval are the control interval bounds, which are updated and used to decide which load shedding action should be performed. The required load shedding rate is the load shedding rate required by the system to process the data stream without overload. The suggested load shedding rate is compared to this control interval around the required load shedding rate, so that small temporary derivations from the required load shedding rate are enabled to allow for the improvement of the resulting data quality of the data stream. By using the smoothed trend of the EWSA, the required load shedding rate is guaranteed despite these temporary derivations for the overall data stream.","At process block , the suggested load shedding rate is compared to the updated control interval bounds. If the suggested load shedding rate is higher than the higher bound of the updated control interval bounds, it is determined that the tuple should be deleted at process block . It is determined that the tuple should be deleted, because, if the suggested load shedding rate is higher than the higher bound of the control interval bounds, then the required load shedding rate can not be achieved with the suggested load shedding action and the tuple has to be deleted to guarantee the required reduction of the system overload (that is, overload in the data stream). If the suggested load shedding rate is lower than the lower bound of the updated control interval bounds, it is determined that unused capacity exists in the system, and the tuple should not be deleted. Thus, at process block , it is decided to keep the tuple and the process described in  is executed to determine the best load shedding action to perform with respect to improving the data quality in the data stream. If the suggested load shedding rate is within the updated control interval bounds, it is determined that the required load shedding rate can be achieved and the suggested load shedding action is performed at process block .",{"@attributes":{"id":"p-0046","num":"0042"},"figref":"FIG. 6","b":["600","602","604","602","612","610","600","608","600","612","610","600","604"]},"The system  also includes a testing module . In one embodiment the testing module  is used to test alternative scenarios for load shedding. The testing module may test alternative scenarios for load shedding in the data stream and determine if a required load shedding rate is achievable. A required load shedding rate may depend on the available capacity and resources in the system . To determine if an overload exists, system resources are compared to the workload of all incoming data streams and queries.","In an alternative embodiment, the system  requires the resulting processed data to have an optimal value of the data quality dimension completeness. In this embodiment, the analysis module  may calculate the completeness of tuples and tuples with high completeness may be sent through the processor  to be stored on the memory. The testing module  may test each consecutive tuple to determine if the completeness of the tuple is higher or lower compared to the lowest completeness stored in the memory . In one embodiment, the testing module may send instructions to the load shedding module  to delete a tuple if the tuple is of unacceptable quality as compared to the tuples already stored to the memory .","In one embodiment, the process as described in  may be performed by components as described in .","In one embodiment, process as described in  may be performed by components as described in .","In one embodiment, the process as described in  may be performed by components as described in .","In one embodiment, the process as described in  may be performed by components as described in .","In one embodiment, the process as described in  may be performed by components as described in .","In one embodiment, the process as described in  may be performed by components as described in .","Some example embodiments of the invention may include the above-illustrated modules and methods being written as one or more software components. These components, and the functionality associated with each, may be used by client, server, or peer computer systems. These components may be written in any computer programming languages including object-oriented computer languages such as C++, and Java. The functionality described herein may be distributed among different components and may be linked to each other via application programming interfaces and compiled into one complete server and\/or client application. Furthermore, these components may be linked together via distributed programming protocols. Some example embodiments of the invention may include remote procedure calls being used to implement one or more of these components across a distributed programming environment. For example, a logic level may reside on a first computer system that is remotely located from a second computer system containing an interface level (e.g., a graphical user interface). These first and second computer systems can be configured in a server-client, peer-to-peer, or other configurations.","Software components described above are tangibly stored on a machine readable medium including a computer readable medium. The term \u201ccomputer readable medium\u201d should be taken to include a single medium or multiple media that stores one or more sets of instructions. The term \u201ccomputer readable medium\u201d should also be taken to include medium that is capable of tangibly storing or encoding instructions for execution by a computer system and that causes the computer system to perform any of the methods described herein.",{"@attributes":{"id":"p-0057","num":"0053"},"figref":"FIG. 7","b":["700","700","705","755","700","740","755","710","715","710","715","705","715","700","725","730","700","720","700","735","700","750","700","745"]},"The above description of illustrated embodiments of the invention, including what is described in the Abstract, is not intended to be exhaustive or to limit the invention to the precise forms disclosed. While specific embodiments of, and examples for, the invention are described herein for illustrative purposes, various equivalent modifications are possible within the scope of the invention, as those skilled in the relevant art will recognize.","These modifications can be made to the invention in light of the above detailed description. The terms used in the following claims should not be construed to limit the invention to the specific embodiments disclosed in the specification and the claims. Rather, the scope of the invention is to be determined entirely by the following claims, which are to be construed in accordance with established doctrines of claim interpretation."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The invention is illustrated by way of example and not by way of limitation in the figures of the accompanying drawings in which like references indicate similar elements. It should be noted that references to \u201can\u201d or \u201cone\u201d embodiment in this disclosure are not necessarily to the same embodiment, and such references mean at least one.",{"@attributes":{"id":"p-0013","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0012"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0013"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0018","num":"0014"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0019","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0020","num":"0016"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
