---
title: Method and apparatus for separating text from images
abstract: The invention described herein provides a method and apparatus for document processing that efficiently separates and interrelates single modalities, such as text, handwriting, and images. In particular, the present invention starts with the recognition of text characters and words for the efficient separation of text paragraphs from images by maintaining their relationships for a possible reconstruction of the original page. The text separation and extraction is based on a hierarchical framing process. The process starts with the framing of a single character, after its recognition, continues with the recognition and framing of a word, and ends with the framing of all text lines. The method and apparatus described herein can process different types of documents, such as typed, handwritten, skewed, mixed, but not half-tone ones.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07082219&OS=07082219&RS=07082219
owner: The United States of America as represented by the Secretary of the Air Force
number: 07082219
owner_city: Washington
owner_country: US
publication_date: 20021205
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["PRIORITY CLAIM UNDER 35 U.S.C. \u00a7119(e)","STATEMENT OF GOVERNMENT INTEREST","BACKGROUND OF THE INVENTION","OBJECTS AND SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["This patent application claims the priority benefit of the filing date of a provisional application, Ser. No. 60\/354,149, filed in the United States Patent and Trademark Office on Feb. 4, 2002.","The invention described herein may be manufactured and used by or for the Government for governmental purposes without the payment of any royalty thereon.","The recognition of printed and handwritten characters and words is an important research field with many applications existing in post offices for identifying the postal code from the addresses on the envelopes and sorting the mail, in banks for check processing, in libraries for computerizing the storage of books and texts, and also as reading devices for blind people, etc. Although many methodologies and systems have been developed for optical character recognition (OCR), OCR remains a challenging area. In particular, a good OCR system spends on the average about 2\u20133 seconds for the recognition of a handwritten character from a handwritten word. An extreme case is the OCR system by Loral, which is based on a very expensive parallel multiprocessor system of 1024 Intel-386 microprocessors, where each 386 CPU processes only one character at a time. There are also many OCR methods based on neural networks, such as the AT&T Bell labs OCR chip, the multiple Neural Networks OCR approach, etc. There are some other OCR methods based on human like recognition. One of them uses a fuzzy graph based OCR approach, with adaptive learning capabilities, which reduces the character dimensions to speed up the recognition process. It scans the text page, detects a character, extracts and recognizes it, produces the appropriate ASCII code, and sends it to the host computer in a few milliseconds simulated average test time. Image Processing and Pattern Recognition (IPPR) are two older research fields with many significant contributions. The recognition and extraction of objects from images is a small sub-field of IPPR. There are many successful methods based on neural nets or graphs to recognize different kind of objects (faces, cars, chairs, tables, buildings, etc) under very noisy conditions.","Recently, attention has been focused on the document processing field due to multimedia applications. Although document processing is an interesting research field, it introduces many difficult problems associated with the recognition of text characters from images. For instance, there are cases where a document can be considered either as text or as image, like images generated by text characters. Also, artistic letters in very old and valuable books, where the starting letter of each paragraph look like a complex image. In some cases, however, the text is handwritten, and the problem becomes more difficult. Several methods have been developed for document processing. Most of these methods deal with the segmentation of a page and the separation of text from images. One prior art method is a \u201ctop-down\u201d approach and produces good results under the condition that the examined page can be separated into blocks. Another prior art method is algorithmic \u201cbottom up\u201d process with good performance in several categories of pages with good spacing features, and \u201cnon overlapping\u201d blocks. Yet another prior art method exists and is also a \u201cbottom up\u201d process with very good performance especially in long text uniform strings. Still another prior art method exists that separates images from text (typed or handwritten) by maintaining their relationships.","One object of the present invention is to provide a method and apparatus for processing documents by separating text from images yet maintaining their relationship for reconstruction.","Another object of the present invention is to provide a method and apparatus for recognizing single characters, words, and lines of text.","Yet another object of the present invention is to provide a method and apparatus for recognizing typed as well as handwritten words and letters.","The invention described herein provides a method and apparatus for document processing that efficiently separates and interrelates single modalities, such as text, handwriting, and images. In particular, the present invention starts with the recognition of text characters and words for the efficient separation of text paragraphs from images by maintaining their relationships for a possible reconstruction of the original page. The text separation and extraction is based on a hierarchical framing process. The method starts with the framing of a single character, after its recognition, continues with the recognition and framing of a word, and ends with the framing of all text lines. The method and apparatus described herein can process different types of documents, such as typed, handwritten, skewed, mixed, but not half-tone ones.","According to an embodiment of the present invention, method for separating text from images, comprises the steps of: a first step of scanning a binarized page of text so as to detect a character; a first step of creating a temporal window on the binarized page and a second step of scanning the temporal window so as to extract a character shape; graphing line segments; recognizing and framing a character; a first step of connecting adjacent character frames in the same word; a second step of creating multi-frame word blocks; recognizing hand-written words; a second step of connecting word frames; saving the coordinates of lines of text and paragraphs on a given page; and extracting images from a page.","Binarization & Character Detection","Referring to  and , the entire text page is initially binarized  and its pyramidal form is generated . A \u201cpyramidal\u201d representation of a 2D array (i.e., an image of a document page in the present invention) is the hierarchically reduced representations of the array from the original representation comprising N\u00d7N pixels, to the final representation comprising 1\u00d71 pixels. All such diminishing array representations (or layers) portray a \u201cpyramidal\u201d structure of reduced size in layers. Then the page area is scanned  for the isolation and interrelation of informative regions R(ij), k\u03b5Z, with text or images. When the first top \u201cinformative\u201d region R\u2014a region with text or image\u2014is detected , the methodology defines that particular region at the \u201cfirst pyramidal\u201d level  (i.e., the \u201cfirst pyramidal\u201d level in the present invention is the original page of N\u00d7N pixels) and focuses  on the upper left corner of the region to detect a text character , if possible.","Character Recognition","Referring to  and , the character recognition process starts with the creation of a temporal window  Wnxm, of nxm pixels. This window W covers the upper left area of the actual (in size) region R. A scanning process takes place  within window Wnxm, to detect the edges of possible character or the shape of an unknown object. When an edge is detected , a Chain Code (CC) method is used to extract the shape  of the unknown character or object. The \u201cunknown\u201d shape extracted by the CC method is represented  as a string S:\n\n()() . . . () . . . ()\n\nwhere n\u03b5 Z, dj\u03b5 {1,2,3,4,5,6,7,8}, c=0, cc=9, and i,j,k,l,m\u03b5Z.\n","Referring to  and , a line generation and recognition process is applied  on the string S and its segments are recognized  either as straight lines (SL) or as curved lines (CL). At this point the present invention converts  a string S into a graph G:\n\n\n\nwhere a line segment (SL or CL) corresponds to a graph node:\n\n\n\nwhere each graph node Nrepresents the properties of the corresponding segment:\n\n={Realtive Starting Point (SP), Length (L), Direction (D), Curvature (K)}\n\nand each are arepresents the relationships between segments:\n\na={connectivity (co), parallelism (p), symmetry (sy), relative size (rs), relative distance (rd), relative orientation (ro), similarity (si), . . . }, r \u03b5{co, p, sy, rm, rd, si}\n","For the actual matching process, each node Nhas only property in the curvature (K).","Referring to  and , in the event that a text character is extracted  and represented in a graph form, a fuzzy graph matching process takes place  within a graph data base to classify  the character. The classification of a character is associated with attributes, such as orientation, size, and font. If, however, the extracted pattern is not recognizable , the present invention considers it as a possible piece of an image or drawing . Thus, the present invention saves the unknown pattern's coordinates  and continues the extraction  of the next pattern. If the new extracted pattern is also unrecognizable as a text character , the present invention repeats its attempts until it covers that particular informative region, by generating a block (or blocks) of non-text patterns and saving each block's coordinates  for future reconstruction.","Character Framing","Referring to , when a particular character is recognized by the present invention, its attributes are used for the generation of its frame  (see ). This a flexible process since it provides the ability to frame characters with different skews and size.  shows the framing of a character by using the maximum points sp (for top) and cp (for left side), and the frames of different size characters. If it is determined that a particular character has overlapping parts with adjacent characters  (see ), a voting recognition process is used to appropriately recognize it  (see ).","Connecting Character Frames","Referring to  and , when the framing of the first character is completed , the character extraction and recognition process is repeated  with the next neighboring character which has the same or different orientation (v) with the previous one. Thus, after the framing of the next character, the present invention connects these two frames into one , once it has been determined that they belong to the same word . The connection (or synthesis) of two frames (see ) starts with the use of the frames orientations (v, v, i,j\u03b5Z+) to match  one of the eight possible connection patterns (see ). The present invention assumes that two consecutive characters belong to the same word if the distance between them is equal or smaller than (dc), where dc is a predefined parameter. The connection block (cb) is generated by the projection of hinto the other frame's high h. Thus, the shape of cb varies according to the orientations of these two frames.","Word Framing","Referring to  and , the present invention repeats character framing  (also see ) until it is determined  that the distance between the last two consecutive characters is greater than dc. Thus, at the end of this step, the present invention creates a multi-frame block  for the extracted word by using the character frames and their projections to each other,  shows graphically the synthesis of frames and connection blocks by using the eight possible connection patterns (see ). In particular, frame (W) is connected to the frame (h) by using connection pattern \u201ce\u201d, frame (h) is connected to the frame (e) using connection pattern \u201ce\u201d, frames (e) and (r) use connection pattern \u201cb\u201d, and frames (r) and (e) use connection pattern \u201ca\u201d.","Word Recognition","Referring to  and , the present invention has the ability to recognize handwritten words by appropriately segmenting them  and temporarily saving  their recognizable ASCII codes. It then composes  these codes into text words and compares  them with the contents of the lexicon database. If it is determined that a character is not isolated from the adjacent characters , due to overlapping and\/or underlining, the present invention moves the window Wnxm into three positions (left, center, right, see table-1) around the character  and each time a character recognition is performed. This means that three character recognition attempts are made  for a possible single character, in an effort to optimize the correct recognition of each character and the \u201cbest\u201d segmentation of the examined word. The three recognizable character outputs are compared  in a voting section and the character with more than two appearances is selected  as the one with the higher probability. At the end of this process, the selected character is saved in the memory . The same process is repeated until it is determined  that the \u201clast\u201d character of the examined word has been recognized and saved in the memory. At this point the present invention extracts the length of that particular word , defines the starting character (if possible)  and attempts a fuzzy matching process with the known words in the lexicon database . As a result of this matching process, a number of words associated with their matching probability are retrieved from the lexicon database. Thus, the word with the highest probability (if any) is selected as the correct one. The word given in , the fuzzy matching to lexicon database, provides as a first choice the word \u201canimation\u201d (55%) and second choice the word \u201canimosity\u201d (11%). It has been shown that the word recognition process has an 89% success on different styles of handwritten words.","Text Line Framing","Referring to , the connection of word frames follows a similar procedure, like the connection of character frames, by connecting  the last frame of each word with the first frame of the next one. Thus, a text line frame may be a multi-skew block, which covers only the characters frames and the space of the connection blocks.","Connecting and Extracting Text Line Frames","Referring to , in order to extract text lines from a document, it is necessary to save the coordinates (x,y)  and the relative orientation (rv)  of the first character frame of each text line relative to the borders of the document page. Thus, the framing and the extraction of paragraphs or the entire text of a document page is obtained by interrelating the extracted text line blocks  with numbers (#N)  according to their relative positions on the document page.","Extracting Images","Referring to , the extraction of the images is based on a sequential scanning of the image region , by saving the coordinates (X,Y) of the upper left top pattern  and its relative orientation (RV)  regarding with the borders of the document page.","While the preferred embodiments have been described and illustrated, it should be understood that various substitutions, equivalents, adaptations and modifications of the invention may be made thereto by those skilled in the art without departing from the spirit and scope of the invention. Accordingly, it is to be understood that the present invention has been described by way of illustration and not limitation."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1B"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2B"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4B"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6B"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 8B"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 9A"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 9B"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
