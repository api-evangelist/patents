---
title: Code and thread differential addressing via multiplex page maps
abstract: Described is a system and method whereby processes may have multiple memory maps associated therewith to provide curtained memory and overcome other memory-related problems. Multiple maps are used to restrict memory access of existing code such as drivers, without changing that code, and without changing existing microprocessors. A thread of a process is associated with one memory map at a time, which by mapping to different memory locations, provides memory isolation without requiring a process switch. Memory isolation may be combined with controlled, closed memory map switching performed only by trusted code, to ensure that some protected memory is inaccessible to all but the trusted code (curtained memory). Map switching among multiple maps eliminates the need to change a process in order to access different memory, thereby allowing expanded memory addressing in a single process and isolating untrusted code run in process from certain memory of that process.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07073173&OS=07073173&RS=07073173
owner: Microsoft Corporation
number: 07073173
owner_city: Redmond
owner_country: US
publication_date: 20010726
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["The present application claims priority to U.S. Provisional Patent Application Ser. No. 60\/251,347, filed Dec. 4, 2000.","A portion of the disclosure of this patent document contains material that is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records, but otherwise reserves all copyright rights whatsoever.","The invention relates generally to computer systems, and more particularly to computer processes and memory.","The concept of virtual memory allows a computer system to have more addressable memory (e.g., four gigabytes) than is physically present in the computer system (e.g., 256 megabytes). To this end, each process has a memory map associated with it that maps virtual addresses allocated to that process to actual physical memory addresses. So that the physical memory can be shared without losing its contents, a memory manager trims (pages) the physical memory contents of one process to disk when the physical memory is needed by another process.","A contemporary microprocessor such as of the x86 family of microprocessors has user mode memory and kernel mode memory, and do not allow user mode processes to access kernel mode memory. Because the operating system allocates memory to user mode processes, the operating system works with the CPU to prevent memory conflicts and ensure security by prohibiting each user process from accessing the address space of other user processes. Further, different kinds of access to memory ranges, e.g., read and write access or read-only access, may be granted when memory is allocated to a process.","However, the operating system and other privileged kernel mode programs may access any memory addresses, including the memory of user mode processes. Among other things, this means that kernel mode code such as drivers can easily copy proprietary or confidential data (e.g., copyrighted content such as music or a movie) from any other process. Because contemporary operating systems are based on having freely installable drivers, of which a large existing base is available, it is not considered practical to prevent such access without entirely revising the existing model, such as by verifying the kernel mode components and not allowing other kernel mode components to be added. However, providing a verified operating system that does not allow for the installation of privileged drivers is highly impractical. As a result, a fundamental change to microprocessors that denies unrestricted memory access to all but certain trusted and verified code (e.g., a verified operating system) is considered necessary to provide content security. However, even at significant expense, such a microprocessor will not be available for a number of years.","Briefly, the present invention provides memory security (sometimes referred to as \u201ccurtained memory\u201d) and overcomes other memory-related problems by restricting existing code such as drivers, without changing that code and without changing existing microprocessors. This is accomplished by enabling processes to have multiple memory maps, with any given thread (unit of execution) of a process being associated with one of the maps at any given time. This provides memory isolation without requiring a process switch. In addition to providing isolation among the various divisions of code (e.g., procedures or drivers) executed by threads within the same process, which eliminates some memory access bugs, multiple maps for a single process may be used to provide curtained memory. To this end, memory isolation may be combined with controlled, closed memory map switching by trusted code to selectively limit the memory addresses that the threads of a process can access. For example, the threads of the process may ordinarily run at one privilege level, while map switching is only allowed at a higher privilege level. Since threads run through code, the map may be changed on entering or leaving certain verified and trusted code, thus controlling what memory addresses a thread can access based on what code is being executed at a given time. In this manner, only a small amount of trusted code decides what virtual memory a given thread can access and when, thus providing curtained memory without changing the microprocessor design.","The present invention may be implemented with any microprocessor that has protection and a protection-context-change mechanism. For example, in an x86 processor, the protection mechanism may comprise a call gate, with map switching not allowed except at a ring 0 privilege level. To change a map for a given code module, which operates at a ring 1 or higher privilege level, a hardware call gate switches to ring 0, where it executes code that switches the map such as to access protected memory, and then calls a predefined service entry point (e.g., a system API) on behalf of the code module. On return from the called service, the privilege level is restored to ring 1 and the code module is returned to a different map (e.g., with less access) on exit. Note that the process (threads) request allocation of memory as before, but trusted code (e.g., as part of the operating system) is in control of which map (e.g., Map or Map in a two-map process) the thread receives. To provide a truly-safe protection mechanism, certain data structures also may need to be protected, (e.g., the tables that determine the virtual-to-physical memory address mapping need to be protected from write access by untrusted processes), otherwise an untrusted process could simply change the table data (the mappings therein) to access otherwise protected memory.","However, this protected memory does need to be accessed for valid reasons, such as when allocating virtual memory to a process. The present invention does this by intercepting the request for memory at verified code, temporarily changing the privilege level to change the mapping, and calling the virtual memory allocation API on behalf of the process. When the API returns, the trusted code restores the map that does not allow access to the protected memory, restores the privilege to the level that does not allow the re-mapping, and then returns the virtual memory allocation information (e.g., list of allocated ranges) to the process.","Moreover, process switching to change maps at other times is a relatively costly and thus undesirable operation. Map switching among multiple maps eliminates the need to change a process in order to access different memory. For example, by changing the map, the same user process can access different sections of memory beyond the two gigabytes (or possibly three gigabytes) normally available to a user mode process. In such an application, multiple mapping facilitates expanded user mode memory addressing in the same process, enabling improvements to programs such as Microsoft\u00ae SQL server that desire additional addressable memory but do not necessarily want multiple processes. To this end, a process has multiple maps, each of which may map to some memory in common with other maps and also map to some memory that is unique to the map in a range above four gigabytes. To address the expanded memory, the process code chooses the appropriate map that points to the desired range or ranges, but otherwise may operate the same as any other process.","Further, less trusted code can be executed in a trusted process having a first map. When a thread runs the untrusted code, the process has that thread use a second map that restricts the memory locations and\/or type of memory access available to those threads. This isolates untrusted code within a process by not allowing it to access any process memory that the trusted process does not want it to access, and\/or only with the access rights granted by the process. Other similar benefits may be obtained via multiple maps.","Other advantages will become apparent from the following detailed description when taken in conjunction with the drawings, in which:","Exemplary Operating Environment",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1","b":["100","100","100","100"]},"The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and the like.","The invention may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, and so forth, that perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote computer storage media including memory storage devices.","With reference to , an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer . Components of the computer  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.","Computer  typically includes a variety of computer-readable media. Computer-readable media can be any available media that can be accessed by the computer  and includes both volatile and nonvolatile media, and removable and non-removable media. By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can accessed by the computer . Communication media typically embodies computer-readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer-readable media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , other program modules  and program data .","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media, discussed above and illustrated in , provide storage of computer-readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules  and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers herein to illustrate that, at a minimum, they are different copies. A user may enter commands and information into the computer  through input devices such as a keyboard  and pointing device , commonly referred to as a mouse, trackball or touch pad. Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . In addition to the monitor, computers may also include other peripheral output devices such as speakers  and printer , which may be connected through a output peripheral interface .","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface  or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on memory device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Turning to  of the drawings, there is shown a general architecture into which the present invention may be incorporated. Note that the present invention is described herein with respect to the Windows\u00ae 2000 (formerly Windows\u00ae NT\u00ae) operating system and the x86 family of microprocessors. However, as can be readily appreciated, the present invention is not limited to any particular operating system and\/or microprocessor, but rather may be used with any operating system or microprocessor that has protection and a protection-context-change mechanism. For example, and as will be understood, to build the protection mechanism on an existing system such as the x86, two kernel mode rings are needed, one of which restricts use of map loading and debug instructions. Alternatively, any other way to restrict special instructions can accomplish the same functionality. For example, while two kernel \u201crings\u201d are not necessarily required, at least two distinct modes in kernel space are needed.","In , each process of a set of user mode processes \u2013and kernel mode processes \u2013communicates with the operating system , which includes a memory manager  for handling the memory requirements of the user level processes \u2013, kernel-level component (such as driver) processes \u2013, and the operating system  itself. In the Windows\u00ae 2000 operating system, one task of the memory manager  is to manage virtual memory, which gives processes (e.g., \u2013) the ability to address more random access memory (e.g., two gigabytes) than may be actually physically available in a given system (e.g., 128 megabytes). The memory manager  in Windows\u00ae 2000 accomplishes this through a combination of address translation techniques and disk swapping techniques, as generally described in the references entitled , H. Custer, Microsoft Press (1993), , D. Solomon, Microsoft Press (1998), and 2000, D. Solomon and M. Russinovich, Microsoft Press (2000), herein incorporated by reference.","To manage virtual and physical memory, the memory manager  maintains memory-related information in a process structure \u2013for each process, including for example, information (e.g., via a pointer) indicating which virtual memory locations are allocated thereto. The memory manager  also maintains a set of tables  that are used by the CPU  to translate virtual memory addresses to actual physical memory addresses. Note that the various components shown in  (other than the CPU ) are often present within the physical memory (e.g., RAM) , but for purposes of clarity are not shown as loaded therein.","In physical memory in the Windows\u00ae 2000 environment, accessible memory is organized in units referred to as a page, wherein, for example, a page equals four kilobytes (4096 bytes in decimal) in an x86 microprocessor-based system. Other page sizes (e.g., eight kilobytes in an Alpha microprocessor-based system) may be employed. Indeed, there is no intention to limit the present invention to any particular microprocessor, page size and\/or memory architecture, as it is expected that as microprocessors evolve into other page sizes and\/or larger amounts of physical memory, such systems will also benefit from the present invention. Thus, as used herein, a \u201cpage\u201d is not limited to any particular size, and may even be variable within a given system. A PFN (page frame number) database  is used by the memory manager  to track the physical pages in memory, including the relationships to virtual page addresses and other state information about the physical pages. Note that the PFN database  maintains state information about the actual physical memory installed in a system, e.g., there is a record in the PFN database  for each page of physical memory, not one for each virtual memory page address.","Multiplex Page Maps","In accordance with one aspect of the present invention, each process (e.g., ) can have multiple maps associated with it (logically attached thereto) as generally represented in . More particularly, as generally represented in  and described in the aforementioned and 2000 references, each process that has virtual memory allocated thereto has one or more page directories \u2013maintained therefor by the memory manager , primarily used for converting a virtual address to a physical page of memory. The relevant virtual page address directory is located from part (e.g., the upper bits) of the virtual address provided by the process (e.g. ). Each page directory (e.g., ) has a number of page directory entries (PDEs), wherein each entry serves as an index to one of a set of page tables \u2013. Each page table (e.g., ) includes page table entries (PTEs), one of which (indexed from another part of the virtual address) identifies the actual physical page in memory (RAM ), along with flags regarding the state of the virtual page address, such as whether the virtual page address is currently mapped to a physical page (valid) or has been trimmed to disk (invalid). When a process is switched to, the operating system writes the map information to an address map-specifier, such as a register , (e.g., the CR3 register on x86 systems). Based on this, the CPU decodes the physical address from the virtual address, which specifies the page table index used to locate a page table entry that describes the physical memory location, and a byte index which describes the byte address within that page.","In accordance with an aspect of the present invention as described below, the operating system can change the map even when the process is not switched, thereby allowing multiple maps per process. To this end, the operating system may be notified by the process as to which map (e.g., page directory page) is desired for a given thread, or the operating system can decide when a map change is needed, and writes the map information to the address map-specifier, e.g., the CR3 register  in x86 systems.","One such call (through an open gateway) to change a map essentially looks like this:","push CurrentThread.MapSelect","TargetSelect=[map which spans the special code to call]","switch to CurrentThread.Process->Map[TargetSelect]","call Target","pop TargetSelect \/\/ return to state before the call","switch to TargetSelect",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 4","FIG. 4","FIG. 4"],"sub":["11","15 ","21","24 ","11","14 ","15 ","13 ","12 ","21","22 ","24 ","23 "],"b":["1","431","3","433","1","3","1","441","2","432","4","434","2","4","2","442"]},"As shown in  via the arrows, each of the map entries essentially point to one of the physical pages in memory , as described above. Note that maps may map similar addresses to the same physical pages, or to different physical pages, and physical pages may or may not be shared. Particular virtual addresses (and thus access to the physical pages) may be present in one mapping and not in another.","To accomplish switching among multiple maps in accordance with an aspect of the present invention, the operating system  includes an array of address map pointers in its process structure, a thread structure which contains a process pointer (as before), and a map selection value. With multiple address maps attached to a process, each thread in the process may request which of the maps it will use, and\/or have a map selected for it by trusted operating system code.","To appropriately switch maps, threads and\/or processes, the operating system executes a routine such as set forth below and generally described in the flow diagram of :",{"@attributes":{"id":"p-0051","num":"0050"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if (OldThread.Process != NewThread.Process)"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ change both thread and process, which implies map"]},{"entry":[{},"\/\/ change"]},{"entry":[{},"Save OldThread.ThreadRegState"]},{"entry":[{},"switch to NewThread.Process\u2212>Map[NewThread.MapSelect]"]},{"entry":[{},"CurrentProcess = NewThread.Process"]},{"entry":[{},"Load NewThread.ThreadRegState"]},{"entry":[{},"Done"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"else if (OldThread.Process\u2212>Map[OldThread.MapSelect] !="}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"NewThread.Proces\u2212>Map[NewThread.MapSelect])"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ process is the same, but maps are different"]},{"entry":[{},"Save OldThread.ThreadRegState"]},{"entry":[{},"switch to NewThread.Process\u2212>Map[NewThread.MapSelect]"]},{"entry":[{},"\/\/ do not reload CurrentProcess, it has not changed"]},{"entry":[{},"Load NewThread.ThreadRegState"]},{"entry":[{},"done"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"else"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ process and map are the same"]},{"entry":[{},"Save OldThread.ThreadRegState"]},{"entry":[{},"Load NewThread.ThreadRegState"]},{"entry":[{},"done"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 5","b":["500","502","504","506","508"]},"If instead at step  the process is unchanged, step  determines whether the maps are different for this thread. If so, the old thread's state is saved, (step ), the new map is switched to (step ) and the new thread's state is loaded (step ). Note that the current process is not reloaded, since it has not changed.","Lastly, if step  determines that the map is the same for the new thread, no map switch is required. Thus, steps  and step  are executed to save the old thread's state and load the new thread's state, respectively.","It should be noted that instead of maintaining separate maps at the memory manager level specifying what memory can be accessed, it is equivalent to maintain one main map, and maintain one or more other \u201cmaps\u201d specifying access changes relative to the main map. The changes are then applied when memory restriction is desired.","One optimization that may be implemented in a multi-level map scheme (such as the pagedir\/page table addressing scheme of the x86) maps map similarities and differences into certain boundaries, e.g., page table-spanned boundaries in the x86. For example, consider page table maps with four megabyte boundaries (as in the x86), wherein some maps are either the same with other maps, or unique unto themselves at four megabyte boundaries. In such a situation, memory management may express map differences by editing only the appropriate page directory entries, while treating PTEs normally. Taking the example of , maps  (#) and  (#) may use one set of page tables for sections b, c, and d. There would be one set for section a. In this example, the maps may have different page directories, which only differ in that map (#) does not have a PDE for section a. With this scheme, PTE edits may be done only once, and automatically apply to multiple maps. Note that PDE edits (e.g., to add a new shared four-megabyte region which is shared) requires edits to be done to both page directories. Note that this technique can be applied in a system which has more than two addressing levels.","Further, although the above description refers primarily to maps being attached to processes, it can be readily appreciated that the above-described techniques would also work with sets of maps attached to each thread (e.g., with more copying amongst maps) and\/or with \u201cfree-floating\u201d maps that could be passed around (e.g., with code to associate\/de-associate maps). While not optimal because of complex synchronization requirements, both of these are workable equivalents.","One efficiency-related optimization to speed map changes leverages the ability of some processors to load a translation look-aside buffer (TLB)  on a process basis, wherein a process switches (using a process\/process identifier (PID) field) to select a different subset of the TLB. In this manner, the operating system can change maps without having to invalidate or reload the entire TLB, (which are inefficient operations). By treating each TLB \u201cprocess\u201d as an address map, when a map is changed, the hardware is told that the process\/PID is changed, even though it is actually the same process. This effectively speeds up map switching, and does so without a process switch.","The ability to switch maps provides numerous benefits, one of which is increased robustness by isolating various code in a process from other code in a process. In other words, by selecting among multiple maps, a thread that runs certain code is not able to access (or for example, may be given lesser access such as read-only access to) the memory associated with some other code in the same process. This isolation provides protection from errant code (e.g., a driver) that incorrectly writes to memory, such as due to an accidental pointer reference or the like, without necessitating any change to the code itself. To isolate, the restricted map may simply omit the mappings to certain addresses, or the maps may list the same address mappings but with the inaccessible addresses marked invalid in the restricted map.","By way of example of isolation, in , it is possible for the thread Tof Process () to be running some ordinary kernel mode code, and thus be running on a full kernel mode address map, while \u201cat the same time\u201d the thread Tof the same process, Process (), runs some restricted code (such as a device driver) and runs on a kernel mode address map which does not map any kernel private data, thus protecting that data from the restricted code. Thus, in , any thread of the process  cannot access a virtual location (a) that maps to physical page  when the map associated with that thread (e.g., T) is map  (Map). Note that the address maps may have some memory that is mapped the same, whereby some of the memory allocated to a process may be accessed by any code (the thread that executes it), while other memory may be restricted to certain code in that process. Further, note that although not shown in , a process may have more than two maps associated with it.","Trusted Memory Access Protection","In accordance with an aspect of the present invention, the above-described map switching may be controlled by trusted (verified) code, thereby preventing kernel mode code such as drivers (or even most of the operating system) from freely switching maps. In this manner, kernel-mode code (even malicious code) is unable to freely access restricted content in memory, whereby curtained memory is enabled. To this end, an already-existing hardware protection mechanism (such as a call gate in an x86 system) may be employed to switch maps in a closed-gateway concept, and since threads run through code, the map may be selectively changed by the trusted code on entering or leaving certain code. Code can thus be protected by only letting it be accessed by a particular map, and the map switch can be controlled by a closed gateway.","By way of example, in x86 systems, a call gate is a mechanism used to switch privilege levels. Four rings, or privilege levels are available, however prior to the present invention, only two are used by contemporary operating systems, ring 0 (the most-privileged level) for kernel mode code and ring 3 for less privileged, user mode code. As generally represented in , to provide memory protection in accordance with the present invention, map switching and some trusted operating system operations will be performed at ring 0, the most privileged level. To this end, the protected components  including the protected code and other components including maps and page frame lists as described below are accessible only at that Ring 0 level. Other kernel mode code components  will have their operations performed at the ring 1 level, (with user mode code and other components  remaining at ring 3). In this manner, a kernel mode process is restricted to requesting a map switch, or having a map switch done for its thread by trusted operating system code only as needed and when the code being executed by the thread is known to be safe, wherein only a relatively small amount of trusted code is needed to control the map switching operations.","For example,  and the flow diagram of  generally describe one way in which memory access protection is achieved without changing the kernel code (e.g., driver) that is executed. In the example of , a driver process  running at ring 1 privilege level and a map  (restricted relative to a map ) is requesting allocation of virtual memory, which it does in its normal manner, such as via a call to an API  in the Windows\u00ae 2000 environment. This is generally represented in  by the arrow labeled with circled numeral one, and in  by step . However, while the driver process  places such a call in its normal manner, in actuality the call is received and otherwise processed by a thunk (code that re-vectors a call)  or the like, (step  of ). In this example, because memory allocation requires access to protected memory (e.g., to update the page tables), the thunk  calls through a call gate  to change the privilege level to ring 0 (circled numerals two and three, , and step , ). This ring 0 privilege level allows map switching, after which the thunk  changes the memory map to map  by writing the CR3 register (step  of ). At this time, the thread has access to protected memory, thus allowing virtual memory to be properly allocated, however the thread is currently running through trusted code of the thunk, not the driver code. The thunk  then places the virtual memory allocation API (application programming interface) call on behalf of the requesting process  at circled numeral four of  (step  of ), and receives the virtual memory allocation data (e.g., list of memory ranges allocated) as represented in  via circled numeral five.","At steps \u2013, the thunk  essentially operates in reverse, changing the mapping back to map  (step ) by writing the CR3 register, and then calling the call gate  to change the privilege level back to ring 1 (circled numerals six and seven of , step  of ). The thunk  then returns the data for the allocated memory back to the calling process, and returns control thereto (circled numeral eight , step  of ). Note that the thread is only given access to protected memory when the thunk or API code is executing, i.e., the code of the process executed by that thread is never given access to the protected memory. In this manner, curtained memory is achieved by controlling precisely what memory a process can access based on the code through which the thread of that process is running.","Note that instead of using a thunk, the virtual allocation API and any other APIs that need access to protected memory can be changed. However, the use of a thunk to perform the privilege level and re-mapping operation eliminates the need to change the existing APIs.","Further, note that in the above example, although more privilege and memory access via a less restrictive map was temporarily allowed, it was controlled by entering a known, safe service entry point. Upon returning, the ring 1 privilege level and more restrictive map were restored. In essence, in keeping with the present invention, the large majority of the kernel code including drivers and most of the operating system runs at a ring 1 privilege level, but is otherwise unchanged. Since existing code was heretofore not normally concerned with its privilege level, the vast majority of reputable code will be unaware of any change, although malicious programs that relied on full privilege will no longer have it.","Moreover, even with the above-described protected memory system, any process can have multiple maps as described above (e.g., for memory isolation purposes). However, because a privilege change is needed to re-map in the protected memory scheme, the process will not be allowed to change among its maps without calling trusted operating system code to do the map change for it. An API may be provided for this purpose, whereby the thunk or the like changes the privilege level, causes the remap via the CR3 register to a different map of the process (not to a map that gives access to protected memory), and then restores the privilege level. Note that the process can only map to memory that the operating system has allocated to it, as it cannot change its map or access the mapping data. Thus, for example, a kernel mode driver cannot freely access user mode data, including privileged content. In addition to allocating memory, a trusted function may be used to allocate handles, synchronization objects, processes, threads and so forth. The function may also perform trust-privileged operations, such as signaling a synchronization object, deleting a timer, or closing a handle. Freeing memory is also an important trusted function as is changing mapping. Indeed, any operation that touches a page table or the PFN database also needs to be trusted.","As one alternative to the above-described map-switching via CR3 loads, it is possible to edit a process map on entry\/exit from trusted space. For example, this may be accomplished by manipulating select entries in the Page Directory (making things appear\/disappear in four megabyte blocks) or by directly editing lists of PTEs. Note that this would likely be slower.","Thus, to fully protect against various possible attacks, certain data needs to be maintained in protected memory, as generally represented by the dashed boxes in , by controlling mapping via trusted code and making the memory be inaccessible through direct memory access (DMA), i.e., via one or more no-DMA zones. For example, the page tables need to be protected, to prevent a process from simply changing the information therein to grant it access. If the TLB was in software, (in contrast to existing systems where the TLB is in hardware), then supporting structures for such a software TLB would also be in trusted space. Similarly, the PFN database  () needs to be in protected memory, otherwise a process could change the information therein to cause data to be paged back into memory that the process can access. Also, the thread structures (objects) and process structures (objects) should be in protected memory, as should the trusted operating system code, including the thunk and memory manager, which comprise instructions in memory, the Global Descriptor Table (GDT) and interrupt descriptor table (IDT). For example, a trusted system built with the present invention may use an IDT that is in trusted space, but which routes interrupt\/traps\/exceptions to either trusted or untrusted space as needed. More particularly, the page fault handler will be in trusted space, (e.g., to prevent perverting trusted code by intercepting a page fault), whereas normal interrupt service routines may run in untrusted space. The NoDma zone can be accomplished via a hardware assist from the motherboard\/platform, or via very restricted platform design that allows it to be programatically constructed.","By proper construction of the trusted code, entities such as handles and synchronization objects may be protected, with some allowed to be referenced by any code, and others only by trusted code. This is done by requiring that protected entities are only manipulated by trusted code, which checks a \u201cTrustAttribute\u201d or the like of the calling process or thread to decide which handles and synchronization objects may be manipulated. By way of example, it can be arranged such that untrusted code may create, delete, and use timer objects as before, however untrusted code will be unable to delete or manipulate system (trusted) timer objects, in addition to being unable to access them. Note that various ways to securely boot a computer system with the trusted operating system of the present invention are available.","Similarly, certain additional protection should be undertaken. For example, in an x86 processor, the following instructions are made illegal at Ring 1, and thus only available to the trusted operating system code running at ring 0: writing the CR3 register (MOV CR3) as described above, writing the machine status register, setting debug registers, loading the interrupt descriptor table register (IDTR) and loading the global descriptor table register (GDTR). As can be appreciated, these various protections are architecture specific, and may include machine-check control, micro-code-patch instructions, and so forth, while others may be chip specific (e.g., jtag test control). In any event, one skilled in the art with a particular hardware configuration will recognize which operations need to be restricted to trusted mode, and the extent to which that hardware configuration already naturally provides protection.","Heretofore it was believed that a fundamental change to the design of microprocessors was required to provide this type of security, however the present invention can accomplish such security, and bolster it with relatively little motherboard modification. To this end, bridges and the like may be modified to protect the CPU cache from direct memory access reads or the like.","Addressable Space Expansion","In accordance with another aspect of the present invention, the use of multiple maps allows a single process to access a relatively large amount of physical memory (e.g., thirty-two gigabytes) with only a relatively small amount of addressable (virtual address) space (e.g., two gigabytes). As is known, a process has a significant amount of state associated with it, possibly including handles, an access token, security identifiers and so forth, which makes a process switch relatively expensive, as well as inconvenient for developers who at times would prefer not to have to switch processes. Note that it is not just the expense of the process switch that is saved, but having a single process saves on the communication (requiring marshalling\/copying) of memory, pointers, handles, objects and so forth between processes. In the present model, the meaning of pointers is context sensitive (as which map is in use) but is otherwise fully normal, unlike multi-process RPC models in which pointers are heavily constrained.","For example, a program that needs access to large amounts of memory such as Microsoft\u00ae SQL Server at times would likely benefit from being able to access large amounts of memory from only a single process.","By way of example,  shows one such possible set of maps \u2013, wherein each map of a multiple map process  shares the same one-gigabyte of address space, with a second gigabyte of virtual memory that maps to a different section of physical memory. Note that in the example of , the operating system has reserved virtual memory addresses from 2 GB to 4 GB.","Although not shown in , the shared memory can be in kernel mode addressable memory rather than user mode memory, thus allowing access to an additional one gigabyte of user mode memory. Also not specifically shown but readily understood is that the access rights in the shared one-gigabyte of memory may be identical in all of the maps, less than all of the maps, or in none of the maps. Further, it can be readily appreciated that the memory range sizes and number of maps shown in  is only an example, and can be varied in virtually any way.","To provide user mode map switching, some user mode APIS may be provided as generally set forth below:\n\n","With the above APIs, a single process can set up its maps in a straightforward manner, such as by using the code set forth below (generally corresponding to  when the physical memory limit equals 32 GB):",{"@attributes":{"id":"p-0079","num":"0082"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["for","(i = 1; i < LIMIT; i++) {"]},{"entry":[{},"m = CreateMap( )"]},{"entry":[{},"if (error(m) )"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"done"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"maplist [i] = m;"]},{"entry":[{},"AttachToMap(m) ;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/"]},{"entry":[{},"\/\/ we have a new map, which is a copy of the"]},{"entry":[{},"\/\/ previous one"]},{"entry":[{},"\/\/ so unmap anything between 1 and 2 (which was a"]},{"entry":[{},"\/\/ phys map anyway) and map in some new physically"]},{"entry":[{},"\/\/ mapped memory)"]},{"entry":[{},"\/\/"]},{"entry":[{},"UnmapPhys(ONE_GIG) ;"]},{"entry":[{},"MapPhys(ONE_GIG, PHYS_BASE+((i\u22121) * ONE_GIG) ;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"MakeRegionCommon(0 to 1 GIG) ;"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"At this point, the maps are the same from 0 to 1 GB (virtual addresses), and all of them are different from 1 GE to 2 GB (virtual addresses). Each map maps a different 1 GB of extended physical memory into its 1 GB to 2 GB area. Any thread can get to any area of extended physical memory by calling AttachToMap( ) with the appropriate map specified.","While the above-described virtual addresses mapped to physical addresses in which the addresses are numerically larger than the largest virtual address. However, it should be pointed out that a system with less or the same amount of physical memory as addressable virtual memory, may also benefit from the present invention. For example, in a system having only 4 gigabytes (GB) of physical memory, only 128 MB may be given to the OS, with access to some physical location between 3 GB and 4 GB desired using only 2 GB of virtual space. The above-described techniques will enable access to these physical locations. Further, any extended memory (above 4 G in the general examples) may, or may not be, pageable, as there is no reason that 4 GB is special for this technique. Instead, this aspect of the present invention extends virtual addresses on any machine that can have more physical memory than virtual memory, whether that is below a certain physical space (e.g., in sub-4 GB space or not.","Note that instead of an API call, the map switching can be made automatic. For example, a page-fault fix-up handler can switch in the map when some page faults are trapped by the application (using exceptions). More particularly, the thread can be switched to a partially empty map, (possibly after a time-out), whereby the thread touches an always not-present page in common memory. This page fault causes a map that corresponds to the data the thread wants to be automatically loaded. In other words, the code, which is not concerned with maps, touches a \u201crefresh pointer\u201d to get the address of an object, and this pointer reference may be used to automatically cause a map change that can access the object.","In-Process Memory Protection","In accordance with another aspect of the present invention, the use of multiple maps allows a process to isolate code being run in-process from certain memory of that process. For example, a process may wish to run untrusted code (e.g., downloaded from an unknown source) without performing a process switch or using interprocess communication, yet not want that untrusted code to get at some of its memory. Note that the process itself may have restricted rights relative to a parent process to prevent untrusted code from doing other types of harm.","As generally represented in , some untrusted code C is run within a process , but mapped to a map Map that is partially different relative to a map of the process Map. If desired, the process code can share some memory with the code C, with potentially different access rights, on a per-page basis. In this manner, the process  isolates its memory from the code C to the extent the process  desires. Similarly, other code C can be isolated from the process memory and the code C's memory, again as controlled by the hosting process . Some or all of C's memory may be shared with the process and\/or with C's memory, with access rights controlled by the process on a per-page basis.","As can be seen from the foregoing detailed description, there is provided a method and system for using multiple maps in a memory for providing security, increased memory access and memory isolation. The method and system may be implemented on existing microprocessors and without changing existing kernel mode components, other than a small part of the operating system.","While the invention is susceptible to various modifications and alternative constructions, certain illustrated embodiments thereof are shown in the drawings and have been described above in detail. It should be understood, however, that there is no intention to limit the invention to the specific form or forms disclosed, but on the contrary, the intention is to cover all modifications, alternative constructions, and equivalents falling within the spirit and scope of the invention."],"BRFSUM":[{},{}],"heading":["COPYRIGHT DISCLAIMER","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
