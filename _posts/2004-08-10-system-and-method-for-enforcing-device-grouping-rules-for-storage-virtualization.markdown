---
title: System and method for enforcing device grouping rules for storage virtualization
abstract: A system includes one or more storage devices and virtualization software configured to aggregate storage in the one or more storage devices into a virtual storage device accessible to a storage consumer. The virtualization software may include a group validation layer comprising a device-independent interface configured to validate a proposed group configuration operation on the one or more storage devices. The device-independent interface may be used to verify that the proposed configuration operation would, if completed, result in a configuration capable of supporting a desired virtualization functionality. The device-independent interface may allow an application to manage the one or more devices as a unit known as a virtual device group.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07818515&OS=07818515&RS=07818515
owner: Symantec Operating Corporation
number: 07818515
owner_city: Mountain View
owner_country: US
publication_date: 20040810
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["1. Field of the Invention","This invention relates to computer systems, and more particularly, to device group management within storage virtualization environments.","2. Description of the Related Art","Many business organizations and governmental entities rely upon applications that access large amounts of data, often exceeding a terabyte or more of data, for mission-critical applications. Often such data is stored on many different storage devices, which may be centrally located or distributed throughout an enterprise. Such storage devices may be heterogeneous in nature, including many different types of devices with varying functional and performance specifications from many different manufacturers.","Configuring individual applications that consume data, or application server systems that host such applications, to recognize and directly interact with each different storage device that may possibly be encountered in a heterogeneous storage environment would be increasingly difficult as the environment scaled in size and complexity.","Therefore, in some storage environments, specialized storage management software and hardware may be used to provide a more uniform storage model to storage consumers. Such software and hardware may also be configured to add storage features not present in individual storage devices to the storage model. For example, features to increase fault tolerance, such as data mirroring, snapshot\/fixed image creation, or data parity, as well as features to increase data access performance, such as disk striping, may be implemented in the storage model via hardware or software.","In such storage environments, a set of storage devices may be aggregated as a virtual device group and managed as a unit in order to support desired functionality. For example, a virtual device group may be exported as a unit from one storage environment, and imported at another. Storage devices aggregated into a virtual device group may need to conform to a set of group membership requirements, where the set of requirements may vary with the specific functionality desired. For example, all the storage devices constituting a virtual device group may be required to provide a specified minimum level of performance, and\/or to support a specific operation such as the ability to create a hardware snapshot. If a virtual device group is modified in a manner incompatible with the group membership requirements (for example, by adding a device that does not support a particular function supported by other devices already included within the virtual device group), data loss may occur, and\/or elements of metadata used to manage the storage environment may become unavailable or corrupted. In a storage environment where storage devices with different technical specifications from multiple vendors may be used, the use of vendor-specific and\/or device-specific interfaces to verify that group membership requirements are met by each device may result in inefficiencies (e.g., duplication of code) and in error-prone storage management software.","Various embodiments of systems and methods for enforcing device grouping rules for storage virtualization are disclosed. According to a first embodiment, a system may include one or more storage devices and virtualization software configured to aggregate storage in the one or more storage devices into a virtual storage device accessible to a storage consumer. The virtualization software may include a group validation layer comprising a device-independent interface configured to validate a proposed group configuration operation on the one or more storage devices. That is, the device-independent interface may be used to verify that the proposed configuration operation would, if completed, result in a configuration capable of supporting a desired virtualization functionality. The device-independent interface may allow an application to manage the one or more devices as a unit known as a virtual device group.","Numerous proposed group configuration operations may be validated using the device-independent interface in different embodiments. For example, in some embodiments, a proposed operation that may result in a change in the membership of the virtual device group may be validated, such as an operation to add a storage device to the virtual device group, an operation to remove a device from the virtual device group, or an operation to remove all devices from the virtual device group and thereby make the virtual device group unavailable. In other embodiments, other proposed group configuration operations may be validated, such as a frozen image operation, an operation to deport (i.e., prevent further access to) the virtual device group from a device group provider (such as a volume manager), or an operation to import a virtual device group to a device group provider.","In one specific embodiment, the system may also include a plurality of nodes coupled to a network to form a cluster. A first subset of the one or more storage devices may be attached to a first node, and a second subset of the one or more storage devices may be attached to a second node. The virtual device group and the virtual storage device may be accessible from any node in the cluster.","In one contemplated embodiment, a system may include one or more storage devices and virtualization software configured to aggregate storage in the one or more storage devices into a virtual storage device accessible to a storage consumer. The virtualization software may include a group validation layer comprising a device-independent interface configured to verify that a current configuration of the one or more storage devices is capable of supporting a desired virtualization function.","While the invention is susceptible to various modifications and alternative forms, specific embodiments are shown by way of example in the drawings and are herein described in detail. It should be understood, however, that drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary, the invention is to cover all modifications, equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.",{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 1","b":["100","110","120","120","110","120","130","120","140","140","150"]},"A typical storage environment may store large amounts of data (e.g., terabytes of data) on a variety of storage devices , which may be centrally located or distributed throughout an enterprise. Such storage devices may be heterogeneous in nature, including many different types of devices with varying functional and performance specifications from many different manufacturers. A technique called virtualization may be employed within some storage environments to aggregate one or more such storage devices into one or more virtual devices  that have better characteristics than the underlying storage devices. Enhanced capabilities provided by virtual device  may include, for example, increased bandwidth, decreased access latency, higher availability, flexible configuration and administration, and automated backup and restore. Virtual device  may hide details of the implementation (for example, the details of the manner in which data is laid out on a physical storage device) of the underlying storage device from a storage consumer, thereby allowing storage consumers to use simple interfaces (such as \u201cread X blocks at offset Y on the virtual storage device\u201d or \u201cwrite N bytes at offset P within file F\u201d) to perform desired operations on the virtualized storage. Virtualization software  may present virtualized storage device  to storage consumers  using a variety of virtualization primitives in different embodiments, such as virtual blocks or virtual objects such as files, as described in more detail below. In organizing storage devices  into virtual device , virtualization software  may form a virtual device group  in order to operate on storage devices  as a unit. As also described below in further detail, operating on a virtual device group  instead of on individual storage devices A-D may support easier implementation of enhanced virtualization functionality in some embodiments, such as flexible allocation of storage, the ability to import storage previously used by a different virtual device, and the ability to manage frozen images (also known as snapshots or point-in-time copies) of data stored in virtual device . Virtualization software  may be referred to herein as a virtual device group manager.","In one embodiment, storage devices  may include physical storage devices, such as disks; while in other embodiments, a storage device  may itself be a virtual storage device, allowing for multiple layers of virtualization in system . A more detailed description of embodiments including multiple layers of virtualization is provided below.","In some embodiments, storage consumer  may represent an application (such as a database management system, a file system, or a frozen image server) that may require access to storage within virtual storage device  for data storage and retrieval. In other embodiments, storage consumer  may itself be an instance of virtualization software that uses virtual device  as a constituent of a higher-level virtual storage device.","As stated above, virtualization software  may provide different virtualization primitives, such as virtual blocks or virtual objects, to storage consumers. (Object-based virtualization is described in greater detail below.)  illustrates an embodiment of system  employing block-based virtualization (also referred to herein as block virtualization). In , block devices  (i.e., block devices A-D) correspond to storage devices  of , where a block device  may comprise a hardware or software entity that provides a collection of linearly addressed data blocks that can be read or written. For example, in one embodiment a block device  may be a single disk drive configured to present all of its sectors as an indexed array of blocks. It is contemplated that any suitable type of storage device may be configured as a block device , such as fixed or removable magnetic media drives (e.g., hard drives, floppy or Zip-based drives), writable or read-only optical media drives (e.g., CD or DVD), tape drives, solid-state mass storage devices, or any other type of storage device. Block virtualization software  may implement the general functionality described above for virtualization software , e.g., it may manage block devices  as a virtual device group , aggregate storage within block devices , provide additional virtualization functionality, and present the aggregated storage to storage consumer  as a collection of linearly addressed data blocks. In some embodiments of block virtualization, a block device  may also be a logical or virtual block storage device resulting from a mapping of blocks of one or more physical storage devices.","Hardware devices configured to provide a collection of linearly addressed data blocks may generally be referred to as physical block devices, and logical or virtual storage devices so configured may generally be referred to as logical or virtual block devices. It is contemplated that in some embodiments, data blocks may be uniformly sized across different physical and logical block devices, while in other embodiments physical and logical block devices may employ different block sizes. It is also contemplated that in some embodiments, block sizes may vary among particular physical block devices and\/or particular logical block devices, or even within a given block device.","A block device  may differ from a file in that it may not require use of a file system for access; that is, a consumer of a block device  may read or write blocks directly to the device, bypassing any file system that may be in use. In some embodiments, a block device presented by an operating system for use by a consumer may present relatively few primitives through which the device may be manipulated. For example, in one embodiment a block device may support open, close, read and write primitives, plus a few miscellaneous control and query primitives. In contrast, file systems may provide a richer set of primitives, such as support for creating and removing files, appending to files, creating and removing directories, etc. Typical interfaces to block devices may allow for higher raw throughput and greater concurrency than typical interfaces to single files of a file system. Block devices that are physical storage devices, such as disks or tape drives, may be configured to present some form of SCSI interface, though other interfaces are possible and contemplated.","In a block virtualization environment, storage within block devices  may be aggregated to form a virtual storage device known as a volume or a logical volume (). Generally speaking, a volume  may comprise a block device that may be presented directly for use by a block device consumer, i.e., storage consumer . In some embodiments, storage consumer  may be a file system or an application (such as a database application, for example) that can directly use block devices. As described in greater detail below, in some embodiments employing block virtualization, a given volume  may be associated with several logical or physical block devices. In such embodiments, each block device included in the logical organization of a given volume or virtualized block device may be referred to as a storage object or logical storage object.","As stated earlier, physical storage devices, including physical block devices such as disks, may have varying functional and performance specifications, and may be obtained from many different manufacturers for use within a given storage environment. In some embodiments, prior to aggregating storage within physical block devices into one or more volumes, the physical block devices may be configured as a virtual device group  for management as a unit with a common configuration. For example, virtualization software included in the VERITAS Volume Manager\u2122 product provided by VERITAS Software Corporation may be used to combine physical disks to form disk groups, which are named collections of disks with a common configuration. A volume formed using this product is created within a disk group (that is, storage for creating a specific volume must be allocated from the disks forming one disk group). A volume formed from a disk group may not span different disk groups, although multiple volumes may share the same disk group. Once a disk group has been created, it provides a convenient administrative interface for volume level operations such as storage allocation (i.e., expanding the total amount of storage within a volume, either by using existing unused disk space within the disk group, or by adding new disks to the disk group), storage deallocation (e.g., by removing a disk from a disk group), deporting storage (making disks within a disk group unavailable for access from a current set of clients, for example, prior to importing the disk group at another client or clients), importing the disk group, etc. In some embodiments, a virtual device group  (such as a disk group) may include an internal virtual device (such as a logical block device) that maps each physical storage device managed as part of the virtual device group. Such internal virtual devices may not be accessible directly to storage consumers . A virtual device group  may also be formed from virtual storage devices in some embodiments. In some embodiments, a virtual device group may be explicitly named, while in other embodiments, a virtual device group may be identified simply by listing its constituent storage devices.","The configuration of a set of storage devices  (or ) as a virtual device group  may require each individual device to comply with a set of specifications in order to allow a virtual storage device  (or a volume ) formed from virtual device group  to provide the desired virtualization functionality. For example, in one embodiment, hardware snapshot-capable block devices may be used to provide frozen image functionality for a volume . Two types of hardware snapshot-capable block devices may be available in such an embodiment: a \u201csource\u201d hardware block device, and a \u201ctarget\u201d hardware block device. During a frozen image creation operation, source hardware block devices may be usable only for a particular kind of data transfer operation (e.g., reading the data), while target hardware block devices may be usable only for a different kind of data transfer operation (e.g., writing a copy of data read from a source hardware block device). Nevertheless, it may be possible to combine both source and target hardware block devices as part of a single virtual device group underlying a logical volume \u2014that is, the interfaces available to configure the two kinds of hardware devices may allow their combination within a single virtual device group. If source and target hardware block devices are inadvertently combined within a virtual device group  intended to be used as for a logical volume  that is a destination of a frozen image operation, and an attempt to create a frozen image onto the destination logical volume is later made without verifying that the hardware block devices are appropriately configured (i.e., that the destination virtual device group comprises only target hardware devices), data corruption may result. In addition, because of the presence of both types of hardware block devices within the destination virtual device group, configuration metadata for the target logical volume or frozen image may also be corrupted. Further details concerning the use of a virtual device group  in a manner that avoids such data and\/or metadata corruption, and the interactions between virtualization software  (or ) and virtual device groups , are provided below.","A volume  may differ from a block device interface implemented in a hardware device or that is accessed through a system disk driver, in that the latter block devices may not present a system-independent block device interface that can be opened for direct use by a consumer. Instead, a system-dependent disk driver may be required to access such block devices. In embodiments employing block virtualization, such a disk driver may be generally unaware of block virtualization and may in some instances present a barrier to using some virtualization techniques, whereas a volume  implementing various block virtualization features may be directly accessible by a consumer without the issues presented by such disk drivers.","In an environment employing block virtualization, block virtualization software  may be executable at a volume server , which may also be referred to as a volume coordinator or as a virtualization coordinator. A volume server  may be any device capable of executing block virtualization software , such as a server computer system, including one or more processors and one or more system memories. Further, storage consumer  may be hosted within a volume client , which may be any type of device capable of interacting with a given volume  for data storage and retrieval.","For example, in one embodiment a volume client may also be a server computer system, where the server system is configured to execute software such as one or more operating systems and\/or applications. In another embodiment, a volume client may be a client computer system configured to access a given volume via a separate server computer system.","In executing block virtualization software , a volume server  may create some number of virtualized block devices out of one or more physical or logical block devices. (In some embodiments, physical storage devices such as intelligent disk arrays and virtualization switches, described in more detail in conjunction with the descriptions of  and  below, may also be configured to perform block virtualization.) In one embodiment of block virtualization, one or more layers of software and\/or hardware rearrange blocks from one or more block devices, such as disks, and add various kinds of functions. The resulting rearranged collection of blocks may then be presented to a storage consumer , such as an application or a file system, as one or more aggregated devices with the appearance of one or more basic disk drives. That is, the more complex structure resulting from rearranging blocks and adding functionality may be presented as if it were one or more simple arrays of blocks, or logical block devices. It is noted that a virtualized block device may also be referred to as a logical block device, and that in some embodiments, multiple layers of block virtualization may be implemented. That is, one or more block devices may be mapped into a particular virtualized block device, which may be in turn mapped into still another virtualized block device, allowing complex storage functions to be implemented with simple block devices.","In various embodiments, block virtualization can support the creation of virtualized block devices implementing numerous different types of storage functions. For example, in one embodiment a virtualized block device may implement device striping, where data blocks may be distributed among multiple physical or logical block devices, and\/or device spanning, in which multiple physical or logical block devices may be joined to appear as a single large logical block device. In some embodiments, virtualized block devices may provide mirroring and other forms of redundant data storage, the ability to create a snapshot or frozen image of a particular block device at a point in time, and\/or the ability to replicate data blocks among storage systems connected through a network such as a local area network (LAN) or a wide area network (WAN), for example. Additionally, in some embodiments virtualized block devices may implement certain performance optimizations, such as load distribution, for example, and\/or various capabilities for online reorganization of virtual device structure, such as online data migration between devices. Block virtualization may provide any or all of these capabilities in a fashion transparent to virtualized block device consumers. That is, virtualized block devices may appear as generic storage devices to consumers such as file systems and applications.","A volume server  may provide functions such as configuration management of virtualized block devices and distributed coordination of block device virtualization. For example, in one embodiment volume server  may be aware of the type and quantity of physical storage devices, such as block devices , that are available within a storage system. In various embodiments, the virtualization functions provided by volume server  may be provided at different levels in the storage hierarchy between a storage consumer  and block devices .","For example, in one embodiment, volume clients  may be provided with a description of a virtualized block device and may be configured to directly access constituent block devices comprising the virtualized device. Such virtualization may also be referred to as host-based or client-based virtualization. In response to a request to configure a virtual block device, for example according to a desired set of virtualization features, volume server  may be configured to build a volume description that describes how a collection of storage objects compliant with the desired features maps to underlying physical block devices. The volume description identifying a particular volume  may be distributed to one or more volume clients . In one embodiment, such a volume description may be a tree of storage objects such as described in greater detail below in conjunction with the description of . Each volume client  may be configured to interact with volume server  for certain functions, for example management or administrative functions. For typical block read and write activity, each volume client  may be configured to interact directly with various block devices  according to the volume description distributed by volume server .","The structure of the volume , for example as indicated by its corresponding storage object tree, may indicate to a given volume client  how the volume relates to one or more underlying physical storage devices. In one embodiment, the leaf nodes of such a tree may correspond to one or more physical block devices such as block devices , and the root node of such a tree may be a logical block device through which the volume is accessed by a consumer. Distribution of a virtualized block device as a volume to one or more volume clients  may also be referred to as distributed block virtualization. In some embodiments, after volume server  has distributed a volume description of a given virtual block device to a given volume client  as a particular volume , the given volume client  may interact with that particular volume  to read and write blocks without further involvement on the part of volume server , as described above. That is, the given volume client  may use the structure of the particular volume  to transform I\/O requests generated by various consumers of that volume  into I\/O requests directed to specific physical storage devices, such as block devices .","In some embodiments, details of block virtualization may not be directly available to individual volume clients . In some such embodiments, the virtualization function of volume server  may be implemented in a device or layer of abstraction in between volume clients  and block devices , such as a switch or virtualization appliance. Such virtualization may also be referred to as switch-based or appliance-based virtualization.","Additionally, in some embodiments, multiple layers of virtualization may be employed, for example at the host level as well as at the switch or appliance level. In such embodiments, some aspects of virtualization may be visible to volume clients , as in the host-based model, while some aspects may be implemented transparently by an intermediate device, as in the switch-based model. Further, in some multilayer embodiments, the virtualization details of one block device (e.g., a given volume ) may be fully defined to a volume client  (i.e., without further virtualization at the switch layer), while the virtualization details of another block device (e.g., another volume) may be partially or entirely transparent to volume client .","One embodiment of a virtualized block device that may be presented to a volume client  as a volume is illustrated in . In the illustrated embodiment, virtualized block device  includes a volume block device  that includes logical block devices  and . In turn, logical block device  includes logical block devices  and , while logical block device  includes logical block device , thus providing three layers of virtualization. Logical devices ,  and  use virtual device group , which includes physical block devices of A-C to of .","Virtualized block device  may in its entirety represent the structure of the data comprising a given volume , which data may be physically stored in physical block devices A-C. Volume block device  may be configured to be mounted within a file system or presented to an application or other volume consumer as the interface through which the consumer may interact with given volume . Each block device that maps to or includes another block device may include an interface whereby the mapping or including block device may interact with the mapped or included device. For example, this interface may be a software interface whereby data and commands for block read and write operations is propagated from lower levels of the virtualization hierarchy to higher levels and vice versa.","Additionally, a given block device may be configured to map the logical block spaces of subordinate block devices into its logical block space in various ways in order to realize a particular virtualization function. For example, in one embodiment, virtualized block device  may be configured as a mirrored volume, in which a given data block written to virtualized storage device  is duplicated, and each of the multiple copies of the duplicated given data block are stored in respective block devices. In one such embodiment, volume block device  may be configured to receive an operation to write a data block from a consumer of corresponding volume . Volume block device  may duplicate the write operation and issue the write operation to both logical block devices  and , such that the block is written to both devices. In this context, logical block devices  and  may be referred to as mirror devices. In various embodiments, volume block device  may read a given data block stored in duplicate in logical block devices  and  by issuing a read operation to one mirror device or the other, for example by alternating devices or defaulting to a particular device. Alternatively, volume block device  may issue a read operation to multiple mirror devices and accept results from the fastest responder.","As described above and shown in , in some embodiments a virtualized block device  may employ multiple layers of virtualization. For example, in the embodiment described above where logical block devices  and  function as mirror devices, it may be the case that underlying physical block devices A-C have dissimilar performance characteristics; specifically, devices A-B may be slower than device C.","In order to balance the performance of the mirror devices, in one embodiment, logical block device  may be implemented as a striped device in which data is distributed between logical block devices  and . For example, even- and odd-numbered blocks of logical block device  may be mapped to logical block devices  and  respectively, each of which may be configured to map in turn to all or some portion of physical block devices A-B respectively. In such an embodiment, block read\/write throughput may be increased over a non-striped configuration, as logical block device  may be able to read or write two blocks concurrently instead of one. Numerous striping arrangements involving various distributions of blocks to logical block devices are possible and contemplated; such arrangements may be chosen to optimize for various data usage patterns such as predominantly sequential or random usage patterns.","In another aspect illustrating multiple layers of block virtualization, in one embodiment physical block device C may employ a different block size than logical block device . In such an embodiment, logical block device  may be configured to translate between the two physical block sizes and to map the logical block space defined by logical block device  to the physical block space defined by physical block device C. In some instances, the logical block space of logical block device  need not be contiguously mapped to blocks of physical block device C; an arbitrary mapping may be used.","Numerous other possible configurations of block devices are contemplated that may incorporate more or fewer layers of virtualization to realize within a given instance of virtualized block device  virtualization functions similar to or different from those described above. For example, volume block device  may employ a greater number of mirror devices, striping may occur higher in the hierarchy than mirroring, certain logical block devices may be configured to perform snapshots of other devices, certain logical block devices may span multiple physical block devices, etc. In another embodiment of a virtualization hierarchy, a set of virtual devices at a given layer of the hierarchy may be organized into a virtual device group, and managed as a unit by a virtual device at a higher layer in the hierarchy.","In one embodiment, volume server  may be configured to read and update configuration information corresponding to volume descriptions (such as a storage object tree corresponding to a given volume) from a configuration database (not shown), which may be implemented either within volume server  or external to it. The configuration information in the database may establish the logical configuration of data on the physical storage devices  (e.g., block devices A, B, and C). For example, such configuration information may indicate how various logical and physical block devices are divided, striped, mirrored, etc. In one embodiment, the configuration information may be stored on the devices (e.g., block devices A, B, and C) that are being virtualized. It is contemplated that in some embodiments, configuration of a given virtualized block device may be managed and\/or stored in data structures other than trees of objects. For example, in one embodiment, tables may be used to map virtual block devices to physical storage.","As noted above, the configuration associated with a virtual block device may change over time, such as to add or remove mirrors; migrate data to new storage; increase or decrease the size of the device; create, manipulate, or remove snapshots; add structure for a new capability; etc. In some embodiments, if the volume description of a given volume  is distributed to more than one volume client , any changes that affect the structure of the given volume  may need to be coherently coordinated among the relevant volume clients . In one embodiment volume server  may be configured to coordinate such changes. For example, volume server  may be configured to coordinate quiescence of those volume clients  to which the given volume  is distributed, in order to temporarily suspend activity to given volume . Volume server  may further distribute changes to the structure of given volume  to relevant volume clients  in an effectively atomic fashion, such that either all or none of the relevant clients  receive the changes.","In some embodiments, volume server  may be configured to distribute all defined volumes  to each volume client  present within a system. Such embodiments may be referred to as symmetric distributed block virtualization systems. In other embodiments, specific volumes  may be distributed only to respective volume clients , such that at least one volume  is not common to two volume clients . Such embodiments may be referred to as asymmetric distributed block virtualization systems.","As mentioned earlier, in contrast to block virtualization environments, in some embodiments, object-based virtualization may be employed: that is, virtualization software  may be configured to organize storage within storage devices  as higher-level logical objects (such as files) instead of using a more traditional block-based interface such as SCSI or IDE. Virtualization software  may be executable within an object storage device (OSD) in such an environment. In an object virtualization environment, virtual storage may be named, managed, and made accessible as a virtual device  using any desired base object as implemented by virtualization software , such as a file object or a database table object. Thus, in one embodiment, storage consumer  may be presented with a virtual storage device  consisting of a collection of named files, and may perform file-based operations (such as reads from a file, writes to a file, increasing the size of a file, truncating a file, etc.) directly on virtual storage device . Object-based virtualization may thus allow the offloading of functionality traditionally performed at a host computer system (such as the translation of a file name and offset within a file to a block device address) to a storage device such as an object storage device that may be optimized to perform the needed storage operations, freeing up resources at the host computers. In addition, once virtual objects have been created and configured, an object storage device may distribute information on the virtual objects in the form of a virtual object-based storage device  to storage consumer , allowing storage consumer  to perform input\/output (I\/O) operations on the virtual objects without further interaction with the object storage device. Thus, unlike some traditional file server implementations, object storage devices may not become bottlenecks under heavy I\/O loads on the managed virtual objects, thus contributing to an overall improvement in system performance. Also, an object storage device may provide storage consumers  with transparent access to virtual objects across different operating systems and hardware\/software platforms.","As stated earlier, storage devices  may be managed collectively as a virtual device group  in both block virtualization environments and object virtualization environments. In some embodiments, individual storage devices  that constitute a virtual device group  may need to meet certain requirements in order to support the virtualization functions provided by one or more virtual devices  that utilize the virtual device group. Prior to performing a proposed configuration operation, such as the addition of a new device  to a virtual device group , it may be desirable to verify that the resultant virtual device group configuration would support the desired virtualization functionality. For example, if a new device is to be added to a virtual device group for the purpose of forming an additional mirror of a mirrored volume containing an existing set of mirrors, it may be desirable to verify that the new device is large enough to store a copy of an existing mirror. In addition, in some storage environments, virtual devices may have associated Quality-Of-Service (QOS) specifications for performance and\/or availability. Such QOS specifications may, for example, require the virtual device vendor to guarantee (to within some specified statistical margin of variability) that an I\/O operation with specific characteristics (e.g., an operation to read of X bytes) performed on the virtual device will, on the average, complete within a specified period of time. QOS specifications for availability may require, for example, that a hardware storage device underlying the virtual device must have a Mean-Time-Between-Failures (MTBF) value of a specified number of days. In such environments, it may be possible to verify whether a specific storage device is capable of meeting the required QOS specification(s) using an interface specific to the storage device: for example, some hardware storage devices may provide a low-level device-specific interface to query whether the device is equipped with a set of redundant power supply units that may impact MTBF values. Performance data that may be used to verify whether a QOS specification may be met by a specific storage device may also be verifiable using a device-specific interface: e.g., by actually performing some I\/O operations on the device and measuring the time taken to complete the operations, or in some cases by querying a storage device for vendor-supplied performance data metrics such as typical and peak random I\/O throughput.","As shown in , a hierarchy of virtual devices may be built using a virtual device group, and different layers of a virtualization hierarchy may offer different virtualization features described earlier, such as mirroring, striping, frozen image operations, and the like. As stated earlier, virtual devices at a given layer of the virtualization hierarchy may be managed as a virtual device group by a virtual device at a higher layer. In some embodiments, virtualization features provided at one layer of a virtualization hierarchy may impose certain requirements on other layers of the same hierarchy, or even on a layer of a different hierarchy. For example, in order to accommodate a larger than expected amount of application data, it may be desired to add a new storage device to an existing virtual device group used by a multi-layered source volume (such as volume ) configured for frozen image creation. If the addition of the new storage device to the source logical volume is not accompanied by a corresponding addition of a second storage device to a virtual device group at a target volume where the frozen image is to be stored, it may not be possible to successfully complete a creation of a frozen image (i.e., not enough storage may be available on the target volume to create a complete frozen image of the source volume). In such an environment, it may be desirable to determine whether a proposed addition of a new storage device may have an adverse impact of the frozen image functionality, prior to expanding the virtual device group at the source volume. Similarly, a removal of a storage device from a virtual device group at the target frozen image volume may also prevent successful frozen image operations, and it may be desirable to verify that such a removal has no adverse consequences prior to removing the device. In another embodiment, one or more copy-on-write (COW) snapshots of a given storage device A may be maintained on other storage devices B-D at a given layer of a virtualization hierarchy. An inadvertent combination of storage device A and devices B-D into a single virtual device group (e.g., by a higher layer of the virtualization hierarchy) may lead to potential data loss or metadata corruption during a subsequent operation on the group, such as a use of the newly formed virtual device group as a snapshot target for a different snapshot source.","A complex storage environment may include hundreds or thousands of physical and virtual storage devices from different storage vendors arranged in numerous storage hierarchies, with different virtualization functions and QOS levels provided by different virtual devices. Each storage vendor may provide a different vendor-specific interface to configure and\/or query each kind of storage device: for example, a different interface may be provided for a disk array provided by a specific vendor than the interface provided by the same vendor for a single disk. In such an environment, it may be desired to simplify storage environment administration by using one (or a small number) of virtualization software products to manage the entire collection of storage, and it may also be desired to automate as much of storage configuration as possible. For example, a large database management system may be used in such a complex storage environment, and it may be a goal to allow the database management system to \u201cautomatically\u201d grow the amount of virtual storage used for its tables, indexes, logs etc. over time. The database management system may rely upon one or more layers of virtualization software  in order to accomplish this goal, which may require the automation of virtual device group enlargement (i.e., automatic discovery and addition of new storage devices to an existing virtual device group). In order to reduce complexity and increase maintainability of virtualization software , a device independent layer of virtualization software may be developed to help manage the organization of storage devices as virtual device groups, as shown in .",{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 4","b":["100","110","410","410","110","120","130","410","140","110","110"]},"In different embodiments, device-independent API  may be provided using one or more programming languages (such as C, C++, or Java), a scripting language (such as Perl, Tcl\/Tk, Python, C-Shell, Korn Shell, or Boume Shell), some other language suitable for interaction with virtualization software  and other client applications, or a combination of such languages. The execution of functions or methods from device-independent API  may result in the invocation of device-specific software modules provided as device-specific plugins , which implement the interfaces of API  and communicate directly with storage devices . Device-specific plugins  implementing the functionality required by device-independent API  may be provided by storage device  vendors in some embodiments, while in other embodiments they may be developed by vendors providing virtualization software .","In some embodiments, device-independent API  may also be exposed to and used by applications (such as storage consumer ) other than virtualization software . For example, a database management system may be configured to automatically expand storage as needed to accommodate growing data, and may use device-independent API  to verify that the addition of a specific storage device  to a virtual device group  would result in a valid configuration prior to expanding virtual device group .","Device-independent API  may include numerous functions, methods, or other interfaces that may be invoked to validate different virtual device group configuration operations in different embodiments. Each method or function may have an associated parameter indicative of the virtualization functions that need to be supported by the virtual device group and may be affected by the configuration operation; for example, such a parameter might indicate that the virtual device group may need to support a frozen image creation capability. Depending on the configuration operation whose validity is being checked, a function, method or interface of device-independent API  may also have associated parameters specifying the virtual device group , one or more storage devices  that may participate in the proposed configuration operation, and other parameters specific to the specific configuration operation. A function or method may also be provided to revalidate an existing configuration; for example, such a revalidation function may be used after a power outage and subsequent restart to verify that an existing virtual device group still meets a specified set of requirements.","In one embodiment, for example, group validation layer  may include the following device-independent interfaces, each of which is described in more detail below:\n\n","In each of the interfaces listed above, the virtualizationFlags parameter may be used to encode information regarding the specific virtualization functions (e.g., frozen image creation, import\/export, virtual RAID-5 functionality, etc.) and\/or QOS requirements to be implemented by virtual storage device . In some embodiments, a virtualizationFlags parameter or its equivalent may also be used to encode other information such as whether virtualization functionality is being implemented by a host-based volume manager, an intelligent disk array, a virtualization switch, or an object storage device, and to identify the client software (e.g., an application such as a database management system) invoking the function or method. A groupId parameter included in each interface may identify a virtual device group upon which a proposed configuration operation (or a configuration revalidation) may be performed. Virtual device group identification may also be implemented in some embodiments using an array or list explicitly enumerating the existing storage devices constituting the virtual device group instead of using a single identifier such as groupId. A deviceId parameter may be used in several of the listed interfaces to identify a specific storage device  involved in the proposed configuration operation. In one embodiment, the invocation of any of the listed interfaces may result in a coded result value being returned to the invoking entity (such as an application or a layer of virtualization software ), where the result value may represent either a successful validation, or an error code indicating that the proposed configuration operation may result in an invalid configuration. In some embodiments, an error code returned by a function or method implementing an interface may encode not just an identification of a potential error, but also a potential corrective action or actions that may need to be taken by the invoking entity to avoid the potential error. An example of such an error encoding is provided below.","As illustrated in  for one specific embodiment, a VerifyAddToGroup( ) interface may be used to validate a proposed addition of a storage device D to a virtual device group . Virtual device group  may include storage devices A-C prior to the proposed addition, as shown in the illustrated embodiment. In other embodiments, virtual device group  may be empty prior to the proposed addition; that is, the proposed configuration operation may be the initial formation of a virtual device group  including a single storage device . As described earlier, various characteristics of virtual device group , device D, and virtual storage device  may be taken into account when validating the proposed addition of a device to a virtual device group. For example, in some embodiments, QOS requirements associated with virtual storage device  may affect the validity of the proposed addition operation. In other embodiments, virtual device group  may be constrained to include only storage devices  that conform to a specific version of a storage management standard specification or a communication protocol specification. In embodiments supporting frozen image operations using hardware source and target snapshot-capable storage devices, a VerifyAddToGroup( ) interface may be used to prevent the inadvertent mingling of source and target devices within a virtual device group . Similarly, in an embodiment where copy-on-write (COW) snapshots of device A may be maintained on devices B-D, as described earlier, a VerifyAddToGroup( ) interface may also be used to prevent a combination of devices B-D with device A within a single virtual device group. As stated above, an error code returned by a method or function implementing the VerifyAddToGroup( )interface may identify the source of a potential invalid configuration and provide suggested corrective actions: e.g., the error code returned may be translatable to an error message such as \u201cConfiguration Invalid: Attempt to add incompatible hardware snapshot target device to virtual device group consisting of hardware snapshot sources; retry using a hardware snapshot source device\u201d.",{"@attributes":{"id":"p-0066","num":"0073"},"figref":"FIG. 6","b":["120","130","120","130","140","120","120","140","120","120","140","120","140","120"]},"As described previously, a device-independent interface of API  may also be used to revalidate an existing configuration, for example subsequent to a power outage followed by a restart of a set of hosts and storage devices. Interface VerifyExistingConfiguration( ) may be used to accomplish this functionality. In some embodiments employing a hierarchy of virtualization such as storage device  of , a function or method implementing the VerifyExistingConfiguration( ) interface may also be used to traverse the virtualization hierarchy to verify whether the hierarchy is correctly configured for one or more virtualization operations such as a frozen image operation. In some embodiments, the virtualization hierarchy may already be organized as virtual device groups prior to a traversal, e.g., the storage devices at each layer of the hierarchy may be organized as one or more virtual device groups accessible to a storage device at a higher layer. In other embodiments, in traversing the virtualization hierarchy for configuration verification, each virtual storage device (such as ) that is built upon a set of lower-level virtual storage devices (e.g.,  and ) may form a temporary or permanent virtual device group out of the set of constituent lower-level devices. Thus, when traversing the hierarchy of , a first invocation of VerifyExistingConfiguration( ) may be used to verify that devices  and  form a valid virtual device group to support the virtualization features provided by device . A second invocation of VerifyExistingConfiguration( ) may be used to verify that devices  and  form a valid virtual device group to support the virtualization features supported by device , and so on. In some embodiments, such a traversal of a virtualization hierarchy may be performed using software (e.g., a configuration verification tool) that is configured to retain the results of the configuration verification for each storage device in the hierarchy, and to combine the results for all the storage devices in the hierarchy into a single report. Such a combined report for a complex virtualization hierarchy may in some cases provide a system administrator with an indication of a suboptimal hierarchy. For example, a higher level of a virtual hierarchy may be configured as a virtual RAID-5 array, while a lower level of the hierarchy may utilize devices implementing RAID-5 in hardware. Thus, duplicated virtualization functionality may be detected using multiple invocations of VerifyExistingConfiguration( ) ina traversal of a virtualization hierarchy, allowing a system administrator or an automated administration tool to reorganize the virtual hierarchy more optimally.","The VerifyChangeDeviceConfiguration( ) interface may be used to validate a proposed change to the configuration of a particular device  within a virtual device group . The VerifyChangeDeviceConfiguration( ) may include a configurationChange parameter identifying the specific type of configuration change proposed on a storage device. For example, a proposed configuration change may modify the size or internal organization of a cache of a specific storage device , or may make part or all of a storage device  read-only, i.e., future writes may be disallowed to the storage device. Such changes at a particular storage device  may also affect the ability of virtual storage device  to provide desired virtualization functionality, even if all other storage devices  remain unchanged.",{"@attributes":{"id":"p-0069","num":"0076"},"figref":"FIG. 7","b":["130","705","240","705","240","130","705","130","705","120","130","130","120","130","705","710","240","705","120","130"]},"The VerifyGroupImportableAtLocation( ) interface may be used in a storage environment where techniques such as zoning and\/or LUN masking may be used to restrict access from various hosts to specific storage devices. A storage address (such as a world-wide-name or WWN) may be associated with each host in such an environment. Prior to importing a virtual device group at a target host with a specific storage address (specified by a storageAddress parameter), the VerifyGroupImportableAtLocation( ) interface may be used to verify that devices within the specified virtual device group are visible at the target host.","The VerifyGroupDestroyable( ) interface may be used to verify that a virtual device group  may be disassembled (i.e., whether its constituent storage devices  may be distributed for use either individually or as part of other virtual device groups) without impacting virtualization functionality currently being provided.","It is noted that the set of interfaces listed above may be extended and modified in various ways in different embodiments to provide the desired functionality. For example, the VerifyAddToGroup( ) and VerifyRemoveFromGroup( ) interfaces may be extended to include the verification of the addition or removal of a set of storage devices  rather than a single storage device (e.g., by including an array parameter deviceIdArray[ ] instead of the single deviceId parameter described above). One or more interface parameters may not be used in some embodiments\u2014for example, the virtualizationFlags parameter may not be used in a storage environment where the virtualization features supported are implicit.","Functionality similar to that provided by the interfaces described above for one embodiment may be provided by using a different device-independent API , for example using a different convention for specifying interfaces and parameters in another embodiment. Interfaces providing additional functionality for verification of proposed changes to virtual device group configurations and\/or existing virtual device group configurations, beyond the functionality listed above, may be used in some embodiments. For example, additional interfaces may be added to restrict access to one or more storage devices or virtual device groups, or to set or verify attributes of a virtual device group. One or more attributes could be used to identify a virtual device group as appropriate for a failover in a clustered environment, as being shared across nodes of a cluster, or as being capable of being used as part of a snapshot operation. In other embodiments, device independent API  may not provide some of the functionality described for the listed interfaces.","Virtualization software  and device-independent API  may be used to provide the functionality described above in a variety of different configurations of system . In one embodiment, storage devices  may all be attached to a single computer host. Virtualization software  may be configured to execute on the same computer host, and virtual storage device  may be made accessible to a storage consumer  utilizing the same computer host. In another embodiment, various components of system  may be distributed among the nodes of a cluster, as illustrated in .","In the embodiment illustrated in , three nodes forming a cluster may be coupled to a network . Storage device A may be attached to Node , storage devices B and C may be attached to Node , and storage device D may be attached to Node . Virtualization software  may be executable on Node . Device-independent API  may be used by virtualization software  to manage storage devices A-C as a virtual device group . Storage within devices A-C may be aggregated into logical volume  by virtualization software , and may be made accessible to storage consumers A on Node  and B on Node . As illustrated, the storage devices  constituting virtual device group  may each be attached to one node of the cluster, while the virtual device group  and a virtual storage device such as volume  utilizing virtual device group  may be accessible from multiple nodes. A node such as Node  may have a storage device D attached to it that does not form part of any virtual device group, while an application executing on the node (such as storage consumer B) may have access to virtual device group  formed from storage devices A-C that are not attached to the node. In another embodiment, a virtual device group may also be formed using storage devices that are shared across multiple nodes of a cluster. In general, device-independent API  may be executable at any suitable node of a cluster, and it may be used to validate configuration operations on storage devices and virtual device groups that may be distributed in arbitrary configurations across the nodes of a cluster. In addition, configuration software  may make virtual device groups and virtual storage devices using the virtual device groups accessible from any combination of nodes in a cluster.","Virtualization software  may be incorporated within different platforms in different embodiments. In one embodiment, virtualization software  may form part of a volume manager that provides virtualization using system software running on host computers. In other embodiments, part or all of virtualization software  may also be provided by migrating some virtualization functions from host computers into one or more separate entities such as an intelligent disk array as depicted in , a virtualization switch as depicted in , or an object storage device (OSD) as depicted in .",{"@attributes":{"id":"p-0077","num":"0084"},"figref":"FIG. 9","b":["900","110","900","975","980","980","900","960","970","900","900","920","110","910","930","940","950","975","960","910","980","900","900"]},"Intelligent disk array  may represent an example of a block server appliance, where specialized hardware may be used to provide virtualization functionality, as described above. Block server appliances may also be provided in some embodiments using block server appliance software running on off-the-shelf computers and commodity disks, rather than using vendor-proprietary hardware and software. For example, the intelligent disk array functions described above may be implemented by specialized software running on a general-purpose computer.","Another method of providing virtualization, using a virtualization switch, is illustrated in  for one embodiment. Virtualization switch  may be connected to a number of computer hosts A-D through a number of host ports , and to a number of different storage devices such as disk arrays A and B containing physical disks A-E. The physical disks contained within a particular disk array  may be managed collectively as a virtual device group . In the illustrated embodiment, hosts  may communicate with virtualization switch  via host ports  using the Internet Protocol (IP). Virtualization switch  may be configured to communicate with different storage devices (such as disk arrays ) through a number of storage ports  using different storage network protocols: for example, it may communicate with disk array A using a fiber-channel connection, and with another disk array B using an iSCSI connection. In the embodiment shown, an I\/O request from an application running on a host  may be converted to one or more SCSI commands and\/or data encapsulated within one or more IP packets and sent to virtualization switch . Switch processor  and switch memory (RAM)  may be used to execute and store virtualization software , respectively. Switch processor  and switch memory  may also be used to collect and recombine the contents of the IP packets and translate them into one or more I\/O requests to one or more disk arrays . Disk arrays A and B may, in some embodiments, be intelligent disk arrays providing the same general functionality as described above for . The use of IP may allow the use of geographically distributed networks (e.g., Metropolitan Area Networks or MANs, Wide Area Networks or WANs, and\/or the Internet) for connections between computer hosts  and storage devices using virtualization switch . In some embodiments, virtualization switches may provide logical volume functionality to hosts , while in others embodiments, a logical volume may be provided by a volume manager running on a host , using virtual storage devices provided by a virtualization switch .",{"@attributes":{"id":"p-0080","num":"0087"},"figref":["FIG. 11","FIG. 1"],"b":["1150","1150","1150","1110","110","1120","110","1150","1160","1150","1160","130","1160","1101","1170","1170","1155","1150","1150","1160","1150"]},"It is noted that various combinations of the different virtualization techniques described above may be employed within different embodiments of system . For example, in one embodiment, a single storage environment may employ host-based volume managers, intelligent disk arrays, virtualization switches, object storage devices, and other virtualization mechanisms, some of which may be combined to provide a hierarchy of virtual storage devices configured to provide different kinds of virtualization functionality. Device-independent API  may be usable in managing a variety of storage devices as virtual device groups within such a storage environment. It is also noted that the use of device-independent API  is not limited to the specific virtualization techniques described herein; rather, device-independent API  may be used in any virtualization environment where storage devices are managed as virtual device groups. It is also noted that membership requirements for virtual device groups may vary in different embodiments and for different virtualization functions. In some embodiments, for example, the requirements may be fairly restrictive (e.g., that all disks within an intelligent disk array are provided by the same manufacturer and have the same part number), while in other environments, the requirements may be less restrictive (e.g., that all disks within a storage array have a redundant power supply unit).","In different embodiments, virtualization software  may be provided to a computer system using a variety of computer-readable storage media including electronic storage media (e.g., flash memory), magnetic storage media such as RAM (e.g., SDRAM, RDRAM, SRAM, etc.), optical storage media such as CD-ROM, etc. In various embodiments, virtualization software  may be provided to a computer system using transmission media or signals such as electrical, electromagnetic or digital signals, conveyed via a communication medium such as a network and\/or a wireless link.","Although the embodiments above have been described in considerable detail, numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 4","FIG. 1"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 8","FIG. 1"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 9","FIG. 1"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 10","FIG. 1"]},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 11","FIG. 1"]}]},"DETDESC":[{},{}]}
