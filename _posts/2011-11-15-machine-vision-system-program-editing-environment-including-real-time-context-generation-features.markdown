---
title: Machine vision system program editing environment including real time context generation features
abstract: A machine vision system program editing environment includes near real time context generation. Rather than requiring execution of all preceding instructions of a part program in order to generate a realistic context for subsequent edits, surrogate data operations using previously saved data replace execution of certain sets of instructions. The surrogate data may be saved during the actual execution of operations that are recorded in a part program. An edit mode of execution substitutes that data as a surrogate for executing the operations that would otherwise generate that data. Significant time savings may be achieved for context generation, such that editing occurs within an operating context which may be repeatedly refreshed for accuracy in near real time. This supports convenient program modification by relatively unskilled users, using the native user interface of the machine vision system, rather than difficult to use text-based or graphical object-based editing environments.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08957960&OS=08957960&RS=08957960
owner: Mitutoyo Corporation
number: 08957960
owner_city: Kawasaki-shi
owner_country: JP
publication_date: 20111115
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The invention relates generally to machine vision inspection systems, and more particularly to methods for creating and editing part programs in such systems.","Precision machine vision inspection systems (or \u201cvision systems\u201d for short) can be utilized to obtain precise dimensional measurements of inspected objects and to inspect various other object characteristics. Such systems may include a computer, a camera and optical system, and a precision stage that is movable in multiple directions so as to allow the camera to scan the features of a workpiece that is being inspected. One exemplary prior art system that is commercially available is the QUICK VISION\u00ae series of PC-based vision systems and QVPAK\u00ae software available from Mitutoyo America Corporation (MAC), located in Aurora, Ill. The features and operation of the QUICK VISION\u00ae series of vision systems and the QVPAK\u00ae software are generally described, for example, in the 3, published January 2003, and the 3, published September 1996, each of which is hereby incorporated by reference in their entirety. This product, as exemplified by the QV-302 Pro model, for example, is able to use a microscope-type optical system to provide images of a workpiece at various magnifications, and move the stage as necessary to traverse the workpiece surface beyond the limits of any single video image. A single video image typically encompasses only a portion of the workpiece being observed or inspected, given the desired magnification, measurement resolution, and physical size limitations of such systems.","Machine vision inspection systems generally utilize automated video inspection. U.S. Pat. No. 6,542,180 teaches various aspects of such automated video inspection and is incorporated herein by reference in its entirety. As taught in the '180 patent, automated video inspection metrology instruments generally have a programming capability that allows an automatic inspection event sequence to be defined by the user for each particular workpiece configuration. This can be implemented by text-based programming, for example, or through a recording mode which progressively \u201clearns\u201d the inspection event sequence by storing a sequence of machine control instructions corresponding to a sequence of inspection operations performed by a user with the aid of a graphical user interface, or through a combination of both methods. Such a recording mode is often referred to as \u201clearn mode\u201d or \u201ctraining mode.\u201d Once the inspection event sequence is defined in \u201clearn mode,\u201d such a sequence can then be used to automatically acquire (and additionally analyze or inspect) images of a workpiece during \u201crun mode.\u201d","Video tools (or \u201ctools\u201d for short) and other graphical user interface features may be used manually to accomplish manual inspection and\/or machine control operations (in \u201cmanual mode\u201d). Their set-up parameters and operation can also be recorded during learn mode, in order to create automatic inspection programs, or \u201cpart programs.\u201d Video tools may include, for example, edge\/boundary detection tools, autofocus tools, shape or pattern matching tools, dimension measuring tools, and the like. Other graphical user interface features may include dialog boxes related to data analysis, step and repeat loop programming, and the like. For example, such tools are routinely used in a variety of commercially available machine vision inspection systems, such as the QUICK VISION\u00ae series of vision systems and the associated QVPAK\u00ae software, discussed above.","The machine control instructions including the specific inspection event sequence (i.e., how to acquire each image and how to analyze\/inspect each acquired image) are generally stored as a \u201cpart program\u201d or \u201cworkpiece program\u201d that is specific to the particular workpiece configuration. For example, a part program defines how to acquire each image, such as how to position the camera relative to the workpiece, at what lighting level, at what magnification level, etc. Further, the part program defines how to analyze\/inspect an acquired image, for example, by using one or more video tools such as edge\/boundary detection video tools.","Editing a part program for a machine vision inspection system is a more complex task than editing a program for a machine tool or assembly robot or the like. For example, part programs for machine vision inspection systems include later portions that control operations and\/or provide image-dependent measurement results that depend at least partially on the results determined by the execution of a previous portion of the program and\/or on the particular instance of a workpiece that is being used to provide the images that are essential to the inspection operations. Furthermore, the required lighting and\/or exposure time required for a particular image may depend on a particular instance of a workpiece. Furthermore, if a user saves a partially completed part program and recalls the part program at a later time to alter or finish the programming, it may be unknown if certain types of changes have occurred in the interim (e.g., changes in environmental conditions, the part being inadvertently moved on the stage, etc.) that may adversely affect the continuing edits to the part program. Due to such concerns, it has been a standard practice for some such systems to actually execute all of the instructions of a part program from the beginning, up to, and including any potential additional modifications or additions to the part program instructions, in order to verify that the modifications and\/or additions are being programmed based on a realistic set of conditions for their operation. However, the execution of all of the instructions of a part program to provide a realistic operating condition for modifications or additions to the instructions is impractical for a large part program (e.g., those including a large number of image acquisitions, and\/or feature inspections), which is particularly common for machine vision inspection systems that provide microscopic inspection (e.g., micron resolution measurements) on macroscopic objects (e.g., objects spanning tens or hundreds of millimeters). A need exists for an editing environment that can reliably update operating conditions in a short time (e.g., nearly \u201creal time\u201d) during editing operations and to allow more rapid, efficient, intuitive, and flexible and robust creation and editing of part programs for precision machine vision inspection systems.","This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter.","According to the considerations outlined above, it would be desirable for a machine vision inspection system to provide near real time updates to the operating context when editing a part program, in order to verify that, at the time modifications and\/or additions are programmed, a realistic set of operating conditions are available as the basis or context for the modifications and\/or additions. This is particularly important when the part program is created and edited by recording actual control operations input by a user of the machine vision inspection system, in that the user is intuitively selecting the details of their input operations based on the state of the machine vision inspection system and\/or the appearance and location of the images that are present at the time that they are providing their input operations, and so on. Thus, the user cannot begin a valid and reliable modification of a part program at an arbitrary location in the part program, without first establishing the system in substantially the same operating context at that location as would be provided by the execution of the previous instructions of the part program during their automatic mode of execution during run mode. Heretofore, no general purpose machine vision inspection system, and particularly no system which records actual user controlled operations in order to create a part program (e.g., as opposed to simple graphical object or text-based programming systems), have provided an editing environment which reliably and robustly provides a valid part programming editing context in near real time, during editing operations.","In order to support this desirable editing environment, a machine vision system program editing environment including real time context generation features is disclosed herein. The machine vision inspection system includes an imaging portion, a stage for holding one or more workpieces in a field of view (FOV) of the imaging portion, a control portion, a display, and a user interface.","In various embodiments, the machine vision inspection system further comprises a run mode, a learn mode, and an editing portion. The run mode is operable to execute a previously-created part program using a run mode of execution. The learn mode is operable to receive user input to control operations of the machine vision inspection system and record part program instructions corresponding to the controlled operations in order to create a part program. The learn mode also includes an editing user interface comprising an editable part program representation of part program instructions, wherein the part program representation comprises instruction representations. The editing portion is operable to edit a part program and includes an editing execution portion operable to execute previously recorded part program instructions according to an edit mode of execution that is different than the run mode of execution.","In various embodiments, the learn mode is configured such that it is further operable to automatically record respective surrogate data which is associated with a respective set of recorded part program instructions, wherein at least some of the surrogate data includes data which results from actual control operations corresponding to the associated set of recorded instructions. In addition, the edit mode of execution includes a surrogate execution mode. During the surrogate execution mode, for at least one set of part program instructions, if respective surrogate data has been previously recorded in association with that set of part program instructions, then at least some members of that set of part program instructions are not executed. In other words, the corresponding associated actual control operations are not executed, and the respective surrogate data is used in the subsequent operation of the surrogate execution mode as a substitute for data that would otherwise result from those actual control operations which are not executed.","In various embodiments, creating a part program may comprise modifying a previously recorded part program instruction.","In various embodiments, respective surrogate data may comprise data which results from actual execution of controlled operations that are controlled based on received user input, and those controlled operations are recorded to provide the associated respective set of recorded part program instructions.","In various embodiments, the edit mode of execution comprises an actual execution mode, and at least some respective surrogate data comprises data which results from actual execution of controlled operations that are controlled based on executing a previously recorded associated respective set of recorded part program instructions using the actual execution mode.","In various embodiments, the machine vision inspection system may comprise a program status managing portion that is operable to save the recorded part program instructions in an editable part program file, and when the recorded part program instructions are saved as an editable part program file, respective surrogate data which is associated with a respective set of recorded part program instructions in the editable part program file are also saved. In some embodiments, the machine vision inspection system is operable to load the saved editable part program file for editing, and the machine vision inspection system is configured such that when the saved editable part program file is loaded for editing, the associated saved respective surrogate data are automatically made available for use in the surrogate execution mode. In one implementation, the program status managing portion is further operable to save the recorded part program instructions in a protected part program file that is executable using the run mode of execution, wherein at least one of the run mode of execution and the protected part program file is configured such that the results of the run mode of execution are not affected by any previously recorded surrogate data corresponding to the protected part program file. In some embodiments, the learn mode is configured to record in a respective set of recorded part program instructions an indication of whether respective surrogate data has been previously recorded in association with that respective set of part program instructions, and the program status managing portion is configured to remove indications of whether respective surrogate data has been previously recorded in association with a respective set of part program instructions, prior to saving the recorded part program instructions in the protected part program file.","In various embodiments, the learn mode may be configured to record in a respective set of recorded part program instructions an indication of whether respective surrogate data has been previously recorded in association with that respective set of part program instructions. In one embodiment, the indication is included in an initial instruction of the respective set of recorded part program instructions. In one embodiment, the respective set of recorded part program instructions may comprise instructions written in a mark-up language (e.g., XML, or a derivative thereof). In various embodiments, the respective set of recorded part program instructions may comprise at least one of an element, a parent element, a container element, and a child element written in the mark-up language. In one embodiment, the indication may comprise the presence of respective surrogate data included within that respective set of recorded part program instructions. In one embodiment, the indication may comprise a respective identifier included within that respective set of recorded part program instructions, the respective identifier usable to locate the corresponding respective surrogate data in a surrogate data memory portion of the machine vision inspection system.","In various embodiments, the editing portion comprises editing commands usable to edit a part program, and the editing execution portion is configured such that when the user uses the editing user interface to input an editing command to edit the program at a target location indicated in the part program representation, then the edit mode of execution begins at a valid context starting location in the part program prior to the target location, and uses the surrogate execution mode for executing at least a portion of the part program instructions, in order to establish a valid context for editing the part program at the target location.","In various embodiments an input editing command may be a command for modifying a part program at the target location, and the part program instruction located at the target location may be a previously recorded part program instruction that is to be modified. In one embodiment, the input editing command may be a command for inserting or appending instructions into the part program at the target location, and the part program instruction located at the target location may be a part program instruction that is to be created and inserted or appended at the target location. In one embodiment, establishing the valid context at the target location includes establishing the hardware state of the machine vision inspection system in an expected or proper state for executing control operations corresponding to a part program instruction located at the target location. In one embodiment, the valid context starting location in the part program comprises one of (a) the beginning of the part program instructions and (b) the next instruction after a previously executed editing initialization block comprising part program instructions. Such an editing initialization block is disclosed in \u201cSystem and Method Utilizing An Editing Initialization Block In A Part Program Editing Environment In A Machine Vision System\u201d (Ser. No. 13\/297,182) which is filed concurrently herewith, and hereby incorporated herein by reference. In order to further clarify the meaning of a \u201cvalid context\u201d starting location in a part program, by way of example and not by way of limitation, it means that execution of the part program can begin at that particular location with the machine vision inspection in an expected or proper state for executing the next control operation and\/or corresponding part program instruction at or following that particular location. By way of example and not by way of limitation, another type of valid context starting location may in some instances be immediately preceding an executable set of part program instructions which include a complete set of previously stored system software and hardware state parameters or variables corresponding to that location in the part program instructions, wherein that set of part program instructions can then be executed to establish or reestablish an operationally equivalent software and hardware state at that location of the part program instructions. Another type of valid context starting location may in some instances be immediately after the stopping location of actually executing the part program instructions after beginning from a valid context starting location. Another type of valid context starting location may in some instances be immediately after the stopping location of executing the part program instructions in surrogate execution mode, as disclosed herein, after beginning from a valid context starting location.","In one embodiment, the learn mode is configured such that when the edit execution mode establishes a valid context at a target location, the learn mode user interface is configured to display learn mode user interface elements that are operable by a user to edit and insert part program instructions at the target location, and those learn mode user interface elements comprise video tool selection elements. In one embodiment, the learn mode is configured such that when the valid context is established at the target location, the learn mode user interface is configured to display a context status indicator proximate to the indication of the target location indicated in the part program representation, and the context status indicator is set to indicate that a valid context has been established at the target location. In one embodiment, the learn mode is configured such that when the edit mode of execution uses the surrogate execution mode for executing at least a portion of the part program instructions in order to establish the valid context, then the state of the context status indicator is set to a state that specifically indicates that surrogate execution mode has been used to establish the valid context. In one embodiment, the context status indicator is an instruction pointer included proximate to the editable part program representation. In one embodiment, the edit mode of execution comprises an actual execution mode which provides actual execution of controlled operations that are controlled based on executing a previously recorded set of part program instructions, and the editing user interface includes a control operable by the user to use the actual execution mode for executing a set of part program instructions that are sufficient to establish a valid context for editing the part program at a target location. In one embodiment, the learn mode is configured such that when the edit mode of execution uses exclusively the actual execution mode for executing the part program instructions that are sufficient to establish the valid context, then the context status indicator is set to a state that specifically indicates that actual execution mode has been used to establish the valid context. In one embodiment, the learn mode is configured such that when a valid context has not been established at the target location, then the state of the context status indicator is set to indicate that the context is at least one of unknown or not valid. In one embodiment, the edit mode of execution by default automatically begins at the valid context starting location. In one embodiment, the edit mode of execution by default automatically uses the surrogate execution mode for executing at least a portion of the part program instructions. In one embodiment, the edit mode of execution comprises an actual execution mode which provides actual execution of controlled operations that are controlled based on executing a previously recorded set of part program instructions, and when the target location is represented within a target parent element represented in the editable part program representation, then surrogate execution mode comprises switching to the actual execution mode at a starting location of part program instructions corresponding to the target parent element. In one embodiment, the target location comprises an instruction that controls an operation corresponding to a video tool that analyzes an acquired image, and the target parent element comprises an instruction that controls an operation of the machine vision inspection system in order to set up the image acquisition conditions for the acquired image. In one embodiment, the edit mode of execution comprises an actual execution mode which provides actual execution of controlled operations that are controlled based on executing a previously recorded set of part program instructions, and surrogate execution mode comprises switching to actual execution mode of part program instructions for instructions that unconditionally require physical system changes in order to establish the valid context. In one embodiment, the edit mode of execution comprises an actual execution mode which provides actual execution of controlled operations that are controlled based on executing a previously recorded set of part program instructions, and surrogate execution mode comprises switching to actual execution mode for a set of part program instructions which provide results data during run mode execution and for which the corresponding surrogate data is not currently recorded for use as a substitute for the results data that would otherwise result from their associated controlled operations. In one embodiment, the edit mode of execution comprises an actual execution mode which provides actual execution of controlled operations that are controlled based on executing a previously recorded set of part program instructions, and surrogate execution mode comprises switching to actual execution mode for at least some part program instructions that control operations that change the physical location of the stage relative to the imaging portion, and the learn mode user interface comprises a query box that asks if the user approves of actual execution mode operations comprising moving the physical location stage prior to the actual execution of that move.","In various embodiments, the edit mode of execution is configured such that, when at least one of the previously recorded part program instructions is modified to provide a modified part program instruction using editing commands, and the modified part program instruction is accepted for recording in the part program, the associated control operations are actually executed and the associated surrogate data is generated and saved. In one embodiment, the surrogate data is derived from analysis of workpiece images of an actual workpiece positioned on the stage, wherein the images are acquired during a period corresponding to the modification and recording of the modified part program instruction.","In various embodiments, the set of part program instructions includes instructions that perform image acquisition operations and an edge detection video tool comprising edge detection operations that identify the edge point positions of points located along a detected edge in that acquired image, if executed, and the surrogate data comprises edge point positions. In one embodiment, during the surrogate execution mode, at least the image acquisition operations and the edge detection operations are not executed.","In various embodiments, the machine vision inspection system is a software emulator of an actual machine vision inspection system that emulates the controlled hardware of that actual machine vision inspection system such that it supports virtual operation by part program instructions usable on the actual machine vision inspection system, and by controlled operations input by the user through the user interface of the machine vision inspection system. In one embodiment, the workpiece comprises a workpiece data configured to provide a virtual workpiece that operates in conjunction with the software emulator of the actual machine vision inspection system.","In some embodiments, the learn mode comprises a learn mode user interface including a results window that displays results due to the execution of part program instructions, and learn mode is configured such that when the particular results are surrogate data results based on using the surrogate execution mode for execution of part program instructions, then the learn mode user interface is configured to display a results status indicator proximate to the surrogate data results, and the results status indicator is set to indicate that those particular results are based on surrogate data. In one embodiment, the results window may appear approximately as disclosed in a patent applications entitled \u201cMachine Vision System Program Editing Environment Including Synchronized User Interface Features\u201d (61\/560,278); which is filed concurrently herewith and hereby incorporated by reference. In various embodiments, each time a result is based on surrogate data and is displayed in the results window, the results status indicator comprises representing that surrogate data-based result with a particular color of text, or a particular color of highlighting on that text, or the like.","With regard to context, in order to further clarify the meaning of a \u201ccontext\u201d or operating context in relation to an editing environment, by way of explanation and not by way of limitation, when continuing edits are being made to a part program in a user interface, it is desirable to know and implement particular parameters at particular editing locations in the part program. For example, in order to set the correct thresholds, size and location for a video tool, it is necessary to have the expected video image including information such as the correct stage position, light levels, magnification, etc. In one embodiment, the \u201chardware context\u201d may be defined as comprising this type of information. In addition, in order to know if a sequence is correct for continuing edits to the part program, it is useful to know what has been done already, including what features have been measured, what part of the coordinate system is being utilized, etc. In one embodiment, the \u201csoftware context\u201d may be defined as comprising this type of information. It will be appreciated that, according to various features outlined above and disclosed herein, accurate context may be provided as a part program is initially recorded, and also, later, during the run mode, in a circumstance where all of the instructions have been executed in order. This provides a valid context for continuing edits to the part program, including indicating any measurements and results already produced by the part program.","It should be appreciated that providing a simple, time-efficient and robust editing environment for machine vision part programs is significantly more difficult than providing an adequate editing environment for editing simple computer programs, because potentially dangerous motions and mechanical collisions must be revealed and considered during the program editing process. In addition, providing a simple, time-efficient and robust editing environment for editing machine vision part programs is significantly more difficult than providing an adequate editing environment for editing assembly robot programs and the like (e.g., programs which control a robot's geometric motions and actuators, and the like), because unique workpiece geometries and surface finishes require that unpredictable and subtle lighting and imaging effects be revealed and considered and customized during the program editing process. In addition, machine vision inspection systems are required to perform operations that determine relationships between features that are measured and inspected at different locations on a workpiece and at different points in time, by respective operations that may be dispersed throughout a part program. Thus, providing a robust editing environment that allows a relatively unskilled user to edit an existing part program beginning at an arbitrary point within the program is a difficult task. It should be appreciated based on the disclosure herein that the surrogate execution mode and methods disclosed herein are of particular utility in contributing to a solution to the combination of problems outlined above (e.g., the need to provide for rapid execution to establish context for editing, etc.), which are unique to providing a time-efficient and robust editing environment for part programs for a general purpose machine vision inspection system.","The methods of the present invention are advantageous, in that when editing a part program, rather than requiring execution of all preceding instructions of a part program in order to generate a realistic context for subsequent edits, surrogate data operations using previously saved data replace execution of certain sets of instructions. The surrogate data may be saved during the actual execution of operations that are recorded in a part program. The edit mode of execution disclosed herein substitutes that data as a surrogate for executing the operations that would otherwise generate that data through time-consuming operations. Significant time savings may be achieved for context generation, such that editing may occur within an operating context which may be repeatedly refreshed for accuracy in near real time. This supports convenient program modification by relatively unskilled users, using the native user interface of the machine vision system, rather than using a difficult-to-use text-based or graphical object-based editing environment without experiencing a reliably realistic operating context.","It should be noted that the surrogate execution mode disclosed herein differs from previously known simulation methods used for creating and editing various types of programs, in that execution of various operations is not merely simulated (e.g., using a simulated workpiece, or the like), but is actually suppressed\u2014using the surrogate data in place of actual execution. Furthermore, the surrogate data may be exceptionally realistic, since it may be result from actual inspection operations on an actual workpiece in various embodiments. This is particularly advantageous, and even necessary, for some machine vision inspection systems. The methods disclosed herein may provide a particularly fast and particularly realistic and accurate editing environment, which is uniquely required and uniquely suited to machine vision inspection systems.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 1","b":["10","10","12","14","14","16","18","22","24","26","16","10"]},"The vision measuring machine  includes a moveable workpiece stage  and an optical imaging system  which may include a zoom lens or interchangeable lenses. The zoom lens or interchangeable lenses generally provide various magnifications for the images provided by the optical imaging system . The machine vision inspection system  is generally comparable to the QUICK VISION\u00ae series of vision systems and the QVPAK\u00ae software discussed above, and similar state-of-the-art commercially available precision machine vision inspection systems. The machine vision inspection system  is also described in commonly assigned U.S. Pat. Nos. 7,454,053 and 7,324,682, and U.S. Patent Publication Nos. 2010\/0158343 and 2011\/0103679, which are each incorporated herein by reference in their entireties.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIGS. 2A and 2B","FIG. 1","FIG. 2A"],"b":["120","200","100","120","200","200","205","220","230","240","210","212","210","20","205","260","250","280","286","288","205","294"]},"A workpiece , or a tray or fixture holding a plurality of workpieces , which is to be imaged using the machine vision inspection system  is placed on the workpiece stage . The workpiece stage  may be controlled to move relative to the optical assembly portion , such that the interchangeable objective lens  moves between locations on a workpiece , and\/or among a plurality of workpieces . One or more of a stage light , a coaxial light , and a surface light  may emit source light , , or , respectively, to illuminate the workpiece or workpieces . The source light is reflected or transmitted as workpiece light , which passes through the interchangeable objective lens  and the turret lens assembly  and is gathered by the camera system . The image of the workpiece(s) , captured by the camera system , is output on a signal line  to the control system portion . The light sources , , and  may be connected to the control system portion  through signal lines or busses , , and , respectively. To alter the image magnification, the control system portion  may rotate the turret lens assembly  along axis  to select a turret lens, through a signal line or bus .","In various exemplary embodiments, the optical assembly portion  is movable in the vertical Z-axis direction relative to the workpiece stage  using a controllable motor  that drives an actuator, a connecting cable, or the like, to move the optical assembly portion  along the Z-axis to change the focus of the image of the workpiece  captured by the camera system . The term Z-axis, as used herein, refers to the axis that is intended to be used for focusing the image obtained by the optical assembly portion . The controllable motor , when used, is connected to the input\/output interface  via a signal line .","As shown in , in various exemplary embodiments, the control system portion  includes a controller , a power supply portion , the input\/output interface , a memory , a workpiece program generator and executor , a recorder translator , and a learn mode component , a run mode component , an editing portion , a surrogate data manager , a program status manager , a node manager , and an auto scroll manager . Each of these components, as well as the additional components described below, may be interconnected by one or more data\/control buses and\/or application programming interfaces, or by direct connections between the various elements.","The input\/output interface  includes an imaging control interface , a motion control interface , a lighting control interface , and a lens control interface . The motion control interface  may include a position control element , and a speed\/acceleration control element , although such elements may be merged and\/or indistinguishable. The lighting control interface  controls, for example, the selection, power, on\/off switch, and strobe pulse timing if applicable, for the various corresponding light sources of the machine vision inspection system .","The memory  includes an image file memory portion , a workpiece program memory portion  that may include one or more part programs PP, or the like, a video tool portion , and a surrogate data memory portion . The video tool portion  includes video tool portion and other video tool portions, which determine the GUI, image processing operation, etc., for each of the corresponding video tools. Many known video tools are included in commercially available machine vision inspection systems, such as the QUICK VISION\u00ae series of vision systems and the associated QVPAK\u00ae software, discussed above. The video tool portion  also includes a region of interest (ROI) generator that supports automatic, semi-automatic, and\/or manual operations that define various ROIs that are operable in various video tools included in the video tool portion . The surrogate data memory portion  includes surrogate data SD. As will be described in more detail below, in accordance with the present invention, when editing a part program, rather than being required to execute all of the steps of the part program in order to generate the needed context for continuing edits, certain context can be simulated using previously saved data as surrogate data.","In general, the memory portion  stores data usable to operate the vision system components portion  to capture or acquire an image of the workpiece  such that the acquired image of the workpiece  has desired image characteristics. The memory portion  may also store inspection result data, may further store data usable to operate the machine vision inspection system  to perform various inspection and measurement operations on the acquired images (e.g., implemented, in part, as video tools), either manually or automatically, and to output the results through the input\/output interface . The memory portion  may also contain data defining a user interface operable through the input\/output interface .","The signal lines or busses , , and  of the stage light , the coaxial light , and the surface light , respectively, are all connected to the input\/output interface . The signal line  from the camera system  and the signal line  from the controllable motor  are connected to the input\/output interface . In addition to carrying image data, the signal line  may carry a signal from the controller  that initiates image acquisition.","One or more display devices  (e.g., the display  of ) and one or more input devices  (e.g., the joystick , keyboard , and mouse  of ) can also be connected to the input\/output interface . The display devices  and input devices  can be used to display a user interface, which may include various user interface features that are usable to perform inspection operations, and\/or to create and\/or modify part programs, to view the images captured by the camera system , and\/or to directly control the vision system components portion . In particular, according to various exemplary embodiments of the present invention, the display devices  and input devices  are used to present various user interface features usable to allow rapid, efficient, intuitive, and flexible editing of part programs on the machine vision inspection system .","The workpiece generator and executor , recorder translator , learn mode executor , run mode executor , editing portion , surrogate data manager , program status manager , node manager  and auto scroll manager  may in one embodiment all be considered to be part of a general machine controller block MC that is linked to the controller . The workpiece program generator and executor  is responsible for creating and executing part programs. It will be appreciated that the terms \u201cworkpiece program\u201d and \u201cpart program\u201d may be used interchangeably herein. In accordance with the operations of the workpiece program generator and executor , in various exemplary embodiments, when a user utilizes the machine vision inspection system  to create a part program for the workpiece , the user generates part program instructions either by explicitly coding the instructions automatically, semi-automatically, or manually, using a workpiece programming language, and\/or by generating the instructions by operating the machine vision inspection system  in a learn mode (e.g., as controlled by the learn mode portion ) to provide a desired image acquisition training sequence. For example a training sequence may comprise positioning a workpiece feature in the field of view (FOV), setting light levels, focusing or autofocusing, acquiring an image, and providing an inspection training sequence applied to the image (e.g., using video tools). The learn mode operates such that the sequence(s) are captured or recorded and converted to corresponding part program steps (i.e., instructions). These part program steps, when the part program is executed in a run mode (e.g., as controlled by the run mode portion ), will cause the machine vision inspection system to reproduce the trained image acquisition and inspection operations to automatically inspect a workpiece or workpieces matching the workpiece used when creating the part program.","The recorder translator  is utilized for translating machine operations into part program code. In other words, if a user performs an action (e.g., such as altering a video tool that is used to measure a feature on a workpiece) a basic instruction is generated that is translated into a machine readable language, and a reverse translation may also be performed. As will be described in more detail below, in certain embodiments of the present invention, certain mark up type language instructions in a part program may also be translated into instruction representations in a user interface. In one specific example embodiment, the mark-up language code may be XML-like code. The editing portion  provides or activates various operations and user interface features related to editing a part program, as will be described in more detail below with respect to .","The surrogate data manager  links to surrogate data, which in accordance with the present invention, may be recorded in a part program. In certain implementations, the surrogate data manager  is responsible for obtaining the surrogate data from an output where it would normally be generated, and providing the surrogate data to be written into the part program. The program status manager , in one embodiment, manages whether programs are protected or unprotected. In one implementation, an unprotected part program may include stored surrogate data, while a protected part program has had any surrogate data removed. In one example embodiment, protected programs are programs for which the editing process has been completed, such as may be utilized in a factory in a run mode. In one embodiment, a user may select a part program that is to be protected, at which point the program status manager  automatically removes all of the surrogate data so that the part program is not burdened with extra execution steps at run time. The program status manager  is also responsible for when a program is unprotected, such that the surrogate data remains recorded in the part program and when a part program is recalled by the editing portion , the surrogate data is indicated as being available.","In one embodiment, the node manager  is responsible for managing node numbers that are assigned to nodes in a part program. In one implementation, within a representation of a part program, each of the instruction representations is assigned a node number. In certain implementations, an organizational tree structure may be utilized wherein there are parent nodes and child nodes. In certain implementations, every line of a part program representation that is generated by the recorder translator  is assigned a node number by the node manager . The auto scroll manager  utilizes the node numbers assigned by the node manager  to display related elements of associated part program elements and corresponding editing functions in different windows at the same time. In other words, if a user wishes to see which measurements of a workpiece are related to which instruction representations and coded instructions in a part program, the auto scroll manager  will automatically scroll in the respective windows to the relevant lines in the part program representation and\/or coded instructions that correspond to the relevant node number.","Related editing features and functions are also described in patent applications entitled \u201cMachine Vision System Program Editing Environment Including Synchronized User Interface Features\u201d (61\/560,278); \u201cSystem and Method Utilizing An Editing Initialization Block In A Part Program Editing Environment In A Machine Vision System\u201d (Ser. No. 13\/297,182); and \u201cMachine Vision System Editing Environment For A Part Program In Which A Continuous Stream Of Image Acquisition Operations Are Performed During A Run Mode\u201d (Ser. No. 13\/297,220), each of which is filed concurrently herewith and hereby incorporated by reference.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIG. 2B","FIG. 2A","FIG. 2B","FIG. 3"],"b":["160","160","174","176","177","178","174","176","176","176","176","176","176","176","176"]},"The edit execution portion  is responsible for various execution modes during an editing process, and includes a surrogate mode portion , an actual mode portion , and an edit execution user interface features portion . The surrogate mode portion  includes a node analyzer , which includes surrogate data operations A and machine operations B. As will be described in more detail below, when the surrogate mode portion  operates a surrogate execution mode, in accordance with the present invention, surrogate data is utilized for generating context for the continuing editing operations. The node analyzer  in one implementation determines whether the part program execution has reached the target node (e.g., where a modification is to be made in the part program). The node analyzer  determines whether the surrogate data operations A or actual machine operations B will be performed, in accordance with the type of node that is involved. In general, once the target node is reached, then actual machine operations are performed, wherein for part program instructions prior to the target node, surrogate data operations may be utilized for generating at least some of the context that is needed for the continuing editing operations. If surrogate data is missing, a user may be prompted to allow\/perform actual machine operations to generate the needed context. In one implementation, each node is analyzed to determine if surrogate data operations are applicable, including whether surrogate data exists, if it is the right type of node for surrogate data operations, or alternatively, whether actual machine operations need to be utilized, etc.","The actual mode portion  includes operations that are more traditionally performed by prior machine vision systems. It will be appreciated that the actual mode portion  may also be called by the surrogate mode portion  for performing the machine operations B, when appropriate. The actual mode portion  includes machine operations A and data operations B. The machine operations A perform actual machine operations (e.g., moving the stage as part of a video tool operation), while the data operations B generally output data. The edit execution user interface features  provide user interface features for the execution of the editing functions (e.g., indications as to the status of various execution operations, such as color codes indicating what portions of a part program have utilized surrogate data, or have been run through an actual execution, etc.).","The editor commands  includes a run segment portion A, a modify portion B and an insert\/append portion C. The operations of the insert\/append portion C will be described in more detail below with respect to , while the operations of the modify portion B will be described in more detail below with respect to . In general, the run segment portion A performs an actual run of a selected segment of the part program. It will be appreciated that in order to run a selected segment of a part program, the proper context up to the selected segment must be established. As will be described in more detail below, in accordance with the present invention, the proper context may be established by utilizing surrogate data. If surrogate data does not exist for a certain portion of a part program, then a segment may be run so as to generate the needed surrogate data. It will be appreciated that in prior machine vision systems, it has been difficult to run an isolated segment of a part program without running all of the preceding portions of the part program, due to the need for the proper context leading up to the selected segment. For example, if the segment required the stage to be lowered, but the system was unaware of the present X-Y-Z location of the stage, then lowering the stage to an unknown position could be inadvisable. Thus, in prior implementations, the technique typically utilized was to run the entire part program from the beginning in order to be able to run a segment in the middle, for which all of the preceding operations could require a significant amount of time to perform. In contrast, in accordance with the present invention, surrogate data may be utilized to establish the proper context for making edits to or running a segment of a part program without requiring the running of the entire part program from the beginning.","The modify portion B has certain similarities to the operation of the run segment portion A. In general, when an instruction representation in a part program is selected to be modified, then the surrogate mode may be utilized for the portions of the part program that precede the instruction that is to be modified. In one embodiment, when the modify command is selected for an instruction representation in a part program, the node for the instruction representation is designated as the target node. Once the target node is reached, the editor switches out of the surrogate mode and switches into the actual execution mode (e.g., as controlled by the actual mode portion ) and executes the first relevant part program instruction of the node. In one embodiment, if the instruction that is selected for modification corresponds to a child node, then the actual execution may be designated to begin at the parent node. In one specific example embodiment, if a child node related to a box tool is to be modified, the parent node, which involves setting up the image acquisition for the box tool, may be the node at which the actual execution is set to begin. With regard to the insert\/append component C, if the insert is in between child nodes, then the parent node may also need to be executed in order to perform the desired insertion. It will be appreciated that in certain implementations an append operation may generally be considered to be a special case of an insert operation, which occurs at the end of an existing part program.",{"@attributes":{"id":"p-0064","num":"0063"},"figref":["FIG. 3","FIG. 4"],"b":["300","310","351","364","300","320","310"]},{"@attributes":{"id":"p-0065","num":"0064"},"figref":["FIG. 4","FIG. 3","FIG. 3"],"b":["400","410","415","400","420","440","430","450","460","415","3","4","3","4","2"]},"The following description will make reference to both the initial part program instruction representations - of , and the corresponding features on the workpiece  of . In one embodiment, each of the instruction representations - is associated with a node, and is assigned a node number. In certain implementations, a tree-structure is utilized, wherein some of the instruction representations are associated with parent nodes, and some are associated with children nodes. For example, the children node instruction representations A-D, A-C, A-B, A-C, and A-B are associated with parent node instruction representations , , , , and , respectively. It will also be appreciated that in one embodiment, the instruction representations - as displayed in the editing interface , comprise icons and labels derived from the mark-up language instructions of the part program. In one embodiment, the mark-up language of the part program may comprise XML-like code. The instruction representations - thus point to associated code instructions that are executed, as will be described in more detail below with respect to .","As shown in , the part program representation  begins with the instruction representations  and , which indicate that the user manually selects a location on the workpiece  to act as a rough origin point ROP (not shown), and then aligns the origin to the rough origin point ROP. More specifically, the instruction representations A, B, C, and D indicate that the user sets up and utilizes a manual tool to define the rough origin point ROP and the instruction representation  aligns the origin with the rough origin point ROP. The instruction representation  then indicates that a box tool will be opened for measuring the line XLINE. More specifically, the instruction representations A and B indicate that the user sets up (e.g., including moving the stage to a designated location and acquiring a corresponding image) and utilizes the box tool to determine the edge points PTX. The functions and operations of box tools and other edge detection video tools are known in the art and are described in more detail in the previously incorporated references. The edge points PTX that are determined by the box tool are then utilized by the instruction representation C to define the line XLINE. Similarly, the instruction representation  indicates that a box tool will be opened for measuring the line YLINE, wherein the instruction representation A indicates that the user utilizes the box tool to determine the edge points PTY, which are then utilized as indicated by the instruction representation B to define the line YLINE.","The instruction representation  then indicates that an intersection point XYORIGIN is determined at the intersection of the lines XLINE and YLINE. The instruction representation  then indicates that the machine vision system is commanded to align the origin to the point XYORIGIN. The instruction representation  then indicates that the machine vision system is commanded to align the X axis for the workpiece  to the line XLINE. As will be described in more detail below with respect to , and as indicated by the comment line , the operations of the instruction representations - establish the correct location and orientation of the workpiece  for performing additional measurements.","The instruction representation  then indicates that a box tool will be opened for measuring the line L. More specifically, the instruction representations A and B indicate that the user sets up (e.g., including moving the stage to a designated location and acquiring a corresponding image) and utilizes the box tool to determine the edge points PT, which are then utilized as indicated by the instruction representation C to define the line L. As will be described in more detail below, the box tool utilized for measuring the line L (i.e., illustrated as box tool  in ), and the associated instruction representations  and A-C, are utilized as examples in  and -B for illustrating how surrogate data is generated, stored and modified.","Returning to , the instruction representation  indicates that a box tool will be opened for measuring the line L, wherein the instruction representation A indicates that the user utilizes a box tool to determine the edge points PT, which are then utilized as indicated by the instruction representation B to define the line L. The instruction representation  indicates that the user defines a selected position tolerance and the instruction representation  indicates that an intersection point I is determined where the previously determined lines L and L intersect.","After the part program corresponding to the representation  is stored and exited, when the part program is recalled for editing, prior implementations have required that the entire part program be executed from the beginning, in order to produce valid context for continuing edits to the part program. While prior implementations have produced accurate results and part programs by executing all of the instructions each time a part program is recalled for editing, the execution of all of the instructions may take a significant amount of time (particularly those instructions that require certain time consuming processes such as hardware interactions, etc.). As will be described in more detail below, in accordance with the present invention, rather than executing the entire part program from the beginning, previously saved data may be used as surrogate data for simulating valid context for continuing edits to the part program.","In other words, in one embodiment, when continuing edits are being made to the part program for making measurements on the workpiece , it is useful to know certain parameters. For example, in order to know the correct thresholds, size, and location for a video tool, it is necessary to have the right video image, including information such as the correct stage position, light levels, magnification, etc. In one embodiment, such information may be considered as part of the \u201chardware context.\u201d In addition, in order to know if a sequence is correct for continuing edits to the part program, it is useful to know what has been done already, including what features have been measured, what part coordinate system is being utilized, etc. In one embodiment, this information may be considered as part of the software context. In one embodiment, the context is generally considered as establishing the user interface of the machine vision inspection system in a state such that all of the native interface control elements are ready for modifying the part program. As noted above, accurate context is provided at the time the part program is initially recorded, and also later at runtime, in that all of the part program instructions (e.g., corresponding to the representations -) are generally executed in order. As noted above, this provides a valid context for continuing edits to the part program, including indicating any measurements and results already produced by the part program (e.g., the indications of the lines XLINE, YLINE, L, L, and intersection points XYORIGIN and I as illustrated with respect to the workpiece  in the user interface ).","As will be described in more detail below, in accordance with the present invention, when editing a part program, rather than being required to execute all of the instruction representations of the part program in order to generate the needed context, certain context can be simulated by using previously saved data as surrogate data. Briefly, during the recording or runtime execution of a part program, the data that is needed to determine context is stored with the part program. Then, at a later time, certain results may be simulated utilizing the saved data as surrogate data in order to produce the desired context. Thus, by avoiding the execution of certain time-consuming operations (e.g., those requiring hardware interaction such as the moving of the stage, edge detection, focusing, lighting changes, pattern matching, etc.), significant time savings may be achieved. The saving of data that may be later utilized as surrogate data will be described in more detail below with respect to .",{"@attributes":{"id":"p-0074","num":"0073"},"figref":["FIGS. 5A and 5B","FIG. 3","FIGS. 5A and 5B","FIG. 3","FIGS. 5A and 5B","FIGS. 5A and 5B"],"b":["500","500","361","361","361","3","361","361","361","361","361","361"]},"As shown in , the XML-like code instructions include node I.D. numbers , A, B, and C, which in one embodiment may correspond to the instruction representations , A, B, and C of . The XML-like code instructions also include certain position information  for the image position, and certain box tool position information  for the box tool, such as may be displayed in the areas  and  of the user interface  of . As shown in , data  is stored with the part program that may be utilized at a later time as surrogate data for simulating context (e.g., as will be described in more detail below with respect to ). More specifically, when the instruction representation B of  indicates that the box tool  of  is run to determine the set of edge points PT, the positions of the set edge points PT relative to the part coordinate system for the workpiece are stored in the XML-like code instructions as the data . As will be described in more detail below with respect to , modifications may be made to the part program which may result in modifications to the surrogate data .",{"@attributes":{"id":"p-0076","num":"0075"},"figref":["FIG. 6","FIG. 3","FIG. 6","FIG. 6","FIG. 6","FIGS. 7 and 8","FIG. 5B"],"b":["600","310","620","620","621","622","623","624","625","626","627","628","629","620","364","364","364","640","364","620","621","530","620","627"]},"As described in concurrently filed and commonly assigned application entitled \u201cSystem and Method Utilizing an Editing Initialization Block in a Part Program Editing Environment in a Machine Vision System,\u201d Ser. No. 13\/297,182, which was previously incorporated by reference, the user may designate one of the instruction representations (e.g., instruction representation ) as an editing initialization block marker. Once the user designates the instruction representation  with the editing initialization block marker, this designates that all of the instruction representations preceding and up to instruction representation  (i.e., instruction representations -) are editing initialization instruction representations which make up an editing initialization block . The instruction representation  is therefore determined to be the last initial part program instruction representation that is an editing initialization step. In one embodiment, an editing initialization indicator may be provided in the editing interface  that indicates that each of the instruction representations - are editing initialization steps. In the specific example illustration of , a color bar  (shown with cross hatching) is provided next to the instruction representations - to indicate that they are in the editing initialization block . In alternative embodiments, other editing initialization indicators may be utilized for indicating the editing initialization instruction representations (e.g., a delimiting pointer, delineating markers, highlighting of the actual instruction representations rather than a bar next to the steps, etc.). In one embodiment, when the part program is saved, the indication of which instruction representations are editing initialization instruction representations is also saved.","It will be appreciated that the remaining initial part program instruction representations - which follow the editing initialization block  and which are therefore not included in the editing initialization block, may not be run in the same manner when the editing initialization block is run, as will be described in more detail below. In one embodiment, the instruction representations - are designated as being in a remaining instruction representations block .","As will be described in more detail below, in one embodiment the editing initialization block  may be utilized to address certain changes in conditions that may occur during the editing process for a part program. For example, if after a user saves a part program, the user leaves the work station and returns at a later time, in the interim certain changes may have occurred (e.g., the part being inadvertently moved on the stage, etc.) that may affect the editing of the part program. However, due to the amount of time that may be required for rerunning all of the previous instructions of a part program (particularly those instructions that require certain time consuming processes such as hardware interactions, etc.), a user may desire to only rerun certain instructions which help ensure the accuracy of context that is simulating using surrogate data. The editing initialization instruction representations of the editing initialization block  represent initial part program instructions that will reestablish a part coordinate system for the part, so as to compensate for any inadvertent movement of the part on the stage since the last part program instructions were performed.",{"@attributes":{"id":"p-0080","num":"0079"},"figref":["FIG. 7","FIG. 3","FIG. 8"],"b":["700","310","770","770","771","774","621","650","621"]},{"@attributes":{"id":"p-0081","num":"0080"},"figref":["FIG. 8","FIG. 7","FIG. 8"],"b":["800","415","650","415","415","351","357","415","415","310","650","415"]},"In contrast, in one embodiment, the initial part program instruction representations - in the remaining instruction representations block , which are not editing initialization steps, are not run in the same manner. Instead, in certain implementations, the saved location data (e.g., data  of ) may be utilized as surrogate data for determining the locations of the sets of points PT\u2032 and PT\u2032. In other words, the locations of the sets of points PT\u2032 and PT\u2032 may be provided based on the relative locations of those points as determined from the initial performance of the part program instruction representations - as illustrated in  (e.g., as saved as the data  of ). In other words, the relative locations of the points PT and PT in  (e.g., as referenced to the part coordinate system including the point XYORIGIN) are saved when the part program is initially performed and saved. Thereafter, when the part program  is recalled for editing and the editing initialization block  is run so as to reestablish the location of the point XYORIGIN as shown in , rather than also reestablishing the locations of the points PT and PT, the previously saved relative locations to the point XYORIGIN are used as surrogate data to determine the locations of the points PT\u2032 and PT\u2032.","In other words, the locations of the points PT\u2032 and PT\u2032 may not be based on the running of the instructions associated with the representations A, B, and A, all of which require hardware interaction and edge detection and would take a relatively long time to perform. In one embodiment, any instructions which are not in the editing initialization block and which would generally require certain designated time-consuming operations (e.g., hardware interactions such as moving the stage, edge detection, focusing, lighting changes, pattern matching, etc.) are not performed. Instead, any resulting data (e.g., redetermined edge points, etc.) that would have been provided is based on surrogate data (e.g., the locations of the points PT\u2032 and PT\u2032 relative to the point XYORIGIN). As noted above, orientation of the part coordinate system including the correct location of the point XYORIGIN has been reestablished by running the editing initialization block  so as to help ensure the accuracy of any related surrogate data that is used.","It will be appreciated that by not running certain designated time-consuming operations, significant time savings may be achieved. This is due to the fact that such operations may take a relatively long time to perform, particularly in comparison to operations which only require calculations to be performed by the controller of the machine vision system. It will be appreciated that while in the example of  only a few such instruction representations (e.g., instruction representations A, B, and A) of this type have been illustrated, in a more detailed part program, significantly more instruction representations of this type may be utilized, for which the time savings may be significant.","In one embodiment, the instructions associated with the representations C and B (which do not require relatively time-consuming operations and only require the relatively fast processing of the controller of the machine vision system to utilize the points PT\u2032 and PT\u2032 to establish the locations of the lines L\u2032 and L\u2032) may be executed to generate context. Similarly, the additional instructions associated with the representation  (which only require the relatively fast processing of the controller) may also be executed to determine the context including the intersection point I\u2032 at the intersection of the lines L\u2032 and L\u2032. It will be appreciated that the calculations performed by the instructions associated with the representations C, B and  are all of a type that can be performed relatively quickly on the estimated edge points PT\u2032 and PT\u2032 that are determined from the surrogate data, without requiring significant time or input from the user. Thus, certain instructions associated with the initial part program instruction representations - in the remaining instruction representations block  may also be executed to generate context.","With regard to the additional part program instruction representations - that are added by the insert operation , the specific operations associated with the instruction representations will also be described with respect to . Similar to the instruction representations -, the additional part program instruction representations - are organized in a tree-structure, wherein children node instruction representations A-C and A-B are associated with parent node instruction representations  and , respectively. As shown in , the instruction representation  indicates that a box tool will be opened for measuring a line L. More specifically, the instruction representations A and B indicate that a user sets up (e.g., including moving the stage to a desired location and acquiring a corresponding image) and utilizes the box tool to determine the edge points PT, which are then utilized as indicated by the instruction representation C to define the line L. Similarly, the instruction representation  indicates that a box tool will be opened for measuring a line L, wherein the instruction representation A indicates that the box tool is utilized to determine the edge points PT, which are then utilized as indicated by the instruction representation B to define the line L.","The instruction representation  indicates that an intersection point I is determined at the intersection of the lines L and L. The instruction representation  indicates that a distance D is determined between the intersection point I and the intersection point I\u2032 that was determined at the instruction representation . It will be appreciated that the instruction representation  thus illustrates how a new measurement of the distance between the intersection point I and the intersection point I\u2032 may rely on the context generated from the utilization of surrogate data. More specifically, the location of the intersection point I\u2032, which as described above was context that was able to be determined relatively quickly and with a reasonable assurance of accuracy based on the running of the editing initialization block , was able to be utilized for the new distance measurement D to the intersection point I.",{"@attributes":{"id":"p-0088","num":"0087"},"figref":["FIG. 9","FIG. 7","FIG. 6","FIG. 9","FIG. 9","FIG. 9"],"b":["900","620","920","620","620","361","361","361","640"]},"After the user has selected the instruction representation B, as a result, the drop down menu  is provided, in which the user has selected the modify operation . As will be described in more detail below, once the user selects a modify operation , a determination is made that the stage will need to be moved. As a result, an indicator box  is provided indicating that the system will need to be synchronized, and a query box  is provided that asks the user to approve the corresponding movement of the stage.","As will be described in more detail below, the selected instruction representation (e.g., instruction representation B) is utilized for the designation of a target node. For certain of the instruction representations which precede the target node, surrogate data may be utilized for determining valid context. Once the target node is reached, then actual execution operations may begin, which may require certain physical operations to be performed, such as requiring a movement of the stage.",{"@attributes":{"id":"p-0091","num":"0090"},"figref":["FIGS. 10A and 10B","FIG. 9","FIG. 10A","FIGS. 5A and 5B","FIG. 4","FIG. 10B","FIG. 4","FIGS. 11A and 11B"],"b":["1000","1000","361","1000","470","361","1015","1000","470","470","3","3","2","1","3","3","3","3","460","1000","460","400","3"]},{"@attributes":{"id":"p-0092","num":"0091"},"figref":["FIGS. 11A and 11B","FIGS. 10A and 10B","FIGS. 11A and 11B","FIGS. 5A and 5B","FIG. 11A","FIG. 5A","FIG. 11B","FIG. 5B"],"b":["1100","1100","1120","1130","530","1130","530"]},{"@attributes":{"id":"p-0093","num":"0092"},"figref":["FIGS. 12A and 12B","FIG. 12A","FIG. 12B"],"b":["1200","1210","1220","1230","1230"]},"As shown in , from the point A, the routine continues to a block . At the block , the learn mode is configured such that it is further operable to automatically record respective surrogate data which is associated with a respective set of recorded part program instructions. In addition, at least some respective surrogate data comprises data which results from actual execution of controlled operations corresponding to the associated respective set of recorded part program instructions. At a block , the edit mode of execution is configured such that it comprises a surrogate execution mode wherein during surrogate execution mode of part program instructions represented in the editable part program representation, for at least one set of part program instructions, if respective surrogate data has been previously recorded in association with that set of part program instructions, then at least some members of that set of part program instructions are not executed such that their associated controlled operations are not actually executed. In addition, the respective surrogate data is used in subsequent operation of the surrogate execution mode as a substitute for data that would otherwise result from their associated controlled operations which are not executed.",{"@attributes":{"id":"p-0095","num":"0094"},"figref":["FIG. 13","FIGS. 7 and 8"],"b":["1300","1310","361","650","650","650"]},"At a block , the routine continues to the next node as a current node. At a decision block , a determination is made as to whether the current node is the target node of an editing command. If the current node is the target node of an editing command, then the routine continues to a block , where an actual execution mode is begun at the current node, after which the routine continues to a decision block , as will be described in more detail below. As a specific example of a current node being the target node of an editing command, in the embodiment of , the instruction representation B is the one that has been selected for editing with the modify command . However, because the instruction representation B is designated as child node of the parent node for the instruction representation , the actual execution mode may be begun at the parent node corresponding to the instruction representation . Thus, in one implementation, the target node may be considered to be the parent node associated with the instruction representation , and the actual execution mode may start at the parent node such that the physical set up for measurement corresponding to instruction representation A is performed to provide the correct physical context for editing at the instruction representation B.","If, at the decision block , it is determined that the current node is not the target node of an editing command, then the routine continues to a decision block , where a determination is made as to whether the current node unconditionally requires physical system changes. For example, if the node moves the stage to image a new portion of the workpiece (e.g., via a simple \u201cmove\u201d command, or the like), then in some embodiments this may unconditionally require physical system changes. Similarly, certain magnification changes are unconditional physical system changes, and so on. However, it will be appreciated that in some embodiments, if such changes are embedded within a parent node that already has associated surrogate data, and a subsequent node again requires a similar physical change (e.g., a move or magnification change, respectively), then it may not be unconditionally required, since it will eventually be superseded by the similar subsequent instruction. Various methods of analyzing whether a current node unconditionally requires physical system changes may be determined by one skilled in the art, based on the teachings of this disclosure. In any case, if the current node does unconditionally require physical system changes, then the routine continues to the block . If the current node does not unconditionally require physical system changes, then the routine continues to a decision block .","At the decision block , a determination is made as to whether the current node provides results data. If the current node does provide results data, then the routine continues to a decision block , as will be described in more detail below. If the current node does not provide results data, then the routine continues to a block , where the node is executed in surrogate execution mode, after which the routine continues to the block , as will be described in more detail below.","At the decision block , a determination is made as to whether surrogate data exists for the current node. If surrogate data does exist for the current node, then the routine continues to a block , as will be described in more detail below. If surrogate data does not exist for the current node, then the routine continues to the block .","At the block , the node is executed in surrogate execution mode. For the surrogate execution mode, surrogate data is used as a substitute for data that would otherwise result from the execution of control operations associated with at least some members of a set of part program instructions corresponding to the current node, and those members of the set of part program instructions are skipped such that the associated control operations are not actually executed. As a specific example, in the embodiment of , the surrogate data (e.g., data  of ) is utilized as a substitute for the data that would otherwise result from the execution of the control operations associated with the instruction representations , A, and B, such that the associated instructions and control operations are skipped and not actually executed. Similarly, surrogate data is also used with regard to the operations associated with the instruction representations  and A, such that the associated instructions and control operations are skipped and not actually executed. In contrast, the instructions associated with the instruction representations C (i.e., for defining the line L\u2032 utilizing the surrogate data edge points), the instruction representation B (i.e., for defining the line L\u2032 utilizing the surrogate data edge points), and the instruction representation  (i.e., for determining the intersection point I\u2032 between the lines L\u2032 and L\u2032) are all executed to generate the associated context. In other words, the generation of the lines L\u2032 and L\u2032 and the intersection point I\u2032, as illustrated in the user interface  of , demonstrates how surrogate data may be utilized to generate context for continuing edits to the part program.","The routine then continues to the decision block , where a determination is made as to whether there is another node to execute in the surrogate execution mode. If there is another node to execute in the surrogate execution mode, then the routine returns to the block , and if not, then the routine ends. For example, if execution has arrived at decision block  by reaching a target node and executing blocks  and , then in some instances there will not be another node to execute in surrogate execution mode because the context may already be established for editing at, or within, the target node.","While various preferred and exemplary embodiments of the invention have been illustrated and described, it will be appreciated that various changes can be made therein without departing from the spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF THE DRAWINGS","p":["The foregoing aspects and many of the attendant advantages of this invention will become more readily appreciated as the same become better understood by reference to the following detailed description, when taken in conjunction with the accompanying drawings, wherein:",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIGS. 2A and 2B","FIG. 1"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIGS. 5A and 5B","FIG. 3"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 6","FIG. 3"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIG. 7","FIG. 3"]},{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 9","FIG. 7"]},{"@attributes":{"id":"p-0039","num":"0038"},"figref":["FIGS. 10A and 10B","FIG. 8"]},{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIGS. 11A and 11B","FIGS. 10A and 10B"]},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIGS. 12A and 12B"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
