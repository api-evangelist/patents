---
title: System for improved efficiency in motion compensated video processing and method thereof
abstract: A system and methods are shown for improved processing of motion compensated video. A software driver handles image data related to motion compensated video. The image data includes IDCT coefficients and motion compensation vector data. A unique identifier is attached to the image data, preserving the relationship between the IDCT coefficients and motion compensated vector data related to an image block. The software driver sends the IDCT coefficients to an IDCT component. The IDCT coefficients are processed and an interrupt is sent to the software driver including the unique identifier of the processed IDCT coefficients. The software driver sends the motion compensation vector data related to the unique identifier in the interrupt. A 3D pipe receives the motion compensation vector data and reads the corresponding processed IDCT data. The 3D pipe sends an interrupt allowing the software driver to submit new IDCT coefficients as the 3D pipe processes the current motion compensation data with the read IDCT data. The 3D pipe processes the motion compensation data along with the read IDCT data to generate at least a portion of an image. The image portion is stored in a frame buffer until it is ready to be displayed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06873735&OS=06873735&RS=06873735
owner: ATI Technologies, Inc.
number: 06873735
owner_city: Thornhill
owner_country: CA
publication_date: 20010205
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE DRAWINGS"],"p":["The present invention relates generally to processing video and more particularly to processing motion compensated video.","Digital video is generally processed in sets of video frames. Each frame is a still image representing an instant in time of the video being processed. Each frame can further be broken down into blocks. The blocks are individually transmitted and then recombined to form a frame. The amount of data needed to represent the image blocks can become large. Motion compensation can be used to reduce the amount of data needed to represent the image blocks.","Using motion compensation, image blocks can be represented by motion compensation vectors and error data. Motion compensation vectors are used on prediction frames. For example, an object in one frame may simply be displaced either partially or fully into in a new frame. Accordingly, the image blocks used to represent the object in the new frame may be processed with motion vectors, using the image blocks in the original frame as reference. The motion vectors provide the direction and distance in which the referenced image blocks have moved to in the new, or predicted, frame. While the motion vectors may track an object, the temporal compression achieved by motion compensation is intended to reduce the bits required to reproduce the error term, and as such need not necessarily track a specific object.","In some cases, motion compensation vectors are all that are needed to reproduce an image block. However, in many situations, some error exists between the referenced image blocks and the blocks in the predicted frame. Error data can be sent to recover the differences and adequately generate the image block. The error data itself is basic image information, including the luminance of the pixels within the image block. A transform, such as a discrete cosine transform (DCT), can be used to reduce the size of the error data to a transformed data set. The transformed data set includes transfer coefficients, which can then be inverse transformed to reproduce the error data. In some cases, no motion vectors can be generated for a given image block. For example, when a video switches to a new scene none of the objects in the new frame can be referenced to objects in the previous frame. In such a case, the image block is represented only with error data. Furthermore, some reference frames for motion compensation are made up of image blocks represented with only error data. They are referred to as intra-frames, or I-frames. Prediction frames, or P-frames, are motion compensated frames that use previous I- or P-frames for reference. Bi-directional frames can use previous or upcoming I- or P-frames for reference. It should be noted that B-frames are never used as reference themselves to avoid the accumulation of precision errors.","To process the frame data, conventional video processing hardware is used to capture the motion compensation vector data and the error data. The transformed data sets are inverse transformed, such as through an inverse discrete cosine transform (IDCT) component, to accurately reproduce the error data. In some cases, very little or no motion compensation vector data may be present for a given block and most of the data will be related to error data. The hardware must wait for the error data to be fully processed before it can process or receive more motion compensation vector data. The hardware pipeline becomes stalled as it waits for the error data to be processed. In other cases, when reconstruction of an image frame involves mostly motion compensation vector data and few IDCT operations, the IDCT component may become stalled as it waits for the hardware pipeline to process the motion compensation vector data.","Conventional systems force the hardware to be idle when the workloads between the IDCT operations and the motion compensation operations are not well balanced. Stalling the hardware reduces the efficiency with which frames of video are processed and increases the delay in which an image frame can be displayed. Therefore, a system for allowing the video processing hardware to efficiently process the motion compensated video data would be useful.","In accordance with at least one embodiment of the present invention, a technique for processing image data is provided. The technique comprises receiving a first transformed error data, wherein the first transformed error data is for a first set of image data, processing the first transformed error data to generate a first inverse transformed results, associating an identifier with the first inverse transformed results, and storing the first inverse transformed results in memory. The technique further comprises receiving motion compensation vector data, wherein the motion compensation vector data is for the first set of image data, accessing the first inverse transformed results from memory based at least in part on a comparison of the identifier associated with the first inverse transformed results with an identifier associated with the motion compensation vector data, and processing the motion compensation vector data and the first inverse transformed results to generate at least part of an image.","At least one embodiment of the present invention provides a method for processing image data. The method includes receiving IDCT data. The IDCT data is inverse discrete cosine transform coefficients related to a set of image data. The method also includes processing the IDCT data to generate IDCT results. The method includes receiving motion compensation vector data. The motion compensation vector data is related to the set of image data. The method includes retrieving the inverse transformed results related to the set of image data, based upon receiving the motion compensation vector data. The method further includes processing the motion compensation vector data and the IDCT results to generate at least part of an image.","Referring now to , a video processing system for collecting and processing motion compensation video data is shown, according to one embodiment of the present invention. In one embodiment, the video processing system is part of an information handling system. Software driver  is part of software located in memory within the information handling system, run with a central processing unit (CPU-not shown). Software driver  handles video requests generated by an application program, such as video application , and routes the video requests to graphics chip  where they can be processed. Video application  can include video applications such as digital video disk (DVD) player software, a digital television tuner, an application programming interface (API), or video decoding software.","In one embodiment, when using motion compensation techniques to display video images, video information related to a new block of image data within a frame of video is temporal-wise compressed using motion compensation (MC) vectors. Blocks in a new frame are compared to blocks in a reference frame. For example, objects in the reference frame may simply move or be displaced in the new frame. Therefore, a MC vector, indicating the direction and distance, can be used to describe where the blocks representing the object should be in the new frame. MC vectors may not always be enough to represent the block in the new, or predicted, frame. Differences between the block in the reference frame and the block in the new frame are transmitted as error data.","Error data is generally image data, including pixel information to reproduce any image information not covered using MC vectors. The error data can be compressed using a discrete cosine transform (DCT). The DCT is a discrete orthogonal transformation between a time and frequency domain. Generally a forward DCT (FDCT) is performed on the error data to generate transform coefficients, allowing an inverse DCT (IDCT) to later be used on the coefficients to restore the error data from the DCT results. The error data can correct for any image information left out using the MC vectors. Some blocks, even in predicted frames, may be sent using only transformed error data, without any corresponding MC vectors.","The DCT results and MC data can be received through video application . Video application  can be an application programming interface (API), or a device driver interface (DDI), such as a DirectX Video Acceleration API\/DDI. The results of the DCT can be further compressed using run-length coding, wherein the number of zeroes between values are delivered as discrete values between the coefficients. The video data, DCT results and MC vector data, are then sent by the API\/DDI to a software driver, such as software driver .","Software driver  receives the video data from video application  and may decode the data if necessary, such as through a run-length decoder. In one embodiment, the DCT results are quantized when generated by the DCT. Accordingly, the values can be de-quantized to obtain a better representation of original video data. The DCT results can be used as IDCT coefficients by an inverse transform component, such as IDCT component , to reproduce the error data. Accordingly, the DCT results are stored in an IDCT buffer . The MC vector data is stored in a MC buffer . Sets of the IDCT coefficients and the MC vector data are related to the same portions of an image and must be processed together. For example, IDCT coefficients set  and MC vector set  relate to the same image portion. IDCT coefficients set  and MC vector set  relate to another image portion.","To track the relations between the IDCT coefficients and the MC data, a unique identifier is applied to each IDCT and MC vector set. In one embodiment, IDCT coefficients set  and MC vector set  are given one identifier; while, IDCT coefficients set  and MC vector set  are given another identifier. The identifier can be any unique value assigned to the data sets, such as a value which changes after each data set, such as from a counter, or a timestamp indicating when the data was received, such as from a clock. In one embodiment, the image portion represented by IDCT coefficients sets  and  and the MC data sets  and  include a block of image data, wherein a block can represent a portion of image data covering a space of eight by eight pixels. In another embodiment, the image portion includes a macroblock covering an image space of sixteen by sixteen pixels. It will be appreciated that other image portion sizes can be used and the size of the image portion represented can be altered without departing from the scope of the present invention.","The IDCT coefficients are then processed by an inverse transform, such as IDCT component , to generate the error data for the image block being represented. In at least one embodiment, when MC data from MC buffer  is to be processed by hardware, such as 3D pipe  on graphics chip , the corresponding error data must also be presented. Therefore, before the MC data related to an image portion is provided to 3D pipe , on graphics chip , the IDCT coefficient data related to the image portion is presented to IDCT component  on graphics chip . In one embodiment, graphics chip  represents a monolithic semiconductor device used for processing video data.","In one embodiment, IDCT coefficients set  is sent to IDCT component  of graphics chip . IDCT component  stores the unique identifier associated with IDCT coefficients set  in an identifier register . IDCT component  then performs an inverse transform to generate the error data represented by IDCT coefficients set . In one embodiment, the inverse transform includes an inverse discrete cosine transform. Identifier register  can be a hardware register in graphics chip . Alternatively, identifier register  may be a part of system memory in the information handling system, as illustrated in FIG. .","The results generated by IDCT component , are stored in IDCT results . IDCT results  represent a portion of external memory. As described herein, external memory is used to describe system or cache memory such as random access memory (RAM) or a first in first out (FIFO) memory array which is not a part of 3D pipe  or IDCT component . In comparison, a register is used herein to refer to internal hardware components used to store specific values within the hardware components, such as IDCT component  and 3D pipe . In one embodiment, IDCT results  represent a frame buffer used to store error data. In another embodiment, IDCT results  are stored in cache memory. IDCT component  sends an interrupt to control  of software driver . The interrupt indicates that IDCT component  has completed processing the IDCT coefficients, such as IDCT coefficients set . In one embodiment, the interrupt includes the unique identifier stored in identifier register . The unique identifier is used to indicate which IDCT coefficients were processed. Software driver  may use the unique identifier to determine the corresponding sets of MC vector data in MC buffer  to send.","MC vector data sets, such as MC vector set , corresponding to the processed IDCT coefficients blocks are sent by software driver  to a motion compensation processing component, such as 3D pipe . In one embodiment, 3D pipe  receives a memory address with the MC vector data sets to indicate where to read the error data, stored in IDCT results , related to the MC vector data sets. 3D pipe  processes the MC vector data along with the error data retrieved from memory to generate image data. The processed image data can be stored in frame buffer . Frame buffer  can be represented by a location in memory  or in hardware, such as in graphics chip . Alternatively, the processed image data can be delivered to a display device. In one embodiment, a prediction plane is obtained based on the motion compensation vector data and a reference frame. The prediction plane may combine with error data to produce the final image blocks.","It should be noted that 3D pipe  is capable of operating asynchronously to IDCT component . In one embodiment, the asynchronous nature is based on clocks used to run the components, wherein 3D pipe  and IDCT component  operate using separate clocks. In another embodiment, the asynchronous nature is based on the relationship between operations within the components, wherein there is no fixed time relationship between the completion of an operation on IDCT component  and the initiation of operations on 3D pipe . In one embodiment, while 3D pipe is processing the image data related to MC Vector set  and the processed error data from IDCT coefficients set , IDCT  can process a second set of IDCT coefficients, such as IDCT coefficients set , sent by software driver . However, if software driver  detects, such as through control , that the memory associated with IDCT results  is full of unread data, software driver  may restrict the transfer of IDCT coefficients sets until the memory can be cleared.","Once 3D pipe  has read the error data stored in IDCT results , 3D pipe  can send a second interrupt to control  in software driver . The second interrupt instructs software driver  that the data in IDCT results  has been read. Software driver  can then free the memory space associated with IDCT results . Software driver  can also send more IDCT coefficients from IDCT buffer  to IDCT component , allowing IDCT results  to be filled with new error data, while 3D pipe  is busy processing the received image data. Software driver  can also use the second interrupt to determine whether to display any completed image frames or portions of image frames.","In one embodiment, several sets of IDCT coefficients are sent to IDCT component  for processing. For example, IDCT coefficient sets  and  can be processed by IDCT component . The error data associated to the image portions represented by IDCT coefficient sets  and  can be saved as different portions of memory in IDCT results . If 3D pipe  is busy processing other image data, IDCT  can process both IDCT coefficient sets  and . Once software driver  received the unique identifier associated with IDCT coefficients set , through an interrupt on control , software driver  can send both MC data sets  and , recognizing that the respective IDCT coefficients sets  and  have already been processed. As discussed in , several methods may be employed to optimize video processing for image portions associated mostly with error data or with motion compensation data.","In one embodiment, all data sent between software driver  and graphics chip  is encoded or scrambled to protect the video content represented. For example, the IDCT coefficients sent to IDCT component  and the motion compensation vector data sent to 3D pipe  is scrambled on software driver . Accordingly, graphics chip  would de-scramble the content, through a de-scrambling component (not shown), before it is processed by respective components. As previously discussed, the system described herein may be part of an information handling system. The term \u201cinformation handling system\u201d refers to any system that is capable of processing information or transferring information from one source to another. An information handling system may be a single device, such as a computer, a personal digital assistant (PDA), a hand held computing device, a cable set-top box, an Internet capable device, such as a cellular phone, and the like. Alternatively, an information handling system may refer to a collection of such devices.","Referring now to , a flow chart of a method for a software driver to handle video data for delivery to a video processing hardware is shown, according to one embodiment of the present invention. As previously discussed, individual images of video are temporal-wise compressed using motion compensation. In one embodiment, the image is broken down into blocks of pixel elements. A target block in a target frame is compared to a reference frame and motion compensation vectors are generated indicating the displacement of a reference block in the reference frame that best describes the target block. Differences between the target block and the reference block are transformed using a discrete cosine transform (DCT). The transformed data are used as coefficients for an inverse DCT (IDCT). In one embodiment, a block refers to an eight by eight set of pixels. As previously discussed, the image can also be broken down into multiple sixteen by sixteen macroblocks of pixels. It will be appreciated that the image can be broken down into portions with sizes other than those discussed herein, without departing from the scope of the present invention.","In step , the software driver receives the video data, including motion compensation vectors and IDCT coefficients. Processing may be needed to handle the video data appropriately. For example, in one embodiment, the IDCT coefficients are compressed using run-length coding. Accordingly, a run-length decoding component of the software driver may be required to decode the IDCT coefficients. The video data may also be de-quantized, since many of the IDCT coefficients may be quantized to reduce bandwidth requirements. Quantization may cause unfavorable image artifacts when recreating the image. Therefore, further processing, such as image filtering, may be needed along with de-quantization to reduce the artifacts due to DCT quantization.","In step , the software driver stores the IDCT coefficients in a memory buffer. In step , the corresponding motion compensation vector data is also stored in a memory buffer. As previously discussed, the IDCT coefficients may relate to the same portion of an image as the motion compensation vector data. In one embodiment, the error data related to the IDCT coefficients must be processed with the motion compensation vector data. Accordingly, the software driver generates a unique identifier for tracking the IDCT coefficients and motion compensation vector data related to the same image portion. In step , the unique identifier is applied to the IDCT coefficients. In step , the unique identifier is applied to the motion compensation vector data related to the IDCT coefficients. The unique identifier may be used to identify and preserve the relationship between the motion compensation vector data and corresponding IDCT coefficients, representing the error data. In step , the software driver submits IDCT coefficients stored in the IDCT buffer to processing hardware. As previously discussed, the processing hardware performs an inverse transform on the IDCT coefficients to reproduce image error data.","In step , the software driver receives a notification from the processing hardware. The notification indicates that the processing hardware has completed processing at least some of the IDCT coefficients sent in step , and stored the processed error data in memory. The notification also indicates that the processing hardware is ready to receive motion compensation vector data to process the image block associated with the processed IDCT coefficients. In one embodiment, the notification sent is an interrupt generated by the processing hardware.","In step , the software driver submits motion compensation vector data stored in the motion compensation buffer to the processing hardware. The notification received in step  includes the unique identifier associated with the processed error data. By noting the unique identifier, the software driver identifies which of the stored motion compensation vector data to submit. The software driver may use the notification to locate the address of the processed error data stored in memory, related to the motion compensation vector data. In one embodiment, the software driver sends the memory address in which the processed error data can be accessed. The processing hardware can then read the memory address to access the error data for processing with the motion compensation vector data. The processing hardware processes the motion compensation vector data with the error data to generate the associated image block.","While the hardware is busy processing the motion compensation vector data and the error data, the software driver can continue to submit more IDCT coefficients to be processed, as in step . However, if the memory where the processed error data is stored is full, the software driver must wait until the hardware has read the processed error data. In one embodiment, the hardware sends a second notification to the software driver. Once the processing hardware has read the error data from memory, the processing hardware sends the second notification to the software driver. Once it receives the second notification, the software driver can free up the memory where the error data is being stored, allowing new error data to be stored. The notification indicates that additional IDCT coefficients can be sent to the processing hardware. In one embodiment, the second notification is an interrupt generated by the processing hardware.","Referring now to , a flow chart illustrating a method of processing data related to video in hardware is shown, according to at least one embodiment of the present invention. In step , a software driver receives the video data. The transformed results, IDCT coefficients, and the motion compensation vectors are stored in buffers by the software driver, storing motion compensation data for several image blocks. In one embodiment, the data is stored until the video processing hardware is ready to process more video data.","In step , the video processing hardware receives sets of IDCT coefficients from the software driver. The IDCT coefficients are passed along to an IDCT component, such as IDCT component  (FIG. ). In step , the IDCT component begins to process the IDCT coefficients. The IDCT coefficients are used to reproduce the error image data represented by the IDCT coefficients. In one embodiment, the IDCT component stores a unique identifier associated with the IDCT coefficients. The unique identifier allows the processing hardware to notify the software driver from step  which of the IDCT results is ready to be processed, allowing the software driver to send corresponding motion compensation data. In one embodiment, the notification to the software driver is sent as an interrupt. In step , the processed IDCT data is stored as error data. As previously discussed, the error data may be stored in system memory or in a frame buffer.","In step , the processing hardware receives motion compensation vector data from the software driver. In at least one embodiment, the motion compensation vector data corresponds to the same image block as the processed error image data stored in step . In one embodiment, the processing hardware uses a unique identifier associated with the received motion compensation vector data to determine where the stored error data the motion compensation vector data is associated with is stored. For example, in one embodiment, the memory address in which the associated error data is stored is passed along with the motion compensation vector data. The processing hardware simply reads the address provided by the software driver.","It should be noted that the IDCT component used to process the IDCT coefficients and the processing hardware used to process the motion compensation vector data can operate asynchronously. The software driver is used to coordinate and synchronize the activities of the IDCT component and the processing hardware. For example, while the processing hardware is busy processing a set of motion compensation vector data, the software driver can send more IDCT coefficients to be processed by the IDCT component. However, the memory used to store the processed error data related to the IDCT coefficients may become full. In one embodiment, the processing hardware sends an interrupt to the software driver to indicate that the error data has been read, allowing the memory to be cleared and more IDCT coefficients to be sent and processed. In step , the motion compensation vector data and the error image data are processed together to generate at least a portion of an image. In step , the generated image portion is output. In one embodiment, the image portion is output to a frame buffer in memory. In another embodiment, the image portion is output to a display device where it is displayed as a portion of an image. It will be appreciated that enough data to process an entire image frame or sets of image frames may be processed and output. In one embodiment, all data submitted to hardware, steps  and , is scrambled to protect the content represented by the data.","Referring now to , a method of optimizing video processing for image data containing only IDCT data is shown, according to one embodiment of the present invention. As previously discussed, motion compensation video data generally consists of error data and motion compensation vector data. The error data is compressed into IDCT coefficients. Occasionally, video data will consist of only IDCT coefficients. Since no associated motion compensation vectors are provided, 3D pipe  () is not needed for processing the image data. Since the processed IDCT data can be provided directly to frame buffer  (FIG. ), the memory space for IDCT results  () is also not needed.","In step , a software driver receives image data associated with a block of an image frame. As previously discussed, the software driver may perform processing on the received image data. For example, run-length decoding or de-quantization may be necessary for processing the image data. In step , the software driver identifies if the image data only has IDCT coefficient data associated with it. In one embodiment, the software driver identifies the IDCT-only image data when the image frame to be processed is an I-frame.","As previously discussed, portions of a single image frame may be stored as separate blocks of data, wherein the data includes Luma (Y) data and Chroma (UV) data. Compression of the data within a single block may be performed using data transformation, such as through the DCT, or by sub-sampling the Y and UV data. Accordingly, further compression may be performed among sets of consecutive frames, or video. A single frame may be compressed through inter-frame coding, wherein differences among blocks of sequential frames are used in data compression. A method of temporal prediction may be used for inter-frame coding of video data. Initially, a set of blocks corresponding to a first frame of data is transmitted. The data may include intra-frame coding among the blocks and the frame is generally referred to as an I-frame. Once the I-frame information has been sent, a frame with prediction data, referred to as a P-frame, may be transmitted. The P-frame data includes prediction vectors for the blocks in the preceding frame, such as motion vectors relating to blocks within a previously sent I-frame or P-frame.","By detecting when an I-frame is processed, the software driver can recognize that the image data is entirely made up of IDCT data. Alternatively, the software driver may determine the image data is entirely made up of IDCT data by analyzing the data packet regarding the image data it receives. In step , the IDCT-only data is submitted to an IDCT component, such as IDCT component  (FIG. ), in processing hardware. When submitting the IDCT-only data, the software driver may attach an identifier to the submitted data to indicate that there is no associated motion compensation data, allowing the IDCT component to initiate the optimization techniques described herein.","In step , the IDCT component processes the received IDCT coefficients to generate image data from the IDCT coefficients. In step , the IDCT component identifies if the IDCT data it processed was IDCT-only or if it had motion compensation data associated with it. The IDCT component may detect IDCT-only data according to an identifier attached to the data by the software driver, as discussed in step . If the data is not IDCT-only data, indicating it has associated motion compensation data, the IDCT component may perform according to a first mode of operation, as previously discussed in FIG. .","According to the first mode of operation, the IDCT component functions to prepare the IDCT data to be processed along with motion compensation data in a processing component, such as 3D pipe  (FIG. ). Accordingly, in step , the IDCT component stores the IDCT results in memory. In one embodiment, the IDCT results are 9-bit values. Due to memory spaces being allocated in 8-bit segments, 16-bit spaces are allocated for the values of the IDCT results. In step , the IDCT component sends an interrupt to the software driver indicating that the IDCT data has been processed and to request that the associated motion compensation vector data be sent to the processing hardware. The processing component can then process the motion compensation vector data with the stored IDCT results to generate the image data to store in the frame buffer.","Alternatively, in step , the IDCT component may determine the processed IDCT data has no associated motion compensation data. The IDCT component can process the data according to a second mode of operation. In the second mode of operation, the IDCT component can perform optimizations related to IDCT-only image data. The processing component, 3D pipe  () can be bypassed. The processed IDCT data can also store the IDCT results into frame buffer memory, freeing up the space associated with IDCT results  () in the first mode of operation. However, since the IDCT results are generally 9-bit values, the results must be converted to 8-bit values to store them as displayable image data in the frame buffer. Accordingly, in step , the IDCT results are converted to 8-bit values. In one embodiment, converting the results to 8-bits includes adding a bias value to the results and clamping the results to 8-bit values. Following the second mode of operation, in step , the converted results are stored directly in the frame buffer. The IDCT component can send a notification to the software driver, notifying it to send more IDCT data or to indicate the stored image frames are ready to be displayed.","Referring now to , a flow diagram describing the steps taken to optimize image processing for image data containing only motion compensation data is shown, according to one embodiment of the present invention. As previously discussed, I-frames are used as reference for P-frames and B-frames in motion compensation. P-frames and B-frames can use motion compensation vectors to indicate the motion of a block in a reference frame to the current frame. P-frames and B-frames can also use error data to indicate differences in image information between a referenced block and a current block.","As previously discussed in , error data is represented using IDCT coefficients. The IDCT coefficients are processed by an IDCT component, such as IDCT component  (FIG. ), to reproduce the error data. Motion compensation vector data is processed using a processing component, such as 3D pipe  (FIG. ). In one embodiment, when IDCT coefficients are included with the motion compensation data, the IDCT component must first process the IDCT coefficients. The 3D pipe is then used to process the motion compensation vector data with the processed IDCT results.","A frame of video may be composed of image blocks that are entirely composed of motion vectors, with no error data. For example, the video being represented may be of a simple bouncing ball. If the background does not change, a large portion of the frame can be simply represented using motion compensation vectors. If the ball is the only part of the frame that is changing, only a small subset of blocks would involve both IDCT coefficients and motion compensation vectors. The 3D pipe can then be used to process the pure motion compensation areas without waiting for IDCT results to be processed. In one embodiment, the image data associated with only motion compensation vector data is submitted to the 3D pipe. The motion compensation data with associated IDCT data can be withheld while other motion compensation data is processed, allowing the IDCT coefficients to be processed by the IDCT component, concurrently with other motion compensation data being processed in the 3D pipe.","In step , a software driver receives image data referring to blocks within a frame 505. Frame  includes blocks that contain only motion compensation vector data, motion compensation only blocks . Among motion compensation only blocks  is a block with both IDCT coefficients and motion compensation vector data, IDCT block . In one embodiment, the received image data is stored in buffers. In step , the software driver submits the motion compensation vector data associated with the motion compensation only blocks  to the 3D pipe in processing hardware. In step , the software driver submits the IDCT coefficients from IDCT block  to the IDCT component in the processing hardware.","The motion compensation data associated with IDCT block  can be withheld in the buffer, allowing the motion compensation blocks  to be processed. In step  the 3D pipe processes the submitted motion compensation vector data. In step , the submitted IDCT data is processed by the IDCT component. In one embodiment, step , submitting the IDCT data, is performed concurrently with the motion compensation data being processed in step . The processed IDCT data is stored in memory, such as in IDCT results  (FIG. ).","In step , after being processed by the 3D pipe, the image data associated with motion compensation blocks  are stored in a frame buffer. In step , the software driver submits the motion compensation data associated with IDCT block  to the 3D pipe. The software driver may include an identifier with the motion compensation vector data, notifying the 3D pipe to read the associated IDCT data that has already been processed by the IDCT component. In one embodiment, the identifier is the address in which the processed IDCT data is stored, allowing the 3D pipe to simply access the provided memory address to read the processed IDCT data. In step , the 3D pipe processes the motion compensation vector data submitted in step  along with the processed IDCT data from step . In step , the processed image data related to IDCT block  is stored in the frame buffer. By processing the data from the blocks that only contain motion compensation data concurrently with the IDCT data from other blocks, the idle time of the 3D pipe is reduced. Accordingly, the 3D pipe does not wait for completed IDCT results to process image data, allowing it to process other image data.","Referring now to , a video processing system for collecting and processing motion compensation video data is shown using a semaphore, according to one embodiment of the present invention. Software driver  handles video requests generated by an application program, such as video application , and routes the video requests to graphics chip  where they can be processed. As previously discussed, video application  can include video applications such as digital video disk (DVD) player software, a digital television tuner, an application programming interface (API), or video decoding software.","In one embodiment, software driver  stores inverse transformed error data, such as IDCT coefficients sets  and , in an IDCT buffer . Software driver  stores motion compensation (MC) vector data, such as MC data sets  and , in an MC buffer . The stored inverse transformed error data and MC data are held in buffers  and , respectively, until being sent to graphics chip .","Graphics chip  includes an IDCT component , similar in function to IDCT component  (FIG. ), for processing IDCT data sets sent from software driver . In one embodiment, processed error data from IDCT component  is stored in IDCT results  of memory . Graphics chip  also includes a 3D pipe , similar in operation to 3D pipe  (FIG. ), for processing MC data sets sent from software driver . In one embodiment, 3D pipe  processes the MC data sets with processed error data stored in IDCT results . Processed video data generated by 3D pipe  is stored in a frame buffer . As will be discussed further, a control component  is used to track the processing of motion compensation vector data and related error data. In one embodiment, control  includes a semaphore to halt the processing performed by 3D pipe , until error data has been received by IDCT component .","Software driver  coordinates the delivery of transformed error data to IDCT component , as well as the delivery of related motion compensation vector data to 3D pipe . According to one embodiment, the motion compensation vector data related to the transformed data cannot be processed until the inverse transformed error data has been processed into error data. In the embodiments described in , interrupt-based methods are described wherein software driver  () is issued interrupts from components  and  (FIG. ), indicating when a set of data has been processed. For example, IDCT component  may issue an interrupt indicating a unique identifier of processed error data. Using the unique identifier, software driver  can issue related motion compensation data to 3D pipe .","In an alternate embodiment, semaphore-based methods may be employed, wherein a semaphore in control component  is used by components  and  of graphics chip , to track and control the processing of received data. Semaphores describe protected variables, or registers, used to restrict specific processes. Access to alter the value of the semaphore is generally made through specific commands. In one embodiment, software driver  includes commands to alter a semaphore value, within graphics chip , when submitting transformed error data to IDCT component . Software driver  also includes a command with the motion compensation vector data indicating to 3D pipe  to wait until the value of the semaphore is incremented. For example, software driver  sends both sets of transformed error data, such as IDCT coefficients set , and motion compensation vector data, such as MC data set , to graphics chip , including the semaphore commands described.","In one embodiment, while 3D pipe  may have received motion compensation vector data, 3D pipe  waits until the value of the semaphore has been incremented. IDCT component  increments the semaphore value once IDCT component  receives the inverse transformed error data with the semaphore command. It should be noted that the semaphore value is incremented once the command to alter the semaphore value is received by IDCT component  and is performed regardless of whether the inverse transformed error data sent has been fully processed. Once the semaphore value has been incremented, 3D pipe  begins to process the motion compensation vector data, taking for granted that the related error data has already been processed. Once 3D pipe  has processed the motion compensation vector data, 3D pipe  can decrement the value of the semaphore, returning the semaphore to its original state, prior to increment by IDCT component . In one embodiment, altering the value of the semaphore includes incrementing the value of the semaphore so that, when incremented, the semaphore allows motion compensation vector data to be processed by 3D pipe . In a specific embodiment, the semaphore alternates between an asserted state in which the semaphore halts processing by 3D pipe , and an unasserted state in which the semaphore allows processing to be performed by 3D pipe .","It should be noted that if the increment commands related to the semaphore value are provided immediately after the transformed error data is issued, the increment in the semaphore value does not necessarily indicate the transformed error data has been fully processed. Accordingly, software driver  may need to account for the latency associated with processing in components  and . For example, software driver  may need to include \u201cdummy\u201d commands with the data to provide added latency to a receiving component, such as IDCT component . In another embodiment, the command to increment the semaphore value is provided at a later period of time after the IDCT coefficient sets are provided to IDCT component . In an alternate embodiment, a delay is applied by within hardware, such as graphics chip . A counter or timer (not shown) may be used by control  or IDCT component  before altering the semaphore value. Applying a delay for incrementing or altering the semaphore value insures that 3D pipe , does not grab error data values from memory, such as IDCT results , before they have been fully processed by IDCT component . It will be appreciated that unique identifiers, as described for the interrupt-based embodiment, may also be employed using semaphores in graphics chip . Identifiers corresponding to processed error data sets can be stored in memory, such as in identifier register . Control  can then be used to track the sets of processed data, and issue semaphore values to allow associated motion compensation data to be processed through 3D pipe . It will be appreciated that the selection of a semaphore-based implementation over an interrupt-based implementation may be made without departing from the spirit or scope of the present invention.","In the preceding detailed description of the preferred embodiments, reference has been made to the accompanying drawings which form a part thereof, and in which is shown by way of illustration specific preferred embodiments in which the invention may be practiced. These embodiments are described in sufficient detail to enable those skilled in the art to practice the invention, and it is to be understood that other embodiments may be utilized and that logical, mechanical, chemical and electrical changes may be made without departing from the spirit or scope of the invention. To avoid detail not necessary to enable those skilled in the art to practice the invention, the description may omit certain information known to those skilled in the art. Furthermore, many other varied embodiments that incorporate the teachings of the invention may be easily constructed by those skilled in the art. Accordingly, the present invention is not intended to be limited to the specific form set forth herein, but on the contrary, it is intended to cover such alternatives, modifications, and equivalents, as can be reasonably included within the spirit and scope of the invention. The preceding detailed description is, therefore, not to be taken in a limiting sense, and the scope of the present invention is defined only by the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Embodiments of the present invention are shown and described in the drawings presented herein. Various objects, advantages, features and characteristics of the present invention, as well as methods, operation and functions of related elements of structure, and the combination of parts and economies of manufacture, will become apparent upon consideration of the following description and claims with reference to the accompanying drawings, all of which form a part of this specification, and wherein:",{"@attributes":{"id":"P-00010","num":"00010"},"figref":"FIG. 1"},{"@attributes":{"id":"P-00011","num":"00011"},"figref":"FIG. 2"},{"@attributes":{"id":"P-00012","num":"00012"},"figref":"FIG. 3"},{"@attributes":{"id":"P-00013","num":"00013"},"figref":"FIG. 4"},{"@attributes":{"id":"P-00014","num":"00014"},"figref":"FIG. 5"},{"@attributes":{"id":"P-00015","num":"00015"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
