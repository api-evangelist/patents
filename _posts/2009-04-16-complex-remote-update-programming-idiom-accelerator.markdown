---
title: Complex remote update programming idiom accelerator
abstract: A remote update programming idiom accelerator is configured to detect a complex remote update programming idiom in an instruction sequence of a thread. The complex remote update programming idiom includes a read operation for reading data from a storage location at a remote node, a sequence of instructions for performing an update operation on the data to form result data, and a write operation for writing the result data to the storage location at the remote node. The remote update programming idiom accelerator is configured to determine whether the sequence of instructions is longer than an instruction size threshold and responsive to a determination that the sequence of instructions is not longer than the instruction size threshold, transmit the complex remote update programming idiom to the remote node to perform the update operation on the data at the remote node.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08145723&OS=08145723&RS=08145723
owner: International Business Machines Corporation
number: 08145723
owner_city: Armonk
owner_country: US
publication_date: 20090416
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"p":["This invention was made with United States Government support under Agreement No. HR0011-07-9-0002 awarded by DARPA. The Government has certain rights in the invention.","The present application relates generally to an improved data processing system and method. More specifically, the present application is directed to a mechanism to wake a sleeping thread based on an asynchronous event.","Multithreading is multitasking within a single program. Multithreading allows multiple streams of execution to take place concurrently within the same program, each stream processing a different transaction or message. In order for a multithreaded program to achieve true performance gains, it must be run in a multitasking or multiprocessing environment, which allows multiple operations to take place.","Certain types of applications lend themselves to multithreading. For example, in an order processing system, each order can be entered independently of the other orders. In an image editing program, a calculation-intensive filter can be performed on one image, while the user works on another. Multithreading is also used to create synchronized audio and video applications.","In addition, a symmetric multiprocessing (SMP) operating system uses multithreading to allow multiple CPUs to be controlled at the same time. An SMP computing system is a multiprocessing architecture in which multiple central processing units (CPUs) share the same memory. SMP speeds up whatever processes can be overlapped. For example, in a desktop computer, SMP may speed up the running of multiple applications simultaneously. If an application is multithreaded, which allows for concurrent operations within the application itself, then SMP may improve the performance of that single application.","If a process, or thread, is waiting for an event, then the process goes to sleep. A process is said to be \u201csleeping,\u201d if the process is in an inactive state. The thread remains in memory, but is not queued for processing until an event occurs. Typically, this event is detected when there is a change to a value at a particular address or when there is an interrupt.","As an example of the latter, a processor may be executing a first thread, which goes to sleep. The processor may then begin executing a second thread. When an interrupt occurs, indicating that an event for which the first thread was waiting, the processor may then stop running the second thread and \u201cwake\u201d the first thread. However, in order to receive the interrupt, the processor must perform interrupt event handling, which is highly software intensive. An interrupt handler has multiple levels, typically including a first level interrupt handler (FLIH) and a second level interrupt handler (SLIH); therefore, interrupt handling may be time-consuming.","In the former case, the processor may simply allow the first thread to periodically poll a memory location to determine whether a particular event occurs. The first thread performs a get instruction and a compare instruction (GET&CMP) to determine whether a value at a given address is changed to an expected value. When one considers that a computing system may be running thousands of threads, many of which are waiting for an event at any given time, there are many wasted processor cycles spent polling memory locations when an expected event has not occurred.","In one illustrative embodiment, a method is provided in a data processing system for performing a remote update. The method comprises detecting, by a remote update programming idiom accelerator of the data processing system, a complex remote update programming idiom in an instruction sequence of a thread running on a processing unit. The complex remote update programming idiom includes a read operation for reading data from a storage location at a remote node, a sequence of instructions for performing an update operation on the data to form result data, and a write operation for writing the result data to the storage location at the remote node. The method further comprises determining, by the remote update programming idiom accelerator, whether the sequence of instructions is longer than an instruction size threshold and responsive to a determination that the sequence of instructions is not longer than the instruction size threshold, transmitting the complex remote update programming idiom from the remote update programming idiom accelerator to the remote node to perform the update operation on the data at the remote node.","In another illustrative embodiment, a method is provided in a data processing system for performing a remote update. The method comprises determining an instruction size threshold value for the data processing system, sending the instruction size threshold value for the data processing system to each remote node connected to the data processing system within a heartbeat message, and receiving, at a remote update programming idiom accelerator within the data processing system, a complex remote update programming idiom from a remote node. The complex remote update programming idiom includes a read operation for reading data from a storage location local to the data processing system, at least one update operation for performing an operation on the data to form result data, and a write operation for writing the result data to the storage location local to the data processing system, wherein the sequence of instructions is not longer than the instruction size threshold value. The method further comprises reading, by the remote update programming idiom accelerator, the data from the storage location local to the data processing system, executing, by the remote update programming idiom accelerator, the sequence of instructions to perform the update operation on the data to form the result data, writing, by the remote update programming idiom accelerator, the result data to the storage location local to the data processing system, and returning a completion notification from the remote update programming idiom accelerator to the remote node informing the remote node that processing of the complex remote update programming idiom has been completed on the data processing system.","In another illustrative embodiment, a data processing system is provided comprising at least one processing unit executing a thread and a remote update programming idiom accelerator. The remote update programming idiom accelerator is configured to detect a complex remote update programming idiom in an instruction sequence of the thread. The complex remote update programming idiom includes a read operation for reading data from a storage location at a remote node, a sequence of instructions for performing an update operation on the data to form result data, and a write operation for writing the result data to the storage location at the remote node. The remote update programming idiom accelerator is configured to determine whether the sequence of instructions is longer than an instruction size threshold and responsive to a determination that the sequence of instructions is not longer than the instruction size threshold, transmit the complex remote update programming idiom to the remote node to perform the update operation on the data at the remote node.","These and other features and advantages of the present invention will be described in, or will become apparent to those of ordinary skill in the art in view of, the following detailed description of the exemplary embodiments of the present invention.","With reference now to the figures and in particular with reference to , an exemplary diagram of data processing environments is provided in which illustrative embodiments of the present invention may be implemented. It should be appreciated that  is only exemplary and is not intended to assert or imply any limitation with regard to the environments in which aspects or embodiments of the present invention may be implemented. Many modifications to the depicted environments may be made without departing from the spirit and scope of the present invention.",{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 1","b":["100","111","111","111","111","111","112","113","111","112","113"],"i":["a","n","a","n ","a ","a ","a","n ","n ","n. "]},"Processor cards -connect to symmetric multiprocessing (SMP) bus . SMP bus  supports a system planar  that contains processor cards -and memory cards . The system planar also contains data switch  and memory controller\/cache . Memory controller\/cache  supports memory cards  that includes local memory  having multiple dual in-line memory modules (DIMMs).","Data switch  connects to bus bridge  and bus bridge  located within a native I\/O (NIO) planar . As shown, bus bridge  connects to peripheral components interconnect (PCI) bridges  and  via system bus . PCI bridge  connects to a variety of I\/O devices via PCI bus . As shown, hard disk  may be connected to PCI bus  via small computer system interface (SCSI) host adapter . A graphics adapter  may be directly or indirectly connected to PCI bus . PCI bridge  provides connections for external data streams through network adapter  and adapter card slots -via PCI bus .","An industry standard architecture (ISA) bus  connects to PCI bus  via ISA bridge . ISA bridge  provides interconnection capabilities through NIO controller  having serial connections Serial 1 and Serial 2. A floppy drive connection , keyboard connection , and mouse connection  are provided by NIO controller  to allow data processing system  to accept data input from a user via a corresponding input device. In addition, non-volatile RAM (NVRAM)  provides a non-volatile memory for preserving certain types of data from system disruptions or system failures, such as power supply problems. A system firmware  also connects to ISA bus  for implementing the initial Basic Input\/Output System (BIOS) functions. A service processor  connects to ISA bus  to provide functionality for system diagnostics or system servicing.","The operating system (OS) resides on hard disk , which may also provide storage for additional application software for execution by data processing system. NVRAM  stores system variables and error information for field replaceable unit (FRU) isolation. During system startup, the bootstrap program loads the operating system and initiates execution of the operating system. To load the operating system, the bootstrap program first locates an operating system kernel type from hard disk , loads the OS into memory, and jumps to an initial address provided by the operating system kernel. Typically, the operating system loads into random-access memory (RAM) within the data processing system. Once loaded and initialized, the operating system controls the execution of programs and may provide services such as resource allocation, scheduling, input\/output control, and data management.","The present invention may be executed in a variety of data processing systems utilizing a number of different hardware configurations and software such as bootstrap programs and operating systems. The data processing system  may be, for example, a stand-alone system or part of a network such as a local-area network (LAN) or a wide-area network (WAN).",{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 1","FIG. 1"],"b":"115"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 2","b":["202","204","206","202","204","206","210","212","232","220"]},"In accordance with the illustrative embodiment, a wake-and-go mechanism for a microprocessor includes wake-and-go array  attached to the SMP fabric. The SMP fabric is a communication medium through which processors communicate. The SMP fabric may comprise a single SMP bus or a system of busses, for example. In the depicted example, the SMP fabric comprises bus . A thread, such as thread , for example, may include instructions that indicate that the thread is waiting for an event. The event may be an asynchronous event, which is an event that happens independently in time with respect to execution of the thread in the data processing system. For example, an asynchronous event may be a temperature value reaching a particular threshold, a stock price falling below a given threshold, or the like. Alternatively, the event may be related in some way to execution of the thread. For example, the event may be obtaining a lock for exclusive access to a database record or the like.","Typically, the instructions may comprise a series of get-and-compare sequences; however, in accordance with the illustrative embodiment, the instructions include instructions, calls to operating system  or API , or calls to a background sleeper thread, such as thread , for example, to update wake-and-go array . These instructions store a target address in wake-and-go array , where the event the thread is waiting for is associated with the target address. After updating wake-and-go array  with the target address, thread  may go to sleep.","When thread  goes to sleep, operating system  or other software or hardware saves the state of thread  in thread state storage , which may be allocated from memory  or may be a hardware private array within the processor (not shown) or pervasive logic (not shown). When a thread is put to sleep, i.e., removed from the run queue of a processor, the operating system must store sufficient information on its operating state such that when the thread is again scheduled to run on the processor, the thread can resume operation from an identical position. This state information is sometime referred to as the thread's \u201ccontext.\u201d The state information may include, for example, address space, stack space, virtual address space, program counter, instruction register, program status word, and the like.","If a transaction appears on bus  that modifies a value at an address in wake-and-go array , then operating system  may wake thread . Operating system  wakes thread  by recovering the state of thread  from thread state storage . Thread  may then determine whether the transaction corresponds to the event for which the thread was waiting by performing a get-and-compare operation, for instance. If the transaction is the event for which the thread was waiting, then thread  will perform work. However, if the transaction is not the event, then thread  will go back to sleep. Thus, thread  only performs a get-and-compare operation if there is a transaction that modifies the target address.","Alternatively, operating system  or a background sleeper thread, such as thread , may determine whether the transaction is the event for which the thread was waiting. Before being put to sleep, thread  may update a data structure in the operating system or background sleeper thread with a value for which it is waiting.","In one exemplary embodiment, wake-and-go array  may be a content addressable memory (CAM). A CAM is a special type of computer memory often used in very high speed searching applications. A CAM is also known as associative memory, associative storage, or associative array, although the last term is more often used for a programming data structure. Unlike a random access memory (RAM) in which the user supplies a memory address and the RAM returns the data value stored at that address, a CAM is designed such that the user supplies a data value and the CAM searches its entire memory to see if that data value is stored within the CAM. If the data value is found, the CAM returns a list of one or more storage addresses where the data value was found. In some architectures, a CAM may return the data value or other associated pieces of data. Thus, a CAM may be considered the hardware embodiment of what in software terms would be called an associative array.","Thus, in the exemplary embodiment, wake-and-go array  may comprise a CAM and associated logic that will be triggered if a transaction appears on bus  that modifies an address stored in the CAM. A transaction that modifies a value at a target address may be referred to as a \u201ckill\u201d; thus, wake-and-go array  may be said to be \u201csnooping kills.\u201d In this exemplary embodiment, the data values stored in the CAM are the target addresses at which threads are waiting for something to be written. The address at which a data value, a given target address, is stored is referred to herein as the storage address. Each storage address may refer to a thread that is asleep and waiting for an event. Wake-and-go array  may store multiple instances of the same target address, each instance being associated with a different thread waiting for an event at that target address. Thus, when wake-and-go array  snoops a kill at a given target address, wake-and-go array  may return one or more storage addresses that are associated with one or more sleeping threads.","In one exemplary embodiment, software may save the state of thread , for example. The state of a thread may be about 1000 bytes, for example. Thread  is then put to sleep. When wake-and-go array  snoops a kill at a given target address, logic associated with wake-and-go array  may generate an exception. The processor that was running thread  sees the exception and performs a trap. A trap is a type of synchronous interrupt typically caused by an exception condition, in this case a kill at a target address in wake-and-go array . The trap may result in a switch to kernel mode, wherein the operating system  performs some action before returning control to the originating process. In this case, the trap results in other software, such as operating system , for example, to reload thread  from thread state storage  and to continue processing of the active threads on the processor.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 3","FIG. 3"],"b":["302","304","306","300","302","304","306","310","312","332","320"]},"In an illustrative embodiment, when a thread, such as thread , first starts executing, a wake-and-go mechanism automatically allocates space for thread state in hardware private array  and space for a target address and other information, if any, in wake-and-go array . Allocating space may comprise reserving an address range in a memory, such as a static random access memory, that is hidden in hardware, such as processor , for example. Alternatively, if hardware private array  comprises a reserved portion of system memory, such as memory , then the wake-and-go mechanism may request a sufficient portion of memory, such as 1000 bytes, for example, to store thread state for that thread.","Thus hardware private array  may be a memory the size of which matches the size of thread state information for all running threads. When a thread ends execution and is no longer in the run queue of processor , the wake-and-go mechanism de-allocates the space for the thread state information for that thread.","In accordance with the illustrative embodiment, a wake-and-go mechanism for a microprocessor includes wake-and-go array  attached to the SMP fabric. The SMP fabric is a communication medium through which processors communicate. The SMP fabric may comprise a single SMP bus or a system of busses, for example. In the depicted example, the SMP fabric comprises bus . A thread, such as thread , for example, may include instructions that indicate that the thread is waiting for an event. The event may be an asynchronous event, which is an event that happens independently in time with respect to execution of the thread in the data processing system. For example, an asynchronous event may be a temperature value reaching a particular threshold, a stock price falling below a given threshold, or the like. Alternatively, the event may be related in some way to execution of the thread. For example, the event may be obtaining a lock for exclusive access to a database record or the like.","Typically, the instructions may comprise a series of get-and-compare sequences; however, in accordance with the illustrative embodiment, the instructions include instructions, calls to operating system  or API , or calls to a background sleeper thread, such as thread , for example, to update wake-and-go array . These instructions store a target address in wake-and-go array , where the event the thread is waiting for is associated with the target address. After updating wake-and-go array  with the target address, thread  may go to sleep.","When thread  goes to sleep, operating system  or other software or hardware within processor  saves the state of thread  in hardware private array  within processor . In an alternative embodiment, hardware private array may be embodied within pervasive logic associated with bus  or wake-and-go array . When a thread is put to sleep, i.e., removed from the run queue of processor , operating system  must store sufficient information on its operating state such that when the thread is again scheduled to run on processor , the thread can resume operation from an identical position. This state information is sometime referred to as the thread's \u201ccontext.\u201d The state information may include, for example, address space, stack space, virtual address space, program counter, instruction register, program status word, and the like, which may comprise about 1000 bytes, for example.","If a transaction appears on bus  that modifies a value at an address in wake-and-go array , then operating system  may wake thread . Operating system  wakes thread  by recovering the state of thread  from hardware private array . Thread  may then determine whether the transaction corresponds to the event for which the thread was waiting by performing a get-and-compare operation, for instance. If the transaction is the event for which the thread was waiting, then thread  will perform work. However, if the transaction is not the event, then thread  will go back to sleep. Thus, thread  only performs a get-and-compare operation if there is a transaction that modifies the target address.","Hardware private array  is a thread state storage that is embedded within processor  or within logic associated with bus  or wake-and-go array . Hardware private array  may be a memory structure, such as a static random access memory (SRAM), which is dedicated to storing thread state for sleeping threads that have a target address in wake-and-go array . In an alternative embodiment, hardware private array  may be a hidden area of memory . Hardware private array  is private because it cannot be addressed by the operating system or work threads.","Hardware private array  and\/or wake-and-go array  may have a limited storage area. Therefore, each thread may have an associated priority. The wake-and-go mechanism described herein may store the priority of sleeping threads with the thread state in hardware private array . Alternatively, the wake-and-go mechanism may store the priority with the target address in wake-and-go array . When a thread, such as thread , for example, goes to sleep, the wake-and-go mechanism may determine whether there is sufficient room to store the thread state of thread  in hardware private array . If there is sufficient space, then the wake-and-go mechanism simply stores the thread state in hardware private array .","If there is insufficient space in hardware private array , then if the hardware private array is a portion of system memory , then the wake-and-go mechanism may ask for more of system memory  to be allocated to the hardware private array .","If there is insufficient space in hardware private array , then the wake-and-go mechanism may compare the priority of thread  to the priorities of the threads already stored in hardware private array  and wake-and-go array . If thread  has a lower priority than all of the threads already stored in hardware private array  and wake-and-go array , then thread  may default to a flee model, such as polling or interrupt as in the prior art. If thread  has a higher priority than at least one thread already stored in hardware private array  and wake-and-go array , then the wake-and-go mechanism may \u201cpunt\u201d a lowest priority thread, meaning the thread is removed from hardware private array  and wake-and-go array  and converted to a flee model.","In an alternative embodiment, priority may be determined by other factors. For example, priority may be time driven. That is, the wake-and-go mechanism may simply punt the stalest thread in hardware private array  and wake-and-go array .","Alternatively, operating system  or a background sleeper thread, such as thread , may determine whether the transaction is the event for which the thread was waiting. Before being put to sleep, thread  may update a data structure in the operating system or background sleeper thread with a value for which it is waiting.","In one exemplary embodiment, wake-and-go array  may be a content addressable memory (CAM). A CAM is a special type of computer memory often used in very high speed searching applications. A CAM is also known as associative memory, associative storage, or associative array, although the last term is more often used for a programming data structure. Unlike a random access memory (RAM) in which the user supplies a memory address and the RAM returns the data value stored at that address, a CAM is designed such that the user supplies a data value and the CAM searches its entire memory to see if that data value is stored within the CAM. If the data value is found, the CAM returns a list of one or more storage addresses where the data value was found. In some architectures, a CAM may return the data value or other associated pieces of data. Thus, a CAM may be considered the hardware embodiment of what in software terms would be called an associative array.","Thus, in the exemplary embodiment, wake-and-go array  may comprise a CAM and associated logic that will be triggered if a transaction appears on bus  that modifies an address stored in the CAM. A transaction that modifies a value at a target address may be referred to as a \u201ckill\u201d; thus, wake-and-go array  may be said to be \u201csnooping kills.\u201d In this exemplary embodiment, the data values stored in the CAM are the target addresses at which threads are waiting for something to be written. The address at which a data value, a given target address, is stored is referred to herein as the storage address. Each storage address may refer to a thread that is asleep and waiting for an event. Wake-and-go array  may store multiple instances of the same target address, each instance being associated with a different thread waiting for an event at that target address. Thus, when wake-and-go array  snoops a kill at a given target address, wake-and-go array  may return one or more storage addresses that are associated with one or more sleeping threads.",{"@attributes":{"id":"p-0078","num":"0077"},"figref":["FIGS. 4A and 4B","FIG. 4A"],"b":["410","410","422","422","410","412"],"sub":"2 "},"When a transaction appears on SMP fabric  with an address that matches the target address A, array  returns the storage address that is associated with thread . The operating system (not shown) or some other hardware or software then wakes thread  by retrieving the thread state information from thread state storage  and placing the thread in the run queue for the processor. Thread  may then perform a compare-and-branch operation to determine whether the value written to the target address represents the event for which thread  is waiting. In the depicted example, the value written to the target address does not represent the event for which thread  is waiting; therefore, thread  goes back to sleep.","In one exemplary embodiment, software may save the state of thread , for example. Thread  is then put to sleep. When wake-and-go array  snoops a kill at target address A, logic associated with wake-and-go array  may generate an exception. The processor sees the exception and performs a trap, which results in a switch to kernel mode, wherein the operating system may perform some action before returning control to the originating process. In this case, the trap results in other software to reload thread  from thread state storage  and to continue processing of the active threads on the processor.","In one exemplary embodiment, thread state storage  is a hardware private array. Thread state storage  is a memory that is embedded within the processor or within logic associated with bus  or wake-and-go array . Thread state storage  may comprise memory cells that are dedicated to storing thread state for sleeping threads that have a target address in wake-and-go array . In an alternative embodiment, thread state storage  may be a hidden area of memory , for example. Thread state storage  may private in that it cannot be addressed by the operating system or work threads.","Turning to , thread  runs in a processor (not shown) and performs some work. Thread  executes a specialized processor instruction to update wake-and-go array , storing a target address Ain array . Then, thread  goes to sleep with thread state being stored in thread state storage .","When a transaction appears on SMP fabric  with an address that matches the target address A, array  returns the storage address that is associated with thread . The operating system (not shown) or some other hardware or software then wakes thread  by retrieving the thread state information from thread state storage  and placing the thread in the run queue for the processor. Thread  may then perform a compare-and-branch operation to determine whether the value written to the target address represents the event for which thread  is waiting. In the depicted example, the value written to the target address does represent the event for which thread  is waiting; therefore, thread  updates the array to remove the target address from array , and performs more work.",{"@attributes":{"id":"p-0084","num":"0083"},"figref":["FIGS. 5A and 5B","FIG. 5A"],"b":["510","510","530","522","530","530","530","522","510","512"],"sub":"2 "},"When a transaction appears on SMP fabric  with an address that matches the target address A, array  returns the storage address that is associated with thread . Operating system  or some other hardware or software then wakes thread  by retrieving the thread state information from thread state storage  and placing the thread in the run queue for the processor. Thread  may then perform a compare-and-branch operation to determine whether the value written to the target address represents the event for which thread  is waiting. In the depicted example, the value written to the target address does not represent the event for which thread  is waiting; therefore, thread  goes back to sleep.","In one exemplary embodiment, software may save the state of thread , for example. Thread  is then put to sleep. When wake-and-go array  snoops a kill at target address A, logic associated with wake-and-go array  may generate an exception. The processor sees the exception and performs a trap, which results in a switch to kernel mode, wherein operating system  may perform some action before returning control to the originating process. In this case, the trap results in the operating system  to reload thread  from thread state storage  and to continue processing of the active threads on the processor.","In one exemplary embodiment, thread state storage  is a hardware private array. Thread state storage  is a memory that is embedded within the processor or within logic associated with bus  or wake-and-go array . Thread state storage  may comprise memory cells that are dedicated to storing thread state for sleeping threads that have a target address in wake-and-go array . In an alternative embodiment, thread state storage  may be a hidden area of memory , for example. Thread state storage  may private in that it cannot be addressed by the operating system or work threads.","Turning to , thread  runs in a processor (not shown) and performs some work. Thread  makes a call to operating system  to update wake-and-go array . The call to operating system  may be an operating system call or a call to an application programming interface (not shown) provided by operating system . Operating system  then stores a target address Ain array . Then, thread  goes to sleep with thread state being stored in thread state storage .","When a transaction appears on SMP fabric  with an address that matches the target address A, array  returns the storage address that is associated with thread . Operating system  or some other hardware or software then wakes thread  by retrieving the thread state information from thread state storage  and placing the thread in the run queue for the processor. Thread  may then perform a compare-and-branch operation to determine whether the value written to the target address represents the event for which thread  is waiting. In the depicted example, the value written to the target address does represent the event for which thread  is waiting; therefore, thread  updates the array to remove the target address from array , and performs more work.",{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 6","b":["610","610","640","622","640","640","640","622","610","640","610","610","612"],"sub":["2 ","2"]},"When a transaction appears on SMP fabric  with an address that matches the target address A, array  returns the storage address that is associated with thread . Operating system  or some other hardware or software then wakes thread  by retrieving the thread state information from thread state storage  and placing the thread in the run queue for the processor. Background sleeper thread  may then perform a compare-and-branch operation to determine whether the value written to the target address represents the event for which thread  is waiting. If the value written to the target address does represent the event for which thread  is waiting, then background sleeper thread  does nothing. However, if the value written to the target address does represent the event for which thread  is waiting, then background sleeper thread  wakes thread . Thereafter, thread  updates the array  to remove the target address from array  and performs more work.","In one exemplary embodiment, software may save the state of thread , for example. Thread  is then put to sleep. When wake-and-go array  snoops a kill at target address A, logic associated with wake-and-go array  may generate an exception. The processor sees the exception and performs a trap, which results in a switch to kernel mode, wherein the operating system may perform some action before returning control to the originating process. In this case, the trap results in other software, such as background sleeper thread  to reload thread  from thread state storage  and to continue processing of the active threads on the processor.","In one exemplary embodiment, thread state storage  is a hardware private array. Thread state storage  is a memory that is embedded within the processor or within logic associated with bus  or wake-and-go array . Thread state storage  may comprise memory cells that are dedicated to storing thread state for sleeping threads that have a target address in wake-and-go array . In an alternative embodiment, thread state storage  may be a hidden area of memory , for example. Thread state storage  may private in that it cannot be addressed by the operating system or work threads.","As will be appreciated by one skilled in the art, the present invention may be embodied as a system, method, or computer program product. Accordingly, the present invention may take the form of an entirely hardware embodiment, an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to herein as a \u201ccircuit,\u201d \u201cmodule\u201d or \u201csystem.\u201d Furthermore, the present invention may take the form of a computer program product embodied in any tangible medium of expression having computer usable program code embodied in the medium.","Any combination of one or more computer usable or computer readable medium(s) may be utilized. The computer-usable or computer-readable medium may be, for example, but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, device, or propagation medium. More specific examples (a non-exhaustive list) of the computer-readable medium would include the following: an electrical connection having one or more wires, a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a portable compact disc read-only memory (CDROM), an optical storage device, a transmission media such as those supporting the Internet or an intranet, or a magnetic storage device. Note that the computer-usable or computer-readable medium could even be paper or another suitable medium upon which the program is printed, as the program can be electronically captured, via, for instance, optical scanning of the paper or other medium, then compiled, interpreted, or otherwise processed in a suitable manner, if necessary, and then stored in a computer memory. In the context of this document, a computer-usable or computer-readable medium may be any medium that can contain, store, communicate, propagate, or transport the program for use by or in connection with the instruction execution system, apparatus, or device. The computer-usable medium may include a propagated data signal with the computer-usable program code embodied therewith, either in baseband or as part of a carrier wave. The computer usable program code may be transmitted using any appropriate medium, including but not limited to wireless, wireline, optical fiber cable, radio frequency (RF), etc.","Computer program code for carrying out operations of the present invention may be written in any combination of one or more programming languages, including an object oriented programming language such as Java\u2122, Smalltalk\u2122, C++ or the like and conventional procedural programming languages, such as the \u201cC\u201dprogramming language or similar programming languages. The program code may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider). In addition, the program code may be embodied on a computer readable storage medium on the server or the remote computer and downloaded over a network to a computer readable storage medium of the remote computer or the users' computer for storage and\/or execution. Moreover, any of the computing systems or data processing systems may store the program code in a computer readable storage medium after having downloaded the program code over a network from a remote computing system or data processing system.","The illustrative embodiments are described below with reference to flowchart illustrations and\/or block diagrams of methods, apparatus (systems) and computer program products according to the illustrative embodiments of the invention. It will be understood that each block of the flowchart illustrations and\/or block diagrams, and combinations of blocks in the flowchart illustrations and\/or block diagrams, can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions\/acts specified in the flowchart and\/or block diagram block or blocks.","These computer program instructions may also be stored in a computer-readable medium that can direct a computer or other programmable data processing apparatus to function in a particular manner, such that the instructions stored in the computer-readable medium produce an article of manufacture including instruction means which implement the function\/act specified in the flowchart and\/or block diagram block or blocks.","The computer program instructions may also be loaded onto a computer or other programmable data processing apparatus to cause a series of operational steps to be performed on the computer or other programmable apparatus to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions\/acts specified in the flowchart and\/or block diagram block or blocks.","The flowchart and block diagrams in the figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods and computer program products according to various embodiments of the present invention. In this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and\/or flowchart illustration, and combinations of blocks in the block diagrams and\/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.",{"@attributes":{"id":"p-0101","num":"0100"},"figref":["FIGS. 7A and 7B","FIG. 7A"],"b":["702","704","706"]},"If the end of the thread is not reached in block , the processor determines whether the next instruction updates the wake-and-go array (block ). An instruction to update the wake-and-go array may be a specialized processor instruction, an operating system call, a call to a background sleeper thread, or a call to an application programming interface. If the next instruction does not update the wake-and-go array, operation returns to block  to perform more work.","If the next instruction does update the wake-and-go array in block , the processor updates the array with a target address associated with an event for which the thread is waiting (block ). The update to the wake-and-go array may be made by the thread through a specialized processor instruction, the operating system, or a background sleeper thread. Next, the operating system then determines whether to put the thread to sleep (block ). The operating system may keep the thread active in the processor if the processor is underutilized, for instance; however, the operating system may put the thread to sleep if there are other threads waiting to be run on the processor. If the operating system determines that the thread is to remain active, operation returns to block  to perform more work, in which case the thread may simply wait for the event.","In one exemplary embodiment, if the operating system determines that the thread is to be put to sleep in block , then the operating system or some other software or hardware saves the state of the thread (block ) and puts the thread to sleep (block ). Thereafter, operation proceeds to  where the wake-and-go mechanism monitors for an event. In one exemplary embodiment, software may save the state of the thread in thread state storage. The thread is then put to sleep.","In an alternative embodiment, if the operating system determines that the thread is to be put to sleep in block , then the operating system or some other software or hardware saves the state of the thread (block ) in the hardware private array and puts the thread to sleep (block ). Thereafter, operation proceeds to  where the wake-and-go mechanism monitors for an event.","With reference now to , the wake-and-go mechanism, which may include a wake-and-go array, such as a content addressable memory, and associated logic, snoops for a kill from the symmetric multiprocessing (SMP) fabric (block ). A kill occurs when a transaction appears on the SMP fabric that modifies the target address associated with the event for which a thread is waiting. The wake-and-go mechanism then performs a compare (block ) and determines whether the value being written to the target address represents the event for which the thread is waiting (block ). If the kill corresponds to the event for which the thread is waiting, then the operating system updates the array (block ) to remove the target address from the wake-and-go array. Thereafter, operation returns to block  in  where the operating system restarts the thread.","In one exemplary embodiment, when the wake-and-go mechanism snoops a kill at a target address, the wake-and-go mechanism may generate an exception. The processor sees the exception and performs a trap, which results in a switch to kernel mode, wherein the operating system may perform some action before returning control to the originating process. In this case, the trap results in other software to reload the thread from the thread state storage and to continue processing of the active threads on the processor in block .","In one exemplary embodiment, when the wake-and-go mechanism snoops a kill at a target address, software or hardware reloads the thread from the hardware private array and the processor continues processing the active threads on the processor in block .","If the kill does not correspond to the event for which the thread is waiting in block , then operation returns to block  to snoop a kill from the SMP fabric. In , the wake-and-go mechanism may be a combination of logic associated with the wake-and-go array, such as a CAM, and software within the operating system, software within a background sleeper thread, or other hardware.","In an alternative embodiment, the wake-and-go mechanism may be a combination of logic associated with the wake-and-go array and software within the thread itself. In such an embodiment, the thread will wake every time there is a kill to the target address. The thread itself may then perform a compare operation to determine whether to perform more work or to go back to sleep. If the thread decides to go back to sleep, it may again save the state of the thread. The over head for waking the thread every time there is a kill to the target address will likely be much less than polling or event handlers.","Prioritization of Threads",{"@attributes":{"id":"p-0112","num":"0111"},"figref":"FIGS. 8A and 8B","b":["802","804","806"]},"If the end of the thread is not reached in block , the processor determines whether the next instruction updates the wake-and-go array (block ). An instruction to update the wake-and-go array may be a specialized processor instruction, an operating system call, a call to a background sleeper thread, or a call to an application programming interface. If the next instruction does not update the wake-and-go array, operation returns to block  to perform more work.","If the next instruction does update the wake-and-go array in block , the wake-and-go mechanism determines whether there is sufficient space for the thread state in the hardware private array (block ). If there is sufficient space available, the wake-and-go mechanism allocates space for the thread state in the hardware private array (block ). This allocation may simply comprise reserving the requisite space for the thread space, which may be about 1000 bytes, for example. If the hardware private array is reserved portion of system memory, then allocating space may comprise requesting more system memory to be reserved for the hardware private array. Then, the wake-and-go mechanism saves the state of the thread in the hardware private array (block ), updates the wake-and-go array with the target address and other information, if any (block ), and puts the thread to sleep (block ). Thereafter, operation proceeds to  where the wake-and-go mechanism monitors for an event.","If there is insufficient space for the thread state available in the hardware private array in block , then the wake-and-go mechanism determines whether there is at least one lower priority thread in the hardware private array or wake-and-go array (block ). As described above, each thread may have an associated priority parameter that is stored in the hardware private array or wake-and-go array. Alternatively, priority may be determined by other factors, such as staleness. If there is at least one lower priority thread in the hardware private array, the wake-and-go mechanism removes the lower priority thread from the hardware private array and wake-and-go array (block ) and converts the lower priority thread to a flee model (block ). Thereafter, operation proceeds to block  to save the state of the new thread, update the wake-and-go array, and put the thread to sleep.","If there is not a lower priority thread in the hardware private array in block , the wake-and-go mechanism converts the new thread to a flee model (block ). Thereafter, operation proceeds to block  to put the thread to sleep.","With reference now to , the wake-and-go mechanism, which may include a wake-and-go array, such as a content addressable memory, and associated logic, snoops for a kill from the symmetric multiprocessing (SMP) fabric (block ). A kill occurs when a transaction appears on the SMP fabric that modifies the target address associated with the event for which a thread is waiting. The wake-and-go mechanism then performs a compare (block ) and determines whether the value being written to the target address represents the event for which the thread is waiting (block ). If the kill corresponds to the event for which the thread is waiting, then the operating system updates the wake-and-go array (block ) to remove the target address from the wake-and-go array. Then, the wake-and-go mechanism reloads the thread from the hardware private array (block ). Thereafter, operation returns to block  in  where the operating system restarts the thread.","In one exemplary embodiment, when the wake-and-go mechanism snoops a kill at a target address, software or hardware reloads the thread from the hardware private array and the processor continues processing the active threads on the processor in block .","If the kill does not correspond to the event for which the thread is waiting in block , then operation returns to block  to snoop a kill from the SMP fabric. In , the wake-and-go mechanism may be a combination of logic associated with the wake-and-go array, such as a CAM, and software within the operating system, software within a background sleeper thread, or other hardware.","Dynamic Allocation in Hardware Private Array",{"@attributes":{"id":"p-0121","num":"0120"},"figref":"FIGS. 9A and 9B","b":["902","904","906","908","910"]},"If the end of the thread is not reached in block , the processor determines whether the next instruction updates the wake-and-go array (block ). An instruction to update the wake-and-go array may be a specialized processor instruction, an operating system call, a call to a background sleeper thread, or a call to an application programming interface. If the next instruction does not update the wake-and-go array, operation returns to block  to perform more work.","If the next instruction does update the wake-and-go array in block , the wake-and-go mechanism updates the wake-and-go array with a target address associated with an event for which the thread is waiting (block ). The update to the wake-and-go array may be made by the thread through a specialized processor instruction, the operating system, or a background sleeper thread. Next, the operating system then determines whether to put the thread to sleep (block ). The operating system may keep the thread active in the processor if the processor is underutilized, for instance; however, the operating system may put the thread to sleep if there are other threads waiting to be run on the processor. If the operating system determines that the thread is to remain active, operation returns to block  to perform more work, in which case the thread may simply wait for the event.","If the operating system determines that the thread is to be put to sleep in block , then the operating system or some other software or hardware saves the state of the thread (block ) in the hardware private array and puts the thread to sleep (block ). Thereafter, operation proceeds to  where the wake-and-go mechanism monitors for an event.","With reference now to , the wake-and-go mechanism, which may include a wake-and-go array, such as a content addressable memory, and associated logic, snoops for a kill from the symmetric multiprocessing (SMP) fabric (block ). A kill occurs when a transaction appears on the SMP fabric that modifies the target address associated with the event for which a thread is waiting. The wake-and-go mechanism then performs a compare (block ) and determines whether the value being written to the target address represents the event for which the thread is waiting (block ). If the kill corresponds to the event for which the thread is waiting, then the operating system updates the wake-and-go array (block ) to remove the target address from the wake-and-go array. The wake-and-go mechanism then reloads the thread state from the hardware private array (block ). Thereafter, operation returns to block  in  where the operating system restarts the thread.","If the kill does not correspond to the event for which the thread is waiting in block , then operation returns to block  to snoop a kill from the SMP fabric. In , the wake-and-go mechanism may be a combination of logic associated with the wake-and-go array, such as a CAM, and software within the operating system, software within a background sleeper thread, or other hardware.","Hardware Wake-and-Go Mechanism",{"@attributes":{"id":"p-0128","num":"0127"},"figref":["FIG. 10","FIG. 10"],"b":["1002","1004","1006","1000","1002","1004","1006","1010","1032","1020"]},"Wake-and-go mechanism  is a hardware implementation within processor . In an alternative embodiment, hardware wake-and-go mechanism  may be logic associated with wake-and-go array  attached to bus  or a separate, dedicated wake-and-go engine as described in further detail below.","In accordance with the illustrative embodiment, hardware wake-and-go mechanism  is provided within processor  and wake-and-go array  is attached to the SMP fabric. The SMP fabric is a communication medium through which processors communicate. The SMP fabric may comprise a single SMP bus or a system of busses, for example. In the depicted example, the SMP fabric comprises bus . A thread, such as thread , for example, may include instructions that indicate that the thread is waiting for an event. The event may be an asynchronous event, which is an event that happens independently in time with respect to execution of the thread in the data processing system. For example, an asynchronous event may be a temperature value reaching a particular threshold, a stock price falling below a given threshold, or the like. Alternatively, the event may be related in some way to execution of the thread. For example, the event may be obtaining a lock for exclusive access to a database record or the like.","Processor  may pre-fetch instructions from storage (not shown) to memory . These instructions may comprise a get-and-compare sequence, for example. Wake-and-go mechanism  within processor  may examine the instruction stream as it is being pre-fetched and recognize the get-and-compare sequence as a programming idiom that indicates that thread  is waiting for data at a particular target address. A programming idiom is a sequence of programming instructions that occurs often and is recognizable as a sequence of instructions. In this example, an instruction sequence that includes load (LD), compare (CMP), and branch (BC) commands represents a programming idiom that indicates that the thread is waiting for data to be written to a particular target address. In this case, wake-and-go mechanism  recognizes such a programming idiom and may store the target address in wake-and-go array , where the event the thread is waiting for is associated with the target address. After updating wake-and-go array  with the target address, wake-and-go mechanism  may put thread  to sleep.","Wake-and-go mechanism  also may save the state of thread  in thread state storage , which may be allocated from memory  or may be a hardware private array within the processor (not shown) or pervasive logic (not shown). When a thread is put to sleep, i.e., removed from the run queue of a processor, the operating system must store sufficient information on its operating state such that when the thread is again scheduled to run on the processor, the thread can resume operation from an identical position. This state information is sometime referred to as the thread's \u201ccontext.\u201d The state information may include, for example, address space, stack space, virtual address space, program counter, instruction register, program status word, and the like.","If a transaction appears on bus  that modifies a value at an address in wake-and-go array , then wake-and-go mechanism  may wake thread . Wake-and-go mechanism  may wake thread  by recovering the state of thread  from thread state storage . Thread  may then determine whether the transaction corresponds to the event for which the thread was waiting by performing a get-and-compare operation, for instance. If the transaction is the event for which the thread was waiting, then thread  will perform work. However, if the transaction is not the event, then thread  will go back to sleep. Thus, thread  only performs a get-and-compare operation if there is a transaction that modifies the target address.","Alternatively, operating system  or a background sleeper thread, such as thread , may determine whether the transaction is the event for which the thread was waiting. Before being put to sleep, thread  may update a data structure in the operating system or background sleeper thread with a value for which it is waiting.","In one exemplary embodiment, wake-and-go array  may be a content addressable memory (CAM). A CAM is a special type of computer memory often used in very high speed searching applications. A CAM is also known as associative memory, associative storage, or associative array, although the last term is more often used for a programming data structure. Unlike a random access memory (RAM) in which the user supplies a memory address and the RAM returns the data value stored at that address, a CAM is designed such that the user supplies a data value and the CAM searches its entire memory to see if that data value is stored within the CAM. If the data value is found, the CAM returns a list of one or more storage addresses where the data value was found. In some architectures, a CAM may return the data value or other associated pieces of data. Thus, a CAM may be considered the hardware embodiment of what in software terms would be called an associative array.","Thus, in an exemplary embodiment, wake-and-go array  may comprise a CAM and associated logic that will be triggered if a transaction appears on bus  that modifies an address stored in the CAM. A transaction that modifies a value at a target address may be referred to as a \u201ckill\u201d; thus, wake-and-go array  may be said to be \u201csnooping kills.\u201d In this exemplary embodiment, the data values stored in the CAM are the target addresses at which threads are waiting for something to be written. The address at which a data value, a given target address, is stored is referred to herein as the storage address. Each storage address may refer to a thread that is asleep and waiting for an event. Wake-and-go array  may store multiple instances of the same target address, each instance being associated with a different thread waiting for an event at that target address. Thus, when wake-and-go array  snoops a kill at a given target address, wake-and-go array  may return one or more storage addresses that are associated with one or more sleeping threads.",{"@attributes":{"id":"p-0137","num":"0136"},"figref":["FIGS. 11A and 11B","FIG. 11A"]},"The wake-and-go mechanism may recognize the poll operation idiom. When the wake-and-go mechanism recognizes such a programming idiom, the wake-and-go mechanism may store the target address from GPR A in the wake-and-go array, where the event the thread is waiting for is associated with the target address. After updating the wake-and-go array with the target address, the wake-and-go mechanism may put the thread to sleep.","With reference now to , thread  may have a plurality of programming idioms. The wake-and-go mechanism may look ahead within thread  and load wake-and-go array  with the target address and other information, if any. Therefore, when thread  reaches each programming idiom while executing, the wake-and-go array  will already be loaded with the target address, and thread  may simply go to sleep until wake-and-go array snoops the target address on the SMP fabric.","The wake-and-go mechanism may perform a look-ahead polling operation for each programming idiom. In the depicted example, idioms A, B, C, and D fail. In those cases, the wake-and-go mechanism may update wake-and-go array . In this example, idiom E passes; therefore, there is no need to update wake-and-go array , because there is no need to put the thread to sleep when idiom E executes.","In one exemplary embodiment, the wake-and-go mechanism may update wake-and-go array  only if all of the look-ahead polling operations fail. If at least one look-ahead polling operation passes, then the wake-and-go mechanism may consider each idiom as it occurs during execution.",{"@attributes":{"id":"p-0142","num":"0141"},"figref":["FIGS. 12A and 12B","FIG. 12A"],"b":["1210","1210","1222","1210","1212","1222","1210"],"sub":["2 ","2"]},"When a transaction appears on SMP fabric  with an address that matches the target address A, array  returns the storage address that is associated with thread . The wake-and-go mechanism then wakes thread  by retrieving the thread state information from thread state storage  and placing the thread in the run queue for the processor. Thread  may then perform a compare-and-branch operation to determine whether the value written to the target address represents the event for which thread  is waiting. In the depicted example, the value written to the target address does not represent the event for which thread  is waiting; therefore, thread  goes back to sleep.","Turning to , thread  runs in a processor (not shown) and performs some work. Thread  executes a series of instructions that are a programming idiom for wake-and-go. The wake-and-go mechanism may recognize the poll operation idiom. When the wake-and-go mechanism recognizes such a programming idiom, the wake-and-go mechanism may store the target address Ain wake-and-go array , where the event the thread is waiting for is associated with the target address, and stores thread state information for thread  in thread state storage . After updating wake-and-go array  with the target address A, the wake-and-go mechanism may put the thread  to sleep.","When a transaction appears on SMP fabric  with an address that matches the target address A, array  returns the storage address that is associated with thread . The wake-and-go mechanism then wakes thread  by retrieving the thread state information from thread state storage  and placing the thread in the run queue for the processor. Thread  may then perform a compare-and-branch operation to determine whether the value written to the target address represents the event for which thread  is waiting. In the depicted example, the value written to the target address does represent the event for which thread  is waiting; therefore, thread  updates the array to remove the target address from array , and performs more work.",{"@attributes":{"id":"p-0146","num":"0145"},"figref":"FIGS. 13A and 13B","b":["1302","1304","1306"]},"If the end of the thread is not reached in block , the processor determines whether the next instructions comprise a wake-and-go idiom, such as a polling operation, for example (block ). A wake-and-go idiom may comprise a series of instructions, such as a load, compare, and branch sequence, for example. If the next instructions doe not comprise a wake-and-go idiom, the wake-and-go mechanism returns to block  to perform more work.","If the next instructions do comprise a wake-and-go idiom in block , the wake-and-go mechanism determines whether to put the thread to sleep (block ). The wake-and-go mechanism may keep the thread active in the processor if the processor is underutilized, for instance; however, the wake-and-go mechanism may put the thread to sleep if there are other threads waiting to be run on the processor. If the wake-and-go mechanism determines that the thread is to remain active, operation returns to block  to perform more work, in which case the thread may simply wait for the event.","If the wake-and-go mechanism determines that the thread is to be put to sleep in block , then the wake-and-go mechanism updates the array with a target address associated with an event for which the thread is waiting (block ). The update to the wake-and-go array may be made by the thread through a specialized processor instruction, the operating system, or a background sleeper thread. Next, the wake-and-go mechanism then saves the state of the thread (block ) and puts the thread to sleep (block ). Thereafter, operation proceeds to  where the wake-and-go mechanism monitors for an event.","With reference now to , the wake-and-go mechanism, which may include a wake-and-go array, such as a content addressable memory, and associated logic, snoops for a kill from the symmetric multiprocessing (SMP) fabric (block ). A kill occurs when a transaction appears on the SMP fabric that modifies the target address associated with the event for which a thread is waiting. The wake-and-go mechanism, the operating system, the thread, or other software then performs a compare (block ) and determines whether the value being written to the target address represents the event for which the thread is waiting (block ). If the kill corresponds to the event for which the thread is waiting, then the wake-and-go mechanism updates the array (block ) to remove the target address from the wake-and-go array. Thereafter, operation returns to block  in  where the operating system restarts the thread.","If the kill does not correspond to the event for which the thread is waiting in block , then operation returns to block  to snoop a kill from the SMP fabric. In , the wake-and-go mechanism may be a combination of hardware within the processor, logic associated with the wake-and-go array, which may be a CAM as described above, and software within the operating system, software within a background sleeper thread. In other embodiments, the wake-and-go mechanism may be other software or hardware, such as a dedicated wake-and-go engine, as described in further detail below.","Look-Ahead Polling",{"@attributes":{"id":"p-0153","num":"0152"},"figref":["FIGS. 14A and 14B","FIG. 14A"],"b":["1410","1410","1422","1410","1412","1422","1410"],"sub":["2 ","2"]},"When a transaction appears on SMP fabric  with an address that matches the target address A, array  returns the storage address that is associated with thread . The wake-and-go mechanism then wakes thread  by retrieving the thread state information from thread state storage  and placing the thread in the run queue for the processor. Thread  may then perform a compare-and-branch operation to determine whether the value written to the target address represents the event for which thread  is waiting. In the depicted example, the value written to the target address does not represent the event for which thread  is waiting; therefore, thread  goes back to sleep.","Turning to , thread  runs in a processor (not shown) and performs some work. Thread  executes a series of instructions that are a programming idiom for wake-and-go. The wake-and-go mechanism may recognize the poll operation idiom. When the wake-and-go mechanism recognizes such a programming idiom, the wake-and-go mechanism may store the target address Ain wake-and-go array , where the event the thread is waiting for is associated with the target address, and stores thread state information for thread  in thread state storage . After updating wake-and-go array  with the target address A, the wake-and-go mechanism may put the thread  to sleep.","When a transaction appears on SMP fabric  with an address that matches the target address A, array  returns the storage address that is associated with thread . The wake-and-go mechanism then wakes thread  by retrieving the thread state information from thread state storage  and placing the thread in the run queue for the processor. Thread  may then perform a compare-and-branch operation to determine whether the value written to the target address represents the event for which thread  is waiting. In the depicted example, the value written to the target address does represent the event for which thread  is waiting; therefore, thread  updates the array to remove the target address from array , and performs more work.",{"@attributes":{"id":"p-0157","num":"0156"},"figref":"FIG. 15","b":["1502","1504"]},"If the wake-and-go look-ahead engine has not reached the end of the thread in block , the wake-and-go look-ahead engine determines whether the thread comprises at least one wake-and-go programming idiom that indicates that the thread is waiting for a data value to be written to a particular target address (block ). If the thread does not comprise a wake-and-go programming idiom, operation ends.","If the thread does comprise at least one wake-and-go programming idiom in block , then the wake-and-go look-ahead engine performs load and compare operations for the at least one wake-and-go programming idiom (block ). Thereafter, the wake-and-go look-ahead engine determines whether all of the load and compare operations fail (block ). If all of the look-ahead polling operations fail, then the wake-and-go look-ahead engine updates the wake-and-go array for the at least one programming idiom (block ), and operation ends. If at least one look-ahead polling operation succeeds, then operation ends without updating the wake-and-go array. In an alternative embodiment, the look-ahead engine may set up the wake-and-go array without performing look-ahead polling.","Speculative Execution",{"@attributes":{"id":"p-0161","num":"0160"},"figref":["FIG. 16","FIG. 11B"],"b":["1610","1610"]},"Look-ahead wake-and-go engine  analyzes the instructions in thread  ahead of execution. Look-ahead wake-and-go engine  may recognize the poll operation idioms and perform look-ahead polling operations for each idiom. If the look-ahead polling operation fails, the look-ahead wake-and-go engine  populates wake-and-go array  with the target address. In the depicted example from , idioms A-D fail; therefore, look-ahead wake-and-go engine  populates wake-and-go array  with addresses A-A, which are the target addresses for idioms A-D.","If a look-ahead polling operation succeeds, look-ahead wake-and-go engine  may record an instruction address for the corresponding idiom so that the wake-and-go mechanism may have thread  perform speculative execution at a time when thread  is waiting for an event. During execution, when the wake-and-go mechanism recognizes a programming idiom, the wake-and-go mechanism may store the thread state in thread state storage . Instead of putting thread  to sleep, the wake-and-go mechanism may perform speculative execution.","When a transaction appears on SMP fabric  with an address that matches the target address A, array  returns the storage address that is associated with thread  to the wake-and-go mechanism. The wake-and-go mechanism then returns thread  to the state at which idiom A was encountered by retrieving the thread state information from thread state storage . Thread  may then continue work from the point of idiom A.",{"@attributes":{"id":"p-0165","num":"0164"},"figref":"FIG. 17","b":["1702","1704"]},"If the wake-and-go look-ahead engine has not reached the end of the thread in block , the wake-and-go look-ahead engine determines whether next sequence of instructions comprises a wake-and-go programming idiom that indicates that the thread is waiting for a data value to be written to a particular target address (block ). If the next sequence of instructions does not comprise a wake-and-go programming idiom, operation returns to block  to examine the next sequence of instructions in the thread. A wake-and-go programming idiom may comprise a polling idiom, as described with reference to .","If the next sequence of instructions does comprise a wake-and-go programming idiom in block , then the wake-and-go look-ahead engine performs load and compare operations for the wake-and-go programming idiom (block ). Thereafter, the wake-and-go look-ahead engine determines whether the load and compare operation passes (block ). If the look-ahead polling operation fails, then the wake-and-go look-ahead engine updates the wake-and-go array for the programming idiom (block ), and operation returns to block  to examine the next sequence of instructions in the thread. If the look-ahead polling operation passes, then the look-ahead wake-and-go engine records an instruction address for the successful programming idiom to be used for speculative execution later (block ). Thereafter, operation ends.",{"@attributes":{"id":"p-0168","num":"0167"},"figref":["FIGS. 18A and 18B","FIG. 18A"],"b":["1802","1804","1806"]},"If the end of the thread is not reached in block , the processor determines whether the next instructions comprise a wake-and-go idiom, such as a polling operation, for example (block ). A wake-and-go idiom may comprise a series of instructions, such as a load, compare, and branch sequence, for example. If the next instructions do not comprise a wake-and-go idiom, the wake-and-go mechanism returns to block  to perform more work.","If the next instructions do comprise a wake-and-go idiom in block , the wake-and-go mechanism saves the state of the thread (block ). Then, the wake-and-go mechanism determines whether to perform speculative execution (block ). The wake-and-go mechanism may make this determination by determining whether the look-ahead wake-and-go engine previously performed a successful look-ahead polling operation and recorded an instruction address.","If the wake-and-go mechanism determines that the processor cannot perform speculative execution, the wake-and-go mechanism puts the thread to sleep. Thereafter, operation proceeds to  where the wake-and-go mechanism monitors for an event.","If the wake-and-go mechanism determines that the processor can perform speculative execution from a successful polling idiom, the wake-and-go mechanism begins performing speculative execution from the successfully polled idiom (block ). Thereafter, operation proceeds to  where the wake-and-go mechanism monitors for an event.","With reference now to , the wake-and-go mechanism, which may include a wake-and-go array, such as a content addressable memory, and associated logic, snoops for a kill from the symmetric multiprocessing (SMP) fabric (block ). A kill occurs when a transaction appears on the SMP fabric that modifies the target address associated with the event for which a thread is waiting. The wake-and-go mechanism, the operating system, the thread, or other software then performs a compare (block ) and determines whether the value being written to the target address represents the event for which the thread is waiting (block ). If the kill corresponds to the event for which the thread is waiting, then the wake-and-go mechanism updates the array (block ) to remove the target address from the wake-and-go array. Thereafter, operation returns to block  in  where the processor performs more work.","If the kill does not correspond to the event for which the thread is waiting in block , then operation returns to block  to snoop a kill from the SMP fabric. In , the wake-and-go mechanism may be a combination of hardware within the processor, logic associated with the wake-and-go array, such as a CAM, and software within the operating system, software within a background sleeper thread, or other hardware.","Data Monitoring","Returning to , the instructions may comprise a get-and-compare sequence, for example. Wake-and-go mechanism  within processor  may recognize the get-and-compare sequence as a programming idiom that indicates that thread  is waiting for data at a particular target address. When wake-and-go mechanism  recognizes such a programming idiom, wake-and-go mechanism  may store the target address, the data thread  is waiting for, and a comparison type in wake-and-go array , where the event the thread is waiting for is associated with the target address. After updating wake-and-go array  with the target address, wake-and-go mechanism  may put thread  to sleep.","The get-and-compare sequence may load a data value from a target address, perform a compare operation based on an expected data value, and branch if the compare operation matches. Thus, the get-and-compare sequence had three basic elements: an address, an expected data value, and a comparison type. The comparison type may be, for example, equal to (=), less than (<), greater than (>), less than or equal to (\u2266), or greater than or equal to (\u2267). Thus, wake-and-go mechanism  may store the address, data value, and comparison value in wake-and-go array .","Thread  may alternatively include specialized processor instructions, operating system calls, or application programming interface (API) calls that instruct wake-and-go mechanism  to populate wake-and-go array  with a given address, data value, and comparison type.","Wake-and-go mechanism  also may save the state of thread  in thread state storage , which may be allocated from memory  or may be a hardware private array within the processor (not shown) or pervasive logic (not shown). When a thread is put to sleep, i.e., removed from the run queue of a processor, the operating system must store sufficient information on its operating state such that when the thread is again scheduled to run on the processor, the thread can resume operation from an identical position. This state information is sometime referred to as the thread's \u201ccontext.\u201d The state information may include, for example, address space, stack space, virtual address space, program counter, instruction register, program status word, and the like.","If a transaction appears on bus  that modifies a value at an address where the value satisfies the comparison type in wake-and-go array , then wake-and-go mechanism  may wake thread . Wake-and-go array  may have associated logic that recognizes the target address on bus  and performs the comparison based on the value being written, the expected value stored in wake-and-go array , and the comparison type stored in wake-and-go array . Wake-and-go mechanism  may wake thread  by recovering the state of thread  from thread state storage . Thus, thread  only wakes if there is a transaction that modifies the target address with a value that satisfies the comparison type and expected value.","Thus, in an exemplary embodiment, wake-and-go array  may comprise a CAM and associated logic that will be triggered if a transaction appears on bus  that modifies an address stored in the CAM. A transaction that modifies a value at a target address may be referred to as a \u201ckill\u201d; thus, wake-and-go array  may be said to be \u201csnooping kills.\u201d In this exemplary embodiment, the data values stored in the CAM are the target addresses at which threads are waiting for something to be written, an expected value, and a comparison type. The address at which a data value, a given target address, is stored is referred to herein as the storage address.","Each storage address may refer to a thread that is asleep and waiting for an event. Wake-and-go array  may store multiple instances of the same target address, each instance being associated with a different thread waiting for an event at that target address. The expected values and comparison types may be different. Thus, when wake-and-go array  snoops a kill at a given target address, wake-and-go array  may return one or more storage addresses that are associated with one or more sleeping threads. When wake-and-go array  snoops a kill at the given target address, wake-and-go array  may also return the expected value and comparison type to associated logic that performs the comparison. If the comparison matches, then the associated logic may return a storage address to wake-and-go mechanism  to wake the corresponding thread.",{"@attributes":{"id":"p-0183","num":"0182"},"figref":["FIG. 19","FIG. 10","FIG. 10"],"b":["1902","1908","1920","1902","1908","1008","1022","1912","1920","1914"]},"The wake-and-go array of each processor - snoops bus . If a transaction appears on bus  that modifies a value at an address where the value satisfies the comparison type in a wake-and-go array, then the wake-and-go mechanism may wake a thread. Each wake-and-go array may have associated logic that recognizes the target address on bus  and performs the comparison based on the value being written, the expected value stored in the wake-and-go array, and the comparison type stored in the wake-and-go array. Thus, the wake-and-go mechanism may only wake a thread if there is a transaction on bus  that modifies the target address with a value that satisfies the comparison type and expected value.",{"@attributes":{"id":"p-0185","num":"0184"},"figref":"FIG. 20","b":["2010","2010","2022","2010","2012","2022","2010"],"sub":["2","2","2 ","2","2","2"]},"When a transaction appears on SMP fabric  with an address that matches the target address A, logic associated with wake-and-go array  may perform a comparison based on the value being written, the expected value Dand the comparison type T. If the comparison is a match, then the logic associated with wake-and-go array  returns the storage address that is associated with thread . The wake-and-go mechanism then wakes thread  by retrieving the thread state information from thread state storage  and placing the thread in the run queue for the processor.","Parallel Lock Spinning","Returning to , the instructions may comprise a get-and-compare sequence, for example. In an illustrative embodiment, the instructions may comprise a sequence of instructions that indicate that thread  is spinning on a lock. A lock is a synchronization mechanism for enforcing limits on access to resources in an environment where there are multiple threads of execution. Generally, when a thread attempts to write to a resource, the thread may request a lock on the resource to obtain exclusive access. If another thread already has the lock, the thread may \u201cspin\u201d on the lock, which means repeatedly polling the lock location until the lock is free. The instructions for spinning on the lock represent an example of a programming idiom.","Wake-and-go mechanism  within processor  may recognize the spinning on lock idiom that indicates that thread  is spinning on a lock. When wake-and-go mechanism  recognizes such a programming idiom, wake-and-go mechanism  may store the target address in wake-and-go array  with a flag to indicate that thread  is spinning on a lock. After updating wake-and-go array  with the target address and setting the lock flag, wake-and-go mechanism  may put thread  to sleep. Thus, wake-and-go mechanism  allows several threads to be spinning on a lock at the same time without using valuable processor resources.","If a transaction appears on bus  that modifies a value at an address in wake-and-go array , then wake-and-go mechanism  may wake thread . Wake-and-go mechanism  may wake thread  by recovering the state of thread  from thread state storage . Thread  may then determine whether the transaction corresponds to the event for which the thread was waiting by performing a get-and-compare operation, for instance. If the lock bit is set in wake-and-go array , then it is highly likely that the transaction is freeing the lock, in which case, wake-and-go mechanism may automatically wake thread .",{"@attributes":{"id":"p-0191","num":"0190"},"figref":["FIGS. 21A and 21B","FIG. 21A"],"b":["2110","2110","2122","2124","2110","2112","2122","2110"],"sub":["1 ","1"]},"The processor may then run thread , which performs some work. The wake-and-go mechanism may recognize a spin on lock operation idiom, responsive to which the wake-and-go mechanism stores the target address Ain wake-and-go array , set the lock bit , and store thread state information for thread  in thread state storage . After updating wake-and-go array  with the target address A, the wake-and-go mechanism may put the thread  to sleep.","Turning to , thread  runs in the processor and performs some work. When a transaction appears on SMP fabric  with an address that matches the target address A, wake-and-go array  returns the storage address that is associated with thread . The wake-and-go mechanism then wakes thread  by retrieving the thread state information from thread state storage  and placing the thread in the run queue for the processor, because it is highly likely that the transaction is freeing the lock. Thread  may update array  to remove the target address. In the depicted example, thread  and thread  run concurrently in the processor. Thus, thread  and thread , and any number of other threads, may be spinning on a lock at the same time. When a lock is freed, the processor may wake the thread, such as thread  in the depicted example, and the remaining threads may continue \u201cspinning\u201d on the lock without consuming any processor resources.",{"@attributes":{"id":"p-0194","num":"0193"},"figref":"FIGS. 22A and 22B","b":["2202","2204","2206"]},"If the end of the thread is not reached in block , the processor determines whether the next instructions comprise a spin on lock idiom (block ). A spin on lock idiom may comprise a series of instructions, such as a load, compare, and branch sequence, for example. If the next instructions do not comprise a spin on lock idiom, the wake-and-go mechanism returns to block  to perform more work.","If the next instructions do comprise a spin on lock idiom in block , the wake-and-go mechanism updates the array with a target address associated with an event for which the thread is waiting (block ) and sets the lock bit in the wake-and-go array (block ). The update to the wake-and-go array may be made by the thread through a specialized processor instruction, the operating system, or a background sleeper thread. Next, the wake-and-go mechanism saves the state of the thread (block ) and puts the thread to sleep (block ). Thereafter, operation proceeds to  where the wake-and-go mechanism monitors for an event.","With reference now to , the wake-and-go mechanism, which may include a wake-and-go array, such as a content addressable memory (CAM), and associated logic, snoops for a kill from the symmetric multiprocessing (SMP) fabric (block ). A kill occurs when a transaction appears on the SMP fabric that modifies the target address associated with the event for which a thread is waiting. The wake-and-go mechanism determines whether the value being written to the target address represents the event for which the thread is waiting (block ). If the lock bit is set, then it is highly likely that the event is merely freeing the lock. If the kill corresponds to the event for which the thread is waiting, then the wake-and-go mechanism updates the array (block ) to remove the target address from the wake-and-go array and reloads the thread state for the thread that was spinning on the lock (block ). Thereafter, operation returns to block  in  where the operating system restarts the thread.","If the kill does not correspond to the event for which the thread is waiting in block , then operation returns to block  to snoop a kill from the SMP fabric. In , the wake-and-go mechanism may be a combination of hardware within the processor, logic associated with the wake-and-go array, such as a CAM, and software within the operating system, software within a background sleeper thread, or other hardware.","Central Repository for Wake-and-Go Engine","As stated above with reference to , while the data processing system in  shows one processor, more processors may be present depending upon the implementation where each processor has a separate wake-and-go array or one wake-and-go array stores target addresses for threads for multiple processors. In one illustrative embodiment, one wake-and-go engine stores entries in a central repository wake-and-go array for all threads and multiple processors.",{"@attributes":{"id":"p-0201","num":"0200"},"figref":"FIG. 23","b":["2302","2308","2320","2312","2320","2314","2350","2302","2308","2350","2350","2352"]},"Wake-and-go engine  snoops bus . If a transaction appears on bus  that modifies a value at an address where the value satisfies the comparison type in a wake-and-go array, then the wake-and-go engine  may wake a thread. Wake-and-go engine  may have associated logic that recognizes the target address on bus  and performs the comparison based on the value being written, the expected value stored in the wake-and-go array, and the comparison type stored in central repository wake-and-go array . Thus, wake-and-go engine  may only wake a thread if there is a transaction on bus  that modifies the target address with a value that satisfies the comparison type and expected value.",{"@attributes":{"id":"p-0203","num":"0202"},"figref":"FIG. 24","b":["2400","2402","2404","2406","2408","2410","2412","2414","2416"]},"The wake-and-go engine  may use the thread ID  to identify the thread and the CPU ID  to identify the processor. Wake-and-go engine  may then place the thread in the run queue for the processor identified by CPU ID . Wake-and-go engine  may also use thread state pointer  to load thread state information, which is used to wake the thread to the proper state.","Programming Idiom Accelerator","In a sense, a wake-and-go mechanism, such as look-ahead wake-and-go engine , is a programming idiom accelerator. A programming idiom is a sequence of programming instructions that occurs often and is recognizable as a sequence of instructions. In the examples described above, an instruction sequence that includes load (LD), compare (CMP), and branch (BC) commands represents a programming idiom that indicates that the thread is waiting for data to be written to a particular target address. Wake-and-go engine  recognizes this idiom as a wake-and-go idiom and accelerates the wake-and-go process accordingly, as described above. Other examples of programming idioms may include spinning on a lock or traversing a linked list.",{"@attributes":{"id":"p-0207","num":"0206"},"figref":"FIG. 25","b":["2502","2508","2520","2502","2514","2502","2550","2550","2550","2550"]},"As another example, if programming idiom accelerator  accelerates lock spinning programming idioms, programming idiom accelerator  may obtain the lock for the processor, if the lock is available, thus making the lock spinning programming sequence of instructions unnecessary. Programming idiom accelerator  may accelerate any known or common sequence of instructions or future sequences of instructions. Although not shown in , a data processing system may include multiple programming idiom accelerators that accelerate various programming idioms. Alternatively, programming idiom accelerator  may recognize and accelerator multiple known programming idioms. In one exemplary embodiment, each processor - may have programming idiom accelerators within the processor itself.","As stated above with respect to the wake-and-go engine, programming idiom accelerator  may be a hardware device within the data processing system. In an alternative embodiment, programming idiom accelerator  may be a hardware component within each processor -. In another embodiment, programming idiom accelerator  may be software within an operating system running on one or more of processors -. Thus, in various implementations or embodiments, programming idiom accelerator  may be software, such as a background sleeper thread or part of an operating system, hardware, or a combination of hardware and software.","More particularly, examples of programming idioms may include local locking, global locking, local barriers, global barriers, and global collectives. The programming idiom accelerator my perform operations to accelerate execution of the above programming idioms.","In one embodiment, the programming language may include hint instructions that may notify programming accelerator  that a programming idiom is coming.  is a series of instructions that are a programming idiom with programming language exposure in accordance with an illustrative embodiment. In the example depicted in , the instruction stream includes programming idiom , which in this case is an instruction sequence that includes load (LD), compare (CMP), and branch (BC) commands that indicate that the thread is waiting for data to be written to a particular target address.","Idiom begin hint  exposes the programming idiom to the programming idiom accelerator. Thus, the programming idiom accelerator need not perform pattern matching or other forms of analysis to recognize a sequence of instructions. Rather, the programmer may insert idiom hint instructions, such as idiom begin hint , to expose the idiom  to the programming idiom accelerator. Similarly, idiom end hint  may mark the end of the programming idiom; however, idiom end hint  may be unnecessary if the programming idiom accelerator is capable of identifying the sequence of instructions as a recognized programming idiom.","In an alternative embodiment, a compiler may recognize programming idioms and expose the programming idioms to the programming idiom accelerator.  is a block diagram illustrating a compiler that exposes programming idioms in accordance with an illustrative embodiment. Compiler  receives high level program code  and compiles the high level instructions into machine instructions to be executed by a processor. Compiler  may be software running on a data processing system, such as data processing system  in , for example.","Compiler  includes programming idiom exposing module , which parses high level program code  and identifies sequences of instructions that are recognized programming idioms. Compiler  then compiles the high level program code  into machine instructions and inserts hint instructions to expose the programming idioms. The resulting compiled code is machine code with programming idioms exposed . As machine code  is fetched for execution by a processor, one or more programming idiom accelerators may see a programming idiom coming up and perform an action to accelerate execution.",{"@attributes":{"id":"p-0215","num":"0214"},"figref":"FIG. 28","b":["2802","2804","2806"]},"If the sequence of code includes a recognized programming idiom, the compiler inserts one or more instructions to expose the programming idiom to the programming idiom accelerator (block ). The compiler compiles the sequence of code (block ). If the sequence of code does not include a recognized programming idiom in block , the compiler proceeds to block  to compile the sequence of code.","After compiling the sequence of code in block , the compiler determines if the end of the high level program code is reached (block ). If the end of the program code is not reached, operation returns to block  to consider the next sequence of high level program instructions. If the end of the program code is reached in block , then operation ends.","The compiler may recognize one or more programming idioms from a set of predetermined programming idioms. The set of predetermined programming idioms may correspond to a set of programming idiom accelerators that are known to be supported in the target machine. For example, if the target data processing system has a wake-and-go engine and a linked list acceleration engine, then the compiler may provide hints for these two programming idioms. The hint instructions may be such that they are ignored by a processor or data processing system that does not support programming idiom accelerators.","Remote Update","One common programming idiom is a remote update. Frequently, a thread includes a sequence of instructions that attempts to get a socket to read some data from a remote node, perform some operation or a more complex series of operations on the data, and write a result back to the remote node. In accordance with an illustrative embodiment, a programming idiom accelerator recognizes this programming idiom as a remote update and performs some action to accelerate execution of the idiom. More particularly, the programming idiom may send the remote update to the remote node to have the remote update performed remotely.",{"@attributes":{"id":"p-0221","num":"0220"},"figref":"FIG. 29","b":["2910","2940","2902","2910","2912","2914","2916","2930","2934","2936","2930","2912","2922","2914","2924","2916","2926","2922","2924","2926","2920"]},"Virtualization layer  virtualizes resources, such as processor resources, memory resources, hardware resources, and the like. From the perspective of virtualization layer , a (virtual) processor may be a whole physical processor, two or more physical processors, a processor core, two or more processor cores, a thread within a multi-threaded processor or core, or a time slice of a processor or core. Therefore, in the example depicted in , processors , ,  may be virtual processors from the perspective of virtualization layer . Virtualization layer  may allow several operating systems to run on data processing system  by creating an operating system instance, assigning a virtual processor and other resources to the operating system. Virtualization layer  may also de-allocate and reallocate resources dynamically and perform workload balancing in a workload manager (not shown).","In data processing system , processors , , and  connect to bus . Memory controller  and network interface controller  also connect to bus . Processor  executes operating system , processor  runs operating system , and processor  runs operating system . Operating systems , , and  run on top of virtualization layer . While the example depicted in  shows three processors in data processing system  and data processing system , each data processing system may include more or fewer processors depending upon the implementation or the allocation of processing resources by virtualization layers  and . Furthermore, a person of ordinary skill in the art will recognize that more than two data processing systems may be connected via network . A person of ordinary skill in the art may recognize that other modifications to the example depicted in  may be made without departing from the spirit and scope of the present invention.","In the depicted example, data processing system  and data processing system  may communicate over the Internet with network  representing a worldwide collection of networks and gateways that use the Transmission Control Protocol\/Internet Protocol (TCP\/IP) suite of protocols to communicate with one another. At the heart of the Internet is a backbone of high-speed data communication lines between major nodes or host computers, consisting of thousands of commercial, governmental, educational and other computer systems that route data and messages. Of course, data processing systems ,  may also be implemented to include a number of different types of networks, such as for example, an intranet, a local area network (LAN), a wide area network (WAN), or the like.  is intended as an example, not as an architectural limitation for different embodiments of the present invention, and therefore, the particular elements shown in  should not be considered limiting with regard to the environments in which the illustrative embodiments of the present invention may be implemented.","Operating systems - and - coordinate and provide control of various components within data processing systems , . As a client, the operating system may be a commercially available operating system such as Microsoft\u00ae Windows\u00ae XP (Microsoft and Windows are trademarks of Microsoft Corporation in the United States, other countries, or both). An object-oriented programming system, such as the Java\u2122 programming system, may run in conjunction with the operating system and provides calls to the operating system from Java\u2122 programs or applications executing on data processing systems ,  (Java is a trademark of Sun Microsystems, Inc. in the United States, other countries, or both).","As a server, data processing system  or data processing system  may be, for example, an IBM\u00ae eServer\u2122 System p\u00ae computer system, running the Advanced Interactive Executive (AIX\u00ae) operating system or the LINUX\u00ae operating system (eServer, System p, and AIX are trademarks of International Business Machines Corporation in the United States, other countries, or both while LINUX is a trademark of Linus Torvalds in the United States, other countries, or both). Data processing system  or data processing system  may be a symmetric multiprocessor (SMP) system. Alternatively, a single processor system may be employed.","Instructions for the operating system, the object-oriented programming system, and applications or programs are located on storage devices, such as a hard disk drive (not shown), and may be loaded into memory for execution by processors - or processors -. The processes of the illustrative embodiments may be performed by processing units - and - using computer usable program code, which may be located in a memory.","Bus  or bus  as shown in , may be comprised of one or more buses. Of course, the bus system may be implemented using any type of communication fabric or architecture that provides for a transfer of data between different components or devices attached to the fabric or architecture. A communication unit, such network interface controller  or network interface controller  of , may include one or more devices used to transmit and receive data.","A processor, such as processor  for example, may fetch instructions from memory via memory controller . As processor  fetches instructions, programming idiom accelerator  may look ahead to determine whether a programming idiom is coming up in the instruction stream. If programming idiom accelerator  recognizes a programming idiom, programming idiom accelerator  performs an action to accelerate execution of the programming idiom.","A thread running in processor , for example, may access data in local memory through the operating system , virtualization layer , bus , and memory controller . For a remote access, a thread running in processor , for example, may access data in memory at data processing system  through operating system , virtualization layer , bus , network interface controller , network , network interface controller  in data processing system , bus , and memory controller . In order to perform a remote access, the thread running in processor  must attempt to get a socket. A socket is a method of directing data to the appropriate application in a TCP\/IP network. The combination of the IP address of the station and a port number make up a socket. Thus, when a thread gets a socket, the thread must traverse software, network, and physical layers, and address spaces, which is a high-overhead process that may be performed repeatedly.","In accordance with an illustrative embodiment, programming idiom accelerator  recognizes a remote update programming idiom and performs an action to accelerate execution of the programming idiom. In the example depicted in , programming idiom accelerator  is illustrated as a special purpose hardware device, such as a dedicated processor, associated with bus . As such, programming idiom accelerator  resides in the hardware layer, either within each processor - and -, within logic for bus , or as a dedicated processor connected to bus . In an example embodiment, programming idiom accelerator  may reside in network interface controller  or, alternatively, a host channel adapter or other communications adapter. In one example embodiment, programming idiom accelerator  may be embodied within a host fabric interface (HFI) controller, which is described in co-pending patent application Ser. No. 12\/342,559, entitled \u201cManagement of Process-to-Process Communication Requests,\u201d Ser. No. 12\/342,616 entitled \u201cManagement of Process-to-Process Intra-Cluster Communication Requests,\u201d Ser. No. 12\/342,691 entitled \u201cManagement of Process-to-Process Inter-Cluster Communication Requests,\u201d Ser. No. 12\/342,881 entitled \u201cManagement of Application to I\/O Device Communication Requests Between Data Processing Systems,\u201d Ser. No. 12\/342,834 entitled \u201cManagement of Application to Application Communication Requests Between Data Processing Systems,\u201d all filed Dec. 23, 2008.","A common \u201cuniversal\u201d remote update may comprise a read, a simple operation, and a write. Examples of such a simple operation may include logic AND, logic OR, logic XOR, ADD, MULITPLY, atomic increment, compare, and so forth. Thus, a \u201cuniversal\u201d remote update idiom is a common and easily recognizable sequence of instructions that read data from a remote node, perform a common operation, and return a result to the remote node. Programming idiom accelerator  may see a sequence of instructions, such as a read\/AND\/write, and recognize this sequence of instructions as one of a set of \u201cuniversal\u201d remote update idioms. When programming idiom accelerator  identifies a remote update idiom, programming idiom accelerator  may send the remote update to programming idiom accelerator .","Programming idiom accelerator  may in turn perform the remote update, which is local to data processing system . When the update is completed, programming idiom accelerator  may then return a completion notification to programming idiom accelerator , which then notes that the remote update is complete. As such, programming idiom accelerator  may anticipate the needs of threads running on processors , , , and perform specialized actions to avoid the inefficient and high-overhead process of getting a socket to perform a remote update, particularly when these idioms appear frequently in program code.","In one illustrative embodiment, a remote update idiom may include a read operation to obtain some data from a remote node, a sequence of instructions to perform some complex operation on the data, and a write operation to return some result to the remote node. Thus, a \u201ccomplex\u201d remote update is a sequence of instructions that reads data from a remote node, performs a complex, variable-length sequence of operations on the data, and returns result data to the remote node.","Programming idiom accelerator  may see a sequence of instructions and recognize this sequence of instructions as a \u201ccomplex\u201d remote update idiom. When programming idiom accelerator  identifies a complex remote update idiom, programming idiom accelerator  may send the remote update, including the complex sequence of instructions, to programming idiom accelerator . Programming idiom accelerator  may in turn receive the complex sequence of instructions and perform the remote update, which is local to data processing system . When the update is completed, programming idiom accelerator  may then return a completion notification to programming idiom accelerator , which then notes that the remote update is complete.","In one illustrative embodiment, programming idiom accelerator  may comprise special purpose hardware, such as a dedicated processor, for performing the update operation. Thus, programming idiom accelerator  may perform the update and return a completion notification to programming idiom accelerator  without significantly affecting operation of processors , , .","Alternatively, in on illustrative embodiment, programming idiom accelerator  may submit a request to virtualization layer  for processing resources to perform the remote update. In turn, virtualization layer  may assign processing resources, i.e. virtual processor, for the purpose of performing the remote update. Programming idiom accelerator  may then send the complex sequence of instructions to the virtual processor, such as processor , which executes the instructions to perform the remote update. The virtual processor then notifies programming idiom accelerator  that the remote update is complete, and programming idiom accelerator  may then send a completion notification back to programming idiom accelerator .","Programming idiom accelerator  may have an inherent instruction size threshold, referred to herein as the dedicated threshold. Alternatively, programming idiom accelerator  may determine the dedicated threshold dynamically based on the demand for remote updates from other nodes. If the instruction size of the complex remote update is below the dedicated threshold, programming idiom accelerator  can perform the remote update without requesting processing resources from virtualization layer . However, if the instruction size of the complex remote update is above the dedicated threshold, programming idiom accelerator  may request processing resources from virtualization layer .","Virtualization layer  may provide feedback information to programming idiom accelerator . This feedback information may include processor utilization information based on the workload manager (not shown). Using the feedback information, programming idiom accelerator  may determine a dynamic instruction size, referred to herein as the remote threshold. If the instruction size of the complex remote update is below the remote threshold, virtualization layer  can assign processing resources to perform the remote update. Because processors , , and  are performing other work by executing their own threads locally, virtualization layer  will have limited resources to allocate for a complex remote update. Therefore, the more work data processing system  is doing locally, the fewer processing resources virtualization layer  can allocate for complex remote update, and the lower the remote threshold.","In one embodiment, the thread itself may indicate within an idiom hint that the complex remote update is to be performed by a virtual processor assigned by the virtualization layer . Thus, the programmer or compiler may recognize that the processing resources of the remote node are the most efficient and effective resources for performing this particular sequence of instructions. In this case, the programmer or compiler may insert idiom hints in the program code to expose the idiom and directly request that the idiom be performed by processor resources allocated by the virtualization layer.","It is common practice in clustering data processing, for example, for data processing systems to provide heartbeat information among the cluster. In accordance with an illustrative embodiment, data processing system  and data processing system  may send heartbeat information between each other. This heartbeat information may include the remote threshold. Then, when programming idiom accelerator  in data processing system  encounters a complex remote update idiom, programming idiom accelerator  compares the instruction size of the complex remote update to the remote threshold. If the instruction size of the complex remote update is greater than the remote threshold, then programming idiom accelerator  cannot send the complex remote update to data processing system . In this instance, the thread with the complex remote update idiom executes normally by getting a socket, reading data from the remote node, performing the complex sequence of operations on the data, and writing result data back to the remote node. However, if the instruction size of the complex remote update is less than the remote threshold, programming idiom accelerator  can send the complex remote update to programming idiom accelerator .",{"@attributes":{"id":"p-0242","num":"0241"},"figref":["FIGS. 30A and 30B","FIG. 30A"],"b":["3002","3002","3002","3004","3006","3006","3006","3002"]},"Turning to , operation begins, and the programming idiom accelerator determines whether the programming idiom accelerator receives a remote update from a remote node (block ). If the programming idiom accelerator does not receive a remote update from a remote node, then operation returns to block . If the programming idiom accelerator receives a remote update in block , then the data processing system performs the update locally (block ). Thereafter, the programming idiom accelerator notifies the sending node of completion (block ), and operation returns to block  to determine whether the programming idiom accelerator receives a remote update from a remote node.",{"@attributes":{"id":"p-0244","num":"0243"},"figref":["FIGS. 31A and 31B","FIG. 31A"],"b":["3102","3104","3102","3106","3102"]},"If the programming idiom accelerator encounters a remote update in block , the programming idiom accelerator determines whether the instruction size of the remote update is greater than the remote threshold for the remote node (block ). If the programming idiom accelerator determines that the instruction size is greater than the remote threshold, then the thread performs the remote update using a socket without acceleration (block ), and operation returns to block  to determine whether the programming idiom accelerator receives remote instruction size information.","However, if the programming idiom accelerator determines that the instruction size of the remote update is not greater than the remote threshold, then the programming idiom accelerator sends the remote update to the remote node (block . Then, the programming idiom accelerator determines whether a completion notification is received from the remote node (block ). If the programming idiom accelerator does not receive a completion notification, then operation returns to block . If the programming idiom accelerator receives a completion notification in block , operation returns to block  to determine whether the programming idiom accelerator receives remote instruction size information.","Turning to , operation begins, and the programming idiom accelerator determines whether the programming idiom accelerator receives processor instruction size information from the virtualization layer (block ). If the programming idiom accelerator receives processor instruction size information, then the programming idiom accelerator sets the remote threshold (block ) and sends the remote threshold to the other nodes in heartbeat information (block ). Then, the programming idiom accelerator sets the dedicated threshold (block ). The dedicated threshold may be constant or may be determined dynamically based on a number of remote updates received from other nodes.","Thereafter, or if the programming idiom accelerator does not receive processor instruction information in block , the programming idiom accelerator determines whether it receives a remote update from a remote node (block ). If the programming idiom accelerator does not receive a remote update from a remote node, then operation returns to block  to determine whether the programming idiom accelerator receives processor instruction size information.","If the programming idiom accelerator receives a remote update from a remote node in block , then the programming idiom accelerator determines whether the instruction size of the remote update is greater than the dedicated threshold (block ). If the programming idiom accelerator determines that the instruction size of the remote update is not greater than the dedicated threshold, the programming idiom accelerator performs the update locally in the dedicated processor of the programming idiom accelerator (block ). Then, the programming idiom accelerator notifies the remote node of completion of the remote update (block ), and operation returns to block  to determine whether the programming idiom accelerator receives processor instruction size information.","If the programming idiom accelerator determines that the instruction size of the remote update is greater than the dedicated threshold, then the programming idiom accelerator requests processor resources from the virtualization layer (block ). The programming idiom accelerator receives a virtual processor assignment from the virtualization layer (block ). The programming idiom accelerator then performs the update using the assigned processor resources (block ). Thereafter, operation proceeds to block  where the programming idiom accelerator notifies the remote node of completion of the remote update. Then, operation returns to block  to determine whether the programming idiom accelerator receives processor instruction size information from the virtualization layer.","Thus, the illustrative embodiments solve the disadvantages of the prior art by providing a wake-and-go mechanism for a microprocessor. When a thread is waiting for an event, rather than performing a series of get-and-compare sequences, the thread updates a wake-and-go array with a target address associated with the event. The target address may point to a memory location at which the thread is waiting for a value to be written. The thread may update the wake-and-go array using a processor instruction within the program, a call to the operating system, or a call to a background sleeper thread, for example. The thread then goes to sleep until the event occurs.","The wake-and-go array may be a content addressable memory (CAM). When a transaction appears on the symmetric multiprocessing (SMP) fabric that modifies the value at a target address in the CAM, which is referred to as a \u201ckill,\u201d the CAM returns a list of storage addresses at which the target address is stored. The operating system or a background sleeper thread associates these storage addresses with the threads waiting for an even at the target addresses, and may wake the one or more threads waiting for the event.","In one illustrative embodiment, a programming idiom accelerator identifies a remote update programming idiom. The programming idiom accelerator sends the remote update to a remote node to perform an operation on data at the remote node. A programming idiom accelerator at the remote node receives the remote update and performs the update as a local operation. The programming idiom accelerator at the remote node may request processing resources from a virtualization layer to perform the update. The programming idiom accelerator may determine a remote update threshold that limits the instruction size of remote updates that may be sent to a remote node. The programming idiom accelerator may also determine a dedicated threshold that limits the instruction size of remote updates that may be performed by the programming idiom accelerator.","It should be appreciated that the illustrative embodiments may take the form of a specialized hardware embodiment, a software embodiment that is executed on a computer system having general processing hardware, or an embodiment containing both specialized hardware and software elements that are executed on a computer system having general processing hardware. In one exemplary embodiment, the mechanisms of the illustrative embodiments are implemented in a software product, which may include but is not limited to firmware, resident software, microcode, etc.","Furthermore, the illustrative embodiments may take the form of a computer program product accessible from a computer-usable or computer-readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description, a computer-usable or computer-readable medium can be any apparatus that can contain, store, communicate, propagate, or transport the program for use by or in connection with the instruction execution system, apparatus, or device.","The medium may be an electronic, magnetic, optical, electromagnetic, or semiconductor system, apparatus, or device. Examples of a computer-readable medium include a semiconductor or solid state memory, magnetic tape, a removable computer diskette, a random access memory (RAM), a read-only memory (ROM), a rigid magnetic disk, and an optical disk. Current examples of optical disks include compact disk\u2014read-only memory (CD-ROM), compact disk\u2014read\/write (CD-R\/W) and DVD.","The program code of the computer program product may comprise instructions that are stored in a computer readable storage medium in a client or server data processing system. In a client data processing system embodiment, the instructions may have been downloaded over a network from one or more remote data processing systems, such as a server data processing system, a client data processing system, or a plurality of client data processing systems using a peer-to-peer communication methodology. In a server data processing system embodiment, the instructions may be configured for download, or actually downloaded, over a network to a remote data processing system, e.g., a client data processing system, for use in a computer readable storage medium with the remote data processing system.","A data processing system suitable for storing and\/or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus. The memory elements can include local memory employed during actual execution of the program code, bulk storage, and cache memories which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.","Input\/output or I\/O devices (including but not limited to keyboards, displays, pointing devices, etc.) can be coupled to the system either directly or through intervening I\/O controllers. Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems, cable modems and Ethernet cards are just a few of the currently available types of network adapters.","The description of the present invention has been presented for purposes of illustration and description, and is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. The embodiment was chosen and described in order to best explain the principles of the invention, the practical application, and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated."],"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS","p":["The invention, as well as a preferred mode of use and further objectives and advantages thereof, will best be understood by reference to the following detailed description of illustrative embodiments when read in conjunction with the accompanying drawings, wherein:",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIGS. 4A and 4B"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIGS. 5A and 5B"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIGS. 7A and 7B"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIGS. 8A and 8B"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIGS. 9A and 9B"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIGS. 11A and 11B"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIGS. 12A and 12B"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIGS. 13A and 13B"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIGS. 14A and 14B"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIGS. 18A and 18B"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIGS. 21A and 21B"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIGS. 22A and 22B"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIGS. 30A and 30B"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIGS. 31A and 31B"}]},"DETDESC":[{},{}]}
