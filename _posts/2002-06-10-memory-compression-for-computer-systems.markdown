---
title: Memory compression for computer systems
abstract: A computer system is provided including a processor, a persistent storage device, and a main memory connected to the processor and the persistent storage device. The main memory includes a compressed cache for storing data retrieved from the persistent storage device after compression and an operating system. The operating system includes a plurality of interconnected software modules for accessing the persistent storage device and a filter driver interconnected between two of the plurality of software modules for managing memory capacity of the compressed cache and the buffer cache.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06857047&OS=06857047&RS=06857047
owner: Hewlett-Packard Development Company, L.P.
number: 06857047
owner_city: Houston
owner_country: US
publication_date: 20020610
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","DISCLOSURE OF THE INVENTION","BEST MODES FOR CARRYING OUT THE INVENTION","Initialization","Read Operations","Write Operations"],"p":["1. Technical Field","The present invention relates generally to computer systems and more particularly to memory compression in computer systems.","2. Background Art","A computer system typically includes a processor and volatile memory, which stores data for computer programs (programs) being executed by the computer system. The volatile memory includes a main memory typically using dynamic random-access memory (DRAM) technology. The volatile memory might additionally include caches, typically using static random-access memory (SRAM) technology. The computer system also includes one or more persistent storage devices, such as hard disks, optical storage disks, magnetic tape drives, etc., which have high memory storage capacities.","In operation, a computer program reads and\/or writes data stored in the persistent storage devices using an Operating System (OS) running on the computer system. The OS invokes appropriate software modules to identify the locations on the persistent storage device where data being accessed is stored. Since access to the persistent storage device is very slow, the OS reads data in large units, known as \u201cdata blocks\u201d, and stores them in the main memory. The part of the main memory reserved by the OS for storing these data blocks is known as \u201cbuffer cache\u201d. The OS then passes the requested part of the data to the program by copying it into memory spaces of the computer program. The computer program then performs its read and write operations on the data in the main memory. If the computer program subsequently accesses data items in the same data block that were fetched earlier from the persistent storage device and that are still present in the buffer cache, the OS can provide these data items very quickly when compared to having to access the persistent storage device.","There are two typical approaches in which the buffer cache can identify the data blocks it stores. The first approach involves using the location of the data blocks on the persistent storage device, such as the physical addresses on a hard disk. The second approach involves using an abstraction provided by a file system. In this case, the identity of the data blocks will be logical addresses, namely the offset of the data blocks from the beginning of the file system.","The buffer cache has limited storage capacity compared to the large amounts of data that the computer programs can operate on for two main reasons. First, the buffer cache is part of the main memory, which is more expensive and hence has less storage capacity available than the persistent storage device. Second, the OS allocates only a part of the main memory to the buffer cache. Therefore, when working with large amounts of data, a program often finds that the data blocks it needs to read or write are not present in the buffer cache. This occurrence is referred to as a \u201cmiss\u201d in the buffer cache as opposed to a \u201chit\u201d when the data block is actually present. The miss forces the OS to temporarily stall the program while the data blocks are brought into the buffer cache from the persistent storage device.","Since the buffer cache contains only a small amount of storage capacity compared to the amount of data in the persistent storage device that will be accessed by the program, the buffer cache often runs out of storage space. Therefore, a replacement algorithm must be run to decide which data blocks in the buffer cache must be replaced to bring in the required data blocks from the persistent storage device. A simple policy for replacement of data blocks could be replacing the least-recently-used data. Some of the data blocks selected for replacement might contain data changes written by the program. Hence, they must be written back to the persistent storage device before they are replaced. These data blocks cannot be used for reading data from the persistent storage device until the changed data is written out first. This will delay the execution of the program further. To avoid this scenario, the OS periodically selects data blocks containing data written into by the program and schedules a single write operation to flush their data out to the persistent storage device. This allows the subsequent selection of these data blocks by the replacement algorithm without having to wait for the data to be written out. In most cases, however, the program will be delayed because it needs to wait for the data it requires to be read from the persistent storage device.","It should be noted that the latency of accessing a persistent-storage device, such as a hard disk, may be several orders of magnitude more than that of accessing memory such as the main memory or the buffer cache. With current technology, a hard-disk access might have a latency of several milliseconds, while a memory (main memory or buffer cache) access may take only several tens of nanoseconds. To hide the latency of accessing the persistent storage device, the OS can schedule some other task to run on the processor. However, this may not be possible for computer systems dedicated to one main task, such as computationally demanding computer simulations. The latency can be minimized if the access pattern can be predicted, allowing the OS to schedule the transfer of data blocks from the persistent storage device into buffer cache ahead of time. However, such prediction is not always successful.","Thus, programs run on computer systems have performance problems when accessing large amount of data stored on persistent storage devices because the access to persistent storage devices are much slower than primary storage devices such as the main memory. It is not always desirable to add extra memory due to factors such as cost or limitations imposed by the physical system design. The lack of adequate main memory can severely degrade the performance of these programs.","One prior solution for speeding up access to data stored on persistent storage devices involves modifying the OS to improve the performance of the buffer cache. However, such solution is both costly and time-consuming.","Another prior solution involves adding DRAM or SRAM to the controller for caching data blocks in persistent storage devices like hard disks. Compression techniques are applied to the hard disk cache using hardware or software running on a coprocessor. However, accessing these persistent storage devices is still quite slow.","Thus, there is a need for a system and a method of operation that would improve the performance of computer systems, which execute programs that require accessing large amount of data from persistent storage devices. This has been a long-term need and solutions have long eluded those skilled in the art.","The present invention provides a computer system and a method of operation, which includes a processor, a persistent storage device, and a main memory connected to the processor and the persistent storage device. The main memory includes a compressed cache for storing data retrieved from the persistent storage device after compression and an operating system. The operating system includes a plurality of interconnected software modules for accessing the persistent storage device and a filter driver interconnected between two of the plurality of software modules for managing memory capacity of the compressed cache. This improves the performance of computer systems, which execute programs that require accessing large amount of data from persistent storage devices.","The above and additional advantages of the present invention will become apparent to those skilled in the art from a reading of the following detailed description when taken in conjunction with the accompanying drawings.","The present invention uses a unique method to hide latency involved in accessing a persistent storage device such as a hard disk. In an embodiment of the present invention, a part of the main memory is allocated as a first buffer cache and a second buffer cache. The first buffer cache is regular cache and the second buffer cache is a \u201ccompressed cache\u201d where data blocks are stored after compression. A software module (\u201cfilter driver\u201d) is introduced wherein the filter driver is invoked every time the operating system (OS) reads or writes from the persistent storage device. The invocation is possible since the filter driver can be plugged into the OS with an OS compatible interface. No modification to the OS is required according to an embodiment of the present invention.","Referring now to  (PRIOR ART), therein is shown a prior art computer system . The computer system  includes a processor  and a memory system  connected to the processor . The memory system  includes processor caches , a main memory  connected to the processor caches , and a persistent storage device  connected to the main memory .","The processor caches  typically include static random-access memory (SRAM) or other memory devices, which allow very fast accesses.","The main memory  includes a virtual memory  and a buffer cache .","The virtual memory  functions as temporary memory storage for computer programs that are being executed by the computer system . The buffer cache  is a portion of the main memory , which is reserved for storing data blocks retrieved from the persistent storage device .","The persistent storage device  may include memory systems such as one or more hard disks.","Referring now to  (PRIOR ART), therein is shown a portion of a prior art Operating System (OS)  used by the computer system . The OS  is the software that controls the allocation and usage of hardware resources such as memory, processor time, disk space, and peripheral devices. The OS  includes a software stack  for accessing the persistent storage device . The software stack  has a multi-layer structure and includes a number of software modules. The first software module is a system call interface layer . The system call interface layer  defines the Application Programming Interface (API) functions a program can use to work with various types of resources. The API is a set of routines used by an application program to direct the performance of procedures by the OS . The system call interface layer  for the file system  implements functions such as open, read, write, close, etc.","The second software module is a file system layer , which is one layer below the system call interface layer . The file system layer  is a portion of the OS  and implements the overall functionality in which files are named, stored, and organized. The file system layer  includes files, directories, folders, the implementation of the API functions specified in the system call interface layer , and the information needed to locate and access these items.","The third software module is a logical volume manager layer , which is one layer below the file system layer . The logical volume manager layer  takes multiple hard disks and can aggregate physical locations from the multiple hard disks to present an abstraction of a single sequence of storage locations.","The fourth software module is a device driver layer , which is one layer below the logical volume manager layer . The device driver layer  contains low-level, sector-oriented task instructions used to control the persistent storage devices .","Referring now to , therein is shown a schematic block diagram of a computer system  in accordance with an embodiment of the present invention. The nomenclatures and numbers in  are the same as in  (PRIOR ART) for the same elements.","The computer system  includes the processor , and a memory system  connected to the processor . The memory system  includes the processor caches , a main memory  connected to the processor caches , and the persistent storage device  connected to the main memory .","The main memory  includes a virtual memory , a buffer cache , a compressed cache , and a temporary buffer . The virtual memory  functions as temporary memory storage for computer programs that are being executed by an Operating System (OS  as shown in ) used by the computer system . The buffer cache  is a portion of the main memory  for storing data blocks retrieved from the persistent storage device  without compression. The memory system , with the persistent storage device  excluded, is all considered to be non-persistent memory.","Compression and decompression algorithms, per se, are well known in the art and the present disclosure will allow those having ordinary skill in the art to understand their application in the present invention.","The compressed cache  is a second buffer cache formed by allocating a portion of the main memory . The compressed cache  stores the contents of the data blocks after compression. The compressed cache  forms another layer in the memory and storage hierarchy for holding data from the persistent storage devices .","The temporary buffer  is a portion in the main memory that is allocated on an as-needed basis for holding data temporarily when a certain algorithm is processed.","Referring to , therein is shown a schematic block diagram of the compressed cache  constructed in accordance with an embodiment of the present invention. The compressed cache  includes a number of memory spaces (buckets) - through -n (with only -, -, -, -, -, and -j shown). Each of the buckets includes a number of bytes, such as 128 bytes. Each of the buckets - to -j does not have the same number of bytes. For example, each of buckets - through - has a memory space of m bytes, while each of buckets - through - has a memory space of n bytes. In this case, m and n are integers, and m is not equal to n.","Referring to , therein is shown a schematic block diagram of an operating system (OS)  of the computer system  in accordance with an embodiment of the present invention. The nomenclatures and numbers in  are the same as in  (PRIOR ART) for the same elements.","The OS  includes the software stack  for accessing the persistent storage device . The software stack  has a multi-layer structure and includes the following software modules: the system call interface layer , the file system layer  below the system call interface layer , the logical volume manager layer  below the file system layer , and the device driver layer  below the logical volume manager layer . The OS  also includes a filter driver .","In this embodiment, the filter driver  is a software module that is plugged into (operatively connected to) the OS  using an interface , which is compatible with the OS . The filter driver  may be plugged in between any two layers in the software stack , for example between the system call interface layer  and the file system layer  as shown. To the layer above it, the filter driver  presents the same interface as the layer below it so it is transparent in both directions for reads and writes.","When the OS  invokes a \u201cread\u201d operation to the persistent storage devices , the filter driver  searches the compressed cache  for the required data blocks. If the required data blocks are present in the compressed cache , the filter driver  decompresses the required data blocks, either with or without hardware assistance, and returns them to the software module of the OS  that called it. If the required data blocks are not present in the compressed cache , the filter driver  calls the software module that is below it in the OS , which eventually results in access to the persistent storage device . Since decompressing the required data blocks can be done much faster than accessing the same data blocks from the persistent storage device , the read operation takes less time. This translates into reduced total execution time for the computer program.","During initialization, if the filter driver  is enabled, the filter driver  requests a certain amount of memory space (capacity) from the OS  based on configuration parameters provided.","This memory space, which forms the compressed cache , becomes another layer in the memory and storage hierarchy for holding data from the persistent storage devices .","The compressed cache  is then carved into a number of buckets such as buckets - to -j. Each of the buckets may have a different size. The buckets are initialized as a free pool of buckets maintained by the filter driver .","Referring to , therein is shown a flow diagram illustrating a read operation carried out by the filter driver  of the computer system .","When the OS  invokes a read operation, the filter driver  checks to determine if the required data blocks are present in the compressed cache  at a step .","If the required data blocks are present in the compressed cache  in a compressed form, the filter driver  identifies the buckets (- through -j) occupied by the data blocks and the compression algorithm used at a step .","The filter driver  calls the compression algorithm and decompresses the data blocks at a step . The decompression can be implemented in hardware and\/or software.","The uncompressed data blocks are then returned to the layer above the filter driver  at a step .","If the required data blocks are not present, the filter driver  allocates temporary storage and invokes the software module positioned one layer below it to complete the read operation by accessing the persistent storage device  at a step .","After the software module positioned one layer below the filter driver  receives the required data blocks, it supplies the required data blocks to the filter driver . The filter driver  supplies the data to the layer above the filter driver . A compression algorithm is selected, and the required data blocks are compressed at step . To fully utilize computer resources, the compression of the data blocks is preferably done during an idle period. An idle period is a period of time when there is low utilization of the processor . For example, when a program, which runs on the computer system , is waiting for data to come back from the persistent storage device , there will be low utilization of the processor . It is advantageous to perform data compression during the idle period as it makes use of the computer resources when the utilization of the processor  is low.","The output of the compression algorithm can take variable amount of space depending on the compressibility of the data blocks at a step . The output of the compression algorithm is sent to one or more buckets. Most likely the last bucket used will not be completely full. This wastage will be repeated to varying degree each time data blocks are compressed. To minimize this wastage, an embodiment of the present invention allocates buckets with different sizes (lengths) based on the size (length) of compressed data. When the output of the compression algorithm is stored, the bucket selection algorithm identifies the buckets to be used to minimize wastage.","At a step , the compressed data is stored in the buckets and the state of the buffer cache  is updated.","Referring to , therein is shown a flow diagram illustrating a write operation carried out by the filter driver  of the computer system .","When the OS  invokes a write operation, the filter driver  receives a \u201cwrite\u201d instruction from the software module above it at a step .","The write instruction is then directly passed to the software module below the filter driver  at a step . This is to ensure that the data is actually sent to the persistent storage device .","If the required data blocks are not present in the compressed cache  (a step ) and if a write allocation policy is not activated (a step ), no further action will be taken at a step . The write allocation policy determines whether a write operation should be held in the compressed cache  if the required data blocks are not already present in the compressed cache .","If the required data blocks are not present in the compressed cache  (the step ) and if the write allocation policy is activated (the step ), then a compression algorithm appropriate for the data is selected at a step . The data is then compressed at a step . After the data is compressed, buckets are allocated based on the size (length) of the data at a step . The compressed data is then stored in the allocated buckets at a step .","If the required data blocks are already present in the compressed cache  as determined at the step , it must then determine whether a write invalidate policy will be followed at step . The write invalidate policy determines whether a \u201cwrite\u201d should invalidate (erase) the contents of the compressed cache .","If the write invalidate policy is followed, the buckets containing the data are freed up at a step  and the state of the buffer cache  is updated accordingly at a step .","If the required data blocks are already present in the compressed cache  in a compressed form as determined at the step , and if the write invalidate policy is not to be followed as determined at the step , the temporary buffer  is allocated at a step .","The compressed data contained in the buckets in the compressed cache  is uncompressed and then written into the temporary buffer  at a step . The temporary buffer  is a buffer in the main memory  for temporarily holding the uncompressed data during this algorithm of the write operation.","If the data coming in at the step  completely overwrites the temporary buffer , the step , which involves the decompression of data will be skipped.","It should be noted that the state for the buffer cache  indicates the range of data blocks that are in the buckets. If the range of the data blocks required in the write operation matches exactly the range of data blocks that are in the buckets, decompression is not required.","To the extent that the data coming in at the step  shares buckets with any portion of the uncompressed data, the data coming in at the step  will overwrite such portion of the uncompressed data at a step .","After the new data is written into the temporary buffer , it must be compressed again at a step .","Based on the size (or length) difference of the newly compressed and the compressed data, some buckets might have to be allocated or freed at a step .","The newly compressed data is then stored in the buckets and the state of the buffer cache  is updated at a step .","It should be noted that the path involving the steps  through  is desirable when write operations are not frequent since further read operations will find data in the compressed cache . However, the disadvantage of this path is that the steps  through  consume CPU cycles, i.e., incur overhead.","The path involving the step  is desirable when write operations are frequent since there is no overhead incurred because the steps  through  are avoided. However, the disadvantage of this path is that future read operations will miss in the compressed cache  and will require access to persistent storage device.","Similarly, the path involving the steps  through  is desirable when write operations are not frequent since further read operations will find data in the compressed cache . However, the disadvantage of this path is that the steps  through  consume CPU cycles, i.e., incur overhead.","Also, the path involving the steps  through  is desirable when write operations are frequent since there is no overhead incurred because the steps  through  are avoided. However, the disadvantage of this path is that future read operations will miss in the compressed cache  and will require access to persistent storage device.","The different paths can be preset or monitored so as to change with the frequency of write operations to optimize operation.","Since the optimum choice of compression algorithm will be different based on the data being compressed, the filter driver  according to an embodiment of the present invention provides a choice of compression algorithms. At runtime, the type of data is detected and a compression algorithm is selected. For each sequence of data blocks compressed as a unit, the module maintains, in addition to the identity of the buckets used and the range of data blocks compressed, the choice of compression algorithm. On subsequent reads to the same data blocks, the corresponding decompression algorithm is selected.","Another optimization in one of the embodiments is to initially compress only a fraction of any data blocks read from the persistent storage device . Based on the compressibility, a prediction is made on the size of the entire compressed data. Using the prediction, three scenarios are possible. First, compression is continued for the rest of the data blocks. In this case, the compressed data is stored in the compressed cache . Second, compression is aborted, and the data blocks read are stored in the compressed cache  in the uncompressed form. Third, compression is aborted, and the data is not stored in the compressed cache .","In another embodiment, a counter is set up to record the number of times a policy, e.g., the write invalidation policy, is applied to a given piece of data. If the counter's record reached a certain threshold value, the policy may be switch from an activated state to a non-activated state, or vice versa.","The filter driver  is responsible for managing the memory capacity (space) of the compressed cache . When the compressed cache  is full, the filter driver  must free up an adequate number of buckets to accommodate the output of the compression algorithm. It does that by evicting some of the blocks currently present based on policies such as least-recently-used or least-frequently-used based on configuration parameters. Also, based on the configuration parameters, the filter driver  can request the OS  to allocate more memory capacity to the compressed cache  to increase the size of the compressed cache . The filter driver  may also shrink the compressed cache  by returning unneeded memory capacity to the OS . Since the ultimate aim is to reduce time spent in accessing the persistent storage device , the filter driver  monitors the rate at which read operations are sent to it and adjusts the size of the compressed cache  to keep this rate low.","Accordingly, an embodiment of the present invention uses a layered software module known as a filter driver to implement a compressed cache for data from persistent storage devices. The present invention does not require any knowledge of compression to be built into the OS, nor does it require support from the persistent storage devices or their software drivers. The present invention is flexible as it does not preclude the use of new compression algorithms, implemented in either hardware or software. Thus the present invention is suitable for all modern operation systems such as Windows NT and its variants, and different flavors of UNIX such as HP-UX and Linux. The compressed cache described herein could also be used to completely replace the original buffer cache (or reduce it in size significantly) since it hides accesses to persistent storage devices more effectively.","While the invention has been described in conjunction with a specific best mode, it is to be understood that many alternatives, modifications, and variations will be apparent to those skilled in the art in light of the aforegoing description. Accordingly, it is intended to embrace all such alternatives, modifications, and variations that fall within the spirit and scope of the included claims. All matters hither-to-fore set forth herein or shown in the accompanying drawings are to be interpreted in an illustrative and non-limiting sense."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"P-00017","num":"00017"},"figref":"FIG. 1"},{"@attributes":{"id":"P-00018","num":"00018"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"P-00019","num":"00019"},"figref":"FIG. 3"},{"@attributes":{"id":"P-00020","num":"00020"},"figref":"FIG. 4"},{"@attributes":{"id":"P-00021","num":"00021"},"figref":["FIG. 5","FIG. 3"]},{"@attributes":{"id":"P-00022","num":"00022"},"figref":["FIG. 6","FIG. 3"]},{"@attributes":{"id":"P-00023","num":"00023"},"figref":["FIG. 7","FIG. 3"]}]},"DETDESC":[{},{}]}
