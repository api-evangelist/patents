---
title: Methods and apparatus for voice information registration and recognized sentence specification in accordance with speech recognition
abstract: A group of sentences to be recognized is obtained from an application and, using parsing logic, each target sentence to be recognized is divided into words, e.g., speech recognition units. Thereafter, the words in each target sentence are examined to determine whether among them there are unknown words that are not registered in the speech recognition dictionary, but for which the sounds-like spelling is available. If an unknown word is found, a base form, for which the pronunciation is inferred from the sounds-like spelling, is prepared and is registered in the speech recognition dictionary. This base form is employed when the voice of a user, who has orally designated one of the sentences, is recognized.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06952675&OS=06952675&RS=06952675
owner: International Business Machines Corporation
number: 06952675
owner_city: Armonk
owner_country: US
publication_date: 20000907
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS"],"p":["The present invention relates to speech recognition, and relates more specifically to a method whereby voice is used to specify information displayed on a screen.","As is described in Japanese Unexamined Patent Publication No. Hei 10-320168, the disclosure of which is incorporated by reference herein, a conventional method is available whereby voice is used to specify information displayed on a screen. However, to use this method, a menu or a button in an application, and a sentence in which a link to a web is included must be registered using words that can be recognized by a speech recognition system.","All of the character strings for a menu, in this case, can be statically added to a speech recognition dictionary, but since the web link would tend to be changed daily, coping with such a change would exceed the capabilities of a method for which static registration is employed. In addition, if too many words, more than are necessary, are added to the dictionary, other problems, such as a reduction in the recognition accuracy or an extended processing time, may be encountered.","It is one object of the present invention to provide a speech recognition system whereby voice can be employed for the recognition of all sentences, even those including words that have not been registered in a speech recognition dictionary.","It is another object of the present invention to provide a speech recognition system that maintains predetermined standards for recognition accuracy and processing speed, and that requires only a small amount of resources.","It is an additional object of the present invention to provide a speech recognition system that is easy to use and that enables a user to intuitively understand an obtained result.","A group of sentences to be recognized is obtained from an application, and using parsing logic, each target sentence to be recognized is divided into words, speech recognition units. Thereafter, the words in each target sentence are examined to determine whether among them there are unknown words that are not registered in the speech recognition dictionary, but for which the sounds-like spelling is available. If an unknown word is found, a base form, for which the pronunciation is inferred from the sounds-like spelling, is prepared and is registered in the speech recognition dictionary. This base form is employed when the voice of a user is recognized who has orally designated one of the sentences.","According to one aspect of the present invention, provided is a voice information registration method, employed by a speech recognition apparatus, for which a voice input device is used, comprises:\n\n","According to one more aspect of the present invention, provided is a sentence specification method, employed by a speech recognition apparatus, for which a voice input device is used, comprises:\n\n","According to another aspect of the present invention, the group of target sentences is obtained from an application, and provided is the sentence specification method further comprises a step of generating a control message corresponding to the i-th sentence and transmitting the control message to the application.","According to an additional aspect of the present invention, provided is the sentence specification method in which a sounds-like spelling score is stored in correlation with the sounds-like spelling of the word, in which a pronunciation score is stored in correlation with the base form, and in which, when a function value that is obtained by using the sounds-like spelling score and the pronunciation score exceeds a threshold value, the base form is registered in a speech recognition dictionary.","According to one further aspect of the present invention, provided is a sentence specification method, employed by a speech recognition apparatus, for which a voice input device is used, comprises:\n\n","According to yet one more aspect of the present invention, provided is a speech recognition apparatus, for which a voice input device is used, comprises:\n\n","According to yet another aspect of the present invention, provided is a speech recognition apparatus, for which a voice input device is used, comprises:\n\n","According to yet an additional aspect of the present invention, provided is the speech recognition apparatus in which the sentence specification unit obtains the group of target sentences from an application, generates a control message corresponding to the i-th sentence, and transmits the control message to the application.","According to yet one further aspect of the present invention, provided is the speech recognition apparatus in which a sounds-like spelling score is stored in correlation with the sounds-like spelling of the word, in which a pronunciation score is stored in correlation with the base form, and in which, when a function value that is obtained by using the sounds-like spelling score and the pronunciation score exceeds a threshold value, the base form is registered in a speech recognition dictionary.","According to still one more aspect of the present invention, provided is a speech recognition apparatus, for which a voice input device is used, comprises:\n\n","According to still another aspect of the present invention, provided is a storage medium in which a program for specifying a sentence is stored to be executed by a speech recognition apparatus, for which a voice input device is used, the program comprising:\n\n","According to still an additional aspect of the present invention, provided is a storage medium in which a program for specifying a sentence is stored to be executed by a speech recognition apparatus, for which a voice input device is used, the program comprising:\n\n","According to still one further aspect of the present invention, the group of target sentences is obtained from an application, and provided is the storage medium in which program code is stored to instruct the speech recognition apparatus to generate a control message corresponding to the i-th sentence and to transmit the control message to the application.","According to again one more aspect of the present invention, provided is the storage medium in which a sounds-like spelling score is stored in correlation with the sounds-like spelling of the word; in which a pronunciation score is stored in correlation with the base form, and in which, when a function value that is obtained by using the sounds-like spelling score and the pronunciation score exceeds a threshold value, the base form is registered in a speech recognition dictionary.","According to again another aspect of the present invention, provided is a storage medium in which a program for specifying a sentence is stored to be executed by a speech recognition apparatus, for which a voice input device is used, the program comprising:\n\n","These and other objects, features and advantages of the present invention will become apparent from the following detailed description of illustrative embodiments thereof, which is to be read in connection with the accompanying drawings.","A. Hardware Arrangement",{"@attributes":{"id":"p-0037","num":"0108"},"figref":"FIG. 1","b":["100","100","1","4","1","4","2","13","30","20","26","28","29","30","28","26","29","2","19","25","27"]},"A floppy disk (or another storage medium, such as an MO or a CD disk) is inserted into the floppy disk drive  (or into the storage medium driver , ,  or , such as an MO or a CD-ROM), and code or data is read for a computer program, which interacts with an operating system and which issues instructions to the CPU  for carrying out the present invention, that is stored on the floppy disk, or on the hard disk drive  or in a ROM . The code for this computer program, which is executed by loading it into the memory , can either be compressed or can be divided into multiple segments for storage on multiple storage mediums.","The speech recognition system  further comprises user interface hardware components. These user interface hardware components include a pointing device (a mouse, a joystick or a track ball) , for entering on-screen positioning information; a keyboard , for keying in data; and display devices  and , for providing visual data for a user. A loudspeaker  is used to receive audio signals from an audio controller  via an amplifier , and to output the signals as sound. A voice input device or microphone  is also provided for inputting speech.","The speech recognition system  of the present invention can communicate with another computer via a serial port  and a modem, or via a communication adaptor , such as one for a token ring.","The present invention can be carried out by a common personal computer (PC); by a workstation; by a computer incorporated in a television set, a facsimile machine or another electrical home appliance; by a computer (car navigation system, etc.) mounted in a vehicle or an airplane; or by a combination of the components described above. It should be noted, however, that these components are merely examples, and that not all of them are required for the present invention. In particular, since the present invention relates to the vocal specification of character information, components such as the serial port  and the parallel port  are not necessarily required.","A preferable operating system for the speech recognition system  is one that supports a GUI multi-window environment, such as WindowsNT, Windows9x or Windows3.x (trademarks of Microsoft), OS\/2 (a trademark of IBM), MacOS (a trademark of Apple Corp.), Linux (a trademark of Linus Torvalds), or the X-WINDOW system (a trademark of MIT) on AIX (a trademark of IBM); one that runs in a character-based environment, such as PC-DOS (a trademark of IBM) or MS-DOS (a trademark of Microsoft); a real-time OS, such as OS\/Open (a trademark of IBM) or VxWorks (a trademark of Wind River Systems, Inc.); or an OS that is incorporated in a network computer, such as JavaOS. However, the operating system for the present invention is not specifically limited.","B. System Configuration",{"@attributes":{"id":"p-0043","num":"0114"},"figref":"FIG. 2"},"The speech recognition system in a preferred embodiment of the present invention comprises a recognized character specification unit , a speech recognition engine , an unknown word detector , a base form generator , a voice input unit , an application , a speech recognition dictionary , an unknown word detection dictionary , and a pronunciation dictionary .","The recognized character specification unit  enters a group of sentences obtained from the application , and selects one of the sentences in the group based on a speech recognition sentence that is received from the speech recognition engine . In addition, the recognized character specification unit  controls certain components, such as the unknown word detector .","The speech recognition engine  employs the speech recognition dictionary  to analyze voice information that is actually input and to output a speech recognition sentence.","The unknown word detector  receives data for the target sentence from the recognized character specification unit , employs the unknown word detection dictionary  to detect an unknown word, and outputs the sounds-like spelling and the score for the unknown word. In addition, based on a predetermined logic, the unknown word detector  corrects the sounds-like spelling score.","In a case where the inscription of a word consists of only kana characters, and the sound of the word is not prolonged, the score is corrected to 1. In a case wherein the accuracy attained by a speech recognition dictionary is not high and a word that matches the inscription is recorded in the dictionary (for example, if a dictionary for kana\/kanji conversion is employed), the sounds-like spelling score is corrected and a lower value is awarded if the sound of the word can be prolonged. The sounds-like spelling score can be designated in accordance with statistical information, such as the probability of an occurrence, and an empirical value.",{"@attributes":{"id":"p-0049","num":"0120"},"figref":["FIG. 3","FIG. 3"],"b":["233","301","303","305","307","233"]},"The base form generator  uses an unknown word inscription and sounds-like spelling information that are input to conduct a search of the pronunciation dictionary , and outputs a corresponding base form and a pronunciation score. In addition, a predetermined logic is employed by the base form generator  to correct a pronunciation score. The pronunciation score can be set based on statistical information, such as the probability of an occurrence, and an empirical value. And based on the sounds-like spelling score and the pronunciation score, a function value, obtained, for example, by multiplying the sounds-like spelling score by the pronunciation score, can be set as the score for a base form corresponding to the unknown word.",{"@attributes":{"id":"p-0051","num":"0122"},"figref":["FIG. 4","FIG. 4"],"b":["235","311","313","315","235"]},"The voice input unit  fetches voice information from the user into the system.","The application  is a web browser used for this embodiment. However, the application  can also be software, such as a word processor or a presentation application, that processes character information, or software that processes image information that can be converted into character information.","The functional blocks in  have been explained. These functional blocks are logical blocks. This does not mean that they must each be implemented by a hardware unit or a software unit; rather, they can be implemented by employing a combination composed of common hardware and software.","C. Operating procedures","In a preferred embodiment of the present invention, generally, the following four operating procedures are employed when sentences for which recognition processing is to be performed are specified.\n\n","The pronunciation score can be set based on statistical information, such as the probability of an occurrence, and an empirical value. And based on the sounds-like spelling score and the pronunciation score, a function value, obtained, for example, by multiplying the sounds-like spelling score by the pronunciation score, can be set as the score for a base form corresponding to an unknown word. An explanation will now be given for the processing employed to obtain a group of target sentences when a web browser is employed as the application .","First, the use of a method that employs MSAA (Microsoft Active Accessibility) (\u201cMSAA (Microsoft Active Accessibility)\u201d is a trademark of Microsoft Corp.) will be considered. MSAA can be employed for a program version in a Windows environment. When an API (application programming interface) defined using MSAA is employed, the information for controlling the page displayed on a browser can be obtained in real time. The information indicating the existence of links can be extracted from the control information and defined as a group of target sentences.","Second, the use of a method for directly reading an HTML (HyperText Markup Language) document will be considered. According to this method, a source corresponding to a page displayed on a browser is obtained. HTML tags for the source are analyzed, and sentences at tags indicating the existence of links can be extracted and defined as a group of target sentences.","Third, the use of a method for employing an API provided by a browser will be considered. A browser, such as the Internet Explorer (\u201cInternet Explorer\u201d is a trademark of Microsoft Corp.) or the Netscape Navigator (\u201cNetscape Navigator\u201d is a trademark of Netscape Communications), provides a unique API for extracting information from a displayed page. The state of the page and link information can be obtained by using the API.","The above methods are merely examples, and the idea on which the present invention is based is not thereby limited. Various methods have been proposed for extracting sentences from target applications, and the alternation of the extraction method before executing the present invention should present no problems for one having ordinary skill in the art.","C-2. Detection of Unknown Word","Unknown words are detected in extracted sentences. In this instance, an unknown word is one that is recognized as being a word but that is not registered in the speech recognition dictionary , and that has a base form that is unknown to the system.",{"@attributes":{"id":"p-0062","num":"0137"},"figref":"FIG. 5","b":["205","403","405","407"]},"When a space is inserted between words, in English, for example, it is comparatively easy to divide a sentence into words by using the information provided by the space. However, in languages such as Japanese, for which Chinese characters are used, generally no space is provided between words. Therefore, the parsing method (segmentation or word division) is employed for complicated word division and unknown word detection. Since at the time of the submission of the present application, however, various parsing logics, which are appropriate for sentence navigation, had already been proposed, and since parsing logic is well known to one having the ordinary skill in the art, no detailed explanation will be given for the parsing method that is used.","To continue, each of the parsed words is examined, and a word that is determined to be unknown (is entered in the unknown word detection dictionary ) is registered in the unknown array U (steps  to ). In this embodiment, a set consisting of the sounds-like spelling, a pronunciation inscription and a sounds-like spelling score, which is explained while referring to , is registered for one unknown word.","Examples of target sentences that have has been parsed are shown in . In the sentences, \u201c\/\u201d is a delimiter, and an unknown word is underlined.","The sentence  means:","\u201cYokohama Municipal Subway is extended from Totsuka to Shonandai.\u201d The word  is \u201cYokohama,\u201d  is \u201cMunicipal,\u201d  is \u201cSubway,\u201d  is \u201cis,\u201d  is \u201cTotsuka,\u201d  is \u201cfrom,\u201d  is \u201chonandai,\u201d  is \u201cto\u201d and  is \u201cextended.\u201d","The sentence  means:","\u201cThe e-business of IBM is satisfactory.\u201d","The word  is \u201cIBM,\u201d  is \u201cof,\u201d  is \u201ce-business,\u201d  is \u201cis,\u201d  and  are \u201csatisfactory.\u201d","The sentence  means:","\u201cMy name is Tahara.\u201d","The word  means \u201cI\u201d and  means the possessive case.","The word  is \u201cname,\u201d  is \u201cis,\u201d  is \u201cTahara\u201d and  is a redundant word for the politeness.","C-3. Acquisition of Base Form Corresponding to Unknown Word, and Registration of Pertinent Base Form in Speech Recognition Dictionary","An explanation will now be given for the processing performed to acquire a base form corresponding to an unknown word, and the processing performed to register the base form in a speech recognition dictionary.  is a flowchart for explaining this processing. First, when an unknown word is detected (step ), it is registered (steps  to ).",{"@attributes":{"id":"p-0076","num":"0151"},"figref":"FIGS. 7 and 8","b":"425"},"This process will now be described while referring to the flowcharts in . First, the number of unknown words is established (step ), and then the base form generator  searches the pronunciation dictionary  for the sounds-like spelling of each unknown word and generates a base form group corresponding to the unknown words. A pronunciation score is then calculated that corresponds to each base form. But when there is no corresponding base form in the pronunciation dictionary (step ), an error process (step ) is performed.","A combination of pronunciations is obtained for each target sentence (steps  and ).  are flowcharts for obtaining a combination consisting of a target sentence NS and the n-th corresponding pronunciation. In Example 1 of , the number of unknown words is two, there is a sounds-like spelling combination and there is pronunciation combination consisting of \u201cTotsuka\u201d  and \u201cShonandai,\u201d  and the number of combinations is \u201cthe number of unknown words\u201d\u00d7\u201cthe number of sounds-like spellings\u201d\u00d7\u201cthe number of pronunciations.\u201d In , these combinations are acquired.","Initially, a score is set for the target sentence (step ), and then the score for each unknown word is employed to calculate the score for the entire target sentence (steps  to ). The score for each of the unknown words is calculated based on the sounds-like spelling score and the pronunciation score. When the score for the target sentence exceeds a threshold value (step ) and an unknown word has not yet been registered (step ), the base form for the unknown word, in the combination for which the score exceeds the threshold value, is registered in the speech recognition dictionary (registered in accordance with a combination of a word inscription and a base form) (step ). In this embodiment, an unknown word is registered temporarily, and is erased from memory when the recognized character specification unit  or the speech recognition engine  is halted.","The above individual steps will be explained using a variable in the flowchart. First, B(i, j(i)) denotes a pronunciation choice generated for unknown word U(i) (1\u2266i\u2266n), which is a segment of a target sentence STRNAVI. The inequality 1\u2266j(i)\u2266CN(i) is established for j(i) and CN(i), which is the number of pronunciation choices generated for U(i). And the score for the pronunciation choice B(i, j(i)) is defined as S(i, j(i)).","Assuming that the score for a known word is 1, the score (STRNAVI) for sentence STRNAVI, which is to be navigated, is\n\n","When a threshold value used to determine whether the pronunciation should be dynamically registered is defined as TH1, from among SCN sets of S(STRNAVI), a group of pronunciations (B(1, j(1)), B(2, j(2)), . . . , B(n, j(n))) that satisfies S(STRNAVI)\u2267TH1 is dynamically registered in the recognition dictionary. Since all the words now become known words, the sentence S(STRNAVI) can be recognized.","A case wherein Example 1 is employed is shown below. The pronunciation (Baseform) is not the same as the sounds-like spelling; however, for convenience sake, it is represented as \u201csounds-like spelling.\u201d","\u201cYokohama\/shiei\/chikatetsu\/ga\/\/kara\/\/made\/encho\u201d",{"@attributes":{"id":"p-0084","num":"0161"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u201cTotsuka\u201d"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"91pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u201ctotsuka\u201d","score: 0.9 S(1, 1)"]},{"entry":[{},"\u201ctozuka\u201d","score: 0.5 S(1, 2)"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u201cShonandai\u201d"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"91pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u201cshounandai\u201d","score: 0.9 S(2, 1)"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"TH1: 0.5"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"S(1, 1)*S(2, 1) = 0.9*0.9 = 0.81 \u2267 0.5"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Registered (\u201cTotsuka (totsuka)\u201d \u201cShonandai"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"(shounandai)\u201d)"]},{"entry":[{},"S(1, 2)*(2, 1) = 0.5*0.9 = 0.45 < 0.5"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Not registered"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},{"@attributes":{"id":"p-0085","num":"0162"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u201cTahara\u201d"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u201ctahara\u201d","score: 0.83 S(1, 1)"]},{"entry":[{},"\u201ctawara\u201d","score: 0.56 S(1, 2)"]},{"entry":[{},"\u201ctabara\u201d","score: 0.45 S(1, 3)"]},{"entry":[{},"\u201ctabaru\u201d","score: 0.20 S(1, 4)"]},{"entry":[{},"\u201cdahara\u201d","score: 0.02 S(1, 5)"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003TH1: 0.5",{}]},{"entry":[{},"S(1, 1) = 0.83 \u2267 0.5","registered (\u201cTahara (tahara)\u201d)"]},{"entry":[{},"S(1, 2) = 0.56 \u2267 0.5","registered (\u201cTahara (tawara)\u201d)"]},{"entry":[{},"S(1, 3) = 0.45 < 0.5","not registered"]},{"entry":[{},"S(1, 4) = 0.20 < 0.5","not registered"]},{"entry":[{},"S(1, 5) = 0.02 < 0.5","not registered"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}},"br":{},"ul":{"@attributes":{"id":"ul0021","list-style":"none"},"li":["RegistBaseform(TH)","begin","Extract unknown word U(i) from STRNAVI","for i=1 to N","Generate pronunciation choice B(i, j(i)) from U(i) using baseform generation algorithm","(1\u2266j(i)\u2266CN(i))","endfor","for i=1 to N","for k=0 to CN(i)","j(k)=1","endfor","endfor","loop=TRUE","while loop=TRUE","S=1","for i=0 to N","S=S*S(i, j(i))","endfor","if S\u2267TH","for i=0 to N","if B(i, j(i)) is not registered as pronunciation","Register B(i, j(i))","endif","endfor","endif","if nextpath(1)=TRUE","loop=FALSE","endif","endwhile","end","nextpath(i)","begin","if i>N","return TRUE","endif","if nextpat(i+1)=TRUE","j(i)=j(i)+1","endif","if j(i)>CN(i)","j(i)=1","return TRUE","endif","return FALSE","end\n\nIn the case for Example 5,\n"]}},{"@attributes":{"id":"p-0086","num":"0207"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u201c401(k)\u201d"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u201cfour-o-one-kei\u201d","score: 0.9"]},{"entry":[{},"\u201cfour-zero-one-kei\u201d","score: 0.9"]},{"entry":[{},"\u201cfour-hundred-one-kei\u201d","score: 0.5"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"The processing in this sub-division for dynamically changing a threshold value at the time of erroneous recognition is the additional processing for the present invention, and is not a requisite component for one aspect of the present invention. This processing will now be described while referring to the flowchart in .","First, voice information (a voice command) entered by a user's voice is fetched, and the speech recognition engine  obtains a sentence for speech recognition (steps  and ). In this example, for the convenience sake, only one sentence is output by the speech recognition engine . However, the speech recognition engine may return a speech recognition group consisting of a plurality of sentences having speech recognition scores. In this case, the above process is repeated by the times equivalent to the number of sentences, and at step  the matching score is calculated.","To repeat the process for the target sentences, variable i is initially set (step ). A check is performed to determine whether a speech recognition sentence to be compared matches the i-th sentence to be recognized (step ).","When the speech recognition sentence to be compared matches the i-th sentence, the i-th sentence is recognized as the one that corresponds to the speech recognition sentence, and is employed for a necessary process (step ). For example, if the sentence to be recognized is one obtained from a web browser, the corresponding URL (Uniform Resource Locator) is transmitted to the web browser as a URL to be displayed. Or for a word processor, the pertinent sentence can be inverted and a command corresponding to the sentence can be executed.","When the speech recognition sentence to be compared and the i-th sentence do not match, a check is performed to determine whether in the i-th sentence there is a matching portion between the beginning portion and the unknown word portion (step ). When no matching portion exists, it is ascertained that the target i-th sentence does not correspond to the speech recognition sentence, and the next target sentence is examined (step ). When there are no more sentences to be recognized, a recognition error message is displayed (step ), and a user is instructed to enter the voice command again.","When a match is found for a portion extending from the sentence beginning to the unknown word portion, the threshold value, used for comparison when the base form of an unknown word is registered, is reduced (step ), and an unknown word included in the target sentence is registered (step ). The unknown word that is registered is used for the next speech recognition process. Therefore, if a recognition error occurs due to the pronunciation of an unknown word, the threshold value in the above processing is dynamically changed, so that frequent recognition error occurrences can be prevented.","Since TH1 is 0.5, for example, for the sentence  of , the pronunciations that are dynamically registered are \u201ctahara\u201d and \u201ctawara.\u201d So if a speaker pronounces the word  as \u201ctabara,\u201d the recognition engine can not recognize the full sentence, and does not return a path of  and . In this case, the threshold value for the portion of the path, leading from the beginning, that is matched is reviewed (reduced), and the pronunciation is dynamically added to designate the sentence a recognition target.","An explanation will now be given using Example 4. In this processing, if only the portion \u2013 are recognized using TH1: 0.5, the pertinent sentence is registered again using TH2: 0.25.","Sentence .",{"@attributes":{"id":"p-0095","num":"0216"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"The word 635"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u201ctahara\u201d","score: 0.83 S(1, 1)"]},{"entry":[{},"\u201ctawara\u201d","score: 0.56 S(1, 2)"]},{"entry":[{},"\u201ctabara\u201d","score: 0.45 S(1, 3)"]},{"entry":[{},"\u201ctabaru\u201d","score: 0.20 S(1, 4)"]},{"entry":[{},"\u201cdahara\u201d","score: 0.02 S(1, 5)"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003TH2: 0.25",{}]},{"entry":[{},"S(1, 1) = 0.83 \u2267 0.25","alread registered"]},{"entry":[{},"S(1, 2) = 0.56 \u2267 0.25","already registered"]},{"entry":[{},"S(1, 3) = 0.45 \u2267 0.25","registered (The word 635 as tabara)"]},{"entry":[{},"S(1, 4) = 0.20 < 0.25","not registered"]},{"entry":[{},"S(1, 5) = 0.02 < 0.25","not registered"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"The logic employed for the processing for dynamically changing a threshold value when a recognition error occurs is shown below.\n\n","As is described above, according to the present invention, even a sentence that includes words that are not registered in a speech recognition dictionary can be specified by using voice.","Although illustrative embodiments of the present invention have been described herein with reference to the accompanying drawings, it is to be understood that the invention is not limited to those precise embodiments, and that various other changes and modifications may be made by one skilled in the art without departing from the scope or spirit of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0025","num":"0096"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0026","num":"0097"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0027","num":"0098"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0028","num":"0099"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0029","num":"0100"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0030","num":"0101"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0031","num":"0102"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0032","num":"0103"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0033","num":"0104"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0034","num":"0105"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0035","num":"0106"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0036","num":"0107"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
