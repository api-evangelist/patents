---
title: Distributed query engine pipeline method and system
abstract: A distributed query engine pipeline architecture comprises cascaded analysis engines that accept an input query and each identifies a portion of the input query that it can pass on to an execution engine. Each stage rewrites the input query to remove the portion identified and replaces it with a placeholder. The rewritten query is forwarded to the next analysis engine in the cascade. Each engine compiles the portion it identified so that an execution engine may process that portion. Execution preferably proceeds from the portion of the query compiled by the last analysis engine. The execution engine corresponding to the last analysis engine executes the query and makes a call to the next higher execution engine in the cascade for data from the preceding portion. The process continues until the results from the input query are fully assembled.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07472112&OS=07472112&RS=07472112
owner: Microsoft Corporation
number: 07472112
owner_city: Redmond
owner_country: US
publication_date: 20030623
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS"],"p":["The invention relates generally to the field of software querying over data sources, and more particularly to distributed querying over data sources containing different data models.","Querying over heterogeneous data sources is the challenge of performing a search over data sources having different data models. The challenge also presents itself where disparate data sources have the same data model. In order to query over multiple data sources with multiple data models, a multiplicity of query execution engines is normally required. The input query is normally split up by one monolithic processor which decides a priori which attached execution engine should get which portion of the original input query. The original query is thus monolithically processed to divide up the query into distinct pieces for execution. Each execution engine corresponds to a particular data model or data source. The individual query execution engines then execute their portion of the query and return the results to the monolithic processor. The monolithic processor then has the task of combining the individual query results from each of the query execution engines and stringing them together to form a complete set of query results.","This approach to heterogeneous data querying has the disadvantage of requiring a monolithic processor that can identify and manipulate all possible data sources. This is an ominous task because different data sources have very different API's or models for interacting with their data, and it is not generally feasible or desirable to build a monolithic processor that has knowledge of all data models and can manipulate all possible data sources. For example, if one wished to query over a SQL database or an XML file, the only interface to interact with an XML file is the Document Object Model (DOM), and the only interface to the database is SQL commands. As a result, one would require different code to work with the database and the XML file. The problem is exacerbated if one attempts to build a monolithic processor capable of handling additional data model types as those data types emerge to importance in the field. Under such conditions, the monolithic engine capacity may very well be exceeded by changing requirements and may require a redesign if any additional data model types are added or if an existing data model type is significantly changed.","An additional problem in creating a heterogeneous data source query mechanism is virtual querying. If a data source can be queried easily in one data model type yet it is desirable to structure the query in a second data model query language, then a conversion from one data model query language type may be needed. This need may cause multiple query language conversions requiring multiple sets of hardware and software modules and a corresponding number of optimizers to ensure efficient coding of the queries.","Thus there is a need for an architecture which avoids the problem of designing and building a monolithic query processor which is adaptable for changing query language requirements. Additionally, there is a need for an architecture that avoids the problems associated with converting multiple query languages from one form into another. The present invention addresses the aforementioned needs and solves them with an inventive architecture which is adaptable to changing query environment needs.","The invention addresses the problem of querying over multiple data sources having multiple data model types by utilizing a distributed query engine pipeline. The pipeline provides advantages over a typical solution of using a monolithic processor to divide up the input query, deal out the respective portions to specific execution engines and then combining the results to form input query results. The present invention utilizes cascaded analysis engines, without a monolithic processor, to identify and extract portions of the input query which can be compiled and executed on specific execution engines.","In one embodiment of the invention, an analysis engine is associated with an execution engine type and, although cascaded, each analysis engine operates independently from the other. Each analysis engine has two outputs: a compiled portion that the engine has identified as corresponding to an execution engine, and a rewritten query where the identified portion is removed and replaced with a placeholder. The analysis engine which lies next in the cascade receives the rewritten query, identifies its executable portion, replaces it with another placeholder and passes the twice rewritten query along with both placeholders down to the next stage.","The execution phase of processing the query preferably begins with the execution engine corresponding to the last analysis engine. The execution engine executes the query apportioned out to it, and places a call to the next higher execution engine in the cascade of execution engines to retrieve placeholder query results. Each execution engine places calls to higher stacked engines to retrieve data corresponding to the placeholders. Successive calls within cascaded execution engines eventually results in one execution engine accumulating all of the query results corresponding to input query.","Optionally, the execution phase of the pipelined query may start with the execution of the outermost or first analysis engine compilation output. As before, each execution engine may execute its apportioned query and make calls to succeeding execution engines for placeholder data. The input query return results are similar.","Overview","The present invention addresses the problem of querying over multiple types of data sources from multiple query sources. One solution to the problem of querying over virtual XML data sources may be to use a unifying intermediate language. The XML intermediate language used in the context of the present invention represents the meaning or semantics of a query. The XML intermediate language is termed a query intermediate language (QIL).","QIL addresses the problem known as \u201cquery\/view composition\u201d. As an example, assume an XML query is to be performed over a virtual XML view of data, either XML, XML virtual, or other data. One approach may be to materialize that data source as XML, but this may be very inefficient and may require more memory than is available to the system. Another approach is to virtualize the view, compose the query with that virtual view, and translate the result into operations over the original data. The user sees an XML query over a logical XML data model, but the implementation queries the native data format using whatever query system it provides. This approach is used in relational databases for SQL queries over SQL views. Using an XML intermediate language, such as QIL, the original potentially complex view may be decomposed into query operations over smaller atoms of data. In this way, a query over a complex view becomes a query over a query plus a simpler view. Query composition turns this into just a query over the simpler view, thereby simplifying the problem.","The XML intermediate language QIL provides (1) a uniform representation of both the XML query and the XML view, thereby greatly simplifying the query\/view composition problem and (2) treating all views as \u201cvirtual XML\u201d greatly simplifies the system's interfaces. Instead of having one API for every possible language and data model, all the APIs can share a common data model, the operators of the XML intermediate language QIL.","Along with the use of an intermediate language representation of an input query, the present invention discloses an exemplary architecture utilizing a distributed architecture for conducting a query over multiple data sources. A true distributed architecture is able to distribute the mixed source query over different execution engines without the need for a monolithic processor to supervise the work. An exemplary distributed query engine pipeline of the present invention also has the capability to be modular in that new or modified execution engines may be added to the architecture to accommodate differing query needs. Additionally, the execution engines utilized need not be informed of the workings of the other query execution engines in order to operate correctly. Each engine may be stacked or cascaded on top of each other with each engine processing and optimizing only the parts of the query that the engine understands and passing the rest of the query to the next engine in the chain or cascade.","Exemplary Computing Device",{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 1"},"Although not required, the invention can be implemented via an operating system, for use by a developer of services for a device or object, and\/or included within application software that operates according to the invention. Software may be described in the general context of computer-executable instructions, such as program modules, being executed by one or more computers, such as client workstations, servers or other devices. Generally, program modules include routines, programs, objects, components, data structures and the like that perform particular tasks or implement particular abstract data types. Typically, the functionality of the program modules may be combined or distributed as desired in various embodiments. Moreover, those skilled in the art will appreciate that the invention may be practiced with other computer configurations. Other well known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers (PCs), automated teller machines, server computers, hand-held or laptop devices, multi-processor systems, microprocessor-based systems, programmable consumer electronics, network PCs, appliances, lights, environmental control elements, minicomputers, mainframe computers and the like. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network\/bus or other data transmission medium. In a distributed computing environment, program modules may be located in both local and remote computer storage media including memory storage devices, and client nodes may in turn behave as server nodes.",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1","b":["100","100","100","100"]},"With reference to , an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer system . Components of computer system  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus (also known as Mezzanine bus).","Computer system  typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer system  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, Random Access Memory (RAM), Read Only Memory (ROM), Electrically Erasable Programmable Read Only Memory (EEPROM), flash memory or other memory technology, Compact Disk Read Only Memory (CDROM), compact disc-rewritable (CDRW), digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can accessed by computer system . Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer system , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , other program modules , and program data .","The computer system  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk , such as a CD ROM, CDRW, DVD, or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media discussed above and illustrated in  provide storage of computer readable instructions, data structures, program modules and other data for the computer system . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that, at a minimum, they are different copies. A user may enter commands and information into the computer system  through input devices such as a keyboard  and pointing device , commonly referred to as a mouse, trackball or touch pad. Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus , but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface , which may in turn communicate with video memory (not shown). In addition to monitor , computer systems may also include other peripheral output devices such as speakers  and printer , which may be connected through an output peripheral interface .","The computer system  may operate in a networked or distributed environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer system , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks\/buses. Such networking environments are commonplace in homes, offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer system  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer system  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer system , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on memory device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Various distributed computing frameworks have been and are being developed in light of the convergence of personal computing and the Internet. Individuals and business users alike are provided with a seamlessly interoperable and Web-enabled interface for applications and computing devices, making computing activities increasingly Web browser or network-oriented.","For example, MICROSOFT\u00ae's .NET\u2122 platform, available from Microsoft Corporation, One Microsoft Way, Redmond, Wash. 98052, includes servers, building-block services, such as Web-based data storage, and downloadable device software. While exemplary embodiments herein are described in connection with software residing on a computing device, one or more portions of the invention may also be implemented via an operating system, application programming interface (API) or a \u201cmiddle man\u201d object between any of a coprocessor, a display device and a requesting object, such that operation according to the invention may be performed by, supported in or accessed via all of .NET\u2122's languages and services, and in other distributed computing frameworks as well.","Exemplary Embodiments",{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 2","FIG. 1","FIG. 2"],"b":["200","210","210","210","220"]},"The intermediate language generated as depicted in  is a representation of an input query or view. As such, it may be termed a query intermediate language (QIL) because it is an explicit representation of the meaning of a query. The query intermediate language may be viewed as a semantic representation common across all query and view language compilers  used in the architecture . For example, if the input compilers operate over XML data, then the QIL enables the abstraction of multiple different XML query languages and view definition languages (such as XPath and XSLT) over a variety of different target data sources (such as relational and non-relational data). As such, the QIL enables a common construction to support all of the compatible XML query languages. Those of skill in the art will recognize the advantage of employing an intermediate language representation in the query architecture . Every operation within is both explicit and unambiguous, which preferably completely decouples front-end compilers that assist in generating QIL from a distributed query engine pipeline that uses the QIL.","The preceding example represents one contextual embodiment of the current invention using an XML intermediate language representation as an input to the distributed query engine pipeline. Other intermediate language representations or direct base languages may be utilized as an input to the present invention, such as for example, a direct LDAP, AD, XML or a SQL language query inputs to name a few.","The intermediate language representation  may be optionally optimized  for more efficient processing by subsequent stages. The optimizer of  is presented only as context for the current invention and is not strictly required. The optimized or un-optimized intermediate language representation  of the input query may be presented to the distributed query engine pipeline .","The distributed query engine pipeline allows for queries over heterogeneous data sources . The engines of the pipeline distribute the intermediate language query to execution machines having specific data models. This allows a query execution to be accomplished by an execution engine that maximizes the query efficiency within a particular data model. Thus the execution engines in the pipeline  may be constructed so that they efficiently work on data sources comporting with the model of the data within each supported data source. For example, an execution engine for a SQL database source may be optimized for efficiency in querying over a relational database with a SQL database management system. Each of the execution engines within the pipeline has access  to its particular data source bearing it own data model. The distributed query engine is able to query over one or more data sources having one or more data models in a heterogeneous search. Upon execution of the distributed query, the execution engines of the pipeline normally produce query results  available for further processing, storage, display to a user, or provision to a subsequent software application, for example.",{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIG. 3","FIG. 2","FIG. 3","FIG. 3"],"b":["240","310","320","330","370","380","390"]},"An input query  is received by the analysis engine A . The engine examines the query and finds the potions of the query that it knows how to optimize or pass off  to an execution engine. Analysis engine A  removes the identified portions and replaces them with a placeholder. The engine  thus rewrites the query and passes  the balance of the query plus the placeholder on to analysis engine B . Thus the engine  passes the modified query to the next engine in the stack.","The portion of the query that analysis engine A  recognizes is compiled and passed  to an accumulator  to hold the compiled query portion (compiled query A). Note that analysis engine A  has no knowledge of analysis engine B. Engine A extracts the portion of the query that it can recognize as that which can be processed by a specific execution engine and passes the balance of the query out. The next analysis engine in the stack, if any, then recognizes only a portion of the query that corresponds to a different execution engine.","Analysis engine B  accepts the modified query from engine A and identifies which portion of the modified query that it can pass  to an execution engine. Analysis engine B then removes that identified portion, compiles it, and sends it to an accumulator  holding the compiled query B. Analysis engine B  then rewrites the query it received by replacing, with a placeholder, the portion it identified and extracted with a placeholder. The analysis engine  then passes  the twice modified query to the next engine in the stack. Analysis engine C  accepts the twice modified query from engine B and identifies which portion of the twice modified query that it can pass  to an execution engine. Analysis engine C then removes that identified portion, compiles it, and sends it to an accumulator  holding the compiled query C. In system where more tiers or stages of analysis engines are implemented, analysis engine C  could then rewrite the query it received by replacing, with a placeholder, the portion it identified and extracted. The analysis engine C  could then pass the thrice modified query to the next engine in the stack. It is thus apparent that the distributed pipeline analysis engines may be cascaded as desired.","The compiled query accumulators ,  and  together form a composite query. Each query portion (A, B and C) is associated with an execution engine that efficiently perform a query over a data source that has a specific data model. For example, compiled query A  is capable of being executed by execution engine A . Execution engine A is able to access  one or more data sources  that have at least some portion that corresponds to the data model consistent with compiled query A.","The composite query formed by the combination of compiled queries A, B and C ,  and  respectively may be viewed as a wrapped series of queries. For example, compiled query C  is a sub-query and therefore a part of compiled query B . Thus, compiled query C is wrapped by compiled query B. Likewise, compiled query B  is a sub-query of compiled query A  and therefore compiled query B is wrapped by compiled query A.","It should be noted that the compiled and nested or wrapped queries resulting in compiled queries A, B and C are useful outputs of the present invention as these query outputs may be stored for future use. The stored queries may be executed on the same or a different computer immediately or at a delayed time.","In order to execute the composite query combination of compiled queries A, B and C, the execution engines desirably work in an order which allows successive levels of wrapping to be uncovered. For example, in order for the compiled query A to be fully executed, compiled query B should preferably be executed. But in order to execute compiled query B to be fully executed, compiled query C should preferably be executed. Thus, the order of unwrapping is preferably the innermost wrapping first, followed by successively higher levels of wrapping. In the example of , compiled query C may be preferably executed before compiled query B and compiled query B may be preferably executed before compiled query A. The execution engines of  allow for this priority of execution.","Execution engine C  receives  the innermost executable compiled query . The execution engine C then executes its compiled query. One or more data sources  containing a compatible data model are accessed,  and . The data sources  return  the requested data. However, the presence of the placeholder inserted into compiled query C by analysis engine B  indicates to the execution engine C that additional information is needed to complete the query results. Essentially, execution engine C calls back  to execution engine B  as an external source for information to complete the execution of compiled query C. The placeholder inserted into compiled query C by analysis engine B triggered the call to the previous execution engine as if it were an external data source.","Execution engine B  receives  the call from execution engine C. Execution engine B then inputs  the compiled query B . Execution of compiled query B proceeds by accessing,  and , one or more data sources . The data sources  return  the requested data. However, the presence of the placeholder inserted into compiled query B by analysis engine A  indicates to the execution engine B that additional information is needed to complete the query results. Execution engine B calls back  to execution engine A  as an external source for information to complete the execution of compiled query B. The placeholder inserted into compiled query B by analysis engine A triggered the call to the previous execution engine as if it were an external data source.","Execution engine A  receives  the call from execution engine B. Execution engine B then inputs  the compiled query B . Execution of compiled query A proceeds by accessing,  and , one or more data sources . The data sources  return  the requested data. In this instance there is no previously inserted placeholder in compiled query A, so the query can be executed in full.","Execution engine A provides the compiled query A  results to execution Engine B. Execution engine A has completed its response to the call from Execution engine B. Upon receipt of the query results from execution engine A, execution engine B is able to complete its execution of compiled query B . Execution engine B then responds by providing  both the information it acquired from execution engine A and its own query results to execution engine C. Execution engine B has completed its response to the call from Execution engine C.","Upon receipt of the query results from execution engine B, execution engine C is able to complete its execution of compiled query C . Execution engine C then responds by providing  both the information it acquired from execution engine B and its own query results to form the complete results of the original input query . Execution engine C has accumulated all of the previously extracted query results to form the completed query results.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 4","FIG. 3"],"b":["410","415","420","425","430","435","440","415","420","425","430"]},"If the last analysis engine has completed its tasks , then the execution phase may begin . Preferably, the execution phase begins with the last analysis engine compilation that was stored. This last compilation is also known as the innermost compilation. Optionally, the execution may begin with the first analysis engine compilation. The flow diagram of  is structured to depict starting execution with the last analysis engine compilation although those of skill in the art may construct a flow where the first analysis engine compilation is used to begin the execution of the composite query.","It should be noted that the compiled query portions at the beginning of execution  may be a usable output of the system. The compiled queries may be executed immediately or retrieved for later use on the same or a different system employing the appropriate execution engines.","Beginning the execution with the last analysis engine  compilation, the corresponding execution engine may recall its corresponding compiled portion of the query . The engine executes the retrieved compiled query . Initially, there will be a placeholder in the query which will instruct the execution engine to make an external source call for information . The external source call may be made  and data from the next cascaded execution engine will be requested. In this instance, the external data source is the next cascaded execution engine. The next engine will recall from storage its corresponding compiled query  and execute the query . The executing engine may proceed to make an external source data call to the next cascaded execution engine if a placeholder is encountered in the executed query. Note that the process continues moving from one cascaded execution engine to the next until no placeholder for an external source is encountered by an execution engine.","If an execution engine in the cascade has no external placeholder and thus no external call need be made, then an entire response to that query can be given to the calling execution engine . The next higher engine in the cascade can then respond to its next higher execution engine call to gather or accumulate the nested query results . If the next higher engine is also responding to a call  then the fulfillment of external source calls moves to the next execution engine . The next execution engine then sends its query results back to the calling engine  to gather the accumulating query results . When all calls for external data are completed, the innermost execution engine, or base engine, has essentially received all the results of all of the higher level executions and accumulates the results of the entire query . At this point the query results from the original received input query  are accumulated and are available to the next process or for use by a user.","A codified example of the process outlined above is provided below. Consider, for example, the following query:",{"@attributes":{"id":"p-0056","num":"0055"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"\u2018An XQuery combining relational and XML operators\u2019"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"For $i in sql : table (\u201cCustomers\u201d)"]},{"entry":[{},"where sql : column ($i, \u2018CustomerID\u2019) = \u2018ALFKI\u2019"]},{"entry":[{},"return"]},{"entry":[{},"<Customer id = \u201c{sql : column ($i, \u2018Customer ID\u2019) }\u201d"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"name = \u201c{ sql column ( $i, \u2018ContactName\u2019) }\u201c>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<OrderList>{"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"for $j in sql : table ( \u201cOrders\u201d)"]},{"entry":[{},"where sql : column ($i, \u2018CustomerID\u2019) ="]},{"entry":[{},"sql column ($j, \u2018CustomerID\u2019)"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"and position ($j) >= 3"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"return <Order id=\u201d {sql : column ($J, \u2018OrderID\u2019) }\u201c\/>"]},{"entry":[{},"}<\/OrderList>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<\/Customer>"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"This query combines relational operators such as comparing column values with XML operators such as position. If the query is split into two parts; one portion may execute using an SQL Server engine and another portion may execute using an XML engine. The XQuery may be compiled into QIL and then analyzed for patterns that can be performed by SQL Server. The query may then be rewritten by removing those patterns, replacing them with navigation over a virtual XML document.","Once again, the advantage is that the operation materializes only the part of the mapping that is absolutely required, and as much of the query as possible is pushed into SQL Server. This may be accomplished by extracting all the SQL Server operations from the query and replacing them with navigation over a virtual XML document as follows, for example:",{"@attributes":{"id":"p-0059","num":"0058"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"for $i in document (\u201cvirtual\u201d)\/root\/X1"]},{"entry":[{},"return"]},{"entry":[{},"<Customer id = \u201c{$i\/@CustomerID} \u201cname ="]},{"entry":[{},"\u201c{ $i\/@ContactName} \u201c>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<OrderList>"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"for $j in $i\/X2"]},{"entry":[{},"where position ($j) >= 3"]},{"entry":[{},"return, Order id = {$j\/@OrderID}\/>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"<\/OrderList>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<\/Customer>"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"Note that the position operator is left in place for the XML engine to perform. This virtual XML document that replaced the SQL tables and columns is conceptually equivalent to the results of the SQL query:",{"@attributes":{"id":"p-0061","num":"0060"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u2018Extracted SQL parts of the XQuery, to be executed by SQL Server\u2019"},{"entry":"SELECT X1.CustomerID, X1.ContactName, X2.OrderID"},{"entry":"FROM Customers X1 JOIN Orders X2 ON X1.CustomerID ="},{"entry":"X2.CustomerID"},{"entry":"WHERE X1.CustomerID = \u2018ALFKI\u2019"},{"entry":"FOR XML AUTO"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0062","num":"0061"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"\u2018Virtual XML document\u2019"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<root>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<X1 CustomerID = \u201cALFKI\u201d ContactName = \u201cMaria Anders\u201d>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<X2 OrderID = \u201c10643\u201d \/>"]},{"entry":[{},"<X2 OrderID = \u201c10692\u201d \/>"]},{"entry":[{},"<X2 OrderID = \u201c10702\u201d \/>"]},{"entry":[{},"<X2 OrderID = \u201c10835\u201d \/>"]},{"entry":[{},"<X2 OrderID = \u201c10952\u201d \/>"]},{"entry":[{},"<X2 OrderID = \u201c11011\u201d \/>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<\/X1>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<\/root>"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"However, this in true only conceptually; in reality, no XML is ever constructed. Instead, an ordinary SQL query is sent to SQL Server to perform the join and filtering, and the rowset results are exposed to the XML engine as virtual XML through a custom XPathNavigator interface.","As mentioned above, while exemplary embodiments of the present invention have been described in connection with various computing devices and network architectures, the underlying concepts may be applied to any computing device or system in which it is desirable to implement a query system. Thus, the methods and systems of the present invention may be applied to a variety of applications and devices. While exemplary programming languages, names and examples are chosen herein as representative of various choices, these languages, names and examples are not intended to be limiting. One of ordinary skill in the art will appreciate that there are numerous ways of providing object code that achieves the same, similar or equivalent systems and methods achieved by the invention.","The various techniques described herein may be implemented in connection with hardware or software or, where appropriate, with a combination of both. Thus, the methods and apparatus of the present invention, or certain aspects or portions thereof, may take the form of program code (i.e., instructions) embodied in tangible media, such as floppy diskettes, CD-ROMs, hard drives, or any other machine-readable storage medium, wherein, when the program code is loaded into and executed by a machine, such as a computer, the machine becomes an apparatus for practicing the invention. In the case of program code execution on programmable computers, the computing device will generally include a processor, a storage medium readable by the processor (including volatile and non-volatile memory and\/or storage elements), at least one input device, and at least one output device. One or more programs that may utilize the signal processing services of the present invention, e.g., through the use of a data processing API or the like, are preferably implemented in a high level procedural or object oriented programming language to communicate with a computer. However, the program(s) can be implemented in assembly or machine language, if desired. In any case, the language may be a compiled or interpreted language, and combined with hardware implementations.","The methods and apparatus of the present invention may also be practiced via communications embodied in the form of program code that is transmitted over some transmission medium, such as over electrical wiring or cabling, through fiber optics, or via any other form of transmission, wherein, when the program code is received and loaded into and executed by a machine, such as an EPROM, a gate array, a programmable logic device (PLD), a client computer, a video recorder or the like, or a receiving machine having the signal processing capabilities as described in exemplary embodiments above becomes an apparatus for practicing the invention. When implemented on a general-purpose processor, the program code combines with the processor to provide a unique apparatus that operates to invoke the functionality of the present invention. Additionally, any storage techniques used in connection with the present invention may invariably be a combination of hardware and software.","While the present invention has been described in connection with the preferred embodiments of the various figures, it is to be understood that other similar embodiments may be used or modifications and additions may be made to the described embodiment for performing the same function of the present invention without deviating therefrom. Furthermore, it should be emphasized that a variety of computer platforms, including handheld device operating systems and other application specific operating systems are contemplated, especially as the number of wireless networked devices continues to proliferate. Therefore, the present invention should not be limited to any single embodiment, but rather should be construed in breadth and scope in accordance with the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing summary, as well as the following detailed description of preferred embodiments, is better understood when read in conjunction with the appended drawings. For the purpose of illustrating the invention, there is shown in the drawings exemplary constructions of the invention; however, the invention is not limited to the specific methods and instrumentalities disclosed. In the drawings:",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
