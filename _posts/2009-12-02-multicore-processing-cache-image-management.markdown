---
title: Multi-core processing cache image management
abstract: A multi-core processor chip comprises at least one shared cache having a plurality of ports and a plurality of address spaces and a plurality of processor cores. Each processor core is coupled to one of the plurality of ports such that each processor core is able to access the at least one shared cache simultaneously with another of the plurality of processor cores. Each processor core is assigned one of a unique application or a unique application task and the multi-core processor is operable to execute a partitioning operating system that temporally and spatially isolates each unique application and each unique application task such that each of the plurality of processor cores does not attempt to write to the same address space of the at least one shared cache at the same time as another of the plurality of processor cores.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08423717&OS=08423717&RS=08423717
owner: Honeywell International Inc.
number: 08423717
owner_city: Morristown
owner_country: US
publication_date: 20091202
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Typical multi-core processors need to manage cache and cache coherency for each of the processing cores. Cache coherency is often managed by using a plurality of caches and tying each cache to a particular processing core. In other systems, a shared cache is used. In typical multi-core processors with a shared cache, access to the shared cache is arbitrated. These methods may be effective for applications in which the executed code and data sets are independent for each processor core. However, for applications in which the code space (e.g. operating system, I\/O routines, algorithms, etc.) is common and\/or the data set is shared, independent caches requires cache coherency algorithms that can significantly reduce bandwidth and make the cache areas ineffective since redundant information is stored in multiple caches. In addition, when a single cache is arbitrated between multiple processor cores, the bandwidth to the cache for a given processor core is reduced by the actions of the other processor cores.","In one embodiment, a multi-core processor chip is provided. The multi-core processor chip comprises at least one shared cache having a plurality of ports and a plurality of address spaces and a plurality of processor cores. Each processor core is coupled to one of the plurality of ports such that each processor core is able to access the at least one shared cache simultaneously with another of the plurality of processor cores. Each processor core is assigned one of a unique application or a unique application task and the multi-core processor is operable to execute a partitioning operating system that temporally and spatially isolates each unique application and each unique application task such that each of the plurality of processor cores does not attempt to write to the same address space of the at least one shared cache at the same time as another of the plurality of processor cores.","In accordance with common practice, the various described features are not drawn to scale but are drawn to emphasize specific features relevant to the exemplary embodiments.","In the following detailed description, reference is made to the accompanying drawings that form a part hereof, and in which is shown by way of illustration specific illustrative embodiments. However, it is to be understood that other embodiments may be utilized and that logical, mechanical, and electrical changes may be made. The following detailed description is, therefore, not to be taken in a limiting sense.","The embodiments described below implement a partitioning operating system (OS) on a multi-processor core to manage a shared cache. A partitioning operating system is an operating system which isolates each running application both temporally and spatially. Exemplary partitioning operating systems include, but are not limited to, ARINC 653 compliant operating systems, such as LynxOS-178, VxWorks 653, INTEGRITY-178B, and PikeOS. Other appropriate partitioning operating systems, such as non-ARINC 653 compliant operating systems, are known to one of skill in the art and can be used in other embodiments.",{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1","b":["100","106","100"]},"The architecture  includes hardware, such as a processor and cache, on which the partitioning operating system  is run. The partitioning operating system  isolates each of a plurality of running applications - . . . -M with a time\/space separation . That is, only one of the plurality of applications - . . . -M is allowed write access to a given address space in the cache at a given time. For example, if application - is writing to a particular address space, applications - . . . -M are not given read or write access to that particular address space. However, at another moment in time, one of applications - . . . -M can be given read or write access to that particular address space. In addition, more than one of the applications - . . . -M can be given read access to an address space as long as no other application has concurrent write access to the same address space. Thus, the applications are isolated temporally and spatially such that one of the applications - . . . -M does not interfere with the other applications.",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 2","b":["201","205","201"]},"In the example of , each of the plurality of processor cores - . . . -N is associated with a corresponding independent level 1 (L1) cache - . . . -N. It is to be understood that the L1 cache can include separate instruction cache (i-cache) and data cache (d-cache), as known to one of skill in the art. Each of the plurality of processor cores - . . . -N also has access to an N-ported level 2 (L2) cache . The term \u201cN-ported\u201d means that each of the N processor cores  has a dedicated port  to the cache and can have simultaneous access to the shared L2 cache .","A partitioning operating system  is loaded into the shared L2 cache  from a main memory external to the multi-core processor chip . In addition, executable code of the partitioning operating system  can be loaded into the L1 cache  of each corresponding core  as well. The plurality of processor cores - . . . -N execute the partitioning operating system  and other executable code in the common code space. As used herein, a shared common code space refers to executable code that can be accessed by each of the plurality of processor cores , such as, but not limited to, an operating system, I\/O routines, algorithms, etc. For example, one or more applications - . . . -M are executed or run by each of the processor cores - . . . -N. The multi-core processor chip  can be configured to operate in asymmetric or symmetric multi-processing. In asymmetric multi-processing, the applications  that are executed by each core  are different from the applications  executed by other cores . In symmetric multi-processing, the applications  run by two or more cores  can be the same. However, in this example, even if the same applications are run by a plurality of cores , each instance of the application is scheduled to be performing a different task. Enforcement of the task scheduling is handled by the partitioning operating system .","As described above, the partitioning operating system  isolates the plurality of applications  temporally and spatially to prevent more than one application from writing to the same address space at the same time. Assigning unique applications or unique tasks to each core  helps ensure that no two cores  attempt to write to the same address space at the same time. A unique application, as used herein, refers to an application which is only executed by one of the plurality of cores . Similarly, a unique task refers to an application task which is executed by only one of the plurality of cores . Since the partitioning operating system  prevents multiple applications or tasks from writing to the same address space at the same time, no two cores , which execute unique applications, are able to write to the same address space at the same time.","In addition, the executable code of the partitioning operating system  and the applications  is not self-modifying code. In other words, the processor cores  only have read access to the executable code. In addition, the multiple processor cores  share common code. The ability to have concurrent read access is advantageous for sharing common code between the multiple processor cores . Thus, each core  has the ability to simultaneously access a shared common code space without coherency algorithms or arbitration. For example, the multiple processor cores  can simultaneously access and execute common routines from libraries, such as Operating System libraries, I\/O interface drivers, etc.","Indeed, by assigning different applications  or different tasks to different cores , the multi-core processor chip  leverages the isolation and scheduling capabilities of the partitioning operating system  to manage access to the shared L2 cache  without the coherency or arbitration algorithms that are used in typical multi-core processor chips. Thus, each core  can access the data  and executable code (e.g. partitioning operating system  and applications ) in the N-ported cache  while increasing the bandwidth available for each core  as compared to typical multi-core processor chips. In addition, each core  is not subject to hard limitations in accessing the cache , such as limits to a specific assigned region of the cache . Rather, each core  has read and write access to the cache  controlled via its respective MMU and system configuration without such hard limitations. By managing write privileges through each processor core's respective MMU, a performance benefit is obtained. In particular, a table look-up typically performed by a cache controller to manage write privileges in typical multi-processor cores is avoided by managing write access through the respective MMUs.","Thus, the cores  are able to operate independently such that the actions of one core  do not interfere with the actions of another core . This increases bandwidth by eliminating the need for arbitrating access to the shared L2 cache . In addition, since the processor cores  share the larger L2 cache , a benefit in the area used on the multi-processor chip  is obtained. In particular, rather than having multiple smaller caches, a single larger cache can be used with data and executable code, such as the partitioning operating system and system drivers, are located in place in the cache. Since access to the shared L2 cache  is not arbitrated, any performance impact on the multiple cores by having a shared cache is reduced.","It should be noted that although the L2 cache  is shared in this example, the L1 cache  can be shared in other implementations, as is shown in the example in . The multi-core processor chip  is similar to the multi-core processor chip . However, the L1 cache  and the L2 cache  are both shared in the example of . In addition, a level 3 (L3) cache, not shown, can also be shared by a plurality of cores in other implementations.",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 4","b":["400","401","400","401","410","416","401","410","400","410"]},"The multi-core processor chip  can be implemented as the multi-core processor chip described and shown in  or . In particular, the multi-core processor chip  has a shared N-ported cache  and a plurality of processor cores - . . . -N which run a partitioning operating system. As described above, running the partitioning operating system on the plurality of processor cores enables the processor cores to access the shared N-ported cache without the coherency and arbitration algorithms of prior multi-core processor chips.","Executable code, such as the partitioning operating system  and\/or other applications, is loaded into the shared cache  of the multi-core processor chip  from the main memory . The main memory  can be implemented as, but is not limited to, Random Access Memory (RAM) (including, but not limited to, Synchronous Dynamic Random Access Memory (SDRAM), Double Data Rate (DDR) RAM, RAMBUS Dynamic RAM (RDRAM), Static RAM (SRAM), etc.), Read Only Memory (ROM), Electrically Erasable Programmable ROM (EEPROM), and flash memory, as known to one of skill in the art. Access to the main memory  by each processor core is managed by its respective memory management unit (MMU) . The respective MMU , together with the partitioning operating system , enforce the time\/space separation of the executed applications as well as the assignment of unique applications and tasks to different processor cores.","The multi-core processor chip  runs a plurality of applications, as described above. The applications run by the multi-core processor chip  are dependent on the implementation of the system . Improvements are thus made in the performance of system  by implementing a multi-core processor  as described above in  above. For example, increased bandwidth and efficiency are achieved through the inclusion of the multi-core processor chip  running a partitioning operating system. In particular, the multi-core processor chip  manages access to a shared cache  without coherency or arbitration algorithms that cause decreased bandwidth and efficiency.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 5","FIGS. 2 and 3"],"b":["500","500","502"]},"At block , the unique applications and application task are isolated temporally and spatially by a partitioning operating system executed by the multi-core processor chip, as described above. For example, in some embodiments, the partitioning operating system is an ARINC 653 compliant operating system.","At block , a shared cache is accessed by the plurality of processor cores based on the temporal and spatial isolation of the unique applications and unique application tasks. In addition, access to the shared cache is also managed by the respective MMU of each processor core. In this example, the shared cache is a N-ported cache and each processor core accesses the shared cache via a separate port. In this way, each processor core is able to access the shared cache simultaneously with another of the plurality of processor cores. In some embodiments, the shared cache is a level 2 (L2) cache. Alternatively, the shared cache is a level 1 (L1) cache. In other implementations, the shared cache can be a level 3 (L3) cache or more than one of the L1, L2, and L3 caches can be an N-ported shared cache.","By accessing the shared cache according to the temporal and spatial isolation of the applications and tasks, each processor core does not attempt to write to the same address space of the shared cache at the same time as another of the plurality of processor cores. In other words, the multi-core processor does not need the coherency or arbitration algorithms which limit bandwidth in typical multi-core processors.","Although specific embodiments have been illustrated and described herein, it will be appreciated by those of ordinary skill in the art that any arrangement, which is calculated to achieve the same purpose, may be substituted for the specific embodiments shown. Therefore, it is manifestly intended that this invention be limited only by the claims and the equivalents thereof."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DRAWINGS","p":["Understanding that the drawings depict only exemplary embodiments and are not therefore to be considered limiting in scope, the exemplary embodiments will be described with additional specificity and detail through the use of the accompanying drawings, in which:",{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
