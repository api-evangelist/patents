---
title: Method and system for providing an interface through which an application can access a media stack
abstract: A communications system provides a media sender object and a media receiver object that provide an interface between a media stack and an application. The application can use the media sender object to send content to a source media stack and the media receiver object to receive content from a sink media stack. The application programming interface of the media sender object and the media receiver object provides functions for registering and un-registering buffers for storing and receiving content. When a source media stack is ready to send content, it invokes each registered source to collect content to be sent. When a sink media stack has received content, it invokes each registered sink to provide the received content. An application interfaces with a media sender object and a media receiver object to add content to a channel or to receive content from a channel.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07716359&OS=07716359&RS=07716359
owner: Microsoft Corporation
number: 07716359
owner_city: Redmond
owner_country: US
publication_date: 20050509
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATION(S)","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application is related to U.S. patent application Ser. No. 11\/124,911, filed May 9, 2005, entitled \u201cMethod and System for Generating a Routing Table for a Conference,\u201d and filed concurrently, now U.S. Pat. No. 7,593,986 issued on Sep. 22, 2009, which is hereby incorporated by reference.","The described technology relates generally to communication systems and particularly to communicating via a channel having a media stack.","Video conferencing allows conference participants who are at different locations to participate in a conference. Typically, each conference participant has a computer-based video conferencing system that includes a video camera, a microphone, a display device, and a speaker. The video conferencing system of a conference participant captures the video and audio of that conference participant using the video camera and microphone and transmits the video and audio to the video conferencing systems of the other conference participants. When a video conferencing system receives the video and audio from the other conference participants, it presents the video on the display device and outputs the audio to the speaker. A video conferencing system may display each video in a different window on the display device or in a different area of a window. Thus, the conference participants can view the video and hear the audio of the other conference participants.","To support video and audio conferencing, the participant computer systems need to be interconnected in some way. Each connection has a video channel and an audio channel between participant computer systems. Each channel includes a send stream and a receive stream for sending and receiving content of the channel. Each endpoint of a channel includes a source and a sink that are connected to the streams of the channel. For example, the source and the sink of an audio channel are microphones and speakers, respectively. For both streams of an audio channel, a microphone is connected at one endpoint and a speaker is connected at the other endpoint.","Each endpoint of each stream of a channel may have a media stack of components that implement the functions of the stream. The components of the media stack of an audio channel for a source may receive audio content in PCM format, convert the audio content from PCM format to G.722 format, packetize the audio content that is in the G.722 format, and transmit the packetized content to the sink at the other endpoint. The components of a media stack of an audio channel for a sink may receive packetized audio content from the source at the other endpoint, de-packetize the received content, convert the de-packetized content from G.722 format to PCM format, and provide the content in PCM format to the local sink.","The existing channel structure allows only actual devices (e.g., microphones and speakers) to be sources and sinks of a channel. If, for example, a developer wants to intercept and record the content that is received at the sink, then the sink device driver will need to be modified to perform the intercepting and recording. In addition, if a developer wants to provide additional content not provided by a device, then the developer will also need to modify a source device driver. Each developer who wants to provide additional functions will need to modify the drivers accordingly. It would be desirable to have a technique that would allow for the intercepting of content and providing of content in a uniform manner to make it easier for developers to intercept content and provide additional content.","A communications system provides a media sender object and a media receiver object that provide an interface between a media stack and an application. The application can use the media sender object to send content to a source media stack and the media receiver object to receive content from a sink media stack. The application programming interface of the media sender object and the media receiver object provides functions for registering and un-registering buffers for storing and receiving content. When a source media stack is ready to send content, it invokes each registered source to collect content to be sent. When a sink media stack has received content, it invokes each registered sink to provide the received content. An application interfaces with a media sender object and a media receiver object to add content to a channel or to receive content from a channel.","A method and system for interfacing with a media stack in a uniform manner is provided. In one embodiment, a communications system provides a media sender object and a media receiver object that provide an interface between a media stack and an application. The application can use the media sender object to send content to a source media stack and the media receiver object to receive content from a sink media stack. The media objects provide a uniform interface for the application and for the media stack. The application programming interface of the media sender object and the media receiver object provides functions for registering and un-registering buffers for storing and receiving content. The buffers may be represented by a media buffer object. An application that is to send and receive content registers buffers containing the content with a media sender object and registers buffers to receive the content with a media receiver object. When a media object has completed its use of a buffer, it signals the application. If the buffer contains received content, the application can then access the content of the buffer. If the buffer contains content that was sent, then the application can reuse the buffer when sending additional content. An application registers media sender objects and media receiver objects with the streams of a channel. Drivers of actual devices also register with a media stack. Media sender objects and media receiver objects may be considered to be virtual sources and sinks, and drivers for actual devices may be considered to be non-virtual sources and sinks. The media stack provides the channels with the opportunity to send or receive content. When a channel is ready to send content, it invokes each registered source to collect content to be sent. When a channel has received content, it invokes each registered sink to provide the received content. An application interfaces with a media sender object and a media receiver object to add content to a channel or to receive content from a channel. For example, an application may provide background music to an audio channel using a media sender object and may intercept and archive the content of the audio channel using a media receiver object. In this way, applications can use a common interface to interface with the media stack of a channel.","Tables 1A, 1B, 2A, 2B, 3A, and 3C list the methods and properties of the application programming interface (\u201cAPI\u201d) for the media sender object, the media receiver object, and the media buffer object in one embodiment. Tables 1A and 1B list the methods and properties of the media sender object. The media sender object provides methods for enqueueing media buffer objects containing content to be sent and dequeueing media buffer objects whose content has already been sent, canceling queued media buffer objects, and activating and deactivating the functions of the media sender object. The media sender object provides properties indicating status of the current, pending, and completed media buffers, threshold specifications, and media formats. The threshold specifications indicate a threshold mode and a threshold used by the media sender object to notify an application via an event when the threshold of that threshold mode is reached. The application can set the threshold mode to the remaining bytes (i.e., that have not yet been sent) in the pending media buffer objects, remaining pending media buffer objects, or remaining bytes in the current media buffer object. When the application-defined threshold is reached for the application-defined threshold mode, then the media sender object sets an event to notify the application.",{"@attributes":{"id":"p-0018","num":"0017"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"315pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1A"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Media Sender Object--Methods"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Method","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["Activate( )","Start sending content of the media buffer objects in the"]},{"entry":[{},"media buffer queue and enable events"]},{"entry":["Deactivate( )","Stop sending content of the media buffer objects and disable"]},{"entry":[{},"events"]},{"entry":["CancelCurrentBuffer( )","Stop sending content of the current media buffer object; the"]},{"entry":[{},"media sender object will start sending content of the next"]},{"entry":[{},"media buffer object and set a buffer completion event for the"]},{"entry":[{},"canceled media buffer object"]},{"entry":["CancelAllPendingBuffers( )","Stop sending content of the current and pending media"]},{"entry":[{},"buffer objects; the media sender object will set buffer"]},{"entry":[{},"completion events for the canceled media buffer objects"]},{"entry":["EnqueueBuffer(RtpMediaBuffer{circumflex over (\u2009)}buffer)","Add the passed media buffer object onto the end of the"]},{"entry":[{},"media buffer queue"]},{"entry":["RtpMediaBuffer{circumflex over (\u2009)}DequeueCompleteBuffer( )","Remove the next completed media buffer object from the"]},{"entry":[{},"media buffer queue and return a reference to the media"]},{"entry":[{},"buffer object"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0019","num":"0018"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1B"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Media Sender Object--Properties"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Property","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["NumberOfPendingBuffers","Number of media buffer objects in the media buffer queue"]},{"entry":[{},"that are not completed"]},{"entry":["NumberOfPendingBytes","Number of bytes in the pending media buffer objects that"]},{"entry":[{},"have not yet been sent"]},{"entry":["CurrentPendingBuffer","Reference to media buffer object whose data is currently"]},{"entry":[{},"being sent"]},{"entry":["NumberOfCompletedBuffers","Number of media buffer objects in the media buffer queue"]},{"entry":[{},"that are completed"]},{"entry":["NumberOfCompletedBytes","Number of bytes in the completed media buffer objects"]},{"entry":["FirstCompletedBuffer","Reference to first completed media buffer object"]},{"entry":["BufferThreshold","Threshold for event notification"]},{"entry":["BufferThresholdMode","Type of threshold for threshold event notification: number of"]},{"entry":[{},"remaining bytes in the pending media buffer objects, number"]},{"entry":[{},"of pending media buffer objects, or number of bytes"]},{"entry":[{},"remaining in the current media buffer object"]},{"entry":["BufferThresholdEvent","Event that is set when the buffer threshold is satisfied"]},{"entry":["BufferCompletedEvent","Event that is set upon completion of sending the data of the"]},{"entry":[{},"current media buffer object"]},{"entry":["IsActive","Flag indicating whether the media sender object is active"]},{"entry":["MixMediaSender","Flag indicating whether the data of the media sender object"]},{"entry":[{},"is to be mixed"]},{"entry":["VideoFormat","Format of the video of the media sender object such as"]},{"entry":[{},"IYUV and YUY2"]},{"entry":["VideoSize","Size of the video such as VGA and CIF"]},{"entry":["TargetFramesPerSecond","Number of frames per second to be sent"]},{"entry":["FramesPerSecond","Number of frames per second actually sent"]},{"entry":["AudioFormat","Format of the audio of the media sender object such as"]},{"entry":[{},"PCM16K and PCM8K"]},{"entry":["Volume","Percent of supplied volume"]},{"entry":["NormalizeAudioForMixer","Flag indicating whether to normalize audio for mixer"]},{"entry":["DetectSignalLevel","Flag indicating whether the signal level is to be detected"]},{"entry":["CompressAudio","Percent to stretch or compress the audio"]},{"entry":["SignalLevel","Signal level of PCM16K"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"Tables 2A and 2B list the methods and properties of the media receiver object. The media receiver object provides methods for enqueueing media buffer objects for storing content that is to be received and dequeueing media buffer objects that contain received content, canceling queued media buffer objects, and activating and deactivating the functions of the media receiver object. The media receiver object provides properties indicating status of the current, pending, and completed media buffer objects, threshold specifications, and media formats. The threshold specifications indicate the threshold mode and threshold used by the media sender object to notify an application via an event when the threshold of the threshold mode is reached. The application can set the threshold mode to the remaining bytes (i.e., bytes that do not yet have content stored in them) in the pending media buffer objects, remaining pending media buffer objects, or remaining bytes in the current media buffer object. When the application-defined threshold is reached for the application-defined threshold mode, then the media sender object sets an event to notify the application.",{"@attributes":{"id":"p-0021","num":"0020"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2A"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Media Receiver Object--Methods"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"119pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Method","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["Activate( )","Start receiving content into the media buffer objects in the"]},{"entry":[{},"media buffer queue and enable events"]},{"entry":["Deactivate( )","Stop receiving content into the media buffer objects in the"]},{"entry":[{},"media buffer queue and disable events"]},{"entry":["CancelCurrentBuffer( )","Stop receiving content into the current media buffer object;"]},{"entry":[{},"the media receiver object will start receiving content into the"]},{"entry":[{},"next media buffer object and set a completion event for the"]},{"entry":[{},"canceled media buffer object"]},{"entry":["CancelAllPendingBuffers( )","Stop receiving content into the current and pending media"]},{"entry":[{},"buffer objects; the media receiver object will set completion"]},{"entry":[{},"events for the canceled media buffer objects"]},{"entry":["EnqueueBuffer(RtpMediaBuffer{circumflex over (\u2009)}buffer)","Add the passed media buffer object onto the end of media"]},{"entry":[{},"buffer queue"]},{"entry":["RtpMediaBuffer{circumflex over (\u2009)}","Remove the next completed media buffer object from the"]},{"entry":["DequeueCompletedBuffer( )","media buffer queue and return a reference to the media"]},{"entry":[{},"buffer object"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0022","num":"0021"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"280pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2B"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Media Receiver Object--Properties"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Property","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["NumberOfPendingBuffers","Number of media buffer objects in the media buffer queue"]},{"entry":[{},"that are not completed"]},{"entry":["NumberOfPendingBytes","Number of bytes in the pending media buffer objects that"]},{"entry":[{},"have not yet received data"]},{"entry":["CurrentPendingBuffer","Reference to media buffer object that is currently receiving"]},{"entry":[{},"data"]},{"entry":["NumberOfCompletedBuffers","Number of media buffer objects in the media buffer queue"]},{"entry":[{},"that are completed"]},{"entry":["NumberOfCompletedBytes","Number of bytes in the completed media buffer objects"]},{"entry":["FirstCompletedBuffer","Reference to first completed media buffer object"]},{"entry":["BufferThreshold","Threshold for event notification"]},{"entry":["RtpMediaBufferThresholdMode","Type of threshold for threshold event notification: number of"]},{"entry":[{},"remaining bytes in the pending media buffer objects, number"]},{"entry":[{},"of pending media buffer objects, or number of bytes"]},{"entry":[{},"remaining in the current media buffer object"]},{"entry":["BufferThresholdEvent","Event that is set when the buffer threshold is satisfied"]},{"entry":["BufferCompletedEvent","Event that is set upon completion of receiving data into the"]},{"entry":[{},"current media buffer object"]},{"entry":["IsActive","Flag indicating whether the media sender object is active"]},{"entry":["VideoFormat","Format of the video of the media sender object"]},{"entry":["AudioFormat","Format of the audio of the media sender object"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"Tables 3A and 3B list the methods and properties of the media buffer object. The media buffer object provides methods for setting the length of an allocated media buffer and for copying media buffers between managed and unmanaged memory. The media buffer objects provide properties for the media buffer such as the allocated length and processed length.",{"@attributes":{"id":"p-0024","num":"0023"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"308pt","align":"center"}},"thead":{"row":{"entry":"TABLE 3A"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Media Buffer Object--Methods"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Method","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["RtpMediaBuffer(int bufferlength)","Sets the length of the media buffer to be allocated"]},{"entry":["Int UnmanagedCopy(int start, int length,","Copies from the passed buffer of unmanaged memory into"]},{"entry":["void *buffer)","the media buffer in managed memory"]},{"entry":["Int UnmanagedCopyIn(int rtpBufferOffset,","Copies from the passed buffer of unmanaged memory into"]},{"entry":["void *buffer, int offset, int length)","the media buffer at buffer offset in managed memory"]},{"entry":["Int UnmanagedCopyOut(int rtpBufferOffset,","Copies to the passed buffer of unmanaged memory from the"]},{"entry":["void *buffer, int offset, int length)","media buffer at buffer offset in managed memory"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0025","num":"0024"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 3B"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Media Buffer Object--Properties"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Property","Description"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Buffer","Reference to media buffer"]},{"entry":[{},"AllocatedLength","Length of media buffer"]},{"entry":[{},"UsedLength","Length of media buffer used"]},{"entry":[{},"ProcessedLength","Length of media buffer that"]},{"entry":[{},{},"has been processed"]},{"entry":[{},"UserData","Reference to user data in"]},{"entry":[{},{},"managed memory"]},{"entry":[{},"Timestamp","Local timestamp"]},{"entry":[{},"IsQueued","Flag indicating whether media"]},{"entry":[{},{},"buffer object is queued in a"]},{"entry":[{},{},"media sender object or a"]},{"entry":[{},{},"media receiver object"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 1","b":["100","110","120","101","100","150","101","131","133","100","141","143","100","111","112","113","113","150","121","122","123","123","150","111","111","111","112","112","113","150","123","150","101","123","122","121","121","141","143","101"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 2","b":["200","250","201","251","201","251","201","202","251","252","203","253","255","205"]},"The computing device on which the communications system is implemented may include a central processing unit, memory, input devices (e.g., keyboard and pointing devices), output devices (e.g., display devices), and storage devices (e.g., disk drives). The memory and storage devices are computer-readable media that may contain instructions that implement the communications system. In addition, the data structures and message structures may be stored or transmitted via a data transmission medium, such as a signal on a communications link. Various communications links may be used, such as the Internet, a local area network, a wide area network, a point-to-point dial-up connection, a cell phone network, and so on.","Embodiments of the communications system may be implemented in various operating environments that include personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, programmable consumer electronics, digital cameras, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and so on. The computer systems may be cell phones, personal digital assistants, smart phones, personal computers, programmable consumer electronics, digital cameras, and so on.","The communications system may be described in the general context of computer-executable instructions, such as program modules, executed by one or more computers or other devices. Generally, program modules include routines, programs, objects, components, data structures, and so on that perform particular tasks or implement particular abstract data types. Typically, the functionality of the program modules may be combined or distributed as desired in various embodiments.",{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 3","FIG. 3"],"b":["301","302","302","303"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 4","FIG. 4"],"b":["401","402","403","403","404","405","406","407","401","407","401"]},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 5","b":["501","502","502","503","509","503","504","510","506","506","507","507","508","509","503","510","513","510","511","512","513","501","513","501"]},{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 6","FIG. 6"],"b":["601","602","602","603"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 7","b":["701","702","702","703","709","703","704","710","705","705","706","707","708","709","708","709","703","710","714","710","712","712","713","714","701","714","701"]},"From the foregoing, it will be appreciated that specific embodiments of the communications system have been described herein for purposes of illustration, but that various modifications may be made without deviating from the spirit and scope of the invention. In one embodiment, the media receiver object may provide metadata associated with a buffer to be transmitted. The metadata may be an array of structures with each structure corresponding to a certain amount of content (e.g., 10 milliseconds). When the content is audio, the structure may identify whether the content was modified by an audio healer (e.g., to perform error concealment or delay reduction in voice over IP), compressed, or stretched. The structure may also identify whether a frame contains concealed audio or comfort noise audio generated by an audio healer. Accordingly, the invention is not limited except as by the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
