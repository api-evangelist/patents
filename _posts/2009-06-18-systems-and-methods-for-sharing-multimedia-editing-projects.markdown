---
title: Systems and methods for sharing multimedia editing projects
abstract: The sharing of video editing techniques is performed by receiving a project description file, thumbnail graphics, and a location identifier at a first server, wherein the project description file is generated during editing of multimedia content by the user, and wherein the thumbnail graphics represent multimedia editing objects incorporated into the edited multimedia content. The edited multimedia content is retrieved from a second server based on the location identifier. The edited multimedia content is synchronized with the thumbnail graphics and multimedia editing objects specified by the project description file. The synchronized edited multimedia content, thumbnail graphics, and multimedia editing objects are displayed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08701008&OS=08701008&RS=08701008
owner: Cyberlink Corp.
number: 08701008
owner_city: Shindian, Taipei
owner_country: TW
publication_date: 20090618
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The present disclosure generally relates to editing multimedia content and more particularly, relates to systems and methods for sharing multimedia editing projects.","With the vast array of video editing tools available, many people can readily edit existing video and incorporate special effects to customize videos and to produce stylish graphics. These videos may later be published for others to view. In many cases, however, an individual may want a more professional look before sharing the video with friends and family. Use of professional video editing services may not be a feasible alternative in many instances due to cost. One common problem with traditional video editing solutions, however, is the degree of time and complexity involved in the overall editing process. Therefore, there exists a need for improving a user's ability to share video editing techniques with others.","Briefly described, one embodiment, among others, is a method performed at a first server for sharing video editing techniques by a user. The method comprises receiving a project description file, wherein the project description file is generated during editing of multimedia content by the user, and the project description file contains information relating to the edited multimedia content. The method further comprises receiving a location identifier specifying a location of the edited multimedia content, retrieving the edited multimedia content from a second server using the location identifier, providing a user interface comprising a timeline, and displaying multimedia editing objects specified by the project description file along the timeline. While rendering the edited multimedia content received from the second server on the user interface, the rendering of the edited multimedia content is synchronized with the multimedia editing objects according to timing data specified in the project description file with respect to the timeline.","Another embodiment is a system for sharing multimedia editing techniques. The system comprises a first server and a project sharing application executable in the first server that responds to requests for reviewing edited multimedia content. For such embodiments, the project sharing application comprises a user interface configured to receive the edited multimedia content from a second server and an object collecting module configured to receive a project description file associated with timing data of the edited multimedia content and determine arrangement of multimedia editing objects specified in the project description file. The project sharing application further comprises a playback module configured to playback the edited multimedia content from the second server while the multimedia editing objects specified in the project description file are synchronized according to the timing data.","Another embodiment is a method for sharing multimedia content editing techniques by a user. The method comprises receiving a project description file, thumbnail graphics, and a location identifier at a first server, wherein the project description file is generated during editing of multimedia content by the user, and wherein the thumbnail graphics represent multimedia editing objects incorporated into the edited multimedia content. The method further comprises retrieving the edited multimedia content from a second server based on the location identifier. The method also comprises synchronizing the edited multimedia content with the thumbnail graphics and multimedia editing objects specified by the project description file and displaying the synchronized edited multimedia content, thumbnail graphics, and multimedia editing objects.","Other systems, methods, features, and advantages of the present disclosure will be or become apparent to one with skill in the art upon examination of the following drawings and detailed description. It is intended that all such additional systems, methods, features, and advantages be included within this description, be within the scope of the present disclosure, and be protected by the accompanying claims.","Having summarized various aspects of the present disclosure, reference will now be made in detail to the description of the disclosure as illustrated in the drawings. While the disclosure will be described in connection with these drawings, there is no intent to limit it to the embodiment or embodiments disclosed herein. On the contrary, the intent is to cover all alternatives, modifications and equivalents included within the spirit and scope of the disclosure as defined by the appended claims.","One perceived shortcoming with traditional multimedia editing solutions is the degree of time and complexity involved in the overall editing process. Various embodiments are thus described where a user uploads a multimedia editing project in order to allow other users to view and track the editing process of multimedia content. In this regard, the embodiments described provide users with a means for sharing creative ideas in editing multimedia content so that those with more extensive experience in editing multimedia content have a forum for sharing their techniques with others. In the following discussion, a description of the various components of a networked environment is described, followed by a discussion of the operation of these components. It should be understood that, as used herein, \u201cvideo\u201d or \u201cmultimedia content\u201d may include, but is not limited to, video data, audio data, text, still images, or combinations of such content.","Reference is made to , which depicts a top-level diagram of a system for sharing multimedia editing techniques. For some embodiments, a system for sharing multimedia editing techniques may be incorporated in an editing system  such as, for example, a desktop computer, a computer workstation, or a laptop. The editing system  may include a display  and input devices such as a keyboard  and a mouse . In other embodiments, the editing system  may comprise a video gaming console , which includes a video game controller . For such embodiments, the video gaming console  may be connected to a television (not shown) or other display. Generally, the editing system  may comprise a playback application  such as CyberLink's PowerDirector\u00ae. The playback application  is generally embodied on a computer readable medium and executable by a processor that allows a user to view a movie title, input special effects, and upload a video editing project. The editing system  may further comprise project metadata , which is created and collected in a project description file, for example, during the video editing process using a video editor .","The project metadata  may be used to specify certain attributes of a video and may be utilized in a wide variety of ways. As non-limiting examples, metadata might contain miscellaneous information about a given video such as the chapter list, content rating (e.g., General (G), Parental Guidance (PG), PG-13, Restricted (R)), performers (actors, actresses, musicians, etc.), and a brief synopsis of the movie. Other non-limiting examples include information relating to the multimedia editing objects such as special effects, audio, and subtitles incorporated into video clips. Such information may comprise, for example, timing data of each of the special effects, audio, and subtitles and the category of special effect. By way of illustration, the metadata might specify that a customized subtitle is shown at start time 00:00:31 and disappears at an end time 00:00:41 in a particular video. As another illustration, the metadata might specify that a picture-in-picture (PiP) object such as a star object is shown in the video at a start time 00:00:45 and disappears at an end time 00:00:55. With exemplary embodiments described, project metadata  may be generated during the video editing process and associated with a video editing project. Note that the video editing project may comprise a combination of project metadata  and existing metadata associated with a particular video.","The editing system  in  reads multimedia content stored in any of a variety of formats or stored on various types of storage media. As non-limiting examples, the editing system  may be configured to read media content encoded in such formats as Digital Video Disc (DVD), Video CD (VCD), High Definition DVD (HD-DVD), BLU-RAY Disc, and China Blue High-Definition (CBHD) stored on a storage medium . In some embodiments, the editing system  may also be configured to read multimedia content from managed copies  of an HD-DVD or a BLU-RAY Disc. The phrase \u201cmanaged copy\u201d refers to authorized copies of multimedia content used as a reference video for editing purposes. The above exemplary formats are merely examples, and it is intended that the various embodiments described herein cover multimedia content in general.","The editing system  receives the storage media  or managed copies  containing the multimedia content and plays back the multimedia for a user to view and edit. In some embodiments, the editing system  may be coupled to a network , such as the Internet. For some implementations, the networked environment depicted in  may be configured to incorporate cloud computing, whereby hosted services are delivered via the Internet. In accordance with some embodiments, a user uploads an edited multimedia content to one or more video sharing\/content portal websites , such as, for example, YouTube. Such websites  may be hosted on a web portal server  and where web pages are rendered locally on the display  of a computer .","The networked environment shown in  further comprises a information sharing website , such as, for example, CyberLink's\u00ae DirectorZone or other Web 2.0 websites, where users can upload a project description file containing project metadata  to and share their video editing techniques with others. For some implementations, project description files may include a mapping table that specifies a particular multimedia editing object, a corresponding description, and a corresponding time tag. As such, the information sharing website  may serve as a forum for users to share their video editing projects. Note that for some implementations, the information sharing website and the video sharing\/content portal website may be integrated into a single website. Also shown in  is a viewing system or client , which allows a second user to view edited multimedia content created on the editing system . The viewing system  may also be connected to the network . Through the network , the second user may utilize the viewing system or client  to view both the edited multimedia content and the project metadata including multimedia editing objects such as special effects, audio and subtitles incorporated by the first user by accessing the information sharing website . The edited multimedia content may comprise a combination of edited video and audio.","Reference is now made to , which illustrates an embodiment of the editing system  shown in . Generally speaking, the editing system  may comprise any one of a wide variety of wired and\/or wireless computing devices, such as a desktop computer, portable computer, dedicated server computer, multiprocessor computing device, cellular telephone, personal digital assistant (PDA), handheld or pen based computer, embedded appliance and so forth. The editing system  may also comprise a video game console such as the popular Wii\u00ae platform by Nintendo and the Playstation 3\u00ae from Sony. Irrespective of its specific arrangement, editing system  can, for instance, comprise memory , a processing device , a number of input\/output interfaces , a network interface , a display , and mass storage , wherein each of these devices are connected across a data bus .","The processing device  can include any custom made or commercially available processor, a central processing unit (CPU) or an auxiliary processor among several processors associated with the editing system , a semiconductor based microprocessor (in the form of a microchip), a macroprocessor, one or more application specific integrated circuits (ASICs), a plurality of suitably configured digital logic gates, and other well known electrical configurations comprising discrete elements both individually and in various combinations to coordinate the overall operation of the computing system.","The memory  can include any one of a combination of volatile memory elements (e.g., random-access memory (RAM, such as DRAM, and SRAM, etc.)) and nonvolatile memory elements (e.g., ROM, hard drive, tape, CDROM, etc.). The memory  typically comprises a native operating system , one or more native applications, emulation systems, or emulated applications for any of a variety of operating systems and\/or emulated hardware platforms, emulated operating systems, etc. For example, the applications may include application specific software such as the playback application  and video editor  depicted in . One of ordinary skill in the art will appreciate that the memory  can, and typically will, comprise other components which have been omitted for purposes of brevity.","Input\/output interfaces  provide interfaces for the input and output of data. For example, where the editing system  comprises a personal computer, these components may interface with user input device , which may be a keyboard or a mouse, as shown in . Where the editing system  comprises a gaming console, the input\/output interfaces  may communicate with a video game controller such as, for example, the wireless Wii Remote\u00ae and Wii MotionPlus\u00ae from Nintendo or the DualShock\u00ae and wand-shaped motion controller from Sony. Using such controllers, a user can incorporate multimedia editing objects into a video through a series of motions. Display  can comprise, for example, a computer monitor, plasma television, or a liquid crystal display (LCD).","In the context of this disclosure, a \u201ccomputer-readable medium\u201d stores the program for use by or in connection with the instruction execution system, apparatus, or device. The computer readable medium can be, for example, but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, device, or transport medium. More specific examples (a non-exhaustive list) of the computer-readable medium may include by way of example and without limitation: an electrical connection (electronic) having one or more wires, a portable computer diskette (magnetic), a random access memory (RAM) (electronic), a read-only memory (ROM) (electronic), an erasable programmable read-only memory (EPROM, EEPROM, or Flash memory) (electronic), an optical fiber (optical), and a portable compact disc read-only memory (CDROM) (optical).","With further reference to , network interface device  comprises various components used to transmit and\/or receive data over a network environment. For example, the network interface  may include a device that can communicate with both inputs and outputs, for instance, a modulator\/demodulator (e.g., a modem), wireless (e.g., radio frequency (RF)) transceiver, a telephonic interface, a bridge, a router, network card, etc.). As shown in , the editing system  may communicate with the video sharing server  and the information sharing server  via the network interface  over the network . As noted earlier, the video sharing server  and the information sharing server  may be integrated into a single server for some embodiments. The editing system  may further comprise mass storage  which stores and manages such data as the project metadata  associated with a video editing project.","Reference is made to , which illustrates an embodiment of the information sharing server  shown in . As with the editing system  described above for , the information sharing server  may comprise any one of a wide variety of computing devices, such as a desktop computer, portable computer, and so forth. The information sharing server  may be further embodied in a server-client configuration as known by one of ordinary skill in the art. The information sharing server  further comprises memory , a processing device , and a network interface , which allows the information sharing server  to communicate with external devices such as the editing system  and viewing system\/client  in  via the network . Each of these components , ,  may be connected across a data bus .","The memory  may comprise application specific software such as a video sharing server interface  that allows the information sharing server  to receive video and other content from the video sharing server  or other web portals. The memory  further comprises an object collecting module  configured to receive project metadata  stored in a project description file and determine which special effects, audio, and subtitles have been incorporated into a particular video. The playback module  receives the video from the video sharing server interface  and the multimedia editing objects such as special effects, audio, and subtitles from the object collecting module  and forwards the data to the synchronizer . The synchronizer  provides an output comprising the edited multimedia content synchronized with the multimedia editing objects such as special effects, audio, and subtitles. The information sharing server  further comprises a website portal application  stored in memory  which hosts and manages one or more information sharing web pages .","The information sharing web pages  are rendered on a display at the user end and provide a user such as one utilizing the viewing station\/client  in  with a graphical user interface for uploading video editing project data. The website portal application  also receives the output generated by the synchronizer  and renders the output on one or more information sharing pages  for a user to view. As will be described later, a viewing station or client  receiving the output views the edited multimedia content in addition to various thumbnail graphics depicted in a timeline. The thumbnails signify the various special effects, audio, and subtitles and the associated timing that have been incorporated into the video. As described earlier, a computer-readable medium can be any medium that can contain, store, or maintain the various applications , , , ,  described above for use by or in connection with an instruction execution system whereby a processor  executes the applications , , , , .",{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 4A","FIG. 1"],"b":["102","132","136","132","136","132","136","132","136","118","132","136","132","136"]},"A user edits a video using a video editor  on the editing system  in , whereby project metadata  associated with the video editing process is generated, and the association of the project metadata  is stored in a project description file . The project description file  may be in the form of an extensible markup language (XML) file or written in other language. As shown in , the project description file  may include a plurality of objects , , which may include, for example, thumbnails, effects, original video clips, audio, subtitle, etc. For some embodiments, the project description file  may thus comprise an XML file and thumbnail graphics. In other embodiments, however, the project description file  itself may be an XML file that describes information relating to the effects. For such embodiments, the thumbnail graphics are not included in the project description file . Each object ,  comprises a corresponding time tag according to the edited multimedia content.","Upon editing the multimedia content, the user uploads the edited multimedia content  to one or more video sharing\/content portal websites , where the edited multimedia content  may be stored online on the one or more video sharing servers . After uploading the edited multimedia content  and storing the edited multimedia content  online at the one or more video sharing servers , the video system  may receive a location identifier from the one or more video sharing servers , which specifies where to retrieve the stored multimedia content . For some embodiments, the location identifier may comprise a uniform resource locator (URL). The video system  then uploads the project description file , the thumbnail graphics, and the location identifier  to the information sharing server .","Upon playback, the edited multimedia content  may be streamed from the video sharing server  and rendered as a web page by the information sharing server . Specifically, the web page may be rendered on a display and viewed by the client . When the client  elects to playback the edited multimedia content  and view how the special effects and\/or templates were incorporated into the video, the information sharing server  accesses the edited multimedia content  using the location identifier , and the video sharing server  streams the edited multimedia content  to the information sharing server . In the non-limiting example described earlier, the video sharing website may be the popular YouTube website, where many individuals access personalized video content. In implementations where the edited multimedia content  is stored on YouTube, the information sharing server  interfaces with the YouTube server(s) using a YouTube application programming interface (API), whereby video content is played back on the information sharing web page to provide seamless playback. Thus, during playback of a selected multimedia content , the viewing station\/client  receives both the edited multimedia content  and the special effects, audio, and subtitles  synchronized together. This allows the user at the viewing station  to precisely follow the editing process and techniques utilized by the first user  in editing the video.",{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIG. 5","FIG. 1"],"b":["502","114","102","502","502","508","504","508"]},"As part of the editing process, the user specifies the timing of the special effect. For example, the star  shown in  may be displayed starting at time 00:00:31, at which time, the star appears and moves in the manner shown. While the video is being edited, the special effect (i.e., star PiP effect) and the associated timing (e.g., 00:00:31 to 00:00:39) is captured in project metadata , which is later uploaded to the information sharing website  to be stored on the information sharing server . Furthermore, thumbnail graphics such as the one  shown in  are created that represent the various special effects being incorporated into the video. In accordance with some embodiments, the thumbnails  may be defined by the user by specifying, for example, a bitmap file or other graphic file. Alternatively, the thumbnails  may comprise a snapshot of the particular frame in which the multimedia editing object is first introduced into the edited multimedia content . The thumbnails  are also captured in the project description file . As described earlier, for some implementations, project metadata  may be stored in a project description file, whereby timing data of the multimedia editing content or special effects are specified. The project description file may be in the form of an extensible markup language (XML) file, which allows a user to share information between the editing system  and the information sharing server .","The user interface  further comprises a \u201cSHARE\u201d button  which allows a user to upload the edited multimedia content  and associated project metadata  to the information sharing website  to be shared among a community of users that access the website . It should be noted that that the user interface  may further comprise different buttons to separately upload edited multimedia content and project metadata. The user interface  may also be used to share an individual template (i.e., special effect) to the information sharing website  by clicking the \u201cSHARE\u201d button  or other button.","In some embodiments, the user may login to an existing account maintained by the information sharing server . The information sharing server  provides online storage of the video editing metadata  captured in a project description file  without the need for storing the edited multimedia content itself , thereby saving considerable storage space. As described above, the edited multimedia content  is stored at the video sharing server . For some embodiments, however, the video sharing server  and the information sharing server  may be integrated into a single server, so that the edited multimedia content  is stored in the integrated server.",{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 6","FIG. 1"],"b":["602","402","103","134","402","610","612","614","616","618","620","604","402","604","602"]},"The user interface  further comprises a main display  in which the edited multimedia content  is played back in addition to a plurality of navigation control buttons  for the user to control playback, fast forward, fast backward, pause, and stop functions relating to the edited multimedia content . A user may click navigation control buttons  to view the edited multimedia content  or click the timing bar  at a particular time. A progression bar (e.g., a vertical bar)  on the effects bar of the user interface  moves according to movement of the timing bar  by the user and jumps to a particular time. For some implementations, a user may drag the progression bar  to control playback of the edited multimedia content , as depicted in . The information sharing server  sends timing data based on movement of the progression bar  to the video sharing server  to request streaming of the edited multimedia content  according to timing data  specified by movement of the progression bar . This gives the user full control in viewing the edited multimedia content  in conjunction with the special effects.","By way of illustration, suppose the user drags the progression bar  to time 00:00:31. For some embodiments, the information sharing server  sends this information  to the video sharing server . In response, the video sharing server  transmits the edited multimedia content , which is received at the information sharing server  to be displayed on the user interface hosted by the information sharing server . The edited multimedia content  is then displayed, beginning at time 00:00:31. The user interface may be rendered on the display at a client . For some implementations, the information sharing server  may receive the edited multimedia content  from the video sharing server  via streaming transmission. While the user drags the progression bar , the edited multimedia content  and the special effects are synchronized according to the associated timing specified in the project description file. As described earlier, the information sharing server  and the video sharing server  may be integrated into a single server for some implementations. For such implementations, communication between the two server modules ,  may be performed via an internal interface. In this regard, displaying the time of the edited multimedia content  is synchronized with the location of the progression bar .","In an alternative embodiment, a user may control playback of the edited multimedia content  via navigation controls comprising the timing bar (i.e., seek bar)  and\/or control buttons . For some embodiments, the navigation controls may be similar to those normally displayed by the video sharing server  when users wish to view multimedia content. The information sharing server  generates a user interface that embeds a user interface similar to one normally provided by the video sharing server  in order to provide seamless playback. As an illustration, the navigation controls displayed when users access the YouTube website may be embedded into the user interface hosted by the information sharing server . The embedded user interface includes the navigation controls , . Thus, when a user utilizes the navigation controls ,  to control playback, playback instructions are executed by the video sharing server  rather than by the information sharing server . For such embodiments, the marker\/progression bar  is synchronized with the seek bar  in order to show which special effect or video editing object is applied to the edited multimedia content at a particular point in time.","During playback of the edited video received from the video sharing server , the information sharing server  sends a timing request  to the video sharing server  to determine the current playback time. Based on timing data  received from the video sharing server , the information sharing server  updates the progression bar  in the user interface  according to the received timing data from the video sharing server . As one of ordinary skill will appreciate, there are different means for controlling playback of the edited multimedia content .","The effects bar shown in the user interface  comprises the various multimedia editing objects. The effects bar provides an index of the special effects, audio, subtitles, etc. used by the creator of the video. Shown also are various thumbnails , , , , ,  that represent the various multimedia editing objects which are used by the author to create the edited multimedia content . As described earlier, the thumbnails , , , , ,  may comprise customized graphics selected by the user during editing of multimedia content by using a video editor. In some embodiments, the thumbnails , , , , ,  may also be automatically generated whereby a snapshot of the frame within the video  is stored as the thumbnail , , , , , . The user interface  contained in the information sharing website  also comprises a timeline and a marker or a progression bar  which shows the progression of the edited multimedia content  during playback. The placement of each of the thumbnails , , , , ,  corresponds with the associated timing data specified in the project description file . The timing data or time tags ,  stored in the project description file  specify the start time and end time of each of the multimedia editing objects.","For some implementations, the thumbnails , , , , ,  appear only as the progression bar  passes. In other implementations, the thumbnails , , , , ,  are highlighted as the progression bar  passes. The user may also select one of the thumbnails , , , , ,  to highlight a multimedia editing object which the user is interested in. When the user clicks on the thumbnail , , , , , , the edited multimedia content is synchronized on the main display to a point in time corresponding to the timing data of the selected thumbnail , , , , , . The user viewing the editing process may further control playback of the edited multimedia content by controlling the progression bar  or by using the navigation controls  shown.","The timing data of the one or more multimedia editing objects may be monitored by viewing or controlling the timing bar  shown. One should note that the timing bar  associated with video playback is synchronized with the display or highlighting of thumbnails , , , , ,  as the corresponding special effect (e.g., customized text) is incorporated into the video. As described earlier, the user may drag the progression bar  to jump to another point in time along the timeline. While the user is dragging the progression bar , the edited multimedia content  is synchronized and displayed on the main display  according to location of the progression bar . In this regard, the viewer can fully appreciate the timing and editing techniques used by the creator (e.g., \u201cSmithJ\u201d) without the need for first investing in video editor software. For some embodiments, the user can also download the special effects by clicking a link . For other embodiments, the user can download the special effects by clicking the thumbnails , , , , , . The user will then be directed to another website to download the desired special effects. Depending on the implementation, this may involve the user downloading the previously uploaded project metadata . Upon downloading the project metadata , the user may utilize a video editor  compatible with the project metadata  and utilize the project metadata  as a template. To help a user navigate through the one or more information sharing websites  hosted on the information sharing server , the information sharing websites  may provide another user interface (not shown) whereby a user can choose to view edited multimedia content  that are categorized according to the special effects (e.g., static objects, motion objects, frames) contained in the edited multimedia content . If a user clicks on the \u201cMotion Objects\u201d tab, for instance, a list of edited multimedia content  containing moving graphics will be displayed. The user can then select specific multimedia content  to view.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 9","FIG. 1","FIG. 1"]},"In the embodiment described below, a method is performed at a first server for sharing video editing techniques by a user. In block , a project description file is received. The project description file is generated during editing of multimedia content by the user and contains information relating to the edited multimedia content. In block , a location identifier specifying a location of the edited multimedia content is received. For some embodiments, the location identifier may comprise a uniform resource locator (URL). In block , the edited multimedia content is received from a second server using the location identifier. A user interface comprising a timeline is provided in block . In block , multimedia editing objects specified by the project description file are display along the timeline. While rendering the edited multimedia content received from the second server on the user interface, the rendering of the edited multimedia content is synchronized with the multimedia editing objects according to timing data specified in the project description file with respect to the timeline (block ). Note that for some embodiments, the steps described above may be performed in real time where individuals are able to view video editing objects being incorporated into a multimedia file in real-time or near real-time. For such embodiments, the real time editing may be performed by incorporating Internet based interactive functionality into the editing system  of . For other embodiments, such real time editing may be incorporated into the Blu-ray (BD) Live platform. Using the real-time feature, users may take part in peer-to-peer interactions.",{"@attributes":{"id":"p-0051","num":"0050"},"figref":["FIG. 10","FIG. 1","FIG. 1"]},"Beginning with block , the method comprises receiving a project description file, thumbnail graphics, and a location identifier at a first server. Again, for some embodiments, the location identifier may comprise a URL. The project description file is generated during editing of multimedia content by the user. Furthermore, the thumbnail graphics represent multimedia editing objects incorporated into the edited multimedia content. In block , the edited multimedia content is retrieved from a second server based on the location identifier. In block , the edited multimedia content is synchronized with the thumbnail graphics and multimedia editing objects specified by the project metadata. In block , the synchronized edited multimedia content, thumbnail graphics, and multimedia editing objects are displayed.","It should be emphasized that the above-described embodiments are merely examples of possible implementations. Many variations and modifications may be made to the above-described embodiments without departing from the principles of the present disclosure. All such modifications and variations are intended to be included herein within the scope of this disclosure and protected by the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Many aspects of the disclosure can be better understood with reference to the following drawings. The components in the drawings are not necessarily to scale, emphasis instead being placed upon clearly illustrating the principles of the present disclosure. Moreover, in the drawings, like reference numerals designate corresponding parts throughout the several views.",{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0011","num":"0010"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIGS. 4A-B","FIG. 1"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 5","FIG. 1"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIGS. 6-8"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 9","FIG. 1"]},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 10","FIG. 1"]}]},"DETDESC":[{},{}]}
