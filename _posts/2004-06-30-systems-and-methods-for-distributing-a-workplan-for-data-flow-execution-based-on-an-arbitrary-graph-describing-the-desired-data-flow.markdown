---
title: Systems and methods for distributing a workplan for data flow execution based on an arbitrary graph describing the desired data flow
abstract: Various embodiments of the present invention are directed to the creation of multiple redundant chains of transforms, each on a separate processing thread, for a data flow execution (DFE) of a data transformation pipeline (DTP). For certain of these embodiments, a “distributor” receives a buffer as input and directs that buffer to one of several parallel identical threads to process that buffer. A scheduler would create each of these multiple threads, each thread having an identical (redundant) strings of transforms (chains) downstream from the distributor, and all of which would lead even further downstream to a collector that is responsible for collecting and, if necessary, ordering the buffers processed by the previous redundant chains. In this way, the distributors and collectors provide increased scalability for the pipeline by implicitly partitioning (distributing) individual buffers to one of many threads for at least a part of their execution/processing.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07930432&OS=07930432&RS=07930432
owner: Microsoft Corporation
number: 07930432
owner_city: Redmond
owner_country: US
publication_date: 20040630
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS","CONCLUSION"],"p":["This application claims benefit of U.S. Provisional Application No. 60\/573,963, entitled \u201cSYSTEMS AND METHODS FOR DISTRIBUTING A WORKPLAN FOR DATA FLOW EXECUTION BASED ON AN ARBITRARY GRAPH DESCRIBING THE DESIRED DATA FLOW\u201d, filed May 24, 2004, the entire contents of which are hereby incorporated herein by reference.","This application is also related to the following commonly-assigned patent applications, the entire contents of each are hereby incorporated herein this present application by reference: U.S. patent application Ser. No. 10\/681,610, entitled \u201cSYSTEMS AND METHODS FOR TRANSFORMING DATA IN BUFFER MEMORY WITHOUT UNNECESSARILY COPYING DATA TO ADDITIONAL MEMORY LOCATIONS\u201d, filed Oct. 8, 2003; which is a continuation-in-part of U.S. patent application Ser. No. 10\/391,726, entitled \u201cSYSTEMS AND METHODS FOR SCHEDULING DATA FLOW EXECUTION BASED ON AN ARBITRARY GRAPH DESCRIBING THE DESIRED DATA FLOW\u201d, filed Mar. 18, 2003.","The present invention relates generally to database systems and, more particularly, to systems and methods for distributing a workplan for data flow execution based on an arbitrary graph describing the desired flow of data from at least one source to at least one destination.","A relational database is a collection of related data that can be represented by two-dimensional tables of columns and rows wherein information can be derived by performing set operations on the tables, such as join, sort, merge, and so on. The data stored in a relational database is typically accessed by way of a user-defined query that is constructed in a query language such as Structured Query Language (SQL).","Often it is useful to extract data from one or more sources, transform the data into some more useful form, and then load the results to a separate destination. A data warehouse, for example, is a central repository for all or significant parts of the data that an entity's various business systems collect and store (often in separate databases), the purpose of the data warehouse being to support data mining, decision support systems (DSS), and other data actions. Data from various sources is selectively extracted and organized on the data warehouse database for use by analytical applications and user queries. Data warehousing emphasizes the capture of data from diverse sources for useful analysis and access.","In the context of a data warehousing, and more generally for managing databases, extract-transform-load (ETL) refers to three separate functions of obtaining, processing, and storing data. The extract function reads data from a specified source database and extracts a desired subset of data. The transform function works with the acquired data\u2014using rules or lookup tables, or creating combinations with other data\u2014to convert it to the desired state as defined by the specific ETL tool. The load function is used to write the resulting data (either all of the subset or just the changes) to a destination database. Various and diverse ETL tools can be used for many purposes, including populating a data warehouse, converting a database of a specific type into a database of another type, or migrating data from one database to another.","In general, ETL tools operate to perform the aforementioned simple three-step process: (a) the ETL tool extracts the data from the source; (b) the ETL tool transforms the data according to its predefined functionality; and (c) the ETL tool loads the data to the destination. However, while basic transformations can be achieved with simple ETL tools, complex transformations require custom development of new ETL tools with specific and complex functionality\u2014an approach that is resource intensive. While simple ETL tools might have broader usability and thus naturally lend themselves to widespread reuse, complex ETL tools do not lend themselves to reusability due to their high customization and narrow utility (and thus the frequent need to custom develop complex ETL tools when they are needed).","U.S. patent application Ser. No. 10\/391,726, entitled \u201cSYSTEMS AND METHODS FOR SCHEDULING DATA FLOW EXECUTION BASED ON AN ARBITRARY GRAPH DESCRIBING THE DESIRED DATA FLOW\u201d, filed Mar. 18, 2003 is directed toward database technology that provides users with a means for developing complex transformation functionality that is more efficient than custom development of complex ETL tools. That application discloses a system and method for scheduling data flow execution based on an arbitrary graph describing the desired flow of data from at least one source to at least one destination. The data transformation system (DTS) in one embodiment of the that application comprises a capability to receive data from a data source, a data destination and a capability to store transformed data therein, and a data transformation pipeline (DTP) that constructs complex end-to-end data transformation functionality (data flow executions or DFEs) by pipelining data flowing from one or more sources to one or more destinations through various interconnected nodes (that, when instantiated, become components in the pipeline) for transforming the data as it flows by (where the term transforming is used herein to broadly describe the universe of interactions that can be conducted to, with, by, or on data). Each component in the pipeline possesses specific predefined data transformation functionality, and the logical connections between components define the data flow pathway in an operational sense.","The data transformation pipeline (DTP) enables a user to develop complex end-to-end data transformation functionality (the DFEs) by graphically describing and representing, via a graphical user interface (GUI), a desired data flow from one or more sources to one or more destinations through various interconnected nodes (a graph). Each node in the graph selected by the user and incorporated in the graph represents specific predefined data transformation functionality (each a component), and connections between the nodes (the components) define the data flow pathway.","After the user inputs a graph, the DTP's scheduler traverses the graph and translates the graph into lists of specific work items comprised of a relatively small set of functionality necessary to efficiently obtain data from an external source, route data from transformation process to transformation process (component to component) as reflected in the graph, and then release the resultant data to an external target destination. Despite its name, the scheduler does not schedule work items into time slots, but instead it forms work lists and then manages the operation of the work items in the lists. As such, the scheduler work items comprise the following elements of functionality (each discussed in more detail herein):\n\n","DTS also provides a multitude of components with defined inputs and outputs, whereby the user can graphically construct complex data transformations to combine the functionality of the components to achieve the desire end results. These components, similar to a plurality of ETL tools but lacking the individual functionality of ETL tools to extract and load data (as these tasks are handled by the scheduler in the DTP subsystem), provide black box transformation functionality\u2014that is, components can be developed on a variety of platforms (Java, ActiveX, etc.), but the development platform is irrelevant to the DTP as it (and the user) are only concerned about the inputs, outputs, and transformation functionality.","Adding to the efficiency of the system, the DTP also utilizes a unique memory management scheme whereby data extracted from an external source is placed in a memory buffer where it is then manipulated by the components without the need for copying. This technology is discussed in U.S. patent application Ser. No. 10\/681,610, entitled \u201cSYSTEMS AND METHODS FOR TRANSFORMING DATA IN BUFFER MEMORY WITHOUT UNNECESSARILY COPYING DATA TO ADDITIONAL MEMORY LOCATIONS\u201d, filed Oct. 8, 2003.","Several embodiments of the present invention are directed to systems and methods for distributing work of a data flow engine across multiple processors to improve performance in connection with data flow handling systems. Given a data flow, various embodiments provide for the addition of a \u201cdistributor\u201d and a \u201ccollector\u201d to a planned workflow to make a pipeline more scaleable by enabling implicit partitioning whereby buffers are distributed to multiple threads for at least a part of their execution. Distributors act on complete sets of buffered data (\u201cbuffers\u201d) in each operation\u2014that is, they take a single buffer as input and direct that buffer to one of several threads to actually process the buffer. By using multiple threads with redundant strings of transforms (\u201cchains\u201d) downstream from a distributor, the same work can be done on several buffers concurrently and, thus, the resources of a machine running the pipeline are more effectively and aggressively utilized. Downstream from the redundant chains, in turn, is a collector that is responsible for collecting and possibly ordering the buffers which were processed by the previous redundant chains. In this way, a substantial scalability increase can be found by increasing the number of processors\u2014that is, the computer system nets a runtime performance increase in proportion to the number of processors available to the system and utilized for parallel processing of the buffers in the redundant chains. In addition, several embodiments of the present invention are directed to the utilization of a unique memory management scheme for distributing work of a data flow engine across multiple processors to improve performance in connection with data flow handling systems.","Overview","The following discussion is directed to systems and methods for distributing work of a data flow engine across multiple processors to improve performance in connection with data flow handling systems. The subject matter is described with specificity to meet statutory requirements. However, the description itself is not intended to limit the scope of this patent. Rather, the inventors have contemplated that the claimed subject matter might also be embodied in other ways, to include different elements or combinations of elements similar to the ones described in this document, in conjunction with other present or future technologies. Moreover, where the embodiments described herein describe the invention in connection with row-level access and processing, it should be noted that the invention is by no means limited to row-level access and processing and could be applied on a column basis or a table basis as well.","Computer Environment",{"@attributes":{"id":"p-0034","num":"0039"},"figref":"FIG. 1"},"With reference to , an exemplary system for implementing the invention includes a general purpose computing device in the form of a conventional personal computer  or the like, including a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. The system memory includes read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within the personal computer , such as during start up, is stored in ROM . The personal computer  may further include a hard disk drive  for reading from and writing to a hard disk, not shown, a magnetic disk drive  for reading from or writing to a removable magnetic disk , and an optical disk drive  for reading from or writing to a removable optical disk  such as a CD ROM or other optical media. The hard disk drive , magnetic disk drive , and optical disk drive  are connected to the system bus  by a hard disk drive interface , a magnetic disk drive interface , and an optical drive interface , respectively. The drives and their associated computer readable media provide non-volatile storage of computer readable instructions, data structures, program modules and other data for the personal computer . Although the exemplary environment described herein employs a hard disk, a removable magnetic disk  and a removable optical disk , it should be appreciated by those skilled in the art that other types of computer readable media which can store data that is accessible by a computer\u2014such as magnetic cassettes, flash memory cards, digital video disks, Bernoulli cartridges, random access memories (RAMs), read only memories (ROMs) and the like\u2014may also be used in the exemplary operating environment. Further, as used herein, the term computer readable medium includes one or more instances of a media type (e.g., one or more floppy disks, one or more CD-ROMs, etc.).","A number of program modules may be stored on the hard disk, magnetic disk , optical disk , ROM  or RAM , including an operating system , one or more application programs , other program modules  and program data . A user may enter commands and information into the personal computer  through input devices such as a keyboard  and pointing device . Other input devices (not shown) may include a microphone, joystick, game pad, satellite disk, scanner or the like. These and other input devices are often connected to the processing unit  through a serial port interface  that is coupled to the system bus, but may be connected by other interfaces, such as a parallel port, game port or universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video adapter . In addition to the monitor , personal computers typically include other peripheral output devices (not shown), such as speakers and printers.","The personal computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be another personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the personal computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) . Such networking environments are commonplace in offices, enterprise wide computer networks, Intranets and the Internet.","When used in a LAN networking environment, the personal computer  is connected to the local network  through a network interface or adapter . When used in a WAN networking environment, the personal computer  typically includes a modem  or other means for establishing communications over the wide area network , such as the Internet. The modem , which may be internal or external, is connected to the system bus  via the serial port interface . In a networked environment, program modules depicted relative to the personal computer , or portions thereof, may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Network Environment",{"@attributes":{"id":"p-0039","num":"0044"},"figref":"FIG. 2A"},"The network may include client computers , a server computer , data source computers , and databases , , and . The client computers and the data source computers are in electronic communication with the server computer via communications network , e.g., an Intranet. Client computers and data source computers are connected to the communications network by way of communications interfaces . Communications interfaces  can be any one of the well-known communications interfaces such as Ethernet connections, modem connections, and so on.","Server computer provides management of database  by way of database server system software, described more fully below. As such, server acts as a storehouse of data from a variety of data sources and provides that data to a variety of data consumers.","In the example of , data sources are provided by data source computers . Data source computers communicate data to server computer via communications network , which may be a LAN, WAN, Intranet, Internet, or the like. Data source computers store data locally in databases , , which may be relational database servers, excel spreadsheets, files, or the like. For example, database shows data stored in tables , , and . The data provided by data sources is combined and stored in a large database such as a data warehouse maintained by server ","Client computers that desire to use the data stored by server computer can access the database  via communications network . Client computers request the data by way of SQL queries (e.g., update, insert, and delete) on the data stored in database .","Database Architecture","A database is a collection of related data. In one type of database, a relational database, data is organized in a two-dimensional column and row form called a table.  illustrates tables such as tables , , and  that are stored in database . A relational database typically includes multiple tables. A table may contain zero or more records and at least one field within each record. A record is a row in the table that is identified by a unique numeric called a record identifier. A field is a subdivision of a record to the extent that a column of data in the table represents the same field for each record in the table.","A database typically will also include associative structures. An example of an associative structure is an index, typically, but not necessarily, in a form of B-tree or hash index. An index provides for seeking to a specific row in a table with a near constant access time regardless of the size of the table. Associative structures are transparent to users of a database but are important to efficient operation and control of the database management system. A database management system (DBMS), and in particular a relational database management system (RDBMS) is a control system that supports database features including, but not limited to, storing data on a memory medium, retrieving data from the memory medium and updating data on the memory medium.","As shown in , the exemplary database comprises employee table , department table , and sysindexes table . Each table comprises columns  and rows  with fields  formed at the intersections. Exemplary employee table  comprises multiple columns  including empl_id, empl_name, empl_salary, and dept_id. Columns  in department table  include dept_id, dept_name, and dept_location. Sysindexes table  contains information regarding each table in the database.","Generally, data stored in a relational database is accessed by way of a user-defined query that is constructed in a query language such as SQL. Typically, for any given SQL query there are numerous procedural operations that need be performed on the data in order to carry out the objectives of the SQL query. For example, there may be numerous joins and table scans that need to be performed so as to accomplish the desired objective.","As noted, control and management of the tables is maintained by a DBMS, e.g., a RDBMS. An exemplary SQL Server RDBMS architecture  is graphically depicted in . The architecture comprises essentially three layers. Layer one provides for three classes of integration with the SQL Server, comprising: (1) a SQL Server Enterprise Manager  that provides a common environment for managing several types of server software in a network and provides a primary interface for users who are administering copies of SQL Server on the network; (2) an Applications Interface  that allows integration of a server interface into user applications such as Distributed Component Object Modules (DCOM); and (3) a Tools Interface  that provides an interface for integration of administration and configuration tools developed by Independent Software Vendors (ISV).","Layer two opens the functionality of the SQL server to other applications by providing three application programming interfaces (API): SQL Namespace , SQL Distributed Management Objects , and Data Transformation Services . A user interface  is provided by Wizards, HTML, and so on. SQL Namespace API  exposes the user interface (UI) elements of SQL Server Enterprise Manager . This allows applications to include SQL Server Enterprise Manager UI elements such as dialog boxes and wizards.","SQL Distributed Management Objects API  abstracts the use of DDL, system stored procedures, registry information, and operating system resources, providing an API to all administration and configuration tasks for the SQL Server.","Distributed Transformation Services API  exposes the services provided by SQL Server to aid in building data warehouses and data marts. As described more fully below, these services provide the ability to transfer and transform data between heterogeneous OLE DB and ODBC data sources. Data from objects or the result sets of queries can be transferred at regularly scheduled times or intervals, or on an ad hoc basis.","Layer three provides the heart of the SQL server. This layer comprises an SQL Server Engine  and a SQL Server Agent  that monitors and controls SQL Server Engine  based on Events  that inform SQL Server Agent of the status of the SQL Server Engine .","The Server Engine processes SQL statements, forms and optimizes query execution plans, and so on.","Logical Database Application","The above description focused on physical attributes of an exemplary database environment in which the present invention operates.  logically illustrates the manner in which data moves among a number of database servers, which may simultaneously be data sources for other database servers, to the destination database. Here, database server provides management of database . Data for database  is provided by data sources and , which are managed by database servers \u2032 and , respectively. Significantly, database \u2032 gathers data from databases and , which are managed by servers . Thus, database  is fed directly with data from databases and and indirectly with data from databases and ","In the exemplary system of this figure, data from database moves through database and then on to database . Along the way, the data may also undergo transformation. This example illustrates the general concept how data movement may comprise several hops in order for such data to actually reach the database server of interest. Those skilled in the art will recognize that many other combinations of movement and transformation of data is possible.",{"@attributes":{"id":"p-0056","num":"0061"},"figref":"FIG. 5","b":["150","72","149","72","151","70"],"i":["a ","b"]},"Although both tables ,  contain similar information, it is not in an identical format. As a result, the data must be transformed by separate ETL tools into the format of table . For example, table  maintains a column empl_name that contains employee names as first name followed by last name; whereas, table  maintains a column name that contains employee names as last name followed by first name. Table  contains employee names in the form of table . In order for the name columns of table  to be inserted into the empl_name column of table , the name must be converted to the proper form. Similarly, table  does not contain dept_id information.","The above example illustrates that data moving between databases may need to be transformed in some manner before insertion into the target database. However, using separate ETL tools to achieve each transformation is inefficient. In , for example, transformation application  (one ETL tool) transforms the data of table  into proper form for table  and transformation application  (a separate ETL tool) transforms the data of table  into proper form for table .","Data Transfer Service and Data Transfer Pipeline","The data transformation system (DTS) in one embodiment of the present invention comprises a capability to receive data from a data source (such as a data retrieval system that receives data from a source), a data destination and a capability to store transformed and or non-transformed data therein (a destination data storage system to store data), and a data transformation pipeline (DTP) that constructs complex end-to-end data transformation functionality (data flow executions or DFEs) by pipelining data flowing from one or more sources to one or more destinations through various interconnected nodes (that, when instantiated, become components in the pipeline) for transforming the data as it flows by (where the term transforming is used herein to broadly describe the universe of interactions that can be conducted to, with, by, or on data). Each component in the pipeline possesses specific predefined data transformation functionality, and the logical connections between components define the data flow pathway in an operational sense.","The solution to the efficiency problem of traditional ETL-based transformations is the use of the data transformation pipeline of the present invention, the functional structure of one embodiment of which is illustrated in . In this particular embodiment, the DTP  comprises a graphical user interface (GUI)  that enables a user  (represented here as a PC client computer) to develop a complex end-to-end data transformation function (a data flow execution or DFE) by graphically describing and representing a desired data flow from one or more sources to one or more destinations through various interconnected nodes (a graph). Each node in the graph represents specific predefined data transformation functionality that is offered by uninstantiated component objects  residing in a component library , and connections between the nodes as drawn by the user  represent the data flow pathway between the components for the graph.","After the user  inputs graph data  via the GUI , the DTP  utilizes a translator  to traverse the graph data  and to translate the graph into a DFE plan (not shown). Moreover, in the present embodiment, the translator  works in conjunction with an optimizer subsystem  to optimize the simple graph developed by the user  into a maximally efficient execution structure by eliminating redundancies, simplifying and enhancing the DFE plan and possibly performing a plethora of other optimizations that are known and appreciated by those of skill in the art. Based on the DFE plan, the scheduler  uses its pipeline engine  to build the actual DFE  by instantiating appropriate components objects  from the component library  (as detailed in ). The translator  also produces work lists  for the scheduler  where each work list  contains specific work items for the scheduler  to control the operation of the DFE ; moreover, it is important to note that the actual interconnectivity between the various component objects is in effect reflect in the work lists as parameters associated with each work item in each work list. The DTP  also comprises a buffer  which is utilized by the DFE  (the role of which is described more fully later herein).","Notwithstanding the name, the scheduler  does not schedule work items according to time, but instead the scheduler  manages the work lists  and the execution of the work items in the lists by the DFE . Each work item in a work list is one of five operations that the scheduler  uses to control the operation of the DFE , the five operations comprising:\n\n","Referring to both , the latter of which is a detailed view of the DFE , the first operation, extracting data from a data source, is a work item that causes the scheduler  to thread\/task\/program\/schedule\/etc. (hereinafter, simply to thread) a specific extraction component\u2014for example, extraction component \u2014to extract certain data from a certain data source\u2014for example, data source \u2014and for the extraction component  to logically hold that data to be passed to another component although, in reality, the data is actually stored in a buffer . The second operation, providing data to a component, causes the scheduler  to thread a specific component\u2014for example, transformation component \u2014to transform the data according to the input\/output functionality of the component . (As described more fully below, in operation the scheduler  actually passes primary pointers for the buffer data to the component so that the component can directly access the data in the buffer  and transform it without having to copy it.) The third operation, enabling the split of data along two or more paths, is a work item that causes the scheduler  to thread a specialized component\u2014for example, split component \u2014to analyze each row of data and, based on a specified criteria, group the data into one of two groups, alpha or omega, each of which will thereafter logically travel along separate paths of the pipeline during continuing execution of the DFE . Moreover, from this point forward, the scheduler  treats alpha and omega as distinct and separate data groups. The fourth operation, enabling the merger of data from two or more paths into a single path, is the logical converse of a split that causes the scheduler  to thread another specialized component\u2014for example, merge component \u2014to merge two distinct and separate data groups into a single data group that travels along a common path in the pipeline during continuing execution of the DFE , and from this point forward the scheduler  treats the merged data as a single group. The fifth operation, loading data to a data destination, is a work item that causes the scheduler  to thread a specific loading component\u2014for example, loading component \u2014to load certain data onto a certain data destination\u2014for example, data destination . These five operations comprise the general functionality of the scheduler , although it is the specific input\/output functionality of the uninstantiated component objects  that are available to the DTP  (and which are threaded to by the five operational elements) that enable the development of complex data transforms.","As previously alluded to herein above, the DTP  has a multitude of uninstantiated component objects categorized in a component library , each of which has defined inputs and outputs from which the user can graphically construct complex data transformations (via the pipeline engine ) by combining the functionality of the components into a DFE  in order to achieve a desired end results. The transformation components are similar to a plurality of ETL tools but individually lack the individual functionality of ETL tools to extract and load data (as these tasks are handled by the scheduler in the DTP system through special, non-transformation components such as the extract components  and the load components ). Moreover, all of the components provide black box transformation functionality\u2014that is, components can be developed on a variety of platforms (Java, ActiveX, etc.) because the development platform is irrelevant to the DTP  as it (and the user ) are only concerned about the inputs and outputs for the component\u2014that is, the functional information necessary to use the component as a black box object.","Referring again to , after the DFE  is formed by the pipeline engine  as described earlier herein, the scheduler begins executing the individual work items in one of the work lists , the individual work items of which are textually depicted . For example, in executing a work list , the scheduler might individually thread the extraction components  and  to extract data from three data sources , , and  to create two data groups (which are stored as two distinct data groups, A and B respectively, in the buffer ). Upon each completed extraction, the scheduler then threads the appropriate transformation component  or  to begin transforming the data corresponding to each path (A and B respectively). When component  is complete, and presuming that component  is complete before component , the scheduler recognizes that the next step for data group A (hereinafter A) is to merge with data from a split process  and, since that data is not yet available, the scheduler may not yet initiate the thread for the merger component . Meanwhile, component  completes its transformation of data group B (hereinafter B) and the scheduler  then threads the split component  to split B according to input parameters specified by the work item. Consequently, B is logically split into B and B, each data group being the output of component  along separate paths in the DFE . Once the split is complete the scheduler  then threads the merger component  to merge A and B. Also, recognizing that the remaining execution of B is independent from the continuing execution of A and B, the scheduler  also threads component  to transform B.","Without further regard to each remaining pathway, and to summarize the rest of the dataflow in the DFE  (without explicitly referring to the scheduler , the operation of which can be easily implied), A and B are merged by component  to form AB, which is then transformed by component  and thereafter loaded to an external data destination  by loading component . Meanwhile, B, having been transformed by component , is then transformed by components  and  in order, and thereafter B is loaded to two external data destinations  and  by loading component .","The scheduler of the present invention, including the important translator\/optimizer functionality that has been separate in the figures for clarity but which may in fact be scheduler subsystems, performs a critically important role in the DTP. Not only does the scheduler enable a user to describe complex data transformations in a simple graph easily drawn via the GUI interface, and not only does the scheduler (via the translator) map the graph to a DFE plan and task lists, but it also controls the actual execution of the data flows throughout the actual DFE to ensure consistent functionality for situations such as: pipelining data through a DFE comprising both synchronous and asynchronous components (where the latter requires all data to be inputted before any data can be outputted); keeping data in sequence when necessary while employing parallel processing techniques; load balancing; enabling parallel processing despite the data residing in a single location in memory (as discussed below); and so forth. Consequently, an important consideration for the present invention is the care given to ensuring that the relationship between elements in a graph and the DTPs capabilities are clearly defined and entirely consistent.","Memory Management","An important element for certain embodiments of the invention is unique memory management scheme utilized by the DTP whereby data extracted from an external source is placed in a memory buffer and is then manipulated by the components without the need for copying the data to any other location in memory. While logically we view the data to be moving from component to component in the DFE, the data does not in fact change locations but, instead, the data resides in the buffer and is operated upon by a series of components that, in turn, access the data in the buffer via pointers and manipulate same.","Consider , B, C, D, and E which collectively illustrates how data is (a) extracted by an extraction component and stored in buffer memory, (b) transformed by a component, and then (c) loaded to a destination from the buffer memory by a loading component.  (with references to other prior figures) illustrates a sample graph  for a data transformation specified by a user  via the GUI . The user  for this example has described that data regarding his subordinates employees should be extracted from the corporate database , divided into two groups based on sex (male or female) , each group then sorted by name  and  and, finally, each group loaded to the two separate databases  and .",{"@attributes":{"id":"p-0070","num":"0080"},"figref":"FIG. 7B","b":["308","310","314","318","314","312","420","424","422","426","428","434","436","430","432","308","310"]},{"@attributes":{"id":"p-0071","num":"0081"},"figref":"FIGS. 7C and 7D","b":["380","320","440","442","444","380","446","400","448","450","426","446","426","446","426"]},{"@attributes":{"id":"p-0072","num":"0082"},"figref":"FIG. 7E","b":["380","320","426","428","446","428","448","450","308","448","450","446","314","446","430","432","434","436","320"]},"Workplan Distribution","Given a data flow, various embodiments of the present invention are directed to the incorporation of a \u201ccollector\u201d and a \u201cdistributor\u201d to the planned workflow where the distributor acts on a complete buffer (an autonomous block of data suitable for processing in the pipeline) in each operation, for example, receiving a single buffer as input and directing that single buffer to one of several parallel identical threads to process that buffer. For various embodiments, the scheduler would create each of these multiple threads, each thread having an identical (redundant) strings of transforms (chains) downstream from the distributor, and all of which would lead even further downstream to a collector that is responsible for collecting and, if necessary, ordering the buffers processed by the previous redundant chains. In this way, the distributors and collectors provide increased scalability for the pipeline by implicitly partitioning (distributing) individual buffers to one of many threads for at least a part of their execution\/processing.","For example, consider the hypothetical pipeline of  which comprises a source S, an extract component E, a serial plurality of transforms T, T, T, and T, a load component L, and a destination D. The extract component E will produce buffers based on data received from the source S, the load component will produce resultant data based on the processed buffers from the serial set of transforms, and both the extract E and the load L will operate with their own threads. Transforms T, T, T, and T will all run on a third thread, and the processing of each buffer will be serialized through the four transforms\u2014that is, T will not process a new buffer until T has handed the buffer off to the thread running the load component L for writing to the destination D. For various embodiments of the present invention, the scheduler will assure that all processors are fully utilized by managing the number of redundant chains and will also preserve ordering if necessary. For example, on machines with multiple processor resources available, the pipeline designer may employ collectors and distributors to allow the pipeline to create more threads for handling identical sets of parallel transformations as illustrated in .","Interestingly enough, the parallelism achieved in  is only possible where each transform is \u201casynchronous.\u201d An asynchronous transform is one that can complete its processing and produces output on a single buffer without requiring any knowledge of data from other buffers\u2014that is, the transformation that occurs only pertains to each buffer without regard for any other buffer on a buffer-by-buffer basis. In contrast, a \u201csynchronous\u201d transform is one that requires knowledge or awareness of buffers other than the current buffer being transformed. More simply, an asynchronous transform is one that does not need to see all of the data being transformed (and thus can be distributed), while a synchronous transform is one that does (and thus cannot be distributed).","For example, consider the hypothetical pipeline of  which comprises a source S, an extract component E, a serial plurality of transforms T, T, T, and T, a load component L, and a destination D. In this figure, transform T is synchronous (as indicated by the bracketed S \u201c[S]\u201d) and, since transform T is synchronous, it cannot be distributed. Thus, the parallelism achievable for this pipeline, illustrated in , accounts for synchronous transform T by creating redundancy chains for the other transforms while preserving transform T.","For certain embodiments of the present invention, a buffer may comprise special properties to facilitate the creation and operation of redundant chains. For example, certain embodiments may comprise the utilization of a property (stored in a buffer and understandable by the scheduler) that limits the maximum number of concurrent chains that may be employed (a \u201cmax-chain property\u201d), while certain other embodiments may comprise the utilization of a property that informs the scheduler whether or not the order of the buffers upon entering a distributor must be preserved upon exiting the corresponding collector (that is, where ordering among the buffers must be preserved).","For several embodiments of the present invention, the addition of collectors and distributors is done automatically and is not intended to be part of the layout an end-user would define. Thus a layout would continue to represent simply the logical design of the pipeline that the user produced, while the scheduler would be responsible for integrating distributor and collector parallelism when possible and\/or when beneficial. Thus, for these embodiments, it is the scheduler that will automatically create the redundant chains (including distributors and collectors) In addition, for ease of use, an end-user designing data flows would not need to consider the efficiencies to be gained by multiple processors as several embodiments of the present invention are intended to transform a pipeline designed for a single processor to be optimized for multiple processors through the use of distributors, collectors, and parallel chains of transforms. However, it is important for transform developers to kind in mind that a transform may be used in a distributed system as described herein and, as such, transform developers may designate whether their transform is in fact capable of being used in a parallel pipeline system as described herein. For certain embodiments, this is accomplished by the developer setting a value in a predesignated field of the transform that, as a default (or in the absence thereof) is set to not distributable.","The various techniques described herein may be implemented with hardware or software or, where appropriate, with a combination of both. Thus, the methods and apparatus of the present invention, or certain aspects or portions thereof, may take the form of program code (i.e., instructions) embodied in tangible media, such as floppy diskettes, CD-ROMs, hard drives, or any other machine-readable storage medium, wherein, when the program code is loaded into and executed by a machine, such as a computer, the machine becomes an apparatus for practicing the invention. In the case of program code execution on programmable computers, the computer will generally include a processor, a storage medium readable by the processor (including volatile and non-volatile memory and\/or storage elements), at least one input device, and at least one output device. One or more programs are preferably implemented in a high level procedural or object oriented programming language to communicate with a computer system. However, the program(s) can be implemented in assembly or machine language, if desired. In any case, the language may be a compiled or interpreted language, and combined with hardware implementations.","The methods and apparatus of the present invention may also be embodied in the form of program code that is transmitted over some transmission medium, such as over electrical wiring or cabling, through fiber optics, or via any other form of transmission, wherein, when the program code is received and loaded into and executed by a machine, such as an EPROM, a gate array, a programmable logic device (PLD), a client computer, a video recorder or the like, the machine becomes an apparatus for practicing the invention. When implemented on a general-purpose processor, the program code combines with the processor to provide a unique apparatus that operates to perform the indexing functionality of the present invention.","While the present invention has been described in connection with the preferred embodiments of the various figures, it is to be understood that other similar embodiments may be used or modifications and additions may be made to the described embodiment for performing the same function of the present invention without deviating there from. For example, while exemplary embodiments of the invention are described in the context of digital devices emulating the functionality of personal computers and PDAs, one skilled in the art will recognize that the present invention is not limited to such digital devices, as described in the present application may apply to any number of existing or emerging computing devices or environments, such as a gaming console, handheld computer, portable computer, etc. whether wired or wireless, and may be applied to any number of such computing devices connected via a communications network, and interacting across the network. Furthermore, it should be emphasized that a variety of computer platforms, including handheld device operating systems and other application specific operating systems, are herein contemplated, especially as the number of wireless networked devices continues to proliferate. Therefore, the present invention should not be limited to any single embodiment, but rather construed in breadth and scope in accordance with the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing summary, as well as the following detailed description of preferred embodiments, is better understood when read in conjunction with the appended drawings. For the purpose of illustrating the invention, there is shown in the drawings exemplary constructions of the invention; however, the invention is not limited to the specific methods and instrumentalities disclosed. In the drawings:",{"@attributes":{"id":"p-0016","num":"0021"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0022"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0018","num":"0023"},"figref":"FIG. 2B"},{"@attributes":{"id":"p-0019","num":"0024"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0020","num":"0025"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0021","num":"0026"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0022","num":"0027"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0023","num":"0028"},"figref":["FIG. 6B","FIG. 6A"]},{"@attributes":{"id":"p-0024","num":"0029"},"figref":"FIG. 7A"},{"@attributes":{"id":"p-0025","num":"0030"},"figref":["FIG. 7B","FIG. 7A"]},{"@attributes":{"id":"p-0026","num":"0031"},"figref":"FIG. 7C"},{"@attributes":{"id":"p-0027","num":"0032"},"figref":"FIG. 7D"},{"@attributes":{"id":"p-0028","num":"0033"},"figref":"FIG. 7E"},{"@attributes":{"id":"p-0029","num":"0034"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0030","num":"0035"},"figref":["FIG. 8B","FIG. 8A"]},{"@attributes":{"id":"p-0031","num":"0036"},"figref":"FIG. 9A"},{"@attributes":{"id":"p-0032","num":"0037"},"figref":["FIG. 9B","FIG. 9A"]}]},"DETDESC":[{},{}]}
