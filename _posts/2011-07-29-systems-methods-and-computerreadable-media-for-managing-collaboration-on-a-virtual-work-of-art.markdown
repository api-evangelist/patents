---
title: Systems, methods, and computer-readable media for managing collaboration on a virtual work of art
abstract: Systems, methods, and computer-readable media for managing collaboration on a virtual work of art between multiple electronic devices are provided. A first graphical display system of a first device may generate an input command in response to receiving user information through a user interface of the first device, and may then share this input command with a second graphical display system of a second device. The first graphical display system may process the shared input command to generate pixel array data in a canvas of the first device while the second graphical display system may process the shared input command to generate pixel array data in a canvas of the second device. By sharing input commands rather than pixel array data, system latency may be reduced. Despite operating on the same artwork, the user interfaces and graphical processing capabilities of each device may vary, thereby providing the user greater expressiveness.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09075561&OS=09075561&RS=09075561
owner: APPLE INC.
number: 09075561
owner_city: Cupertino
owner_country: US
publication_date: 20110729
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE DISCLOSURE","SUMMARY OF THE DISCLOSURE","DETAILED DESCRIPTION OF THE DISCLOSURE"],"p":["This can relate to systems, methods, and computer-readable media for sharing graphical object data and, more particularly, to systems, methods, and computer-readable media for managing collaboration on a virtual work of art between multiple electronic devices.","Some electronic devices include a graphical display system for generating and presenting graphical objects, such as free-form drawing strokes, images, strings of text, and drawing shapes, on a display to create a virtual work of art. The processing capabilities and interfaces provided to a user for creating such works of art often vary between different types of electronic devices. However, the ways in which two or more electronic devices may allow one or more users to collaborate on a single virtual work of art may be confusing or inefficient.","Systems, methods, and computer-readable media for managing collaboration on a virtual work of art are provided.","In some embodiments, there is provided a method for sharing graphical data. The method may include receiving first user instructions with a first user interface of a first electronic device, generating a first input command based on the received first user instructions with a first graphics application on the first electronic device, and transmitting the first input command from the first electronic device to a second electronic device. The method may also include processing the first input command with the first graphics application on the first electronic device to generate first pixel array data in a first canvas of the first electronic device. Moreover, in some embodiments, the method may also include processing the first input command with a second graphics application on the second electronic device to generate second pixel array data in a second canvas of the second electronic device.","In other embodiments, there is provided a method for sharing graphical data that includes loading a first graphics application on a first electronic device, loading an artwork into the first graphics application on the first electronic device, and sending first information from the first electronic device to a second electronic device. The first information may be configured to instruct the second electronic device to load at least a first portion of the artwork into a second graphics application on the second electronic device.","In yet other embodiments, there is provided an electronic device that includes a display, a user input component, communications circuitry, and a processor. The processor may be configured to receive a first user instruction from the user input component, generate a first input command based on the received first user instruction, provide the first input command to the communications circuitry for transmission of the first input command to an other electronic device, process first pixel array data from the first input command, and present at least a portion of the first pixel array data on the display.","In still yet other embodiments, there is provided computer-readable media for controlling an electronic device. The media includes computer-readable code recorded thereon for receiving first user instructions with a first user interface of the electronic device, generating a first input command based on the received first user instructions, transmitting the first input command from the electronic device to an other electronic device, and processing the first input command on the electronic device to generate first pixel array data.","In still yet other embodiments, there is provided a data processing system that includes a processor to execute instructions and a memory coupled with the processor to store instructions. When executed by the processor, the instructions may cause the processor to perform operations to generate an application programming interface (\u201cAPI\u201d) that may allow an API-calling component to perform the following operations: receive first user instructions with a first user interface of a first electronic device, generate a first input command based on the received first user instructions, transmit the first input command from the first electronic device to an other electronic device, and process the first input command on the first electronic device to generate first pixel array data.","Systems, methods, and computer-readable media for managing collaboration on a virtual work of art are provided and described with reference to .","A virtual work of art may be simultaneously loaded by and presented on two or more electronic devices in a communications network, such that any change made to the artwork by a user interaction with any one of the devices may be reflected in the artwork on all of the devices. Each device may have different user interfaces and processing capabilities, such that the strengths of each device may be leveraged by one or more users to collaborate on the artwork in an efficient and intuitive manner.","A user's interaction with a virtual drawing application running on each device may be utilized to generate one or more input commands for editing the artwork. Each input command may be processed to generate pixel array data that can present the graphical object content of the artwork. Each device may receive each input command generated by each of the other devices in the communications network, and each device may be similarly configured to process each received input command in a consistent manner, such that the artwork may be updated with the same pixel array data on each of the devices.","For example, a first graphical display system of a first electronic device may be able to generate a first input command in response to receiving first user information through a user interface of the first device. The first graphical display system may then share this first input command with a second graphical display system of a second electronic device in a communications network. The first graphical display system may be configured to process the shared input command to generate pixel array data in a first canvas of the first device, while the second graphical display system may be configured to process the shared input command to generate the same pixel array data in a second canvas of the second device. By sharing input commands rather than pixel array data, the two devices may reduce latency in the communications network. The first canvas and the second canvas may each include the same pixel array data such that the same artwork may be available on each device. However, different portions of the artwork may be presented on different devices. For example, at least a first portion of the first canvas may be presented on a display of the first device, and at least a second portion of the second canvas may be presented on a display of the second device. In other embodiments, the entirety of the first canvas may be presented on the display of the first device, and the entirety of the second canvas may be presented on the display of the second device, such that the entirety of the shared artwork is presented on each device.",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1","b":["1","1","100","200","1","50","100","200","100","200","51"]},"Either one or both of first electronic device  and second electronic device  may be any portable, mobile, or hand-held electronic device configured to create a virtual work of art wherever the user travels. Alternatively, either one or both of first electronic device  and second electronic device  may not be portable at all, but may instead be generally stationary. Either one or both of first electronic device  and second electronic device  can include, but is not limited to, a music player (e.g., an iPod\u2122 available by Apple Inc. of Cupertino, Calif.), video player, still image player, game player, other media player, music recorder, movie or video camera or recorder, still camera, other media recorder, radio, medical equipment, domestic appliance, transportation vehicle instrument, musical instrument, calculator, cellular telephone (e.g., an iPhone\u2122 available by Apple Inc.), other wireless communication device, personal digital assistant, remote control, pager, computer (e.g., a desktop, laptop, tablet, server, etc.), monitor, television, stereo equipment, set up box, set-top box, boom box, modem, router, printer, and combinations thereof. In some embodiments, either one or both of first electronic device  and second electronic device  may perform a single function (e.g., a device dedicated to creating a virtual work of art) and, in other embodiments, either one or both of first electronic device  and second electronic device  may perform multiple functions (e.g., a device that creates virtual artwork, plays music, and receives and transmits telephone calls).","First electronic device  of system  may include a processor or control circuitry , memory , communications circuitry , power supply , input component , display , and sensor . First electronic device  may also include a bus  that may provide one or more wired or wireless communications links or paths for transferring data and\/or power to, from, or between various other components of first electronic device . In some embodiments, one or more components of first electronic device  may be combined or omitted. Moreover, first electronic device  may include other components not combined or included in  and\/or several instances of the components shown in . For the sake of simplicity, only one of each of the components of first electronic device  is shown in .","Memory  of first electronic device  may include one or more storage mediums, including for example, a hard-drive, flash memory, permanent memory such as read-only memory (\u201cROM\u201d), semi-permanent memory such as random access memory (\u201cRAM\u201d), any other suitable type of storage component, or any combination thereof. Memory  may include cache memory, which may be one or more different types of memory used for temporarily storing data for electronic device applications. Memory  may store media data (e.g., music and image files), software (e.g., for implementing functions on first electronic device ), firmware, preference information (e.g., media playback preferences), lifestyle information (e.g., food preferences), exercise information (e.g., information obtained by exercise monitoring equipment), transaction information (e.g., information such as credit card information), wireless connection information (e.g., information that may enable first electronic device  to establish a wireless connection), subscription information (e.g., information that keeps track of podcasts or television shows or other media a user subscribes to), contact information (e.g., telephone numbers and e-mail addresses), calendar information, any other suitable data, or any combination thereof.","Communications circuitry  of first electronic device  may be provided to allow first electronic device  to communicate with one or more other electronic devices or servers (e.g., second electronic device  and\/or a server  of communications network ) using any suitable communications protocol. For example, communications circuitry  may support Wi-Fi (e.g., an 802.11 protocol), Ethernet, Bluetooth\u2122, Bluetooth\u2122 Low Energy (\u201cBLE\u201d), high frequency systems (e.g., 900 MHz, 2.4 GHz, and 5.6 GHz communication systems), infrared, transmission control protocol\/internet protocol (\u201cTCP\/IP\u201d) (e.g., any of the protocols used in each of the TCP\/IP layers), hypertext transfer protocol (\u201cHTTP\u201d), BitTorrent\u2122, file transfer protocol (\u201cFTP\u201d), real-time transport protocol (\u201cRTP\u201d), real-time streaming protocol (\u201cRTSP\u201d), secure shell protocol (\u201cSSH\u201d), any communications protocol that may be used by wireless and cellular telephones and personal e-mail devices (e.g., Global System for Mobile Communications (\u201cGSM\u201d), GSM plus Enhanced Data rates for GSM Evolution (\u201cEDGE\u201d), Code Division Multiple Access (\u201cCDMA\u201d), Orthogonal Frequency-Division Multiple Access (\u201cOFDMA\u201d), high speed packet access (\u201cHSPA\u201d), multi-band, etc.), any other communications protocol, or any combination thereof. Communications circuitry  may also include circuitry that can enable first electronic device  to be electrically coupled to another device (e.g., a host computer or an accessory device) and communicate with that other device, either wirelessly or via a wired connection.","Power supply  of first electronic device  may provide power to one or more of the components of first electronic device . In some embodiments, power supply  can be coupled to a power grid (e.g., when device  is not a portable device, such as a desktop computer). In some embodiments, power supply  can include one or more batteries for providing power (e.g., when device  is a portable device, such as a cellular telephone). As another example, power supply  can be configured to generate power from a natural source (e.g., solar power using solar cells).","One or more input components  of first electronic device  may be provided to permit a user to interact or interface with first electronic device . For example, input component  can take a variety of forms, including, but not limited to, a touch pad, dial, click wheel, scroll wheel, touch screen, one or more buttons (e.g., a keyboard), mouse, joy stick, track ball, microphone, camera, proximity sensor, light detector, and combinations thereof. Each input component  can be configured to provide one or more dedicated control functions for making selections or issuing commands associated with operating first electronic device .","First electronic device  may also include one or more output components that may present information (e.g., graphical, audible, and\/or tactile information) to a user of first electronic device . An output component of first electronic device  may take various forms, including, but not limited to, audio speakers, headphones, audio line-outs, visual displays, antennas, infrared ports, rumblers, vibrators, or combinations thereof.","For example, as shown in , first electronic device  may include display  as an output component. Display  may include any suitable type of display or interface for presenting visual data to a user. In some embodiments, display  may include a display embedded in first electronic device  or coupled to first electronic device  (e.g., a removable display). Display  may include, for example, a liquid crystal display (\u201cLCD\u201d), a light emitting diode (\u201cLED\u201d) display, an organic light-emitting diode (\u201cOLED\u201d) display, a surface-conduction electron-emitter display (\u201cSED\u201d), a carbon nanotube display, a nanocrystal display, any other suitable type of display, or combination thereof. Alternatively, display  can include a movable display or a projecting system for providing a display of content on a surface remote from first electronic device , such as, for example, a video projector, a head-up display, or a three-dimensional (e.g., holographic) display. As another example, display  may include a digital or mechanical viewfinder, such as a viewfinder of the type found in compact digital cameras, reflex cameras, or any other suitable still or video camera.","In some embodiments, display  may include display driver circuitry, circuitry for driving display drivers, or both. Display  can be operative to display content (e.g., media playback information, application screens for applications implemented on first electronic device , information regarding ongoing communications operations, information regarding incoming communications requests, device operation screens, etc.) that may be under the direction of processor . Display  can be associated with any suitable characteristic dimensions defining the size and shape of the display. For example, the display can be rectangular or have any other polygonal shape, or alternatively can be defined by a curved or other non-polygonal shape (e.g., a circular display). Display  can have one or more primary orientations for which an interface can be displayed, or can instead or in addition be operative to display an interface along any orientation selected by a user.","It should be noted that one or more input components and one or more output components may sometimes be referred to collectively herein as an input\/output (\u201cI\/O\u201d) component or I\/O interface (e.g., input component  and display  as I\/O component or I\/O interface ). For example, input component  and display  may sometimes be a single I\/O component , such as a touch screen, that may receive input information through a user's touch of a display screen and that may also provide visual information to a user via that same display screen.","Sensor  of first electronic device  may include any suitable motion sensor operative to detect movements of first electronic device . For example, sensor  may be a motion-sensing component operative to detect movement of first electronic device . In some embodiments, sensor  may include one or more three-axis acceleration motion sensors (e.g., an accelerometer) operative to detect linear acceleration in three directions (i.e., the x- or left\/right direction, the y- or up\/down direction, and the z- or forward\/backward direction). As another example, sensor  may include one or more single-axis or two-axis acceleration motion sensors which may be operative to detect linear acceleration only along each of the x- or left\/right direction and the y- or up\/down direction, or along any other pair of directions. In some embodiments, sensor  may include an electrostatic capacitance (e.g., capacitance-coupling) accelerometer that is based on silicon micro-machined micro electro-mechanical systems (\u201cMEMS\u201d) technology, including a heat-based MEMS type accelerometer, a piezoelectric type accelerometer, a piezo-resistance type accelerometer, or any other suitable accelerometer.","In some embodiments, sensor  may be operative to directly or indirectly detect rotation, rotational movement, angular displacement, tilt, position, orientation, motion along a non-linear (e.g., arcuate) path, or any other non-linear motions. In some embodiments, sensor  may alternatively or additionally include one or more gyro-motion sensors or gyroscopes for detecting rotational movement. For example, sensor  may include a rotating or vibrating element. Using sensor , first electronic device  can determine an orientation of display , for example.","Processor  of first electronic device  may include any processing circuitry operative to control the operations and performance of one or more components of first electronic device . For example, processor  may receive input signals from input component  and\/or drive output signals through display . In some embodiments, as shown in , processor  may be used to run an application . Application  may include, but is not limited to, one or more operating system applications, firmware applications, media playback applications, media editing applications, or any other suitable applications. For example, processor  may load application  as a user interface program to determine how instructions or data received via an input component  or other component of device  may manipulate the way in which information is stored and\/or provided to the user via an output component (e.g., display ). Application  may be accessed by processor  from any suitable source, such as from memory  (e.g., via bus ), from second electronic device  or from server  of communications network  (e.g., via communications circuitry ), or from any other suitable source. First electronic device  (e.g., processor , memory , or any other components available to device ) may be configured to process graphical data at various resolutions, frequencies, intensities, and various other characteristics as may be appropriate for the capabilities and resources of first electronic device .","First electronic device  may also be provided with a housing  that may at least partially enclose one or more of the components of first electronic device  for protection from debris and other degrading forces external to device . In some embodiments, one or more of the components of first electronic device  may be provided within its own housing (e.g., input component  may be an independent keyboard or mouse within its own housing that may wirelessly or through a wire communicate with processor , which may be provided within its own housing).","Second electronic device  of system  may include a processor or control circuitry , memory , communications circuitry , power supply , input component , display , and sensor . In some embodiments, input component  and display  of second electronic device  may sometimes be a single I\/O interface or I\/O component . Second electronic device  may also include a housing  as well as a bus  that may provide one or more wired or wireless communications links or paths for transferring data and\/or power to, from, or between various other components of second electronic device . As also shown in , processor  may be used to run an application  that may include, but is not limited to, one or more operating system applications, firmware applications, media playback applications, media editing applications, or any other suitable applications. Application  may be accessed by processor  from any suitable source, such as from memory  (e.g., via bus ), from first electronic device  or from server  of communications network  (e.g., via communications circuitry ), or from any other suitable source. In some embodiments, one or more components of second electronic device  may be combined or omitted. Moreover, second electronic device  may include other components not combined or included in  and\/or several instances of the components shown in . For the sake of simplicity, only one of each of the components of second electronic device  is shown in .","Each one of housing , processor , application , memory , communications circuitry , power supply , input component , I\/O component , display , sensor , and bus  of second electronic device  may be the same as or substantially similar to a respective one of housing , processor , application , memory , communications circuitry , power supply , input component , I\/O component , display , sensor , and bus  of first electronic device  and, therefore, may not be independently described in greater detail. While, in some embodiments, first electronic device  and second electronic device  may be the same or substantially similar devices, in other embodiments, first electronic device  may have one or more different and\/or additional components that second electronic device  does not have, and vice versa.","In some embodiments, communications circuitry  of first electronic device  and communications circuitry  of second electronic device  may communicate with one another directly, such as, for example, via shared communications link  of system . Shared communications link  may include one or more wired and\/or wireless communications links or paths for transferring any suitable data and\/or power between first electronic device  and second electronic device . Alternatively or additionally, in some embodiments, system  may include communications network , with which one or both of first electronic device  and second electronic device  may communicate. For example, a first electronic device communications link  of system  may include one or more wired and\/or wireless communications links or paths for transferring any suitable data and\/or power between communications circuitry  of first electronic device  and communications network . Similarly, a second electronic device communications link  of system  may include one or more wired and\/or wireless communications links or paths for transferring any suitable data and\/or power between communications circuitry  of second electronic device  and communications network . In some embodiments, as an alternative or in addition to communicating with one another via shared communications link , first electronic device  and second electronic device  may communicate with one another via communications network  and communications links  and .","Any suitable circuitry, device, system or combination of these (e.g., a wireless communications infrastructure including one or more communications towers, telecommunications servers, or the like) operative to create a communications network may be used to provide communications network . Communications network  may be capable of providing communications using any suitable communications protocol. For example, communications network  may support Wi-Fi, Ethernet, Bluetooth\u2122, BLE, high frequency systems (e.g., 900 MHz, 2.4 GHz, and 5.6 GHz communication systems), infrared, TCP\/IP, HTTP, BitTorrent\u2122, FTP, RTP, RTSP, SSH, any communications protocol that may be used by wireless and cellular telephones and personal e-mail devices (e.g., GSM, GSM plus EDGE, CDMA, OFDMA, HSPA, multi-band, etc.), any other communications protocol, or any combination thereof.","Moreover, in some embodiments, communications network  may include one or more servers  or any other suitable components (e.g., any suitable cloud computing components) that may communicate with first electronic device  and\/or second electronic device  via communications network . In some embodiments, server  may be a source of one or more files, applications, or any other suitable resource that may be provided to and utilized by first electronic device  and\/or second electronic device  (e.g., application  and\/or application ). For example, server  may be configured as a media store that may provide first electronic device  and\/or second electronic device  with various resources or media items including, but not limited to, audio files, video files, text files, graphical object files, various other multimedia files, various applications (e.g., a virtual drawing space application), and the like. An example of such a media store that may be provided by server  may be the iTunes\u2122 Store and\/or the App Store\u2122, each of which is made available by Apple Inc. of Cupertino, Calif.","It should be noted that any mechanism or combination of mechanisms for enabling communication between communications circuitry  of first electronic device  and communications circuitry  of second electronic device  may sometimes be referred to collectively herein as communications media. For example, as shown in , shared communications link , first electronic device communications link , second electronic device communications link , communications network , and\/or server  may be referred to individually and\/or collectively as communications media .",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 2","b":["301","100","1","100","301","112","100","301"]},"As shown in , for example, graphical display system  of first electronic device  may include a graphical command generating module  that may define and generate one or more generated input commands  that may be processed to create at least a portion of the graphical contents of each of the screens to be rendered for display by first electronic device . Such commands and graphical screen contents may be based on the one or more applications being run by first electronic device  (e.g., application ) as well as any input instructions being received by first electronic device  (e.g., via input component ). The graphical screen contents can include free-form drawing strokes, image content (e.g., photographic images), textual information (e.g., one or more alphanumeric characters in a text string), drawing shape objects, video data based on images of a video program, and combinations thereof. For example, an application run by first electronic device  (e.g., application  of ) may be any suitable application that may provide a virtual canvas or workspace on which a user may create and manipulate graphical objects, such as free-form drawing strokes, images, drawing shapes, and text strings (e.g., Photoshop\u2122 or Illustrator\u2122 by Adobe Systems Incorporated or Microsoft Paint\u2122 by Microsoft Corporation). Graphical command generating module  may define and generate input commands  that may be processed to create at least a portion of these types of graphical objects on display . For example, graphical command generating module  may define and generate input commands  that may be processed to create drawing stroke graphical objects, image graphical objects, drawing shape graphical objects, and\/or text string graphical objects on a virtual canvas for display by graphical display system  on display  of first electronic device .","Graphical object data may generally be represented or described in two ways or as two types of data (i.e., pixel data and analytical graphic objects or \u201cvector objects\u201d). Graphical object data of the pixel data type may be collections or arrays of one or more pixels (e.g., samples of color and\/or other information including transparency and the like) that may be provided in various raster or bitmap or pixmap layers on a canvas or workspace. On the other hand, graphical object data of the vector object type may be an abstract graphic entity (e.g., such that its appearance, position, and orientation in a canvas or workspace may be defined analytically through geometrical formulas, coordinates, and the like). Some pixel data may be provided with additional position and orientation information that can specify the spatial relationship of its pixels relative to a canvas or workspace containing the pixel data, which may be considered a bitmap vector graphic object when placed in a vector graphics document. Before the application of any additional transformation or deformation, such a bitmap vector object may be equivalent to a rectangular vector object texture-mapped to the pixel data.","Graphical command generating module  may receive input information  from various input sources for defining one or more graphical object properties of a graphical object that may be generated and presented on display . For example, such input sources may be the one or more applications being run by first electronic device  (e.g., application  of ) and\/or any user input instructions being received by device  (e.g., via input component  of first electronic device , as shown in ). In some embodiments, based on at least a portion of the received input information , graphical command generating module  may define and generate one or more generated input commands  that may be processed to create at least a portion of any suitable type of graphical content, such as a drawing stroke, an image, a string of text, a drawing shape, and the like. In some embodiments, the graphical object content may be at least partially based on one or more graphical object properties defined by received input information .","For example, when graphical command generating module  generates an input command  that may be processed to create at least a portion of a drawing stroke graphical object, input information  may be received by module  to define at least a portion of that input command  and, thus, one or more drawing stroke properties of that drawing stroke graphical object. Such input information  may be referred to herein as drawing stroke graphical object input information .","A drawing stroke graphical object may be considered a path along which a drawing stroke input tool (e.g., a stamp) may be applied. Such a drawing stroke input tool may define a particular set of pixel data to be applied on a virtual canvas when the stamp is used for creating a drawing stroke graphical object along a defined trail. For example, such a trail may define a path on the canvas along which an associated drawing stroke input tool may repeatedly apply its pixel data for generating a drawing stroke graphical object on the canvas to be displayed. A drawing stroke input tool may be defined by any suitable drawing stroke input tool property or set of drawing stroke input tool properties including, but not limited to, shape, size, pattern, orientation, hardness, color, transparency, spacing, and the like. A drawing stroke trail may be defined by any suitable drawing stroke trail property or set of drawing stroke trail properties including, but not limited to, starting point, end point, length, path, and the like.","Therefore, drawing stroke graphical object input information  may define one or more drawing stroke input tool properties and\/or one or more drawing stroke trail properties for a particular drawing stroke graphical object that may be at least partially created by processing a command  generated by graphical command generating module  using that drawing stroke graphical object input information . Once drawing stroke graphical object input information  has been received by graphical command generating module , graphical command generating module  may define and generate at least one appropriate drawing stroke graphical object input command  that may be processed for creating at least a portion of an appropriate drawing stroke graphical object.","As another example, when graphical command generating module  generates an input command  that may be processed to create at least a portion of an image graphical object, input information  may be received by module  to define at least a portion of that input command  and, thus, one or more properties of that image graphical object. Such input information  may be referred to herein as image graphical object input information . An image graphical object may be any suitable image file that can be imported into a graphical object document or canvas. For example, a property of an image graphical object may be an address at which image data of the image is stored as an image file (e.g., in memory  of first electronic device ). An image file may be in any suitable format for providing image content to graphical display system  of first electronic device  including, but not limited to, a JPEG file, a TIFF file, a PNG file, a GIF file, and the like. As another example, a property of an image graphical object may be the size or position of the image in the graphical object canvas. Once image graphical object input information  has been received by graphical command generating module , graphical command generating module  may define and generate at least one appropriate image graphical object input command  that may be processed for creating at least a portion of an appropriate image graphical object.","As another example, when graphical command generating module  generates an input command  that may be processed to create at least a portion of a text string graphical object, input information  may be received by module  to define at least a portion of that input command  and, thus, one or more properties of that text string graphical object. Such input information  may be referred to herein as text string graphical object input information . For example, a text string graphical object may include one or more characters, such as a letter, number, punctuation, or other symbol that may be used in the written form of one or more languages. Symbol characters may include, but are not limited to, representations from a variety of categories, such as mathematics, astrology, astronomy, chess, dice, ideology, musicology, economics, politics, religion, warning signs, meteorology, and the like. A property of a text string graphical object may be the selection of one or more particular characters and\/or a characteristic of a particular character. Such a characteristic may include, but is not limited to, a font type (e.g., Arial or Courier), a style type (e.g., bold or italic), a color, a character size, a position of the character on the graphical object canvas, and the like. Once text string graphical object input information  has been received by graphical command generating module , graphical command generating module  may define and generate at least one appropriate text string graphical object input command  that may be processed for creating at least a portion of an appropriate text string graphical object.","As yet another example, when graphical command generating module  generates an input command  that may be processed to create at least a portion of a drawing shape graphical object, input information  may be received by module  to define at least a portion of that input command  and, thus, one or more properties of that drawing shape graphical object. Such input information  may be referred to herein as drawing shape graphical object input information . For example, a property of a drawing shape graphical object may be a pre-defined shape (e.g., a box, a star, a heart, etc.), a free-form drawing input indicative of a user-defined shape, or a characteristic of such a shape (e.g., color, size, position on the canvas, etc.). Once drawing shape graphical object input information  has been received by graphical command generating module , graphical command generating module  may define and generate at least one appropriate drawing shape graphical object input command  that may be processed for creating at least a portion of an appropriate drawing shape graphical object.","Regardless of the type of graphical object to be created, a user may interact with one or more drawing applications running on first electronic device  (e.g., application  of ) via input component  to generate suitable input information  for defining one or more of the graphical object properties of a graphical object. Alternatively or additionally, in other embodiments, an application running on first electronic device  may be configured to automatically generate at least a portion of input information  for defining one or more of the graphical object properties.","As shown in , for example, graphical display system  of first electronic device  may also include a graphical command processing module  that may process graphical object input commands  generated by graphical command generating module  such that graphical objects may be created and presented to a user on display  of first electronic device . In some embodiments, as shown in , for example, graphical command processing module  may be configured to process received input commands  for providing pixel array data  for presentation on display . For example, graphical command processing module  may be configured to interpret each input command  and generate appropriate pixel array data  for representing the graphical object described by each input command  on a virtual canvas of display .","Graphical command processing module  may utilize application  to interpret commands  for generating graphical object content as pixel array data  on a virtual canvas. For example, graphical command processing module  may be configured to perform various types of graphics computations or processing techniques and\/or implement various rendering algorithms on graphical object content that module  may generate based on commands , such that module  may provide the graphical data necessary to define at least a portion of the canvas to be displayed on display . Such processing may include, but is not limited to, matrix transformations, scan-conversions, various rasterization techniques, various techniques for three-dimensional vertices and\/or three-dimensional primitives, texture blending, and the like. For example, in some embodiments, graphical command processing module  may encompass at least a portion of the graphics library of the operating system of first device , which may be a code module that may handle function calls like \u201cdraw circle in bitmap\u201d or \u201cfill bitmap with color\u201d or \u201cdraw this set of triangles in 3-dimensional space\u201d, and that may appropriately modify the bitmap with commands performed by processor  (e.g., for software rendering), and\/or which may be dedicated graphics processing hardware (e.g., for hardware accelerated rendering). The bitmap may be either a frame buffer in video memory (e.g., a region of bytes that may directly represent the colors of pixels on the display) or an off-screen buffer in main memory.","Pixel array data  generated by graphical command processing module  may include one or more sets of pixel data, each of which may be associated with a respective pixel of canvas  to be displayed by display . For example, each of the sets of pixel data included in pixel array data  may be correlated with coordinate values that identify a particular one of the pixels of canvas  to be displayed by display , and each pixel data set may include a color value for its particular pixel as well as any additional information that may be used to appropriately shade and\/or provide other cosmetic features for its particular pixel.","Graphical display system  of first electronic device  may also be configured to share one or more input commands  generated by graphical command generating module  with one or more other electronic devices or servers. For example, as shown in , graphical command generating module  and\/or graphical command processing module  may be configured to provide one or more input commands  as one or more shared input commands to communications circuitry  of first electronic device . Shared input commands may then be transmitted by communications circuitry  from first electronic device  to any other device (e.g., second electronic device  and\/or server , via communications media ).","Similarly, graphical display system  of first electronic device  may also be configured to share at least a portion of pixel array data  generated by graphical command processing module  with one or more other electronic devices or servers. For example, as shown in , graphical command processing module  may be configured to provide at least a portion of generated pixel array data  as shared pixel array data to communications circuitry  of first electronic device . Shared pixel array data may then be transmitted by communications circuitry  from first electronic device  to any other device (e.g., second electronic device  and\/or server , via communications media ).","Graphical display system  of first electronic device  may also be configured to receive one or more input commands from one or more other electronic devices or servers. For example, as shown in , graphical command processing module  may be configured to receive one or more received input commands from communications circuitry  of first electronic device . Received input commands may be received by communications circuitry  of first electronic device  from any other device (e.g., second electronic device  and\/or server , via communications media ). Graphical command processing module  may utilize application  to interpret both generated input commands  provided by graphical command generating module  as well as received input commands provided by communications circuitry  for generating pixel array data  on a virtual canvas.","Similarly, graphical display system  of first electronic device  may also be configured to receive pixel array data from one or more other electronic devices or servers. For example, as shown in , graphical command processing module  may be configured to receive received pixel array data from communications circuitry  of first electronic device . Received pixel array data may be received by communications circuitry  of first electronic device  from any other device (e.g., second electronic device  and\/or server , via communications media ). Graphical command processing module  may utilize application  to generate pixel array data  by combining any received pixel array data with any pixel array data generated by graphical command processing module  in response to input commands  and received input commands ",{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 2","b":["401","200","1","200","401","200","404","403","210","203","200","405","401","200","408","405","409","212","200"]},"Graphical command generating module  and\/or graphical command processing module  may be configured to provide one or more input commands  as one or more shared input commands to communications circuitry  of second electronic device , which may then transmit shared input commands from second electronic device  to any other device (e.g., first electronic device  and\/or server , via communications media ). For example, a particular shared input command provided by graphical command generating module  and\/or graphical command processing module  of graphical display system  of second electronic device  may be transmitted by communications circuitry  of second electronic device , via communications media , and received by communications circuitry  of first electronic device  as a particular received input command , which may then be provided to graphical command processing module  of graphical display system  of first electronic device .","Similarly, graphical command processing module  may be configured to provide at least a portion of generated pixel array data  as shared pixel array data to communications circuitry , which may then transmit shared pixel array data from second electronic device  to any other device (e.g., first electronic device  and\/or server , via communications media ). For example, particular shared pixel array data provided by graphical command processing module  of graphical display system  of second electronic device  may be transmitted by communications circuitry  of second electronic device , via communications media , and received by communications circuitry  of first electronic device  as particular received pixel array data , which may then be provided to graphical command processing module  of graphical display system  of first electronic device .","Moreover, graphical command processing module  may be configured to receive one or more received input commands from communications circuitry  of second electronic device , which may receive received input commands from any other device (e.g., first electronic device  and\/or server , via communications media ). For example, a particular shared input command provided by graphical display system  to communications circuitry  of first electronic device , may be transmitted by communications circuitry , via communications media , and received by communications circuitry  of second electronic device  as a particular received input command , which may then be provided to graphical command processing module  of graphical display system  of second electronic device .","Similarly, graphical command processing module  may be configured to receive received pixel array data from communications circuitry  of second electronic device , which may receive received pixel array data from any other device (e.g., first electronic device  and\/or server , via communications media ). For example, particular shared pixel array data provided by graphical command processing module  to communications circuitry  of first electronic device , may be transmitted by communications circuitry , via communications media , and received by communications circuitry  of second electronic device  as particular received pixel array data , which may then be provided to graphical command processing module  of graphical display system  of second electronic device .","The type of data that may be exchanged or otherwise shared between devices may be either bitmap or vector data. The format of the data exchanged between devices does not have to be identical to the format used by the operating system and\/or underlying hardware (e.g., the graphics processing unit) of the devices. For example, graphical data might be converted to and\/or from a hardware-independent format before being sent and\/or after being received, which may to allow for differences in hardware platforms between devices (e.g., whether integers may be stored big-endian or little-endian, whether or not both devices conform to the IEEE 754-2008 floating point arithmetic specification, etc.).","Each one of graphical display system , input information , graphical command generating module , generated input command , shared input command , received input command , graphical command processing module , generated pixel array data , shared pixel array data , and received pixel array data of second electronic device  may be the same as or substantially similar to a respective one of graphical display system , input information , graphical command generating module , generated input command , shared input command , received input command , graphical command processing module , generated pixel array data , shared pixel array data , and received pixel array data of first electronic device  and, therefore, may not be independently described in greater detail. While, in some embodiments, graphical display system  of first electronic device  and graphical display system  of second electronic device  may be the same or substantially similar graphical display systems, in other embodiments, graphical display system  of first electronic device  may have one or more different and\/or additional modules that graphical display system  of second electronic device  does not have, and vice versa. While, in some embodiments, graphical display system  of first electronic device  and graphical display system  of second electronic device  may be the same or substantially similar graphical display systems, in other embodiments, graphical display system  of first electronic device  may be configured to process or otherwise handle one or more different and\/or additional types of input commands and\/or types of pixel array data that graphical display system  of second electronic device  may not be configured to process or otherwise handle, and vice versa.","An illustrative example of how system  may manage collaboration on a virtual work of art may be described with reference to .",{"@attributes":{"id":"p-0069","num":"0068"},"figref":["FIGS. 4A-4K","FIGS. 4A-4K"],"b":["100","101","112","500","500","200","201","212","600","600","100","200","100","112","110","112","116","110","112","116","200","212","210","211","210","201"],"i":["a","k ","a","k ","a ","a","a "]},"At least a portion of the visual information of each one of screens -may be defined by graphical command generating module  and\/or processed by graphical command processing module  of graphical display system , while at least a portion of the visual information of each one of screens -may be defined by graphical command generating module  and\/or processed by graphical command processing module  of graphical display system . As shown, screens -may present a user interface for a virtual drawing space application of first electronic device , with which a user may create and manipulate graphical objects for making original works of art (e.g., a virtual drawing space application, such as application , that may be similar to that of Photoshop\u2122 by Adobe Systems Incorporated or Microsoft Paint\u2122 by Microsoft Corporation). It is to be understood, however, that screens -are merely exemplary, and display  may present any content representing any type of graphical objects and\/or graphical object animations that may be at least partially generated and\/or processed by graphical display system  of first electronic device .","Similarly, as shown, screens -may present a user interface for a virtual drawing space application of device  (e.g., application ), with which a user may create and manipulate graphical objects for making original works of art. It is to be understood, however, that screens -are merely exemplary, and display  may present any content representing any type of graphical objects and\/or graphical object animations that may be at least partially generated and\/or processed by graphical display system  of second electronic device .","For example, as shown in , a virtual drawing space application of first electronic device  (e.g., application ) may provide at least a portion of a canvas  on a portion of each one of screens -in which various graphical objects may be presented on display . At least a portion of canvas  may be provided in a virtual drawing workspace portion of each screen in which pixel data may be created and\/or manipulated for generating a virtual work of art . In some embodiments, the size of canvas  may dynamically change in response to various graphical objects that may be positioned on canvas , such that canvas  may always be large enough to contain whatever objects are generated for artwork . However, the amount of canvas  that may actually be displayed on any of screens -of display  may vary from screen to screen as application  is utilized. For example, a user may zoom-in on a specific portion of canvas  such that only a portion of artwork  may be presented across the entire virtual drawing workspace portion on display .","In some embodiments, a virtual drawing space application of first device  (e.g., application ) may also provide at least one artist menu  on a portion of each one of screens -of first device . Menu  may include one or more graphical input options that a user may choose from to access various tools and functionalities of the application that may then be utilized by the user to create various types of graphical objects in canvas area . Menu  may provide one or more toolbars, toolboxes, palettes, buttons, or any other suitable user interface submenus that may be one or more layers or windows distinct from canvas . For example, artist menu  may include one or more suitable submenus, such as a graphical object type selection submenu , a graphical object property selection submenu , and an inter-device submenu . It is to be understood, however, that submenus , , and  of artist menu  are merely exemplary, and a virtual drawing space application of first electronic device  (e.g., application ) may provide various other types of submenus that a user may interact with for creating and\/or manipulating content in artwork  on canvas area .","As shown in , for example, graphical object type selection submenu  of artist menu  of first electronic device  may include various graphical object type input options for selecting a particular type of graphical object to be created on canvas  for artwork . For example, graphical object type selection submenu  may include a free-form drawing stroke input option , which a user may select for creating one or more free-form drawing strokes on canvas  (e.g., by repeatedly applying a stamp of a user-controlled virtual input drawing tool along a stroke trail on canvas ). Graphical object type selection submenu  may alternatively or additionally include a text string input option , which a user may select for creating one or more strings of characters on canvas . Graphical object type selection submenu  may alternatively or additionally include a drawing shape input option , which a user may select for creating one or more various drawing shapes on canvas . Moreover, graphical object type selection submenu  may alternatively or additionally include an image input option , which a user may select for importing one or more video-based and\/or photographic images into canvas . It is to be understood, however, that options , , , and  of graphical object type selection submenu  of artist menu  are merely exemplary, and a virtual drawing space application of first electronic device  (e.g., application ) may provide various other types of graphical object type input options that a user may interact with for creating and manipulating content in artwork  on canvas .","In some embodiments, as also shown in , for example, artist menu  may include graphical object property selection submenu , which may provide various graphical object property input options for selecting particular properties of a graphical object to be created on canvas . For example, graphical object property selection submenu  may include a graphical object style input option , which a user may interact with to alter one or more various style properties of a graphical object to be created on canvas . Graphical object property selection submenu  may alternatively or additionally include a graphical object color input option , which a user may interact with to alter one or more various color properties of a graphical object to be created on canvas . Moreover, graphical object property selection submenu  may alternatively or additionally include a graphical object effect input option , which a user may interact with to alter one or more various effect properties of a graphical object to be created on canvas . It is to be understood, however, that options , , and  of graphical object property selection submenu  of artist menu  are merely exemplary, and a virtual drawing space application of first electronic device  (e.g., application ) may provide various other types of graphical object property input options that a user may interact with for creating and manipulating content in artwork  on canvas .","In some embodiments, as also shown in , for example, artist menu  may include inter-device submenu , which may provide various options for regulating how a user of first electronic device  may interact with another device (e.g., second electronic device ) for collaborating on a shared work of art (e.g., artwork ). For example, inter-device submenu  may include an input synch option , which a user of first device  may interact with to synchronize the current active user interface selections of first electronic device  (e.g., the current active graphical object type selection(s) of submenu  and\/or the current active graphical object property selection(s) of submenu ) with the current active user interface selections of another device (e.g., the current active user interface selections of second electronic device ). Inter-device submenu  may alternatively or additionally include an outline lock option , which a user of first device  may interact with to fix an outline of another device's actively displayed canvas portion (e.g., an outline of the actively displayed canvas portion of a canvas of second electronic device ) on canvas  of first electronic device . It is to be understood, however, that options  and  of inter-device submenu  of artist menu  are merely exemplary, and a virtual drawing space application of first electronic device  (e.g., application ) may provide various other types of inter-device input options that a user may interact with for regulating how a user of first electronic device  may interact with another device (e.g., second electronic device ) for collaborating on a shared work of art (e.g., artwork ).","Similarly, as also shown in , a virtual drawing space application  of second electronic device  may provide at least a portion of a canvas  on a portion of each one of screens -in which various graphical objects may be presented on display . At least a portion of canvas  may be provided in a virtual drawing workspace portion of each screen in which pixel data may be created and manipulated for creating a user work of art (e.g., artwork ). In some embodiments, the size of canvas  may dynamically change in response to various graphical objects that may be positioned on canvas , such that canvas  may always be large enough to contain whatever objects are generated for the artwork shown by device . However, the amount of canvas  that may actually be displayed on any of screens -of display  may vary from screen to screen as application  is utilized.","Virtual drawing space application  may also provide at least one artist menu  on a portion of each one of screens -of second device . Like menu  of first device , menu  may also include one or more graphical input options that a user may choose from to access various tools and functionalities of the application that may then be utilized by the user to create various types of graphical objects in the work of art on canvas . For example, artist menu  may include one or more suitable submenus, such as a graphical object type selection submenu , a graphical object property selection submenu , and an inter-device submenu . It is to be understood, however, that submenus , , and  of artist menu  are merely exemplary, and a virtual drawing space application of second electronic device  (e.g., application ) may provide various other types of submenus that a user may interact with for creating and manipulating content in a work of art on canvas .","For example, as shown in , artist menu  of second device  may include some or all of the same options as menu  of first device . In some embodiments, graphical object type selection submenu  of menu  may include a free-form drawing stroke input option , a text string input option , a drawing shape input option , and\/or an image input option . Alternatively or additionally, graphical object property selection submenu  of menu  may include a graphical object style input option , a graphical object color input option , and\/or a graphical object effect input option . Moreover, alternatively or additionally, inter-device submenu  of menu  may include an input synch option  and\/or an outline lock option . It is to be understood, however, that options , , , , , , , , and  of submenus , , and  of artist menu  are merely exemplary, and a virtual drawing space application of second electronic device  (e.g., application ) may provide various other types of input options that a user may interact with for creating and\/or editing an original work of art on canvas .","Each one of canvas , artist menu , graphical object type selection submenu , free-form drawing stroke input option , text string input option , drawing shape input option , image input option , graphical object property selection submenu , graphical object style input option , graphical object color input option , graphical object effect input option , inter-device submenu , input synch option , and outline lock option  of second electronic device  may be the same as or substantially similar to a respective one of canvas , artist menu , graphical object type selection submenu , free-form drawing stroke input option , text string input option , drawing shape input option , image input option , graphical object property selection submenu , graphical object style input option , graphical object color input option , graphical object effect input option , inter-device submenu , input synch option , and outline lock option  of first electronic device  and, therefore, may not be independently described in greater detail. While, in some embodiments, artist menu  of first electronic device  and artist menu  of second electronic device  may be presented as the same or substantially similar artist menus, in other embodiments, menu  of first electronic device  may present one or more different and\/or additional submenus or options that menu  of second electronic device  may not present, and vice versa. For example, in some embodiments, menu  may not present a text string input option  (e.g., if second electronic device  is not provided with a keyboard for a user of second electronic device  to interact with for entering strings of text).","Virtual drawing space application  of first electronic device  may be synched with virtual drawing space application  of second electronic device  such that a single work of art (e.g. artwork ) may be presented on both first device  and second device , and such that the single work of art may be collaboratively created and\/or edited through both user interactions with first device  and user interactions with second device . First device  and second device  may connect with one another in any suitable way such that application  may be synched with application . For example, each device may be configured to utilize any suitable service discovery protocol for communicating with one another via communications media , such as a zero configuration networking protocol (e.g., Bonjour\u2122 available by Apple Inc.).","Before or after devices  and  have established communication between each another, at least one device may load a virtual drawing application. For example, first device  may initially load application  into processor  (e.g., from memory  or from server ). Then, once communication has been established between first device  and second device  via communications media , first device  may instruct second device  to load a virtual drawing application (e.g., application ) into processor . In some embodiments, first device  may transmit a copy of application  to second device , which device  may load into processor  as application . Alternatively, first device  may instruct second device  to access a suitable virtual drawing application  from server . In other embodiments, second device  may already have application  available in memory  and may receive an instruction from first device  to load application  into processor . In yet other embodiments, each device may already have an appropriate drawing application loaded, and the devices may communicate this fact to one another.","Once first device  and second device  have established communication between each other, and once an appropriate virtual drawing application has been loaded by at least one of the devices, a single virtual work of art may be shared between the two applications. A virtual work of art may be any suitable document or file that may be accessed by a virtual drawing application from any suitable source (e.g., a local device memory \/ or from a remote server ). For example, application  of first device  may initially load artwork  from memory  or server  and present artwork  on canvas . Artwork  may have been previously created and may be loaded by application  to edit the graphical contents of artwork . Alternatively, artwork  may be initially generated as a new virtual work of art by application .","Once artwork  is loaded by application , and once first device  and second device  have established communication between each other, artwork  may be shared between the two devices. In some embodiments, first device  may transmit to second device  both an instruction to load an appropriate drawing application  and a copy of artwork  to be loaded by that drawing application  on second device . Alternatively, first device  may just send a copy of artwork  to second device , which may have already loaded application . In yet other embodiments, first device  may send an instruction to second device  to load a copy of artwork  from an independent source (e.g., server ). In still yet other embodiments, it may not be necessary for an entire copy of artwork  to be loaded by each device upon initial connection. For example, first device  may transmit only a subregion of the pixel array data of artwork  to second device  (e.g., if first device  detects that second device  has a smaller screen or only wishes to initially display a particular portion of artwork ). In some embodiments, before transmitting any portion of artwork  or instructing second device to load any portion of artwork , first device  may initially ask second device  for the dimensions of its canvas , or screen resolution, or initial portion of its canvas  second device  wishes to initially display, and first device  may then share a portion of artwork  according to the response received from second device . In some embodiments, before transmitting any portion of artwork  or instructing second device to load any portion of artwork , a user may interact with first device  to define an outline of second device  (e.g., an outline  of ) on a portion of canvas , and first device  may then share only the portion of artwork  within that outline with second device . Regardless of the various ways in which first device  and second device  may be configured to not only establish communication with one another, but also to load the same artwork  in their respective virtual drawing applications  and , first device  and second device  may be configured to collaboratively edit artwork  through both user interactions with first device  and user interactions with second device .","Application  of first device  and application  of second device  may be the same application. Alternatively, application  may at least be configured to handle at least some of the same commands as application  (e.g., commands \/). For example, although applications  and  may not be the exact same binary code, certain portions of their source code may be the same and may share a common command vocabulary, while other portions of their source code may be device-specific layers and\/or platform-specific layers. Applications  and  may be referred to as cross-platform applications. In some embodiments, first device  may be a device configured to run on a first platform that may be different than a second platform on which second device  may be configured to run, yet applications  and  may still share a common portion of source code for handling or interpreting a particular set of commands. For example, first device  may be configured to run the Android\u2122 operating system available from Google Inc. of Mountain View, Calif., such that application  may be written in the Java programming language, while second device  may be configured to run the iOS\u2122 operating system available from Apple Inc., such that application  may be written in the Objective-C programming language. However, although applications  and  may be configured to run on different platforms and\/or different devices, applications  and  may share at least a portion of the same source code, and each application may have its own abstraction layer of the common source code that may be configured to call a platform-specific and\/or device-specific portion of the code.","Regardless, application  and  may be configured to share the same semantic application-specific information. Each application may have the same semantics or semantic response when a command of a particular command set is received from another one of the applications. Therefore, all communication between application  of first device  and application  of second device  may be in terms relevant to each application and not to any system-wide, device-specific, or platform-specific events that aren't also application-specific events. For example, any communication between applications  and  that relate to coordinates may be defined in an application-specific coordinate space. Each one of applications  and  may recognize and receive any command in a command set that may be communicated from another one of the applications (e.g., commands \/). Although a device-specific layer and\/or a platform-specific layer of an application of a particular device may determine whether or not the application may act on a particular command in a particular way, each application may still receive and recognize that command.","In some embodiments, the bytes or other data that may be provided as a graphical input command may not necessarily be identical to the bytes or other data that a device's display subsystem may use to represent vector object data or pixel array data. An additional layer of translation may be provided to make the shared commands and pixel data be platform-independent, which may allow compatibility between devices (e.g., between devices with different CPU architectures). Additionally, vector or pixel array data may be compressed before being sent between devices over communications media  and may be decompressed by the receiving device before being drawn to the screen or otherwise interpreted (e.g., to save bandwidth of the system).","There may be various ways in which devices can determine each others' capabilities. For example, as part of an initial synchronization process, each device may send a message over communications media  indicating which operations are supported by that device. Additionally, a first device may be configured to respond with an error code or any other suitable communication type if a second device instructs the first device to perform an operation that the first device does not support or is not currently able to handle. The second device may be configured to process such an error code and fall back to an alternate command (e.g., the second device may send to the first device pixel array data corresponding to the unsupported instruction). The scheme by which pixel array data may be shared may be a part of a common command vocabulary. There can be a common, platform-independent format for pixel data that all devices may be capable of sending and receiving. The specifics of this format (e.g., the order of bytes and color components, whether pixel data is split into chunks for easier transport, whether or not compression is used, etc.) may be defined in various ways by a party responsible for defining the common command set\/network communication protocol for the system.","Once first device  has loaded application  and\/or second device  has loaded application , artwork  may be loaded by at least one of the applications. For example, as shown in , application  may be loaded by first device  and artwork  may be loaded by application . As shown by screen of , artwork  may initially include no graphical content. For example, application  may initially create artwork  as a new artwork . Next, application  may either share artwork  with second device  (e.g., by instructing second device  to load application  and receive artwork  from first device ) before a user interacts with either device for generating new graphical content in artwork , or a user may interact with first device to generate new graphical content in artwork  before sharing artwork  with second device . As shown in , for example, artwork  may be shared with application  of second device  such that artwork  is also displayed on canvas  of second device .","As shown by screen of , for example, once artwork  has been loaded by application , a user of first electronic device  may select drawing stroke input option  of submenu  of artist menu  for creating one or more free-form drawing strokes in artwork  on canvas  (e.g., user selection of option  may be shown by shading indicia within option  on screen of , although selection of any option may be made apparent in any other suitable way, including non-visual ways). When a user selects drawing stroke input option , various additional options (not shown) may be made available to the user with respect to one or more of submenu options , , and  of graphical object property selection submenu , such that a user may select one or more drawing stroke properties that may at least partially define a drawing stroke graphical object to be created in artwork  on canvas . For example, drawing stroke graphical object style input option  of property selection submenu  may allow the user to select a drawing stroke input tool from a group of various pre-defined drawing stroke input tools or stamps (e.g., a \u201ccircular pen\u201d drawing stroke input tool, as shown in ), drawing stroke graphical object color input option  of property selection submenu  may allow the user to select a color from a group of various pre-defined drawing stroke colors (e.g., a color represented by \u201c\/\/\/\u201d markings, as shown in ), and drawing stroke graphical object effect input option  of property selection submenu  may allow the user to select one or more effects to be applied to the drawing stroke from a group of various pre-defined drawing stroke effects (e.g., no effects, as shown in ). It is to be understood that additional or alternative pre-defined drawing stroke input tools of various other pre-defined shapes, colors, effects, and other various pre-defined drawing stroke graphical object properties may also be provided by submenu  of menu  when drawing stroke input option  of submenu  is selected.","Any selections made by the user with respect to the options provided by menu  may be received by graphical display system  of first electronic device  for generating and displaying menu input content on menu . For example, selections made by the user with respect to the options provided by menu  may be received by graphical command generating module  of graphical display system  as menu input information . In some embodiments, a user may interact with menu  to provide selections using any suitable pointing input component of first electronic device  (e.g., mouse input component  of ). For example, a user may interact with mouse input component  to point and click a cursor (not shown) at one or more suitable portions of screen of display  that may be presenting the appropriate selectable options of menu . It is to be understood, however, that any suitable pointing input component may be used by a user to point to or otherwise identify a particular menu option provided by menu  and any suitable input gesture of that pointing input component or another input component may be used to interact with that particular menu option in any particular way.","When a user selectively interacts with options , , , and  of menu  for creating a drawing stroke graphical object with a circular pen drawing stroke input tool of a particular color and no effects, for example, the selections may be received by graphical command generating module  of graphical display system  as menu input information , and graphical command generating module  may generate one or more appropriate menu input commands  that may be representative of these menu selections. These menu input commands  may be processed by graphical command processing module  to generate at least a portion of pixel array data  with pixel data that may represent these menu selections, and that pixel data may be presented on display  in menu  or at any other suitable portion of the displayed interface.","For example, as shown by screen of , in response to a user selecting drawing stroke input option  (e.g., with mouse input component ), graphical command generating module  may receive certain menu input information  and may then generate a particular menu input command  (e.g., a menu input command with the representative syntax \u201cCOMMAND: CLASS=MENU INPUT; SELECT=MENU OPTION \u201d), which may be processed by graphical command processing module  to generate at least a portion of pixel array data  with updated menu pixel data that may present shading indicia at the portion of screen identifying input option  in menu  on display . Similarly, as shown by screen of , in response to a user selecting a circular pen drawing stroke graphical object style input option , graphical display system  may generate and present a rigid circle within the box identifying input option  in menu  on display . Moreover, as shown by screen of , in response to a user selecting a particular color with input option  and no effect with input option , graphical display system  may generate and present a representation of that color (e.g., \u201c\/\/\/\u201d) within the box identifying input option  in menu  on display  and a representation of no effect (e.g., \u201cnone\u201d) within the box identifying input option  in menu  on display .","Once options , , , and  of menu  have been selected for creating a drawing stroke graphical object (e.g., with a circular pen drawing stroke input tool of a particular color and no effects), and once the selections have been received by graphical display system  and represented on display  in menu , the user may then interact with graphical display system  for generating one or more new drawing stroke graphical objects in artwork  on canvas  according to the selected options. Based on any appropriate drawing stroke graphical object input information , which may be generated by a user (e.g., using input component  and\/or ) and\/or by any application running on device  (e.g., application ), graphical command generating module  may be configured to define and generate at least one new drawing stroke graphical object input command . This new drawing stroke graphical object input command  may then be processed by graphical command processing module  as new drawing stroke graphical object pixel array data  and presented on display  in canvas .","For example, as also shown by screen of , a user may interact with graphical display system  to generate a new drawing stroke graphical object  in artwork  on canvas . As shown, drawing stroke graphical object  of artwork  may include a straight diagonal line extending along a trail path from a starting point P on canvas  to an ending point P on canvas  with the selected drawing stroke properties of options , , and . For example, in response to a user defining a trail path for a new drawing stroke graphical object (e.g., by dragging a cursor along canvas  from point P to point P with mouse input component ), graphical command generating module  may receive certain drawing stroke input information  and then generate a particular drawing stroke input command . For example, based on the currently selected properties of options , , and , and the trail path defined by points P and P, graphical command generating module  may generate a new drawing stroke graphical object input command , which may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=CIRCULAR PEN; COLOR=\/\/\/; EFFECT=NONE; START:P; END:P\u201d. The new drawing stroke input command  generated by graphical command generating module  may then be processed by graphical command processing module  to generate at least a portion of new drawing stroke pixel array data  that may present new drawing stroke graphical object  at the appropriate position on canvas  of screen of display .","It is to be understood that the above representative syntax of new drawing stroke input command  for generating new drawing stroke graphical object  is merely representative, and that any suitable syntax may be used by application  of first electronic device  for generating a new drawing stroke input command  in response to received drawing stroke input information . The actual data that may be shared between devices may be binary (e.g., one byte to indicate a command class, two bytes to represent a coordinate value, four bytes to represent a color, etc.). For example, a command to create a new graphical object might include (1) a code indicating this command creates a new object, (2) the length in bytes of the data that follows, and (3) a sequence of attribute\/value pairs. The attributes may be represented as numeric codes. For example, a byte with a value of 1 may represent \u201ccolor\u201d and may indicate that four bytes of color data (e.g., red\/green\/blue\/alpha) follow. As another example, a byte with a value of 2 may represent \u201cstroke width\u201d and may indicate that one byte follows.","As yet another example, a byte with a value of 20 may represent \u201cstart point\u201d and may indicate that four bytes follow (e.g., two for the X coordinate and two for the Y coordinate). The exact sequence of attribute\/value pairs sent may depend on the type of the object being created. The absence of an attribute may indicate that a default value can be used. For example, a \u201cnew circle\u201d command sent without a color attribute may inform the recipient device to simply use the currently selected color.","Common attributes that may be shared among shape and drawing stroke tools may be stroke color, interior color, line width, and initial position. Shape tools may also send height and width values, as well as an identifier indicating the type of the shape (e.g., circle, square, diamond, etc.). A pen stroke may not have a two-dimensional size, but it can treat the initial position as the starting point of the stroke, and send an endpoint attribute. It may also send control points as attributes if the stroke is to be a Bezier curve or other spline. The set of attributes can be orthogonal to the set of actions. For example, an action might be \u201ccreate new object\u201d or \u201cmodify existing object.\u201d Both actions may use the same attribute\/value pairs, where the \u201ccreate new object\u201d action may use the attributes to determine the appearance of the new object, and the \u201cmodify existing object\u201d action may use the attributes to describe which properties of the object should be changed.","Although only starting point P and ending point P of the trail of new drawing stroke graphical object  may be defined by the exemplary representative syntax of new drawing stroke input command , it is to be understood that, in other embodiments, multiple additional points of the trail may be defined by the new drawing stroke input command . For example, if the new drawing stroke is a straight line (e.g., as is shown in  by the straight diagonal line of drawing stroke graphical object  between starting point P and ending point P), graphical command generating module  may only define a new drawing stroke input command  with a starting point and an ending point in order for the new drawing stroke input command  to adequately instruct graphical command processing module  to generate the appropriate path of the new drawing stroke graphical object on canvas . However, if the new drawing stroke is not a straight line (e.g., a drawing stroke that follows a curved or otherwise non-linear path), graphical command generating module  may define a new drawing stroke input command  with multiple additional points along the path between the starting point and the ending point in order for the new drawing stroke input command  to adequately instruct graphical command processing module  to generate the appropriate path of the new drawing stroke graphical object on canvas .","In some embodiments, rather than generating a single new drawing stroke input command  for a new drawing stroke graphical object to be generated on canvas , graphical command generating module  may generate multiple new drawing stroke input commands , each of which may adequately instruct graphical command processing module  to generate a particular portion of the new drawing stroke graphical object on canvas . For example, as shown in , the trail path of drawing stroke graphical object  may be defined by starting point P, ending point P, and an intermediate point P, such that graphical command generating module  may generate two drawing stroke graphical object input commands . The first of such two drawing stroke graphical object input commands  for defining drawing stroke graphical object  may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=CIRCULAR PEN; COLOR=\/\/\/; EFFECT=NONE; START:P; END:P\u201d, while the second of such two drawing stroke graphical object input commands  for defining drawing stroke graphical object  may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=CIRCULAR PEN; COLOR=\/\/\/; EFFECT=NONE; START:P; END:P\u201d. Each one of these two drawing stroke input commands  generated by graphical command generating module  may be processed by graphical command processing module  to generate at least a portion of new drawing stroke pixel array data  that may present new drawing stroke graphical object  at the appropriate position on canvas  of screen ","A first input command  defining a first portion of a graphical object may be processed by processing module  while a second input command  defining a second portion of the graphical object is being generated by command generating module  in order to decrease the latency of system . That is, each one of multiple input commands  defining different portions of a graphical object may be processed for displaying its particular portion of the graphical object as soon as that particular input command is received by processing module , rather than none of the multiple input commands  being processed until all of the multiple input commands  are received by processing module . For example, following the example of drawing stroke graphical object  being defined by two drawing stroke input commands , the first drawing stroke input command  may be processed by processing module  for presenting a first portion of new drawing stroke graphical object  at the appropriate position on canvas  of screen (i.e., the portion of new drawing stroke graphical object  between points P and P defined by the first of the two drawing stroke input commands ) before and\/or while command generating module  may be generating the second drawing stroke input command  (i.e., the input command  defining the portion of new drawing stroke graphical object  between points P and P).","As mentioned, virtual drawing space application  of first electronic device  may be synched with virtual drawing space application  of second electronic device  such that a single work of art (e.g. artwork ) may be presented on both first device  and second device , and such that the single work of art may be collaboratively created and\/or edited through both user interactions with first device  and user interactions with second device . Therefore, when applications  and  are synched and have loaded common work of art , graphical object input commands generated by devices  and  may be shared by the devices such that artwork  presented by each device may have the same graphical object content. For example, at least some graphical object input commands  generated by graphical command generating module  may be provided to communications circuitry  of first electronic device  as shared graphical object input commands . A shared graphical object input command may be provided to communications circuitry  directly from graphical command generating module  or from graphical command processing module  (e.g., after graphical command processing module  has received the graphical object input command  from graphical command generating module ). Communications circuitry  may then provide the shared graphical object input command to communications circuitry  of second electronic device  via communications media , and communications circuitry  may provide the shared graphical object input command as a received graphical object input command to graphical command processing module  of graphical display system .","Therefore, continuing with the example of , based on the selected properties of options , , and , and points P and P of the trail path defined by new drawing stroke input information , graphical display system  may generate at least one new drawing stroke graphical object input command  that not only may be received and processed by graphical command processing module  of first electronic device  to generate at least a portion of new drawing stroke pixel array data  that may present new drawing stroke graphical object  at the appropriate position on canvas  of screen of display , but that also may be received and processed (i.e., as a received graphical object input command ) by graphical command processing module  of second electronic device  to generate at least a portion of new drawing stroke pixel array data  that may present a new drawing stroke graphical object  at the appropriate position on canvas  of screen of display . By sharing each of the one or more new drawing stroke graphical object input commands  that may define new drawing stroke graphical object  (e.g., as one or more shared drawing stroke graphical object input commands and, eventually, as one or more received drawing stroke graphical object input commands ), both graphical command processing module  of first device  and graphical command processing module  of second device  may independently receive and process the same new drawing stroke graphical object input command(s) for generating and displaying a new drawing stroke graphical object of shared work of art  on both canvas  of first device  and canvas  of second device . It is to be appreciated that, in some embodiments, no confirmation is required when a device receives a shared command. For example, after a user interacts with first device  to generate a graphical input command  and that input command is shared with second device  (e.g., as shared input command \/received input command ), second device  need not send any command or other data back to first device  in order for second device to process the input command or for first device to stop sharing the command.","Alternatively, as mentioned, at least some new drawing stroke graphical object pixel array data  generated by graphical command processing module  may be provided to communications circuitry  of first electronic device  as shared drawing stroke graphical object pixel array data . Communications circuitry  may then provide the shared drawing stroke graphical object pixel array data to communications circuitry  of second electronic device  via communications media , and communications circuitry  may provide the shared drawing stroke graphical object pixel array data as received drawing stroke graphical object pixel array data to graphical command processing module  of graphical display system .","Therefore, graphical command processing module  may process at least one new drawing stroke graphical object input command  to generate at least a portion of new drawing stroke pixel array data  that not only may present at least a portion of new drawing stroke graphical object  at the appropriate position on canvas  of screen of display , but that also may be received (i.e., as received drawing stroke pixel array data ) by graphical command processing module  of second electronic device  to present at least a portion of new drawing stroke graphical object  at the appropriate position on canvas  of screen of display . By sharing the pixel array data  that may present new drawing stroke graphical object  (e.g., as shared drawing stroke graphical object pixel array data and, eventually, as received drawing stroke graphical object pixel array data ), both graphical command processing module  of first device  and graphical command processing module  of second device  may independently display a new drawing stroke graphical object of shared work of art  on both canvas  of first device  and canvas  of second device . There may be semantics attached to shared pixel array data, but they may minimal compared to that of shared graphical input commands. For example, a chunk of pixel array data may contain the following fields: (1) a width of the region in pixels; (2) a height of the region in pixels; (3) an X and Y coordinate pair where a particular point of the region (e.g., the upper-left point) is to be placed on the canvas; and (4) the pixel data. Such pixel data may include a sequence of, for example, 4-byte values that may indicate pixel colors starting at the upper-left point and progressing to the right and downward. The number of pixels in this sequence may be configured to equal the width value times the height value for the command to be well-formed.","However, this approach of sharing pixel array data may add unnecessary latency to system , as graphical display system  of first device  may have to generate new drawing stroke pixel array data  from a new drawing stroke graphical object input command  before sharing new drawing stroke pixel array data  with second device , whereas the previously described approach may allow graphical display system  of first device  to share a new drawing stroke graphical object input command  with second device  before and\/or while graphical display system  of first device  may generate new drawing stroke pixel array data  from the new drawing stroke graphical object input command . Moreover, the bandwidth that may be required by communications media  to communicate a drawing stroke graphical object input command  from first device  to second device  (e.g., as shared drawing stroke graphical object input command \/received drawing stroke graphical object input command ) may be significantly less than the bandwidth that may be required by communications media  to communicate drawing stroke pixel array data  from first device  to second device  (e.g., as shared drawing stroke pixel array data \/received drawing stroke pixel array data ). Each particular command generated and\/or shared by system  may be smaller in size (e.g., may require less bandwidth to be transmitted across communications media ) than that of the pixel array data that may be generated by processing the particular command. By utilizing common semantics in response to particular shared input commands, graphical display system  of first device  and graphical display system  of second device  may share the input commands generated by one another so that each device may independently process the same input commands and so that each device may display the resultant pixel array data with reduced latency.","However, in some embodiments, despite utilizing common semantics in response to particular input commands, first electronic device  and second electronic device  may have different resources or capabilities, and may sometimes rather share pixel array data generated by one of the two devices for updating collaborative artwork  instead of or in addition to sharing input commands generated by one of the two devices for updating collaborative artwork . For example, upon receiving a received drawing stroke graphical object input command , graphical display system  may determine that second electronic device  is not able to or does not wish to generate new drawing stroke pixel array data  from the received drawing stroke graphical object input command . For example, graphical display system  may determine that second device  is trying to conserve its power supply  and does not have enough processing power to utilize for generating new drawing stroke pixel array data  from the received drawing stroke graphical object input command . As another example, graphical display system  may determine that second device  may lack a graphics processing unit powerful enough to perform a complex operation for processing a received graphical input command (e.g., a filter that renders an image with simulated oil pastels or paintbrush strokes in real time). As yet another example, graphical display system  may determine that first device  may have native support for hardware-accelerated image processing filters (e.g., that first device  may be an iMac\u2122 with a Core Image library), and that it may be faster to use the native functionality of first device  and then receive the results from first device  over communications media  rather than perform the operation on second device . In some embodiments, in response to such a determination, rather than generating new drawing stroke pixel array data  from received drawing stroke graphical object input command with graphical command processing module , graphical display system  of second device  may instead send a command to graphical display system  of first device  that may instruct graphical display system  to transmit new drawing stroke pixel array data  (e.g., as shared drawing stroke pixel array data ) to graphical command processing module  (e.g., as received drawing stroke pixel array data ), such that graphical command processing module  may avoid having to independently process received drawing stroke graphical object input command ","As shown by screen of , for example, a user of first electronic device  may select text string input option  of submenu  of artist menu  for creating one or more text string graphical objects in artwork  on canvas  (e.g., selection of option  may be shown by shading indicia within option  on , although selection of any option may be made apparent in any other suitable way, including non-visual ways). When a user selects text string input option , various options (not shown) may be made available to the user with respect to one or more of submenu options , , and  of graphical object property selection submenu , such that a user may select one or more text string properties that may at least partially define a text string graphical object to be created in artwork  on canvas . For example, text string graphical object style input option  of property selection submenu  may allow the user to select a font type from a group of various pre-defined font types (e.g., a \u201cArial\u201d text string style, as shown in ), text string graphical object color input option  of property selection submenu  may allow the user to select a color from a group of various pre-defined text string colors (e.g., a solid color represented by \u201c\u25aa\u201d, as shown in ), and text string graphical object effect input option  of property selection submenu  may allow the user to select one or more effects to be applied to the text string from a group of various pre-defined text string effects (e.g., an underlining effect, as shown in ). It is to be understood that additional or alternative pre-defined text string input tools of various other pre-defined fonts, colors, effects, and other various pre-defined text string graphical object properties may also be provided by submenu  of menu  when text string input option  of submenu  is selected.","Any interactions made by the user with respect to the options provided by menu  may be received by graphical display system  of first electronic device  for generating and displaying new menu content in menu . For example, when a user selects options , , , and  of menu  for creating a text string graphical object with an Arial font of a particular color and an underlining effect, for example, the menu selections may be received by graphical command generating module  of graphical display system  as menu input information , and graphical command generating module  may generate one or more appropriate menu input commands  representative of these menu selections. These menu input commands  may be processed by graphical command processing module  to generate at least a portion of pixel array data  with pixel data that may represent these menu selections, and that menu selection pixel data may be presented on display  in menu .","For example, as shown by screen of , in response to a user selecting text string input option  (e.g., with mouse input component ), graphical command generating module  may receive certain menu input information  and then generate a particular menu input command  (e.g., a menu input command with the representative syntax \u201cCOMMAND: CLASS=MENU INPUT; SELECT=MENU OPTION \u201d), which may be processed by graphical command processing module  to generate at least a portion of pixel array data  with updated menu pixel data that may present shading indicia at the portion of screen identifying input option  in menu  of display . Submenu  may be configured such that only one of options , , , and  may be selected at any given time. Therefore, the shading indicia identifying input option  on screen of  may be removed. Similarly, as shown by screen of , in response to a user selecting an Arial font at style input option , graphical display system  may generate and present \u201cArial\u201d within the box identifying input option  in menu  of display . Moreover, as shown by screen of , in response to a user selecting a particular color with input option  and an underlining effect with input option , graphical display system  may generate and present a representation of that color (e.g., \u201c\u25aa\u201d) within the box identifying input option  in menu  of display  and a representation of the underlining effect (e.g., \u201c_\u201d) within the box identifying input option  in menu  of display . It is to be understood that a menu input command generated with respect to a particular platform's user interface might not be shared with another device (e.g., if input synch \/ is not selected). Different devices may have entirely different user interfaces, with different menu schemes, button layouts, presence or lack of certain features, and the like. Therefore, certain menu input commands may not affect the user interface of one device like it may affect another.","Once options , , , and  of menu  have been selected for creating a text string graphical object (e.g., with an Arial font of a particular color and an underlining effect), and once the selections have been received by graphical display system  and represented on display  in menu , the user may then interact with device  for generating one or more glyphs of text on canvas  according to the selected options. Based on any appropriate text string graphical object input information , which may be generated by a user (e.g., using input component  and\/or input component ) and\/or any application running on device  (e.g., application ), graphical command generating module  may be configured to define and generate at least one new text string graphical object input command . This new text string graphical object input command  may then be processed by graphical command processing module  as new text string graphical object pixel array data  and presented on display .","For example, as also shown by screen of , a user may interact with graphical display system  to generate a new text string graphical object  in artwork  on canvas . As shown, text string graphical object  may include the text \u201cOK\u201d beginning at a starting point P on canvas  with the selected text string properties of options , , and . For example, in response to a user defining a starting point P of a new text string graphical object (e.g., by pointing a cursor at point P on canvas  with mouse input component ) and defining the characters \u201cOK\u201d of the new text string graphical object (e.g., by selecting the appropriate keys on keyboard input component ), graphical command generating module  may receive certain text string input information  and then generate a particular text string input command . For example, based on the selected properties of options , , and , starting point P, and characters \u201cOK\u201d, graphical command generating module  may generate a new text string graphical object input command , which may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=TEXT STRING; STYLE=ARIAL; COLOR=BLACK; EFFECT=UNDERLINE; START:P; CHARACTER(S):OK\u201d. The new text string input command  generated by graphical command generating module  may then be processed by graphical command processing module  to generate at least a portion of new text string pixel array data  that may present new text string graphical object  at the appropriate position on canvas  of screen of display .","It is to be understood that the above representative syntax of new text string input command  for generating new text string graphical object  is merely representative, and that any suitable syntax may be used by application  of first electronic device  for generating a new text string input command  in response to received text string input information . Although only starting point P of new text string graphical object  may be defined by the exemplary representative syntax of new text string input command , it is to be understood that, in other embodiments, multiple additional points on canvas  with respect to the new text string graphical object may be defined by the new text string input command .","In some embodiments, rather than generating a single new text string input command  for a new text string graphical object to be generated on canvas , graphical command generating module  may generate multiple new text string input commands , each of which may adequately instruct graphical command processing module  to generate a particular portion of the new text string graphical object on canvas . For example, as shown in , the starting position of text string character \u201cO\u201d of text string graphical object  may be defined by starting point P, and the starting point of text string character \u201cK\u201d of text string graphical object  may be defined by starting point P, such that graphical command generating module  may generate two text string graphical object input commands . The first of such two text string graphical object input commands  for defining text string graphical object  may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=TEXT STRING; STYLE=ARIAL; COLOR=BLACK; EFFECT=UNDERLINE; START:P; CHARACTER(S):O\u201d, while the second of such two text string graphical object input commands  for defining text string graphical object  may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=TEXT STRING; STYLE=ARIAL; COLOR=BLACK; EFFECT=UNDERLINE; START:P; CHARACTER(S):K\u201d. Each one of these two text string input commands  generated by graphical command generating module  may be processed by graphical command processing module  to generate at least a portion of new text string pixel array data  that may present new text string graphical object  at the appropriate position on canvas  of screen of display .","As mentioned, virtual drawing space application  of first electronic device  may be synched with virtual drawing space application  of second electronic device  such that a single work of art (e.g. artwork ) may be presented on both first device  and second device , and such that the single work of art may be collaboratively created and\/or edited through both user interactions with first device  and user interactions with second device . Therefore, continuing with the example of , based on the selected properties of options , , and , point P, and characters \u201cOK\u201d defined by text string graphical object input information  and received by first electronic device , graphical command generating module  may generate a new text string graphical object input command  that not only may be received and processed by graphical command processing module  of first electronic device  to generate at least a portion of new drawing stroke pixel array data  for presenting new text string graphical object  at the appropriate position on canvas  of screen of display , but that also may be received and processed (i.e., as a received graphical object input command ) by graphical command processing module  of second electronic device  to generate at least a portion of new text string pixel array data  for presenting a new text string graphical object  at the appropriate position on canvas  of screen of display . By sharing the new text string graphical object input command  (e.g., as shared text string graphical object input command and, eventually, as received text string graphical object input command ), both graphical command processing module  of first device  and graphical command processing module  of second device  may independently receive and process the same new text string graphical object input command for generating a new text string graphical object of artwork  on both canvas  of first device  and canvas  of second device .","Alternatively, as mentioned, at least some new text string graphical object pixel array data  generated by graphical command processing module  may be provided to communications circuitry  of first electronic device  as shared text string graphical object pixel array data . Communications circuitry  may then provide the shared text string graphical object pixel array data to communications circuitry  of second electronic device  via communications media , and communications circuitry  may provide the shared text string graphical object pixel array data as received text string graphical object pixel array data to graphical command processing module  of graphical display system . Therefore, graphical command processing module  may process a new text string graphical object input command  to generate at least a portion of new text string pixel array data  that not only may present new text string graphical object  at the appropriate position on canvas  of screen of display , but that also may be received (i.e., as received text string pixel array data ) by graphical command processing module  of second electronic device  to present new text string graphical object  at the appropriate position on canvas  of screen of display .","Rather than a user interacting with menu  of first device  to generate input information for defining new graphical object content of artwork  to be displayed on canvas  and\/or , a user may similarly interact with menu  of second device  to generate input information for defining new graphical object content of artwork . As shown by screen of , for example, a user of second electronic device  may select shape input option  of submenu  of artist menu  for creating one or more shapes on canvas  (e.g., selection of option  may be shown by shading indicia within option  on , although selection of any option may be made apparent in any other suitable way, including non-visual ways). When a user selects shape input option , various options (not shown) may be made available to the user with respect to one or more of submenu options , , and  of graphical object property selection submenu , such that a user may select one or more shape properties that may at least partially define a shape graphical object to be created in artwork  on canvas . For example, shape graphical object style input option  of property selection submenu  may allow the user to select a shape type from a group of various pre-defined shape types (e.g., a triangle style shape, as shown in ), shape graphical object color input option  of property selection submenu  may allow the user to select a color from a group of various pre-defined shape colors (e.g., a color represented by \u201c\\\\\\\u201d markings, as shown in ), and shape graphical object effect input option  of property selection submenu  may allow the user to select one or more effects to be applied to the shape from a group of various pre-defined shape effects (e.g., no effects, as shown in ). It is to be understood that additional or alternative pre-defined shapes of various other pre-defined colors, effects, and other various pre-defined shape graphical object properties may also be provided by submenu  of menu  when shape input option  of submenu  is selected.","Any interactions made by the user with respect to the options provided by menu  may be received by graphical display system  of second electronic device  for generating and displaying new menu content in canvas area . For example, when a user selects options , , , and  of menu  for creating a triangle shape graphical object of a particular color and no effects, the selections may be received by graphical command generating module  of graphical display system  as new menu input information , and graphical command generating module  may generate one or more appropriate new menu input commands  representative of these menu selections. These menu input commands  may be processed by graphical command processing module  to generate at least a portion of pixel array data  with pixel data that may represent these menu selections, and that menu selection pixel data may be presented on display  in menu .","For example, as shown by screen of , in response to a user selecting shape input option  (e.g., with touch screen I\/O component ), graphical command generating module  may receive certain menu input information  and then generate a particular menu input command  (e.g., a menu input command with the representative syntax \u201cCOMMAND: CLASS=MENU INPUT; SELECT=MENU OPTION \u201d), which may be processed by graphical command processing module  to generate at least a portion of pixel array data  with updated menu pixel data that may present shading indicia at the portion of screen identifying input option  in menu  of display . Similarly, as shown by screen of , in response to a user selecting a triangle shape at style input option , graphical display system  may generate and present a \u201cA\u201d within the box identifying input option  in menu  of display . Moreover, as shown by screen of , in response to a user selecting a particular color with input option  and no effects with input option , graphical display system  may generate and present a representation of that color (e.g., \u201c\\\\\\\u201d) within the box identifying input option  in menu  of display  and a representation of no effect (e.g., \u201cnone\u201d) within the box identifying input option  in menu  of display .","Once options , , , and  of menu  have been selected for creating a shape graphical object (e.g., a triangle shape of a particular color with no effects), and once the selections have been received by graphical display system  and represented on display  in menu , the user may then interact with device  for generating at least one triangle shape on canvas  according to the selected options. Based on any appropriate shape graphical object input information , which may be generated by a user (e.g., using input component  and\/or input component ) and\/or any application running on device  (e.g., application ), graphical command generating module  may be configured to define and generate at least one new shape graphical object input command . This new shape graphical object input command  may then be processed by graphical command processing module  as new shape graphical object pixel array data  and presented on display .","For example, as also shown by screen of , a user may interact with graphical display system  to generate a new shape graphical object  in artwork  on canvas . As shown, shape graphical object  may include a triangle with a first corner at a point P on canvas , a second corner at point P on canvas , and a third corner at point P on canvas , with the selected shape properties of options , , and . For example, in response to a user defining a point P on canvas  for positioning a lower-left corner of a new triangle shape graphical object (e.g., by touching point P on canvas  with touch screen input component ), and additional points P and P on canvas  for respectively positioning a top corner and a lower-right corner of the new triangle shape graphical object, graphical command generating module  may receive certain shape input information  and then generate a particular shape input command . For example, based on the selected properties of options , , and , and points P-P, graphical command generating module  may generate a new shape graphical object input command , which may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=SHAPE; STYLE=TRIANGLE; COLOR=\\\\\\; EFFECT=NONE; CORNER:P; CORNER:P; CORNER:P\u201d. The new shape input command  generated by graphical command generating module  may then be processed by graphical command processing module  to generate at least a portion of new shape pixel array data  that may present new shape graphical object  at the appropriate position on canvas  of screen of display . It is to be understood that the above representative syntax of new shape input command  for generating new shape graphical object  is merely representative, and that any suitable syntax may be used by application  of second electronic device  for generating a new shape input command  in response to received shape input information .","In some embodiments, rather than generating a single new shape input command  for a new shape graphical object to be generated on canvas , graphical command generating module  may generate multiple new shape input commands , each of which may adequately instruct graphical command processing module  to generate a particular portion or configuration of the new shape graphical object  on canvas . For example, as shown in , when a user has only defined a point P on canvas  for positioning a lower-left corner of a new triangle shape graphical object, but has not yet defined point P or point P, a default position for the top corner of the triangle may be defined by a default point P\u2032 and a default position for the lower-right corner of the triangle may be defined by a default point P\u2032 (e.g., based on a default size and\/or a default orientation of the shape), such that graphical command generating module  may generate at least two shape graphical object input commands . The first of such two shape graphical object input commands  for defining shape graphical object  may be generated only after the user has defined point P and may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=SHAPE; STYLE=TRIANGLE; COLOR=\\\\\\; EFFECT=NONE; CORNER:P; CORNER:P\u2032; CORNER:P\u2032\u201d, while the second of such two shape graphical object input commands  for defining shape graphical object  may be generated after the user has defined point P and then point P and may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=SHAPE; STYLE=TRIANGLE; COLOR=\\\\\\; EFFECT=NONE; CORNER:P; CORNER:P; CORNER:P\u2033\u201d (e.g., where point P\u2033 may be at a default position for the lower-right corner of the triangle when the user has defined both point P and point P, but not yet point P; although as shown in , point P\u2033 may be the same as point P). Each one of these two shape input commands  generated by graphical command generating module  may be processed by graphical command processing module  to generate at least a portion of new shape pixel array data  that may present new shape graphical object  at the appropriate position on canvas  of screen of display .","As mentioned, virtual drawing space application  of first electronic device  may be synched with virtual drawing space application  of second electronic device  such that a single work of art (e.g. artwork ) may be presented on both first device  and second device , and such that the single work of art may be collaboratively created and\/or edited through both user interactions with first device  and user interactions with second device . Therefore, continuing with the example of , based on the selected properties of options , , and , and points P-P defined by shape graphical object input information  and received by second electronic device , graphical command generating module  may generate at least one new shape graphical object input command  that not only may be received and processed by graphical command processing module  of second electronic device  to generate at least a portion of new shape pixel array data  for presenting new shape graphical object  at the appropriate position on canvas  of screen of display , but that also may be received and processed (i.e., as a received graphical object input command ) by graphical command processing module  of first electronic device  to generate at least a portion of new shape pixel array data  that may present a new shape graphical object  at the appropriate position on canvas  of screen of display . By sharing at least one new shape graphical object input command  (e.g., as shared shape graphical object input command and, eventually, as received shape graphical object input command ), both graphical command processing module  of second device  and graphical command processing module  of first device  may independently receive and process the same new shape graphical object input command for generating a new shape graphical object of artwork  on both canvas  of first device  and canvas  of second device .","Alternatively, at least some new shape graphical object pixel array data  generated by graphical command processing module  may be provided to communications circuitry  of second electronic device  as shared shape graphical object pixel array data . Communications circuitry  may then provide the shared shape graphical object pixel array data to communications circuitry  of first electronic device  via communications media , and communications circuitry  may provide the shared shape graphical object pixel array data as received shape graphical object pixel array data to graphical command processing module  of graphical display system . Therefore, graphical command processing module  may process a new shape graphical object input command  to generate at least a portion of new shape pixel array data  that not only may present new shape graphical object  at the appropriate position on canvas  of screen of display , but that also may be received (i.e., as received shape pixel array data ) by graphical command processing module  of first electronic device  to present new shape graphical object  at the appropriate position on canvas  of screen of display .","As shown by screen of , for example, a user of second electronic device  may select image input option  of submenu  of artist menu  for creating one or more images on canvas  (e.g., selection of option  may be shown by shading indicia within option  on , although selection of any option may be made apparent in any other suitable way, including non-visual ways). When a user selects image input option , various options (not shown) may be made available to the user with respect to one or more of submenu options , , and  of graphical object property selection submenu , such that a user may select one or more image properties that may at least partially define an image graphical object to be created in artwork  on canvas . For example, image graphical object style input option  of property selection submenu  may allow the user to select a particular image file from a group of various image files that may be accessible to second device  (e.g., an image of a car, as shown in ), image graphical object color input option  of property selection submenu  may allow the user to select a color or color scheme from a group of various pre-defined image colors or color schemes (e.g., a black and white color scheme represented, as shown in ), and image graphical object effect input option  of property selection submenu  may allow the user to select one or more effects to be applied to the image from a group of various pre-defined image effects (e.g., no effects, as shown in ). It is to be understood that additional or alternative pre-defined images of various other pre-defined colors, effects, and other various pre-defined image graphical object properties may also be provided by submenu  of menu  when image input option  of submenu  is selected.","Any selections made by the user with respect to the options provided by menu  may be received by graphical display system  of second electronic device  for generating and displaying new menu content in menu . For example, when a user selects options , , , and  of menu  for creating an image graphical object of a car of a particular color and no effects, the selections may be received by graphical command generating module  of graphical display system  as new menu input information , and graphical command generating module  may generate one or more appropriate new menu input commands  representative of these menu selections. These menu input commands  may be processed by graphical command processing module  to generate at least a portion of pixel array data  with pixel data that may represent these menu selections, and that menu pixel array data may be presented on display  in menu .","For example, as shown by screen of , in response to a user selecting image input option  (e.g., with touch screen I\/O component ), graphical command generating module  may receive certain menu input information  and then generate a particular menu input command  (e.g., a menu input command with the representative syntax \u201cCOMMAND: CLASS=MENU INPUT; SELECT=MENU OPTION \u201d), which may be processed by graphical command processing module  to generate at least a portion of pixel array data  with updated menu pixel data that may present shading indicia at the portion of screen identifying input option  in menu  of display . Similarly, as shown by screen of , in response to a user selecting a car image at style input option , graphical display system  may generate and present \u201c<car>\u201d within the box identifying input option  in menu  of display . Moreover, as shown by screen of , in response to a user selecting a particular black and white color scheme with input option  and no effects with input option , graphical display system  may generate and present a representation of that color scheme (e.g., \u201cB&W\u201d) within the box identifying input option  in menu  of display  and a representation of no effect (e.g., \u201cnone\u201d) within the box identifying input option  in menu  of display .","Once options , , , and  of menu  have been selected for creating an image graphical object (e.g., a black and white image of a car with no effects), and once the selections have been received by graphical display system  and represented on display  in menu , the user may then interact with device  for generating at least one car image on canvas  according to the selected options. Based on any appropriate image graphical object input information , which may be generated by a user (e.g., using input component  and\/or input component ) and\/or any application running on device  (e.g., application ), graphical command generating module  may be configured to define and generate at least one new image graphical object input command . This new image graphical object input command  may then be processed by graphical command processing module  as new image graphical object pixel array data  and presented on display .","For example, as also shown by screen of , a user may interact with graphical display system  to generate a new image graphical object  in artwork  on canvas . As shown, image graphical object  may include a black and white image of a car centered about a point P on canvas  and with an upper-left corner at a point P on canvas , with the selected image properties of options , , and . For example, in response to a user defining point P on canvas  for positioning the center of a new image graphical object (e.g., by touching point P on canvas  with touch screen input component ), and additional point P for positioning the upper-left corner of the new image graphical object, graphical command generating module  may receive certain image input information  and then generate a particular image input command . For example, based on the selected properties of options , , and , and points P and P, graphical command generating module  may generate a new image graphical object input command , which may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=IMAGE; STYLE=<CAR.FILE>; COLOR=B&W; EFFECT=NONE; CENTER:P; CORNER:P\u201d. The new image input command  generated by graphical command generating module  may then be processed by graphical command processing module  to generate at least a portion of new image pixel array data  that may present new image graphical object  at the appropriate position on canvas  of screen of display . It is to be understood that the above representative syntax of new image input command  for generating new image graphical object  is merely representative, and that any suitable syntax may be used by application  of second electronic device  for generating a new image input command  in response to received shape input information .","In some embodiments, rather than generating a single new image input command  for a new image graphical object to be generated on canvas , graphical command generating module  may generate multiple new image input commands , each of which may adequately instruct graphical command processing module  to generate a particular portion or configuration of new image graphical object  on canvas . For example, as shown in , when a user has only defined a point P on canvas  for positioning the center of a new image graphical object, but has not yet defined point P, a default position for the upper-right corner of the image may be defined by a default point P\u2032 (e.g., based on a default size and\/or a default orientation of the image), such that graphical command generating module  may generate two image graphical object input commands . The first of such two image graphical object input commands  for defining image graphical object  may be generated only after the user has defined point P and may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=IMAGE; STYLE=<CAR.FILE>; COLOR=B&W; EFFECT=NONE; CENTER:P; CORNER:P\u2032\u201d, while the second of such two image graphical object input commands  for defining image graphical object  may be generated after the user has defined points P and P and may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=IMAGE; STYLE=<CAR.FILE>; COLOR=B&W; EFFECT=NONE; CENTER:P; CORNER:P\u201d. Each one of these two image input commands  generated by graphical command generating module  may be processed by graphical command processing module  to generate at least a portion of new image pixel array data  that may present new image graphical object  at the appropriate position on canvas  of screen of display .","As mentioned, virtual drawing space application  of first electronic device  may be synched with virtual drawing space application  of second electronic device  such that a single work of art (e.g. artwork ) may be presented on both first device  and second device , and such that the single work of art may be collaboratively created and\/or edited through both user interactions with first device  and user interactions with second device . Therefore, continuing with the example of , based on the selected properties of options , , and , and points P and P defined by image graphical object input information  and received by second electronic device , graphical command generating module  may generate at least one new image graphical object input command  that not only may be received and processed by graphical command processing module  of second electronic device  to generate at least a portion of new image pixel array data  for presenting new image graphical object  at the appropriate position on canvas  of screen of display , but that also may be received and processed (i.e., as a received graphical object input command ) by graphical command processing module  of first electronic device  to generate at least a portion of new image pixel array data  that may present a new image graphical object  at the appropriate position on canvas  of screen of display . By sharing at least one new image graphical object input command  (e.g., as shared image graphical object input command and, eventually, as received image graphical object input command ), both graphical command processing module  of second device  and graphical command processing module  of first device  may independently receive and process the same new image graphical object input command for generating a new image graphical object of artwork  on both canvas  of first device  and canvas  of second device .","Alternatively, at least some new image graphical object pixel array data  generated by graphical command processing module  may be provided to communications circuitry  of second electronic device  as shared image graphical object pixel array data . Communications circuitry  may then provide the shared image graphical object pixel array data to communications circuitry  of first electronic device  via communications media , and communications circuitry  may provide the shared image graphical object pixel array data as received image graphical object pixel array data to graphical command processing module  of graphical display system . Therefore, graphical command processing module  may process a new image graphical object input command  to generate at least a portion of new image pixel array data  that not only may present new image graphical object  at the appropriate position on canvas  of screen of display , but that also may be received (i.e., as received image pixel array data ) by graphical command processing module  of first electronic device  to present new image graphical object  at the appropriate position on canvas  of screen of display .","As mentioned, in some embodiments, based on the selected properties of options , , and , and points P and P, graphical command generating module  may generate a new image graphical object input command , which may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=IMAGE; STYLE=<CAR.FILE>; COLOR=B&W; EFFECT=NONE; CENTER:P; CORNER:P\u201d. The style portion of such a new image graphical object input command  (i.e., the \u201cSTYLE=<CAR.FILE>\u201d portion) may be a pointer, URL, or any other suitable address at which the appropriate image file may be accessed. The appropriate image file may be stored in any suitable location that may be accessible to first device  and\/or second device  (e.g., memory , memory , and\/or server ), and the appropriate image file may be stored in any suitable format (e.g., JPEG, TIFF, PNG, GIF, etc.). When such a new image graphical object input command  is received by a graphical command processing module, the graphical command processing module may access the addressed image file and process the file as new image pixel array data. In other embodiments, the style portion of such a new image graphical object input command  (i.e., the \u201cSTYLE=<CAR.FILE>\u201d portion) may be a copy of at least a portion of the appropriate image file. For example, in some embodiments, the style portion of a new image graphical object input command  may include at least a portion of an actual image file in any suitable format (e.g., a JPEG file, a TIFF file, a PNG file, a GIF file, etc.) that may be in any compressed or uncompressed state. When such a new image graphical object input command  is received by a graphical command processing module, the graphical command processing module may process the received image file as new image pixel array data.","As mentioned, inter-device submenu  of artist menu  may include an input synch option , and inter-device submenu  of artist menu  may include an input synch option , each of which a user may interact with to selectively synchronize the current active user interface selections of first electronic device  with the current active user interface selections of second electronic device . As shown in , input synch options  and  are unselected. When input synch options  and  are unselected, system  may be configured such that the current active user interface selections of first electronic device  are not synchronized with the current active user interface selections of second electronic device . Such non-synchronization may allow for the current active graphical object type selection(s) of submenu  and\/or the current active graphical object property selection(s) of submenu  of first device  to differ from the current active graphical object type selection(s) of submenu  and\/or the current active graphical object property selection(s) of submenu  of second device . Such non-synchronization may also allow for first device  to be interacted with for generating a first type of graphical object while second device  may be simultaneously interacted with for generating a second type of graphical object.","For example, with continued reference to , although a user of second device  may select image input option  of submenu  of artist menu  for creating image graphical object  on canvas  (e.g., selection of option  may be shown by shading indicia within option  on ), text string input option  of submenu  of artist menu  may still be selected (e.g., due to a user of first device  originally creating text string graphical object  in ). Therefore, in some embodiments, while one user may interact with second device  for creating new image graphical object  on canvas  and\/or new image graphical object  on canvas , the same user or another user may simultaneously interact with first device  for creating another new graphical object on canvas  and\/or on canvas .","For example, as also shown by screen of , while one user may interact with second device  for creating image graphical object  on canvas  and\/or image graphical object  on canvas , the same or another user may simultaneously interact with first electronic device  for creating a new text string graphical object. The new text string graphical object to be created may be at least partially defined by the same selections for submenu options , , and  as made with respect to  or by new properties as selected by the user. Once options , , , and  of menu  have been selected for creating a new text string graphical object (e.g., with an Arial font of a particular color and an underlining effect), the user may then interact with device  for generating one or more glyphs of text on canvas  according to the selected options. Based on any appropriate text string graphical object input information , which may be generated by a user (e.g., using input component  and\/or input component ) and\/or any application running on device  (e.g., application ), graphical command generating module  may be configured to define and generate at least one new text string graphical object input command . This new text string graphical object input command  may then be processed by graphical command processing module  as new text string graphical object pixel array data  and presented on display .","For example, as also shown by screen of , a user may interact with graphical display system  to generate a new text string graphical object  in artwork  on canvas . As shown, text string graphical object  may include the text \u201cA\u201d beginning at a starting point P on canvas  with the selected text string properties of options , , and . For example, in response to a user defining a starting point P of a new text string graphical object (e.g., by pointing a cursor at point P on canvas  with mouse input component ) and defining the character \u201cA\u201d of the new text string graphical object (e.g., by selecting the appropriate key(s) on keyboard input component ), graphical command generating module  may receive certain text string input information  and then generate a particular text string input command . For example, based on the selected properties of options , , and , starting point P, and character \u201cA\u201d, graphical command generating module  may generate a new text string graphical object input command , which may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=TEXT STRING; STYLE=ARIAL; COLOR=BLACK; EFFECT=UNDERLINE; START:P; CHARACTER(S):A\u201d. The new text string input command  generated by graphical command generating module  may then be processed by graphical command processing module  to generate at least a portion of new text string pixel array data  that may present new text string graphical object  at the appropriate position on canvas  of screen of display .","As mentioned, virtual drawing space application  of first electronic device  may be synched with virtual drawing space application  of second electronic device  such that a single work of art (e.g. artwork ) may be presented on both first device  and second device , and such that the single work of art may be collaboratively created and\/or edited through both user interactions with first device  and user interactions with second device . Therefore, continuing with the example of , based on the selected properties of options , , and , point P, and character \u201cA\u201d defined by text string graphical object input information  and received by first electronic device , graphical command generating module  may generate a new text string graphical object input command  that not only may be received and processed by graphical command processing module  of first electronic device  to generate at least a portion of new drawing stroke pixel array data  for presenting new text string graphical object  at the appropriate position on canvas  of screen of display , but that also may be received and processed (i.e., as a received graphical object input command ) by graphical command processing module  of second electronic device  to generate at least a portion of new text string pixel array data  that may present a new text string graphical object  at the appropriate position on canvas  of screen of display . By sharing the new text string graphical object input command  (e.g., as shared text string graphical object input command and, eventually, as received text string graphical object input command ), both graphical command processing module  of first device  and graphical command processing module  of second device  may independently receive and process the same new text string graphical object input command for generating a new text string graphical object of artwork  on both canvas  of first device  and canvas  of second device .","Alternatively, as mentioned, at least some new text string graphical object pixel array data  generated by graphical command processing module  may be provided to communications circuitry  of first electronic device  as shared text string graphical object pixel array data . Communications circuitry  may then provide the shared text string graphical object pixel array data to communications circuitry  of second electronic device  via communications media , and communications circuitry  may provide the shared text string graphical object pixel array data as received text string graphical object pixel array data to graphical command processing module  of graphical display system . Therefore, graphical command processing module  may process a new text string graphical object input command  to generate at least a portion of new text string pixel array data  that not only may present new text string graphical object  at the appropriate position on canvas  of screen of display , but that also may be received (i.e., as received text string pixel array data ) by graphical command processing module  of second electronic device  to present new text string graphical object  at the appropriate position on canvas  of screen of display .","Due to input synch options  and  being unselected, system  may be configured such that first electronic device  may define, process, display, and\/or share new text string graphical object input command  and\/or new text string graphical object pixel array data  for new text string graphical object  with second electronic device  before, during, and\/or at the same time as second electronic device  may define, process, display, and\/or share new image graphical object input command  and\/or new image graphical object pixel array data  for new image graphical object  with first electronic device . Alternatively, if input synch options  and  are selected (not shown), system  may be configured such that whenever a user interacts with either first device  to make a selection on artist menu  or second device  to make a selection on artist menu , the selection may be made to both artist menu  and artist menu .","In some embodiments, different portions of a collaborative work of art may be shown on different devices at a particular time. For example, although  may show the entirety of collaborative work of art  on both canvas  of first electronic device  and canvas  of second electronic device , a user may choose to view the entirety of collaborative artwork  on display  of first device  and only a portion of collaborative artwork  on display  of second device  (e.g., to view a portion of the artwork in greater detail by zooming-in to that portion using second device ). However, before describing such additional features of system  with respect to screens -and -of , a more detailed description of portions of graphical display system  and graphical display system  is provided.","In some embodiments, as shown in , for example, graphical command generating module  of graphical display system  may include a graphical input command generating module , an active display adjusting module , and an outline selecting module . Moreover, as shown in , graphical command processing module  of graphical display system  may include an outline moving module , a graphical command sharing module , a pixel array requesting module , a pixel array sharing module , a pixel array generating module , a pixel array combining module , and an active display defining module .","As described in more detail with respect to , graphical input command generating module  may be configured to receive graphical input information  and to generate one or more generated graphical input commands , which may then be provided to graphical command sharing module  and\/or to pixel array generating module . Active display adjusting module  may be configured to receive active display adjustment input information  and to generate one or more active display adjustment input commands , which may then be provided to active display defining module  and\/or to communications circuitry  of first device  for sharing with a remote entity. Outline selecting module  may be configured to receive outline selecting input information  and to generate one or more shared other device active display adjustment input commands , which may then be provided to communications circuitry  of first device  for sharing with a remote entity. Moreover, outline selecting module  may be configured to generate one or more generated outline moving commands , which may then be provided to outline moving module . Graphical input information , active display adjustment input information , and\/or outline selecting input information  may be a portion of input information  and may be received from various input sources, such as the one or more applications being run by first electronic device  (e.g., application ) and\/or any user input instructions being received by device  (e.g., via any input component  of first electronic device ). When provided to communications circuitry  of first device  for sharing with a remote entity, active display adjustment input commands  and\/or shared other device active display adjustment input commands  may be a shared input command ","Outline moving module  may be configured to receive one or more generated outline moving commands  from outline selecting module  and\/or one or more received outline moving commands  from communications circuitry  of first device . Received outline moving commands  may be received by communications circuitry  from any suitable remote entity (e.g., second device ) and a received outline moving command  may be a received input command . Moreover, outline moving module  may be configured to generate one or more master outline moving commands , which may then be provided to pixel array generating module .","Graphical command sharing module  may be configured to receive one or more generated graphical input commands  from graphical input command generating module  and to generate one or more shared graphical input commands , which may then be provided to communications circuitry  of first device  for sharing with a remote entity. When provided to communications circuitry  of first device  for sharing with a remote entity, a graphical input command  may be a shared input command ","Pixel array requesting module  may be configured to receive one or more received graphical input commands  from communications circuitry  of first device  and\/or active display adjustment pixel array data request information  from active display defining module . Received graphical input commands  may be received by communications circuitry  from any suitable remote entity (e.g., second device ) and a received graphical input command  may be a received input command . Moreover, pixel array requesting module  may be configured to provide one or more received graphical input commands  to pixel array generating module . Additionally or alternatively, pixel array requesting module  may be configured to generate one or more shared pixel array data request commands , which may then be provided to communications circuitry  of first device  for sharing with a remote entity. When provided to communications circuitry  of first device  for sharing with a remote entity, a shared pixel array data request command  may be a shared input command ","Pixel array sharing module  may be configured to receive one or more received pixel array data request commands  from communications circuitry  of first device . Received pixel array data request commands  may be received by communications circuitry  from any suitable remote entity (e.g., second device ) and a received pixel array data request command  may be a received input command . Moreover, pixel array sharing module  may be configured to receive combined pixel array data  from pixel array combining module . Pixel array sharing module  may also be configured to generate shared pixel array data , which may then be provided to communications circuitry  of first device  for sharing with a remote entity. When provided to communications circuitry  of first device  for sharing with a remote entity, shared pixel array data  may be shared pixel array data ","Pixel array generating module  may be configured to receive one or more generated graphical input commands  from graphical input command generating module , one or more master outline moving commands  from outline moving module , and\/or one or more received graphical input commands  from pixel array requesting module . Moreover, pixel array generating module  may be configured to generate generated pixel array data , which may then be provided to pixel array combining module .","Pixel array combining module  may be configured to receive generated pixel array data  from pixel array generating module  and\/or received pixel array data  from communications circuitry  of first device . Received pixel array data  may be received by communications circuitry  from any suitable remote entity (e.g., second device ) and pixel array data  may be received pixel array data . Moreover, pixel array combining module  may be configured to generate combined pixel array data , which may then be provided to pixel array sharing module  and\/or to active display defining module .","As also shown in , active display defining module  may be configured to receive one or more active display adjustment input commands  from active display adjusting module , combined pixel array data  from pixel array combining module , and\/or one or more received active display adjustment input commands  from communications circuitry  of first device . Received active display adjustment input commands  may be received by communications circuitry  from any suitable remote entity (e.g., second device ) and a received active display adjustment input command  may be a received input command . Active display defining module  may also be configured to generate active pixel array data , which may then be presented on display  of first device . Active pixel array data  may be pixel array data . Alternatively or additionally, active display defining module  may be configured to generate active display adjustment pixel array data request information , which may then be provided to pixel array requesting module .","In some embodiments, as shown in , for example, graphical command generating module  of graphical display system  may include a graphical input command generating module , an active display adjusting module , and an outline selecting module . Moreover, as shown in , graphical command processing module  of graphical display system  may include an outline moving module , a graphical command sharing module , a pixel array requesting module , a pixel array sharing module , a pixel array generating module , a pixel array combining module , and an active display defining module .","As described in more detail with respect to , graphical input command generating module  may be configured to receive graphical input information  and to generate one or more generated graphical input commands , which may then be provided to graphical command sharing module  and\/or to pixel array generating module . Active display adjusting module  may be configured to receive active display adjustment input information  and to generate one or more active display adjustment input commands , which may then be provided to active display defining module  and\/or to communications circuitry  of second device  for sharing with a remote entity. Outline selecting module  may be configured to receive outline selecting input information  and to generate one or more shared other device active display adjustment input commands , which may then be provided to communications circuitry  of second device  for sharing with a remote entity. Moreover, outline selecting module  may be configured to generate one or more generated outline moving commands , which may then be provided to outline moving module . Graphical input information , active display adjustment input information , and\/or outline selecting input information  may be a portion of input information  and may be received from various input sources, such as the one or more applications being run by second electronic device  (e.g., application ) and\/or any user input instructions being received by device  (e.g., via any input component  of second electronic device ). When provided to communications circuitry  of second device  for sharing with a remote entity, active display adjustment input commands  and\/or shared other device active display adjustment input commands  may be a shared input command ","Outline moving module  may be configured to receive one or more generated outline moving commands  from outline selecting module  and\/or one or more received outline moving commands  from communications circuitry  of second device . Received outline moving commands  may be received by communications circuitry  from any suitable remote entity (e.g., first device ) and a received outline moving command  may be a received input command . Moreover, outline moving module  may be configured to generate one or more master outline moving commands , which may then be provided to pixel array generating module .","Graphical command sharing module  may be configured to receive one or more generated graphical input commands  from graphical input command generating module  and to generate one or more shared graphical input commands , which may then be provided to communications circuitry  of second device  for sharing with a remote entity. When provided to communications circuitry  of second device  for sharing with a remote entity, a graphical input command  may be a shared input command ","Pixel array requesting module  may be configured to receive one or more received graphical input commands  from communications circuitry  of second device  and\/or active display adjustment pixel array data request information  from active display defining module . Received graphical input commands  may be received by communications circuitry  from any suitable remote entity (e.g., first device ) and a received graphical input command  may be a received input command . Moreover, pixel array requesting module  may be configured to provide one or more received graphical input commands  to pixel array generating module . Additionally or alternatively, pixel array requesting module  may be configured to generate one or more shared pixel array data request commands , which may then be provided to communications circuitry  of second device  for sharing with a remote entity. When provided to communications circuitry  of second device  for sharing with a remote entity, a shared pixel array data request command  may be a shared input command ","Pixel array sharing module  may be configured to receive one or more received pixel array data request commands  from communications circuitry  of second device . Received pixel array data request commands  may be received by communications circuitry  from any suitable remote entity (e.g., first device ) and a received pixel array data request command  may be a received input command . Moreover, pixel array sharing module  may be configured to receive combined pixel array data  from pixel array combining module . Pixel array sharing module  may also be configured to generate shared pixel array data , which may then be provided to communications circuitry  of second device  for sharing with a remote entity. When provided to communications circuitry  of second device  for sharing with a remote entity, shared pixel array data  may be shared pixel array data ","Pixel array generating module  may be configured to receive one or more generated graphical input commands  from graphical input command generating module , one or more master outline moving commands  from outline moving module , and\/or one or more received graphical input commands  from pixel array requesting module . Moreover, pixel array generating module  may be configured to generate generated pixel array data , which may then be provided to pixel array combining module .","Pixel array combining module  may be configured to receive generated pixel array data  from pixel array generating module  and\/or received pixel array data  from communications circuitry  of second device . Received pixel array data  may be received by communications circuitry  from any suitable remote entity (e.g., first device ) and pixel array data  may be received pixel array data . Moreover, pixel array combining module  may be configured to generate combined pixel array data , which may then be provided to pixel array sharing module  and\/or to active display defining module .","As also shown in , active display defining module  may be configured to receive one or more active display adjustment input commands  from active display adjusting module , combined pixel array data  from pixel array combining module , and\/or one or more received active display adjustment input commands  from communications circuitry  of second device . Received active display adjustment input commands  may be received by communications circuitry  from any suitable remote entity (e.g., first device ) and a received active display adjustment input command  may be a received input command . Active display defining module  may also be configured to generate active pixel array data , which may then be presented on display  of second device . Active pixel array data  may be pixel array data . Alternatively or additionally, active display defining module  may be configured to generate active display adjustment pixel array data request information , which may then be provided to pixel array requesting module .","Each one of graphical input command generating module , active display adjusting module , outline selecting module , outline moving module , graphical command sharing module , pixel array requesting module , pixel array sharing module , pixel array generating module , pixel array combining module , and active display defining module  of graphical display system  of second electronic device , and any of the information, commands, and pixel array data generated or received by any of those modules of system , may be the same as or substantially similar to a respective one of graphical input command generating module , active display adjusting module , outline selecting module , outline moving module , graphical command sharing module , pixel array requesting module , pixel array sharing module , pixel array generating module , pixel array combining module , and active display defining module  of graphical display system  of first electronic device , and any of the information, commands, and pixel array data generated or received by any of those modules of system , and, therefore, may not be independently described in greater detail.","While, in some embodiments, graphical display system  of first electronic device  and graphical display system  of second electronic device  may be the same or substantially similar graphical display systems, in other embodiments, graphical display system  of first electronic device  may have one or more different and\/or additional modules that graphical display system  of second electronic device  may not have, and vice versa. While, in some embodiments, graphical display system  of first electronic device  and graphical display system  of second electronic device  may be the same or substantially similar graphical display systems, in other embodiments, graphical display system  of first electronic device  may be configured to process or otherwise handle one or more different and\/or additional types of input commands and\/or types of pixel array data that graphical display system  of second electronic device  may not be configured to process or otherwise handle, and vice versa.","As also shown in , a shared other device active display adjustment input command  generated by graphical display system  may be received by graphical display system  as a received own active display adjustment input command , while a shared other device active display adjustment input command  generated by graphical display system  may be received by graphical display system  as a received own active display adjustment input command . An active display adjustment input command  generated by graphical display system  may be received by graphical display system  as a received outline moving command , while an active display adjustment input command  generated by graphical display system  may be received by graphical display system  as a received outline moving command . A shared graphical input command  generated by graphical display system  may be received by graphical display system  as a received graphical input command , while a shared graphical input command  generated by graphical display system  may be received by graphical display system  as a received graphical input command . Moreover, a shared pixel array data request command  generated by graphical display system  may be received by graphical display system  as a received pixel array data request command , while a shared pixel array data request command  generated by graphical display system  may be received by graphical display system  as a received pixel array data request command . Finally, as shown in , shared pixel array data  generated by graphical display system  may be received by graphical display system  as received pixel array data , while shared pixel array data  generated by graphical display system  may be received by graphical display system  as received pixel array data .","As mentioned, although  show the entirety of collaborative artwork  on both canvas  of first electronic device  and canvas  of second electronic device , a user may choose to view the entirety of collaborative artwork  on display  of first device  and only a portion of collaborative artwork  on display  of second device  (e.g., to view a portion of the work in greater detail by zooming-in to that portion using second device ). For example, as shown in , a user may interact with second device  to generate input information for changing the portion of canvas  that may be displayed on display . As shown by screen of , for example, a user of second electronic device  may select a point P on canvas  that the user would like to zoom-in on. A user may interact with second electronic device  in any suitable way (e.g., using input component  and\/or input component ) to identify point P or to instruct device  to zoom-in on a particular portion of canvas  in any suitable way. For example, a user may use a multi-touch pull user input gesture to zoom-in on canvas  about point P with a particular zoom factor Z. Additionally or alternatively, a user may trace an outline on canvas  to define the portion of canvas  that the user would like to be displayed across the entirety of the canvas portion of screen  (e.g., by tracing outline O as shown in ). Although not shown, artist menu  may provide a user of second electronic device  with input options for appropriately interacting with device  to properly identify the portion of canvas  to be actively displayed on display .","Any selections or interactions made by the user of second device  with respect to identifying the portion of canvas  to be actively displayed on display  may be received by graphical display system  of second electronic device  for updating the visible portion of canvas  on display . For example, when a user identifies zoom point P and an appropriate zoom factor Z on canvas  of screen of , such user interactions may be received by active display adjusting module  of graphical command generating module  of graphical display system  as active display adjustment input information , and active display adjusting module  may generate one or more active display adjustment input commands  representative of these user interactions. These active display adjustment input commands  may be processed by active display defining module  of graphical command processing module  to adjust the portion of pixel array data of canvas  (e.g., combined pixel array data ) that may be actively displayed (e.g., as active pixel array data ) on display .","For example, as shown by screen of , in response to a user interacting with second device  to identify the portion of canvas  to be actively displayed on display  (e.g., zoom point P and zoom factor Z with touch screen I\/O component ), active display adjusting module  may receive certain active display adjustment input information  and may then generate a particular active display adjustment input command  (e.g., an active display adjustment input command with the representative syntax \u201cCOMMAND: CLASS=ACTIVE DISPLAY ADJUSTMENT INPUT; ADJUST=ZOOM; POINT=P; FACTOR=Z\u201d). Such an active display adjustment input command  may then be processed by active display defining module  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display , as shown by screen of . For example, as shown in , a zoomed-in canvas portion of canvas  (e.g., about point P) may be actively displayed by screen of display .","As mentioned, virtual drawing space application  of first electronic device  may be synched with virtual drawing space application  of second electronic device  such that a single work of art (e.g. artwork ) may be presented on both first device  and second device , and such that the single work of art may be collaboratively created and\/or edited through both user interactions with first device  and user interactions with second device . Therefore, continuing with the example of , based on the active display adjustment input information  received by active display adjusting module  of second electronic device , active display adjusting module  may generate an active display adjustment input command  that not only may be received and processed by active display defining module  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display  as canvas portion of screen of display , but that also may be received and processed (i.e., as received outline moving command ) by graphical display system  of first electronic device  to generate at least a portion of new pixel array data that may present a second device outline  at the appropriate position on canvas  of screen of display . Second device outline  may be configured to identify on canvas  of screen the portion of collaborative artwork  on canvas  that is currently actively displayed by canvas portion on screen of display  (i.e., the zoomed-in portion about point P of synched canvases  and ).","For example, active display adjustment input command  may be received as received outline moving command  by outline moving module  of graphical command processing module  of first electronic device . Outline moving module  may be configured to process received outline moving command  and generate a master outline moving command , which may then be provided to pixel array generating module . In some embodiments, master outline moving command  may be the same as received outline moving command  (e.g., when outline moving module  has not also received a generated outline moving command  that has priority over received outline moving command ). When received outline moving command  is passed on to pixel array generating module  (e.g., as a master outline moving command ), pixel array generating module  may process that command in order to generate appropriate generated pixel array data  for defining second device outline  at the appropriate position on canvas . Such generated pixel array data  may be received by pixel array combining module , which may combine generated pixel array data  with any received pixel array data  in order to generate combined pixel array data . Such combined pixel array data , which may include the generated pixel array data  for defining second device outline  at the appropriate position on canvas , may then be processed by active display defining module  for generating active pixel array data  for presentation on display .","In some embodiments, system  may be configured such that when the displayed portion of a synched canvas on one device is adjusted to be different than the displayed portion of the synched canvas on another device, an outline of the adjusted displayed portion may be automatically provided on the non-adjusted canvas (e.g., outline  on canvas ). However in other embodiments, no such outline may be provided. System  may be configured such that a user may selectively determine whether or not such an outline is to be presented.","Due to input synch options  and  being unselected, system  may be configured such that first electronic device  may not adjust the actively displayed portion of canvas  on screen when electronic device  adjusts the actively displayed portion of canvas  on screen . Alternatively, if input synch options  and  are selected (not shown), system  may be configured such that whenever a user interacts with either first device  to adjust the portion of canvas  displayed on display  or second device  to adjust the portion of canvas  displayed on display , the adjustment may be made to both canvas  and canvas .","As mentioned, inter-device submenu  of artist menu  may include an outline lock option , and inter-device submenu  of artist menu  may include an outline lock option , each of which a user may interact with to selectively fix an outline of the device's canvas on another device's canvas (e.g., to fix second device outline  on canvas  of first device ). As shown in , outline lock options  and  are unselected. When outline lock options  and  are unselected, system  may be configured such that the actively displayed portion of canvas  represented by second device outline  on canvas  is not prevented from being adjusted by interaction with first device . That is, when outline lock options  and  are unselected, system  may be configured such that a user may interact with outline  displayed on canvas  of first device  to adjust the actively displayed portion of canvas  displayed on display  of second device .","For example, with continued reference to , although a user of second device  may have interacted with second device  to identify the portion of canvas  to be actively displayed on display  (e.g., zoomed-in canvas portion ), a user may then interact with outline  on canvas  of first device  in order to alter the portion of canvas  to be actively displayed on display . As shown by screen of , for example, a user of first electronic device  may select a point P on canvas  that may include a displayed portion of outline  that the user would like to move to another point on canvas  (e.g., to point P, in the direction of arrow D). A user may interact with first electronic device  in any suitable way (e.g., using input component  and\/or input component ) to identify point P of outline  and to instruct device  to move that point of outline  from point P on canvas  to point P on canvas  in any suitable way. For example, a user may click on that portion of outline  and drag it down in the direction of arrow D to point P (e.g., using mouse input component ). Although not shown, artist menu  may provide a user of first electronic device  with input options for appropriately interacting with device  to easily adjust the portion of canvas  covered by outline  on display .","Any selections or interactions made by the user of first device  for identifying how to adjust outline  with respect to canvas  may be received by graphical display system  of first electronic device  for updating outline  on canvas . For example, when a user identifies initial outline point P and adjusted outline point P on canvas  of screen of , such user interactions may be received by outline selecting module  of graphical command generating module  of graphical display system  as outline selecting input information , and outline selecting module  may generate one or more generated outline moving commands  representative of these user interactions (e.g., one or more generated outline moving input commands with the representative syntax \u201cCOMMAND: CLASS=OUTLINE MOVEMENT INPUT; ADJUST=MOVE; FROMPOINT=P; TOPOINT=P\u201d). These generated outline moving commands  may be processed by outline moving module  of graphical command processing module , which may pass generated outline moving commands  on to pixel array generating module  as master outline moving commands  (e.g., if outline moving module  does not receive any received outline moving commands  of higher priority). Pixel array generating module  may then generate appropriate pixel array data for an updated outline  to be displayed on display . For example, as shown by screen of , in response to a user interacting with first device  to identify how to adjust outline  with respect to canvas  on display , such that appropriate outline selecting input information  may be provided to outline selecting module  for generating the appropriate generated outline moving command , and such that the appropriate master outline moving commands  may then be provided to pixel array generating module  for generating appropriate pixel array data for an updated outline  to be displayed on display , outline  may be moved to a new position on canvas .","As mentioned, virtual drawing space application  of first electronic device  may be synched with virtual drawing space application  of second electronic device  such that a single work of art (e.g. artwork ) may be presented on both first device  and second device , and such that the single work of art may be collaboratively created and\/or edited through both user interactions with first device  and user interactions with second device . Therefore, continuing with the example of , based on the outline selecting input information  received by outline selecting module  of first electronic device , outline selecting module  may also generate one or more shared other device active display adjustment input commands  that may be received and processed (i.e., as received own active display adjustment input command ) by graphical display system  of second electronic device  to adjust the portion of canvas  that may be actively displayed on screen of display . For example, a shared other device active display adjustment input command  may be received as received own active display adjustment input command  by active display defining module  of graphical command processing module  of second electronic device . Active display defining module  may be configured to process received own active display adjustment input command  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display , as shown by screen of . For example, as shown in , an adjusted zoomed-in canvas portion \u2032 of canvas  (e.g., with new point P) may be actively displayed by screen of display . In some embodiments, a shared other device active display adjustment input command  may be similar to an associated generated outline moving input command  that has also been generated by outline selecting module  for particular input information  (e.g., a shared other device active display adjustment input command  may have the representative syntax \u201cCOMMAND: CLASS=OTHER DEVICE ACTIVE DISPLAY ADJUSTMENT INPUT; ADJUST=MOVE; FROMPOINT=P; TOPOINT=P\u201d).","If however, at screen of , outline lock option  and\/or outline lock option  is selected, system  may be configured such that any user interaction with device  to adjust outline  would be disregarded and would not be processed by outline selecting module . For example, if outline lock option  and\/or outline lock option  is selected (e.g., by a user interaction with menu  and\/or menu ), that selection may generate specific input information  that may set an outline lock register  in outline selecting module  that may then prevent outline selecting module  from generating any command  and\/or command  until that register is unset (e.g., until outline lock option  and\/or outline lock option  is unselected).","Alternatively, rather than moving outline  in response to a user interacting with outline  on first device , a user may interact with canvas  on second device  to similarly move outline . For example, as shown in screen of , a user of second device  may interact with canvas  to pan canvas  such that the center of the actively displayed portion of canvas  on second device  may be changed from point P to a new center point P\u2032 (e.g., a user of device  may interact with touch screen  to drag original center point P in the direction of arrow D to new center point P\u2032). Any selections or interactions made by the user of second device  with respect to identifying the portion of canvas  to be actively displayed on display  may be received by graphical display system  of second electronic device  for updating the visible portion of canvas  on display .","For example, when a user identifies original center point P and a new center point P\u2032 on canvas  of screen of , such user interactions may be received by active display adjusting module  of graphical command generating module  of graphical display system  as active display adjustment input information , and active display adjusting module  may then generate one or more active display adjustment input commands  responsive to that active display adjustment input information . For example, as shown by screen of , in response to a user interacting with second device  to identify the new portion of canvas  to be actively displayed on display  (e.g., original center point P and a new center point P\u2032 in the direction of arrow D with touch screen I\/O component ), active display adjusting module  may receive certain active display adjustment input information  and may then generate a particular active display adjustment input command  (e.g., an active display adjustment input command with the representative syntax \u201cCOMMAND: CLASS=ACTIVE DISPLAY ADJUSTMENT INPUT; ADJUST=PAN; STARTPOINT=P; ENDPOINT=P\u2032\u201d). Such an active display adjustment input command  may then be processed by active display defining module  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display , as shown by screen of . For example, as shown in , a panned canvas portion \u2032 of canvas  (e.g., about new center point P\u2032) may be actively displayed by screen of display .","Moreover, rather than a user interacting with second device  to define a portion of canvas  to be actively displayed (e.g., by defining an outline O or a center point P and a zoom factor Z as described with respect to ), a user may instead interact with first device  to initially define a portion of canvas  to be actively displayed by second device . A user may interact with first electronic device  in any suitable way (e.g., using input component  and\/or input component ) to identify a portion of artwork  on canvas  to be made the actively displayed portion of canvas  on second device  and, thus, the portion of canvas  indicated by outline . For example, as shown in , a user of first device  may interact with first device  to define an outline O\u2032 on screen of  and to instruct device  share a command with device  to make the portion of artwork  within outline O\u2032 on canvas  the portion of canvas  actively displayed by device . Such a shared command may be similar to shared other device active display adjustment input command . For example, a user may define outline O\u2032 using mouse input component . Although not shown, artist menu  may provide a user of first electronic device  with input options for appropriately interacting with device  to easily define the portion of artwork  to be actively displayed by device .","Continuing with the example of , based on the panning active display adjustment input information  received by active display adjusting module  of second electronic device , active display adjusting module  may generate an active display adjustment input command  that not only may be received and processed by active display defining module  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display  as panned canvas portion \u2032 of screen of display , but that also may be received and processed (i.e., as received outline moving command ) by graphical display system  of first electronic device  to generate at least a portion of new pixel array data that may present an adjusted second device outline  at the appropriate adjusted position on canvas  of screen of display . Second device outline  may be configured to identify on canvas  of screen the portion of collaborative artwork  on canvas  that is currently actively displayed by canvas portion \u2032 on screen of display  (i.e., the panned portion about point P\u2032 of synched canvases  and ).","In some embodiments, rather than sharing artwork  with application  of second device  before creating any graphical content in artwork , a user may first interact with first device  to generate one or more graphical objects in artwork . Then, once certain content has been created in artwork  on canvas , a user of first device may share artwork  with application  of second device  such that both devices may proceed with collaborating on artwork . In some embodiments, a user of first device  may select only a portion of artwork  to be initially displayed by application  on display . For example, as mentioned, a user may interact with first device  to define outline  for indicating which portion of artwork  and canvas  is to be actively displayed by application  on display . When artwork  is initially being shared with application , a user of first device  may define outline  such that only the portion of artwork  within outline  may be initially shared with application  of second device . This may reduce the amount of information that may have to be communicated to second device  for defining the portion of artwork  to be initially displayed by device . For example, when artwork  is initially shared with second device  only after a user has interacted with first device  to define outline , application  may be configured to only share the portion of artwork  defined by the portion of canvas  within outline . This portion of artwork  may be shared with application  as shared pixel array data containing the graphical content of that portion and\/or as one or more shared input commands defining the graphical content of that portion.","As shown by screen of , for example, a user of first electronic device  may select drawing stroke input option  of submenu  of artist menu  for creating a new free-form drawing stroke on canvas  (e.g., selection of option  may be shown by shading indicia within option  on , although selection of any option may be made apparent in any other suitable way, including non-visual ways). As described above with respect to , when a user selects drawing stroke input option , various options (not shown) may be made available to the user with respect to one or more of submenu options , , and  of graphical object property selection submenu , such that a user may select one or more drawing stroke properties that may at least partially define a drawing stroke graphical object to be created on canvas . For example, drawing stroke graphical object style input option  of property selection submenu  may allow the user to select a drawing stroke input tool from a group of various pre-defined drawing stroke input tools or stamps (e.g., a \u201ccircular pen\u201d drawing stroke input tool, as shown in ), drawing stroke graphical object color input option  of property selection submenu  may allow the user to select a color from a group of various pre-defined drawing stroke colors (e.g., a color represented by \u201c\/\/\/\u201d markings, as shown in ), and drawing stroke graphical object effect input option  of property selection submenu  may allow the user to select one or more effects to be applied to the drawing stroke from a group of various pre-defined drawing stroke effects (e.g., no effects, as shown in ). It is to be understood that additional or alternative pre-defined drawing stroke input tools of various other pre-defined shapes, colors, effects, and other various pre-defined drawing stroke graphical object properties may also be provided by submenu  of menu  when drawing stroke input option  of submenu  is selected.","Any selections made by the user with respect to the options provided by menu  may be received by graphical display system  of first electronic device  for generating and displaying drawing stroke graphical object content on canvas . For example, selections made by the user with respect to the options provided by menu  may be received by graphical input command generating module  of graphical input command generating module  of graphical display system  as menu graphical input information . In some embodiments, a user may interact with menu  to provide selections using any suitable pointing input component of first electronic device  (e.g., mouse input component  of ). For example, a user may interact with mouse input component  to point and click a cursor (not shown) at any suitable portions of screen of display  that may be presenting the appropriate selectable options of menu . It is to be understood, however, that any suitable pointing input component may be used by a user to point to or otherwise identify a particular menu option provided by menu  and any suitable input gesture of that pointing input component or another input component may be used to interact with that particular menu option in any particular way.","When a user selects options , , , and  of menu  for creating a new drawing stroke graphical object in artwork  with a circular pen drawing stroke input tool of a particular color and no effects, for example, the selections may be received by graphical input command generating module  of graphical display system  as menu graphical input information , and graphical input command generating module  may generate one or more appropriate generated menu graphical input commands  representative of these menu selections. These menu input commands  may be processed by array generating module  of graphical command processing module  to generate at least a portion of generated pixel array data  with pixel data that may represent these menu selections. Such menu selection pixel data  may be presented on display  in menu , for example, after first being combined with any received pixel array data  by pixel array combining module  as combined pixel array data , and then provided by active display defining module  as at least a portion of active pixel array data .","For example, as shown by screen of , in response to a user selecting drawing stroke input option  (e.g., with mouse input component ), graphical input command generating module  may receive certain menu graphical input information  and then generate a particular menu generated graphical input command  (e.g., a menu generated graphical input command with the representative syntax \u201cCOMMAND: CLASS=MENU INPUT; SELECT=MENU OPTION \u201d), which may be processed by modules of graphical command processing module  to generate at least a portion of active pixel array data  with updated menu pixel data that may present shading indicia at the portion of screen identifying input option  in menu  of display . Similarly, as shown by screen of , in response to a user selecting a circular pen drawing stroke graphical object style input option , graphical display system  may generate and present a rigid circle within the box identifying input option  in menu  of display . Moreover, as shown by screen of , in response to a user selecting a particular color with input option  and no effect with input option , graphical display system  may generate and present a representation of that color (e.g., \u201c\/\/\/\u201d) within the box identifying input option  in menu  of display  and a representation of no effect (e.g., \u201cnone\u201d) within the box identifying input option  in menu  of display .","As also shown in , menu generated graphical input command  may also be provided to graphical command sharing module , which may be configured to pass certain generated graphical input commands  on to communications circuitry  of first device  as shared graphical input commands . Such shared graphical input commands  may be received by graphical display system  of second device  as received graphical input commands . Therefore, in some embodiments, particular menu generated graphical input commands  may be provided by graphical command sharing module  to graphical display system  of second device  such that similar changes may be made to menu  of screen of . However, as shown in , because input synchs  and  of menus  and  are not selected, system  may be configured such that the current active user interface selections of first electronic device  are not synchronized with the current active user interface selections of second electronic device . Such non-synchronization may allow for the current active graphical object type selection(s) of submenu  and\/or the current active graphical object property selection(s) of submenu  of first device  to differ from the current active graphical object type selection(s) of submenu  and\/or the current active graphical object property selection(s) of submenu  of second device .","For example, as shown in , graphical command sharing module  may include an input synch register . In some embodiments, if input synch option  is selected (e.g., by a user interaction with menu ) (not shown), that selection may generate specific input information  that may generate one or more menu generated graphical input commands , which may set input synch register  in graphical command sharing module . When input synch register  is set, then graphical command sharing module  may be configured to pass certain menu generated graphical input commands  on to graphical display system  of second device  such that similar changes may be made to menu  of screen of  (e.g., for presenting shading indicia at the portion of screen identifying input option  in menu  of display ). However, because input synch option  is not selected on screen , input synch register  may not be set in graphical command sharing module , such that graphical command sharing module  may not pass on menu generated graphical input commands  to device  for updating menu  similarly to menu .","Once options , , , and  of menu  have been selected for creating a drawing stroke graphical object (e.g., with a circular pen drawing stroke input tool of a particular color and no effects), and once the selections have been received by graphical display system  and represented on display  in menu , the user may then interact with graphical display system  for generating one or more new drawing stroke graphical objects in artwork  on canvas  according to the selected options. Based on any appropriate drawing stroke graphical object input information , which may be generated by a user (e.g., using input component  and\/or input component ) and\/or any application running on device  (e.g., application ), graphical input command generating module  may be configured to define and generate at least one new drawing stroke graphical object input command . This new drawing stroke graphical object input command  may then be processed by pixel array generating module , and eventually by active display generating module  as new active drawing stroke graphical object pixel array data  for presentation on display .","For example, as also shown by screen of , a user may interact with graphical display system  to generate a new drawing stroke graphical object  in artwork  on canvas . As shown, drawing stroke graphical object  may include a straight vertical line extending along a trail path from a starting point P on canvas  to an ending point P on canvas  with the selected drawing stroke properties of options , , and . For example, in response to a user defining a trail path for a new drawing stroke graphical object (e.g., by dragging a cursor along canvas  from point P to point P with mouse input component ), graphical input command generating module  may receive certain drawing stroke input information  and then generate a particular drawing stroke input command . For example, based on the selected properties of options , , and , and the trail path defined by points P and P, graphical command generating module  may generate a new drawing stroke graphical object input command , which may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=CIRCULAR PEN; COLOR=\/\/\/; EFFECT=NONE; START:P; END:P\u201d. The new drawing stroke input command  generated by graphical command generating module  may then be processed by graphical command processing module  (e.g., modules , , and\/or ) to generate at least a portion of new drawing stroke pixel array data  that may present new drawing stroke graphical object  at the appropriate position on canvas  of screen of display . It is to be understood that the above representative syntax of new drawing stroke input command  for generating new drawing stroke graphical object  is merely representative, and that any suitable syntax may be used by application  of first electronic device  for generating a new drawing stroke input command  in response to received drawing stroke input information .","Although only starting point P and ending point P of the trail of new drawing stroke graphical object  may be defined by the exemplary representative syntax of new drawing stroke input command , it is to be understood that, in other embodiments, multiple additional points of the path may be defined by the new drawing stroke input information . For example, if the new drawing stroke is a straight line (e.g., as is shown in  by the straight vertical line of drawing stroke graphical object  between starting point P and ending point P), graphical command generating module  may only define a new drawing stroke input command  with a starting point and an ending point in order for the new drawing stroke input command  to adequately instruct graphical command processing module  to generate the appropriate path of the new drawing stroke graphical object on canvas . However, if the new drawing stroke is not a straight line (e.g., a drawing stroke that follows a curved or otherwise non-linear path), graphical command generating module  may define a new drawing stroke input command  with multiple additional points along the path between the starting point and the ending point in order for the new drawing stroke input command  to adequately instruct graphical command processing module  to generate the appropriate path of the new drawing stroke graphical object on canvas .","In some embodiments, rather than generating a single new drawing stroke input command  for a new drawing stroke graphical object to be generated on canvas , graphical command generating module  may generate multiple new drawing stroke input commands , each of which may adequately instruct graphical command processing module  to generate a particular portion of the new drawing stroke graphical object on canvas . For example, as shown in , the trail path of drawing stroke graphical object  may be defined by starting point P, ending point P, and an intermediate point P, such that graphical command generating module  may generate two drawing stroke graphical object input commands . The first of such two drawing stroke graphical object input commands  for defining drawing stroke graphical object  may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=CIRCULAR PEN; COLOR=\/\/\/; EFFECT=NONE; START:P; END:P\u201d, while the second of such two drawing stroke graphical object input commands  for defining drawing stroke graphical object  may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=CIRCULAR PEN; COLOR=\/\/\/; EFFECT=NONE; START:P; END:P\u201d. Each one of these two drawing stroke input commands  generated by graphical command generating module  may be processed by graphical command processing module  to generate at least a portion of new drawing stroke pixel array data  that may present new drawing stroke graphical object  at the appropriate position on canvas  of screen of display .","As mentioned, virtual drawing space application  of first electronic device  may be synched with virtual drawing space application  of second electronic device  such that a single work of art (e.g. artwork ) may be presented on both first device  and second device , and such that the single work of art may be collaboratively created and\/or edited through both user interactions with first device  and user interactions with second device . Therefore, at least some graphical object input commands  generated by graphical command generating module  may be provided to communications circuitry  of first electronic device  as shared graphical object input commands . Continuing with the example of , based on the selected properties of options , , and , and points P and P of the trail path defined by input information  received by first electronic device , graphical command generating module  may generate at least one new drawing stroke graphical object input command  that not only may be received and processed by pixel array generating module  to generate at least a portion of new drawing stroke pixel array data  that may present new drawing stroke graphical object  at the appropriate position on canvas  of screen of display , but that also may be received and processed by graphical command sharing module . Graphical command sharing module  may pass on new drawing stroke graphical object input command  as shared new drawing stroke graphical object input command  to communications circuitry , which may provide shared new drawing stroke graphical object input command  to graphical display system  of second device  (e.g., as received new drawing stroke graphical object input command ) to generate at least a portion of new drawing stroke pixel array data  that may present a new drawing stroke graphical object  at the appropriate position on canvas  of screen of display .","Such a received new drawing stroke graphical object input command  may be received by pixel array requesting module  of graphical display system  of second device . For example, pixel array requesting module  may process a received new drawing stroke graphical object input command  and may pass that received new drawing stroke graphical object input command  on to pixel array generating module , such that at least a portion of new drawing stroke pixel array data  may be generated to present at least a portion of a new drawing stroke graphical object  at the appropriate position on canvas  of screen of display . As shown in , because only a zoomed-in portion \u2032 of canvas  may be presented on screen , only a portion of new drawing stroke graphical object  on canvas  of screen may be displayed on screen as new drawing stroke graphical object . For example, although the entirety of the new drawing stroke graphical object input command  may be processed by pixel array generating module  to generate generated pixel array data  that may be presented on canvas  as the entirety of new drawing stroke graphical object , active display defining module  may only pass a portion of that pixel array data on as active pixel array data  to be displayed on screen of .","In other embodiments, rather than passing each new received drawing stroke graphical object input command  defining portions of the new drawing stroke graphical object  on to pixel array generating module  for processing as pixel array data, pixel array requesting module  may determine that only certain new received drawing stroke graphical object input commands  should be passed on to pixel array generating module  for processing as pixel array data. For example, pixel array requesting module  may also be configured to receive active display adjustment pixel array data request information  from active display defining module . This active display adjustment pixel array data request information  may be indicative of the portion of canvas  that is currently actively displayed on display  (e.g., zoomed-in portion \u2032). Therefore, in some embodiments, pixel array requesting module  may determine that only the new received drawing stroke graphical object input commands  that may be processed to update currently actively displayed canvas portion \u2032 may be passed on to pixel array generating module  for processing as pixel array data . This may save some processing power or other resources of second device .","For example, following the above example where graphical command generating module  may generate two drawing stroke graphical object input commands  for new drawing stroke graphical object , each of those commands  may be received by pixel array requesting module  as one of two received drawing stroke graphical object input commands  for defining a portion of new drawing stroke graphical object  on canvas . The first of such two received drawing stroke graphical object input commands  for defining drawing stroke graphical object  may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=CIRCULAR PEN; COLOR=\/\/\/; EFFECT=NONE; START:P; END:P\u201d, while the second of such two received drawing stroke graphical object input commands  for defining drawing stroke graphical object  may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=CIRCULAR PEN; COLOR=\/\/\/; EFFECT=NONE; START:P; END:P\u201d. When the first of these two received drawing stroke graphical object input commands  is received by pixel array requesting module , pixel array requesting module  may determine that the portion of new drawing stroke graphical object  defined by that first received drawing stroke graphical object input command  would be positioned in the currently actively displayed canvas portion \u2032 of canvas . That is, by determining that both start point P and end point P defined by the first of these two received drawing stroke graphical object input commands  fall within currently actively displayed canvas portion \u2032 of canvas  (e.g., by analyzing active display adjustment pixel array data request information ), pixel array requesting module  may be configured to pass that first of the two received drawing stroke graphical object input commands  on to pixel array generating module  for processing as pixel array data.","However, when the second of these two received drawing stroke graphical object input commands  is received by pixel array requesting module , pixel array requesting module  may determine that the portion of new drawing stroke graphical object  defined by that second received drawing stroke graphical object input command  would not be positioned in the currently actively displayed canvas portion \u2032 of canvas . That is, by determining that the portion of canvas  between start point P and end point P defined by the second of these two received drawing stroke graphical object input commands  does not fall within currently actively displayed canvas portion \u2032 of canvas  (e.g., by analyzing active display adjustment pixel array data request information ), pixel array requesting module  may be configured to not pass that second of the two received drawing stroke graphical object input commands  on to pixel array generating module  for processing as pixel array data. This may save some processing power or other resources of second device . In some embodiments, pixel array requesting module  may only be configured to selectively pass certain received graphical object input commands  on to pixel array generating module  when a certain operating condition of device  is met (e.g., the battery of second device  is below a certain threshold). In some embodiments, pixel array requesting module  may be configured to store or otherwise make accessible to system  any received graphical object input commands  that are not immediately passed on by module  to module . Instead, such commands may be later accessed by module  for updating a portion of canvas  when that portion is made an actively displayed portion of canvas  on display .","Alternatively, as mentioned, at least some new drawing stroke graphical object pixel array data generated by graphical display system  may be provided to communications circuitry  of first electronic device  as shared drawing stroke graphical object pixel array data. Communications circuitry  may then provide the shared drawing stroke graphical object pixel array data to communications circuitry  of second electronic device  via communications media , and communications circuitry  may provide the shared drawing stroke graphical object pixel array data as received drawing stroke graphical object pixel array data to graphical display system  for presentation on display .","For example, in some embodiments, despite utilizing common semantics in response to particular input commands, first electronic device  and second electronic device  may have different resources or capabilities and may sometimes rather share pixel array data instead of or in addition to sharing input commands. For example, upon receiving a received drawing stroke graphical object input command , pixel array requesting module  of graphical display system  may determine that second electronic device  does not currently have enough processing power or capabilities for enabling pixel array generating module  to generate new drawing stroke pixel array data from the received drawing stroke graphical object input command  (e.g., graphical display system  may determine that second device  is trying to conserve its power supply  or is otherwise unable to generate pixel array data based on the received input command). In some embodiments, in response to such a determination, rather than passing received drawing stroke graphical object input command  on to pixel array generating module , pixel array requesting module  may instead send a command to graphical display system  of first device  instructing graphical display system  to transmit new drawing stroke pixel array data (e.g., as shared drawing stroke pixel array data) to graphical display system  (e.g., as received drawing stroke pixel array data), such that graphical display system  may avoid having to independently process a received drawing stroke graphical object input command  for adding new drawing stroke graphical object  on canvas .","For example, in response to determining that system  would rather receive corresponding pixel array data from device  than generate its own pixel array data from received drawing stroke graphical object input command , pixel array requesting module  may generate a shared pixel array data request command . In some embodiments, shared pixel array data request command  may request the pixel array data for the entirety of canvas . In other embodiments, shared pixel array data request command  may request the pixel array data for the portion of canvas  associated with the currently active display portion of canvas  (e.g., zoomed-in canvas portion \u2032), which may be determined by pixel array requesting module  based on active display adjustment pixel array data request information . In yet other embodiments, shared pixel array data request command  may request only the pixel array data that was updated based on the shared graphical object input command.","In response to receiving received drawing stroke graphical object input command , and in response to determining that system  would rather receive corresponding pixel array data from device  than generate its own pixel array data from received drawing stroke graphical object input command , pixel array requesting module  may generate a shared pixel array data request command  that may request only the pixel array data that updated canvas  based on the drawing stroke graphical object input command  that was also provided to system  as received drawing stroke graphical object input command . For example, such a shared pixel array data request command  may request only the pixel array data that was generated to update screen of  to screen of .","For example, in response to receiving received drawing stroke graphical object input command  that may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=CIRCULAR PEN; COLOR=\/\/\/; EFFECT=NONE; START:P; END:P\u201d, pixel array requesting module  may generate a shared pixel array data request command  that may have the following representative syntax: \u201cCOMMAND: CLASS=PIXEL ARRAY DATA REQUEST; TYPE=DRAWING STROKE; STYLE=CIRCULAR PEN; COLOR=\/\/\/; EFFECT=NONE; START:P; END:P\u201d. This shared pixel array data request command  may be provided by pixel array requesting module  to communications circuitry  of second device , which may then provide the shared pixel array data request command to communications circuitry  of first device  via communications media , and communications circuitry  may provide the shared pixel array data request command as received pixel array data request command  to graphical display system .","Received pixel array data request command  may be received by graphical display system  at pixel array sharing module , which may be configured to acquire the portion of pixel array data  requested by received command . For example, pixel array sharing module  may be configured to receive both combined pixel array data  from pixel array combining module  and received pixel array data request command  from communications circuitry , and then to generate shared pixel array data . Following the example in which shared pixel array data request command  may request only the pixel array data that was generated to update screen of  to screen of , shared pixel array data  may be the portion of combined pixel array data  that was provided to pixel array combining module  by pixel array generating module  as new drawing stroke graphical object generated pixel array data , which may have been generated by pixel array generating module  in response to processing a new drawing stroke graphical object input command  defining new drawing stroke graphical object .","Such shared pixel array data  may be provided by pixel array sharing module  to communications circuitry  of first device , which may then provide the shared pixel array data to communications circuitry  of second device  via communications media , and communications circuitry  may provide the shared pixel array data as received pixel array data  to graphical display system . Received pixel array data  may be provided to pixel array combining module  of graphical display system . Pixel array combining module  may be configured to combine any pixel array data  generated internally by pixel array generating module  of graphical display system  with any received pixel array data  received from any external entity (e.g., graphical display system  of first device ) in order to generate combined pixel array data . This combined pixel array data  may then be received by active display defining module , and active display defining module  may pass at least a portion of combined pixel array data  on to display  as active pixel array data .","Following the example in which received pixel array data  is the pixel array data for updating canvas  with drawing stroke graphical object , pixel array combining module  may combine this data with the other pixel array data defining canvas  (e.g., the pixel array data defining graphical objects , , , , and ) and may generate combined pixel array data . Next active display defining module  may only pass the portion of this combined pixel array data  defining the portion of canvas  currently actively displayed on display  (e.g., zoomed-in canvas portion \u2032) on to display  as active pixel array data . An example of such active pixel array data  may be displayed by screen of .","Although not shown, in some embodiments, a user's interaction with first device  for generating a new graphical object on canvas  may adjust the actively displayed portion of canvas  on second device . For example, as a user of first device  generates input information  for defining the trail path of drawing stroke graphical object  between points P and P on canvas  (e.g., by dragging a cursor of mouse input component  along canvas ), when the user's interaction extends beyond point P towards P such that the trail path extends beyond outline , system  may be configured to automatically move outline  with the trail path. This may allow for the new graphical object being created to be shown by the actively displayed portion of canvas  on second device  (e.g., as opposed to the example of , in which only a portion of new drawing stroke graphical object  may be presented in actively displayed portion \u2032 of canvas  on screen ). However, in other embodiments, outline  may only be moved along canvas  in response to a user of first device  directly interacting with outline  (e.g., as described above with respect to ). For example, a user of system  may interact with outline lock  and\/or outline lock  to adjust the ways in which outline  may be moved or otherwise adjusted.","As mentioned, (e.g., with respect to ), a user may interact with second device  to generate input information for changing the portion of canvas  that may be displayed on display . As shown by screen of , for example, a user of second electronic device  may provide a multi-touch \u201cpinch\u201d user input gesture on touch screen  by imparting a first touch event or gesture from point P to point P in the direction of arrow g on canvas , while also imparting a second touch event or gesture from point P to point P in the direction of arrow g on canvas , which may change the distance between the set points on display  (e.g., the displayed distance between canvas points P and P as shown on screen may be pinched or reduced to the distance between canvas points P and P as shown on screen ). Any selections or interactions made by the user with respect to identifying the portion of canvas  to be actively displayed on display  may be received by graphical display system  of second electronic device  for updating the visible portion of canvas  on display . For example, when a user identifies points P-P on canvas  of screen of  in a pinch gesture, such user interactions may be received by active display adjusting module  of graphical command generating module  of graphical display system  as active display adjustment input information , and active display adjusting module  may generate one or more active display adjustment input commands  representative of these user interactions. These active display adjustment input commands  may be processed by active display defining module  of graphical command processing module  to adjust the portion of pixel array data of canvas  (e.g., combined pixel array data ) that may be actively displayed (e.g., as active pixel array data ) on display .","For example, as shown by screen of , in response to a user interacting with second device  to identify the adjusted portion of canvas  to be actively displayed on display  (e.g., pinch gesture points P-P with touch screen I\/O component ), active display adjusting module  may receive certain active display adjustment input information  and may then generate a particular active display adjustment input command  (e.g., an active display adjustment input command with the representative syntax \u201cCOMMAND: CLASS=ACTIVE DISPLAY ADJUSTMENT INPUT; ADJUST=PINCH; STARTPOINT=P; ENDPOINT=P; STARTPOINT=P; ENDPOINT=P\u201d). Such an active display adjustment input command  may then be processed by active display defining module  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display , as shown by screen of . For example, as shown in , a pinched canvas portion \u2033 of canvas  may be actively displayed by screen of display . Such a pinch gesture user input may expand the portion of canvas  actively displayed by second device .","Continuing with the example of , based on the active display adjustment input information  received by active display adjusting module  of second electronic device , active display adjusting module  may generate an active display adjustment input command  that not only may be received and processed by active display defining module  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display  as pinched canvas portion \u2033 of screen of display , but that also may be received and processed (i.e., as received outline moving command ) by graphical display system  of first electronic device  to generate at least a portion of new pixel array data that may present an adjusted second device outline  at the appropriate position on canvas  of screen of display . Adjusted second device outline  may be configured to identify on canvas  of screen the portion of collaborative artwork  on canvas  that is currently actively displayed by pinched canvas portion \u2033 on screen of display  (i.e., the pinched portion from points P\/P to points P\/P of synched canvases  and ).","Alternatively, rather than expanding the portion of canvas  actively displayed by second device  by interacting with second device , a user may alternatively interact with outline  on canvas  of first device  in order to alter the size of the portion of canvas  to be actively displayed on display . As shown by screen of , for example, a user of first electronic device  may select a point P on canvas  that may include a displayed portion of outline  that the user would like to expand to another point on canvas  (e.g., to point P\u2032, in the direction of arrow E). A user may interact with first electronic device  in any suitable way (e.g., using input component  and\/or input component ) to identify point P of outline  and to instruct device  to expand that point of outline  from point P on canvas  to point P\u2032 on canvas  in any suitable way. For example, a user may click on that portion of outline  and drag it in the direction of arrow E to point P\u2032 (e.g., using mouse input component ). Although not shown, artist menu  may provide a user of first electronic device  with input options for appropriately interacting with device  to easily adjust the portion of canvas  covered by outline  on display .","Any selections or interactions made by the user of first device  for identifying how to adjust outline  with respect to canvas  may be received by graphical display system  of first electronic device  for updating outline  on canvas . For example, when a user identifies initial outline point P and expanded outline point P\u2032 on canvas  of screen of , such user interactions may be received by outline selecting module  of graphical command generating module  of graphical display system  as outline selecting input information , and outline selecting module  may generate one or more generated outline moving commands  representative of these user interactions (e.g., one or more generated outline moving input commands with the representative syntax \u201cCOMMAND: CLASS=OUTLINE MOVEMENT INPUT; ADJUST=EXPAND; FROMPOINT=P; TOPOINT=P\u2032\u201d). These generated outline moving commands  may be processed by outline moving module  of graphical command processing module , which may pass generated outline moving commands  on to pixel array generating module  as master outline moving commands  (e.g., if outline moving module  does not receive any received outline moving commands  of higher priority). Pixel array generating module  may then generate appropriate pixel array data for an updated outline  to be displayed on display . For example, as shown by screen of , in response to a user interacting with first device  to identify how to adjust outline  with respect to canvas  on display , such that appropriate outline selecting input information  may be provided to outline selecting module  for generating the appropriate generated outline moving command , and such that the appropriate master outline moving commands  may then be provided to pixel array generating module  for generating appropriate pixel array data for an updated outline  to be displayed on display , outline  may be moved to a new position on canvas .","Continuing with this example, based on the outline selecting input information  received by outline selecting module  of first electronic device , outline selecting module  may also generate one or more shared other device active display adjustment input commands  that may be received and processed (i.e., as received own active display adjustment input command ) by graphical display system  of second electronic device  to adjust the portion of canvas  that may be actively displayed on screen of display . For example, a shared other device active display adjustment input command  may be received as received own active display adjustment input command  by active display defining module  of graphical command processing module  of second electronic device . Active display defining module  may be configured to process received own active display adjustment input command  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display , as shown by screen of . For example, as shown in , an adjusted zoomed-in canvas portion \u2033 of canvas  (e.g., with new point P\u2032) may be actively displayed by screen of display . In some embodiments, a shared other device active display adjustment input command  may be similar to an associated generated outline moving input command  that has also been generated by outline selecting module  for particular input information  (e.g., a shared other device active display adjustment input command  may have the representative syntax \u201cCOMMAND: CLASS=OTHER DEVICE ACTIVE DISPLAY ADJUSTMENT INPUT; ADJUST=EXPAND; FROMPOINT=P; TOPOINT=P\u2032\u201d).","When the active display of second device  is adjusted, whether in response to an active display adjustment command  generated by second device  or in response to an active display adjustment command  received from first device , second device  may be configured to access one or more input commands or one or more portions of pixel array data (e.g., from first device  or from memory  of second device ) to update the new portion of canvas  displayed by the adjusted active display. For example, as mentioned above, pixel array requesting module  may be configured to only pass received graphical object input commands  that may be processed to update the currently actively displayed portion of canvas portion . Therefore, when the currently actively displayed portion of canvas portion  is adjusted, canvas  may not include all of the graphical content of canvas .","Module  may be configured only to pass on a particular received command  to pixel array generating module  for processing as pixel array data  when that command may be processed to update the currently actively displayed portion of canvas portion . In some embodiments, graphical display system  may be configured to store (e.g., in memory  of device ) or otherwise have access to (e.g., from first device ) any received graphical object input commands  or to only those received graphical object input commands  that have not already been passed on to module  for processing. For example, in response to any active display adjustment command  or any active display adjustment command  received by module  that defines a new actively displayed portion of canvas , module  may provide request information  to module . Such request information  may instruct module  to access and pass on to pixel array generating module  any previously received input commands  that may be processed to update the new actively displayed portion of canvas portion . Such previously received commands  may be stored in memory  of device  and accessed by module , or stored by device  and provided to device  when requested.","Following the above example, the second of two received drawing stroke graphical object input commands  for defining drawing stroke graphical object  may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=CIRCULAR PEN; COLOR=\/\/\/; EFFECT=NONE; START:P; END:P\u201d and may not have been passed on by module  to module  when portion \u2032 of canvas  was actively displayed on display . However, when the actively displayed portion of canvas  is adjusted to be portion \u2033 of , module  may access and pass that second of two received drawing stroke graphical object input commands  on to module  for generating at least a portion of object  on a portion of canvas  that is included in canvas portion \u2033 but not canvas portion \u2032 (e.g., a portion of object  between point P and point P). By only processing the input commands necessary to generate the graphical content of canvas  that is currently actively displayed, second device  may preserve certain resources (e.g., processing resources or power resources). In some embodiments, pixel array requesting module  may only be configured to selectively pass certain received graphical object input commands  on to pixel array generating module  when a certain operating condition of device  is met (e.g., the battery of second device  is below a certain threshold).","Alternatively, when a new portion of canvas  is included as an actively displayed portion of canvas  on display , second device  may rather receive shared pixel array data for updating that portion of canvas  instead of or in addition to processing received input commands. For example, upon receiving information  indicative of a new actively displayed portion of canvas  on display , pixel array requesting module  may determine that second electronic device  does not currently have enough processing power or capabilities for enabling pixel array generating module  to process accessible input commands  for properly updating the new actively displayed portion of canvas  (e.g., graphical display system  may determine that second device  is trying to conserve its power supply  or is otherwise unable to process or access such input commands). In some embodiments, in response to such a determination, pixel array requesting module  may instead send a command to graphical display system  of first device  instructing graphical display system  to transmit new pixel array data (e.g., as shared pixel array data) to graphical display system  (e.g., as received pixel array data) that may be the pixel array data of the new actively displayed portion of canvas .","For example, in response to determining that system  would rather receive corresponding pixel array data from device  than generate its own pixel array data from received graphical object input commands in order to ensure that the current actively displayed portion of canvas  is synched or otherwise similar to canvas , pixel array requesting module  may generate a shared pixel array data request command . Such a shared pixel array data request command  request the pixel array data for the portion of canvas  associated with the new portion of canvas  that is actively displayed (e.g., the portion of canvas \u2033 of  that is not a portion of canvas \u2032 of , which may be determined by pixel array requesting module  based on active display adjustment pixel array data request information . In yet other embodiments, shared pixel array data request command  may request only the pixel array data of the new canvas portion that has been updated by input commands since that canvas portion was last displayed by display .","This shared pixel array data request command  may be provided by pixel array requesting module  to communications circuitry  of second device , which may then provide the shared pixel array data request command to communications circuitry  of first device  via communications media , and communications circuitry  may provide the shared pixel array data request command as received pixel array data request command  to graphical display system . Received pixel array data request command  may be received by graphical display system  at pixel array sharing module , which may be configured to acquire the portion of pixel array data  requested by received command  and then to generate shared pixel array data . Such shared pixel array data  may be provided as received pixel array data  to graphical display system , and received pixel array data  may be provided to pixel array combining module  of graphical display system  as at least a portion of the appropriate pixel array data for the newly displayed portion of canvas  on display .","As another example, a user may interact with second device  to generate input information for pulling rather than pinching canvas  to change the portion of canvas  that may be displayed on display . As shown by screen of , for example, a user of second electronic device  may provide a multi-touch \u201cpull\u201d user input gesture on touch screen  by imparting a first touch event or gesture from point P to point P in the opposite direction of arrow g on canvas , while also imparting a second touch event or gesture from point P to point P in the opposite direction of arrow g on canvas , which may change the distance between the set points on display  (e.g., the displayed distance between canvas points P and P as shown on screen may be pulled or expanded to the distance between canvas points P and P as shown on screen ). In response to a user interacting with second device  to identify the adjusted portion of canvas  to be actively displayed on display  (e.g., pull gesture points P-P with touch screen I\/O component ), active display adjusting module  may receive certain active display adjustment input information  and may then generate a particular active display adjustment input command  (e.g., an active display adjustment input command with the representative syntax \u201cCOMMAND: CLASS=ACTIVE DISPLAY ADJUSTMENT INPUT; ADJUST=PULL; STARTPOINT=P; ENDPOINT=P; STARTPOINT=P; ENDPOINT=P\u201d). Such an active display adjustment input command  may then be processed by active display defining module  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display , as shown by screen of . For example, as shown in , a pulled canvas portion \u2032 of canvas  may be actively displayed by screen of display . Such a pull gesture user input may expand the portion of canvas  actively displayed by second device .","Continuing with the example of , based on the active display adjustment input information  received by active display adjusting module  of second electronic device , active display adjusting module  may generate an active display adjustment input command  that not only may be received and processed by active display defining module  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display  as pulled canvas portion \u2032 of screen of display , but that also may be received and processed (i.e., as received outline moving command ) by graphical display system  of first electronic device  to generate at least a portion of new pixel array data that may present an adjusted second device outline  at the appropriate position on canvas  of screen of display . Adjusted second device outline  may be configured to identify on canvas  of screen the portion of collaborative artwork  on canvas  that is currently actively displayed by pulled canvas portion \u2032 on screen of display  (i.e., the pulled portion from points P\/P to points P\/P of synched canvases  and ).","As yet another example, a user may interact with second device  to generate input information for rotating rather than pinching or pulling canvas  to change the portion of canvas  that may be displayed on display . As shown by screen of , for example, a user of second electronic device  may provide a multi-touch \u201crotate\u201d user input gesture on touch screen  by imparting a first touch event or gesture from point P to point P in the direction of arrow g on canvas , while also imparting a second touch event or gesture from point P to point P in the direction of arrow g on canvas , which may change the orientation of display  with respect to the segments between the set points. In response to a user interacting with second device  to identify the adjusted portion of canvas  to be actively displayed on display  (e.g., rotate gesture points P, P, P, and P with touch screen I\/O component ), active display adjusting module  may receive certain active display adjustment input information  and may then generate a particular active display adjustment input command  (e.g., an active display adjustment input command with the representative syntax \u201cCOMMAND: CLASS=ACTIVE DISPLAY ADJUSTMENT INPUT; ADJUST=ROTATE; STARTPOINT=P; ENDPOINT=P; STARTPOINT=P; ENDPOINT=P\u201d). Such an active display adjustment input command  may then be processed by active display defining module  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display , as shown by screen of . For example, as shown in , a rotated canvas portion \u2032\u2033 of canvas  may be actively displayed by screen of display . Such a rotate gesture user input may rotate the portion of canvas  actively displayed by second device .","It is to be understood that a user may interact with second device  to rotate the actively displayed portion of canvas  in a counter-clockwise direction, rather than the clockwise direction shown with respect to . It is also to be understood that a rotate gesture user input for changing the portion of canvas  that may be displayed on display  may be achieved in any other suitable way. For example, a user of second device  may rotate device  within the X-Y plane of  in the direction of arrow R (e.g., with respect to first device ), and that movement may be detected by sensor  of second device  and incorporated into active display adjustment input information  that may be received and processed by module .","Continuing with the example of , based on the active display adjustment input information  received by active display adjusting module  of second electronic device , active display adjusting module  may generate an active display adjustment input command  that not only may be received and processed by active display defining module  to adjust the portion of combined pixel array data  of canvas  that may be actively displayed as active pixel array data  on display  as rotated canvas portion \u2032\u2033 of screen of display , but that also may be received and processed (i.e., as received outline moving command ) by graphical display system  of first electronic device  to generate at least a portion of new pixel array data that may present an adjusted second device outline  at the appropriate position on canvas  of screen of display . Adjusted second device outline  may be configured to identify on canvas  of screen the portion of collaborative artwork  on canvas  that is currently actively displayed by rotated canvas portion \u2032\u2033 on screen of display . It is to be understood that any user interaction with first device  to move or otherwise change the size or orientation of outline  on canvas  of display  may alternatively be accomplished through appropriate user interaction with second device  to pan or otherwise change the size or orientation of the actively displayed portion of canvas  on display .","Continuing with the example of , a user of first electronic device  may select input synch option  of menu  and\/or a user of second electronic device  may select input synch option  of menu . When input synch options  and  are selected, system  may be configured such that whenever a user interacts with first device  to adjust a menu selection of menu  or to move a cursor or user position on canvas , the same changes may occur on second device  as if a user had interacted directly with second device , and vice versa. Therefore, as also shown in , because input synch options  and  are selected, a user of first electronic device  and\/or a user of second electronic device  may select drawing stroke input option \/ for creating a new free-form drawing stroke in artwork  on canvases \/. Moreover, when a user selects drawing stroke input option \/, drawing stroke graphical object style input option \/ may allow the user to select a drawing stroke input tool from a group of various pre-defined drawing stroke input tools or stamps (e.g., a \u201cpaint brush\u201d drawing stroke input tool, as shown in ), drawing stroke graphical object color input option \/ may allow the user to select a color from a group of various pre-defined drawing stroke colors (e.g., a solid color represented by \u201c\u25aa\u201d, as shown in ), and drawing stroke graphical object effect input option \/ may allow the user to select one or more effects to be applied to the drawing stroke from a group of various pre-defined drawing stroke effects (e.g., a \u201cshake to splatter\u201d effect, as shown in ). It is to be understood that additional or alternative pre-defined drawing stroke input tools of various other pre-defined shapes, colors, effects, and other various pre-defined drawing stroke graphical object properties may also be provided by submenu \/ of menu \/ when drawing stroke input option \/ is selected.","Any selections made by the user with respect to the options provided by menus \/ may be received by graphical display systems \/ of electronic devices \/ for generating and displaying drawing stroke graphical object content on canvases \/. For example, as shown in , graphical command sharing module  may include an input synch register . When input synch option  is selected (e.g., by a user interaction with menu  of second device ), that selection may generate specific input information  that may generate one or more menu generated graphical input commands , which may set input synch register  in graphical command sharing module . When input synch register  is set, then graphical command sharing module  may be configured to pass certain menu generated graphical input commands  on to graphical display system  of first device  such that similar changes may be made to menu  of screen of  (e.g., for presenting shading indicia at the portion of screen identifying input option  in menu  of display  if a user of second device  initially selects option  in menu ).","Once options \/, \/, \/, and \/ of menus \/ have been selected and synchronized for creating a drawing stroke graphical object (e.g., with a paint brush drawing stroke input tool of a particular color and a \u201cshake to splatter\u201d effect), and once the selections have been received by graphical display systems \/ and represented on displays \/ in menus \/, a user may then interact with either first device  or second device  to generate one or more new drawing stroke graphical objects in artwork  on both of canvases  and  according to the selected options. For example, when a user interacts with second device , based on any appropriate drawing stroke graphical object input information , which may be generated by the user (e.g., using input component  and\/or input component ) and\/or any application running on device  (e.g., application ), graphical input command generating module  may be configured to define and generate at least one new drawing stroke graphical object input command . This new drawing stroke graphical object input command  may then be processed by pixel array generating module , and eventually by active display generating module  as new active drawing stroke graphical object pixel array data  for presentation on display .","For example, as also shown by screen of , a user may interact with graphical display system  to generate a new drawing stroke graphical object  in artwork  on canvas . As shown, drawing stroke graphical object  may include a straight uniform paint brush stroke body portion  extending along a trail path from a starting point P on canvas  to an ending point P on canvas  with the selected drawing stroke properties of options , , and . For example, in response to a user defining a trail path for a new drawing stroke graphical object (e.g., by dragging a finger along canvas  from point P to point P with touch screen input component ), graphical input command generating module  may receive certain drawing stroke input information  and then generate a particular drawing stroke input command . This particular drawing stroke input command  may be received by processing module  of graphical display system  to generate straight uniform paint brush stroke body portion  of new drawing stroke graphical object  on display .","The selected \u201cshake to splatter\u201d input effect may increase the distance that additional drawing stroke graphical object data may be stamped away from body portion  of the stamped trail of the paint brush input tool. For example, as shown in , drawing stroke graphical object  may also include a splatter portion , which may be additional drawing stroke graphical object data representative of paint brush splatter. Splatter portion  may extend a first splatter distance S along and away from a first portion of body portion  (e.g., adjacent point P) and that may extend a second splatter distance S along and away from another portion of body portion  (e.g., adjacent point P). The splatter distance of splatter portion  of drawing stroke graphical object  may be determined by any suitable data accessible to second device  from any suitable source. For example, in some embodiments, the splatter distance of drawing stroke graphical object  may be determined by a detected magnitude of a particular movement of second device  at a particular time (e.g., as a user of device  may define a trail path for new drawing stroke graphical object  by dragging a finger along canvas  from point P to point P with touch screen input component , the user may also define one or more suitable splatter distances by shaking device  (e.g., as may be detected by sensor )).","Based on the selected properties of options , , and , the trail path defined by points P and P, and any received splatter distance data, graphical command generating module  may generate a new drawing stroke graphical object input command , which may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PAINT BRUSH; COLOR=BLACK; START:P; END:P; EFFECT=SHAKE TO SPLATTER; SHAKESTART=S; SHAKEEND=S\u201d. Such a new drawing stroke input command  generated by graphical command generating module  may then be processed by graphical command processing module  (e.g., modules , , and\/or ) to generate at least a portion of new drawing stroke pixel array data  that may present both portions  and  of new drawing stroke graphical object  at the appropriate position on canvas  of screen of display . It is to be understood that the above representative syntax of new drawing stroke input command  for generating new drawing stroke graphical object  is merely representative, and that any suitable syntax may be used by application  of second electronic device  for generating a new drawing stroke input command  in response to received drawing stroke input information . For example, any effect that may be selected by input options \/ for any suitable graphical object may alter that graphical object in any suitable way using any suitable data accessible from any suitable source.","Although only starting point P and ending point P of the trail of new drawing stroke graphical object  may be defined by the exemplary representative syntax of new drawing stroke input command , it is to be understood that, in other embodiments, multiple additional points of the path may be defined by the new drawing stroke input information . For example, if the new drawing stroke is a straight line (e.g., as is shown in  by the straight line of drawing stroke graphical object  between starting point P and ending point P), graphical command generating module  may only define a new drawing stroke input command  with a starting point and an ending point in order for the new drawing stroke input command  to adequately instruct graphical command processing module  to generate the appropriate path of the new drawing stroke graphical object on canvas . However, if the new drawing stroke is not a straight line (e.g., a drawing stroke that follows a curved or otherwise non-linear path), or if any effect determined by input option  is not static along the trail of the drawing stroke, graphical command generating module  may define a new drawing stroke input command  with multiple additional points along the path between the starting point and the ending point in order for the new drawing stroke input command  to adequately instruct graphical command processing module  to generate the appropriate path of the new drawing stroke graphical object with the appropriate effect on canvas .","In some embodiments, rather than generating a single new drawing stroke input command  for a new drawing stroke graphical object to be generated on canvas , graphical command generating module  may generate multiple new drawing stroke input commands , each of which may adequately instruct graphical command processing module  to generate a particular portion of the new drawing stroke graphical object on canvas . For example, as shown in , the trail path of drawing stroke graphical object  may be defined by starting point P, ending point P, and an intermediate point P, such that graphical command generating module  may generate two drawing stroke graphical object input commands . Moreover, as shown in , the splatter distance of drawing stroke graphical object  may extend a first splatter distance S along the portion of the trail between points P and P, and a second splatter distance S along the portion of the trail between points P and P. The first of such two drawing stroke graphical object input commands  for defining drawing stroke graphical object  may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PAINT BRUSH; COLOR=BLACK; START:P; END:P; EFFECT=SHAKE TO SPLATTER; SHAKESTART=S; SHAKEEND=S\u201d, while the second of such two drawing stroke graphical object input commands  for defining drawing stroke graphical object  may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PAINT BRUSH; COLOR=BLACK; START:P; END:P; EFFECT=SHAKE TO SPLATTER; SHAKESTART=S; SHAKEEND=S\u201d. Each one of these two drawing stroke input commands  generated by graphical command generating module  may be processed by graphical command processing module  to generate at least a portion of new drawing stroke pixel array data  that may present new drawing stroke graphical object  at the appropriate position on canvas  of screen of display .","As mentioned, virtual drawing space application  of first electronic device  may be synched with virtual drawing space application  of second electronic device  such that a single work of art (e.g. artwork ) may be presented on both first device  and second device , and such that the single work of art may be collaboratively created and\/or edited through both user interactions with first device  and user interactions with second device . Therefore, at least some graphical object input commands  generated by graphical command generating module  may be provided to communications circuitry  of second electronic device  as shared graphical object input commands . Continuing with the example of , based on the selected properties of options , , and , points P-P of the trail path, and the splatter distance(s) along the trail path defined by input information  received by second electronic device , graphical command generating module  may generate at least two new drawing stroke graphical object input commands  that not only may be received and processed by pixel array generating module  to generate at least a portion of new drawing stroke pixel array data  that may present new drawing stroke graphical object  at the appropriate position on canvas  of screen of display , but that also may be received and processed by graphical command sharing module . Graphical command sharing module  may pass on the new drawing stroke graphical object input commands  as shared new drawing stroke graphical object input commands  to communications circuitry , which may provide shared new drawing stroke graphical object input commands  to graphical display system  of first device  (e.g., as received new drawing stroke graphical object input commands ) to generate new drawing stroke pixel array data  that may present a new drawing stroke graphical object  at the appropriate position on canvas  of screen of display .","Such received new drawing stroke graphical object input commands  may be received by pixel array requesting module  of graphical display system  of first device . For example, pixel array requesting module  may process the received new drawing stroke graphical object input commands  and may pass those received new drawing stroke graphical object input commands  on to pixel array generating module , such that at least a portion of new drawing stroke pixel array data  may be generated to present at least a portion of a new drawing stroke graphical object  at the appropriate position on canvas  of screen of display .","In some embodiments, first electronic device  may not be provided with a sensor  and, therefore, may not be provided with the ability to allow a user to interact with first device  to generate appropriate splatter distance data (e.g., as described above with respect to splatter distances S and S generated by the interaction of a user of second device  with sensor  of second device ). Although such a lack of a sensor  may prevent a user of first electronic device  from generating one or more drawing stroke input commands  similar to drawing stroke commands  described above that may indicate splatter distance data, such a lack of a sensor  may not prevent first electronic device  from receiving and processing such drawing stroke commands  (e.g., as received new drawing stroke graphical object input commands ) that indicate splatter distance data for generating new drawing stroke graphical object  on display .","Alternatively, rather than a user interacting with second device  for generating new drawing stroke input information  to define new drawing stroke graphical object  on canvas  and then sharing graphical input commands with first device  to create new drawing stroke graphical object  on canvas , a user may instead interact with first device  for generating new drawing stroke input information  to define at least a portion of new drawing stroke graphical object  on canvas . For example, even in such embodiments where first electronic device  may not be provided with a sensor  configured to allow a user to interact with first device  to generate appropriate splatter distance data (e.g., as described above with respect to splatter distances S and S generated by the interaction of a user of second device  with sensor  of second device ), a user may interact with first device  to define at least some of the new drawing stroke input information  for defining new drawing stroke graphical object \/ on canvases \/ of artwork .","Once options \/, \/, \/, and \/ of menus \/ have been selected and synchronized for creating a drawing stroke graphical object (e.g., with a paint brush drawing stroke input tool of a particular color and a \u201cshake to splatter\u201d effect), a user may then interact with first device  to define at least a portion of a new drawing stroke graphical object in artwork  according to the selected options. For example, when a user interacts with first device , based on any appropriate drawing stroke graphical object input information , which may be generated by the user (e.g., using input component  and\/or input component ) and\/or any application running on device  (e.g., application ), graphical input command generating module  may be configured to define and generate at least one new drawing stroke graphical object input command . This new drawing stroke graphical object input command  may then be processed by pixel array generating module , and eventually by active display generating module  as new active drawing stroke graphical object pixel array data  for presentation on display .","For example, a user may interact with graphical display system  to generate a portion of new drawing stroke graphical object  in artwork  on canvas  (e.g., the portion of new drawing stroke graphical object  that may be independent from the portion defined by splatter distance data). As shown in , for example, drawing stroke graphical object  may include a straight uniform paint brush stroke body portion  extending along a trail path from a starting point P on canvas  to an ending point P on canvas , via point P, with the selected drawing stroke properties of options , , and . For example, in response to a user defining a trail path for a new drawing stroke graphical object (e.g., by dragging a cursor along canvas  from point P, via point P, to point P with mouse input component ), graphical input command generating module  may receive certain drawing stroke input information  and then generate a particular drawing stroke input command . This particular drawing stroke input command  may be received by processing module  of graphical display system  to generate straight uniform paint brush stroke body portion  of new drawing stroke graphical object  on display .","As mentioned, the selected \u201cshake to splatter\u201d input effect may adjust the distance that additional drawing stroke graphical object data may be stamped away from the body portion of the stamped trail of the paint brush input tool. For example, as shown in , drawing stroke graphical object  may also include a splatter portion , which may extend a first splatter distance S along and away from a first portion of body portion  (e.g., adjacent point P) and that may extend a second splatter distance S along and away from another portion of body portion  (e.g., adjacent point P). The splatter distance of splatter portion  of drawing stroke graphical object  may be determined by any suitable data accessible to first device  from any suitable source. For example, in some embodiments, splatter distance of splatter portion  may be determined by a detected magnitude of a particular movement of second device  at a particular time (e.g., as a user of device  may define body portion  of new drawing stroke graphical object  by dragging a cursor along canvas  from point P to point P with mouse input component , the same or another user may interact with device  to define one or more suitable splatter distances by shaking device  (e.g., as may be detected by sensor )). Therefore, a user may interact with first device  to define a first portion of a new graphical object while the same user or a different user may concurrently interact with second device  to define another portion of the new graphical object. This may allow a user of first device  to leverage the ease with which a mouse input component  of device  may define a trail or body portion of the new drawing stroke graphical object along canvas  while a user of second device  may leverage the ease with which portable device  equipped with a sensor  may be shaken to define one or more splatter distances of the new drawing stroke graphical object.","For example, based on the selected properties of options , , and  of device , and based on the trail path defined by points P, P, and P defined by input information , graphical command generating module  may generate a single new drawing stroke graphical object input command , which may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PAINT BRUSH; COLOR=BLACK; START:P; END:P; EFFECT=SHAKE TO SPLATTER; SHAKESTART=<UNKNOWN>; SHAKEEND=<UNKNOWN>\u201d, or two drawing stroke graphical object input commands , which may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PAINT BRUSH; COLOR=BLACK; START:P; END:P; EFFECT=SHAKE TO SPLATTER; SHAKESTART=<UNKNOWN>; SHAKEEND=<UNKNOWN>\u201d and \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PAINT BRUSH; COLOR=BLACK; START:P; END:P; EFFECT=SHAKE TO SPLATTER; SHAKESTART=<UNKNOWN>; SHAKEEND=<UNKNOWN>\u201d. Such new drawing stroke input commands  generated by graphical command generating module  may then be processed by graphical command processing module  (e.g., modules , , and\/or ) to generate at least a portion of new drawing stroke pixel array data  that may present at least a portion of new drawing stroke graphical object  at the appropriate position on canvas  of screen of display  (e.g., body portion  of new drawing stroke graphical object ).","As mentioned, virtual drawing space application  of first electronic device  may be synched with virtual drawing space application  of second electronic device  such that a single work of art (e.g. artwork ) may be presented on both first device  and second device , and such that the single work of art may be collaboratively created and\/or edited through both user interactions with first device  and user interactions with second device . Therefore, at least some graphical object input commands  generated by graphical command generating module  may be provided to communications circuitry  of first electronic device  as shared graphical object input commands . Continuing with the example of , based on the selected properties of options , , and , and points P-P of the trail path defined by input information , graphical command generating module  may generate at least two new drawing stroke graphical object input commands  that not only may be received and processed by pixel array generating module  to present body portion  of new drawing stroke graphical object  at the appropriate position on canvas  of screen of display , but that also may be received and processed by graphical command sharing module . Graphical command sharing module  may pass on the new drawing stroke graphical object input commands  as shared new drawing stroke graphical object input commands  to communications circuitry , which may provide shared new drawing stroke graphical object input commands  to graphical display system  of second device  (e.g., as received new drawing stroke graphical object input commands ) to generate new drawing stroke pixel array data  that may present at least a portion of new drawing stroke graphical object  at the appropriate position on canvas  of screen of display . Such received new drawing stroke graphical object input commands  may be received by pixel array requesting module  of graphical display system  of second device . For example, pixel array requesting module  may process the received new drawing stroke graphical object input commands  and may pass those received new drawing stroke graphical object input commands  on to pixel array generating module , such that at least a portion of new drawing stroke pixel array data  may be generated to present body portion  of new drawing stroke graphical object  at the appropriate position on canvas  of screen of display .","As mentioned, first electronic device  may not be provided with the ability to allow a user to interact with first device  to generate appropriate splatter distance data, such that new drawing stroke graphical object input commands  generated and shared as new drawing stroke graphical object input commands  by first device , and, thus, received new drawing stroke graphical object input commands , may not include any known splatter distance data for the new graphical object (e.g., for defining splatter portion \/ of graphical object \/). Regardless, system  may be configured such that second device  may process such input commands and may potentially supplement such input commands with known splatter distance data for the new graphical object. For example, in addition to or as an alternative to passing received new drawing stroke graphical object input commands  on to pixel array generating module , pixel array requesting module  may process received new drawing stroke graphical object input commands  and instruct graphical command sharing module  to share any accessible data that may not have been included in the received new drawing stroke graphical object input commands .","For example, in response to receiving and processing a new drawing stroke graphical object input command  having the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PAINT BRUSH; COLOR=BLACK; START:P; END:P; EFFECT=SHAKE TO SPLATTER; SHAKESTART=<UNKNOWN>; SHAKEEND=<UNKNOWN>\u201d, pixel array requesting module  may instruct graphical command sharing module  with a supplemental data request command  to provide first device  with any known splatter distance data that may be appropriate for the received command . In some embodiments, a user of second device  may have been shaking device  in order to generate certain input information  that may cause input command generating module  to generate a new drawing stroke graphical object input command  that may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PAINT BRUSH; COLOR=BLACK; START:<UNKNOWN>; END:<UNKNOWN>; EFFECT=SHAKE TO SPLATTER; SHAKESTART=S; SHAKEEND=S\u201d. In response to receiving a supplemental data request command  from module  and such a new drawing stroke graphical object input command  from module , module  may be configured to generate a new shared graphical object input command  that may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PAINT BRUSH; COLOR=BLACK; START:P; END:P; EFFECT=SHAKE TO SPLATTER; SHAKESTART=S; SHAKEEND=S\u201d (e.g., to combine supplemental data request command  from module  and such a new drawing stroke graphical object input command  into new shared graphical object input command ). Such a new shared graphical object input command  may be received by first device  as a received input command , which may be shared with pixel array generating module  for creating and\/or updating new drawing stroke graphical object  on canvas  with appropriately known splatter distance data (e.g., for creating splatter portion  of graphical object ).","Alternatively, in response to receiving a supplemental data request command  from module  and such a new drawing stroke graphical object input command  from module , module  may be configured to pass the new drawing stroke graphical object input command  on as a new shared graphical object input command , which may be received by first device  as a received input command  for creating splatter portion  of graphical object . Additionally or alternatively, in response to receiving a supplemental data request command  from module  and such a new drawing stroke graphical object input command  from module , module  may be configured to generate a requested supplemental data command  and provide such a requested supplemental data command  to module . Module  may then receive such a requested supplemental data command  and may supplement the received input command  to provide a supplemented received input command  to module  for creating new drawing stroke graphical object  on canvas  and\/or updating body portion  of new drawing stroke graphical object  on canvas  with splatter data . It is to be understood that graphical display system  may also be configured to generate and share supplemental data request commands  and requested supplemental data commands  that may be similar to supplemental data request commands  and requested supplemental data commands  of graphical display system , and, therefore, each may not be described independently in greater detail.","System  may be configured to associate an input command generated by first device  with an input command generated by second device  in any suitable way such that each device may process at least a portion of each command to generate the same single new graphical object on its respective canvas for artwork . In some embodiments, each generated command may include a timestamp such that each device may synch two or more commands with one another. For example, following the above example, a new drawing stroke graphical object input command  generated by first device  and shared with second device  may be time stamped to have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PAINT BRUSH; COLOR=BLACK; START:P; END:P; EFFECT=SHAKE TO SPLATTER; SHAKESTART=<UNKNOWN>; SHAKEEND=<UNKNOWN>; TIMESTAMP=T\u201d, and a new drawing stroke graphical object input command  generated by second device  and shared with first device  may be time stamped to have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PAINT BRUSH; COLOR=BLACK; START:<UNKNOWN>; END:<UNKNOWN>; EFFECT=SHAKE TO SPLATTER; SHAKESTART=S; SHAKEEND=S; TIMESTAMP=T\u201d. At least based on the commands sharing the same timestamp, or timestamps within a particular threshold time of one another, each device may associate the two commands for defining portions of the same new graphical object. In some embodiments, the two commands may be combined into a single combined command and the single combined command may be processed for generating pixel array data.","Commands may additionally or alternatively be provided with some kind of \u201caction identifier\u201d attached to them. For example, two users on two devices might be drawing strokes at the same time. The action identifier of each command may just be a distinct numerical ID. An action may be assigned an ID when it is initiated (e.g., when a mouse input is initially clicked or a touch screen is initially touched for generating the command). Subsequent actions (e.g., defining additional points along a drawing stroke trail, etc.) may include the same ID so that the receiving device may know which graphical object to associate the command with. After the action is completed (e.g., after the mouse button is released or after the finger touch is lifted), a subsequent action may utilize a new ID. A scheme may be required to make sure that different devices don't generate the same action ID. For example, this could be as simple as prefixing each ID with a number based on the order in which the device connected itself with one or more other devices. Certain actions that are \u201cone shot\u201d and don't require a state to be maintained across multiple network command messages may not need to assign an action ID. For example, such one shot commands may include color change commands, object creation commands, and shake magnitude commands.","In some embodiments, a user may interact with one device to generate one or more input commands, but that device may determine that it would rather leverage the processing capabilities of another device than process the generated commands itself. For example, a user may interact with I\/O interface  of second device  to generate a new graphical object input command  using graphical display system . However, rather than utilizing its own graphical command processing module  for processing this new generated graphical object input command  in order to generate the pixel array data for presenting a new graphical object on display , graphical display system  of second device  may instead utilize graphical command processing module  of first device  for processing this new generated graphical object input command .","As shown in , for example, a user of second electronic device  may select drawing stroke input option \/ for creating a new free-form drawing stroke in artwork  on canvases \/. Moreover, the user may interact with drawing stroke graphical object style input option  to select a drawing stroke input tool from a group of various pre-defined drawing stroke input tools or stamps (e.g., a \u201cpencil\u201d drawing stroke input tool, as shown in ), drawing stroke graphical object color input option  to select a color from a group of various pre-defined drawing stroke colors (e.g., a solid color represented by \u201c\u25aa\u201d, as shown in ), and drawing stroke graphical object effect input option  to select one or more effects to be applied to the drawing stroke from a group of various pre-defined drawing stroke effects (e.g., a \u201csmudge\u201d effect, as shown in ). It is to be understood that additional or alternative pre-defined drawing stroke input tools of various other pre-defined shapes, colors, effects, and other various pre-defined drawing stroke graphical object properties may also be provided by submenu \/ of menu \/ when drawing stroke input option \/ is selected.","Once options , , , and  of menu  have been selected for creating a drawing stroke graphical object (e.g., with a pencil drawing stroke input tool of a particular color and a \u201csmudge\u201d effect), a user may then interact with second device  to generate one or more new drawing stroke graphical objects in artwork  on both of canvases  and  according to the selected options. For example, when a user interacts with second device , based on any appropriate drawing stroke graphical object input information , which may be generated by the user (e.g., using input component  and\/or input component ) and\/or any application running on device  (e.g., application ), graphical input command generating module  may be configured to define and generate at least one new drawing stroke graphical object input command . However, this new drawing stroke graphical object input command  may not be processed by pixel array generating module  for eventually generating new active drawing stroke graphical object pixel array data  for presentation on display . Instead, for any suitable reason, graphical display system  may be configured to determine that it cannot or will not process this new drawing stroke graphical object input command . For example, module  may determine that second device  does not currently have enough processing power or battery power to currently handle the processing of this new drawing stroke graphical object input command  for generating the associated pixel array data to be displayed on display . As another example, second device  may simply not be provided with the adequate processing capabilities to handle certain computations that may be associated with this new drawing stroke graphical object input command  (e.g., computations associated with a smudging effect).","For example, as also shown by screen of , a user may interact with graphical display system  to generate a new drawing stroke graphical object  in artwork  on canvas . As shown, drawing stroke graphical object  may include a pencil stroke extending along a trail path from a starting point P on canvas  to an ending point P on canvas  with the selected drawing stroke properties of options , , and . For example, in response to a user defining a trail path for a new drawing stroke graphical object (e.g., by dragging a finger along canvas  from point P to point P with touch screen input component ), graphical input command generating module  may receive certain drawing stroke input information  and then generate at least a portion of a particular drawing stroke input command .","The selected \u201csmudge\u201d input effect may vary the opacity of the graphical object data that may be stamped by the pencil input tool along the stamped trail. For example, as shown in , drawing stroke graphical object  may have a varying opacity along its trail (e.g., graphical object  may get darker as it extends from point P to point P on canvas ). The opacity of drawing stroke graphical object  may be determined by any suitable data accessible to second device  from any suitable source. For example, in some embodiments, the opacity of drawing stroke graphical object  may be determined by a detected magnitude of pressure exerted on second device  at a particular time. As just one example, as a user of device  may define a trail path for new drawing stroke graphical object  by dragging a finger along canvas  from point P to point P using touch screen input component , the user may also vary the opacity of new drawing stroke graphical object  by gradually increasing the pressure the user applies on to touch screen input component  with his or her finger while it is dragged along the trail path (e.g., as may be detected by sensor  or touch screen  itself). As shown in , new drawing stroke graphical object  may have a smudge opacity S at start point P and a smudge opacity S at end point P that is darker than smudge opacity S.","Based on the selected properties of options , , and , the trail path defined by points P and P, and any received smudge data, graphical command generating module  may generate a new drawing stroke graphical object input command , which may have the following representative syntax: \u201cCOMMAND: CLASS=GRAPHICAL OBJECT INPUT; TYPE=DRAWING STROKE; STYLE=PENCIL; COLOR=BLACK; START:P; END:P; EFFECT=SMUDGE; SMUDGESTART=S; SMUDGEEND=S\u201d. Such a new drawing stroke input command  generated by graphical command generating module  may then be provided to pixel array generating module  and graphical command sharing module . However, this new drawing stroke graphical object input command  may not be processed by pixel array generating module  for eventually generating new active drawing stroke graphical object pixel array data  for presentation on display . Instead, for any suitable reason, module  and\/or , or any other suitable portion of system  may be configured to determine that system  cannot or will not process at least a portion of this new drawing stroke graphical object input command .","Based on such a determination, not only may graphical command sharing module  be configured to provide this new drawing stroke graphical object input command  as shared new drawing stroke graphical object input command  to first device  (e.g., as received new drawing stroke graphical object input command , such that first device may generate the appropriate pixel array data  for presenting a new drawing stroke graphical object  on canvas ), but graphical command sharing module  may also be configured to generate a requested supplemental data command  to pixel array sharing module . Such a requested supplemental data command  may instruct pixel array sharing module  to request at least a portion of the pixel array data generated by first device  in response to receiving the new drawing stroke graphical object input command  (e.g., as received new drawing stroke graphical object input command ). This requested pixel array data may be received by second device  and provided as at least a portion of canvas . Therefore, second device  may leverage the processing capabilities of first device  to receive the pixel array data for a graphical object defined by an input command originally generated by second device .","Although system  is only shown to include two electronic devices in , it is to be understood that system  may include three or more electronic devices, each of which may communicate with one another to collaborate on a single work of art. The network architecture of system  may be configured in many suitable ways. For example, in some embodiments, when a user interacts with a particular device to generate an input command, that device may broadcast the new input command to all of the synched devices within system  it is collaborating with (e.g., system  may be decentralized). In another embodiment, when a user interacts with a particular device to generate an input command, that device may share the new input command to a particular \u201cmaster\u201d device within system , and that master device may then share the received input command with any other synched devices within system . Such a configuration may reduce the number of communication channels between devices and bandwidth in the system but may increase the latency. In some embodiments, more than one outline may be provided over a canvas of a particular device, such that the current actively displayed portion of a shared artwork on two different devices may be identified on the artwork of a third device.",{"@attributes":{"id":"p-0251","num":"0250"},"figref":["FIG. 5","FIG. 4B"],"b":["700","700","702","100","1","303","110","100","704","700","103","100","305","304","301","303"]},"Then, at step , process  may include transmitting the first input command from the first electronic device to a second electronic device. For example, graphical display system  of first device  may transmit input command  as shared input command to second device , which may be received as received input command . Process  may also include step  for processing the first input command with the first graphics application on the first device to generate first pixel array data in a first canvas of the first device. As shown in screen of , for example, application  of first device  may process input command  to generate pixel array data  (e.g., as drawing stroke graphical object ) in canvas  of first device . In some embodiments, process  may also include step  for processing the first input command with a second graphics application on the second device to generate second pixel array data in a second canvas of the second device. As shown in screen of , for example, application  of second device  may process received input command to generate pixel array data  (e.g., as drawing stroke graphical object ) in canvas  of second device .","In some embodiments, the first input command does not include pixel array data. In some embodiments the size of the first pixel array data may be larger than the size of the first input command. For example, the bandwidth required by communications media  to share the first pixel array data between first device  and second device  may be greater than the bandwidth required by communications media  to share the first input command between first device  and second device .","In some embodiments, at least a portion of the transmitting of step  may occur at the same time as at least a portion of the processing of the first input command with the first graphics application of step . For example, graphical display system  may be configured to transmit at least a portion of shared input command at the same time as graphical display system  may be configured to process at least a portion of input command  with processing module . Additionally or alternatively, in some embodiments, at least a portion of the processing of the first input command with the first graphics application of step  may occur at the same time as at least a portion of the processing of the first input command with the second graphics application of step . For example, graphical display system  of first device  may be configured to process at least a portion of input command  with processing module  at the same time as graphical display system  of second device  may be configured to process at least a portion of shared input command \/received input command with processing module .","In some embodiments, the first device of process  may include more processing capabilities than the second device. In other embodiments, the first user interface of process  may include touch input capabilities and the second user interface may not include touch input capabilities. For example, second device  may include a touch screen  and first device  may only include a mouse  and a keyboard . In some embodiments, process  may also include presenting at least a portion of the first canvas on a first display of the first device and presenting at least a portion of the second canvas on a second display of the second device. In some embodiments, the second display may be larger than the first display (e.g., as shown in ).","In some embodiments, the first graphics application of process  and the second graphics application may share a semantic command set. Moreover, in some embodiments of process , the pixel array data in the first canvas may be the same as the pixel array data in the second canvas, and the pixel array data in the portion of the first canvas presented on the first display may be different than the pixel array data in the portion of the second canvas presented on the second display. For example, the pixel array data of canvas  may be the same as the pixel array data of canvas , as each canvas may include the pixel array data of shared artwork . However, in some embodiments, only a portion of canvas  may be presented on display  of second device  while the entirety of canvas  may be presented on display  of first device  (see, e.g., ).","In some embodiments, process  may also include receiving second user instructions with a second user interface of the second device, generating a second input command based on the received second user instructions with the second graphics application on the second device, transmitting the second input command from the second device to the first device, processing the second input command with the first graphics application on the first device to generate third pixel array data in the first canvas, and processing the second input command with the second graphics application on the second device to generate fourth pixel array data in the second canvas. For example, as described with respect to , second device  of system  may receive input information  from a user interacting with input component  of second device . Then graphics application  of second device  may generate an input command  (e.g., with graphical command generating module  of graphical display system ) based on received input information . Graphical display system  of second device  may transmit input command  as shared input command to first device , which may be received as received input command . As shown in screen of , for example, application  of second device  may process input command  to generate pixel array data  (e.g., as shape graphical object ) in canvas  of second device . Moreover, as shown in screen of , for example, application  of first device  may process received input command to generate pixel array data  (e.g., as shape stroke graphical object ) in canvas  of first device . In some embodiments, at least a portion of the transmitting the first input command (e.g., of step ) may occur at the same time as at least a portion of the transmitting the second input command. Alternatively or additionally, at least a portion of the processing of the first input command on the first device (e.g., of step ) may occur at the same time as at least a portion of the processing of the second input command on the second device. Moreover, alternatively or additionally, at least a portion of the processing of the first input command on the first device (e.g., of step ) may occur at the same time as at least a portion of the processing of the second input command on the first device.","It is to be understood that the steps shown in process  of  is merely illustrative and that existing steps may be modified or omitted, additional steps may be added, and the order of certain steps may be altered.",{"@attributes":{"id":"p-0259","num":"0258"},"figref":"FIG. 5A","b":["720","720","722","100","1","103","104","70","724","720","103","100","11","501","100"]},"Then, at step , process  may include sending first information from the first electronic device to a second electronic device, where the first information is configured to instruct the second electronic device to load at least a first portion of the artwork into a second graphics application on the second electronic device. For example, graphical display system  of first device  may transmit first information via communications media  to second electronic device  that may instruct second device  to load at least a portion of artwork  onto canvas  of second device .","In some embodiments, prior to the sending of step , process  may include receiving a first instruction at the first electronic device that defines the first portion of the artwork. For example, such receiving of the first instruction may include receiving the first instruction at the first electronic device from a user of the first electronic device (e.g., a user may define an outline over a portion of the artwork that may be displayed by the first device). As another example, such receiving of the first instruction may include receiving the first instruction at the first electronic device from the second electronic device (e.g., the first instruction may be indicative of the dimensions of a canvas displayed by the second electronic device or a resolution of a display of the second electronic device).","In some embodiments, the first information of process  may include pixel array data. In other embodiments, the first information of process  may include at least one graphical object input command.","It is to be understood that the steps shown in process  of  is merely illustrative and that existing steps may be modified or omitted, additional steps may be added, and the order of certain steps may be altered.","Moreover, the processes described with respect to , as well as any other aspects of the invention, may each be implemented by software, but may also be implemented in hardware, firmware, or any combination of software, hardware, and firmware. They each may also be embodied as machine- or computer-readable code recorded on a machine- or computer-readable medium. The computer-readable medium may be any data storage device that can store data or instructions which can thereafter be read by a computer system. Examples of the computer-readable medium may include, but are not limited to, read-only memory, random-access memory, flash memory, CD-ROMs, DVDs, magnetic tape, and optical data storage devices (e.g., memory , memory , and\/or server  of ). The computer-readable medium can also be distributed over network-coupled computer systems so that the computer readable code is stored and executed in a distributed fashion. For example, the computer-readable medium may be communicated from one electronic device to another electronic device using any suitable communications protocol (e.g., the computer-readable medium may be communicated to electronic device  via communications circuitry  from server  and\/or electronic device  of  (e.g., as at least a portion of an application  and\/or )). The computer-readable medium may embody computer-readable code, instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and may include any information delivery media. A modulated data signal may be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.","It is to be understood that any or each module of either one or both of graphical display system  and graphical display system  may be provided as a software construct, firmware construct, one or more hardware components, or a combination thereof. For example, either one or both of graphical display system  and graphical display system  may be described in the general context of computer-executable instructions, such as program modules, that may be executed by one or more computers or other devices. Generally, a program module may include one or more routines, programs, objects, components, and\/or data structures that may perform one or more particular tasks or that may implement one or more particular abstract data types. It is also to be understood that the number, configuration, functionality, and interconnection of the modules of either one or both of graphical display system  and graphical display system  are merely illustrative, and that the number, configuration, functionality, and interconnection of existing modules may be modified or omitted, additional modules may be added, and the interconnection of certain modules may be altered.","At least a portion of one or more of the modules of either one or both of graphical display system  and graphical display system  may be stored in or otherwise accessible to device  and\/or device  in any suitable manner (e.g., in memory  of device , in memory  of device , and\/or in server  of communications media  (e.g., as at least a portion of an application  and\/or )). Any or each module of either one or both of graphical display system  and graphical display system  may be implemented using any suitable technologies (e.g., as one or more integrated circuit devices), and different modules may or may not be identical in structure, capabilities, and operation. Any or all of the modules or other components of either one or both of graphical display system  and graphical display system  may be mounted on an expansion card, mounted directly on a system motherboard, or integrated into a system chipset component (e.g., into a \u201cnorth bridge\u201d chip). Either one or both of graphical display system  and graphical display system  may include any amount of dedicated graphics memory, may include no dedicated graphics memory and may rely on device memory (e.g., memory  and\/or memory ) or network memory (e.g., memory of server ), or may use any combination thereof.","Either one or both of graphical display system  and graphical display system  may be a dedicated system implemented using one or more expansion cards adapted for various bus standards. For example, all of the modules may be mounted on different interconnected expansion cards or all of the modules may be mounted on one expansion card. With respect to graphical display system , by way of example only, the modules of system  may interface with a motherboard or processor  of device  through an expansion slot (e.g., a peripheral component interconnect (\u201cPCI\u201d) slot or a PCI express slot). Alternatively, system  need not be removable but may include one or more dedicated modules that may include memory (e.g., RAM) dedicated to the utilization of the module. In other embodiments, system  may be a graphics system integrated into device . For example, a module of system  may utilize a portion of device memory  of device . One or more of the modules of graphical display system  may include its own processing circuitry and\/or memory. Alternatively each module of graphical display system  may share processing circuitry and\/or memory with any other module of graphical display system  and\/or processor  and\/or memory  of device . Similar configurations may be provided for graphical display system  with respect to device .","One or more Application Programming Interfaces (\u201cAPIs\u201d) may be used in some embodiments (e.g., with respect to graphical display system , graphical display system , or any other suitable module or any other suitable portion of any suitable module of graphical display system  and\/or graphical display system  of ). An API may be an interface implemented by a program code component or hardware component (hereinafter \u201cAPI-implementing component\u201d) that may allow a different program code component or hardware component (hereinafter \u201cAPI-calling component\u201d) to access and use one or more functions, methods, procedures, data structures, classes, and\/or other services provided by the API-implementing component. An API can define one or more parameters that may be passed between the API-calling component and the API-implementing component.","An API may allow a developer of an API-calling component, which may be a third party developer, to leverage specified features provided by an API-implementing component. There may be one API-calling component or there may be more than one such component. An API can be a source code interface that a computer system or program library may provide in order to support requests for services from an application. An operating system (\u201cOS\u201d) can have multiple APIs to allow applications running on the OS to call one or more of those APIs, and a service (e.g., a program library) can have multiple APIs to allow an application that uses the service to call one or more of those APIs. An API can be specified in terms of a programming language that can be interpreted or compiled when an application is built.","In some embodiments, the API-implementing component may provide more than one API, each providing a different view of or with different aspects that access different aspects of the functionality implemented by the API-implementing component. For example, one API of an API-implementing component can provide a first set of functions and can be exposed to third party developers, and another API of the API-implementing component can be hidden (e.g., not exposed) and can provide a subset of the first set of functions and can also provide another set of functions, such as testing or debugging functions which are not in the first set of functions. In other embodiments, the API-implementing component may itself call one or more other components via an underlying API and may thus be both an API-calling component and an API-implementing component.","An API may define the language and parameters that API-calling components may use when accessing and using specified features of the API-implementing component. For example, an API-calling component may access the specified features of the API-implementing component through one or more API calls or invocations (e.g., embodied by function or method calls) exposed by the API and may pass data and control information using parameters via the API calls or invocations. The API-implementing component may return a value through the API in response to an API call from an API-calling component. While the API may defines the syntax and result of an API call (e.g., how to invoke the API call and what the API call does), the API may not reveal how the API call accomplishes the function specified by the API call. Various API calls may be transferred via the one or more application programming interfaces between the calling component (e.g., API-calling component) and an API-implementing component. Transferring the API calls may include issuing, initiating, invoking, calling, receiving, returning, or responding to the function calls or messages. Thus, transferring can describe actions by either of the API-calling component or the API-implementing component. The function calls or other invocations of the API may send or receive one or more parameters through a parameter list or other structure. A parameter can be a constant, key, data structure, object, object class, variable, data type, pointer, array, list, or a pointer to a function or method or another way to reference a data or other item to be passed via the API.","Furthermore, data types or classes may be provided by the API and implemented by the API-implementing component. Thus, the API-calling component may declare variables, use pointers to, use or instantiate constant values of such types or classes by using definitions provided in the API.","Generally, an API can be used to access a service or data provided by the API-implementing component or to initiate performance of an operation or computation provided by the API-implementing component. By way of example, the API-implementing component and the API-calling component may each be any one of an operating system, a library, a device driver, an API, an application program, or other module. It should be understood that the API-implementing component and the API-calling component may be the same or different type of module from each other. API-implementing components may in some cases be embodied at least in part in firmware, microcode, or other hardware logic. In some embodiments, an API may allow a client program to use the services provided by a Software Development Kit (\u201cSDK\u201d) library. In other embodiments, an application or other client program may use an API provided by an Application Framework. In such embodiments, the application or client program may incorporate calls to functions or methods provided by the SDK and provided by the API or may use data types or objects defined in the SDK and provided by the API. An Application Framework may, in these embodiments, provide a main event loop for a program that responds to various events defined by the Framework. The API may allow the application to specify the events and the responses to the events using the Application Framework. In some implementations, an API call can report to an application the capabilities or state of a hardware device, including those related to aspects such as input capabilities and state, output capabilities and state, processing capability, power state, storage capacity and state, communications capability, and the like, and the API may be implemented in part by firmware, microcode, or other low level logic that may execute in part on the hardware component.","The API-calling component may be a local component (i.e., on the same data processing system as the API-implementing component) or a remote component (i.e., on a different data processing system from the API-implementing component) that may communicate with the API-implementing component through the API over a network. It should be understood that an API-implementing component may also act as an API-calling component (i.e., it may make API calls to an API exposed by a different API-implementing component) and an API-calling component may also act as an API-implementing component by implementing an API that may be exposed to a different API-calling component.","The API may allow multiple API-calling components written in different programming languages to communicate with the API-implementing component, such that the API may include features for translating calls and returns between the API-implementing component and the API-calling component. However, the API may be implemented in terms of a specific programming language. An API-calling component can, in some embodiments, call APIs from different providers, such as a set of APIs from an OS provider and another set of APIs from a plug-in provider and another set of APIs from another provider (e.g., the provider of a software library) or creator of the another set of APIs.",{"@attributes":{"id":"p-0276","num":"0275"},"figref":["FIG. 6","FIG. 6"],"b":["800","800","810","820","820","810","830","820","810","830","830","830","820","810","820","810","820","830"]},"It is to be appreciated that API-implementing component  may include additional functions, methods, classes, data structures, and\/or other features that may not be specified through API  and that may not be available to API-calling component . It is to be understood that API-calling component  may be on the same system as API-implementing component  or may be located remotely and may access API-implementing component  using API  over a network. While  illustrates a single API-calling component  interacting with API , it is to be understood that other API-calling components, which may be written in different languages than, or the same language as, API-calling component , may use API .","API-implementing component , API , and API-calling component  may each be implemented by software, but may also be implemented in hardware, firmware, or any combination of software, hardware, and firmware. They each may also be embodied as machine- or computer-readable code recorded on a machine- or computer-readable medium. The computer-readable medium may be any data storage device that can store data or instructions which can thereafter be read by a computer system. Examples of the computer-readable medium may include, but are not limited to, read-only memory, random-access memory, flash memory, CD-ROMs, DVDs, magnetic tape, and optical data storage devices (e.g., memory , memory , and\/or server  of ). The computer-readable medium can also be distributed over network-coupled computer systems so that the computer readable code is stored and executed in a distributed fashion. For example, the computer-readable medium may be communicated from one electronic device to another electronic device using any suitable communications protocol (e.g., the computer-readable medium may be communicated to electronic device  via communications circuitry  from server  and\/or electronic device  of ). The computer-readable medium may embody computer-readable code, instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and may include any information delivery media. A modulated data signal may be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.",{"@attributes":{"id":"p-0279","num":"0278"},"figref":["FIG. 7","FIG. 7"],"b":["900","901","909","921","929","913","915","917","940","933","937","921","929","940","933","937"]},"For example, as shown in , Service B  may include two APIs, one of which (i.e., Service B API- ) may receive calls from and return values to Application A  and the other of which (i.e., Service B API- ) may receive calls from and return values to Application B . Service A , which can be, for example, a software library, may make calls to and receive returned values from OS API- , and Service B , which can be, for example, a software library, may make calls to and receive returned values from both OS API-  and OS API- . Application B  may make calls to and receive returned values from OS API- .","As mentioned, an input component  of device  may include a touch input component that can receive touch input for interacting with other components of device  via wired or wireless bus . Such a touch input component  may be used to provide user input to device  in lieu of or in combination with other input components, such as a keyboard, mouse, and the like. One or more touch input components may be used for providing user input to device . Although the following describes various touch input components  that may be used for providing user input to device  (e.g., in conjunction with display  and\/or I\/O component ), the same description may additionally or alternatively be applied to various touch input components  that may be used for providing user input to device  (e.g., in conjunction with display  and\/or I\/O component ).","A touch input component  may include a touch sensitive panel, which may be wholly or partially transparent, semitransparent, non-transparent, opaque, or any combination thereof. A touch input component  may be embodied as a touch screen, touch pad, a touch screen functioning as a touch pad (e.g., a touch screen replacing the touchpad of a laptop), a touch screen or touch pad combined or incorporated with any other input device (e.g., a touch screen or touch pad disposed on a keyboard), or any multi-dimensional object having a touch sensitive surface for receiving touch input. In some embodiments, the terms touch screen and touch pad may be used interchangeably.","In some embodiments, a touch input component  embodied as a touch screen may include a transparent and\/or semitransparent touch sensitive panel partially or wholly positioned over, under, and\/or within at least a portion of a display (e.g., display ). In other embodiments, a touch input component  may be embodied as an integrated touch screen where touch sensitive components\/devices are integral with display components\/devices. In still other embodiments, a touch input component  may be used as a supplemental or additional display screen for displaying supplemental or the same graphical data as a primary display and to receive touch input.","A touch input component  may be configured to detect the location of one or more touches or near touches based on capacitive, resistive, optical, acoustic, inductive, mechanical, chemical measurements, or any phenomena that can be measured with respect to the occurrences of the one or more touches or near touches in proximity to input component . Software, hardware, firmware, or any combination thereof may be used to process the measurements of the detected touches to identify and track one or more gestures. A gesture may correspond to stationary or non-stationary, single or multiple, touches or near touches on a touch input component . A gesture may be performed by moving one or more fingers or other objects in a particular manner on touch input component , such as by tapping, pressing, rocking, scrubbing, rotating, twisting, changing orientation, pressing with varying pressure, and the like at essentially the same time, contiguously, or consecutively. A gesture may be characterized by, but is not limited to, a pinching, pulling, sliding, swiping, rotating, flexing, dragging, or tapping motion between or with any other finger or fingers. A single gesture may be performed with one or more hands, by one or more users, or any combination thereof.","As mentioned, electronic device  may drive a display (e.g., display ) with graphical data to display a graphical user interface (\u201cGUI\u201d). The GUI may be configured to receive touch input via a touch input component . Embodied as a touch screen (e.g., with display  as I\/O component ), touch I\/O component  may display the GUI. Alternatively, the GUI may be displayed on a display (e.g., display ) separate from touch input component . The GUI may include graphical elements displayed at particular locations within the interface. Graphical elements may include, but are not limited to, a variety of displayed virtual input devices, including virtual scroll wheels, a virtual keyboard, virtual knobs, virtual buttons, any virtual user interface (\u201cUI\u201d), and the like. A user may perform gestures at one or more particular locations on touch input component , which may be associated with the graphical elements of the GUI. In other embodiments, the user may perform gestures at one or more locations that are independent of the locations of graphical elements of the GUI. Gestures performed on a touch input component  may directly or indirectly manipulate, control, modify, move, actuate, initiate, or generally affect graphical elements, such as cursors, icons, media files, lists, text, all or portions of images, or the like within the GUI. For instance, in the case of a touch screen, a user may directly interact with a graphical element by performing a gesture over the graphical element on the touch screen. Alternatively, a touch pad may generally provide indirect interaction. Gestures may also affect non-displayed GUI elements (e.g., causing user interfaces to appear) or may affect other actions of device  (e.g., affect a state or mode of a GUI, application, or operating system). Gestures may or may not be performed on a touch input component  in conjunction with a displayed cursor. For instance, in the case in which gestures are performed on a touchpad, a cursor or pointer may be displayed on a display screen or touch screen and the cursor or pointer may be controlled via touch input on the touchpad to interact with graphical objects on the display screen. In other embodiments, in which gestures are performed directly on a touch screen, a user may interact directly with objects on the touch screen, with or without a cursor or pointer being displayed on the touch screen. In some embodiments, when input synchs  and  are selected, system  may be configured such that a user's interactions with touch screen  of second device  may interact directly with objects on touch screen , without a cursor or pointer being displayed on touch screen , but such interactions with touch screen  may control a cursor or pointer displayed on display  of first device .","Feedback may be provided to the user via bus  in response to or based on the touch or near touches on a touch input component . Feedback may be transmitted optically, mechanically, electrically, olfactory, acoustically, or the like or any combination thereof and in a variable or non-variable manner.","While there have been described systems, methods, and computer-readable media for manipulating and\/or mapping tiles of graphical object data, it is to be understood that many changes may be made therein without departing from the spirit and scope of the invention. Insubstantial changes from the claimed subject matter as viewed by a person with ordinary skill in the art, now known or later devised, are expressly contemplated as being equivalently within the scope of the claims. Therefore, obvious substitutions now or later known to one with ordinary skill in the art are defined to be within the scope of the defined elements. It is also to be understood that various directional and orientational terms such as \u201cup\u201d and \u201cdown,\u201d \u201ctop\u201d and \u201cbottom,\u201d \u201cleft\u201d and \u201cright,\u201d \u201clength\u201d and \u201cwidth,\u201d \u201chorizontal\u201d and \u201cvertical\u201d and \u201cdiagonal,\u201d and the like are used herein only for convenience, and that no fixed or absolute directional or orientational limitations are intended by the use of these words. For example, the devices of this invention can have any desired orientation. If reoriented, different directional or orientational terms may need to be used in their description, but that will not alter their fundamental nature as within the scope and spirit of this invention.","Therefore, those skilled in the art will appreciate that the invention can be practiced by other than the described embodiments, which are presented for purposes of illustration rather than of limitation."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The above and other aspects of the invention, its nature, and various features will become more apparent upon consideration of the following detailed description, taken in conjunction with the accompanying drawings, in which like reference characters refer to like parts throughout, and in which:",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIGS. 3A and 3B","FIGS. 1 and 2"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIGS. 4A-4K","FIGS. 1-3B"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIGS. 5 and 5A"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
