---
title: Cascaded hidden Markov model for meta-state estimation
abstract: A method and system for training an audio analyzer () to identify asynchronous segments of audio types using sample data sets, the sample data sets being representative of audio signals for which segmentation is desired. The system and method then label asynchronous segments of audio samples, collected at the target site, into a plurality of categories by cascading hidden Markov models (HMM). The cascaded HMMs consist of 2 stages, the output of the first stage HMM () being transformed and used as observation inputs to the second stage HMM (). This cascaded HMM approach allows for modeling processes with complex temporal characteristics by using training data. It also contains a flexible framework that allows for segments of varying duration. The system and method are particularly useful in identifying and separating segments of the human voice for voice recognition systems from other audio such as music.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06963835&OS=06963835&RS=06963835
owner: BAE Systems Information and Electronic Systems Integration Inc.
number: 06963835
owner_city: Nashua
owner_country: US
publication_date: 20030331
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DESCRIPTION OF THE PREFERRED EMBODIMENTS","ALTERNATIVE EMBODIMENTS"],"p":["1. Field of the Invention","This invention generally relates to the field of speech recognition, and more particularly relates to a system and method for segmenting audio signals into different classes that separate segments of voice activity from silence and tones in order to more accurately transcribe speech.","2. Description of Related Art","The process of automatic voice recognition and transcription has gained tremendous popularity-and importance in recent years. Today, voice recognition techniques are used in numerous applications such as closed captioning, speech dictation, and surveillance.","In automated speech recognition, the ability to separate segments of voice activity from other audio has become increasingly important as the desire to apply automatic voice processing to real world audio signals increases. Often, these types of audio signals consist of voice segments interspersed with segments of silence and other sounds such as tones or music. Certain anomalies within a segment of audio signals, such as a random burst of noise, silence, or music will cause errors when attempting to process or transcribe the speech segments. Therefore, prior to automatic processing of these voice segments, they must first be separated from the other audio.","Hidden Markov models (HMM) are commonly used to model random processes such as speech production. Others have tried segmenting speech and music with a single (HMM) using minimum duration constraints. However, with these methods there is a need to know the duration of the different segments beforehand. They also do not allow for segments smaller than the predetermined duration.","Therefore a need exists to overcome the problems with the prior art as discussed above, and particularly for a system and method for segmenting audio into different classes in order to more accurately transcribe speech.","A method and system for training an audio analyzer to identify asynchronous segments of different types of audio signals using sample data sets, the sample data sets being representative of the different types of audio signals to be separated. The system and method then label segments of audio samples collected from an unlabeled source, into a plurality of categories by cascading hidden Markov models (HMM). The cascaded HMMs consist of 2 stages, the output of the first stage HMM being transformed and used as observation inputs to the second stage HMM. This cascaded HMM approach allows for modeling processes with complex temporal characteristics by using training data. It also contains a flexible framework that allows for segments of varying duration.","Training files are used to create models of the signal types seen by the audio analysis system. Currently three models are built: voice, silence and signals (such as tones). The framework is such that other models can be added without many modifications to the software.","The present invention, according to a preferred embodiment, overcomes problems with the prior art by using the transformed output of one synchronous observer HMM as the input to another HMM which models the event sequence and duration. This cascaded HMM approach allows for modeling processes with complex temporal characteristics by using training data. It also contains a flexible framework that allows for segments of varying duration.","In speech recognition, the HMM is typically looking to estimate the state of the speakers vocal tract so that a match to a phonetic pattern can be established. The time scale of these events is on the order of 10 msec\u2013200 msec. Popular features, such as Linear Predictive Coding (LPC) coefficients or Cepstral coefficients, are typically extracted on frames of speech data at regular intervals of 10 msec to 25 msec. Thus the quasi-stable state duration is on the order of 1\u201320 observation frames. In the speech segmentation problem, what is desired is an estimate of a meta-state of the channel, i.e. not the details of the activity of the speaker's vocal tract, but the presence of a speaker. This type of state information is quasi-stable on the order of 2 sec\u2013-60 sec or more (even hours in the case of music) but generally not less. Due to the assumption of a Markov process, an HMM cannot accurately model the probability distribution of quasi-stable state intervals that have a higher probability of occurrence for longer periods of quasi-stability than for shorter periods.","The Cascaded HMM is a technique for separating voice segments from other audio using a 2 stage hidden Markov model (HMM) process. The first stage contains an HMM which segments the data at the frame level into a multiplicity of states corresponding to the short duration hidden sub-states of the meta-states (voice, silence or signal). This is a fine grain segmentation that is not well matched to the time scales of the desired meta-state information, since these transmissions may contain short periods of silence or signal and the HMM is unable to accurately model the lower probability of these short events. To overcome this, the output of the first HMM is modified to explicitly incorporate the timing and state information encoded in the state sequence. The modified output is then used as the input to a second HMM that is trained to recognize the meta-state of the channel.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIGS. 1","b":["2","3","100","110","114","116","110","122","110","122","112","112","114","116","118","120","114","116","214","116","202","208","212","204","310","302","206","210","330","208","332","208","118","124","114","112","118","104","102","106","108","118","110"]},"Glue software  may include drivers, stacks, and low level application programming interfaces (API's) and provides basic functional components for use by the operating system platform  and by compatible applications that run on the operating system platform  for managing communications with resources and processes in the computing system .","Each computer system  may include, inter alia, one or more computers and at least a computer readable medium . The computers preferably include means  for reading and\/or writing to the computer readable medium . The computer readable medium  allows a computer system  to read data, instructions, messages or message packets, and other computer readable information from the computer readable medium. The computer readable medium, for example, may include non-volatile memory, such as Floppy, ROM, Flash memory, disk drive memory, CD-ROM, and other permanent storage. It is useful, for example, for transporting information, such as data and computer instructions, between computer systems.","A microphone  is used for collecting audio signals in analog form, which are digitized (sampled) by an analog to digital converter (ADC) (not shown), typically included onboard a sound card . These sampled signals, or any audio sample already in a digital format (i.e. audio files using .wav, .mp3, etc . . . formats) may be used as input to the Feature Extractor .","A preferred embodiment of the present invention consists of two phases, a training phase and an identification\/segmentation phase. The training phase will occur in non real-time in a laboratory using data sets which are representative of that seen from sources for which segmentation is desired. These training files are used to create models of the signal types seen by the audio analysis system. Currently three models are built: voice, silence and signals (such as tones). The framework is such that other models can be added without many modifications to the software. Once the models have been created, they can be loaded by the real-time segment and used to attempt to classify and segment the incoming audio.","The training and identification\/segmentation phases of the method are performed using a technique called \u201cCascaded Hidden Markov Model (HMM)\u201d. This technique consists of two HMMs, where the transformed output of the first is used as the input to the second. These models are built using audio segments from the training data.","This technique overcomes two weaknesses of the standard HMM in modeling longer duration segments. The first weakness of the HMM in modeling larger segments is the assumption that observations are conditionally independent. The second is that state duration is modeled by an exponential decay. The Cascaded HMM method associates states with feature vector sequences rather than with individual observations, allowing for the modeling of acoustically similar segments of variable duration.","The method, as shown in , takes in a discrete sampled time domain signal at step . For example, the audio signal may be sampled at 48 kHz with a 16-bit linear A\/D converter. The time domain signal is then decimated by a factor of 6 yielding data at a sample-rate of 8 kHz. The time domain signal is transformed into a feature vector , at step . The feature vector  represents various characteristics of the signal over a short observation interval called a frame. The frame is short relative to a typical voice segment; so, many vectors are collected over the duration of a segment. The entire collection of feature vectors  for each of the segments is used for the subsequent training and identification\/segmentation process.","Ideal features should help discriminate between the different classes of signals to be identified and segmented. In the preferred embodiment, the feature vector  consists of three fields relating to the following features:","1. autocorrelation error\u2014indicates degree of voicing in signal.","2. harmonicity (evidence of formants) between 3 and 5 strongest spectral peaks to discriminate between voice and noise.","3. tone identification\u2014indicates presence of tones based on (a) frequency and (b) amplitude consistency criteria.","Other embodiments using different numbers of data fields and different observation techniques for those fields have also been contemplated and put into practice.","During the training phase, the training audio data is labeled into 3 categories (voice, silence, signal) at a coarse level of detail (i.e. a voice transmission which may contain short silences is all labeled as voice, provided it is all part of the same transmission). Feature extraction is preferably performed at a 10 msec frame interval. Each feature vector  is used as an observation input to the 1st stage HMM . The collection feature vectors  for each category, at step , are analyzed to produce a statistical model  for each of the segment types. The model used is multi-state ergodic hidden Markov model (HMM) with the observation probabilities (emission probability density) for each state modeled by a Gaussian probability density as shown in . The number of states is chosen to optimize performance with a particular application. Two (2), three (3), and higher values have all been contemplated and put into practice. For clarity, the number of states in the first stage HMM for each meta-state is referred to as N.","The Baum-Welch expectation. maximization (EM) algorithm  is used at step  to estimate the parameters of the models. Once a model for each category is built, they are combined, at step , into a multi-state ergodic HMM  as shown in  (i.e. each box in  contains an N-state model as shown in ). The transition probabilities between the categories may be manually set to appropriate values based on expert knowledge or estimated from the training data. This results in the 1HMM model that will have three times N output states. The number of output states of the 1HMM will be referred to as N. This HMM  is used to segment the data at the frame level into discrete states corresponding to the hidden sub-states of the 1HMM. This is accomplished by performing a Viterbi search, at step , to determine the most likely path through the HMM .","The input to the second HMM  is formed using the state sequence generated by the first HMM . The state sequence is transformed, at step , from a synchronous sequence of state labels, to an asynchronous sequence of discrete values encoding the first HMM state label and the duration of the state (i.e. number of repeats).","The second stage HMM  is now able to model the meta-state duration explicitly, overcoming the sequence length constraint in a single HMM with synchronous input. The same truth meta-state labeling is used to build models for speech segments, silence segments and signal segments. Each of these models contains 3 states; one for each of the three categories modeled above, with N sub-states each. The states are the same as that of the first stage shown in , except that there are N sub-states (shown in ) contained in each of the larger states. This is to allow for the event that a segment of one category contains frames of another category (i.e. a voice segment contains a short burst of noise in the middle). The emission probability of each of the states models the duration of that state in the segment. This enables the modeling of a segment as a sequence of observations. These models are combined, at step , to create an HMM  of the channel (the meta-state).","Once the HMMs are trained, segmentation of audio signals can be performed, as shown in . The models created during the training stage are loaded, at step , and used for testing. The raw audio signal  is sampled at step , the feature vectors  created at step , and then labeled according to category and duration by the first stage HMM  using the Viterbi algorithm  and the HMM of the first stage  at step . The category and duration labels are then converted into discrete values, at step , and fed to the second stage HMM  at step . The Viterbi is again performed, at step , now using the HMM of the second stage . The result is an asynchronous labeling, at step , of the audio into the three segment categories.","The labeled audio segments  may now be used more reliably in other functions. For example, there will be fewer errors when transcribing speech from a voice segment because the segments labeled \u201cvoice\u201d will only contain voice samples. It also allows for the segmentation of other types of signals in addition to voice. This is desirable in the automatic distribution of signals for further analysis.","The present invention can be realized in hardware, software, or a combination of hardware and software. Any kind of computer system\u2014or other apparatus adapted for carrying out the methods described herein\u2014is suited. A typical combination of hardware and software could be a general-purpose computer system with a computer program that, when loaded and executed, controls the computer system such that it carries out the methods described herein.","The present invention can also be embedded in a computer program product, which comprises all the features enabling the implementation of the methods described herein, and which\u2014when loaded in a computer system\u2014is able to carry out these methods. In the present context, a \u201ccomputer program\u201d includes any expression, in any language, code or notation, of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following: a) conversion to another language, code, or notation; and b) reproduction in a different material form.","Each system may include one or more computers and a computer readable medium that allows the computer to read data, instructions, messages, or message packets, and other computer readable information from the computer readable medium. The computer readable medium may include non-volatile memory such as ROM, Flash memory, a hard or floppy disk, a CD-ROM, or other permanent storage. Additionally, a computer readable medium may include volatile storage such as RAM, buffers, cache memory, and network circuits. Furthermore, the computer readable medium may include computer readable information in a transitory state medium such as a network link and\/or a network interface (including a wired network or a wireless network) that allow a computer to read such computer readable information.","While there has been illustrated and described what are presently considered to be the preferred embodiments of the present invention, it will be understood by those skilled in the art that various other modifications may be made, and equivalents may be substituted, without departing from the true scope of the present invention. Additionally, many modifications may be made to adapt a particular situation to the teachings of the present invention without departing from the central inventive concept described herein. Furthermore, an embodiment of the present invention may not include all of the features described above. Therefore, it is intended that the present invention not be limited to the particular embodiments disclosed, but that the invention include all embodiments falling within the scope of the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIGS. 4 and 5","FIG. 2"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
