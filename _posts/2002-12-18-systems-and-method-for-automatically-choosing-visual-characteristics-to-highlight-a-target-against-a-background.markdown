---
title: Systems and method for automatically choosing visual characteristics to highlight a target against a background
abstract: A method for choosing visual characteristics of a characteristic space within a region includes calculating a mean characteristic of the region, determining a covariance of the region, inverting the covariance to produce an inverse covariance, estimating a target characteristic, determining a difference between the mean characteristic and the target characteristic transposing the difference to produce a difference transpose, determining a saliency from a product of the difference transpose multiplied by the inverse covariance multiplied by the difference, comparing the saliency to an acceptance criterion to yield one of an acceptance if the saliency satisfies the acceptance criterion and a rejection otherwise, adjusting the target characteristic and repeating the determining a difference, transposing the difference, determining a saliency and comparing the saliency steps if the comparing yields the rejection, and outputting the target characteristic if the comparing yields the acceptance.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07130461&OS=07130461&RS=07130461
owner: Xerox Corporation
number: 07130461
owner_city: Stamford
owner_country: US
publication_date: 20021218
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"p":["The patent or application file contains at least one drawing executed in color. Copies of this patent or patent application publication with color drawings will be provided by the office upon request and payment of the necessary fee.","1. Field of Invention","This invention relates generally to visual characteristics of documents displayed to a observer.","2. Description of Related Art","The expansion of visually intensive web pages on the Internet has encouraged efforts to draw attention to a particular item on display. Such methods have included time-varying visual stimuli, such as flashing or animated icons, or audio stimuli, such as beeps. As users have become more experienced, such stimuli can cause annoyance rather than attraction.","More recent developments have led to more subtle methods for distinguishing a particular item on displayed documents, such as a web page. One such method includes highlighting a particular item with a surrounding block of a color that contrasts with the background as well as with the item. In various exemplary embodiments, the item can be enveloped by an outline in a color that contrasts with the background.","An appropriate color to be used in this method can be confidently selected by a person having experience in graphics arts and sufficient time to make a judicious evaluation based on the characteristics of the background and the item to which attention should be drawn.","However, the services of a graphic artist are often either unavailable or unaffordable. This may occur because the budget for a project does not allow for a graphic artist. This may also occur because the size of the project may be too large to allow a graphic artist to effectively review and revise all of the documents, or the project may involve a dynamically-changing display, complicating efforts by a graphic artist to account for all possible appearances of that display.","It would be useful for systems and methods to automatically select a visual characteristic parameter of a target against a background to facilitate a viewer to distinguish and direct attention to the target. Such systems and methods would mitigate the attention-diverting influence of distractors in the background.","Such a visual characteristic parameter could include a particular color hue, shade, texture, size, shape or motion set to a particular value. Such a selection can be based on saliency between the target and the background. Such systems or methods could expedite the selection of visual characteristics in a wide variety of applications at reduced cost from manual operation.","This invention provides systems, methods and tools for automatically recommending a color or alternate visual distinction to an observer of a document so that attention is directed to a particular document item within a background. In various exemplary embodiments, a display can include visual rendering exhibited on a printed page, a computer monitor, a PDA screen, a cockpit instrument, or the like.","This invention separately provides systems and methods that automatically select visual characteristics that provide distinction and thus draw attention of the viewer.","This invention separately provides systems and methods for choosing visual characteristics of a characteristic space within a region.","In various exemplary embodiments of the systems and methods according to this invention, a saliency is determined based on an inverse covariance of the region. A difference is determined between a target characteristic and a mean characteristic of the region. The saliency is compared against an acceptance criterion to yield one of an acceptance if the saliency satisfies the acceptance criterion and a rejection if it does not. The target characteristic is then adjusted. These steps are then repeated if the acceptance criterion is not satisfied. The target characteristic is output once the acceptance criterion is satisfied.","In various exemplary embodiments, the systems and methods according to this invention determine the saliency by first determining a mean characteristic of the region. A covariance of the region is then determined. The covariance is inverted to produce an inverse covariance. A target characteristic is estimated based on a difference in the opposite direction along a coordinate between the coordinate midpoint and the mean of the region. A difference between the mean characteristic and the target characteristic is then determined. The difference is transposed to produce a difference transpose. A product of the difference transpose multiplied by the inverse covariance multiplied by the difference is used to determine the saliency.","In various exemplary embodiments, the characteristic space has a single coordinate. In this case the mean characteristic, the covariance and the target characteristic each have a scalar element. In various exemplary embodiments, the characteristic space has a plurality of coordinates. In these cases, the mean characteristic is a vector having vector elements, the covariance is a matrix having tensor elements, and the target characteristic is a vector having vector elements. In various exemplary embodiments, the mean characteristic has a weighting factor that is multipled with each vector element for each coordinate of the plurality of coordinates. In various exemplary embodiments, the mean characteristic has a bias factor that is added to each vector element for each coordinate of the plurality of coordinates. In various exemplary embodiments, the covariance has a noise factor.","These and other features and advantages of this invention are described in, or are apparent from, the following detailed description of various exemplary embodiments of the systems and methods according to this invention.","Recommending a particular color or alternate visual distinguishing characteristic for directing a viewer's attention to a target despite distracting clutter in the background uses information gathered from studies in human visual response. The target can represent an icon or a text or a highlight to envelope the icon or text to be made prominent. The distracting features can be the background or distractors within that mask portions of the background.","Research in human vision shows that saliency, as characterized by the strength to grab attention (a) increases as a target becomes more distinguishable from distractors, and (b) decreases as the visibility or \u201cspread\u201d of the distractors enlarges. In various exemplary embodiments, the characteristics include colors selected from an available palette. In various other exemplary embodiments, the characteristics include alternate features providing visual distinction.","A well-chosen stimulus feature can facilitate human visual discrimination between a target and a plurality of distractors for drawing stimulus-driven attention. Such attention results from the characteristics of the stimulus, as distinct from items that draw attention due to semantic value for the observer. A stimulus for drawing attention to the icon or the text or to some other item can include distinctions or cyclic alterations in size, shape, color, opacity, hue (or tint), saturation (or chroma), value (or luminance\/shade), luminosity (or brightness), surface texture (e.g., watermark, specular or diffuse reflectivity, moire), focus (sharp, soft), relative position, motion speed and\/or motion direction.","In various exemplary embodiments, the visual characteristic used to provide distinction is color, leading to a search for an available color having an acceptable saliency. To identify an appropriate color, the systems and methods according to this invention represent the colors in a scene or corpus within an appropriate color space or color coordinate system. This appropriate color space is ideally a perceptually meaningful one for human response, although colors can be mapped into any appropriate color space. In various exemplary embodiments, the color space to be selected is CIELAB based on the Commission Internationale de l'Eclairages 1976 orthogonal coordinates L*a*b*. The lightness L* represents a relative gray scale between black and white. Two opposing scales represent the hue and chroma. The a* scale quantifies hues red by a+ and green by a\u2212. The b* scale quantifies hues yellow by b+ and blue by b\u2212. The absolute values of a* and b* correspond to the chroma.","In various exemplary embodiments, a multidimensional feature space can be defined, such as a visual coordinate system for a dynamic simulation. Such a characteristic space could include at least four coordinates w\u2013z, where w is the luminance, x is the hue, y is the saturation and z is the velocity (directional or absolute).",{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 1","b":["100","110","100","110","120","130","100"]},"The object  and the background  have one or more separate patterns, textures, colors and\/or other visually perceptible characteristics. The distinctions in shape and pattern between the object  and the distractors , as shown in , is rendered artificially significant for illustrative purposes only, and is not limiting. Circumscribing the object  is an outline  representing the target. The outline  has a pattern, color and\/or other visual characteristic selected to contrast against the background  and the distractors . The primary criterion for selecting the visual characteristic of the outline  includes facilitating of drawing of the observer's attention to the object . For a static display document, such as a web page, a choice of color could provide sufficient distinction to draw the observer's attention. In various exemplary embodiments, in a moving display, such as in an open loop dynamic simulation, a time-varying parameter, such as position could be used to draw the observer's attention.",{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 2","b":["200","210","220","230","200","210","210","230","240","230","240","210","220","230","240","230"]},"The criteria for the visual characteristic selection include facilitating drawing the observer's attention to the foreground , as well as avoiding obscuring the foreground . For a foreground  that includes text, a visual characteristic the highlight  is selected to create adequate contrast between the foreground  and the highlight  to improve the readability of the text. In other circumstances, the contrast between the highlight  and the background  can provide the basis of saliency.","Generally, in various exemplary embodiments, the visual characteristic for the outline  or highlight  is automatically chosen to draw attention to the outline or highlight. Selecting the visual characteristic is based on the visual characteristics of the object , the backgrounds  and , the foreground , and\/or the distractors  and .","The prominence or saliency of a particular target visual characteristic is determined such that the higher the saliency, the more the visual characteristic draws the observer's attention when that visual characteristic appears in a display having other displayed visual characteristics, such as the visual characteristics of the object, the background, the foreground and\/or any distractors. A visual characteristic can be selected automatically, or a number of visual characteristic choices can be provided to the observer. In various exemplary embodiments, the visual characteristic is color, to be selected from an available palette within a gamut that can be rendered to display the document.",{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 3","b":["300","310","320","330","340","350","300"]},{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIG. 4","FIG. 5"],"b":["360","370","380","390","400","410","420","430"]},"As illustrated in , different highlight colors can be chosen for each document within a corpus of documents, such as a web page, rather than a single selection uniformly applied over the corpus. In addition, a search in three-dimensional space can be performed for the best colors, for the best saturation, or for particular pre-chosen candidate colors. The degree of \u201cpop out\u201d might also be presented by a slider bar, to allow the observer to select the tradeoff between readability and saliency. Because web pages can be viewed on various document monitors driven by a variety of software drivers installed on sundry platforms, reliance on calibration of such monitors should be tempered with caution, so that user preferences can be accommodated by user-operated tailoring of criteria.","For a discretized region, such as a group of m pixels on a computer monitor, each pixel can be described by series quantity xfrom pixels i=1, 2, . . . , m. While the quantity xcan correspond to a scalar value for a single characteristic feature, a series j=1, 2, . . . , n might be used for n different color parameters for color applications. The color space representing the pixel group can be expressed in an n\u00d7m matrix form of n rows and m columns. The pixel quantities xfor L*a*b* colors, in three orthogonal coordinates, can be represented by a 3\u00d7m matrix of elements:",{"@attributes":{"id":"p-0055","num":"0054"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"x","mo":"=","mrow":{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"msub":{"mi":"x","mrow":{"mn":"1","mo":"\u2062","mi":"L"}}},{"msub":{"mi":"x","mrow":{"mn":"2","mo":"\u2062","mi":"L"}}},{"mi":"\u2026"},{"msub":{"mi":"x","mrow":{"mi":["m","L"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}]},{"mtd":[{"msub":{"mi":"x","mrow":{"mn":"1","mo":"\u2062","mi":"a"}}},{"msub":{"mi":"x","mrow":{"mn":"2","mo":"\u2062","mi":"a"}}},{"mi":"\u2026"},{"msub":{"mi":["x","ma"]}}]},{"mtd":[{"msub":{"mi":"x","mrow":{"mn":"1","mo":"\u2062","mi":"b"}}},{"msub":{"mi":"x","mrow":{"mn":"2","mo":"\u2062","mi":"b"}}},{"mi":"\u2026"},{"msub":{"mi":["x","mb"]}}]}]}},"mo":"\u00b7"}}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}}},"In various exemplary embodiments, once the colors appearing in that discretized region are represented, an arithmetic mean \u03bc of those color values can be determined. In various exemplary embodiments, the mean \u03bc can represent a median, a mode, a midpoint of the variation range, or an alternative statistical measure of location, and in the context of this specification should be treated broadly. In various exemplary embodiments for the discretized region, the mean \u03bc corresponds to the average of the color elements xthat appear in the pixel group, and can include both background and distractors within that discretized region.","In various exemplary embodiments, although the mean \u03bc can correspond to a scalar value for a single characteristic feature, the mean \u03bc for color is characterized, as a vector or single column matrix having a plurality of n rows. Each scalar element within the n\u00d71 vector may be denoted as \u03bcby a color coordinate subscripts from 1, 2, . . . , n corresponding to \u03bc, \u03bc, . . . , \u03bc. The mean \u03bccan be determined from the pixel quantities x, separately for each color coordinate j, as:",{"@attributes":{"id":"p-0058","num":"0057"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["\u03bc","j"]},"mo":"=","mrow":{"mfrac":{"mn":"1","mi":"m"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"m"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["x","ij"]},"mo":"."}}}}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}}},"In various exemplary embodiments, weighting factors \u03c9 can be assigned for selected portions of the region represented by the mean \u03bc of the region. For a text of the discretized region that is surrounded by a highlight region, the color variables for the highlight region should contrast against the background, but should also avoid obscuring the foreground text. The background of the discretized region may have low chroma, i.e., may be desaturated, while the highlight region may have low opacity, i.e., translucence, to ensure text readability. The effects of distractors on the ability of the viewer to distinguish the highlight region from the background can be emphasized by according greater weight to distractor pixels than to other background pixels. Consequently, quantities for each coordinate at each pixel of the discretized region can be multiplied by a weighting function based on a pixel characteristic for each weighting factor. Also, a bias factor \u03be can be added to adjust for noise. The weighted mean \u03bcfor each color coordinate can be determined from the weighted pixel quantities \u03c9xand biases \u03be, separately for each color coordinate j, as:",{"@attributes":{"id":"p-0060","num":"0059"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["\u03bc","j"]},"mo":"=","mrow":{"mrow":[{"mfrac":{"mn":"1","mi":"m"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"m"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":[{"mi":["\u03c9","ij"]},{"mi":["x","ij"]}],"mo":"\u2062"}}},{"msub":{"mi":["\u03be","j"]},"mo":"."}],"mo":"+"}}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}}},"For L*a*b* colors, in three orthogonal coordinates, the mean \u03bc can be represented by a 3\u00d71 vector matrix for the j coordinates. In various exemplary embodiments, the mean in this color space can be quantified by values of L* as \u03bc, a* as \u03bcand b* as \u03bc. In various exemplary embodiments, this vector matrix for L*a*b* colors is:",{"@attributes":{"id":"p-0062","num":"0061"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"\u03bc","mo":"=","mrow":{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["\u03bc","L"]}}},{"mtd":{"msub":{"mi":["\u03bc","a"]}}},{"mtd":{"msub":{"mi":["\u03bc","b"]}}}]}},"mo":"."}}},{"mrow":{"mo":["(",")"],"mn":"4"}}]}}}}},"Additionally, a covariance \u03a3 of the colors can be determined that quantifies the variation of color within the space. In general, the covariance \u03a3 represents a measure of correlation between the quantities around the mean \u03bc. More generally, however, the covariance \u03a3 provides a measure of the spread or variability of the quantities about the mean \u03bc. An appropriate measure for the covariance \u03a3 can provide both a magnitude and a directionality to that spread. In various exemplary embodiments, for variables j and k within the n-dimensioned color space, the covariance elements \u03a3can be expressed as:",{"@attributes":{"id":"p-0064","num":"0063"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"munder":{"mo":"\u2211","mi":"jk"},"mo":"\u2062","mrow":{"mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"mi":"m","mo":"-","mn":"1"}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"m"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"msub":[{"mi":["x","ij"]},{"mi":["\u03bc","j"]}],"mo":"-"}},{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["x","ik"]},{"mi":["\u03bc","k"]}],"mo":"-"}},"mo":"."}],"mo":"\u2062"}}}}}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}}}}},"As with the mean \u03bc, the covariance \u03a3 can correspond to a scalar value. However, in various exemplary embodiments, the covariance \u03a3 is characterized as an n\u00d7n matrix, sometimes denoted as a tensor array. Each element value \u03a3within the n\u00d7n matrix may be denoted by a double-subscript of coordinates j and k from 1, 2, . . . , n corresponding to elements \u03a3, \u03a3, . . . \u03a3, \u03a3, \u03a3, . . ,\u03a3, \u03a3, \u03a3, . . . , \u03a3. Positive correlation between coordinates j and k is indicated by covariance values greater than zero. This corresponds to pixel values that increase in the positive j direction and also increase in the positive k direction. Similarly, negative correlation is indicated by covariance values less than zero, while independence between coordinates j and k is indicated by zero covariance.","In various exemplary embodiments, an internal noise term can also be added to the covariance \u03a3 on the right-hand side of Eq. (5). Such a bias term \u03be can account for the noise apparent in the human visual system. For L*a*b* colors, this noise term can be adequately approximated. This noise term can represent noise in the human visual system's observations of displayed features. Additionally, adding noise can also ensure that the covariance matrix is invertible by providing values in the covariance elements that avoid a zero or near-zero determinate. Weighting factors \u03c9 can also be applied to selected covariance elements.","The covariance referred to in Eq. (5) represents a best-fit ellipsoid around the quantities, i.e., about the set of features in the region. In various exemplary embodiments, the covariance can be a maximum absolute difference |x\u2013x)| for all values of i=1, 2, . . . , m and j, k=1, 2, . . . , n. In various exemplary embodiments, the covariance can be a different function to characterize the spread, such as a Euclidean distance between the quantities. This Euclidean distance can be expressed as elements Din a Euclidean matrix D as:",{"@attributes":{"id":"p-0068","num":"0067"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["D","jk"]},"mo":"=","mrow":{"msqrt":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"m"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["x","ij"]},{"mi":["x","ik"]}],"mo":"-"}},"mn":"2"}}},"mo":"."}}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}}}}},"In various exemplary embodiments, the first row of the covariance \u03a3 matrix can be quantified by values of L* with respect to itself as \u03a3, and with respect to a* as \u03a3and b* as \u03a3. Similar quantification of the second and third rows leads to one exemplary embodiment of a covariance matrix for L*a*b* colors of the form:",{"@attributes":{"id":"p-0070","num":"0069"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mo":"\u2211","mrow":{"mo":"=","mrow":{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"munder":{"mo":"\u2211","mi":"LL"}},{"munder":{"mo":"\u2211","mi":"La"}},{"munder":{"mo":"\u2211","mi":"Lb"}}]},{"mtd":[{"munder":{"mo":"\u2211","mi":"aL"}},{"munder":{"mo":"\u2211","mi":"aa"}},{"munder":{"mo":"\u2211","mi":"ab"}}]},{"mtd":[{"munder":{"mo":"\u2211","mi":"bL"}},{"munder":{"mo":"\u2211","mi":"ba"}},{"munder":{"mo":"\u2211","mi":"bb"}}]}]}},"mo":"\u00b7"}}}},{"mrow":{"mo":["(",")"],"mn":"7"}}]}}}}},"While the mean \u03bc and covariance \u03a3 characterize the region, the color of a target T is characterized by an n\u00d71 matrix or vector of the same dimension as the mean \u03bc. In various exemplary embodiments, the saliency is defined as the Mahalanobis distance \u0394 of a particular target color T compared to the mean \u03bc of the distractor distribution in the background of the region. The spread of the distribution can be represented by the covariance \u03a3 or by the Euclidean distance D, or by any other appropriate known or later developed measure of the spread of data.","The Mahalanobis distance \u0394 can be expressed as a series of matrix multiplication operations for a color-choosing method. In various exemplary embodiment, the saliency expression can be determined from the square of the Mahalanobis distance \u0394 as:\n\n\u0394=(\u2212\u03bc)\u2032\u03a3(\u2212\u03bc)\u2003\u2003(8)\n","The vector difference (T\u2212\u03bc) represents the contrast between the target T and the region mean \u03bc for each of the respective vector components from Eq. (4) and forms an n\u00d71 matrix or vector. For L*a*b* colors, the vector can be written as:",{"@attributes":{"id":"p-0074","num":"0073"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mi":["T","\u03bc"],"mo":"-"}},{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":[{"mi":["T","L"]},{"mi":["\u03bc","L"]}],"mo":"-"}}},{"mtd":{"mrow":{"msub":[{"mi":["T","a"]},{"mi":["\u03bc","a"]}],"mo":"-"}}},{"mtd":{"mrow":{"msub":[{"mi":["T","b"]},{"mi":["\u03bc","b"]}],"mo":"-"}}}]}},"mo":"\u00b7"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}}}}},"The transpose of this vector difference (T\u2212\u03bc)\u2032 from Eq. (9) yields a 1\u00d7n compliment, forming a single row matrix. For a scalar difference, the transpose would be itself. For L*a*b* colors, the transpose is:\n\n(\u2212\u03bc)\u2032=[\u2212\u03bc\u2212\u03bc\u2212\u03bc].\u2003\u2003(10)\n","In various exemplary embodiments, the difference (T\u2212\u03bc), whether vector or scalar, represents a minimum distance between the target and the distractors. In various other exemplary embodiments, the difference (T\u2212\u03bc) can be other functions representing a difference between the target and the distractors, for instance a maximum distance between the target and the distractors.","The matrix inverse \u03a3of the covariance \u03a3 can be determined by matrix inversion techniques. For a scalar covariance \u03a3, the inverse is the reciprocal of the base scalar covariance \u03a3. The saliency, expressed by the Mahalanobis distance \u0394, is the transpose of the vector difference, multiplied by the inverse of the covariance, in turn multiplied by the vector difference. These matrix multiplications in Eq. (8) result in a scalar product \u0394for the square of the Mahalanobis distance.","The greater the saliency value calculated using this technique, the higher the probability that the target color T draws the observer's attention when appearing in a background display of colors having the mean \u03bc and the covariance \u03a3. In various exemplary embodiments, as a measure of target saliency, essentially the number of standard deviations between the target feature vector and the mean distractor feature vector are used. Thus, the more salient the target, i.e., the greater the Mahalanobis distance \u0394, the more easily an observer can notice or find the target among the background of distractors.","In various exemplary embodiments, the saliency can alternatively be measured by other techniques, such as by wavelet-based salient point detection or alternative filtering technique. In various exemplary embodiments, characterizations for scalar operations are based on the difference, such as (T\u2212\u03bc), minus spread such as covariance \u03a3, and the difference divided by the spread. In various other exemplary embodiments, the saliency can be determined based on the difference multiplied by the inverse of the spread in matrix form. In various exemplary embodimenets, positive weighting is applied to the difference and negative weighting is applied to the spread.","For L*a*b* colors, for example, a high level of saliency can be identified by comparing color characteristics of the target T and the mean \u03bc of the region about a midpoint, without performing the full saliency determination as outlined in Eq. (4) through Eq. (8). For example, in various exemplary embodiments, the lightness L* ranges from black (zero) to white (one-hundred), with a midpoint at neutral gray (fifty). Both a* and b* axes have zero midpoints, which are associated with no chroma.","Thus, if a background has a high mean lightness, i.e., \u03bc>50, then a high value for the saliency corresponds to a low target lightness, i.e., T<50, and vice versa. Similarly, if a background mean is green, i.e., \u03bc<0, and yellow, i.e., \u03bc>0, then a high value for the saliency corresponds to a target that is more red, i.e., \u03bc>0 and\/or blue, i.e., \u03bc<0, and vice versa. Consequently, a first estimate for a saliency target color could include, for example, values as T=100\u2212\u03bc, T=\u2212\u03bc, and T=\u2212\u03bc.","The mean \u03bc can use one or more weighting factors \u03c9 to adjust the measure of the region against which the saliency of the target T is to be compared. For the highlighted text example, the lightness L* could be used to emphasize the highlight, while the hue values a* and b* could be used to emphasize the background. In various exemplary embodiments, the highlight can be treated as a first target, while the text can be treated as a second target with preselected color characteristics. Concatenated saliency comparisons could then be used to select, and ideally optimize, the highlight color. The one or more weighting factors could also be used to account for the tendency for spatially neighboring colors to have more effect on the saliency of the target color than colors that are spatially more distant from the target.",{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIG. 6","b":["100","110","120","130","140"]},"In step S, a difference (T\u2212\u03bc) is determined. In various exemplary embodiments, such as, for example, when the difference is defined as a vector, the difference (T\u2212\u03bc) is also transposed. Then, in step S, the Mahalanobis distance \u0394 is determined as the scalar measure for saliency of the target T within the region. Next, in step S, the determined saliency is compared to an acceptance criterion. Then, in step S, a determination is made whether the comparison indicates that the saliency is acceptable. If the saliency is not acceptable, operation continues to step S. Otherwise, operation jumps to step S.","In various exemplary embodiments, the square of the Mahalanobis distance \u0394 is determined using matrix multiplication. In various other exemplary embodiments, the square of the Mahalanobis distance \u0394 is determined by scalar operations. In various exemplary embodiments, the square-root of the resulting squared Mahalanobis distance \u0394value quantifies the saliency.","In step S, the target value is adjusted. In various exemplary embodiments, the target value is adjusted by incremental changing the target value along at least one coordinate. Such incremental changes can be performed based on differences between the current target value and the mean p of coordinate values in the color space. Alternatively, the target value can be varied randomly. It should be appreciated that the new candidate target value may be chosen according to any desired appropriate technique. Operation then returns to step S. This process repeats indefinitely until the saliency satisfies the acceptance criterion. Alternatively, this process can be interrupted after exceeding a predetermined process condition, with an accompanying status message and\/or the current target value. In contrast, in step S, the target value determined in step S or step S is output. If the saliency satisfies more than one criterion or all criteria, the current target value satisfying the criteria is output. Operation then continues to step S, where operation of the method terminates.",{"@attributes":{"id":"p-0087","num":"0086"},"figref":["FIG. 7","FIG. 7"],"b":["110","110","112","114","120","112"]},{"@attributes":{"id":"p-0088","num":"0087"},"figref":["FIG. 8","FIG. 8"],"b":["120","120","122","124","130"],"sup":"\u22121 "},{"@attributes":{"id":"p-0089","num":"0088"},"figref":["FIG. 9","FIG. 9"],"b":["140","140","142","144","150","144","144"]},"These methods can also be applied to producing a web-safe color palette by producing a small collection of colors that perform such functions adequately on all platforms. See, for example, the web pages under URL addresses www.slashdot.org\/articles\/00\/09\/08\/1622204.shtml and www.hotwired.lycos.com\/webmonkey\/00\/37\/index2a.html?tw=design.","In various exemplary embodiments, the systems and methods for choosing color according to this invention exploits traits within human vision to find a particular target that displays characteristics that distinguish the target from distractors within a background. This characterization of the observer's visual search can be labeled stimulus-driven attraction, from the features of the stimulus, as distinct from those items that draw attention due to their potential semantic value for the observer. The saliency in some exemplary embodiments of the color-choosing systems and methods according to this invention represents a useful measure for stimulus-driven attraction.","In a first example, a selection of highlight colors for a web page text is chosen. The highlight colors should draw the observer's attention, while the highlighted text should also be readable. For example, the highlighted text should be legibly distinct against the highlight. These are conflicting demands on the highlight colors.","Without loss of generality, consider black text, which is most readable against a light, desaturated background. However, the human visual response predicts that saturated colors are the best for drawing attention. A decision can be made to emphasize readability as more crucial than drawing attention. Consequently, colors may be selected with reduced, and ideally, the minimum, saturation required to draw the observer's attention.","In various exemplary embodiments, the systems and methods for choosing useful colors according to this invention starts with a list of possible candidate hues. In an experimental example, to minimize the set of colors for a wide variety of web pages the mean \u03bc and covariance \u03a3 of the colors were determined for a set of twenty selected \u201ctypical\u201d web pages. The saturation of the candidate hues was increased, until the resulting saliency of each color was 3.5. The saliency value of 3.5 was selected based, on theoretical reasons as a 2.5, base value of representing an applicable threshold for a color to \u201cpop out\u201d, plus a margin for error. With L*a*b* colors, this entails increasing the absolute values of a* and\/or b*, while maintaining L* constant. Selecting a reduced, and minimum, saturation that achieves a given saliency allows the systems and methods to balance both the criterion that the highlight colors draw the observer's attention, and the criterion that black text be readable against those highlight colors.","Surrounding an object by a thin outline represents another application for automatic color selection, as shown in the following examples.  present a photograph  in an electronic museum guidebook containing a collection of objects that are outlined, as described herein. The outline must exhibit a target color to draw the observer's attention against an often saturated background selecting a target color can be further complicated by large variations in the background and\/or among the objects to be outlined.",{"@attributes":{"id":"p-0096","num":"0095"},"figref":["FIG. 10","FIGS. 4 and 5"],"b":["500","505","500","360","400","510","520","530","510","520","530"]},"In the examples shown in , the color-choosing systems and methods according to this invention determine the mean \u03bc and the covariance \u03a3 for the background  and the objects \u2013 were analyzed. To select the colors, the set of candidate colors for the outline as the target T. In these examples shown in , the hues for the outlines for all of the candidate colors were highly saturated to maximize Mahalanobis distance \u0394 for the outline.",{"@attributes":{"id":"p-0098","num":"0097"},"figref":["FIGS. 10","FIGS. 13","FIG. 10","FIG. 11","FIG. 12","FIG. 13","FIG. 14","FIG. 15"],"b":["11","12","14","15","510","520","530","540","550","560","570","580","590"]},"A casual observer would likely agree that the orange outline  and the red outline  represent poor selections, in part for the limited contrast in hue against the warm-color background  in the photograph . The same observer might be less persuaded that the cyan outline  constitutes a poor choice. Additionally, the observer would likely also agree that the pink outline  and the green outline  strongly draw the observer's attention, while remaining skeptical that the blue outline  is a good choice. Calibrating the display device used to view the image can enhance the saliency of colors from a human visual-response perspective.","The color-choosing systems and methods show proficiency in determining colors attracting attention that \u201cclash\u201d or contrast with colors in the background scene. An optional user selection can be included to enable controlled change of desired saliency of the chosen color. The saliency determination can thus be inverted to select colors that compliment other adjacent colors.","The saliency can be determined as a color chooser. A heuristic can be used to guess a good color followed by an optimization procedure to pick the color, with saliency as the goodness measure for the optimization. In various exemplary embodiments, a set of candidate colors may already be established for testing the saliency of those candidates and pick those with highest saliency or saliency over some threshold. In various exemplary embodiments, rather than picking colors, a color might already be chosen, and the method would rate the saliency of that color. In further exemplary embodiments, search is confined only to within a limited range of color space, such as for changing only the saturation of a color, and looking a color with saliency above an established threshold (e.g., >3.5). For example, a \u201cgreen\u201d with high saliency could be sought, thereby restricting the search within hues known to appear \u201cgreen\u201d (roughly corresponding to the negative a- region in L*a*b* colors). Finally, saliency might be only one component of the optimization function. Colors might be good for other reasons as well. One example includes readability of black text against the highlight color.",{"@attributes":{"id":"p-0102","num":"0101"},"figref":["FIG. 16","FIG. 16"],"b":["600","600","610","620","630","640","650","660","670","680","690","700","710","720"]},"The input\/output interface  interacts with the outside of the visual characteristics choosing system . For example, the input\/output interface  receives an image from an image data source  over a link . The input\/output interface  also outputs a revised image and\/or one or more instructions for and\/or information about revising an image to an image sink  over a link . The input\/output interface  may also be connected to one or more user input devices and\/or one or more output devices, such as an interactive document, or the like.","In various exemplary embodiments, the data source  can be integrated with the visual characteristics choosing system , such as in a digital optical character recognizer having an integrated image receiver, such as a scanner. In various other exemplary embodiments, the image data source  can be connected to the input\/output interface  over the link . The link  can be implemented using a connection device such as a modem, a local area network, a wide area network, an intranet, the Internet, and any other distributed processing network, or any other known or later-developed connection structure.","It should be appreciated that, while the electronic image data can be generated at the time of decoding a document image from an original physical document, the electronic image data could have been generated at any time in the past. The image data source  is thus any known or later-developed source which is capable of supplying electronic image data to the input\/output interface . For example, the image data source  may be a data carrier such as a magnetic storage disk, CD-ROM or the like, or a host computer that contains scanned image data. Thus, the image data source  can be any known or later-developed source that is capable of providing image data to the visual characteristics choosing system  according to this invention.","The data sink  can be any known or later-developed device that is capable of receiving a recognized output by the visual characteristics choosing system  and either storing, transmitting or displaying the solutions. In various exemplary embodiments, the data sink  can be integrated with the visual characteristics choosing system . In various other exemplary embodiments, the data sink  can be connected to the input\/output interface  over a link . The link  can be implemented using a connection device such as a modem, a local area network, a wide area network, an intranet, the Internet, and any other distributed processing network, or any other known or later-developed connection device.","The image data source  can be any one of a number of different sources, such as a digital copier, a facsimile device, a digital camera, a scanner, or a locally or remotely located computer, or any other known or later-developed device that is capable of generating electronic image data. Similarly, the data source  can be any suitable device that stores and\/or transmits electronic image data, such as a client or a server of a network or the Internet, and especially the World Wide Web.","In various exemplary embodiments, inputs and outputs can present an image or provide instructions for producing an image. Coded instructions can be written in a description language to describe the document format. Hence, an input or an output can present a pixel rendering or command text. In particular, the output can be a specification of a color or colors (such as coordinates in color space), a measure of saliency, etc. A variety of description languages can be used to provide instructions for displaying color in a document image.","The memory  stores information received from the input\/output interface , such as image data received by the input\/output interface . The memory  also stores information and\/or data from various ones of the circuits, routines or applications \u2013 of the visual characteristics choosing system . The memory  can be implemented using any appropriate combination of alterable, volatile or non-volatile memory or non-alterable or fixed, memory. The alterable memory, whether volatile or non-volatile, can be implemented using any one or more of static or dynamic RAM, a floppy disk and disk drive, a writeable or re-writeable optical disk and disk drive, a hard drive, flash memory or the like. Similarly, the non-alterable or fixed memory  can be implemented using any one or more of ROM, PROM, EPROM, EEPROM, an optical ROM, such as a CD-ROM or DVD-ROM disk and disk drive or the like.","As shown in , the memory  includes one or more of a region characterizing portion , which stores region characterizing result; a covariance inverse determining portion , which stores covariance inverse determining result; a target estimating portion , which stores a target estimating result; a difference determining between target and mean portion , which stores a difference determining between target and mean result; a saliency determining portion , which stores a saliency determining result; a saliency comparing portion , which stores a saliency comparing result; an acceptance deciding portion , which stores an acceptance deciding result; and a target adjusting portion , which stores a target adjusting result.","The one or more control and\/or data busses and\/or application programming interfaces  provide communication and data transfer among various ones of the circuits, routines or applications \u2013 of the visual characteristics choosing system . The controller  provides instructions to various ones of the circuit, routine or application \u2013 of the visual characteristics choosing system .","The region characterizing circuit, routine or application  explores partial paths and searches for solutions and determines the mean \u03bc of the region. The covariance inverse determining circuit, routine or application  determines the inverse covariance of the region, represented as a matrix or as a scalar in various exemplary embodiments. The target estimating circuit, routine or application  estimates a target value T for each coordinate in the color space. The difference determining circuit, routine or application  determines a difference between the target and the mean of the region. The difference transpose can also be determined, accordingly.","The saliency determining circuit, routine or application  determines the saliency based on the covariance and the determined difference. The saliency comparing circuit, routine or application  compares the saliency with an acceptance criterion. The acceptance deciding circuit, routine or application  decides whether to adjust the target based on the results put out by the saliency comparing circuit, routine or application . The acceptance deciding circuit, routine or application , based on the comparison result from the saliency comparing circuit, routine or application  or either stops further iteration of the target and outputs the target through the input\/output interface , or directs the target adjusting circuit, routine or application  to adjust the target values within the color space. In one or more exemplary embodiments, the acceptance deciding circuit, routine or application  can also receive input from alternative sources and assess conditions apart from the saliency.","The input\/output interface  outputs the target that satisfies the acceptance criterion. In various exemplary embodiments of the operation of the visual characteristics choosing system  according to this invention, the visual characteristics choosing system  shown in  generates, for example, a displayed color, element values of coordinates in a color space and\/or a recognized text string to represent target information for a received color region.",{"@attributes":{"id":"p-0115","num":"0114"},"figref":["FIG. 17","FIG. 16","FIG. 17"],"b":["640","642","644","720"]},{"@attributes":{"id":"p-0116","num":"0115"},"figref":["FIG. 18","FIG. 16","FIG. 18"],"b":["650","652","654","720"]},{"@attributes":{"id":"p-0117","num":"0116"},"figref":["FIG. 19","FIG. 16","FIG. 19"],"b":["670","672","674","20"]},"In the visual characteristics system , shown in , is based on human vision research on criteria that determine whether a color \u201cpops out\u201d and appears to draw an observer's attention. In various exemplary embodiments, an automatic system for selecting appropriate colors, as disclosed, provides an improvement over current manual selection for various tasks, such as highlighting objects for both noticeability and legibility of the highlighted subject, and for blending into the surroundings.","The visual characteristics choosing system  is, in various exemplary embodiments, implemented on a programmed general purpose computer. However, the visual characteristics choosing system  can also be implemented on a special purpose computer, a programmed microprocessor or microcontroller in peripheral integrated circuits, an ASIC or other integrated circuit, a digital signal processor, a hard wired electronic or logic circuit such as a discrete element circuit, a programmable logic device such as a PLD, PLA, FPGA or PAL, or the like. In general, any device, capable of implementing a finite state machine that is in turn capable of implementing the flowcharts shown in  can be used to implement the visual characteristics choosing system .","It should be understood that each of the circuits, routines and\/or applications shown in  can be implemented as physically distinct hardware circuits within an ASIC, or using an FPGA, a PDL, a PLA or a PAL, a digital signal processor, or using discrete logic elements or discrete circuit elements. The particular form each of the circuits or routines shown in  will take is a design choice and will be obvious and predictable to those skilled in the art.","The system  can be a plurality of separate dedicated or programmable integrated or other electronic circuits or devices or implemented using a suitably programmed general purpose computer, either alone or in conjunction with one or more peripheral data and signal processing devices. In general, any device or assembly of devices on which a finite state machine capable of implementing the procedures described herein can be used as the system . A distributed processing architecture can be used for maximum data\/signal processing capability and speed.","While this invention has been described in conjunction with exemplary embodiments outlined above, many alternatives, modifications and variations will be apparent to those skilled in the art. Accordingly, the exemplary embodiments of the invention, as set forth above, are intended to be illustrative, not limiting. Various changes can be made without departing from the spirit and scope of the invention."],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The patent or application file contains at least one drawing executed in color. Copies of this patent or patent application publication with color drawing(s) will be provided by the Office upon request and payment of the necessary fee.","Various exemplary embodiments of the methods of this invention will be described in detail with reference to the following figures, wherein:",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 7","FIG. 6"]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 8","FIG. 6"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 9","FIG. 6"]},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIG. 17","FIG. 16"]},{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 18","FIG. 16"]},{"@attributes":{"id":"p-0039","num":"0038"},"figref":["FIG. 19","FIG. 16"]}]},"DETDESC":[{},{}]}
