---
title: Document image decoding systems and methods using modified stack algorithm
abstract: Methods and systems for document image decoding incorporating a Stack algorithm improve document image decoding. The application of the Stack algorithm is iterated to improved decoding. A provisional weight is determined for a partial path to reduce template matching. In addition, semantically equivalent hypotheses are identified to reduce redundant hypotheses.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07289668&OS=07289668&RS=07289668
owner: Xerox Corporation
number: 07289668
owner_city: Stamford
owner_country: US
publication_date: 20020809
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS"],"p":["1. Field of Invention","This invention relates to methods and systems for document image decoding.","2. Description of Related Art","Document image decoding (DID) is a method for recognizing text contained within document images that is based on a communications systems view of the document composition, printing, degradation, and scanning processes. Among the advantages of document image decoding are high recognition accuracy in situations where extensive customization is allowable, the ability to recognize some higher-level structure along with the text, and the ability to extend and improve a system within a consistent probabilistic framework.","In the document image decoding framework, document images are regarded as having been produced by transitioning through a Markov source, which is a probabilistic finite-state machine. The source begins in a special start state and terminates in a special stop state. Each transition within the source inputs a portion of the image, e.g., a bitmap, on the page at a current cursor location, outputs a recognized character, then advances that location by a two-dimensional vector displacement in preparation for recognizing the next character. The transitions are selected based on the degree of correspondence between the input image portion and a character template associated with the output character. The set of character templates includes white space of various kinds.","Formally, each transition in the source is assigned a four-tuple consisting of a character template, a two-dimensional displacement by which to advance a cursor, the prior probability of following that transition, and a string label comprising, for example, the recognized character. It should be appreciated that, conventionally, the amount of information encapsulated in the prior probability is quite limited. For instance, the prior probability does not take into account what previous transitions might have occurred on the same path through the Markov source.","Every complete path through the source defines a document image and an associated transcription. In general, the image is the union of the bitmaps imaged on each transition. In general, the transcription is the concatenation of the associated string labels. It should be appreciated that more than one complete path through the source may give rise to the same image and\/or the same transcription.","After the document image has been formed, the document image is assumed to have been subjected to some form of random corruption process prior to the recognition process, which causes some uncertainty in the recognition process. In general, recognition proceeds by finding a complete path through the hypothesized Markov source that \u201cbest\u201d explains the observed image. Specifically, recognizing the document image comprises seeking a complete path through the source that is most probable considering the entire document image as evidence. In general, the probability for the each complete path is determined on the basis of the prior probabilities of the transitions, the likelihood of the associated imaged templates, and the random corruption process. Because multiple paths can correspond to the same transcription, choosing the most probable complete path is not the same as choosing the most probable transcription.","The probability of a transcription is properly determined by summing the probabilities of all of the complete paths that are consistent with that transcription. Nevertheless, experience has shown that choosing a message with the greatest complete-path probability is usually a good approximation to choosing the message with the highest posterior probability. This is known as the Viterbi approximation to the maximum a posteriori probability (MAP) decision rule.","When a language model is incorporated into document image decoding (DID), the decoding space becomes so large that it is difficult to perform decoding with methods such as the Viterbi algorithm. Also, a document image decoding model may include a blank, single-pixel width character, which is called \u201cthin space\u201d. This thin space makes it difficult to incorporate a language model into document image decoding. Furthermore, when a language model is incorporated into document image decoding, template matching becomes very expensive.","Accordingly, systems and methods that reduce difficulties associated with incorporating language models into document image decoding would be desirable.","The Stack algorithm provides a means of directly comparing paths of differing lengths, so that, at each step, the most promising path can be extended. The Stack algorithm uses a priority queue to determine the most promising path according to a measure of the overall potential of each partial path ending in a high-scoring full path.","This invention provides systems and methods that complement a modified Stack algorithm.","This invention separately provides systems and methods that implement a modified Stack algorithm that allows the Stack algorithm to be used with paths having similar weights.","This invention separately provides systems and methods that implement a modified Stack algorithm that allows the Stack algorithm to be used with paths having different lengths.","This invention separately provides systems and methods that implement a modified Stack algorithm that is usable with document image decoding.","This invention provides methods and systems that allow a modified Stack algorithm to be used in document image decoding.","This invention provides methods and systems that allow a modified Stack graph to be explored.","This invention further provides systems and methods that identify a desirable path in document image decoding based on the explored modified Stack graph.","This invention additionally provides methods and systems that allow a priority table to be used to identify the desirable path.","This invention also provides methods and systems that allow only a part of a Stack graph to be explored.","This invention further provides systems and methods that identify a desirable path based on the explored part of the Stack graph.","This invention additionally provides methods and systems that allow a possible extension of a path to be examined.","This invention further provides systems and methods that identify a desirable path based on the examined possible extension.","This invention also provides methods and systems that allow a weight of a path to be determined.","This invention further provides systems and methods that identify a priority of the path in a modified Stack algorithm based on the determined weight.","This invention separately provides methods and systems that allow a template matching component weight to be determined.","This invention separately provides methods and systems that allow a language model component weight in a modified Stack algorithm to be determined.","This invention further provides systems and methods that allow a weight of a partial path to be determined.","This invention separately provides methods and systems that allow the weight of the partial path to be determined using a parameterization between a template matching and a language model component weight.","This invention separately provides methods and systems that allow an amount of template matching to be reduced.","This invention further provides systems and methods that allows the amount of template matching to be reduced by examining only part of the possible extensions of a path.","This invention additionally provides methods and systems that allow an amount of template matching to be reduced by using an upper bound of a plurality of possible extending edge weights.","This invention also provides methods and systems that allow an amount of template matching to be reduced by using a provisional weight.","This invention separately provides methods and systems that allow a partial path to be queued according to a provisional weight of the partial path in document image decoding.","This invention separately provides methods and systems that allow the weight of the partial path to be adjusted.","This invention further provides methods and systems that allow the weight of the partial path to be adjusted according to the length of the partial path.","This invention separately provides methods and systems that allow a path priority of a path to be determined.","This invention further provides systems and methods that allow the path priority to be adjusted based on an adjusted weight in a modified Stack algorithm.","This invention separately provides methods and systems that allow a weight of a complete path to be predicted.","This invention further provides methods and systems that allow the weight of the complete path to be predicted by using a suffix.","This invention separately provides methods and systems that allow a complete path to be predicted from a partial path.","Various exemplary embodiments of the methods and systems according to this invention allow an upper bound of a plurality of possible extending edge weights for a partial path to be determined, a provisional weight for the partial path to be determined, and the partial path queued according to the provisional weight of the partial path. In various exemplary embodiments, using provisional weights in queuing partial paths reduces template matching.","These and other features and advantages of this invention are described in, or are apparent from, the following detailed description of various exemplary embodiments of the methods and systems according to this invention.","Document image decoding (DID) takes a communication systems approach to optical character recognition (OCR). When a language model is incorporated, a document image decoding process considers both a template matching and a linguistic likelihood when decoding a character in a received document image.","Regarding the linguistic likelihood, an original message N=c, c, c, . . . , with statistical properties given by language model L, is \u201ctransmitted\u201d on a channel. In a d-order language model L, each character is given a probability based on a context of size d. For example, in various exemplary embodiments, a current character is given a probability based on a context of the d characters appearing immediately prior to the current character.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 1","FIG. 1"],"b":["100","100","110","110"]},"For ease of discussion, the text fragment  shown in  is considered to be a one-dimensional text line. The text line begins at the left-most point of the text fragment  and ends at the right-most point of the text fragment , with the size of the text line increasing in the increasing direction of an x-coordinate.","Each of the plurality of characters  in  is labeled cfor discussion and is located at a corresponding x-coordinate value x. Here, i=1, 2, 3, . . . , is an index of the characters  of the text fragment .","In the exemplary embodiment of a document image decoding framework shown in , a language model Lmay find that the third character is more likely to be the letter \u201ce\u201d than the letter \u201cc,\u201d because, in view of the one or more characters prior to the third character, the string \u201cT-h-e\u201d is linguistically more probable than the string \u201cT-h-c.\u201d","In various exemplary embodiments of the methods and systems according to this invention, a probability P(c) for a next character cto appear at a position i of a message N=c, c, c, . . . , c, . . . , using a d-order language model L, is expressed as:\n\nP(c|c, c, . . . , c),\u2003\u2003(1)\n\nwhere:\n","cis the next character; and","c, etc. are the d previous characters.","In various exemplary embodiments of the methods and systems according to this invention, the context size d of the d-order language model Lis fixed. In various other exemplary embodiment of the methods and systems according to this invention, the context size d of the d-order language model Lis allowed to vary.","In various exemplary embodiments of the methods and systems according to this invention, a rendering model R is used to account for the character positioning process in a document. A degradation model D is used to account for image distortions that may occur during printing, copying, and\/or scanning of a document containing the text fragment to be recognized. The rendering model R and the degradation model D establish how a character in a source text string N=c, c, c, . . . appears in a received document image Z after being rendered and degraded. Accordingly, a document image decoding process determines a most likely rendering process and a most likely degradation process that define a most likely source N\u2032=c, c, c, . . . to be decoded from a received image Z.","In the rendering model R, it is assumed that a character c, located at a position (x, y), causes a character template from a font f to be placed in an ideal image Q. Such a model may be expressed as:\n\nR(c, f, x, y, Q).\u2003\u2003(2)\n","In various exemplary embodiments of the methods and systems according to this invention, for one line of text with a fixed baseline and a single font typeface, the rendering model R shown in Eq. (2) is simplified as:\n\nR(c, x, Q).\u2003\u2003(3)\n","According to many exemplary rendering models R, there is a character dependent spacing between characters. In the example shown in , after rendering a character cat an x-coordinate position xby R(c, x, Q), the next character cwill be rendered at an next x-coordinate xwhich is determined as:\n\n(),\n\nwhere w(c) is a set-width of the preceding character c.\n","In many exemplary rendering models R, the size of the spacing w(c) depends on the font. Furthermore, in many exemplary fonts, the size of the spacing w(c) may vary from character to character. On the other hand, accordingly to the degradation model, the ideal image Q may be degraded by printing, scanning, and\/or use of the document, to form the received image Z that is to be decoded.","In various exemplary embodiments of the methods and systems according to this invention, a matching function M(c, x, Z) is used to determine the likelihood that the character cwas rendered at a position xby R(c, x, Q) and then degraded by the degradation function or model D(Q\u2192Z) to form the received document image Z. This determination is based on a matching the degraded received document image Z with a set of templates.","In the exemplary text fragment  shown in , the third character  may be compared with a plurality of templates  to identify that the third character  is more likely to match with the template for the character \u201cc\u201d or the template for the character \u201ce\u201d than with the templates of any other characters. Furthermore, based on the d-order language model L, the third character  may be identified to more likely match with the template for the character \u201ce\u201d than with the template for the character \u201cc\u201d.","In various embodiments of the methods and systems according to this invention, the matching function M(c, x, Z) includes a bit flip model. In the bit flip model, there is a small probability that a black pixel becomes white, and another small probability that a white pixel becomes black. In various exemplary embodiment of the methods and systems according to this invention, the matching function M(c, x, Z) includes a symmetric bit flip model, where the probability that a black pixel becomes white is equal to the probability that a white pixel becomes black. In various other exemplary embodiment of the methods and systems according to this invention, the matching function M(c, x, Z) includes a full gray-scale model.","For a received document image Z, such as a line of text, there may exist a plurality of hypotheses H regarding how an original text M is rendered into the ideal image Q and then degraded to the received document image Z. Each hypothesis H has a probability. A hypothesis H that a character cappears at a position xcan be expressed as H(c, x). The probability of H(c, x) that a specific character cappears at that position xin the received document image Z is the product of the probability of matching the specific character cto an appropriate template T(c, x, Z) and the probability P(c|c, c, . . . , c) that the specific character cwill appear next, given the preceding d characters based on a language context from the d-order language model L. Thus, the probability P(c, x) of the hypothesis H(c, x) is:\n\n()=()*().\u2003\u2003(4)\n","Furthermore, a hypothesis H\u2032 that an entire text line of the degraded image Z comprises a string of character cat position x, character cat position x, character cat position x, and, in general, character cat position x, can be expressed as:\n\n\u2032=(), (), (, x), . . . , (), . . . .\u2003\u2003(5)\n","Accordingly, the probability of the hypothesis H\u2032 expressed in Eq. (5) is the product of the probabilities of each (c, x). Thus, the probability of H\u2032 is:",{"@attributes":{"id":"p-0080","num":"0079"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"msup":{"mi":["H","\u2032"]}}},{"mrow":[{"mo":["[","]"],"mrow":{"munder":{"mi":["\u03a0","i"]},"mo":"\u2062","mrow":{"mi":"M","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["c","i"]},{"mi":["x","i"]}],"mo":[",",","],"mi":"Z"}}}}},{"mo":"[","mrow":{"munder":{"mi":["\u03a0","i"]},"mo":"\u2062","mrow":{"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":{"mi":["c","i"]},"mo":"\u2758","mrow":{"msub":[{"mi":"c","mrow":{"mrow":{"mi":["i","d"],"mo":["-","+"],"mn":"1"},"mo":","}},{"mi":"c","mrow":{"mi":["i","d"],"mo":["-","+"],"mn":"2"}}],"mo":"\u2062"}},"mo":[",","\u2062","\u2062",","],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.6em","height":"0.6ex"}}}],"mi":"\u2026","msub":{"mi":"c","mrow":{"mi":"i","mo":"-","mn":"1"}}}}},"mo":"."}}}],"mo":"*"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}}}}},"Thus, the log probability of the hypothesis H\u2032 is:",{"@attributes":{"id":"p-0082","num":"0081"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"msup":{"mi":["H","\u2032"]}}}},{"mrow":[{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"M","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["c","i"]},{"mi":["x","i"]}],"mo":[",",","],"mi":"Z"}}}}},{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":{"mi":["c","i"]},"mo":"\u2758","mrow":{"msub":[{"mi":"c","mrow":{"mrow":{"mi":["i","d"],"mo":["-","+"],"mn":"1"},"mo":","}},{"mi":"c","mrow":{"mi":["i","d"],"mo":["-","+"],"mn":"2"}}],"mo":"\u2062"}},"mo":[",","\u2062","\u2062",","],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.6em","height":"0.6ex"}}}],"mi":"\u2026","msub":{"mi":"c","mrow":{"mi":"i","mo":"-","mn":"1"}}}}},"mo":"."}}}],"mo":"+"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"7"}}]}}}}},"In particular, Eq. (7) contains a template matching component TM(i):\n\n()=log (),\u2003\u2003(8)\n\nand a language model component LM(i):\n\n()=log ().\u2003\u2003(9)\n","In various embodiments of the methods and systems according to this invention, the requirement that the x-coordinate position of the next character c, be defined solely by the set-width w(c) of the preceding character, that is, that x=x+w(c), is relaxed by adding zero or more special \u201cthin space\u201d characters t between the message characters cto achieve a desired positioning of the message characters c. Each thin space t has a set-width of, for example, one pixel. A hypothesis H\u2033 that includes one or more thin spaces t can be expressed as:\n\n\u2033=(), (), (), (), (), . . . ,\u2003\u2003(10)\n\nwhere tis the number of thin spaces between two adjacent message characters cand c.\n","The hypothesis H\u2033 has a log probability given by Eq. (7), with additional template matching terms for the thin space characters. That is, the log probability of the hypothesis H\u2033 can be expressed as:",{"@attributes":{"id":"p-0086","num":"0085"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"msup":{"mi":["H","\u2033"]}}}},{"mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"M","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["c","i"]},{"mi":["x","i"]}],"mo":[",",",","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"Z"}}}}},"mo":"+"}],"mo":["=","\u2062"],"mi":{}}}},{"mtd":{"mrow":{"mi":{},"mo":"\u2062","mrow":{"mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":[{"mi":["c","i"]},{"mi":"c","mrow":{"mi":["i","d"],"mo":["-","+"],"mn":"1"}}],"mo":"|"},"mo":[",",",","\u2062",","],"msub":[{"mi":"c","mrow":{"mi":["i","d"],"mo":["-","+"],"mn":"2"}},{"mi":"c","mrow":{"mi":"i","mo":"-","mn":"1"}}],"mi":"\u2026","mstyle":{"mspace":{"@attributes":{"width":"0.6em","height":"0.6ex"}}}}}}}},"mo":"+"}}}},{"mtd":{"mrow":{"mi":{},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mrow":{"mi":"M","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"t","mn":"1"},{"mi":["x","i"]}],"mo":[",",","],"mi":"Z"}}},"mo":"."}}}}}}]}},{"mrow":{"mo":["(",")"],"mn":"11"}}]}}}}},"In various exemplary embodiments of the methods and systems according to this invention, the log M(t, x, Z) for each thin space character t is defined to be nearly equivalent to a comparable fraction of the log of the match score for a full space in the same location. However, these additional matching terms are defined as slightly smaller than that of a full space, so that the matching function M(c, x, Z) will not replace an ordinary space character with one or more thin space characters t.","Thin space characters t generally introduce multiple hypotheses Hfor the same message character string c, c, c, . . . In this case, each of the multiple hypotheses Hwill differ only in the different numbers of thin space characters t. This often results in duplicate or semantically equivalent hypotheses H, increasing the cost associated with document image decoding.","In various exemplary embodiments of the methods and systems according to this invention, a most likely hypothesis His determined and used for a decoding solution. In such exemplary embodiments, different hypotheses H are compared to determine whether the different hypotheses are semantically equivalent. In various exemplary embodiments, a hash table can be used to make such determinations. When two hypotheses Hand Hare semantically equivalent, the hypothesis Hwith a greater promise to lead to a solution is kept and the other hypothesis His discarded. Accordingly, the number of duplicate or semantically equivalent hypotheses H is reduced, as will be discussed in greater detail below.","The thin space characters t may also allow templates T to separate, while the rendering model R may allow the templates T to overlap. Overlapping templates affect the way template matching is normalized for the whole line, and this may cause difficulties when a language model is incorporated. In general, due to imprecision in modeling, some flexibility is required in combining models. In various exemplary embodiments of the methods and systems according to this invention, a simple parameterization is employed to overcome these difficulties. For example, in many exemplary embodiments, the log probability defined in Eq. 11 is parameterized as:",{"@attributes":{"id":"p-0091","num":"0090"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"Log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"msup":{"mi":["H","\u2033"]}}}},{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mi":"TM","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},{"mi":"\u03bb","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"LM","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}}],"mo":"+"}}}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}},"br":{}},"In various exemplary embodiments of the methods and systems according to this invention, the parameter \u03bb is empirically determined based on data of a noise level to account for the different normalization of the template matching and language model. Typical values of \u03bb range from 1.1 to 1.6.","To determine a most likely hypothesis H, different hypotheses H need to be explored and evaluated. In various exemplary embodiments of the methods and systems according to this invention, a Stack algorithm is used explore different hypotheses H to identify the most likely hypothesis H. In the Stack algorithm, the hypotheses exploration issue of document image decoding is treated as a graph search problem, as discussed in greater detail below.","In various exemplary embodiments of the methods and systems according to this invention, a graph G includes a plurality of vertices V connected by a plurality of edges E. Thus, a graph G can be denoted as:\n\n=().\u2003\u2003(13)\n\nEach edge e of the plurality of edges E connects vertices v and w of the plurality of vertices V. Thus, each edge e can be denoted as:\n\n=(),\u2003\u2003(14)\n\nwhere v and w are the beginning and end vertices connected by the edge e.\n",{"@attributes":{"id":"p-0095","num":"0094"},"figref":["FIG. 2","FIG. 2","FIG. 1"],"b":["200","200","220","230","230","220"]},"Each edge  is associated with a character , while each vertex  is associated with an x-position along the character string. For the text fragment , a decoding process starts at a left-most vertex , which corresponds to the x-position of the left-most edge  of the left-most character . The decoding process continues in the direction towards the right-hand side, from one vertex to another, thus decoding one character after another. The decoding process finishes at a right-most vertex , which corresponds to the x-position of the right-most edge  of the right-most character . Accordingly, each vertex  represents a decoding state in the decoding process, where moving from one vertex to a subsequent vertex decodes one character.","As shown in , the left-most vertex  is a source, and the right-most-vertex  is a sink. The source vertex  is a special type of vertex  that is associated with the beginning of the text fragment  and therefore represents the first decoding state of the decoding process. On the other hand, the sink vertex  is a special type of vertex  that is associated with a possible end of the text fragment, and therefore represents a possible last decoding state of the decoding process.","Each edge  is a possible path from one vertex  to a subsequent vertex , and is therefore a possible decoding step from the one vertex  to the next vertex  in the decoding process. A group of edges  that makes a complete path from the source  to a sink  is a hypothesis H or a possible solution of the decoding process. In various exemplary embodiment of the methods and systems according to this invention, a decoding solution comprises searching through the Stack graph for a hypothesis H that comprises a plurality of edges connecting between the source and a sink and has a desired total weight.","A character  may be associated with a plurality of possible edges . For example, in , the third character  from the left-hand side is associated with four edges  illustrated in  below the third character . These four edges illustrate the most likely decodings for the third character . However, we have not shown all the edges of the graph, which would include less likely decodings such as x or g. Also, each of the four edges  associated with the third character  is connected to a preceding vertex  associated with an x-position between the second character  and the third character . Accordingly, the Stack graph has a tree-like configuration, as shown in , in which each vertex  in one decoding state branches off to a number of possible vertices  in the next decoding state, with one edge for each of the possible template matches. However, when nodes are equivalent for purposes of decoding, they can be combined. For example, in , when no language model is used the nodes  can be combined if they correspond to the same x-position on the line. When nodes are combined the tree-like graph in , will become an acyclic graph.","When the stack graph  is acyclic, the decoding process continues in a single direction, from the left to the right. Accordingly, each edge  points to and develops the tree-like configuration in one direction, i.e., in the direction indicated by the arrows of the edges .","As shown in , each edge  is associated with a score indicator . The score indicator comprises a template indicator  and a weight indicator . The template indicator  indicates a template , against which a character  in the received image  is matched. The weight indicator  indicates a measure or a weight of the match between the character  and the template . The measure or weight thus indicates the degree of correspondence, or the quality of the match, between the current image portion and the corresponding template.  illustrates measures that would correspond to probabilities, and so would be combined with multiplication. Equivalently, one can use measures that correspond to log probabilities and so would be combined with addition.","In the example shown in , the second character  compares most favorably with the templates  for the letters \u201ch\u201d and \u201cb.\u201d The weight for the second character to be an \u201ch\u201d is 0.12, while the weight for the second character to be a \u201cb\u201d is 0.03. Accordingly, the second character is more likely to be an \u201ch.\u201d","Along the path in which the second character is identified as \u201ch,\u201d the weight for the third character to be an \u201ce\u201d is 0.07, while the weight for the third character to be a \u201cc\u201d is 0.05. Thus, along this path, the third character is more likely to be \u201ce.\u201d Similarly, along the path in which the second character is identified as \u201cb,\u201d the weight for the third character to be an \u201ce\u201d is 0.02, while the weight for the third character to be a \u201cc\u201d is 0.01. Thus, along this path, the third character is more likely to be \u201ce.\u201d However, for each of the characters \u201ce\u201d and \u201cc,\u201d these probabilities are less than those for the path in which the second character is identified as \u201ch.\u201d","In various exemplary embodiments of the methods and systems according to this invention, each weight indicator  indicates a measure of the probability of the template matching and the language content of the corresponding template indicator . It is often convenient to use log probabilities for implementation of the weights .","In various exemplary embodiments of the methods and systems according to this invention, a vertex v associated with a character is denoted as:\n\n()=().\u2003\u2003(15)\n","In Eq. (15), x is the x-coordinate of the character, and the string c, c, . . . , cis the linguistic context, i.e., the d\u22121 decoded characters that are to the left of the x-coordinate. Eq. (15) may be rewritten into the form of:\n\n()=((), ()),\u2003\u2003(16)\n\nwhere K(v) is the x-coordinate of K(v) and K(v)=c, c, . . . , cindicates the linguistic context of the vertex K(v).\n","In various exemplary embodiments of the methods and systems of this invention, the Stack algorithm does not need to explore the whole graph. Instead, only a promising part of the Stack graph is explored. This promising part is identified as that part of the Stack graph that is most likely to produce a solution. Exploring only the promising part of the Stack graph allows for document image decoding efficiency.","In various exemplary embodiments of the methods and systems of this invention, a portion of a Stack graph is generated with a generation function:\n\n()={. . . |()\u2208\u2003\u2003(17)\n","The generation function g defined in Eq. (17) enumerates all the edges e leaving a vertex v, or equivalently, all possible next states wfor a decoding process. In various exemplary embodiment, where K(v)=(x, c, c, . . . , c), an edge e is defined from the current vertex v to a subsequent vertex wif K(w)=(x+w(c), c, c, . . . , c) corresponds to decoding the character cfrom the current position x to the next position x+w(c) in the received image.","In various exemplary embodiments of the methods and systems according to this invention, a path is a list of vertices that are linked by edges. Accordingly, a path can be expressed as:\n\n=()\u2208\u2003\u2003(18)\n\nwhere v, v, v, v, v, and vare vertices.\n","In various exemplary embodiments of the methods and systems according to this invention, different paths through the Stack graph correspond to different decoding hypotheses H.  illustrates one exemplary embodiment of a hypothesis in a Stack graph . As shown in , a hypothesis  is a complete path from a source vertex  to a sink vertex . The hypothesis  comprises a plurality of edges , , or . Each edge  or  connects two vertices  or .","As shown in , a partial path  is a portion of the hypothesis . The partial path  starts from the source vertex  and ends at a last vertex  of the partial path .","A suffix of a partial path is the remaining part of the partial path that turns the partial path into a corresponding complete path. As shown in , a suffix  of the partial path  starts from the last vertex  of the partial path  and ends at the sink vertex .","As indicated above, in various exemplary embodiments of the methods and systems according to this invention, the weight of a path is equal to the log probability of the hypothesis Hcorresponding to the path. Because a path hypothesis Hincludes individual edges, the weight of a path W(p) is determined from the weight of the individual edges W(v, v) that form the path:",{"@attributes":{"id":"p-0115","num":"0114"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"p"}},{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"mrow":{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["v","i"]},{"mi":"v","mrow":{"mi":"i","mo":"+","mn":"1"}}],"mo":","}}},"mo":"."}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"19"}}]}}}}},"In various exemplary embodiments of the methods and systems according to this invention, the weight of each individual edge W(v,v) includes a likelihood of a template match and a likelihood of a language model:\n\n()=()+\u03bb(),\u2003\u2003(20)\n\nor:\n\n()=log ()+\u03bblog (2 ).\u2003\u2003(21)\n","In various exemplary embodiments of the methods and systems according to this invention, the modified Stack algorithm according to this invention searches a Stack graph for a desired path as a solution. The desired path may be an optimal path. For example, the desired path may be a path with a maximum weight among all the paths.","As used herein, the terms \u201coptimize\u201d, \u201coptimal\u201d and \u201coptimization\u201d connote a condition where one entity is deemed better than another entity because the difference between the two entities is greater than a desired difference. It should be appreciated that it would always be possible to determine a better entity as the desired difference decreases toward zero. Also, the terms \u201cmaximize\u201d, \u201cmaximum\u201d and \u201cmaximization\u201d connote a condition where one entity is deemed greater than another entity because the difference between the two entities is greater than a desired difference. It should be appreciated that it would always be possible to determine a greater entity as the desired difference decreases toward zero. Similarly, the terms \u201cminimize\u201d and \u201cminimal\u201d connote a condition where one entity is deemed less than another entity because the difference between the two entities is greater than a desired difference. Again, it should be appreciated that it would always be possible to determine a lesser entity as the desired difference approaches zero.","Accordingly, it should be appreciated that, these terms are not intended to describe an ultimate or absolute condition. Rather, it should be appreciated that these terms are intended to describe a condition that is relative to a desired level of accuracy represented by the magnitude of the desired difference between two or more entities. In various exemplary embodiments of the methods and systems according to this invention, when approaching a result that is optimal, it is satisfactory to stop at a result with a desired result, without having to reach the optimal result. In various other exemplary embodiments of the methods and systems according to this invention, when approaching a result that is maximum, it is satisfactory to stop at a result with a desired result, without having to reach the maximum result.","To search for the desired path, in various exemplary embodiments of the methods and systems according to this invention, the modified Stack algorithm according to this invention uses a priority queue Q, where partial paths are queued according to their estimated potential to have a high weight when completed. The desired path is determined as a partial path having a desired priority. In various exemplary embodiments of the methods and systems according to this invention, the potential of a partial path is the weight of the partial path adjusted by either adding an estimated completion weight, or subtracting an expected weight for the partial path, as will be discussed in greater detail below. In various exemplary embodiments of the methods and systems according to this invention, the partial path of a desired priority is a partial path with a maximum estimated potential.","In various embodiments of the methods and systems according to this invention, the partial path of a desired priority is listed at the top of the priority queue Q. In various other exemplary embodiments of the methods and systems according to this invention, the partial paths of a desired priority is listed at the bottom of the priority queue Q.","According to the modified Stack algorithm according to this invention the priority queue Qis iteratively used when searching for a decoding solution. For example, according to the modified Stack algorithm according to this invention, the most promising path (i.e., the partial path with the maximum potential) is removed from the priority queue Q. If the last vertex of this path is a sink, then the path is complete. Because it was the most promising path on the priority queue, it is an optimal path. Accordingly, the search is completed. Otherwise, the partial path is extended to a next vertex in all possible ways and for each possible next vertex, a new partial path is generated based on that original partial path with an extension to that next vertex. All of the possible new partial paths are placed and queued in the priority queue Q. The priority queue Qis updated to accommodate the new partial paths. According to the modified Stack algorithm according to this invention, the newly listed most promising path for the next iteration is removed from the priority queue Q.","In various exemplary embodiments of the methods and systems of this invention, an associative map is used to detect semantically equivalent paths and to update paths in the priority queue Q. In various exemplary embodiments of the methods and systems of this invention, a hash table is used to compare and update paths in the priority queue Q. The hash table is also used to detect semantically equivalent paths. In various exemplary embodiments of the methods and systems of this invention, the priority queue Qis implemented using a heap or a Fibonacci heap to enhance the functionality provided by the hash table.","In various exemplary embodiments of the methods and systems according to this invention, when a new path extends to a vertex of an old path that is already in the priority queue Q, the new path is semantically equivalent to the old path. There may be three different situations. First, the old path may also end at that vertex, and the new path may have a better or greater weight than the weight of the old path. In various exemplary embodiments of the methods and systems according to this invention, in this situation, the old path is updated and replaced by the new path in the priority queue Q.","In the second situation, the old path may also end at that vertex, and the weight of the new path is not better than the weight of the old path. In various exemplary embodiments of the methods and systems according to this invention, in this situation, the new path is discarded and the old path remains in the priority queue Qat its present location.","In a third, \u201cduplicate extended,\u201d situation, the new path has a weight better than that of the old path, but the old path has already been extended past that vertex where the new path joins or intersects the old path. That is, the old path has already been removed at least once from the priority queue and has been placed back in the priority queue extended to at least one additional vertex. Therefore, the old path cannot be easily updated and replaced in the priority queue. In various exemplary embodiments of the methods and systems of this invention, special techniques are introduced into the modified Stack algorithm according to this invention to deal with this problem, as discussed in greater detail below.","In various exemplary embodiments of the methods and systems of this invention, while searching the Stack graph using the Stack algorithm, paths that are being actively explored form a tree-like configuration, as discussed above in connection with . In these exemplary embodiments, each vertex in this tree is associated with a single \u201cback\u201d pointer. The back pointer points to the previous vertex on the path. Similarly, forward pointers can be associated with the vertices as well. Thus, in a \u201cduplicate extended\u201d situation, the extensions of the old path are identified and replaced.","In various other exemplary embodiments of the methods and systems of this invention, in a \u201cduplicate extended\u201d situation, the new path is simply placed into the priority queue Qalong with the old path.","In various other exemplary embodiments of the methods and systems of this invention, in a \u201cduplicate extended\u201d case, the new path is placed into a re-do queue Q, and is processed for extensions to replace the extensions of the old path. In various exemplary embodiments of the methods and systems of this invention, the re-do queue Qis configured the same as the priority queue Q, but the re-do queue Qlists only new paths generated from the duplicate extended case. Moreover, in various exemplary embodiments, the re-do queue Qis processed ahead of the priority queue Q.","A new partial path is compared to a plurality of desired partial paths to determine whether the new partial path is semantically equivalent to any one of the plurality of desired partial paths. In various exemplary embodiments of the methods and systems according to this invention, the plurality of desired partial paths are all the partial paths in the priority queue Q. In various other exemplary embodiments of the methods and systems according to this invention, the plurality of desired partial paths are the n most promising partial paths in the priority queue Q. In various other exemplary embodiments of the methods and systems according to this invention, the plurality of desired partial paths is the single most promising partial path in the priority queue Q.","Every partial path is in the priority queue Qhas a weight given by Eq. (19). Because a possibility or likelihood has a value that is less than 1, the log likelihood of each character template match contributes a negative term to a path weight. Accordingly, a shorter path, with fewer characters, would tend to have a higher weight. Accordingly, an adjustment is desirable for comparing paths of different lengths when determining their priorities.","In various exemplary embodiments of the methods and systems according to this invention, the weight of a path W(p) is adjusted by a weight-altering function W(p) to produce an adjusted weight W(p):\n\n()=()\u2212().\u2003\u2003(22)\n","In Eq. (22), the adjusted weight W(P) is the difference between the actual weight W(p) and the weight-altering function W(p). The weight-altering function W(p) defines an expected weight for the path. In various exemplary embodiments of the methods and systems according to this invention, shorter paths will have a larger value for the weight-altering function W(p). As a result, shorter paths will be weighted appropriately when compared with longer paths. Accordingly, in these exemplary embodiments, the priority queue Qis ordered by the value of the adjusted weight W(p).","In various other exemplary embodiments of the methods and systems according to this invention, partial paths are listed on the priority queue Qbased on the predicted weights. A predicted weight Wfor a complete path p that extends a partial path to a sink vertex is defined as:\n\n()=()+(),\u2003\u2003(23)\n\nwhere W(p) is an estimate of the weight of a suffix of the path.\n","As discussed above in connection with , a suffix is a group of vertices and edges representing the portion of the complete path that occurs after, that is, starting with, the last vertex of the partial path. Accordingly, in these exemplary embodiments, the priority queue Qis ordered by the predicted weight W(p).","In various exemplary embodiments of the methods and systems according to this invention, the x-coordinate of the last vertex in a partial path is used to determine W(p). Thus, a suffix of the path is defined as a group of edges E(x, p). Each edge E(x, p) connects two vertices with x-coordinates greater than or equal to the x-coordinate of the last vertex of the partial path:\n\n()={()\u2267\u2003\u2003(24)\n\nwhere x is the x-coordinate of the last vertex on the partial path.\n","There are usually a plurality of suffices for a partial path, the estimated weight of the complete path is the weight of the suffix that has the highest weight. However, we do not know the suffix with the highest weight (that is the purpose of searching). As will be described in greater detail below, we will use a path from a previous iteration of the algorithm p\u2032 that is the current best solution to estimate the weight of the suffix of a partial path p:\n\n()=((\u2032)).\u2003\u2003(25)\n","As discussed above in connection with , a suffix in Eq. (25) starts at a point  with the x-coordinate of the end vertex of the last character of the partial path . However, the point  may be away from a vertex on the previous path p\u2032 used to estimate the weight of the suffix. Accordingly, to have a desired accuracy in determining the priority of the partial path, in various exemplary embodiment of the methods and systems according to this invention, an interpolation is used:\n\n((\u2032))+(, ()),\u2003\u2003(26)\n\nwhere vis a vertex of p\u2032 with the smallest x-coordinate among all vertices with x-coordinates greater than or equal to the x-coordinate xof the last vertex  of the partial path . Accordingly, the edge e(v, v) on the path p, indicated as the edge  in , crosses x-coordinate xof the last vertex . Thus, the portion of the previous path p\u2032 between the last vertex  of the partial path and the next vertex  is obtained by an interpolation using the edge e(v, v).\n","In various exemplary embodiments of the methods and systems according to this invention, linear interpolation is used, where",{"@attributes":{"id":"p-0140","num":"0139"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","j"]},"mo":",","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"v","mrow":{"mi":"k","mo":"-","mn":"1"}},{"mi":["v","k"]}],"mo":","}}}}},{"mfrac":{"mrow":[{"msub":[{"mi":["x","k"]},{"mi":["x","j"]}],"mo":"-"},{"msub":[{"mi":["x","k"]},{"mi":"x","mrow":{"mi":"k","mo":"-","mn":"1"}}],"mo":"-"}]},"mo":"\u2062","mrow":{"mrow":{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"v","mrow":{"mrow":{"mi":"k","mo":"-","mn":"1"},"mo":","}},{"mi":["v","k"]}],"mo":"\u2062"}}},"mo":"."}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"27"}}]}}}}},"In various other exemplary embodiments of the methods and systems according to this invention, other interpolation functions, such as non-linear interpolation, can be used.","To improve decoding quality, especially in cases where a received image contains distortion due to, for example, coffee stains or poor image quality in copies near the bindings of documents, it is desirable to iteratively apply the Stack algorithm, using the solution from one iteration as the hypothesis for the next iteration. In various exemplary embodiments of the methods and systems according to this invention, an iteration process is used to approximate a solution of a desired quality. In this iteration process, the Stack algorithm is applied iteratively to obtain a series of solutions p, p, . . . , p, . . . , where for each iteration i, the solution of a previous iteration p is used to define the estimate of a suffix in a next iteration. That is:",{"@attributes":{"id":"p-0143","num":"0142"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msubsup":{"mi":["W","f"],"mrow":{"mo":["[","]"],"mi":"i"}},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["p","j"]}}},{"mrow":[{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"E","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","j"]},"mo":",","msup":{"mi":"p","mrow":{"mo":["[","]"],"mrow":{"mi":"i","mo":"-","mn":"1"}}}}}}}},{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","j"]},"mo":",","mrow":{"mo":["(",")"],"mrow":{"msubsup":[{"mi":"v","mrow":[{"mi":"k","mo":"-","mn":"1"},{"mo":["[","]"],"mrow":{"mi":"i","mo":"-","mn":"1"}}]},{"mi":["v","k"],"mrow":{"mo":["[","]"],"mrow":{"mi":"i","mo":"-","mn":"1"}}}],"mo":","}}}}}],"mo":"+"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"28"}}]}}}}},"In various other exemplary embodiments of the methods and systems according to this invention, Eq. (22) is used in the iteration process. That is:\n\n()=()\u2212(),\u2003\u2003(29)\n\nAs a result, the solution of the previous iteration becomes the expectation for the next iteration. That is:\n",{"@attributes":{"id":"p-0145","num":"0144"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"msubsup":{"mi":["W","e"],"mrow":{"mo":["[","]"],"mi":"i"}},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["p","j"]}}},{"mrow":[{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mover":{"mi":["S","_"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","j"]},"mo":",","msup":{"mi":"p","mrow":{"mo":["[","]"],"mrow":{"mi":"i","mo":"-","mn":"1"}}}}}}}},{"mover":{"mi":["I","_"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","j"]},"mo":",","mrow":{"mo":["(",")"],"mrow":{"msubsup":[{"mi":"v","mrow":[{"mi":"k","mo":"-","mn":"1"},{"mo":["[","]"],"mrow":{"mi":"i","mo":"-","mn":"1"}}]},{"mi":["v","k"],"mrow":{"mo":["[","]"],"mrow":{"mi":"i","mo":"-","mn":"1"}}}],"mo":","}}}}}],"mo":"+"}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"30"}}]}}}},"br":[{},{},{}],"in-line-formulae":[{},{}],"i":[{"o":"S"},"x, p","v","\u2208p|K","v","x},"],"sub":["k ","x","k"]},{"@attributes":{"id":"p-0146","num":"0145"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mover":{"mi":["I","_"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","j"]},"mo":",","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"v","mrow":{"mi":"k","mo":"-","mn":"1"}},{"mi":["v","k"]}],"mo":","}}}}},{"mfrac":{"mrow":[{"msub":[{"mi":["x","j"]},{"mi":"x","mrow":{"mi":"k","mo":"-","mn":"1"}}],"mo":"-"},{"msub":[{"mi":["x","k"]},{"mi":"x","mrow":{"mi":"k","mo":"-","mn":"1"}}],"mo":"-"}]},"mo":"\u2062","mrow":{"mrow":{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"v","mrow":{"mi":"k","mo":"-","mn":"1"}},{"mi":["v","k"]}],"mo":","}}},"mo":"."}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"32"}}]}}}}},"As shown in Eqs. (29)-(32), Wis a complementary part of the likelihood of p.","In various exemplary embodiments of the methods and systems according to this invention, Eq. (29) is modified to:\n\n()=()\u2212\u03b1(),\u2003\u2003(33)\n\nwhere \u03b1 is a parameter to enhance convergence to a solution p of a desired quality.\n","In various exemplary embodiments of the methods and systems according to this invention, \u03b1 is slightly greater than 1, for example \u03b1=1.01. the direction of favoring shorter paths. In an explosive regime, no hypothesis can be identified as being promising enough to extend through the graph. Instead, lots of short hypotheses are processed. As a result, a search originally intended only for a partial Stack graph tends to develop into a full and exhausting search in the whole Stack graph. Consequently, the overall cost quickly becomes prohibitive. Accordingly, having the path search through the Stack graph enter an explosive regime is undesirable and should be prevented.","In various exemplary embodiments of the methods and systems according to this invention, using the modified Stack algorithm according to this invention includes testing to detect when the search process has entered an explosive regime of the iteration process. When entry into an explosive regime is detected, the search is terminated. In such a circumstance, a solution p, determined in the last successful iterative step before the termination of the search, is retained as the final solution of the search process, even if this solution has does not meet the desired quality.","In document image decoding, template matching is costly. As discussed above, in various exemplary embodiments of the methods and systems according to this invention, using the modified Stack algorithm according to this invention reduces template matching by using a hash table, so that template matching is not repeated for characters reached by alternative paths, when the only difference between two or more paths to the same portion of the image is in the linguistic context. For example, many edges in the various paths of the graph shown in , where the paths correspond to the same portion of the image, can share the same template matching values. Also, as discussed above, in various other exemplary embodiments of the methods and systems according to this invention, using the modified Stack algorithm according to this invention reduces template matching by exploring only the most promising hypotheses and avoiding exploring the entire graph G.","To further reduce template matching, in various exemplary embodiments of the methods and systems according to this invention, using the modified Stack algorithm according to this invention comprises using a provisional weight in a bounding approach. This bounding approach uses an inexpensive, fast determination of the value of the template match that is an upper bound on the actual template match value. In various exemplary embodiments, this is implemented by defining a provisional weight for a partial path using an upper bound on a template match for the last character on the partial path. The partial path is listed on the priority queue Qaccording to the provisional weight of the partial path. The expensive determination of the actual weight of the partial path is performed only if the partial path, based on the corresponding provisional weight, is found to be the most promising path on the priority queue. This approach thus reduces the amount of the expensive determination of the actual weights of partial paths who are never found to be optimal in view of the provisional weights determined for those partial paths.",{"@attributes":{"id":"p-0153","num":"0152"},"figref":"FIG. 4","b":"342"},"Accordingly, a provisional path weight is defined for the partial path as the sum of the weight of the partial path and the weight of the upper bound of the extension:",{"@attributes":{"id":"p-0155","num":"0154"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"msup":{"mi":["W","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"p"}},{"mrow":[{"munderover":{"mo":"\u2211","mrow":[{"mi":"i","mo":"=","mn":"1"},{"mi":"n","mo":"-","mn":"1"}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"v","mrow":{"mi":"i","mo":"-","mn":"1"}},{"mi":["v","i"]}],"mo":","}}}},{"msup":{"mi":["W","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"v","mrow":{"mi":"n","mo":"-","mn":"1"}},{"mi":["v","n"]}],"mo":","}}}],"mo":"+"}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"34"}}]}}}},"br":[{},{}],"in-line-formulae":[{},{}],"i":["W","v",", v","W","v",", v"],"sub":["n\u22121","n","n\u22121","n"]},"As is indicated in Eq. (34), a provisional weight of a path includes the actual edges of the path and an extending edge having a weight that is at least as great as the actual weight of the extending edge.","In various exemplary embodiments of the methods and systems according to this invention, when a path to vertex vis being extended to a next vertex v, a determination is made whether the template match value for the portion of the image corresponding to the x position of the edge (v, v) has already been determined. If the template match value has already been determined, then an actual weight based on the prior matching is assigned to the path and the path with the extension from vto vis added to the priority queue. On the other hand, if the template match value has not been determined, an inexpensive upper bound weight is used for the edge extending between the vertices vand vto generate a provisional weight and the path with the extension from vto vis added to the priority queue with the provisional weight. Only the provisionally weighted paths that are taken from the priority queue Qfor extension are redetermined with actual weights, and then requeued.","In various exemplary embodiments of the methods and systems according to this invention, provisionally weighted paths are actually weighted before a duplicate path reduction process is performed, such as the duplicate path reduction process discussed above in connection with the use of a hash table. In various exemplary embodiments of the methods and systems according to this invention, a newly extended provisional path having an upper bound that is less than the weight of a semantically equivalent, actually weighted path is discarded.",{"@attributes":{"id":"p-0159","num":"0158"},"figref":"FIG. 5","b":["100","110","120","130","140","150"]},{"@attributes":{"id":"p-0160","num":"0159"},"figref":"FIG. 6","b":["200","210","220","250","230","240","210"]},"In step S, the partial path is explored for a solution. Next, in step S, a determination is made whether the exploration for a solution is successful. If so, operation jumps to S, where operation of the method ends. Otherwise, if not, operation returns to step S.",{"@attributes":{"id":"p-0162","num":"0161"},"figref":"FIG. 7","b":["300","310","315","320","335","325"]},"In step S, a determination is made whether there is a next redundant second partial path in the priority queue that can be selected. If not, operation jumps to step S, where operation of the method ends. Otherwise, operation continues to step S, where a next redundant second partial path is selected from the priority queue. Operation then returns to step S.","In step S, a determination is made whether the second partial path has been extended. If not, operation jumps to step S. Otherwise, operation continues to step S. In step S, the first partial path is placed in a re-do queue. Next, in step S, the re-do queue is processed and the first partial path is extended. This may cause additional paths to be added to the re-do queue. After all extensions of the second partial path are replaced by the extensions of the first partial path, the re-do queue will be empty. Operation then jumps to step S.","In step S, a determination is made whether the weight of the first partial path is greater than the weight of the second partial path. If so, operation jumps to step S. Otherwise, operation proceeds to step S. In step S, the first partial path is discarded. Operation then jumps to step S. In contrast, in step S, the second partial path is replaced by the first partial path. Operation then continues to step S where operation of the method ends.",{"@attributes":{"id":"p-0166","num":"0165"},"figref":"FIG. 8","b":["400","410","420","430","470","460"]},"In step S, a solution is obtained by applying the Stack algorithm to the current Stack graph. Next, in step S, a determination is made whether the solution is of a desired quality. If not, operation continues to step S, where the current hypothesis is replaced by the solution. That is, the solution becomes the current hypothesis. Then, operation returns to step S. Otherwise, operation jumps to step S.","In contrast, in step S, the previous hypothesis is used as a solution. Operation then proceeds to step S, where operation of the method ends.","In various exemplary embodiments of the methods and systems according to this invention, the desired quality used in step S is predetermined. In various other exemplary embodiment of the methods and systems according to this invention, the desired quality used in step S is dynamically determined during the application of the Stack algorithm.",{"@attributes":{"id":"p-0170","num":"0169"},"figref":["FIGS. 9-11","FIG. 9"],"b":["500","505"]},"Next, in step S, Stack algorithm is applied to find a new path P. This step will be discussed in greater detail below in connection with . Then, in step S, a determination is made whether the Stack algorithm exploded. If it is determined in step S that the Stack algorithm exploded in step S, operation proceeds to step S, where the previous complete path P\u2032 is returned as the output of operation, and operation of the method ends. Otherwise, if it is determined in step S that the Stack algorithm did not exploded in step S, operation jumps to step S.","In step S, a determination is made whether the new complete path P is of a desired quality. If so, operation proceeds to step S, where operation returns the complete path P as the output of operation of the method and operation of the method ends. On the other hand, if it is determined in step S that the new complete path P is not of the desired quality, operation jumps to step S. In step S, the new complete path P replaces the previous complete path P\u2032 and operation returns to step S.",{"@attributes":{"id":"p-0173","num":"0172"},"figref":["FIG. 10","FIG. 9","FIG. 10"],"b":["510","540"]},"In step S, a main queue is initialized, as a priority queue, with the source node, and a re-do queue is initialized as being empty. Next, in step S, a highest priority path is removed from the re-do queue, if the re-do queue is not empty. In the case when the re-do queue is empty, a highest priority path is removed from the main queue.","Next, in step S, a determination is made whether the removed path is provisionally scored. If it is determined that the removed path is provisionally scored, operation proceeds to step S, where the removed path is rescored and requeued, and operation returns to step S. On the other hand, if it is determined that the removed path is not provisionally scored, operation jumps to step S.","In step S, a determination is made whether a sink is reached. If so, operation jumps to step S, where the removed path is returned as the output of operation and operation of the method returns to step S in . Otherwise, operation continues to step S.","In step S, a determination is made whether the Stack algorithm is in explosive regime. If so, operation jumps to step S, where operation of the method returns to step S in  with an indication that the Stack algorithm exploded. Otherwise, operation continues to step S.","In step S, all extensions to the removed path are generated and scored provisionally using weights from the previous path P\u2032. Then, in step S, semantic equivalence for extensions are detected and the extensions are queued accordingly, as will be discussed in greater detail below in connection with . Operation then returns to step S.",{"@attributes":{"id":"p-0179","num":"0178"},"figref":["FIG. 11","FIG. 10","FIG. 11"],"b":["585","600"]},"In step S, a determination is made whether a partial path to a node has been previously processed. If so, operation proceeds to step S. Otherwise, operation jumps to step S, where the partial path is queued in the main queue and operation returns to step S in .","In step S, a determination is made whether the score of the partial path is better than that of the previously processed node. If so, operation proceeds to step S. Otherwise, operation jumps to step S, where the partial path is discarded and operation returns to step S in .","In Step S, a determination is made whether the previously processed node is still in the main queue. If so, operation proceeds to step S. Otherwise, operation jumps to step S, where the partial path is placed in the re-do queue and operation returns to step S in .","In step S, the queue entry in the main queue for the previously processed node is replaced with the partial path and the weight of this path in the main queue is updated. Thereafter, operation of the method returns to step S in .",{"@attributes":{"id":"p-0184","num":"0183"},"figref":["FIG. 12","FIG. 12"],"b":["400","400","410","420","430","440","450","460","470","480","490","500","405"]},"As shown in , the document image decoding system  is, in various exemplary embodiments, implemented on a programmed general purpose of a computer. However, the document image decoding system  can also be implemented on a special purpose computer, a programmed microprocessor or microcontroller in peripheral integrated circuit elements, an ASIC or other integrated circuit, a digital signal processor, a hard wired electronic or logic circuit such as a discrete element circuit, a programmable logic device such as a PLD, PLA, FPGA or PAL, or the like. In general, any device, capable of implementing a finite state machine that is in turn capable of implementing the flowcharts shown in  can be used to implement the document image decoding system .","The I\/O interface  interacts with the outside of the document image decoding system . For example, the I\/O interface  receives an image from an image data source  over a link . The I\/O interface  also outputs a solution to an image sink  over a link . The I\/O interface  may also be connected to one or more user input devices and\/or one or more output devices, such as an interactive screen, or the like.","As shown in , the memory  can be implemented using any appropriate combination of alterable, volatile or non-volatile memory or non-alterable or fixed, memory. The alterable memory, whether volatile or non-volatile, can be implemented using any one or more of static or dynamic RAM, a floppy disk and disk drive, a writeable or re-writeable optical disk and disk drive, a hard drive, flash memory or the like. Similarly, the non-alterable or fixed memory can be implemented using any one or more of ROM, PROM, EPROM, EEPROM, an optical ROM, such as a CD-ROM or DVD-ROM disk and disk drive or the like.","The memory  stores information received from the I\/O interface , such as image data received by the I\/O interface . The memory  also stores information and\/or data from various ones of the circuits, routines or applications - of the document image decoding system  during or at intermediate steps of the document image decoding process.","As shown in , the memory  includes one or more of an image portion , which stores received images; a graphic configuration portion , which stores vertices, edges, and the like, for a Stack graph; a weight portion , which stores weights of edges, paths, suffices, and the like, and provisional weights; a priority queue portion , which stores information related to the priority queue; a re-do queue portion , which stores information related to the re-do queue; a solution portion , which stores decoding solutions, such as text strings recognized from the received document image; and\/or a quality portion , which stores quality requirements, such as a desired quality that is used in a iteration process.","As shown in , the one or more control and\/or data busses and\/or application programming interfaces  provide communication and data transfer among various ones of the circuits, routines or applications - of the document image decoding system . The controller  provides instructions to various ones of the circuit, routine or application - of the document image decoding system .","In the document image decoding system  shown in , the graph searching circuit, routine or application  explores partial paths and searches for solutions, e.g., recognized text strings, in a Stack graph. The weight determining circuit, routine or application  determines weights for various paths, including determining template matching components, language model components, interpolations, and\/or the parameters \u03bb and\/or \u03b1. The queuing circuit, routine or application  queues various paths in various queues, such as the priority queue and the re-do queue, according to various criteria such as weights and provisional weights.","The equivalence determining circuit, routine or application  determines whether a first path is semantically equivalent to a second path, and, if the first path is semantically equivalent to the second path, decides whether to discard the first path or to replace the second path in a priority queue with the first path. The upper bound circuit, routine or application  determines an upper bound of the weights of a plurality of possible extended paths of a partial path. The iteration circuit, routine or application  manages an iteration process, including generating hypothesis, checking the quality of solutions and replacing hypotheses with solutions. The explosive regime detecting circuit, routine or application  detects whether the Stack algorithm is in an explosive regime and, if the Stack algorithm is in an explosive regime, terminates the application of the Stack algorithm and retains the last successful solution.","The image data source  can be any one of a number of different sources, such as a digital copier, a facsimile device, a digital camera, a scanner, or a locally or remotely located computer, or any other known or later-developed device that is capable of generating electronic image data. Similarly, the data source  can be any suitable device that stores and\/or transmits electronic image data, such as a client or a server of a network or the Internet, and especially the World Wide Web.","In various exemplary embodiments, the data source  can be integrated with the document image decoding system , such as in a digital optical character recognizer having an integrated image receiver, such as a scanner. In various other exemplary embodiments, the image data source  can be connected to the I\/O interface  over the link . The link  can be implemented using a connection device such as a modem, a local area network, a wide area network, an intranet, the Internet, and any other distributed processing network, or any other known or later-developed connection structure.","It should be appreciated that, while the electronic image data can be generated at the time of decoding a document image from an original physical document, the electronic image data could have been generated at any time in the past. The image data source  is thus any known or later-developed source which is capable of supplying electronic image data to the I\/O interface . For example, the image data source  may be a data carrier such as a magnetic storage disk, CD-ROM or the like, or a host computer that contains scanned image data. Thus, the image data source  can be any known or later-developed source that is capable of providing image data to the document image decoding system  according to this invention.","Also, the data sink  can be any known or later-developed device that is capable of receiving a recognized text string output by the document image decoding system  and either storing, transmitting or displaying the solutions. In various exemplary embodiments, the data sink  can be integrated with the document image decoding system . In various other exemplary embodiments, the data sink  can be connected to the I\/O interface  over the link . The link  can be implemented using a connection device such as a modem, a local area network, a wide area network, an intranet, the Internet, and any other distributed processing network, or any other known or later-developed connection device.","In various exemplary embodiments of the operation of the document image decoding system  according to this invention, a user uses the document image decoding system  shown in  to generate a recognized text string from a received document image. In operation, the I\/O interface  of the document image decoding system , under control of the controller , receives document image data from the image data source  over the link  and stores the received document image data in the image portion . The graph searching circuit, routine or application , under control of the controller , then uses document image decoding and the modified Stack algorithm according to this invention to generate a Stack graph from the received document image and to search for partial paths within the generated Stack graph. The weight determining circuit, routine or application , under control of the controller , determines a weight for each partial path. The queuing circuit, routine or application , under control of the controller , queues the various partial paths in the priority queue according to the weights of the partial paths and, under control of the controller , stores the updated priority queue in the priority queue portion . The results from graph searching are stored in the graph configuration memory . The determined weights are stored in the weight portion .","The upper bound circuit, routine or application , under control of the controller , determines an upper bound of a plurality of possible extending edge weights for the partial path. For a new partial path, the weight determining circuit, routine or application , under control of the controller , determines a provisional weight for the partial path based on the weight of the partial path and the upper bound of the plurality of a possible extending edge weights of the partial path. The queuing circuit, routine or application , under control of the controller , queues the partial path according to the provisional weight of the partial path, and, under control of the controller , stores the updated priority queue in the priority queue portion .","In various exemplary embodiments of the document image decoding system , the graph searching circuit, routine or application , under control of controller , removes a partial path of a desired priority from the priority queue stored in the priority queue portion . The queuing circuit, routine or application  determines whether the partial path is queued according to the provisional weight of the partial path. When the queuing circuit, routine or application , under control of the controller , determines that the partial path is queued according to the provisional weight of the partial path, the weight determining circuit, routine or application , under control of the controller , determines an actual weight of the partial path. Then, the queuing circuit, routine or application , under control of the controller , re-queues the partial path in the priority queue according to the actual weight of the partial path determined by the weight determining circuit, routine or application .","On the other hand, when the queuing circuit, routine or application  determines that the partial path is not queued according to a provisional weight of the partial path, the graph searching circuit, routine or application , under control of the controller , explores a solution for the partial path. If the exploration is successful, the graph searching circuit, routine or application , under control of the controller , stops the exploration. Otherwise, if the graph searching circuit, routine or application  determines that the exploration is not successful, the graph searching circuit, routine or application , under control of the controller , returns to the priority queue portion  to select a next partial path of a desired priority and to repeat the exploration for the selected next partial path.","In various exemplary embodiments, the equivalence determining circuit, routine or application  compares a first partial path with a second partial path on the priority queue. The equivalence determining circuit, routine or application , under control of the controller , determines whether the first partial path is semantically equivalent to the second partial path. If the equivalence determining circuit, routine or application  determines that the first partial path is not semantically equivalent to the second partial path, the equivalence determining circuit, routine or application , under control of the controller , selects a next second partial path on the priority queue, until the first partial path is compared to each second partial path.","Each time the first partial path is determined to be semantically equivalent to the current selected second partial path, the equivalence determining circuit, routine or application , under control of the controller , compares the weight of the first partial path with the weight of the current second partial path. If the weight of the first partial path is not greater than the weight of the current second partial path, the equivalence determining circuit, routine or application , under control of the controller , discards the first partial path. In this case, if the first partial path was originally on the priority queue, the queuing circuit, routine or application , under control of the controller , updates the priority queue and stores the updated priority queue in the priority queue memory .","On the other hand, if the weight of the first partial path is greater than the weight of the second partial path, the equivalence determining circuit, routine or application , under control of the controller , determines whether the second partial path has been extended, based on the information stored at the graph configuration memory . If the equivalence determining circuit, routine or application  determines that the second partial path has been extended, the queuing circuit, routine or application , under control of the controller , queues the first partial path in a re-do queue and stores the information of the re-do queue in the re-do queue memory . If the equivalence determining circuit, routine or application  determines that the second partial path has not been extended, the equivalence determining circuit, routine or application , under control of the controller , replaces the second partial path by the first partial path. Accordingly, the queuing circuit, routine or application , under control of the controller , updates the priority queue, and stores the updated priority queue in the priority queue memory .","Where the first partial path is listed in the re-do queue, the graph searching circuit, routine or application , under control of the controller , explores the first partial path listed on the re-do queue. The weight determining circuit, routine or application , under control of the controller , determines the weights of the extended, first partial path. The queuing circuit, routine or application , under control of the controller , queues the extended, first partial path in the priority queue to replace the extended second partial path, and stores the updated priority queue in the priority queue memory .","It should be appreciated that, in some exemplary embodiments, one or more of the graph searching circuit, routine or application , the weight determining circuit, routine or application , the queuing circuit, routine or application , the equivalence determining circuit, routine or application , the upper bound determining circuit, routine or application , the iteration circuit, routine or application , and\/or the explosive regime detecting circuit, routine or application  can be omitted, should the particular functions implemented by those circuits, routines or applications be left out of the particular implementation of the modified Stack algorithm according to this invention.","Similarly, it should be appreciated that, in some other exemplary embodiments, one or more of the image memory , the graphic configuration memory , the weight memory , the priority queue memory , the re-do queue memory , the solution memory  and\/or the quality memory  can be omitted.","While this invention has been described in conjunction with the exemplary embodiments outlined above, it is evident that many alternatives, modifications and variations will be apparent to those skilled in the art. Accordingly, the exemplary embodiments of the invention, as set forth above, are intended to be illustrative, not limiting. Various changes may be made without departing from the spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Various exemplary embodiments of the methods and systems of this invention will be described in detail, with reference to the following figures, wherein:",{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
