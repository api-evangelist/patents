---
title: User interface contrast filter
abstract: A method of defining a dynamically adjustable user interface (“UI”) of a device is described. The method defines multiple UI elements for the UI, where each UI element includes multiple pixels. The method defines a display adjustment tool for receiving a single display adjustment parameter and in response adjusting the appearance of the UI by differentiating display adjustments to a first set of saturated pixels from the display adjustments to a second set of non-saturated pixels.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08441499&OS=08441499&RS=08441499
owner: Apple Inc.
number: 08441499
owner_city: Cupertino
owner_country: US
publication_date: 20090805
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["The present invention relates to a display control item for adjusting display settings of a user interface.","Many applications generate user interfaces that include various user interface items (e.g., buttons, menu items, selection controls, etc.), background colors and\/or images, and content display areas (e.g., an image editing pane, a video playback pane, etc.). These various user interface component may include black and white sections, grayscale sections, and colored sections that span a range of color saturation values.","In many cases, an application user may wish to adjust the display of the user interface generated by the application. For instance, a user may wish to adjust the brightness or contrast of the display based on ambient lighting conditions, personal preferences, etc. In some cases, while a user wishes to change the display settings of particular user interface items such that certain features or aspects of the user interface items may provide better visibility to the user, the user does not wish to affect the display of any content display areas. Current applications do not allow a user to easily adjust the display of user interface items without affecting the display of any content that may be included in a content display area of the user interface.","In addition, a user may wish to adjust the display of various user interface items such that dark or dully-colored user interface items are affected more than brightly-colored or black and white user interface items. Typically, applications that allow display adjustments affect all areas of the user interface equally.","Thus, there is a need for a display adjustment system that allows a user to change user interface display settings without affecting the display settings of any content display areas included in the user interface. In addition, there is a need for a display adjustment control that treats brightly-colored user interface items differently than dully-colored or grayscale user interface items. Furthermore, the display adjustment system must efficiently generate, and\/or retrieve from storage, the various user interface items when changes in the display settings occur.","Some embodiments provide a method of defining a dynamically adjustable user interface (\u201cUI\u201d) of a device. The method defines multiple UI elements for the UI, with some UI elements defined by reference to saturated colors, other UI elements defined by reference to non-saturated colors, and still other UI elements defined by reference to both saturated and non-saturated colors. The method defines a display adjustment tool for receiving a single display adjustment parameter, and in response, adjusting the appearance of the UI by differentiating display adjustments to saturated colors of the UI elements from the display adjustments to non-saturated colors of the UI elements. Specifically, the display adjustment control in some such embodiments changes the appearance of non-saturated colors more than it changes the appearance of saturated colors for a particular change in the display adjustment parameter.","In some embodiments of the invention, the display adjustment tool includes (1) a user-modifiable display adjustment control for defining the display adjustment parameter, and (2) a display adjustment module for adjusting the appearance of the UI by differentiating display adjustments to saturated colors of the UI elements from the display adjustments to non-saturated colors of the UI elements. Instead of, or in conjunction with, the user-modifiable display adjustment control, the display adjustment tool of some embodiments includes a light-sensor module that produces a display adjustment parameter in response to changes to light conditions in the environment in which the device operates. In some embodiments, the device has a light sensor that produces a signal that specifies changes in light conditions, and provides this signal to the light-sensor module, which in turn produces the display adjustment parameter. From this parameter, the display adjustment module can then adjust the appearance of the UI elements for the new light condition.","The method of some embodiments does not adjust the color of areas of the UI that contain content (e.g., thumbnail images, digital video, a digital image, etc.). In other words, some embodiments perform the color adjustment operations for only the non-content elements (e.g., the user selectable UI elements, the UI background design, the UI descriptive text, etc.) and not for the content elements of the UI. Also, some embodiments allow certain non-content UI elements to be explicitly or implicitly masked from the color adjustment operations.","Some embodiments cache UI elements to improve application performance when adjusting the appearance of the UI. In some embodiments, the cache stores UI elements that were previously processed for a particular value of the display adjustment parameter. Such cached UI elements may be re-used by accessing the cached copies rather than re-processing the UI elements stored on disk. Some embodiments share the cached UI elements across multiple applications having multiple UIs.","In the following detailed description of the invention, numerous details, examples, and embodiments of the invention are set forth and described. However, it will be clear and apparent to one skilled in the art that the invention is not limited to the embodiments set forth and that the invention may be practiced without some of the specific details and examples discussed.","Some embodiments provide a single display adjustment control that optimizes the appearance of a UI for different lighting conditions. In some embodiments, the display adjustment control differentiates the treatment of saturated pixels in the UI from non-saturated pixels in the UI. Specifically, the display adjustment control in some such embodiments changes the appearance of non-saturated pixels more than it changes the appearance of saturated pixels for a particular change in lighting conditions.","For some embodiments of the invention,  illustrates an application UI  with one such display adjustment control. Specifically, this figure illustrates the UI  at three different stages -, a first stage  where the display adjustment control  (a contrast control in this example) is positioned such that the contrast is at a minimum level, a second stage  that is after the adjustment control  has been moved to a mid-point, and a third stage  that is after the adjustment control  has been moved to a maximum level.","As shown in this figure, in addition to the display adjustment control , the UI  includes a content display area , various UI elements  that have high color saturation values, various UI elements  that have low color saturation values, and a UI background area . The UI elements are for receiving input from a user and\/or providing information to the user. These UI elements may include various buttons, menu selection items, indicators, etc. The UI elements, as displayed to a user, may include black and white, grayscale, and\/or color pixels. Such UI elements may be arranged in different configurations in different applications. The content display area  is for displaying various representations of content (e.g., thumbnail images, digital video, a digital image, etc.). Different UIs may have various different backgrounds that include some combination of pixels of various different colors, one or more images, etc.","The UI elements  and  may be used to receive input from a user and\/or to provide information to the user. These UI elements may include various buttons, menu selection items, indicators, etc. These UI elements may include black and white, grayscale, and\/or color pixels. Although the example of  represents high color saturation elements  and low color saturation elements  as being placed in particular locations of the UI , one of ordinary skill will recognize that the UI elements may be arranged in different configurations in different applications. The background area  is shown in this example as white, indicating a uniform background color. Different UIs may include various different backgrounds that may include pixels of various different colors, one or more images, etc.","The operation of the UI display adjustment will now be described by reference to the state of this UI during the first, second, and third stages - that are illustrated in . In the first stage , the display control  is positioned at its minimum value. As shown, the content display area  is represented as completely white, while the high color saturation UI elements  and the low color saturation UI elements  are represented with a first fill pattern and a second fill pattern, respectively. In addition, the UI background  is shown as completely white, indicating that the background has a different color (and color saturation) than that of elements  or .","In the second stage , the display control  has been moved to a mid-point value. The change in the display control does not affect the display of the content display area , which is still shown as a completely white area of the UI . However, one of ordinary skill in the art will recognize that some embodiments may also update each content display area based on the selected display control value. In some embodiments, each content display area may be updated (or not updated) based on a user selected option, a default condition, or some other appropriate criteria. The change in the display control  setting has affected the fill pattern shown for the high color saturation elements  and the low color saturation elements . In some embodiments, the UI background area  may also be changed to increase contrast between the background and the various UI items -.","As shown in the second stage , the display of the high color saturation elements  and the low color saturation elements  have been updated such that the fill patterns are more dense in the second stage  than the first stage . In order to optimize the contrast increase, in this example the high color saturation fill pattern has had its density increased by a factor of two while the low color saturation fill pattern has been increased by a factor of three. Thus, in this example, the elements with lower color saturation values  are affected more than the elements with high color saturation values .","In the third stage , the display control  has been moved to a maximum value. As above, the change in the display control does not affect the display of the content display area , which is still shown as a completely white area. The change in the display control  setting has again affected the fill pattern shown for the high color saturation elements  and the low color saturation elements .","As shown, the fill pattern of the UI background area  has not been changed from the second stage  in response to the movement of the display control . In contrast, the display of the high color saturation elements  and the low color saturation elements  have been updated such that the fill patterns are more dense in the third stage  than the second stage . As above, the high color saturation fill pattern has had its density increased by a factor of two in this example while the low color saturation fill pattern has been increased by a factor of three. Thus, the elements with lower color saturation values  are affected more than the elements with high color saturation values .","Although the example of  and many of the examples that follow below show various specific UIs, controls, display areas, etc., one of ordinary skill in the art will recognize that other embodiments may implement these elements in different ways. For instance, instead of a display adjustment control , some embodiments may utilize pull-down or pop-up menu selections to control the display adjustment. In addition, different UIs may include different variations of high color saturation areas, low color saturation areas, content display areas, etc.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 2","FIG. 1"],"b":["200","200","200"]},"The process begins when it receives (at ) an update to a display adjustment parameter (e.g., brightness, contrast, etc.). The update to the display parameter may be received in various ways. For example, the display parameter may be received by quantifying the slider position of a UI control element such as display adjustment control . Alternatively and\/or conjunctively, the display parameter may be updated based on a pull-down or pop-up menu selection, a combination of keystrokes, a \u201chot-key\u201d (e.g., selecting \u201cctrl-alt-brightness+\u201d or \u201cctrl-alt-brightness\u2212\u201d, where \u201cbrightness+\u201d and \u201cbrightness\u2212\u201d are hotkeys provided by a keyboard or keypad), a change in ambient light as measured through a light sensor, etc. In addition, some embodiments include options that allow a user to select \u201cgo-to-max\u201d or \u201cgo-to-min\u201d such that a user may directly select a maximum or minimum value of the display adjustment parameter. In some embodiments, the process may monitor a display adjustment parameter and determine whether a change in the parameter's value has exceeded a particular threshold before continuing. In addition, some embodiments may perform process  at regular intervals, regardless of whether a display adjustment parameter has changed.","One of ordinary skill in the art will recognize that process  may be initiated in a variety of other ways. For instance, in some embodiments, a first application may receive an update to a display adjustment parameter, and issue a re-draw command to a UI drawing framework, which may cause a framework command (i.e., a function) to be called to adjust the display of UI elements of the first application. Such a UI framework may include various artwork and APIs that are used by one or more applications to render various UI items for display.","In some embodiments, the call to the framework command may further trigger redrawing of UI elements of any other applications that share the same framework with the first application such that the UI elements of the other application are dynamically updated based on the change in the display adjustment parameter of the first application.","For instance, an update to a display parameter of a first application may trigger an update to a second application which shares the same framework such that a redraw command is called for the second application to redraw its UI elements. This redrawing of the UI elements may entail recursively rendering several other UI elements of the second application's UI.","After receiving (at ) an update to the display adjustment parameter, the process retrieves (at ) a pixel for processing. In some embodiments, the pixel is from a previously-rendered version of a UI, such as UI  as shown in the first stage . One of ordinary skill in the art will recognize that although many of the operations of process  are described with reference to a single pixel, some embodiments may process multiple pixels at one time (e.g., UI items such as buttons, artwork, menu items, etc.). In addition, although the process may receive only a single pixel (e.g., when a color is specified), any number of pixels may be generated at the output (e.g., when creating a background area of a UI that includes a single color).","After retrieving (at ) a pixel from the input image, the process determines (at ) whether the pixel will be processed based on the display adjustment parameter. As described above, some embodiments modify the display of particular UI items (e.g., non-content items) based on the display adjustment parameter, while the display of other items (e.g., content items) is not updated based on the display adjustment parameter. In some of these embodiments, the UI application determines which UI items will receive processing based on the display adjustment parameter, while in other embodiments the UI framework may determine the processing to be performed on various UI items.","Some embodiments may use a mask (e.g., a content mask) to define the sections of the UI that will not be modified based on the display adjustment parameter (e.g., sections that include content). In some embodiments, the mask is simply a black and white image where the white areas include sections of the UI that will be modified based on the display adjustment parameter and the black areas include sections of the UI that will not be modified based on the display adjustment parameter. Other embodiments may mask the content display areas using various other appropriate methods. In addition, some embodiments may pass a flag or some other indication to the framework indicating the processing that will be performed on a particular UI item. Applying different processing to different items or areas of the UI will be described in more detail in sub-section I.A below. The content display area  is one example of such a UI section that is not affected by changes to the display adjustment parameter.","When the process determines (at ) that the pixel will be processed according to the modified display adjustment parameter, the process classifies (at ) the pixel based on the amount of color saturation. Otherwise, the process proceeds to operation  which will be described below. High color saturation elements  and low color saturation elements  are examples of such classification of pixels based on color saturation levels. After classifying (at ) the pixel based on the amount of color saturation, the process color corrects (at ) the pixel based on the classification. The calculation of color saturation values, classification of pixels, and the color correction operation will be described in more detail in sub-section I.B below.","After color correcting (at ) the pixel, the process filters (at ) the color correction based on the display adjustment parameter. In some embodiments, this filtering is achieved by blending, based on the display adjustment parameter, the color corrected pixel with the pixel retrieved (at ) from the input image. Thus, in the example shown in , when the display adjustment control  is placed at the far left end of the slider, the output pixel is the same as the input pixel (i.e., the blend operation selects the input pixel and ignores the color corrected pixel). In contrast, when the display adjustment control  is placed at the far right end of the slider, the blend operation selects the color corrected pixel and ignores the input pixel. When the display adjustment control  is placed at an intermediate location along the slider, the output pixel is a weighted combination (based on the slider position) of the input pixel and the color corrected pixel.","After filtering (at ) the color correction or when the process determines (at ) that the pixel will not be processed according to the modified display adjustment parameter, the process determines (at ) whether there is another pixel in the input image. When the process determines that there is another pixel in the input image, the process performs operations - as described above.","When the process determines (at ) that there are no more pixels in the input image to process, the process updates (at ) the display of the UI using the filtered color corrected pixels generated by process . Although not shown, process  may iteratively perform operations - for different layers of the UI output (e.g., background, buttons, shadows, text, etc.) before compositing the different layers and updating the display. Stages two  and three  of  illustrate two such display updates to the UI . After updating (at ) the UI display, the process ends.","One of ordinary skill in the art will recognize that although references were made to content display areas of a UI versus non-content display areas, various other criteria could be used to determine which sections of the UI receive processing as specified in operations - above. For instance, some UI elements may be intended to represent absolute color values and\/or UI elements where the color has a particular meaning (e.g., color scope, color picker, etc.), and therefore would not be adjusted by a contrast adjustment algorithm. As another example, a UI designer may prefer that certain UI items (e.g., a particular button or menu item) are not affected by changes in, for example, a contrast setting, while other UI items (e.g., other buttons or menu items) would be affected by a change in a contrast setting.","Several more detailed embodiments of the invention are described in the sections below. Section I provides a detailed description of the display adjustment operations. Next, Section II shows several example UIs as displayed based on various adjustments. Section III follows that discussion with a description of the caching of UI items to optimize performance. Section IV describes the software modules used by some embodiments to implement the display adjustment. In addition, Section IV described automatic display adjustments based on ambient lighting conditions. Section V then describes the use of an application development tool that allows application developers to define various display adjustment parameters and algorithms. Next, Section VI describes the process used to define the UI display control of some embodiments. Lastly, Section VII describes a computer system which implements some of the embodiments of the invention.","I. Display Adjustment","As mentioned above, some embodiments allow display adjustments that affect different UI elements differently. Sub-section I.A will describe a detailed example of performing different image-processing operations on different UI sections by reference to . Sub-section I.B will then describe a conceptual process used by some embodiments to adjust the UI display by reference to . Next, sub-section I.C describes, by reference to FIGS.  and -, an operational tree diagram used by some embodiments to process the UI display elements.","A. Alternative Processing of User Interface Items",{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIGS. 3-4","FIG. 1","FIG. 3"],"b":["100","300","310"]},{"@attributes":{"id":"p-0060","num":"0059"},"figref":["FIG. 4","FIG. 3"],"b":["400","300"]},"In the example of , the mask  includes various sections  that correspond to content display areas  of the UI . These sections  of the mask  are indicated by black pixels (and may alternatively be represented by an array element with a value of 0). In addition the content mask indicates non-content areas of the UI  using white pixels  (and may alternatively be represented by an array element with a value of 1). Although the example of  shows only two different processing options (i.e., black or white), some embodiments may use any number of different processing options. The different processing options allow different processing to be specified for each UI item, as appropriate. For instance, some UI items may not receive any color correction or contrast processing (e.g., any section of the UI where absolute color is important). Such alternative processing options will be described in more detail in sub-section I.C below.","In some embodiments, the application generating the UI  may generate a mask based on different previously-defined areas of the UI (e.g., content display areas, UI items such as buttons, UI items such as background colors or patterns, etc.) that are designated to receive different image processing operations. In other embodiments, the mask  may be manually generated, stored, and made available to the application that generates the UI.","In addition to the mask (or array) described above in reference to , other embodiments may define the processing to be performed on various UI items using different types of masks or data structures or using other appropriate ways. In addition, different embodiments may designate the processing to be performed using different operations than those described above. For instance, some embodiments may perform display adjustment on all the pixels included in the UI and then superimpose the content display areas over the adjusted UI.","B. Display Adjustment Algorithm",{"@attributes":{"id":"p-0064","num":"0063"},"figref":["FIG. 5","FIGS. 6-7"],"b":["500","500","240","260","200","500","200"]},"Process  begins when it receives (at ) a pixel for processing. As described above, different pixels may receive different processing. In this example, any received pixels have been designated to receive processing by process . In some embodiments, the pixel may be any pixel from a UI item that is designated, by a mask such as that described above in reference to , to receive processing based on an updated display adjustment parameter. In other embodiments, other types of masks or other methods of designating UI items for processing may be used. In addition, some embodiments may not use any mask at all and simply process all pixels from an input image using process .","After receiving (at ) a pixel for processing, the process converts (at ) the pixel from RGB color space to YIQ color space.  illustrates the RGB  and YIQ  color spaces. Specifically, this figure shows conceptual representations of the color definition properties of each color space. As shown, the RGB color space  includes three orthogonal axes, a red color axis , a blue color axis , and a green color axis . The RGB color space is an additive color space. As such, each color in the space  may be defined by specifying a red value, blue value, and green value along the axes - and then adding the three primary component colors to achieve the desired output color.","In addition to the RGB color space ,  shows the YIQ color space , which includes a Y (or luminance) axis , an I (or in-phase, orange-blue) axis , and a Q (or quadrature, purple-green) axis . Breakout section  shows a two-dimensional representation of the YIQ color space  that ignores the Y component. Although section  may typically be represented as a square, as the values along the I and Q axes may range between \u22121 and 1, in this example the section  is shown as a circle for clarity.","In order to perform (at ) the color space conversion, a matrix multiplication is used by some embodiments. This matrix multiplication may be performed in some embodiments using the following equation:",{"@attributes":{"id":"p-0069","num":"0068"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"Y"}},{"mtd":{"mi":"I"}},{"mtd":{"mi":"Q"}}]}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0.299"},{"mn":"0.587"},{"mn":"0.115"}]},{"mtd":[{"mn":"0.596"},{"mrow":{"mo":"-","mn":"0.275"}},{"mrow":{"mo":"-","mn":"0.321"}}]},{"mtd":[{"mn":"0.211"},{"mrow":{"mo":"-","mn":"0.523"}},{"mn":"0.311"}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"R"}},{"mtd":{"mi":"G"}},{"mtd":{"mi":"B"}}]}}],"mo":"\u00b7"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}},"br":{}},"Next, the process calculates (at ) a color saturation value for the pixel based on the I and Q values calculated at . The color saturation value is calculated as the distance from the origin of the I and Q axes - to the point defined by the I and Q values calculated for the pixel using an equation such as equation 1. The color saturation value is calculated in some embodiments using the following equation:\n\nSaturation=\u221a{square root over (())}\u2003\u2003(2)\n\nwhere I and Q are the values calculated using equation (1) above.\n","Since the values of I and Q are limited in range from \u22121 to 1, the calculated saturation value may range from 0 to 1. Since the Y, or luminance, value is ignored in the saturation calculation, brightness of the pixel does not affect the saturation value, only the intensity of the color of the pixel will affect the saturation value. Thus, brightly colored pixels will have a higher saturation value, while dully colored pixels (and grayscale pixels) will have a lower saturation value, and black and white pixels will have a saturation value of zero. These individual saturation values may collectively be referred to as a \u201csaturation mask\u201d that indicates saturation levels for each pixel in the input image.","After calculating (at ) the color saturation value, the process amplifies and limits (at ) the calculated saturation value. This amplification is used to increase the difference in saturation values between dully colored pixels, while limiting the difference in saturation values between brightly colored pixels.  provides a conceptual representation of the amplification and limiting of the saturation value. Specifically, the figure shows various circular two-dimensional (i.e., ignoring the Y value) representations of the YIQ space , , , and , where two of the representations  and  are before amplification and limiting of the saturation value and two representations  and  that are after the amplification and limiting.","As shown in , the first IQ space  includes two indicators and that show two saturation levels before amplification. Indicator represents pixels having a higher saturation value than indicator (i.e., higher saturation values are further away from the center of the space ). The outer edge  of the space  indicates fully saturated pixels (i.e., pixels with a saturation value of 1). IQ space  represents the results of applying amplification and limiting to the space . As shown, the saturation level shown by indicator has been moved away from the center of the circle, indicated by arrow , to an amplified saturation level shown by indicator . This movement away from the center of the color space indicates an increase in saturation level. Likewise, the saturation level shown by indicator has been moved to a location further away from the center of the circle, indicated by arrow , to an amplified saturation level shown by indicator ","Because the amplification is limited (e.g., to maintain a maximum saturation value of 1), any values greater than the maximum saturation value (i.e., points outside the outer edge  of the IQ space ) are set to the maximum saturation value. This limiting is indicated by arrow . This amplification and limiting may be performed in some embodiments by generating a mask value using the following equation:\n\nMask=Maximum[Gain\u00b7\u221a{square root over (())},1]\u2003\u2003(3)\n\nwhere I and Q are the values calculated using equation (1) above, Gain is a parameter that may be set, for example, by an application developer based on the desired performance of the display adjustment, and the Maximum function returns the larger of its two arguments (i.e., in this example, the maximum value of Mask is 1).\n","IQ space  illustrates another example representation of the saturation amplification and limiting operations. As shown, the space  has a range of values that will be set to the maximum saturation value after amplification and limiting. This range includes saturation values from 1\/Gain to 1. In other words, any saturation values greater than 1\/Gain will be set to the maximum allowed value of 1. This is indicated in the post-amplification IQ space , which shows the result of the amplification and limiting operation. As shown, the region of saturation values from IQ space  is now limited to the border of the IQ space . Although the border is drawn as a thicker line in this example to indicate that a range of saturation values have been set to the maximum saturation value, one of ordinary skill in the art will recognize that the indicator includes only those post-amplification and limiting saturation values equal to 1.","In addition to the range of values that are moved to full saturation after the amplification, IQ space  shows that the range of saturation values is increased such that the range of amplified saturation values fills the entire IQ space  (excluding the outer border ). In this manner, differences in saturation values for less-saturated pixels are increased, while the differences in saturation values for more-saturated pixels are reduced or eliminated.","The amplification parameter (\u201cGain\u201d in equation (3)) of some embodiments may be set by a UI developer to achieve the desired level of control when adjusting the UI display. In other words, the developer may use the gain parameter to set the range of saturation values calculated based on I and Q that will be designated as fully saturated after amplification and limiting, versus the range of values that will be less than fully saturated after amplification and limiting. The selection of various parameters used by some embodiments to control the UI display adjustment will be described below in Section V. In other embodiments, an end-user may be able to adjust the gain parameter either directly (e.g., by setting slider position) or indirectly (e.g., by selecting a particular display option from a menu).","Returning to process , after performing (at ) amplification and limiting of the saturation value, the process performs (at ) a first color correction operation. The first color correction operation is optimized for grayscale and dully-colored pixels (i.e., pixels with a lower calculated, amplified, and limited saturation value). The first color correction operation is performed in some embodiments using the following equation:\n\nGrayOut=(Input+GrayLift)\u00b7GrayGain\u2003\u2003(4)\n\nwhere Input refers to the original RGB values for the input pixel, and GrayGamma, GrayLift, and GrayGain are parameters that may be set based on the desired performance of the color correction operation. Although not shown explicitly, the GrayOut variable includes values corresponding to each of the R, G, and B input values used to define the input pixel.\n","Thus, as shown by equation (4), the first color correction operation includes a gamma correction operation (i.e., an allometric function), a lift adjustment (i.e., an addition operation), and a gain adjustment (i.e., a multiplication operation). The parameters (\u201cGrayGamma\u201d, \u201cGrayLift\u201d, and \u201cGrayGain\u201d) that define the properties of this first color correction operation may be set by an application developer in some embodiments such that the display adjustment of the UI is optimized. In other embodiments, similarly to the amplification parameter described above, an end-user may be able to adjust the parameters either directly or indirectly.","After performing (at ) the first color correction operation, the process performs (at ) a second color correction operation. The second color correction operation is performed based on the received input pixel, and not on the output of the first color correction operation. The second color correction operation is optimized for brightly-colored pixels (i.e., pixels with a higher calculated, amplified, and limited saturation value). The second color correction operation is performed in two stages. The first stage of the second color correction involves a saturation control operation that may be performed in some embodiments using the following equation:\n\nColor SAT=luminance(1\u2212ColorSaturation)+Input\u00b7ColorSaturation\u2003\u2003(5)\n\nwhere luminance is the luminance value of the input pixel (e.g., the \u201cY\u201d value, or a luminance value calculated from the RGB values), Input refers to the RGB values for the input pixel, and the ColorSaturation parameter may be set based on the desired performance of the color correction. For example, when ColorSaturation is set to zero, the Color SAT output will include only black and white values. Although not shown explicitly, the Color SAT variable includes values corresponding to each of the R, G, and B input values used to define the input pixel. As above, the ColorSaturation parameter may be set by an application developer, or some other appropriate way, to achieve the desired performance of the display adjustment.\n","The second stage of the color correction operation includes a gamma correction operation, a lift adjustment, and a gain adjustment. These operations may use different parameters than the first color correction operation. The second color correction operation is performed in some embodiments using the following equation:\n\nColorOut=(ColorSAT+ColorLift)\u00b7ColorGain\u2003\u2003(6)\n\nwhere ColorSAT refers to the RGB values for the input pixel after saturation control has been performed using equation (4), and ColorGamma, ColorLift, and ColorGain are parameters that may be set based on the desired performance of the color correction operation. Although not shown explicitly, the ColorOut variable includes values corresponding to each of the R, G, and B input values used to define the input pixel.\n","As above, the parameters (\u201cColorGamma\u201d, \u201cColorLift\u201d, and \u201cColorGain\u201d) that define the properties of this color correction operation may be set by an application developer in some embodiments such that the display adjustment of the UI is optimized. In other embodiments, similarly to the amplification parameter and first color correction parameters described above, an end-user may be able to adjust the parameters either directly or indirectly.","After performing (at ) the second color correction operation, the process blends (at ) the output from the first color correction operation and the output from the second color correction operation based on the amplified and limited saturation value calculated for the input pixel. Some embodiments perform this blend operation using the following equation:\n\nOutput=GrayOut\u00b7(1\u2212Mask)+ColorOut\u00b7Mask\u2003\u2003(7)\n\nwhere GrayOut includes the RGB values calculated using equation (4), ColorOut includes the RGB values calculated using equations (5) and (6), and Mask is the amplified and limited saturation level calculated using equation (3). Thus, the Output varies linearly from the GrayOut values (when Mask=0) to the ColorOut values (when Mask=1). In the range of Mask values between 0 and 1, the Output values are made up from a weighted addition of the GrayOut values and the ColorOut values.\n","When the Mask value (or amplified and limited saturation value) is 0, indicating the lowest level of color saturation, the output is provided completely by the first color correction operation (i.e., Output=GrayOut). When the Mask value is 1, indicating the highest level of color saturation, the output is provided completely by the second color correction operation (i.e., Output=ColorOut). When the Mask value is between 0 and 1, indicating a saturation value between the minimum and maximum, the output is a weighted combination of the GrayOut and ColorOut RGB values.","After performing (at ) the blend of the two color correction outputs, the process blends (at ) the output from the blend of the color correction outputs and the original input pixel values based on the display adjustment parameter. Some embodiments perform this blend operation using the following equation:\n\nFinalOut=Input\u00b7(1\u2212Bias)+Output\u00b7Bias\u2003\u2003(8)\n\nwhere Output includes the RGB values calculated using equation (7), Input includes the RGB values of the input pixel, and Bias is a display adjustment parameter that ranges from 0 to 1. Thus, the Output varies linearly from the Input values (when Bias=0) to the Output values (when Bias=1). In the range of Bias values between 0 and 1, the FinalOut values are made up from a weighted addition of the Input values and the Output values.\n","When the Bias is 0 (e.g., when a slider control such as  shown in  is placed at its minimum value), the FinalOut is the same as the original Input. When the Bias value is 1 (e.g., when a slider control such as  shown in  is placed at its maximum value), the output is provided completely by the blended color correction outputs (Output). When the Bias value is between 0 and 1, indicating a display adjustment value between the minimum and maximum, the output is a weighted combination of the Input and Output values.","In this manner, a user is able to set a single parameter (i.e., \u201cBias\u201d in the above example) that controls the display adjustment of the UI. The Bias parameter may be set by a user in a variety of ways. For instance, the slider control  shown in the example of  is one way a user may set the Bias parameter to the appropriate value between 0 and 1. Alternatively and\/or conjunctively, a user may perform a series of keystrokes, make a pull-down or pop-up menu selection, or perform some other appropriate action to set the Bias parameter. In addition, in some embodiments the Bias parameter may be automatically generated by sensing and responding to ambient light conditions, or through some other automated method.","After blending (at ) the output from the blend of the color correction outputs and the original input pixel values, the process ends. In some embodiments, the process  may be run for each pixel in the input image. Such operation was described above in reference to process .","Although the process  has been described using specific examples and with reference to certain features, actions, and details, one of ordinary skill in the art will recognize that the process may be implemented using other specific embodiments without departing from the spirit of the invention. For instance, the process may be optimized such that only one color correction operation is performed when the saturation level is at 0 or 1. As another example, some embodiments may not perform process  at all when the bias parameter is determined to be 0. In addition, some embodiments may receive input pixels in different color formats, and perform an appropriate color space transformation to generate YIQ color space values. Some embodiments may perform a transformation to another appropriate color space, such as YUV or YCbCr (i.e., a color space that separates a luminance value from chrominance values, allowing color saturation to be calculated independently of brightness). Furthermore, in some embodiments process  may be performed completely separately from process , or embedded into process  at a different location than described above.","In addition, although the process  has been described as operating on a single pixel at a time, in some embodiments multiple pixels are processed at once. These multiple pixels may include so called \u201cartwork\u201d (e.g., buttons or other UI features defined by a set of pixels), or other groupings of pixels (e.g., groupings of pixels based on the limitations of the available image processing capabilities, such as cache size). Furthermore, although the process has been described as performing particular color correction operations, one of ordinary skill will recognize that different embodiments may use one or more different types of color correction operations (e.g., using a gamma curve, a sine curve, a power curve, etc.). In some embodiments, these alternative color correction operations may be selected by an end-user, or the selection may be based on some criteria defined by the application developer or some other appropriate criteria.","C. Operational Flow and Image Compositing",{"@attributes":{"id":"p-0091","num":"0090"},"figref":["FIG. 8","FIG. 8","FIGS. 5 and 9"],"b":"800"},{"@attributes":{"id":"p-0092","num":"0091"},"figref":"FIG. 9","b":["900","900","910","930","910","920","930","910","930"]},"As shown in , the processing tree  includes various individual image-processing operations -, , and , different calculated or received parameters  and  used to direct those operations, sets of image processing operations  performed based on a display adjustment parameter, and alternative sets of processing operations  that are performed without reference to the display adjustment parameter.","As shown in , the processing tree  begins by performing a sample input operation . Such a sample input operation may include receiving a color value for a pixel, retrieving a pixel value from an input image, receiving a pixel value from storage, etc. The sampled input is then passed to a colorspace conversion operation , two different color correction operations  and , and a blend operation . The colorspace conversion  represents the same conversion described above in reference to operation  of process . The first color correction operation  is the same color correction described above in reference to operation  of process . The second color correction operation  is the same color correction described above in reference to operation  of process .","After the sample input operation, the colorspace conversion operation  performs a conversion from the received colorspace (e.g., RGB colorspace) to the desired colorspace (e.g., YIQ, YUV, or YCbCr colorspace). The output of the colorspace conversion operation  is the amplified and limited saturation level . This saturation level is the same saturation level that was calculated using equations (2)-(3) as described above in reference to operations - of process .","In addition to the colorspace conversion operation , the processing tree performs color correction   and color correction   to the sampled input. These color correction operations  and  are performed using equations (4)-(6) as described above in reference to operations - of process . As shown in , the outputs of the color correction operations  and  are passed to a blend operation . The blend operation is the same blend operation described above in reference to operation  of process . As shown, the blend operation  is controlled by the saturation level  calculated by the colorspace conversion operation . Thus, as described above in reference to operation , the blend operation  generates an output that is a weighted combination of the outputs of color correction   and color correction  , based on the saturation level  of the pixel being processed.","The output of the blend operation , as well as the output of the sample input operation  are passed to the blend operation . The blend operation  is the same blend operation described above in reference to operation  of process . As shown, the blend operation  is controlled by the display adjustment parameter . Thus, as described above in reference to operation , the blend operation  generates an output that is a weighted combination of the outputs of blend operation  and the sample input operation , based on the display adjustment parameter .","The output of blend operation  is then provided to the compositing operation . In addition, the compositing operation receives inputs from various alternative sets of image processing operations  performed based on the display adjustment parameter  and various alternative sets of image processing operations  performed without reference to the display adjustment parameter . The compositing operation then produces the final rendered result as its output.","Thus, referring to the example of , the text layer  of button , for example may be processed using operation set , based on a display adjustment parameter. In some embodiments, all pixels in the text layer  are processed through a set of operations (e.g., ) before being passed to the compositing operation .","The button color layer  of button , on the other hand, may be processed using an alternative set of processing operations  that are not affected by the value of the display adjustment parameter . In this manner, an application may process different UI items using different sets of processing operations. For instance, content display areas, for example, may be processed using one set of image processing operations, while other UI items are processed using a second set of image processing operations.","The third layer of the button , drop-shadow layer , may be processed using operation set , an alternative processing operation set , some other set of image processing operations, or even receive no processing at all before being passed to the compositing operation . Thus, the various processing paths allow a developer to completely define the processing that will be performed on not only various UI items, but the various component or layers that make up the UI items. In some embodiments, the content that is displayed in a UI is implicitly masked from particular image-processing operations as these different layers are processed (e.g., through operation set ), while the content is passed directly to the compositing operation (or receives alternative processing).","One of ordinary skill in the art will recognize that the exemplary image processing tree  shown in  may be implemented in various different ways without departing from the spirit of the invention. For instance, some embodiments may process all inputs through the same processing tree. In addition, UI items such as the button  shown in  may include various different layers with a different set of processing operations specified for each layer.","II. Display Adjustment Examples","To better explain adjusting the UI display settings for different lighting conditions, several additional examples will now be described by reference to . Specifically, these figures illustrate adjusting display settings of different UIs using different UI controls such as a slider, incremental adjustment control, etc.",{"@attributes":{"id":"p-0104","num":"0103"},"figref":"FIGS. 10-12","b":["1000","1005","1005","1000","1010","1030","1015","1025","1020","1005"]},"The operations of adjusting the UI  for different lighting conditions will now be described by reference to the state of the UI during the first, second, and third stages that are illustrated in . As shown in , in the first stage, the slider  is positioned at its minimum value. That is, the slider  is set at a position that was deemed to be optimal for a particular lighting condition (e.g., daytime, brightly-lit room).",{"@attributes":{"id":"p-0106","num":"0105"},"figref":"FIG. 11","b":["1000","1005","1000","1005","1030","1010","1025","1015","1015"]},{"@attributes":{"id":"p-0107","num":"0106"},"figref":["FIG. 12","FIG. 12"],"b":["1000","1005","1005","1020","1040","1045"]},"In the previous examples, a slider control was adjusted to change the display setting of a UI for different lighting conditions.  illustrate adjusting the display setting of a touch-screen UI  by selecting a UI button. Specifically, these figures illustrate the UI  at three different stages: a first stage in which the UI  is displayed with a low contrast setting, a second stage in which the UI is displayed with an intermediate contrast setting, and a third stage in which the UI is displayed with a high contrast setting. As shown in , the UI  includes several UI items , a content item , and a contrast control .","The operations of adjusting the UI  for different lighting conditions will now be described by reference to the state of the UI during the first, second, and third stages that are illustrated in . As shown in , in the first stage, the contrast is set to its minimum value (value not shown).",{"@attributes":{"id":"p-0110","num":"0109"},"figref":"FIG. 14","b":["1300","1330","1310","1330","1320","1300"]},{"@attributes":{"id":"p-0111","num":"0110"},"figref":"FIG. 15","b":["1300","1310","1320","1300","1300"]},"In some embodiments, the range of adjustment settings is defined (e.g., mathematically) such that the change in luminance characteristic does not affect usability of the UI (e.g., by creating artifacts, by making UI elements difficult to perceive). In some such embodiments, the range is defined such that colors of the UI elements do not have to be inverted to be viewed by a user of the UI.","Although the adjustment of the UI display has been described with reference to specific examples and features, one of ordinary skill in the art will recognize that the UI display adjustment may be performed using other UIs, other display controls, etc. For instance, some embodiments may adjust the UI display using pull-down menu selections. As another example, some embodiments may adjust the UI display using dedicated brightness control keys (e.g., as provided on many keyboards). In addition, various UIs may have various different UI items, display features, content display areas, etc.","III. Performance Enhancement","Some embodiments cache UI items (e.g., icons, buttons, menus, etc.) to improve application performance when adjusting UI display settings. In some embodiments, the cache stores UI elements that were previously stored elsewhere or previously calculated. Once the UI items are stored in the cache, they can be used again by accessing the cached copies rather than re-fetching or re-computing (e.g., pixel processing) the UI items stored on disk. Caching improves overall performance as cached UI items, having been previously processed, do not need to receive pixel processing. In addition, when storing the cached UI items in, for example, random access memory (RAM), the access time for retrieving data previously stored in the cache is less costly than the access time for retrieving data from disk. Furthermore, in some embodiments, the cache is shared across multiple applications.",{"@attributes":{"id":"p-0115","num":"0114"},"figref":["FIG. 16","FIG. 17"],"b":["1600","1600","1605","1610","1615"]},"At , the process determines whether the UI item affected by the adjusted display setting was previously displayed or cached at that display setting. When the determination is made that the UI item was previously displayed or cached at that display setting, the process retrieves (at ) the UI item from the cache. Otherwise, the process retrieves (at ) the UI item from the disk.","To facilitate performance enhancement, some embodiments store, in cache, multiple versions of a UI item for different UI display settings. This allows the UI item to be loaded directly from cache without having to dynamically process the UI item each time it is loaded.  illustrates various different UI items stored in disk and cache. As shown, the figure includes UI item  , UI item  , and UI item M  stored in disk .","After retrieving (at ) the UI item from storage, the process applies (at ) pixel processing to the UI item. After applying pixel processing to the UI item, the process (at ) stores the UI item in cache memory. This is illustrated in  as several UI items, each representing a different specific display setting, or range of display settings, are loaded onto the cache . Specifically, this figure illustrates that the UI item  at settings   and  , the UI item  at settings   and  , the UI item M at setting  , and several other UI items have previously been loaded to the cache .","By loading the UI items for different settings into cache memory, the processing time for changing the UI display setting is improved as the different versions do not have to be reprocessed and\/or retrieved again from disk. Once the UI item is retrieved either from storage or cache, the process  then redraws (at ) the UI based on the retrieved UI item. The process then ends.","One of ordinary skill in the art will realize that not all features for redrawing the UI need to be used together. Accordingly, some embodiments perform variations on the process . For example, some embodiments might not determine whether the UI item is affected and might only determine whether the UI item was previously stored for a particular setting. Also, in some embodiments the operations of process  might be performed by two or more separate processes. That is, some embodiments could have one process for retrieving the UI item from cache and a separate process for retrieving the UI item from storage.","IV. Software Architecture","A. Software Architecture of an Application","In some embodiments, the processes described above are implemented as software running on a particular machine, such as a computer or a handheld device, or stored in a computer readable medium.  conceptually illustrates the software architecture of an application  of some embodiments for adjusting a UI display such as those described in the preceding sections. In some embodiments, the application is a stand-alone application or is integrated into another application (e.g., application  might be a portion of a video-editing application), while in other embodiments the application might be implemented within an operating system. Furthermore, in some embodiments, the application is provided as part of a server-based (e.g., web-based) solution. In some such embodiments, the application is provided via a thin client. That is, the application runs on a server while a user interacts with the application via a separate client machine remote from the server (e.g., via a browser on the client machine). In other such embodiments, the application is provided via a thick client. That is, the application is distributed from the server to the client machine and runs on the client machine.","As shown in , the application  includes a UI interaction module  for interacting with a user of the application, a display adjustment module  for adjusting the display of the UI, a cache monitor engine  for monitoring stored UI items in one or more caches, an ambient light controller  for dynamically adjusting the display based on sensed ambient light, and a rendering engine  for generating image data for storage or display. The application  may also access a set of storages . The set of storages includes storages for UI items , content data , as well as other data  (e.g., media content data, display parameters, etc.).","The operating system  of some embodiments includes a cursor controller driver  that allows the application  to receive data from a cursor control device, a keyboard driver  that allows the application  to receive data from a keyboard, and a display module  for processing video data that will be supplied to a display device (e.g., a monitor).","A user interacts with items in a UI of the application  via input devices (not shown) such as a cursor controller (e.g., a mouse, touchpad, trackpad, etc.) and\/or keyboard. The input from these devices is processed by the cursor controller driver  and\/or the keyboard driver . The present application describes UIs that provide users with numerous ways to perform different sets of operations and functionalities. In some embodiments, these operations and functionalities are performed based on different commands that are received from users through different input devices (e.g., keyboard, trackpad, touchpad, mouse, etc). For example, the present application describes the use of a cursor in the UI to control (e.g., select, move) objects in the UI. However, in some embodiments, objects in the UI can also be controlled or manipulated through other controls, such as touch control. In some embodiments, touch control is implemented through an input device that can detect the presence and location of touch on a display of the device. An example of such a device is a touch screen device. In some embodiments, with touch control, a user can directly manipulate objects by interacting with the UI that is displayed on the display of the touch screen device. For instance, a user can select a particular object in the UI by simply touching that particular object on the display of the touch screen device. As such, when touch control is utilized, a cursor may not even be provided for enabling selection of an object of a UI in some embodiments. However, when a cursor is provided in a UI, touch control can be used to control the cursor in some embodiments.","When a user interacts with a UI control to change the display settings, some embodiments translate the user interaction into input data and send this data to the display adjustment module . For example, when the user interacts with a control to change the UI display settings from a low ambient light setting to a high ambient light setting, the UI interaction module  may translate the settings and pass the translated settings to the display adjustment module .","The display adjustment module  of some embodiments includes various application programming interfaces (APIs) for processing display settings and\/or commands received from the UI interaction module . The display setting or command is then processed by the display adjustment module to adjust the display setting of the UI. The display adjustment module  may also interface with one or more storages to load UI items (e.g., icons, UI controls, etc). The display adjustment module  may also interface with the cache monitor engine  to load such UI items from cache .","The computing device (e.g., notebook computer, desktop computer, portable devices) may include one or more light sensors configured to receive and measure the level of light that surrounds the computing device during use, as for example, light that is produced by incandescent, sunlight, fluorescents, and the like. This type of light is sometimes referred to as \u201cambient light.\u201d In some embodiments, the display settings of the UI are automatically adjusted based on ambient light. To facilitate such auto-adjustment, the ambient light controller  reads the measure light and determines a display setting for the UI based on the measured light. The display setting is then passed to the display adjustment module  to automatically adjust the display setting of the UI based on the measured light.","In some embodiments, the cache monitor engine  monitors stored UI items in one or more caches. For instance, the cache monitor engine of some embodiments monitors UI items that are loaded in either disk or cache to improve overall performance when changing display settings of the UI.","Rendering engine  enables the storage or output of audio and video from the application . For example, rendering engine  uses stored UI items (e.g., in cache, disk) to render the UI. As such, the rendering engine receives, in some embodiments, data from the display adjustment module  so that the UI can be displayed according a specified setting. Alternatively, data may be passed from the rendering engine  to the set of storages  for later display.","Although the application  and its features have been described using several specific embodiments, other embodiments might implement the application or its features using different resources or by placing the various modules in different specific locations. For instance, while many of the features have been described as being performed by one component (e.g., the UI interaction module , display adjustment module ), one of ordinary skill would recognize that a particular component might be split up into multiple components, and the performance of one feature might even require multiple components in some embodiments.","B. Automatic Adjustment of User Interface Display Setting","As mentioned above, a computing device (e.g., notebook computer, desktop computer, portable devices) may include or be coupled to one or more light sensors configured to receive and measure level of light that surrounds the computing device. For instance, a desktop computer may be coupled with a keyboard that includes one or more light sensors. Alternatively, a mobile smart device may include such a light sensor on a display screen or keypad. Such light sensors may produce one or more signals that specify the light conditions as measured by the sensor. In some embodiments, the display setting of a UI is automatically adjusted based on light measured from one or more such light sensors.",{"@attributes":{"id":"p-0132","num":"0131"},"figref":["FIG. 19","FIG. 35","FIGS. 20 and 21"],"b":["1900","1800","1900"]},"As shown, the process  begins (at ) by determining whether the light sensing feature is activated. For example, an application or an operating system may have a UI option (e.g., check box, button, slider) for specifying an auto-adjustment setting for the UI. When the process determines that the light sensing feature is not activated, the process ends. Otherwise, the process proceeds to .","At , the process  determines an ambient light level.  illustrates an example of automatically adjusting a UI based on the ambient light level. As shown, the figure includes a computing device  that includes a light sensor . The computing device further stores the ambient light controller , the display adjustment module , and a UI . The light sensor  is configured to receive and measure the level of light  that surrounds the computing device  during use. In some embodiments, the ambient light controller  determines the ambient light level based on the measured level of light from the light sensor .","Once the ambient light level is determined, the process  then determines (at ) a UI display parameter according to the ambient light level. In the example illustrated in , the ambient light controller determines the UI display parameter and passes the determined parameter to the display adjustment module .",{"@attributes":{"id":"p-0136","num":"0135"},"figref":"FIG. 21","b":["1900","1950"]},"In some embodiments, process  may be continuously performed by the application generating the UI display. In other embodiments, the process may be performed at regular intervals (e.g., every 2 minutes). In still other embodiments, the process  may be performed when a change is ambient lighting conditions occurs and is sensed by the ambient light controller  through a light sensor .","One of ordinary skill in the art will realize that not all features for automatically adjusting a UI based on a measured level of light need to be used together. Accordingly, some embodiments perform variations on the process . For example, some embodiments might not determine whether a light sensing feature is enabled or disabled. Hence, in some embodiments, the process  might use other factors to estimate the ambient light level. For example, in some such embodiments the UI display setting may be automatically adjusted based on time of day.","V. Application Development","Some embodiments provide an application toolkit that allows developers of different applications to produce different drawing APIs for different applications being developed.  pictorially illustrates an application prototyping toolkit  according to some embodiments. Specifically, this figure illustrates the development of two sets of drawing APIs  and  for two different frameworks  and  based on the UI items stored in storages  and  (each storage  or  corresponding to a particular application or suite of applications). As shown, the drawing APIs  control the display settings of UI items  , while the drawing APIs  control the display settings of UI items  . In addition, each group of drawing APIs  and  includes a color contrast API ( and , respectively) that performs the color contrast processing described, for example, in reference to  above.",{"@attributes":{"id":"p-0140","num":"0139"},"figref":"FIG. 23","b":["2200","2305","2310","2310"]},"The parameter display area  is an area in the application development toolkit  through which a developer can view and modify settings for a set of drawing APIs. Specifically, in this example, the parameter display area  includes (1) an adjusted image slider , (2) a mask intensity slider , (3) a first set of sliders  that defines a first color correction function for applying to non-saturated pixels, (4) a second set of sliders  that defines a second color correction function for applying to saturated pixels, and (5) a content mask check box .","As shown in , the adjusted image slider  represents the control that specifies the parameter which defines the display settings of a UI for different lighting conditions. In some embodiments, the adjusted image slider and\/or a variation of it is provided by the developer to an end-user of an application, while several of these other sliders and controls in the parameter display area  are not made available to the end-user.","The mask intensity slider  is a control that defines the intensity of a saturation mask (e.g., the saturation level calculated above using equation (2)). The mask intensity slider of some embodiments sets an amplification value for the saturation mask (e.g., the \u201cGain\u201d parameter in equation (3), described above). In some embodiments, this mask intensity defines a saturation level that separates saturated colors from non-saturated colors. For instance, if the intensity of the mask is reduced then fewer pixels will be classified as saturated and the distinction between grayscale and color display adjustment may not be clear. Conversely, if the intensity of the mask is increased then more pixels will be classified as saturated and the distinction between color and grayscale display adjustment may become clearer.","The first set of sliders  defines a first color correction function that is optimized for non-saturated pixels. Specifically, the first set of sliders defines constants that are associated with the gamma, lift, and gain parameters for the first color correction function (e.g., the color correction operation described above in reference to equation (4)). The second set of sliders  defines a second color correction function for applying to saturated pixels (e.g., the color correction operation described above in reference to equations (5) and (6)). The second set of sliders includes similar parameters as the first set of controls. However, the second set of sliders  also includes a slider that defines a constant for color saturation. These color correction functions are described above by reference to .","The content mask check box  allows the developer to easily customize the drawing APIs such that content elements of the UI are either masked or unmasked. In the example illustrated in , the parameter display area  also includes several other controls for defining the drawing APIs (e.g., a pull-down menu for selecting a type of adjustment curve and several sliders for defining the selected curve).","The operations of the application development toolkit  will now be described by reference to . As shown, a developer loads UI items (e.g., UI items  and ) to generate drawing APIs. In this example, the UI items (e.g., UI screen capture images, buttons and other UI artwork, menu items, etc.) are displayed in the preview display area . The user then selects an option to display the parameter display area . Once the parameter display area is displayed, the developer adjusts various parameters to define the desired settings for the UI display adjustment by reviewing the effects on the UI item(s) in the preview display area . After selecting the desired parameter values, the developer may store the resulting drawing APIs (e.g., color contrast APIs  or ) as part of a framework (e.g., framework  or ). In addition, the various application user interface items  or  may be stored as part of a framework (e.g., UI items  or ). In some embodiments, the UI items  or  are not stored as part of a framework, but the storage  or  may be accessed by the framework  or  as needed.",{"@attributes":{"id":"p-0147","num":"0146"},"figref":"FIG. 24","b":["2410","2420","2430","2435","2440","2450","2460","2470","2475","2480"]},"The various client applications  and  each execute over a framework  or . When a user of a particular application  or  modifies a display setting of the UI generated by the application  or , the updated display setting is passed to a set of drawing APIs  or  which then renders the UI items for display or caching. In some cases, the framework retrieves data from the appropriate UI item database  or  in order to update the UI. In other cases, the set of drawing APIs  or  renders the UI items for display or caching without accessing the UI item database  or . In such cases, a client application may still use one or more APIs (e.g., color contrast API  or ) to perform image processing operations on a UI item (e.g., the client application may draw a circle and request that the circle be drawn using a yellow theme color, where the yellow theme color has been color contrast adjusted).","In some embodiments, the adjustment to the display setting of a particular application triggers an adjustment to the other applications associated with the framework (i.e., the other applications in a particular suite of applications). In some such embodiments, the framework directs the UI items that are displayed in UIs generated by the other applications in the particular suite of applications to be redrawn.","VI. Process for Defining an Application","Section IV, above, described and illustrated the software architecture of an application in accordance with some embodiments.  conceptually illustrates a process  of some embodiments for defining an application, such as the application . As shown, process  begins by defining (at ) UI elements. In some embodiments, these UI elements are defined using UI items stored in storage.","Process  then defines (at ) a display adjustment module. The display adjustment module  shown in  is an example of such a module. Next, the process defines (at ) a cache monitor engine. As mentioned above, the cache monitor engine of some embodiments monitors stored UI items in one or more caches to improve overall performance when changing display settings of the UI.","The process  next defines (at ) an ambient light controller. An example of such ambient light controller is described above by reference to . The process then defines (at ) other application components and functionalities. After , the components of the application are all defined. Accordingly, the process stores (at ) a representation of the application in a readable storage medium. The readable storage medium may be a disk (e.g., CD, DVD, hard disk, etc.) or a solid-state storage device (e.g., flash memory) in some embodiments. One of ordinary skill in the art will recognize that the various components (e.g., engine, module, UI elements) defined by process  are not exhaustive of the modules and components that could be defined and stored on a readable storage medium for an application incorporating some embodiments of the invention.","VII. Computer System","Many of the above-described processes and modules are implemented as software processes that are specified as a set of instructions recorded on a computer readable storage medium (also referred to as \u201ccomputer readable medium\u201d or \u201cmachine readable medium\u201d). When these instructions are executed by one or more computational element(s), such as processors or other computational elements like Application-Specific ICs (\u201cASIC\u201d) and Field Programmable Gate Arrays (\u201cFPGA\u201d), they cause the computational element(s) to perform the actions indicated in the instructions. Computer is meant in its broadest sense, and can include any electronic device with a processor. Examples of computer readable media include, but are not limited to, CD-ROMs, flash drives, RAM chips, hard drives, EPROMs, etc. The computer readable media does not include carrier waves and\/or electronic signals passing wirelessly or over wired connection.","In this specification, the term \u201csoftware\u201d includes firmware residing in read-only memory or applications stored in magnetic storage which can be read into memory for processing by one or more processors. Also, in some embodiments, multiple software inventions can be implemented as sub-parts of a larger program while remaining distinct software inventions. In some embodiments, multiple software inventions can also be implemented as separate programs. Finally, any combination of separate programs that together implement a software invention described herein is within the scope of the invention. In some embodiments, the software programs when installed to operate on one or more computer systems define one or more specific machine implementations that execute and perform the operations of the software programs.",{"@attributes":{"id":"p-0155","num":"0154"},"figref":["FIG. 26","FIG. 18","FIGS. 2"],"b":["2600","2600","5","16","19","2600"]},"Such a computer system includes various types of computer readable mediums and interfaces for various other types of computer readable mediums. Computer system  includes a bus , a processor , a system memory , a read-only memory (ROM) , a permanent storage device , a graphics processing unit (\u201cGPU\u201d) , input devices , output devices , and a network connection . The components of the computer system  are electronic devices that automatically perform operations based on digital and\/or analog input signals. The various examples of UI display adjustment algorithms and controls shown in  may be at least partially implemented using sets of instructions that are run on the computer system  and displayed using the output devices .","One of ordinary skill in the art will recognize that the computer system  may be embodied in other specific forms without deviating from the spirit of the invention. For instance, the computer system may be implemented using various specific devices either alone or in combination. For example, a local PC may include the input devices  and output devices , while a remote PC may include the other devices -, with the local PC connected to the remote PC through a network that the local PC accesses through its network connection  (where the remote PC is also connected to the network through a network connection).","The bus  collectively represents all system, peripheral, and chipset buses that communicatively connect the numerous internal devices of the computer system . In some cases, the bus  may include wireless and\/or optical communication pathways in addition to or in place of wired connections. For example, the input devices  and\/or output devices  may be coupled to the system  using a wireless local area network (W-LAN) connection, Bluetooth\u00ae, or some other wireless connection protocol or system.","The bus  communicatively connects, for example, the processor  with the system memory , the ROM , and the permanent storage device . From these various memory units, the processor  retrieves instructions to execute and data to process in order to execute the processes of some embodiments. In some embodiments the processor includes an FPGA, an ASIC, or various other electronic components for execution instructions.","The ROM  stores static data and instructions that are needed by the processor  and other modules of the computer system. The permanent storage device , on the other hand, is a read-and-write memory device. This device is a non-volatile memory unit that stores instructions and data even when the computer system  is off. Some embodiments of the invention use a mass-storage device (such as a magnetic or optical disk and its corresponding disk drive) as the permanent storage device .","Other embodiments use a removable storage device (such as a floppy disk, flash drive, or CD-ROM) as the permanent storage device. Like the permanent storage device , the system memory  is a read-and-write memory device. However, unlike storage device , the system memory  is a volatile read-and-write memory, such as a random access memory (RAM). The system memory stores some of the instructions and data that the processor needs at runtime. In some embodiments, the sets of instructions and\/or data used to implement the invention's processes are stored in the system memory , the permanent storage device , and\/or the read-only memory . For example, the various memory units include instructions for processing multimedia items in accordance with some embodiments.","In addition, the bus  connects to the GPU . The GPU of some embodiments performs various graphics processing functions. These functions may include display functions, rendering, compositing, and\/or other functions related to the processing or display of graphical data.","The bus  also connects to the input devices  and output devices . The input devices  enable the user to communicate information and select commands to the computer system. The input devices include alphanumeric keyboards and pointing devices (also called \u201ccursor control devices\u201d). The input devices also include audio input devices (e.g., microphones, MIDI musical instruments, etc.) and video input devices (e.g., video cameras, still cameras, optical scanning devices, etc.). The output devices  include printers, electronic display devices that display still or moving images, and electronic audio devices that play audio generated by the computer system. For instance, these display devices may display a UI. The display devices include devices such as cathode ray tubes (\u201cCRT\u201d), liquid crystal displays (\u201cLCD\u201d), plasma display panels (\u201cPDP\u201d), surface-conduction electron-emitter displays (alternatively referred to as a \u201csurface electron display\u201d or \u201cSED\u201d), etc. The audio devices include a PC's sound card and speakers, a speaker on a cellular phone, a Bluetooth\u00ae earpiece, etc. Some or all of these output devices may be wirelessly or optically connected to the computer system.","Finally, as shown in , bus  also couples computer  to a network  through a network adapter (not shown). In this manner, the computer can be a part of a network of computers (such as a local area network (\u201cLAN\u201d), a wide area network (\u201cWAN\u201d), an Intranet, or a network of networks, such as the Internet. For example, the computer  may be coupled to a web server (e.g., network ) so that a web browser executing on the computer  can interact with the web server as a user interacts with a UI that operates in the web browser.","As mentioned above, some embodiments include electronic components, such as microprocessors, storage and memory that store computer program instructions in a machine-readable or computer-readable medium (alternatively referred to as computer-readable storage media, machine-readable media, or machine-readable storage media). Some examples of such computer-readable media include RAM, ROM, read-only compact discs (CD-ROM), recordable compact discs (CD-R), rewritable compact discs (CD-RW), read-only digital versatile discs (e.g., DVD-ROM, dual-layer DVD-ROM), a variety of recordable\/rewritable DVDs (e.g., DVD-RAM, DVD-RW, DVD+RW, etc.), flash memory (e.g., SD cards, mini-SD cards, micro-SD cards, etc.), magnetic and\/or solid state hard drives, read-only and recordable blu-ray discs, ultra density optical discs, any other optical or magnetic media, and floppy disks. The computer-readable media may store a computer program that is executable by at least one processor and includes sets of instructions for performing various operations.","Examples of hardware devices configured to store and execute sets of instructions include, but are not limited to, ASICs, FPGAs, programmable logic devices (\u201cPLDs\u201d), ROM, and RAM devices. Examples of computer programs or computer code include machine code, such as produced by a compiler, and files including higher-level code that are executed by a computer, an electronic component, or a microprocessor using an interpreter.","As used in this specification and any claims of this application, the terms \u201ccomputer\u201d, \u201cserver\u201d, \u201cprocessor\u201d, and \u201cmemory\u201d all refer to electronic or other technological devices. These terms exclude people or groups of people. For the purposes of this specification, the terms display or displaying mean displaying on an electronic device. As used in this specification and any claims of this application, the terms \u201ccomputer readable medium\u201d and \u201ccomputer readable media\u201d are entirely restricted to tangible, physical objects that store information in a form that is readable by a computer. These terms exclude any wireless signals, wired download signals, and\/or any other ephemeral signals.","It should be recognized by one of ordinary skill in the art that any or all of the components of computer system  may be used in conjunction with the invention. Moreover, one of ordinary skill in the art will appreciate that any other system configuration may also be used in conjunction with the invention or components of the invention.","While the invention has been described with reference to numerous specific details, one of ordinary skill in the art will recognize that the invention can be embodied in other specific forms without departing from the spirit of the invention. For example, several embodiments were described above by reference to particular applications (and their associated UIs) with particular features and components (e.g., with a particular content display area). However, one of ordinary skill will realize that other embodiments might be implemented with other types of applications (and\/or other associated UIs) with other types of features and components (e.g., other types of content display areas).","Moreover, while the examples shown illustrate many individual modules as separate blocks (e.g., the display adjustment module , the ambient light controller , etc.), one of ordinary skill in the art would recognize that some embodiments may combine these modules into a single functional block or element. One of ordinary skill in the art would also recognize that some embodiments may divide a particular module into multiple modules.","One of ordinary skill in the art will realize that, while the invention has been described with reference to numerous specific details, the invention can be embodied in other specific forms without departing from the spirit of the invention. For instance, alternate embodiments may be implemented using different display controls, parameters, masking techniques, etc. One of ordinary skill in the art would understand that the invention is not to be limited by the foregoing illustrative details, but rather is to be defined by the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The novel features of the invention are set forth in the appended claims. However, for purpose of explanation, several embodiments of the invention are set forth in the following figures.",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIGS. 3-4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIGS. 10-12"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIGS. 13-15"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 26"}]},"DETDESC":[{},{}]}
