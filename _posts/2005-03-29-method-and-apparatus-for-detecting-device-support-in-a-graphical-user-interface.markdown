---
title: Method and apparatus for detecting device support in a graphical user interface
abstract: Embodiments of the invention comprise techniques to detect support for a given input device by a screen element of a graphical user interface (GUI). In one embodiment of the invention, a runtime version of a screen element's program code is examined to detect an ability to process a device's events. In another embodiment of the invention, a determination is made at runtime whether a screen element delegated processing of a given input device's events to other program code. In yet another embodiment of the invention, the runtime version of a screen element's program code is examined to detect a declaration of program code that is indicative of a screen element's support or non-support of a given input device. In yet another embodiment of the invention, one or more of the previously-identified embodiments can be combined.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07774717&OS=07774717&RS=07774717
owner: Oracle America, Inc.
number: 07774717
owner_city: Redwood City
owner_country: US
publication_date: 20050329
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application is a continuation of prior application Ser. No. 09\/201,644, filed Nov. 30, 1998, now U.S. Pat. No. 6,930,695 the disclosure of which is incorporated herein by reference.","1. Field of the Invention","This invention relates to components of a graphical user interface, and more specifically to device support by components of a graphical user interface.","Portions of the disclosure of this patent document may contain material that is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office file or records, but otherwise reserves all copyright rights whatsoever. Sun, Sun Microsystems, the Sun logo, Java and all Java-based trademarks and logos are trademarks or registered trademarks of Sun Microsystems, Inc. in the United States and other countries. All SPARC trademarks are used under license and are trademarks or registered trademarks of SPARC International in the United States and other countries. Products bearing SPARC trademarks are based upon an architecture developed by Sun Microsystems, Inc.","2. Background Art","A graphical user interface (GUI) is used to display information on a video display (or screen) of a computer system. A GUI typically includes screen elements such as windows, icons, labels, fields, etc. A screen element refers to both the display in a GUI and the program code that is used to generate and control the display of the screen element in the GUI. A screen element typically interacts with an operating system that is composed of one or more layers of software routines that control the physical devices that a user uses to interact with the computer system. For example, one or more input devices such as a keyboard or a pointing device (e.g., mouse, touch screen, etc.) may be used by the user. When a user generates input using one of the computer system's input devices, feedback may be provided in the GUI which is displayed by a video display to indicate that the user's input was received and is being or was processed. A problem arises when an incompatibility exists between the device capabilities and expectations of a screen element and the actual device capabilities of a computer system. For example, a screen element may support an input device that is not available in the computer system.","Most personal computers currently available provide a mouse input device that may be used to move within the GUI and over a given screen element. Mouse input that occurs within a region of the GUI occupied by a screen element may be forwarded to the screen element. The screen element processes the mouse input and may provide feedback to be displayed in the GUI. For example, the user can move within the region of the screen element in the GUI and press a button on the mouse to select the screen element. The screen element is informed that the mouse is within its region (e.g., a \u201cmouse enter\u201d event) and that the user has pressed a mouse button within its region (e.g., a \u201cmouse down\u201d event). This process is typically referred to as selecting the screen element. When a screen element is selected, the selected screen element typically becomes the focus within the GUI. For example, the display of the selected screen element can be varied from its previous display and that of the other screen elements to identify it as the currently selected screen element. Events from an input device are typically directed to the currently selected (or focused) screen element.","In the above example, it is assumed that a mouse input device is available on the computer system. Further, it is assumed that the screen element is capable of processing input received from the mouse. However, it is possible that a given input device is unavailable or that the screen element is unable to support a given input device. It would be beneficial to be able to determine the type of input devices whose input a screen element can process. That is, before device input is directed to a screen element, it would be beneficial to know whether the screen element is capable of processing the device input. Further, it may be beneficial to be able to give the look and feel of a given input device in the GUI even though that device is not physically connected to the computer system when a screen element can support that type of input device.","The problems associated with detecting whether a screen element can process device input can be better understood from a review of the Java virtual machine's processing environment and an overview of object-oriented programming.","Object-Oriented Programming","Object-oriented programming is a method of creating computer programs by combining certain fundamental building blocks, and creating relationships among and between the building blocks. The building blocks in object-oriented programming systems are called \u201cobjects.\u201d A software application can be written using an object-oriented programming language whereby the program's functionality is implemented using these objects.","An object is a programming unit that groups together a data structure (one or more instance variables) and the operations (methods) that can use or affect that data. Thus, an object consists of data and one or more operations or procedures that can be performed on that data. The joining of data and operations into a unitary building block is called \u201cencapsulation.\u201d","An object can be instructed to perform one of its methods when it receives a \u201cmessage.\u201d A message is a command or instruction sent to the object to execute a certain method. A message consists of a method selection (e.g., method name) and a plurality of arguments. A message tells the receiving object what operations to perform.","One advantage of object-oriented programming is the way in which methods are invoked. When a message is sent to an object, it is not necessary for the message to instruct the object how to perform a certain method. It is only necessary to request that the object execute the method. This greatly simplifies program development.","Object-oriented programming languages are predominantly based on a \u201cclass\u201d scheme. The class-based object-oriented programming scheme is generally described in Lieberman, \u201cUsing Prototypical Objects to Implement Shared Behavior in Object-Oriented Systems,\u201d OOPSLA 86 Proceedings, September 1986, pp. 214-223.","An object class provides a definition for an object which typically includes both fields (e.g., variables) and methods. An object class is used to create a particular \u201cobject instance.\u201d (The term \u201cobject\u201d by itself is often used interchangeably to refer to a particular class or a particular instance.) An instance of an object class includes the variables and methods defined for that class. Multiple instances can be created from the same object class. Each instance that is created from the object class is said to be of the same type or class.","To illustrate, an employee object class can include \u201cname\u201d and \u201csalary\u201d instance variables and a \u201cset_salary\u201d method. Instances of the employee object class can be created, or instantiated for each employee in an organization. Each object instance is said to be of type \u201cemployee.\u201d Each employee object instance includes \u201cname\u201d and \u201csalary\u201d instance variables and the \u201cset_salary\u201d method. The values associated with the \u201cname\u201d and \u201csalary\u201d variables in each employee object instance contain the name and salary of an employee in the organization. A message can be sent to an employee's employee object instance to invoke the \u201cset_salary\u201d method to modify the employee's salary (i.e., the value associated with the \u201csalary\u201d variable in the employee's employee object).","A hierarchy of classes can be defined such that an object class definition has one or more subclasses. A subclass inherits its parent's (and grandparent's etc.) definition. Each subclass in the hierarchy may add to or modify the behavior specified by its parent class. The parent class is also referred to as a superclass with respect to its subclass(es). Some object-oriented programming languages support multiple inheritance where a subclass may inherit a class definition from more than one parent class. Other programming languages support only single inheritance, where a subclass is limited to inheriting the class definition of only one parent class. The Java programming language also provides a mechanism known as an \u201cinterface\u201d which comprises a set of constant and abstract method declarations. An object class can implement the abstract methods defined in an interface. Both single and multiple inheritance are available to an interface. That is, an interface can inherit an interface definition from more than one parent interface.","Java Programming Language and Program Execution","Java applications typically comprise one or more object classes and interfaces. Unlike many programming languages in which a program is compiled into machine-dependent, executable code, classes written in the Java programming language are compiled into machine independent bytecode class files. Each class contains code and data in a platform-independent format called the class file format. A bytecode includes a code that identifies an instruction (an opcode) and none or more operands to be used in executing the instruction. The computer system acting as the execution vehicle contains a program called a virtual machine, which is responsible for executing the code (i.e., bytecode) in Java programming language class files.","Applications may be designed as standalone Java applications, or as Java \u201capplets\u201d which are identified by an applet tag in an HTML (Hypertext Markup Language) document, and loaded by a browser application. The class files associated with an application or applet may be stored on the local computing system, or on a server accessible over a network. Each Java programming language class file is loaded into the Java virtual machine, as needed, by the \u201cclass loader.\u201d","The classes of a Java applet are loaded on demand from the network (stored on a server), or from a local file system, when first referenced during the Java applet's execution. The virtual machine locates and loads each class file, parses the class file format, allocates memory for the class's various components, and links the class with other already loaded classes. This process makes the code in the class readily executable by the virtual machine.","Java applications and applets often make use of class libraries. Classes in the class libraries may contain what are referred to as \u201cnative methods.\u201d A native method is a method that is comprised of native code. Bytecodes contained in a class file generated from programming statements written using the Java programming language is an example of machine-independent code. Native code typically refers to platform-dependent code. However, native code may refer to other program code. For example, native code can also be code that is written using a secondary programming language (i.e., a language other than the primary programming language used to write an application).","Applications and applets may occasionally contain classes that declare native methods. A native method declaration specifies the keyword \u201cnative,\u201d the name of the method, the return type of the method, and any parameters that are passed to the method. In contrast to a \u201cstandard method\u201d (i.e., non-native method) written in the Java programming language, there is no body to a native method within the respective class. Rather, the routines of a native method are carried out by compiled native code (e.g., code written in the C or C++ programming language and compiled into binary form) that is dynamically linked to a given class in the virtual machine at runtime using a linking facility specific to the given platform which supports linked libraries.","In the Solaris\u2122 or UNIX environment, for example, the linked library containing the binary form of the native code may be implemented as a \u201cshared object\u201d library written as a \u201c.so\u201d file. In a Windows environment, the linked library may take the form of a dynamic linked (or dynamic loadable) library written as a \u201c.dll\u201d file. Native code may be used to perform functions otherwise not supported by the Java programming language, such as interfacing with specialized hardware (e.g., display hardware) or software (e.g., database drivers) of a given platform. Native code may also be used to speed up computationally intensive functions, such as rendering.","A class that contains a native method also contains a call to load the respective linked library:","System.loadLibrary(\u201cSample\u201d);","where \u201cSample\u201d is the name of the linked library, typically stored in a file named \u201clibSample.so\u201d or \u201cSample.dll\u201d, depending on the host operating system (e.g., UNIX, Windows, etc.). The linked library is typically loaded at the time the associated class is instantiated within the virtual machine.","The linked library of native code is compiled with stub and header information of the associated class to enable the linked library to recognize the method signature of the native method in the class. The implementation of the native method is then provided as a native code function (such as a C function) in the linked library. At runtime, when a call is made to the native method, control is passed to the function in the linked library that corresponds to the called method (e.g., via pushing of a native method frame onto the native method stack). The native code within the linked library performs the function and passes control back to the Java application or applet.","In contrast to a dynamically linked library, code from a statically linked library is linked during compilation. In the Solaris environment, a statically linked library is typically stored in a file with a \u201c.a\u201d extension (e.g., \u201csample.a\u201d). Statically linked libraries may be used instead of dynamically linked libraries where, for example, there is a limited amount of storage (e.g., a set-top box or personal data assistant).",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 1","b":["100","100","101","100","102","102","102"]},"The runtime environment contains a Java virtual machine (JVM)  which is able to execute bytecode class files and execute native operating system (\u201cO\/S\u201d) calls to operating system  when necessary during execution. Java virtual machine  provides a level of abstraction between the machine independence of the bytecode classes and the machine-dependent instruction set of the underlying computer hardware , as well as the platform-dependent calls of operating system .","Class loader and bytecode verifier (\u201cclass loader\u201d)  is responsible for loading bytecode class files  and supporting class libraries  written using the Java programming language into Java virtual machine  as needed. Class loader  also verifies the bytecodes of each class file to maintain proper execution and enforcement of security rules. Within the context of runtime system , either an interpreter  executes the bytecodes directly, or a \u201cjust-in-time\u201d (JIT) compiler  transforms the bytecodes into machine code, so that they can be executed by the processor (or processors) in hardware . Native code, e.g., in the form of a linked library , is loaded when a class (e.g., from class libraries ) containing the associated native method is instantiated within the virtual machine.","Interpreter  reads, interprets and executes a bytecode instruction before continuing on to the next instruction. JIT compiler  can translate multiple bytecode instructions into machine code that are then executed. Compiling the bytecodes prior to execution results in faster execution. If, for example, the same bytecode instruction is executed multiple times in a program's execution, it must be interpreted each time it is executed using interpreter . If JIT compiler  is used to compile the program, the bytecode instruction may be translated once regardless of the number of times it is executed in the program. Further, if the compilation (i.e., output of JIT compiler ) is retained, there is no need to translate each instruction during program execution.","The runtime system  of virtual machine  supports a general stack architecture. The manner in which this general stack architecture is supported by the underlying hardware  is determined by the particular virtual machine implementation, and reflected in the way the bytecodes are interpreted or JIT-compiled.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 2","FIG. 2"],"b":["108","200","207","207","208","209","210","211","212","216","212","213","214","215","216","217"]},"Runtime data areas  further comprises shared heap . Heap  is the runtime data area from which memory for all class instances and arrays is allocated. Shared heap  comprises method area , which is shared among all threads. Method area  comprises one or more class-based data areas  for storing information extracted from each loaded class file. For example, class-based data area  may comprise class structures such as constant pool , field and method data , and code for methods and constructors . Methods and constructors  may also be referred to as method table .","A virtual machine can support many threads of execution at once. Each thread has its own thread-based data area . At any point, each thread is executing the code of a single method, the \u201ccurrent method\u201d for that thread. If the \u201ccurrent method\u201d is not a native method, program counter register  contains the address of the virtual machine instruction currently being executed. If the \u201ccurrent method\u201d is a native method, the value of program counter register  is undefined. Frame register  points to the location of the current method in method area .","Embodiments of the invention comprise techniques to detect support for a given input device by a screen element of a graphical user interface (GUI). In one embodiment of the invention, a runtime version of a screen element's program code is examined to detect an ability to process a device's events. In another embodiment of the invention, a determination is made at runtime whether a screen element delegated processing of a given input device's events to other program code. In yet another embodiment of the invention, the runtime version of a screen element's program code is examined to detect a declaration of program code that is indicative of a screen element's support or non-support of a given input device. In yet another embodiment of the invention, one or more of the previously-identified embodiments can be combined.","A method and apparatus for detecting device support in a graphical user interface is described. In the following description, numerous specific details are set forth in order to provide a more thorough description of the present invention. It will be apparent, however, to one skilled in the art, that the present invention may be practiced without these specific details. In other instances, well-known features have not been described in detail so as not to obscure the invention.","Embodiments of the invention comprise techniques to detect support for a given input device by a screen element of a graphical user interface (GUI). In one embodiment of the invention, a runtime version of a screen element's program code is examined to detect an ability to process a device's events. In another embodiment of the invention, a determination is made at runtime whether a screen element delegated processing of a given input device's events to other program code. In yet another embodiment of the invention, the runtime version of a screen element's program code is examined to detect a declaration of program code that is indicative of a screen element's support or non-support of a given input device. In yet another embodiment of the invention, one or more of the previously-identified embodiments can be combined.","Determination of the presence of support for an input device may effect the appearance of the screen element in the GUI display. Further, an identification of support for an input device can facilitate the identification of a screen element where it is otherwise difficult to determine which screen element is to receive an input device's event. For example, where a pointing device (e.g., mouse) is positioned within a region of the GUI that is occupied by more than one screen element, the event can be sent to the screen element that has the ability to process the pointing device's event.","Embodiments of the invention can also be used where one or more input devices are not available. For example; in a set-top box for a television or other information appliance (other examples of information appliances include an electronic address book and\/or personal organizer, a smart telephone, and an electronic mail device) that includes a GUI may include only a keyboard device for input. The user might use directional keys (e.g., arrow keys) on the keyboard to mimic a mouse. Using one or more embodiments of the invention, a determination is made whether a screen element supports mouse input. If so, mouse events can be sent to the screen element. Also, an icon that is typically associated with a mouse (e.g., an arrow) can be displayed and moved within the GUI to correspond to the movement associated with a directional key. Therefore, there is no need to modify the screen element to accommodate systems that do not have mouse input devices available.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 7","b":["700","702","706","706","704"]},"The look and feel of screen element  can identify that screen element  supports mouse input. In this example, mouse icon  is displayed in GUI . Mouse icon  can be moved within screen element  to reflect positional input (e.g., positional keys or mouse movement) that is received. If position input is received that is outside screen element , icon  can be removed from the display of GUI . If a focus indication is provided for screen element  in GUI , the focus indication can be removed from GUI  as well when positioning input is received that is outside screen element .","The previous example assumes that a system does not include a given input device. However, it should be apparent that a user may wish to use one input device to simulate or emulate another, available device. For example, a user may elect to use the directional keys of a keyboard to simulate mouse input even though the user's system includes a mouse.","A description of embodiments of the invention is provided herein with reference to a mouse device, however, it should be apparent that embodiments of the invention can be applied to other devices. Further, embodiments of the invention are described with reference to the Java programming language. It should be apparent that other programming languages can also be used with embodiments of the invention.","Method Inspection","In one or more embodiments of the invention, screen elements are object-oriented objects written using the Java programming language. Runtime versions of screen elements (in the form of bytecodes) can be examined to determine whether methods for handling a given device type are present.","In an object-oriented programming language such as the Java programming language, the runtime version is a bytecode version of a class definition of a screen element. The bytecode class definition is examined to determine whether the definition includes at least one \u201cdevice-handling\u201d method.","An object class may inherit methods from another class (e.g., a superclass). Where the screen element's class definition does not include the device method, embodiments of the invention examine the screen element's superclass bytecode object class definition to determine whether the superclass definition includes at least one \u201cdevice-handling\u201d method.","In some instances the screen element inherits from an originating (or ultimate) superclass that includes input device method abstractions. In this case, method inspection does not examine the originating superclass. For example, a screen element in the Abstract Windowing Toolkit (AWT) such as AWT Button inherits from a hierarchy of classes that begins with an originating superclass (java.awt.Component). The java.awt.Component originating class includes mouse event handlers. The process of examining superclasses of the AWT Button screen element terminates before reaching the originating superclass.","To detect whether a screen element (e.g., a Button class developed using AWT of the Java Development Kit version 1.0 available from Sun Microsystems, Inc.) supports mouse input, method inspection is performed on the screen element's bytecode class definition to detect at least one \u201cmouse-handling\u201d method. The following provides examples of \u201cmouse-handling\u201d methods to be detected in one or more embodiments of the invention:\n\n","Where at least one of these mouse-handling methods is detected in the screen element's bytecode class definition, the screen element is marked as being able to support mouse input. An indication that a screen element can support mouse input may also be used to modify the look and feel of the screen element in the GUI.",{"@attributes":{"id":"p-0060","num":"0065"},"figref":"FIG. 3"},"At step , the screen element's class definition becomes the current class definition. At step , the current class definition is examined to determine whether a given method exists in the definition. If so, processing continues at step  to mark the screen element as supporting input for a given device. Processing ends at step .","If the method is not found at step , processing continues at step  to get a superclass of the current class. The superclass becomes the current class. At step , a determination is made whether the current class is the originating superclass (e.g., java.awt.Component). If so, processing continues at step  to mark the screen element as not supporting device input. Processing ends at step . If it is determined, at step , that the current class is not the originating superclass, processing returns to step  to examine the current class for the device method.","In one embodiment of the invention, the detection process (e.g., process flow of ) is performed at runtime on a Java bytecode class definition that is loaded into memory. A reflection Application Programming Interface (API) that includes methods for inspecting the contents of a class definition is used to examine the bytecode class file for a given method. For example, the getDeclaredMethod method of the reflection API can be used to inspect the class definition for a specified method, return a method object that reflects the specified method or throw an exception (e.g., a NoSuchMethod Exception) if the specified method is not found.","In one embodiment of the invention, the detection process is performed when a screen element's object instance is constructed (i.e., in a constructor method). In a platform-independent virtual machine environment such as that provided by a Java virtual machine, a multi-layer architecture is used to generate a GUI. In the multi-layer architecture, a platform-independent screen element object instance is constructed along with one or more platform-dependent screen element object instances. A peer object instance provides an interface between the platform-independent and platform-dependent object instances. The detection process may be performed in a constructor method of the platform-independent object, the peer object or the platform-dependent object.",{"@attributes":{"id":"p-0065","num":"0070"},"figref":"FIG. 4"},"Layer  comprises a platform-independent layer. Layer  allows a developer to design and implement a GUI that can run on multiple platforms (e.g., Windows 95, Windows NT, OS\/2, Solaris). An example in this layer is the AWT that contains a collection of object classes written using the Java programming language. AWT comprises object classes that define the properties and behavior of screen elements that comprise a GUI. For example, an AWT Button object class contains properties and behavior for a button screen element of the GUI. The AWT Button object class provides a platform-independent definition of a button screen element.","Platform-independent screen elements of layer  interface with a peer screen element. Peer elements comprise peer layer . Peer layer  provides a platform-specific abstraction that provides an interface to the platform-specific screen element. For example, an AWT Button instance has a corresponding Button Peer that interfaces with a Windows 95 Button instance.","Peer layer  interfaces with native layer  via a native interface layer . Native interface layer  can be the Java Native Interface (JNI), a native programming interface that allows Java code that runs inside a Java Virtual Machine (VM) to interoperate with program code, such as applications and libraries, written in other programming languages (e.g., C, C++, and assembly). Native layer  is comprised of a platform-specific windowing and\/or operating system (e.g., Windows 95 or Motif). On a Windows platform, a Windows Button element is an example of a native layer screen element.","To illustrate, an AWT Button in platform-independent layer  interfaces with a Button Peer of peer layer . On a Windows platform, the Button Peer interfaces with a Windows Button of native layer  via native interface layer . When an AWT Button instance is constructed, the Button Peer and Windows Button instances are also constructed. Constructor methods of each of these object classes are invoked to create the button instances. The detection process (e.g., the detection process of ) may be performed in one or more of these constructor methods, for example.","Delegation","In some programming languages (e.g., the Java Development Kit, or JDK, version 1.1 written using the Java programming language), a delegation model allows one object to delegate processing (e.g., device event handling) to another object. In the JDK version 1.1 \u201cDelegation Model,\u201d an object (referred to as the \u201csource\u201d) can designate another object (called the \u201clistener\u201d) to handle its inputs.","A source object includes methods to register \u201clisteners\u201d with the source object. Processing (e.g., event handling) that would otherwise be directed to a source object, is directed to a listener object that has registered with the source object. The \u201clistener\u201d object may be activated by the source object to handle the inputs, for example. A source object can register itself and\/or another object as a listener. Thus, a source object may activate itself where it is a registered \u201clistener.\u201d","In one embodiment of the invention, a screen element is marked as supporting a device when the screen element has a listener that supports the device.","For example, listeners that support a mouse device are referred to as either a \u201cmouseListener\u201d or a \u201cmouseMotionListener.\u201d A screen element may register itself or another object as a \u201cmouseListener\u201d or a \u201cmouseMotionListener.\u201d","A screen element is marked as supporting mouse input, if it has at least one \u201cmouseListener\u201d or \u201cmouseMotionListener\u201d registered with it. Conversely, a screen element can be marked as not supporting mouse inputs if neither a \u201cmouseListener\u201d nor a \u201cmouseMotionListener\u201d is registered with the screen element.","A registered \u201clistener\u201d can unregister itself. For example, a \u201clistener\u201d instance that has registered itself as a \u201cmouseListener\u201d and\/or a \u201cmouseMotionListener\u201d can request to be unregistered as a \u201clistener.\u201d A screen element is marked as not supporting mouse input when the last \u201cmouseListener\u201d or \u201cmouseMotionListener\u201d is unregistered.","In Java, when a mouseListener is registered for a screen element, a private flag (or variable), mouselistener, is set in the java.awt.Component. When a mouseMotionListener is registered for a screen element, java.awt.Component sets a private flag, mouseMotionListener. Because these variables are private, they are not accessible from platform-independent layer . These variables may examined at any time during runtime in native layer  to determine whether a screen element supports a mouse device. In one embodiment of the invention, a peer element of the peer layer  may request a native element of the native layer  to inspect the mouseListener and\/or mouseMotionListener variables. A screen element is marked as supporting mouse input if one or both of these variables is set.","Interface Introspection","A screen element may include one or more collections of externally-defined methods. Typically, a collection of externally-defined methods is given a name. A screen element that includes a collection of externally-defined methods declares the methods using the name of the collection. In Java, for example, an interface is an example of a collection of constants and abstract methods. A screen element declares an interface by specifying the name of the interface in an implements clause. The methods of the interface are can be overridden by a method definition of the screen element.","The following table provides examples of interfaces in the Personal Java programming language available from Sun Microsystems, Inc.:",{"@attributes":{"id":"p-0079","num":"0084"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"189pt","align":"left"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["Interface","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["NoInputPreferred","The user may not navigate to the screen element. This interface"]},{"entry":[{},"might be appropriate for screen elements such as labels."]},{"entry":["KeyboardInputPreferred","The screen element will be accessed primarily via keyboard"]},{"entry":[{},"input. An on-screen keyboard may be displayed when the user"]},{"entry":[{},"navigates to or selects this screen element. The developer"]},{"entry":[{},"should ensure that Component isFocusTraversable returns true"]},{"entry":[{},"for this screen element."]},{"entry":["ActionInputPreferred","This interface is intended for those screen elements that the user"]},{"entry":[{},"would click on or otherwise \u201cactivate\u201d using the input device."]},{"entry":[{},"The screen element should receive a MOUSE_ENTER event"]},{"entry":[{},"when the user navigates to the screen element, and a"]},{"entry":[{},"MOUSE_EXIT event when the user navigates from the screen"]},{"entry":[{},"element. The screen element should receive a MOUSE_DOWN"]},{"entry":[{},"event followed by a MOUSE_UP event when the user selects"]},{"entry":[{},"the screen element. The mouse coordinates for all events"]},{"entry":[{},"associated with this screen element will be the coordinates of"]},{"entry":[{},"the center of the screen element."]},{"entry":["PositionInputPreferred","The screen element will be used primarily by the user selecting"]},{"entry":[{},"x, y coordinates within the screen element. The screen element"]},{"entry":[{},"should receive MOUSE_ENTER and MOUSE_EXIT events"]},{"entry":[{},"when this user navigates to the screen element. The system"]},{"entry":[{},"should provide some mechanism for selecting specific x, y"]},{"entry":[{},"coordinates within the screen element's bounds, and provide"]},{"entry":[{},"mouse movement events. The platform should decide if"]},{"entry":[{},"selection of x, y coordinate begins when the user navigates to"]},{"entry":[{},"the screen element or when the user selects the screen. element."]},{"entry":[{},"In either case, the screen element should receive a"]},{"entry":[{},"MOUSE_DOWN and MOUSE_UP event with the selected"]},{"entry":[{},"coordinates."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"In these example interfaces, the NoInputPreferred and KeyboardInputPreferred interfaces do not allow mouse input. Therefore, a screen element that implements these interfaces can be considered to not support mouse input. Thus, according to an embodiment of the invention, if one or both of these interfaces is detected in the runtime version of the screen element, the screen element is marked as not supporting mouse input.","Conversely, where a screen element implements either the ActionInputPreferred or PositionInputPreferred interfaces (or both), it is assumed that the screen element supports mouse input. Therefore, the screen element that implements one or both of these interfaces is marked as supporting mouse input in an embodiment of the invention.","In the Java programming language, an instance of operator can be used to determine the class of an object instance. The instance of operator can also be used to indicate whether an object instance implements an interface. The instance of operation can be placed in the peer element (e.g., Button Peer) constructor method to test for a given interface implementation associated with a screen element. The following instance of pseudocode example is used in an embodiment of the invention to detect whether an object instance supports mouse input:","if (element instance of ActionInputPreferred)\n\n","if (element instance of PositionalInputPreferred)\n\n","A lightweight element is a screen element that does not need a corresponding screen element in native layer . A lightweight element typically looks the same on different platforms. An example of a lightweight element is an element that displays a graphic image (e.g., a .gif file). Since there is no native layer element, native layer  is not necessarily aware of the lightweight element.","In one embodiment of the invention, a lightweight element is initially marked as supporting device input. This default may be overridden. For example, a lightweight element may implement one or both of the NoInputPreferred or KeyboardInputPreferred interfaces. In this case, the lightweight element is marked as unable to support a mouse device. As discussed above, the instance of operator of the Java programming language can be used to detect the inclusion of an interface.",{"@attributes":{"id":"p-0087","num":"0094"},"figref":"FIG. 5","b":["502","504"]},"At step , a determination is made whether the lightweight element implements an interface that indicates that the element does not support a given device. If so, processing continues at step  to mark the lightweight element as not supporting the device and processing ends at step . If it is determined, at step , that the lightweight element does not implement a non-supporting interface, processing ends at step .","If it is determined, at step , that the screen element is not a lightweight element, processing continues at step . A determination is made, at step , whether the screen element implements a device-supporting interface for a given device. If not, processing continues at step  to mark the element as not supporting the device. If it is determined at step  that the screen element implements a device-supporting interface for a given device, processing continues at step  to mark the element as supporting the device. In either case, processing ends at step .","Embodiment of Computer Execution Environment (Hardware)","Embodiments of the invention can be implemented as computer software in the form of computer readable code executed on a general purpose computer or on special purpose computer, or in the form of bytecode class files executable within a Java runtime environment running on such a general or special purpose computer.",{"@attributes":{"id":"p-0091","num":"0098"},"figref":"FIG. 6","b":["610","611","618","613","611","610","619","618"]},"Computer  includes a video memory , main memory  and mass storage , all coupled to system bus  along with keyboard , mouse  and processor . The mass storage  may include both fixed and removable media, such as magnetic, optical or magnetic optical storage systems or any other available mass storage technology. Bus  may contain, for example, sixty-four address lines for addressing video memory  or main memory . The system bus  also includes, for example, a 64-bit data bus for transferring data between and among the components, such as processor , main memory , video memory  and mass storage . Alternatively, multiplex data\/address lines may be used instead of separate data and address lines.","In one embodiment of the invention, the processor  is a microprocessor such as the SPARC microprocessor from Sun Microsystems, Inc., the 680X0 processor manufactured by Motorola, or a microprocessor manufactured by Intel such as the 80X86 or Pentium processor. However, any other suitable microprocessor or microcomputer may be utilized. Main memory  is comprised of dynamic random access memory (DRAM). Video memory  is a dual-ported video random access memory. One port of the video memory  is coupled to video amplifier . The video amplifier  is used to drive the cathode ray tube (CRT) raster monitor . Video amplifier  is well known in the art and may be implemented by any suitable apparatus. This circuitry converts pixel data stored in video memory  to a raster signal suitable for use by monitor . Monitor  is a type of monitor suitable for displaying graphic images. Alternatively, the video memory could be used to drive a flat panel or liquid crystal display (LCD), or any other suitable data presentation device.","Computer  may also include a communication interface  coupled to bus . Communication interface  provides a two-way data communication coupling via a network link  to a local network . For example, if communication interface  is an integrated services digital network (ISDN) card or a modem, communication interface  provides a data communication connection to the corresponding type of telephone line, which comprises part of network link . If communication interface  is a local area network (LAN) card, communication interface  provides a data communication connection via network link  to a compatible LAN. Communication interface  could also be a cable modem or wireless interface. In any such implementation, communication interface  sends and receives electrical, electromagnetic or optical signals which carry digital data streams representing various types of information.","Network link  typically provides data communication through one or more networks to other data devices. For example, network link  may provide a connection through local network  to local server computer  or to data equipment operated by an Internet Service Provider (ISP) . ISP  in turn provides data communication services through the world wide packet data communication network now commonly referred to as the \u201cInternet\u201d . Local network  and Internet  both use electrical, electromagnetic or optical signals which carry digital data streams. The signals through the various networks and the signals on network link  and through communication interface , which carry the digital data to and from computer , are exemplary forms of carrier waves transporting the information.","Computer  can send messages and receive data, including program code, through the network(s), network link , and communication interface . In the Internet example, remote server computer  might transmit a requested code for an application program through Internet , ISP , local network  and communication interface .","The received code may be executed by processor  as it is received, and\/or stored in mass storage , or other non-volatile storage for later execution. In this manner, computer  may obtain application code in the form of a carrier wave.","Application code may be embodied in any form of computer program product. A computer program product comprises a medium configured to store or transport computer readable code or data, or in which computer readable code or data may be embedded. Some examples of computer program products are CD-ROM disks, ROM cards, floppy disks, magnetic tapes, computer hard drives, and servers on a network.","The computer systems described above are for purposes of example only. An embodiment of the invention may be implemented in any type of computer system or programming or processing environment; including embedded devices (e.g., web phones, etc.) and \u201cthin\u201d client processing environments (e.g., network computers (NC's), etc.) that support a virtual machine.",{"@attributes":{"id":"p-0100","num":"0107"},"figref":"FIG. 6"},"Thus, a method and apparatus for detecting device support in a graphical user interface has been described in conjunction with one or more specific embodiments. The invention is defined by the claims and their full scope of equivalents."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 7","b":"700"}]},"DETDESC":[{},{}]}
