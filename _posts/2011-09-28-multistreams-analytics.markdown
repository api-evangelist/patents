---
title: Multi-streams analytics
abstract: Multi-stream analytics is disclosed. An example method of multi-stream analytics with a query engine includes punctuating unbounded streaming data into data chunks, each of the data chunks representing a bounded data set in the unbounded streaming data. The method also includes processing one of the data chunks. The method also includes rewinding a query instance for processing another of the data chunks.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08880493&OS=08880493&RS=08880493
owner: Hewlett-Packard Development Company, L.P.
number: 08880493
owner_city: Houston
owner_country: US
publication_date: 20110928
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","DETAILED DESCRIPTION"],"p":["There are many sources of data, including for example, weather data, temperature data, network traffic data, and automobile traffic data. Analyzing this data in real time can provide valuable insight to various situations, including but not limited to the ability to predict and prevent failures, choose alternatives, and enhance user experiences. Due to the ever increasing volume of data that is available for analysis, and the desire to deliver faster data processing for real-time applications, continuous data analysis is pushing the limits of traditional data warehousing technologies. Data Stream Management Systems (DSMS) provide a paradigm shift from the load-first analyze-later mode of data warehousing by processing more efficiently than disk based data processing systems.","Current generation DSMS lacks the functionality offered by the structured query language (SQL) and Database Management Systems (DBMS). That is, an SQL query is definable only on bounded and finite data, but streaming data is unbounded and infinite. But because a stream query is defined on unbounded data, and in general is limited to non-transactional event processing, the current generation DSMS is typically constructed independent of the database engine. Separating the DSMS and query engine platforms result in higher overhead for accessing and moving data. Managing data-intensive stream processing outside of the query engine causes fails to leverage the full SQL and DBMS functionality.","While some analytical systems purport to offer a \u201ccontinued query\u201d mode, these systems are based on automatic view updates and therefore not really supporting continuous querying. Other systems leverage database technology, but are characterized by providing a workflow-like service for launching a one-time SQL query to buffered data stream sets iteratively in a non-dataflow fashion.","The ever increasing volume of data and the demand for faster and more efficient processing of real-time, continuous data streams makes new data analysis techniques desirable. The techniques described herein enable multi-stream analytics. An example system uses query engines to leverage the expressive power of SQL, the streaming functionality of query processing, and in general, the vast array of available database technologies.","A pipelined query engine can be thought of as a streaming engine, and therefore query processing can be leveraged for continuous stream analytics. But the fundamental difference between the two is that a query is traditionally defined on bounded relations, while data stream is unbounded. Joining multiple streams is a stateful (thus history-sensitive) operation. But a SQL query works on the current state. In addition, joining relations typically is by relation re-scan in a nested-loop. But by its very nature, a stream cannot be recaptured, because reading a stream in real time retrieves new incoming data.","Therefore, the program code described herein executes an extended SQL model that unifies queries over both streaming and stored relational data, and the query engine is extended for integrating stream processing and DBMS. In an example, a Cycle based Continuous Query (CCQ) model is defined. The CCQ model enables an SQL query to be executed on a cycle-by-cycle basis for processing the data stream in a chunk-by-chunk manner, without shutting the query instance down between execution cycles. This helps maintain continuity of the application state across execution cycles for history-sensitive operations (e.g., sliding-window operations).","For joining multiple streams, the approach described herein further includes buffering one or more consecutive data chunks falling in a sliding window across query execution cycles in the CCQ instance, to allow redelivery in subsequent re-scans. In this way multiple streams can be joined, and a single stream can be \u201cself-joined\u201d in a data chunk-based window or sliding window, with various pairing schemes.","Accordingly, the approach described herein may be implemented to unify query processing over both stored relations and dynamic streaming data. In an example, these capabilities are provided using the PostgreSQL engine to support truly continuous, yet cycle-based query execution. In addition, the user defined function (UDF) framework may be used to buffer data across query execution cycles. The systems and methods thus enable handling of multiple streams using an SQL query, in addition to being readily scaled and efficient.","In addition, by leveraging SQL's expressive power and the query engine's data processing capability for continuous analytics involving one or more input streams, the techniques described herein provide a continuous, long-standing query instance that handles per-tuple processing, maintains application state continuously, and supports granular analysis semantics in combination.","Before continuing, it is noted that as used herein, the terms \u201cincludes\u201d and \u201cincluding\u201d mean, but is not limited to, \u201cincludes\u201d or \u201cincluding\u201d and \u201cincludes at least\u201d or \u201cincluding at least.\u201d The term \u201cbased on\u201d means \u201cbased on\u201d and \u201cbased at least in part on.\u201d",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1","b":["100","100","101","102"]},"In an example, the system  may include a host  providing a service  which may be accessed by a user  via a client device  (e.g., personal computer or other electronics device such as a tablet) over a communication network . For purposes of illustration, the service  may be a data processing service executing on the host . Example services may include general purpose computing services (e.g., processing enterprise and\/or other sources of data sets provided via the Internet or as dynamic data endpoints for any number of client applications). Services also include interfaces to application programming interfaces (APIs) and related support infrastructure.","Although, it is noted that the operations described herein may be executed by program code  residing on the client , the data processing operations may be better performed on a separate computer system having more processing capability, such as a server computer or plurality of server computers (i.e., the host ). It is also noted that the service  may be a cloud-based service, wherein the program code is executed on at least one local computing device, but also has access to the service  in the cloud computing system.","The service  may include access to at least one data source . The data source may be local and\/or remote. That is, the data source  may be part of the service , and\/or the data source  may be physically distributed in the network and operatively associated with the service . The data source  may include any type and\/or amount of data. In the examples described herein, the data is streaming data (i.e., continuously arriving data). For example, the data source  may include data providing information about network traffic, automobile traffic, weather, and any of a wide variety of other types of streaming data. There is no limit to the type or amount of data that may be provided. In addition, the data may include unprocessed or \u201craw\u201d data, or the data may undergo at least some level of processing.","In an example, the program code  may be implemented in machine-readable instructions (such as but not limited to, software or firmware). The machine-readable instructions may be stored on a non-transient computer readable medium and are executable by one or more processor to perform the operations described herein.","Before continuing, it should be noted that the example devices and operating environment described above are provided for purposes of illustration, and are not intended to be limiting. Other devices and\/or device configurations may be utilized to carry out the operations described herein.","As mentioned above, the program code may be executed by any suitable computing device for multi-stream analytics of data provided by data source . Example program code  used to implement features of the system can be better understood with reference to the following operations.","The difficulty of using traditional SQL queries for processing data streams is that an SQL query is not definable on unbounded data and cannot return a complete result. If the query involves aggregation, the query engine never returns any result. Instead, the program code  described herein \u201ccuts\u201d the data stream into a sequence of \u201cchunks,\u201d with each chunk representing a bounded data set on which a query is definable.","In general, given a query (Q) over a set of relation tables (T, . . . T), and an infinite stream of relation tuples (S) with a criterion (\u03b8) for cutting S into an unbounded sequence of chunks. For example, a 1-minute time window may be used such that the <s, s, . . . s, . . . > where sdenotes the i-th \u201cchunk\u201d of the data stream according to the chunking-criterion (\u03b8). Then scan be interpreted as a bounded relation. The semantics of applying the query (Q) to the unbounded stream of relation tuples (S) plus relation tables (T, . . . T) lies in the following expression:\n\nQ(S,T, . . . T)\u2192<Q(s,T, . . . T), . . . Q(s,T, . . . T), . . . >\n","This expression continuously generates a sequence of query results, one on each chunk of the data stream. To implement this model on a query engine, a query captures stream elements on-the-fly, to punctuate the input data stream into chunks, to run cycle-by-cycle for processing the stream chunk-by-chunk, while maintaining continuity of the query instance for retaining the buffered data for history-sensitive applications (e.g., sliding window applications).","Accordingly, a stream capture function may be defined. Events are captured from streams and converted to relation data to fuel continuous queries. The first step is to replace the database table, which contains a set of tuples on disk, by a different type of table function, referred to herein as a Stream Capture Function (SCF). The SCF returns a sequence of tuples to feed queries without first storing those tuples on disk. In the other words, a table scan is replaced by a by function scan. The SCF can listen or read data and events sequence, and generate stream elements continuously on a tuple-by-tuple basis. The SCF can be called multiple times during the execution of a continuous query. Each call returns one tuple to fuel the query.","It is noted that fueling the query on a tuple-by-tuple basis upon receipt of an incoming event is not the same as a traditional function-scan. To the contrary, the traditional function-scan first provides all the output tuples, and then delivers those one by one. This can result in significant latency, and is semantically inconsistent with unbounded nature of a data stream.","The SCF scan is supported at two levels: (1) the SCF level, and (2) the query executor level. A data structure containing function call information bridges these two levels. The function call is initiated by the query engine and passed in\/out of the SCF for exchanging function invocation related information. This mechanism minimizes the code change and maximizes the extensibility of the query engine.","In addition, UDFs may be used to add window operators and other history sensitive operators, buffering raw data or intermediate results within the UDF closures. A UDF is called multiple times following a FIRST_CALL, NORMAL_CALL and FINAL_CALL skeleton. The data buffers are initiated in the FIRST_CALL, and used in each NORMAL_CALL. The query engine is extended to allow such \u201cmulti-call-process\u201d of a table function to span multiple input tuples as a scalar function, as will be described in more detail below.","Briefly, a window UDF incrementally buffers the data stream, and manipulates the buffered data chunk for the window operation. Although the CQ runs cycle-by-cycle for processing data stream chunk-by-chunk, the query instance remains active. Thus, the UDF buffer is retained between cycles of execution, and the data states are traceable continuously. In addition, the static data retrieved from the database can be loaded in a window operation initially, and then retained in the entire long-standing query.","To apply the CQ to unbounded data streams on a chunk-by-chunk basis, while maintaining the query instance without shutdown\/restart, the input data stream may be cut into a sequence of chunks. Each chunk represents a bounded data set on which a query is definable. After processing a chunk of data, the query instance is \u201crewound\u201d for processing the next chunk of data. That is, when the end-of-cycle event or condition is signaled from the SCF, the query engine completes the current query execution cycle, then rewinds the query instance for the next execution cycle. As such a CQ is running cycle-by-cycle, and is refer to herein as Cycle-based CQ (CCQ).","An example is illustrated below with reference to -. -illustrate application of (a) a query to a static (bounded) data set, such as tables, and (b) a continuous query cycle-by-cycle for processing a data stream chunk-by-chunk. In this example, a stream of network traffic packets has the following schema [pid, t, from-ip, to-ip, bytes, . . . ], where pid is the identification of the packet, and tis the source timestamp. It is noted that according to the TCP protocol, the stream of TCP\/IP packets transmitted from a source to a destination should arrive in the order of their source timestamps.","Querying may be implemented to capture data related to IP-to-IP network traffic, convert the data to host-to-host traffic, and then measure the traffic volume between each pair of hosts. The mapping from IP to host is given in the hosts_table. In the first example illustrated by , a one-time query defined on a bounded snapshot of the traffic flow is stored in the traffic table \u201ctraffic_table\u201d. This table is bounded, and so the query result involving aggregation (SUM) is well defined.","In the second example illustrated by , a query (Q) may be applied to the unbounded data stream generated using SCF. The SCF receives a packet stream from a socket, and generates and delivers packet tuples to fuel the stream query. The stream is unbounded, but is punctuated to bounded per-minute chunks for processing. The query derives the host-to-host traffic volumes on a minute-by-minute basis, as shown below:",{"@attributes":{"id":"p-0035","num":"0034"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"[Cycle-based Continuous Query: Q]"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"SELECT floor(S.t\/60) AS minute, h1.host-id AS from-host, h2.host-id"},{"entry":"AS to-host, SUM(S.bytes)"},{"entry":"\u2003\u2003\u2003FROM STREAM_get_packets(packet_stream, \u2002\u2018CUT \u2002ON \u2002t"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003BY \u200260 SECS\u2019)) S, Hosts h1, Hosts h2"},{"entry":"\u2003\u2003\u2003WHERE h1.ip = S.from-ip AND h2.ip = S.to-ip"},{"entry":"\u2003\u2003\u2003GROUP BY minute, from-host, to-host."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"In the above query (Q), the disk-resided database table is replaced by the SCF, STREAM_get_packets (packet_stream, \u2018CUT ON ts BY 60 SECS\u2019). Here, the term \u201cpacket_stream\u201d is the stream source, and the term \u201c\u2018CUT ON ts BY 60 SECS\u2019\u201d expresses the chunking criterion specifying that the stream source is to be \u201ccut\u201d into a sequence of bounded chunks every 60 seconds (1 minute chunks). The execution of the query (Q) on an infinite stream is made in a sequence of cycles, one on each data chunk. In this way, the query (Q) returns a sequence of chunk-wise query results.","To support cycle based query execution for chunk-wise data processing, a cut-and-rewind query execution mechanism may be implemented. That is, a query execution is \u201ccut\u201d based on the cycle specification, and then the state of the query rewinds (without shutting down) for processing the next chunk of data stream in the next cycle.","The \u201ccut\u201d originates in the SCF at the bottom of the query tree. The SCF has a general form of STREAM(SS, cycle-spec), which specifies that the stream source SS is to be \u201ccut\u201d into an unbounded sequence of chunks. The \u201ccut point\u201d is specified in the cycle-spec. Upon detection of an end-of-cycle condition, the SCF signals end-of-cycle punctuation to the query engine, resulting in termination of the current query execution cycle.","In general, the end-of-cycle is determined when the first stream element belonging to the next cycle is received. Then that element is cached to be processed first in the next cycle.","Upon termination of an execution cycle, the query engine does not shut down the query instance, but instead rewinds the query instance for processing the next chunk of data stream. Rewinding a query is a top-down process along the query plan instance tree, with specific treatment on each node type. In general, the intermediate results of the SQL operators (associated with the current chunk of data) are discarded. But the application context is maintained in the UDFs (e.g., for handling sliding windows). Because the query instance remains \u201calive\u201d across cycles, data for sliding-window oriented, history sensitive operations can proceed in an ongoing basis.","Multiple common chunking criteria can be supported for punctuating a stream, including chunking by cardinality, i.e. the number of inputs; chunking by input range, e.g. by time-window; and chunking by \u201cobject\u201d based on the chunk-key attribute (e.g., the identification of a graph appearing in multiple consecutive stream elements).","In addition, a cycle-based transaction model can be coupled with the cut-and-rewind query model to \u201ccommit\u201d a stream query one cycle at a time in a sequence of \u201cmicro-transactions.\u201d This approach makes the per-cycle stream processing results visible as soon as the cycle ends.","Stream join is a fundamental operation for relating information from different streams. Referring again to the example described for , two streams of packets seen by network monitors placed at two routers can be joined on packet ids to identify the packets that flowed through both routers, and compute the time delta to reach these routers. Joining operations including input streams will now be described in more detail with reference to -. -illustrate example join operations.","Join a Stream Window and a Static Table.","Joining stream elements falling in a time window (S) and a relation (R) returns the set of all pairs <s, r>, where s\u03b5S, r\u03b5R, and the join condition \u03b8(s, r) evaluates to true. illustrates joining a table with a chunk from a buffered data stream that can be re-scanned for returning the same data as the original scan.","It can be seen with reference to the previously described query (Q), that the input data stream generated by the SCF STREAM_get_packets( ) are joined with table hosts in the per-minute chunk to derive the host-to-host traffic volume on the minute basis. In each cycle, the chunk of data stream is bounded, and so the query (Q) can generate query results on a cycle-by-cycle basis. The join of a data stream chunk returned from STREAM_get_packets( ) with the hosts table, is the operation taking place in each query execution cycle with three nested loops, illustrated below:",{"@attributes":{"id":"p-0047","num":"0046"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"for each tuple r in the chunk of the stream do"]},{"entry":[{},"\u2003\u2003\u2003for each tuple h1 in Hosts do"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003for each tuple h2 in Hosts do"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003if r and h1, h2 satisfy the join condition"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003then output the tuple <r, h1, h2>."]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"It can be seen that re-scanning a table, such as the hosts table above, results in the same data content as the original scan. However, in case the SCF, STREAM_get_packets( ) is re-executed on the \u201cre-scan\u201d demand in an query execution cycle, the query should not read in a new data stream. Instead, the query should deliver the original chunk of data received in the current query execution cycle. Reading in a new data stream during re-scan is inconsistent with the semantics of re-scan and generates incorrect join results. However, this is unlikely in joining a stream with a static table, because the cardinality of a data stream source (represented by a SCF) is unknown. Instead, the query optimizer tends to re-scan the table with a known cardinality.","Window-Join Multiple Streams.","Stream join is an operation for relating information from different streams. Like relation join, stream-join is a stateful operation. In the time-based dataflow context, joining two streams chunk-wise is a block operation. That is, the operation takes place only after two chunks of data stream are received. In general, given two streams S and S\u2032 punctuated by the same chunking criterion, in each query execution cycle, the most recent chunks (Sand S\u2032) are joined. The query execution cycle thus returns the set of all pairs <s, s\u2032>, where s\u03b5S, s\u2032\u03b5S\u2032, and the join condition \u03b8(s, s\u2032) evaluates to true. This can be seen in , where only the most recent chunks of each stream are joined.","As mentioned above for function scan (the access method of stream query), nested loop join is the default system choice that potentially involves \u201cre-scan a stream source\u201d. With non-data stream, re-scan always gets the same set of input data. With SCF, \u201cscan\u201d a stream source initially receives the newly incoming data stream, and \u201cre-scan\u201d returns the same data as the above initial scan. These two behaviors are automatically switchable during stream-join.","The above example can be extended by considering two streams of data packets (Sand S), seen by network monitors placed at two routers (RTand RT). CCQ can be used to join the data streams in the minute based chunks, on packet IDs to identify those packets that flowed through both routers, and compute the average time for such packets to reach the two routers (RTand RT).","The two streams have the same schema [pid, t, from-ip, to-ip, bytes, t. . . ], where tis the timestamp captured at the router, and the stream punctuation point is determined by the source timestamp (t), as follows:",{"@attributes":{"id":"p-0054","num":"0053"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"[Cycle-based Continuous Query for Stream-Join : Qc]"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"SELECT floor(S.t\/60) AS minute, AVG(S.t\u2212S.t) FROM"]},{"entry":[{},"\u2003\u2003\u2003STREAM_get_packets (RT, \u2018CUT ON tBY 60 SECS\u2019,"]},{"entry":[{},"\u2003\u2003\u2003\u2018BLOCK\u2019)) S1,"]},{"entry":[{},"\u2003\u2003\u2003STREAM_get_packets (RT, \u2018CUT ON tBY 60 SECS\u2019,"]},{"entry":[{},"\u2003\u2003\u2003\u2018BLOCK\u2019)) S,"]},{"entry":[{},"\u2003\u2003\u2003WHERE S.pid = S.pid GROUP BY minute."]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The re-scan semantics are enforced by extending the buffer hierarchy and invocation pattern of the table functions serving as SCFs. This allows the data chunk read in each query execution cycle to be buffered and re-delivered in the subsequent \u201cre-scans,\u201d which is indicated by the SCF's parameter \u2018BLOCK\u2019.","In each query execution cycle, the SCF (as a table function) is called multiple times for returning multiple tuples generated from the received events. The associated buffer state is initiated at the beginning of the first call, and finalized (e.g., cleanup) at the end of the last call. These calls make up the multi-call-process of a function scan in the query execution cycle. In the initial function-scan, the SCF returns multiple tuples generated from the received stream elements to fuel the query; it takes place only once per query-cycle. If re-scan is needed in the subsequent function-scans, the SCF returns the buffered tuples.","To support this mechanism, two extensions are made to the query engine. One extension includes buffering SCF's input data across multiple function-scans in a cycle, as well as across multiple cycles. Another extension switches the SCF's behavior for delivering the initially captured data in the first scan and delivering the buffered data in all the subsequent re-scans.","To support re-scan and to distinguish the initial scan and the re-scan, a Boolean variable is provided with state retained across multiple function scan and re-scans in a query execution cycle. This variable is set during the initial scan, indicating \u201cthe initial scan has been done\u201d. For each function scan, if this variable is not set, the initial scan process is invoked for getting new data from the stream source. Otherwise, the re-scan process is invoked for delivering the already buffered data.","It is noted that the above example was described as a nested-loop join. However, this approach is also applicable to other join types.","Join Streams in Sliding-Windows.","In general, by adjusting the buffer boundary, join two streams on the chunk-based sliding windows with various pairing schemes is possible. Note that a chunk-based sliding window shifts chunk-by-chunk, and a chunk can be as small as a single tuple. By way of illustration, consider two streams S and S\u2032 captured by SCF and SCF\u2032, and commonly chunked by timestamp. SCF keeps a sliding window buffer for M data chunks of S, and SCF\u2032 holds N data chunks of S\u2032. In each query execution cycle, join m\u2266M chunks, (S) is held in SCF, and n\u2266N chunks (S\u2032) in SCF\u2032 returns the set of all pairs <s, s\u2032>, where s\u03b5S, S\u2032n, and the join condition \u03b8(s, s\u2032) evaluates to true.","In case M=1 or N=1, the joins are not overlapped between query execution cycles. Instead, the stream join takes place every query execution cycle. This is illustrated in . shows joining two streams -by pairing chunks buffered in chunk-based sliding windows . The buffered data chunks can be re-scanned. The CCQ (Q), described above, is a special (but frequently used) case where M=N=1.","Self-Join a Stream in a Sliding Window.","Self-joining different chunks (e.g., the most recent chunk and certain past chunks) of the same stream for correlation purposes in a sliding window, is useful in many applications. The problem can be described using the following example of a stream (S) and a sliding window (S) having the consecutive chunks of S, <S, S, . . . S>, where Sis the most recent chunk. Joining Swith Sreturns the set of all pairs <s, s>, where s\u03b5S, s\u03b5S, and the joining condition \u03b8(s0, sw) evaluates to true.","This is conceptually shown in . shows joining the most recent chunk with the previous chunks of the same stream maintained in a sliding window, by using two SCFs which buffer the stream differently.","By way of illustration, in telecommunication monitoring applications, a Call Detail Record (CDR) data stream often includes duplicate CDRs representing the same phone call, but generated by different probes with slightly different start-call timestamps (t), for example, 0.2 seconds delta. Identifying such duplicate CDRs can be treated as joining the CDR captured in a 5 second chunk with those captured in the past 1 minute (12 chunks), as expressed by the CCQ.","To fuel this query, the CDR stream may be split and fed in two SCF instances (e.g., SCF and SCF), where both SCF instances chunk the input stream every 5 seconds by timestamp. SCF maintains the current chunk of data, and SCF continuously maintains a sliding window including 12 chunks (e.g., 1 minute) of data. The sliding window shifts chunk-by-chunk. In each 5 second cycle, the current chunk of data captured by SCF are joined with the 12 chunks of data kept in SCF. Each new data chunk appears in SCF only once, and therefore will be joined with the data chunks held in SCF without being duplicated. Additional and\/or other operations to eliminate the duplicates may also be implemented. This technique may be used, for example, to correlate the most recent data stream with the previous ones in a sliding window boundary.","Extending the Query Engine to Support SCF Re-Scan.","As described above, the query engine may be extended to support the cut-and-rewind approach for handling CCQ-based stream processing. In addition, user defined function (UDF) buffer management may also be supported to enable CCQ-based stream join. A UDF can be used to maintain a data buffer. A UDF may be called multiple times in a single host query, with respect to each input and output. Therefore, the life-span of the data buffer may be managed with respect to these invocations.","The input of scalar, aggregate, and\/or table functions is bound to the attribute values of a single tuple, where an aggregate function may be implemented with an incremental, per-tuple calculation. A scalar or aggregate function is called multiple times, one for each input with a single return value (or a tuple as a composite value). A table function, however, can return a set out of a single input. Accordingly, on each input, the function may be called multiple times, one for each output. That is, the multi-call-process of a scalar\/aggregate function spans over all the input tuples, but the multicall-process of a table function limits to one input only, while across multiple returns out of that single input.","The SCF is a table function with parameters bearing the chunking condition, stream source, etc. A function scan by a SCF is a multi-call-process. In each query cycle, there is an initial function scan, and possibly multiple subsequent re-scans.","The \u201ctop-level\u201d data buffer of a table UDF is related to the multi-call-process, and thus only to a single function scan. To support stream join, the table function's data buffering may be extended across multiple function scans in a cycle for a chunk of data, and across multiple chunks. In addition, the table function's data buffering may be extended to the existing per-input\/multi-returns data buffering in a single function scan. Therefore, the query engine and the Table UDF framework may be extended to allow the SCF to retain a data buffer across multiple function-scans with respect to the processing of one or more chunks of data.","In an example, a query may be parsed, optimized, and planned to form a query plan tree. To be executed, an instance of the query plan is initiated with nodes representing operators and their states. A UDF is represented by a function node that is the root of its function closure, where the information about the function, function-invocation, and the data buffers are provided. It is noted that the function node is external to the function (e.g., the UDF), and therefore the data linked to the function node may be sustained across multiple function calls.","Accordingly, the table UDF buffer management may be extended as follows. A data structure is extended under the function node with an additional pointer, and a new buffer allocated under the pointer. The life-span of this buffer sustains across multiple function-scans. Multi-layers of buffers (or memory context) is supported across multiple chunks, per-chunk, per-input tuple (e.g., per-scan with multi-returns), and per-return. In addition, the scope and time of memory de-allocation may be controlled in terms of system internal utilities (e.g. after a returned tuple, a function-scan, or the whole query has been processed).","Accordingly, new APIs for creating data buffer with per-query, per-chunk and per-scan initial states can be distinguished. In general, the buffers of the UDF at all levels are linked to the system handle for function invocation, and accessible through system APIs.",{"@attributes":{"id":"p-0076","num":"0075"},"figref":"FIG. 4","b":"400"},"Operation  includes punctuating unbounded streaming data into data chunks, each of the data chunks representing a bounded data set in the unbounded streaming data. Operation  includes processing one of the data chunks. Operation  includes rewinding a query instance for processing another of the data chunks. In an example, the operations may include executing a sequence of query cycles on a sequence of data chunks. Also in an example, the query may use the structured query language (SQL).","The operations shown and described herein are provided to illustrate example implementations. It is noted that the operations are not limited to the ordering shown. Still other operations may also be implemented.","Still further operations may include joining multiple input streams, joining a stream window and a static table, window-joining multiple input streams, joining streams in sliding windows, and self-joining a stream in a sliding window. Each of these operations has already been described in more detail above, and therefore the description is not repeated again here.","The operations may be implemented at least in part using an end-user interface (e.g., web-based interface). In an example, the end-user is able to make predetermined selections, and the operations described above are implemented on a back-end device to present results to a user. The user can then make further selections. It is also noted that various of the operations described herein may be automated or partially automated.","It is noted that the examples shown and described are provided for purposes of illustration and are not intended to be limiting. Still other examples are also contemplated."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIGS. 2","i":["a","b "]},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIGS. 3","i":["a","c "]},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
