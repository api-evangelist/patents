---
title: Task-driven multitasking method that constrains task suspension to task preemption
abstract: While preemptive multitasking has been available for task-driven methods that use multiple call stacks and even-driven methods that use a single call stack, an embodiment of a new method teaches how preemptive multitasking may be achieved in a single call stack for task-driven applications. The new method requires significantly less memory and processing overhead than required to manage multiple call stacks and provides a significant reduction in transition states and lines of application code than required for event-driven methods. The method comprises providing a single call stack, providing a preemptive scheduler, providing a wait operation which is followed by a return to the scheduler, wherein execution context is not preserved, and providing a signal operation which may be invoked synchronously from a task handling function and/or asynchronously from an interrupt routine, whereby the scheduler is invoked and execution context is preserved and subsequently restored by the single call stack.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08739176&OS=08739176&RS=08739176
owner: 
number: 08739176
owner_city: 
owner_country: 
publication_date: 20100305
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","STATEMENT REGARDING FEDERALLY SPONSORED RESEARCH OR DEVELOPMENT","INCORPORATION-BY-REFERENCE OF MATERIAL SUBMITTED ON A COMPACT DISC","BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION","CONCLUSION, RAMIFICATIONS, AND SCOPE"],"p":["Not applicable","Not applicable","A computer program listing appendix is submitted herewith on a single compact disc (in duplicate). The material contained on the compact disc is incorporated herein by reference. The files included on the compact disc are as follows:",{"@attributes":{"id":"p-0005","num":"0004"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"77pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"98pt","align":"center"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["File Name","Size","Date of Creation"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["darling.c","7,439 bytes","Feb. 12, 2010"]},{"entry":["darling.h","4,160 bytes","Feb. 12, 2010"]},{"entry":["list.c","2,389 bytes","Feb. 12, 2010"]},{"entry":["list.h","2,099 bytes","Feb. 12, 2010"]},{"entry":["node.c","1,805 .bytes","Feb. 12, 2010"]},{"entry":["node.h","3,341 bytes","Feb. 12, 2010"]},{"entry":["port.h","1,882 bytes","Feb. 12, 2010"]},{"entry":["pque.c","5,573 bytes","Feb. 12, 2010"]},{"entry":["pque.h","2,133 bytes","Feb. 12, 2010"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"1. Field of the Invention","This invention relates generally to computer multitasking, specifically to a multitasking method for microcomputers that support a call stack, either in hardware or via software.","2. Description of Related Art","Multitasking methods are widely used in the industry of software development. These methods are often packaged as a software library, whose services are available to software applications via an application programming interface (API). They enable software developers to divide and conquer complex problems into several manageable tasks. They allow a microcomputer to perform several tasks seemingly simultaneously by switching back and forth between tasks. The prior art includes (1) preemptive, task-driven multitasking methods, (2) non-preemptive, task-driven multitasking methods, and (3) preemptive, event-driven multitasking methods. Examples of each of these methods are presented, and their call stack usage and respective disadvantages are explained.","A typical real-time operating system (RTOS) is an example of a preemptive, task-driven multitasking method. Preemptive means lower priority tasks may be interrupted in order to service higher priority tasks. And task-driven means the flow of an application is specified by its application code (the program using the RTOS). An introduction to RTOS theory and design is provided by Jean Labrosse in his book, --2CMP Books 2002.","Coroutines are used to implement non-preemptive, task-driven multitasking methods. Non-preemptive means that lower priority tasks cannot be interrupted to service higher priority tasks. Rather, a higher priority task scheduled while a lower priority task is executing must wait until the lower priority task has completed. Another term often used to describe coroutines is cooperative. An introduction and implementation of coroutines is provided in the article, \u201cCoroutines in C\u201d by Simon Tatham in 2000 (www.chiark.greenend.org.uk\/\u02dcsgtatham\/coroutines.html).","A run-to-completion (RTC) kernel is an example of a preemptive, event-driven multitasking method. (For the purposes of this document, the terms kernel and operating system may be used interchangeably.) Run-to-completion means the task code cannot suspend its own execution prior to completion. Event-driven means the flow of an application is determined by the occurrence of events. For example, when an event occurs, it drives the execution of certain task code. An introduction and explanation of a typical RTC kernel is provided by Miro Samek and Robert Ward in their article \u201cBuild a Super Simple Tasker,\u201d Embedded Systems Programming, July 2006.","Multitasking methods typically employ a call stack to store return addresses and local variables for hierarchal functions and subroutines called for in software. Call stack usage varies considerably, depending on the multitasking method employed. An RTOS typically allocates a call stack for each and every task, whereas coroutines or an RTC kernel may employ a single call stack for use by all tasks. Another component required to support a call stack is an execution context. For each call stack supported by a multitasking method, a corresponding execution context maintains where each task is currently operating within its call stack.","Disadvantages of using a typical RTOS include having to maintain a separate call stack and for each and every task and having to specify upfront how much memory is dedicated to each call stack.  shows three tasks supported by an RTOS, each with its own call stack (, , and ) and each with its own execution context (, , and ). Allocating too little memory for a task can cause unpredictable behavior that can be difficult to troubleshoot. Furthermore, significant overhead is required to save and restore execution contexts when switching from one task context to another. Saving and restoring execution contexts, moreover, is dependent on microcomputer architecture, and thus processor specific code must be written for each processor supported by a typical RTOS.","The obvious disadvantage for coroutines is non-deterministic response time. A small, deterministic response time for high priority events and\/or tasks is a critical performance measure for multitasking methods. As such, preemptive methods typically outperform cooperative methods. Moreover, coroutines that employ a single stack typically constrain task switching to occur at the task level, not from within subroutines. Two such methods exploited for memory constrained applications include Protothreads, explained by Adam Dunkels, et al. in \u201cUsing Protothreads for Sensor Node Programming,\u201d from -(2005) and the method shown in U.S. Pat. No. 6,823,517 to Kalman (2004).","The primary disadvantage of using an RTC kernel is added complexity for application code. Although deterministic task handling may be achieved for event-driven systems via hierarchal state handling, the onus for this is passed to the application code. An analysis of the advantages and disadvantages of implementing task-driven vs. event-driven code is provided by Dunkels, et al., in \u201cProtothreads: Simplifying Event-Driven Programming of Memory-Constrained Embedded Systems.\u201d The analysis shows that while execution overhead and code size grow slightly for task-driven code, reduction in transition states and lines of code is significant.","What is clearly needed is a multitasking method that supports the benefits of preemption, without the execution overhead introduced by a traditional RTOS and without the complexity for application code introduced by event-driven methods. The following definitions are provided for terms or concepts relevant to describing a solution to this need:\n\n","The foregoing examples of the related art and limitations related therewith are intended to be illustrative and not exclusive. Other limitations of the related art will become apparent to those skilled in the art upon a reading of the specification and a study of the drawings.","This invention is directed to an embodiment of a multitasking method for task-driven applications comprising providing a single call stack, providing a preemptive scheduler which supports synchronous and asynchronous task preemption, providing one or more pend-on-event services (i.e. wait or sleep) which are followed by a return to the scheduler, wherein execution context is not preserved, and providing one or more signaling services (i.e. signal or tick) which may be invoked synchronously from a task handling function and\/or asynchronously from an interrupt routine, whereby the scheduler is invoked and execution context is preserved and subsequently restored by the single call stack.","The following embodiments and aspects thereof are described and illustrated in conjunction with systems, tools and methods which are meant to be exemplary and illustrative and not limiting in scope. In various embodiments one or more of the above-described problems have been reduced or eliminated while other embodiments are directed to other improvements. In addition to the exemplary aspects and embodiments described above, further aspects and embodiments will become apparent by reference to the drawings and by study of the following descriptions.","Exemplary embodiments are illustrated in reference figures of the drawings. It is intended that the embodiments and figures disclosed herein are to be considered to be illustrative rather than limiting.","The preferred embodiment provides task-driven, computer multitasking within a framework that constrains task suspension to task preemption. This embodiment comprises a preemptive scheduler (sched_check), two pend-on-event services (sleep and wait), and a call to one of the pend-on-event services each and every time a task must pend on an event occurrence. Other services (tick, signal, and signal_from_isr) work in conjunction with the pend-on-event services. And other services provide for initialization (init, task_init, and sema_init) and multitasking startup (start).","By constraining task suspension to task preemption, preempting tasks can dynamically build upon preempted tasks such that a single call stack and execution context can manage all tasks.  shows the same three tasks as shown in , where task  has preempted task  and task  has preempted task . The context of task  (, f, ) is at the bottom of the call stack (). The context of task  (, a, , , ) is stacked above task . And the context of task  (e, ) is currently executing. When task  is complete, the execution context () pops back to the context of task , and when task  is complete, the execution context pops back to the context of task  (assuming that no further preemptions occur). Note that while the call stacks in  (, , and ) are fixed in size, the call stack in  () grows and shrinks dynamically to fit the tasks that are operating within it.","For the preferred embodiment, task-driven control is supported by pend-on-event services. Although not required for the current invention, it is intuitive that nothing occurs subsequent to a pend-on-event service call until the event has occurred. Therefore, the preferred embodiment restricts pend-on-event services to a tail-call or a nested tail-call. By definition, a tail-call is a final subroutine called prior to returning from a function. See Listing 1 for an example. And a nested tail-call is defined herein as a final subroutine called prior to returning from a tail-call. See Listing 2 for an example.",{"@attributes":{"id":"p-0039","num":"0062"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Listing 1: A tail-call is a final subroutine called prior to "},{"entry":"returning from a function (lines 4, 9, and 11), where"},{"entry":"alternate control paths lead to multiple tail-calls."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","void function1 ( void )"]},{"entry":["2","{"]},{"entry":["3","\u2003subroutine1 ( );"]},{"entry":["4","\u2003subroutine2 ( ); \/* tail-call *\/"]},{"entry":["5","}"]},{"entry":["6","void function2 ( int count )"]},{"entry":["7","{"]},{"entry":["8","\u2003if (count > 0 )"]},{"entry":["9","\u2003\u2003subroutine1 ( ); \/* tail-call *\/"]},{"entry":["10","\u2003else"]},{"entry":["11","\u2003\u2003subroutine2 ( ); \/* tail-call *\/"]},{"entry":["12","}"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0040","num":"0063"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Listing 2: The tail-call of subroutine2 is a nested tail-call "},{"entry":"(a tail-call of a tail-call) for function1."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"1","void subroutine2 ( void )"]},{"entry":[{},"2","{"]},{"entry":[{},"3","do_this ( );"]},{"entry":[{},"4","do_that ( ); \/* nested tail-call *\/"]},{"entry":[{},"5","}"]},{"entry":[{},"6","void function1 ( void )"]},{"entry":[{},"7","{"]},{"entry":[{},"8","subroutine1 ( );"]},{"entry":[{},"9","subroutine2 ( ); \/* tail-call *\/"]},{"entry":[{},"10","}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"The pend-on-event services provided by the preferred embodiment are a sleep service that delays further processing for a period of time, and a wait service that delays further processing pending an event signal. These services provide a means for task-driven control. They do not merely register a task for event notification, as is typical of event-driven systems. Therefore, a task must request a pend-on-event service each and every time further processing depends on an event occurrence. As such, control is maintained by task code.","Application Programming Interface\u2014Listing 3","The services provided by the preferred embodiment are few. They have been selected as a means for describing how to implement and make use of the current invention. Listing 3 shows the application programming interface (API) for the preferred embodiment, as written in the \u2018C\u2019 programming language. The API provides core services, typical of a real-time operating system (RTOS), including services for task initialization and task synchronization.",{"@attributes":{"id":"p-0043","num":"0066"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Listing 3: Application programming interface (API) "},{"entry":"for the preferred embodiment."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","void","init (void);"]},{"entry":["2","void","sched_check (void);"]},{"entry":["3","void","sema_init (Sema* handle, int initial_count);"]},{"entry":["4","void","signal (Sema* handle);"]},{"entry":["5","void","signal_from_isr (Sema* handle);"]},{"entry":["6","void","sleep (int ticks, void (*handler)(void*));"]},{"entry":["7","void","start (void (*idle_task)(void));"]},{"entry":["8","void","task_init (Task* handle, void (*handler)(void*), "]},{"entry":[{},{},"void* parameter, int priority);"]},{"entry":["9","void","tick (void);"]},{"entry":["10","void","wait (Sema* handle, void (*handler)(void*));"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"The return value of each service is specified first, as void since nothing is returned by the API services. The name of the service is then followed by its input parameters in parenthesis. Input parameters also have types, such as void and int, or specially defined types, such as Task and Sema (defined below). The parameter type is followed by the parameter name, and a comma separates one parameter from another. An asterisk indicates a pointer to a type, void* represents a generic pointer, and the notation void (*f)(void*) represents a pointer to a function, f. Note that the API for the pend-on-event services (lines 6 and 10) supports the specification of a task handler (a pointer to a function) as an entry point for further task processing. Although this specification is not typical for an RTOS, nor required for other embodiments, it is supported by the preferred embodiment because it provides the flexibility to specify a new entry point for the current task. Other embodiments may support a separate service for specification of a new entry point.","Data Structures\u2014Listings 4-5",{"@attributes":{"id":"p-0045","num":"0068"},"figref":"FIGS. 3-12"},{"@attributes":{"id":"p-0046","num":"0069"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Listing 4: Data structures for the preferred embodiment."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","struct Task {"]},{"entry":["2","\u2003void (*handler)(void*);"]},{"entry":["3","\u2003void* parameter;"]},{"entry":["4","\u2003int priority;"]},{"entry":["5","\u2003int status;"]},{"entry":["6","\u2003int delay;"]},{"entry":["7","};"]},{"entry":["8","struct Sema {"]},{"entry":["9","\u2003int count;"]},{"entry":["10","\u2003PQue pending_queue;"]},{"entry":["11","};"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"The task components (lines 2-6 of Listing 4) include a task handler, a priority, a status, and a delay. The task handler specifies a function pointer (handler) and a corresponding parameter. The priority specifies the priority level of the task within the multitasking method. The status specifies the current task status (i.e. running, ready, or pending). And the delay component is used in conjunction with the sleep service to track the amount of time (or number of ticks) remaining prior to a task running again. The semaphore components (lines 9-10 of Listing 4) include a count and a pending_qeue. The count keeps track of the number of events that occur, and the pending_queue maintains a priority queue of tasks pending on an event occurrence. A priority queue is a common data structure, well known to one skilled in the art of programming.","The flowcharts also refer to global data, although in other embodiments this data need not be global. Listing 5 shows the global data for the preferred embodiment. A priority queue (line 1 of Listing 5) is used to form a queue of tasks that are ready to run (ready_queue). And although there is no variable that indicates which task is running, that task is referred to in the flowcharts as the running_task. The running_task is the highest priority task in the ready_queue being executed by the sched_check service. And finally, a list (line 2 of Listing 5) is employed for those tasks that have been delayed using the sleep service. (Note that for the preferred embodiment, tasks in the sleeping_list have a status of \u2018pending\u2019.) A list is another common data structure, well known to one skilled in the art of programming.",{"@attributes":{"id":"p-0049","num":"0072"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Listing 5: Global data for the preferred embodiment."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","PQue ready_queue;"]},{"entry":["2","List\u2003 sleeping_list;"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{},"figref":"FIGS. 3-12"},"Prior to starting multitasking, it is necessary to initialize global data, tasks, and semaphores using the init, task_init, and sema_init services, respectively. First, the global data is initialized with the init service, according to the procedure shown in . The init () service initializes the ready_queue () and the sleeping_list () and then returns (). The initialization procedures for these common data structures are well known to one skilled in the art of programming.","Each task is initialized with the task_init () service as shown in , according to the input parameters, handle, handler, parameter, and priority. The handle parameter provides access to a task structure (Task), and a dash (-) notation is used herein to reference the components of a structure from a pointer to that structure. The handler, parameter, and priority components (handle-handler, handle-parameter, and handle-priority) are set equal to the handler, parameter, and priority parameters, respectively (, , and ). The delay component (handle-delay) is set to zero (), the status component (handle-status) is set to \u2018ready\u2019 (), and the task (handle) is added to the ready_queue (). And the service returns ().","Each semaphore is initialized with the sema_init () service as shown in , according to its input parameters, handle and count. The handle parameter is a pointer to a semaphore structure (Sema). The count component (handle-count) is set equal to the count parameter (), the priority queue (handle-pending_queue) is initialized (), and the service returns (). Again, initialization of a priority queue is a procedure well known to one skilled in the art of programming. Each semaphore is initialized once, and the count parameter specifies the initial number of event occurrences.","Tasks typically perform a sequence of operations again and again. Although task-driven task handlers are typically modeled as infinite loops, this is unnecessary for the preferred embodiment. An infinite loop is contained within the start service of the preferred embodiment, and all other tasks build and run preemptively upon it. As shown in , the start () service begins with a call to sched_check (). This call to sched_check runs each initialized task at least once. Next, interrupts are enabled (). If no other tasks are ready to run, execution defaults to an idle_task, passed as a parameter to the start service. The idle_task is called within an infinite loop, and it runs as the lowest priority task when no other tasks are running (). The idle_task may be used to calculate and report the percentage of microcomputer processor cycles used by an application. It may also be used to put the microcomputer into low power modes of operation. Note that this service never returns.","A central component of the preferred embodiment is the preemptive task scheduler, sched_check (). This preemptive task scheduler is invoked within other API services each and every time a new task may have been scheduled. If a newly scheduled task has a higher priority than the currently running task, the new task is executed. The sched_check service is invoked directly only as a tail-call of an interrupt service routine. As shown in , the sched_check service begins by checking if ready_queue () is empty. If not, and the status of the highest priority task is \u2018ready\u2019 (), the following steps are performed: the status of the highest priority task is set to \u2018running\u2019 (), interrupts are enabled (), the highest priority task is executed (), and then interrupts are disabled (). This process then repeats itself by checking if another task is in the ready_queue. If either of the said conditions ( and ) is not satisfied, the sched_check service returns (). Note: Task execution () requires calling the function pointed to by the handler attribute of a task with the parameter attribute as its parameter.","A semaphore is a task synchronization primitive used for interrupt-to-task and inter-task communication. Although a semaphore typically supports non-preemptive task suspension for a traditional RTOS, a semaphore is implemented for the preferred embodiment as a pend-on-event service. The preferred embodiment provides the wait (), signal (), and signal_from_isr () services for pending on events and signaling them, respectively. Although wait and signal may also be used for mutual exclusion, they do not prevent priority inversion scenarios in which a low priority task acquires a semaphore required by a high priority task and the low priority task is interrupted by other medium priority tasks. Other embodiments may provide lock and unlock services that preclude priority inversion, wherein task switching is disabled upon acquiring a semaphore and then enabled upon signaling it.","The wait () service is requested by application code when continued processing depends on an event occurrence. And since wait is a pend-on-event service, it is limited to a tail-call or nested tail-call for the preferred embodiment. The handle parameter provides access to a semaphore's components, and the handler parameter specifies an entry point for further task processing. As shown in , wait starts by setting the task entry point (running_task-handler) equal to the handler parameter () and disabling interrupts (). Then if the count component (handle-count) is zero (), the task status (running_task-status) is set to \u2018pending\u2019 (), and the running_task is moved from the ready_queue to the semaphore's pending_queue (). Otherwise, if the count component is nonzero (), the count is decremented (), the task status (running_task-status) is set to \u2018ready\u2019 (), and the running_task is removed from the ready_queue and re-inserted (). Finally, interrupts are re-enabled () and the service returns ().","The signal () service is provided to mark the occurrence of an event from within a task. This service may only be requested from within a task handler (not an interrupt service routine), and it should be requested with interrupts enabled. As shown in , the signal service begins by disabling interrupts (). If the pending_queue component (handle-pending_queue) is not empty (), the status of the highest priority task in the pending_queue is set to \u2018ready\u2019 (), the highest priority task in the pending_queue is moved to the ready_queue (), and the sched_check service is requested (). Otherwise, if the pending_queue component (handle-pending_queue) is empty () and the count component (handle-count) is less than its maximum value (), the count component is incremented (). If the count component has reached its maximum value, an overflow is reported (). (The method of reporting the overflow is not presented and not relevant to the preferred embodiment. A proper application design will not result in overflows under normal operating conditions.) Finally, interrupts are enabled () and the service returns ().","The sleep () and tick () services are best explained together, as they are interdependent. For the preferred embodiment, sleep is a pend-on-event service and is thus limited to a tail-call or nested tail-call. The sleep service is requested from application code in order to delay further processing. The tick service updates delayed tasks for the preferred embodiment from a timer interrupt routine. The frequency at which the delayed tasks are updated determines the granularity of the sleep service. For example, if the tick service is called every millisecond, tasks may be delayed in units of milliseconds.",{"@attributes":{"id":"p-0059","num":"0082"},"figref":"FIG. 10","b":["1002","1004","1006","1008","1010","1012","1014","1006","1016","1018","1020","1022","1024"]},{"@attributes":{"id":"p-0060","num":"0083"},"figref":"FIG. 11","b":["1102","1104","1106","1108","1110","1112","1114"]},"An interrupt handler is a routine triggered either by an asynchronous event requiring attention or a synchronous event specified in software (i.e. a timer). The way in which interrupt service routines are triggered by interrupt requests depends on microcomputer architecture. Regardless of how an interrupt service routine (ISR) is triggered, the ISR has two main responsibilities: (1) the corresponding interrupt request is acknowledged, and (2) the interrupt is processed. The ISR may require an end of interrupt (EOI) instruction to signal when interrupt processing has completed, depending again upon microcomputer architecture.","For the preferred embodiment, it is assumed that interrupts are disabled when an interrupt service routine is triggered. In order to mitigate high priority interrupt response time, some microcomputers offer interrupt priority schemes that support nested interrupt service routines. A majority of applications can avoid relying on nested interrupts, however, by keeping interrupt service routine processing to a minimum. For the preferred embodiment, it is assumed that interrupts are not enabled during interrupt processing. And thus nested interrupts are not supported. For other embodiments, nested interrupts may be supported.","ISR processing may be minimized by deferring processing to a task handling function. This may be accomplished by communicating an event occurrence within an ISR. The tick () and signal_from_isr () services provide means for event communication from interrupts for the preferred embodiment.  describes the operation of the signal_from_isr () service. The operation is very similar to the signal () service. If the pending_queue component (handle-pending_queue) is not empty (), the status of the highest priority task in the pending_queue is set to \u2018ready\u2019 (), and the highest priority task in the pending_queue is inserted into the ready_queue (). Otherwise, if the pending_queue component (handle-pending_queue) is empty () and the count component (handle-count) is less than its maximum value (), the count component is incremented (). If the count component has reached its maximum value, an overflow is reported (). Finally, the service returns ().","At interrupt completion, the preferred embodiment restricts interrupt handlers such that their tail-call is the sched_check service. This restriction ensures that if a higher priority task is ready to run following the ISR, that task is executed (within sched_check) before returning to the interrupted task. It is assumed that interrupt processing is complete prior to making the tail-call to sched_check. As such, any tasks that are executed from the sched_check service, prior to returning to the interrupted task, are not considered to be part of the ISR. Finally, it is assumed that interrupts are enabled independently of the preferred embodiment upon returning to the interrupted task.","Operation\u2014","Use of the preferred embodiment may be demonstrated through consideration of a solution to the Rendezvous problem, borrowed from 2Copyright 2005, 2006, 2007, 2008 Allen B. Downey. (This book is available online at http:\/\/greenteapress.com\/semaphores\/.) The solution is considered for a traditional RTOS and then modified such that it may be employed within the context of the preferred embodiment. The idea behind the Rendezvous Problem is that two tasks, taskA and taskB, rendezvous at a particular execution point, and neither task proceeds without the other. Consider the task handling functions handlerA and handlerB in Listing 6, and assume that subroutineA2 may not execute prior to subroutineB1 and that subroutineB2 may not execute prior to subroutineA1.",{"@attributes":{"id":"p-0066","num":"0089"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Listing 6: Rendezvous problem - neither taskA nor taskB "},{"entry":"may proceed beyond its first subroutine without the other task."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"91pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","void handlerA ( void* arg )"]},{"entry":["2","{"]},{"entry":["3","\u2003while ( true )"]},{"entry":["4","\u2003{"]},{"entry":["5","\u2003\u2003subroutineA1 ( );"]},{"entry":["6","\u2003\u2003subroutineA2 ( );"]},{"entry":["7","\u2003}"]},{"entry":["8","}"]},{"entry":["9","void handlerB ( void* arg )"]},{"entry":["10","{"]},{"entry":["11","\u2003while ( true )"]},{"entry":["12","\u2003{"]},{"entry":["13","\u2003\u2003subroutineB1 ( );"]},{"entry":["14","\u2003\u2003subroutineB2 ( );"]},{"entry":["15","\u2003}"]},{"entry":["16","}"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"A solution to the Rendezvous Problem, as provided by Downey, is shown in Listing 7. The solution is supported by two semaphores, aArrived and bArrived, such that each semaphore is signaled in one task and waited for in the other. The solution prevents either task from proceeding without the other. A traditional RTOS can support this solution, as it provides for cooperative task suspension. The preferred embodiment cannot support this solution because task suspension is constrained to task preemption. A simple restructuring of the application code, however, can make the preferred embodiment a viable option. A modified solution that can be supported by the preferred embodiment is presented in Listing 8.",{"@attributes":{"id":"p-0068","num":"0091"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Listing 7: Rendezvous solution for a traditional RTOS - two "},{"entry":"semaphores, aArrived and bArrived, prevent either task"},{"entry":"from proceeding beyond its first subroutine without the other task."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","void handlerA ( void* arg )"]},{"entry":["2","{"]},{"entry":["3","\u2003while ( true )"]},{"entry":["4","\u2003{"]},{"entry":["5","\u2003\u2003subroutineA1 ( );"]},{"entry":["6","\u2003\u2003signal ( aArrived );"]},{"entry":["7","\u2003\u2003wait ( bArrived );"]},{"entry":["8","\u2003\u2003subroutineA2 ( );"]},{"entry":["9","\u2003}"]},{"entry":["10","}"]},{"entry":["11","void handlerB ( void* arg )"]},{"entry":["12","{"]},{"entry":["13","\u2003while ( true )"]},{"entry":["14","\u2003{"]},{"entry":["15","\u2003\u2003subroutineB1 ( );"]},{"entry":["16","\u2003\u2003signal ( bArrived );"]},{"entry":["17","\u2003\u2003wait ( aArrived );"]},{"entry":["18","\u2003\u2003subroutineB2 ( );"]},{"entry":["19","\u2003}"]},{"entry":["20","}"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0069","num":"0092"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Listing 8: Modified solution for the preferred embodiment - task "},{"entry":"handling is accomplished with two handlers per task in order"},{"entry":"to constrain the wait service to a tail-call or nested tail-call."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u20021","void handlerA1 ( void* arg )"]},{"entry":["\u20022","{"]},{"entry":["\u20023","\u2003subroutineA1 ( );"]},{"entry":["\u20024","\u2003signal ( aArrived );"]},{"entry":["\u20025","\u2003wait ( bArrived, handlerA2 );"]},{"entry":["\u20026","}"]},{"entry":["\u20027","void handlerA2 ( void* arg )"]},{"entry":["\u20028","{"]},{"entry":["\u20029","\u2003subroutineA2( );"]},{"entry":["10","\u2003handlerA1 ( arg );"]},{"entry":["11 ","}"]},{"entry":["12 ","void handlerB1 ( void* arg )"]},{"entry":["13 ","{"]},{"entry":["14","\u2003subroutineB1 ( );"]},{"entry":["15","\u2003signal ( bArrived );"]},{"entry":["16","\u2003wait ( aArrived, handlerB2 );"]},{"entry":["17 ","}"]},{"entry":["18 ","void handlerB2 ( void* arg )"]},{"entry":["19 ","{"]},{"entry":["20","\u2003subroutineB2( );"]},{"entry":["21","\u2003handlerB1 ( arg );"]},{"entry":["22 ","}"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0070","num":"0093"},"figref":"FIG. 13","b":["1312","1304","1314","1316","1318","1320","1322","1324","1326","1328","1330","1332","1334","1336","1338","1314"]},{"@attributes":{"id":"p-0071","num":"0094"},"figref":["FIG. 14","FIG. 14"],"b":["1412","1430","1402","1404","1412","1414","1416","1418","1428","1420","1422"]},"Processing continues when sched_check re-enters taskA via handlerA2 (). The first action performed by handlerA2 is subroutineA2 (). Then, handlerA2 calls handlerA1 () directly as a subroutine, thus looping back to execute subroutineA1 (). Execution of handlerA1 continues () through to its tail-call, wait (). This tail-call is a nested tail-call for handlerA2. The wait () service returns to handlerA1 (), handlerA1 returns to handlerA2 (), and handlerA2 returns to sched_check (). This process of entering taskA via handlerA2 repeats each time taskA is the highest priority ready task and is thus depicted within an infinite loop structure (, ). All tasks execute as such, on a priority basis against the infinite loop backdrop () of the start () service.","Advantages","From the description of the preferred embodiment, a number of advantages of the current invention become evident:\n\n","An application developer may use various embodiments of the current invention to provide a multitasking capability without the execution overhead associated with supporting multiple call stacks and execution contexts, without the application code complexity associated with event-driven methods, and without constraining task switching to occur at the task level. While the description of the preferred embodiment has provided specific details regarding its implementation, these details should not be considered as limiting the scope of the invention. For example, constraints and restrictions imposed for the preferred embodiment, such as constraining pend-on-event requests to tail-calls or nested tail-calls, pertain specifically to the preferred embodiment. The scope of the invention should be determined by the claims and their legal equivalents.","While a number of exemplary aspects and embodiments have been discussed above, those of skill in the art will recognize certain modifications, permutations and additions and subcombinations thereof. It is therefore intended that the following appended claims and claims hereinafter introduced are interpreted to include all such modifications, permutations, additions and subcombinations that are within their true spirit and scope."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWING(S)","p":[{"@attributes":{"id":"p-0021","num":"0044"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0022","num":"0045"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0023","num":"0046"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0024","num":"0047"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0025","num":"0048"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0026","num":"0049"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0027","num":"0050"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0028","num":"0051"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0029","num":"0052"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0030","num":"0053"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0031","num":"0054"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0032","num":"0055"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0033","num":"0056"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0034","num":"0057"},"figref":"FIG. 14"}]},"DETDESC":[{},{}]}
