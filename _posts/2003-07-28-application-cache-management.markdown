---
title: Application cache management
abstract: A cache management system including an in-memory database system for managing cached data is provided. The cache management system includes an application, a wrapper and an engine. The application utilizes data and has a rule related to the cache management of the data. The wrapper is operable to receive data from the application and provide at least a portion of the data and a component of the rule to the in-memory database system. The engine is operable to monitor the in-memory database system and apply the rule to the cached data. A method for managing cache data is also provided.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07409379&OS=07409379&RS=07409379
owner: Sprint Communications Company L.P.
number: 07409379
owner_city: Overland Park
owner_country: US
publication_date: 20030728
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","STATEMENT REGARDING FEDERALLY SPONSORED RESEARCH OR DEVELOPMENT","REFERENCE TO A MICROFICHE APPENDIX","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["None.","Not applicable.","Not applicable.","The field of the present invention includes computer database management systems. More particularly, embodiments of the present invention are concerned with managing in-memory database cache employing application specific rules.","In-memory database management system (IMDBMS) software products store data in local computer memory, such as in random access memory, for fast access. IMDBMS products may be employed in association with a disk-based database management system (DBMS) which may be employed to support long term persistence of some of the data. While some enterprises may develop their own database management systems, most buy these systems as commercial off-the-shelf, hereafter COTS, software packages and build their data applications on top of these COTS packages.","Data employed by applications may need to be stored in an IMDBMS only on the server supporting the application itself or may need to be shared among multiple servers. The data may have only a transient utility and may be deleted after an interval of time or after a period of non-use. Such transient data should be removed from the IMDBMS when its utility has expired. Other data may have only transient utility, but require long-term persistence for record keeping purposes. Such data should be stored in long term storage, such as disk-based DBMS, and then removed from IMDBMS when its utility has expired. Such different data requirements of applications may be articulated as rules or policies.","It is incumbent on each application to implement these data cache management rules and interact with the IMDBMS to delete transient data, for example, at the appropriate times and to interact with the disk-based DBMS to write-back data requiring long-term persistence. Implementing data management rules adds to the complexity of developing applications and may involve solving the same problem multiple times if different applications are developed by different designers or different teams of designers, perhaps located at different corporate development sites. Additionally, implementing data management rules in the application increases the processing load associated with the application. If the long term storage mechanism changes, the applications may need to be redeveloped to interact with a different long term storage mechanism.","The present embodiment provides a cache management system including an in-memory database system for managing cached data. The cache management system also includes an application, an in-memory database, a wrapper and an engine. The application utilizes data and has a rule related to the cache management of the data. The wrapper is operable to receive the data from the application and provide at least a portion of the data and a component of the rule to the in-memory database system. The engine is operable to monitor the in-memory database system and apply the rule to the cached data. A method for managing cache data is also provided.","In one embodiment, a cache management system is provided that includes an application, a wrapper, and an engine. The application utilizes data and has a rule related to caching the data. The wrapper is in communication with the application to receive at least a component of the rule. The engine is operable to receive at least a component of the rule from the wrapper and apply the rule to the cached data. In another embodiment, the cache management system further comprises an in-memory database for managing cache data. The in-memory database further includes a storage portion for storing the data utilized by the application and a table operable to maintain a rule event related to the rule for caching data. The rule event points to a location in the storage portion of the in-memory database where the data related thereto is stored. In another embodiment, the wrapper is further operable to provide at least a portion of the data from the application and a component of the rule to the in-memory database. In this embodiment, the engine is operable to poll the in-memory database and apply the rule related to the rule event to the data.","These and other features and advantages will be more clearly understood from the following detailed description taken in conjunction with the accompanying drawings and claims. It is important to note that the drawings are not intended to represent the only form of the invention.","It should be understood at the outset that although an exemplary implementation is illustrated below, the application cache management system may be implemented using any number of techniques, whether currently known or in existence. The present disclosure should in no way be limited to the exemplary implementations, drawings, and techniques illustrated below, including the exemplary design and implementation illustrated and described herein.","IMDBMSs store data in memory, such as in random access memory but may also include disk memory in some cases or for some portions of the data, which may be referred to as caching the data. It is the role of the IMDBMS software to keep cached data synchronized across multiple application platforms so that all application servers using the cached data see the same data values as the data is accessed. The IMDBMS software, however, may not know or be operable to implement the specific requirements of enterprise applications for refreshing or otherwise managing cached data or removing data from cache.","For example, a customer data object may be of use to an application for a specific period of time, such as 30 minutes or less. In some instances, it is efficient to retain the customer data object in cache, but the application should remove the customer data object from cache after this 30 minute period expires. It is inefficient and perhaps impossible in some instances, however, for the application to implement these application specific data cache management rules.","Common application specific cache data management rules, which may be referred to hereinafter sometimes simply as rules, may be classified as (1) data refreshment from long term storage, such as by a disk-based DBMS at periodic intervals, (2) data refreshment on an ad hoc basis from long term storage, (3) data removal from cache after an application specific length of time, (4) data removal from cache after an application specific length of time of non-use, (5) data removal from cache after an application specific length of time with data written back to long term storage, (6) data removal from cache after an application specific length of time of non-use with data written back to long term storage, and (7) data removal from cache when marked by the application for removal. Another rule may apply if an attempt to read a data item from cache fails and the application needs the data to be read in from long term storage: this treatment may be referred to as (8) \u2018does not exist retrieval.\u2019 These are called common rules because any application may use all these rules. Other rules which are not common may also be defined by application programs. An example of such a rule will be given hereinafter.","Rules 2, 7, and 8 may be considered synchronous data manipulations with respect to the application while the other data treatments may be considered asynchronous data manipulations with respect to the application. The present embodiment is not limited to these or other rules not enumerated above, whether defined as synchronous, asynchronous or otherwise, and which will readily suggest themselves to one of ordinary skill in the art and are within the spirit and scope of the present disclosure. These several data management rules may be associated with scripts, programs, subroutines, methods, or functions and\/or any operation which may be executed to manipulate the data in a desirous manner.","Turning now to  an exemplary architectural diagram of one embodiment of the present disclosure is depicted. Application server is an application execution platform supporting connections to the resources and services that application programs, hereinafter referred to as applications, may require. Applications may include billing programs, provisioning programs, network management applications or numerous other applications which will readily suggest themselves to one of ordinary skill in the art. While the application server may offer multiple services to applications, such as restart of failed applications, automated fail-over, load balancing, application cache management, for example, only the services related to application cache management are depicted in  and discussed below. The application server may execute on a general purpose computer system which will be discussed in more detail hereinafter.","Multiple application servers through having substantially the same architecture with respect to cache management as application server are depicted. Their cache interactions are substantially similar to those described below with respect to application server . Some embodiments may consist of only a single application server, but other embodiments may consist of a multiplicity of servers as depicted in .","The application servers through may similarly execute on a general purpose computer system which will be discussed in more detail hereinafter. A general purpose computer system may be referred to by the name of the principle or only application executing on that system. For example, a general purpose computer on which application server executes and on which a billing application program executes may be known as the \u201cbilling server.\u201d","For purposes of clarity and understanding, a brief discussion of application servers  and applications may be useful. In one embodiment, the application servers  may be duplicated across multiple general purpose computing systems. In this embodiment, each application server  may run its own unique application programs, or some application programs may be duplicated on one or more application servers . The duplication of a single application program may be referred to as \u2018instantiations\u2019 of the application program on one or more application servers . For example, multiple instances of a provisioning application may run on one or more application servers  to distribute the load of the provisioning application. The provisioning application may be said to be instantiated on one or more application servers .","An exemplary application is depicted as executing on the application server . A second instance of the application may also execute on the application server to distribute the processing load to multiple application servers. Applications through may execute on the application server while applications and may execute on application server . In some embodiments, one or more of the application servers through may be dedicated to a single application.","According to one embodiment, a wrapper  is in communications, such as by an interface or otherwise, with the application . In this manner, the application passes data and any rules associated with the cache management requirements of the data utilized by the application to the wrapper . In some embodiments, an IMDBMS plug-in is provided to enable communication between the wrapper  and an IMDBMS . The IMDBMS plug-in is operable to promote communication between the wrapper  and the IMDBMS . The IMDBMS plug-in may be a translator or interface or other system provided with similar functionality.","According to other embodiments, one or more IMDBMS plug-ins  may be provided to enable communication between the wrapper  and additional IMDBMS. In some embodiments the wrapper  communicates with a rules engine  which may support some cache management operations. In this embodiment, a custom data retriever plug-in is also provided to similarly enable communication between the rules engine  and a back office database  and a legacy COTS application . In some embodiments there may be multiple legacy COTS applications  with which the custom data retriever plug-in communicates. It should be appreciated that fewer or more plug-ins with varying functionality may be utilized and are within the spirit and scope of the present disclosure. According to other aspects, it may be advantageous to build support for one or more IMDBMS and back office system directly into the wrapper , such as by hard-coding or otherwise enabling such functionality in the wrapper .","The wrapper  is operable to receive the data from the application and \u201cwrap\u201d the data with the cache management rule of the application . In some embodiments, the application may provide a rule type related to the data to the wrapper . In such embodiment, the rule type may be relationally related to the complete rule or instruction set for management of the data in cache memory. As such, the complete rule or rules utilized by the application or application server may be loaded in a number of manners that will readily suggest themselves to one skilled in the art. For example, the rules may be loaded at the start-up of the application or application server from or into a data file, into memory or otherwise.","The \u201cwrapping\u201d process may include both the aspect of wrapping the data and of adding the rule related information, such as rule type, to the data transmitted by the application . When the application reads data from or writes data to the IMDBMS it does so, in the present embodiment, via the services offered by the wrapper . When the application desires to write a data item to cache, the wrapper  receives the data item from the application and adds additional rule information before communicating the wrapped data to the IMDBMS . When the application reads a data item from cache, according to one aspect of the present embodiment, the wrapper  obtains data from cache, and may strip the additional information off the data item, and returns the simple data item to the application . In other aspects, data may be passed directly to the application in a manner that bypasses the wrapper .","The IMDBMS plug-in is in communication with an IMDBMS , which manages certain aspects of the in-memory cache data. Data that is accessed by the application server is accessed, through the intermediary of the wrapper , via the IMDBMS plug-in . Data that is accessed by other application servers , such as application server , may be similarly accessed via wrapper and IMDBMS plug-in ","The rules engine  may perform synchronous cache operations such as ad hoc data refresh operations (rule ) for those applications executing on its application server . In this embodiment, the rules engine  typically may execute on the same general purpose computer system that the application server executes upon.","The custom data retriever plug-in is in communication with one or more back office DBMSs  which may be supported by different DBMS COTS packages and may be located in third party enterprises, such as a billing service company. The back office DBMSs  may be executed on one or more general purpose computer systenis to be discussed in more detail hereinafter. One example of a DBMS COTS package that is compatible with the present disclosure is the ORACLE DBMS that may execute on a computer system using the UNIX operating system.","The IMDBMS  supports the IMBDMS plug-ins -located in the various application servers through . The IMDBMS  keeps the data shared among the application servers  consistent or synchronized. It should be appreciated that the IMDBMS  may include, according to one aspect, an IMDBMS operable on a computer server (and hence may be called an IMDBMS server), although a number of configurations and deployments are within the scope of the present disclosure. Examples of IMDBMS COTS packages that are compatible with the present disclosure are TIMESTEN and VERSANT. Other IMDBMS COTS packages may also be compatible with the present disclosure. In one embodiment the IMDBMS  may execute on a general purpose computer system. In another embodiment the IMDBMS  may share a general purpose computing system with an application server  or with other programs.","In one embodiment, the application server includes an initialization module  whose role is to write application specific data management rule definitions\u2014both common rule definitions and non-generic or uncommon rule definitions\u2014into the cache. Rule definitions describe, in some manner, the functional behavior that is to occur to maintain the data associated with the rule. The rule definitions may be described through XML scripting or other means. In other embodiments, the rule definitions may be stored and utilized in other manners. The rule definitions are associated with a rule type identifier or rule name or database key by which the rule definition may be accessed. The initialization module  executes when the application server is started and then exits on completion of its initialization actions. The rule definitions may be coded in the initialization module  or may be read in from a configuration file. The initialization module  employs the application programming interface (API) of the wrapper  to write the rule definitions into cache, a file or otherwise. In some embodiments, the applications  may also write rule definitions into the cache, via the intermediary of the wrapper .","In the present embodiment, a second rules engine  has the role of acting on some or all of the data cache or other management rules. To support this role, the second rules engine , according to the present embodiment, has an IMDBMS plug-in and a custom data retriever plug-in . The second rules engine  has access to the rules definitions, which may include that complete instruction set for acting on the data, stored in cache, for example, during initialization of each of the application servers through via its IMDBMS plug-in -. The IMDBMS  keeps all in-memory cache consistent or synchronized. Data that is present in the cache is visible to application server is also visible to the cache and visible to the second rules engine , as well as to the other application servers through . It should be appreciated that the actual memory location where the data is cached may be local to the application server , the IMDBMS  or on other systems provided with such memory or storage capability.","According to one aspect, the IMDBMS  contains a rules event table  whose entries include a rule type or rule event and a reference to the data associated with the rule type, such as a pointer. The rule type identifies a rule definition which fully describes the function to be applied to the data. The rule event or type entry is provided by the wrapper  when a data item is first entered into the cache by an application. In this embodiment, the second rules engine  is operable to periodically poll or query, based on the rules, the IMBDMS . In this manner, the second rules engine  identifies cached data with the associated rule type. After identifying the cached data and the rule type, the second rules engine  applies the rule to the related data, thereby implementing the application specific rule outside of the IMDBMS . It can be seen that this functionality provides implementation of application specific rules without the inefficiencies associated with these rules being implemented by the application . In addition, the present embodiment provides cache management of data functionality not provided by the IMDBMS , which promotes greater efficiency throughout the system.","The second rules engine  may monitor cache data by polling the rules event table  and data items in the cache. When a rule associated with a data item is ready to be executed, the second rules engine  looks up the associated rule definition, accesses the data item, and performs the cache management operation defined by the rule upon the data item. The wrapper  may build an event table in the IMDBMS  which links data items with rule types. The rule type may be associated with rule definitions. The second rules engine  may monitor this rule event table by polling the table. The second rules engine  may be distinguished from the rules engine  by this polling activity. In other aspects, the rules engine  and second rules engine  may be combined.","In one embodiment the second rules engine  may run on a dedicated general purpose computing system, which will be discussed in detail hereinafter. In another embodiment the second rules engine  may share a general purpose computing system with an application server or other programs. In another embodiment the second rules engine  may share a general purpose computing system with the IMDBMS .","When the application writes a given data item for the first time into cache it may provide the wrapper  with the data item, a key for referencing the data item, and the rule type to associate with the data item. The wrapper  then writes the data item into the cache, along with its reference key, and writes a rule event entry into the rules event table . The rules event entry comprises a reference to the associated data item and the data type. The wrapper  may add information which supports management of the cache data including date and time. In some embodiments the IMDBMS  may add date and time to data items in cache, in which case the wrapper  does not add this information. When this or other applications access this same data in the future, the wrapper  may or may not, depending on the rule governing this data item, update the data wrapper. If rule  applies (removal from cache after an application specific length of time) there is no need to update the data wrapper since the only information relevant to when to remove the data from cache is when the data item was first written to cache. If rule  applies (removal from cache after an application specific length of time of non-use) then it is important to update the date and time associated with the data item to capture the most recent use. Again, if the IMDBMS  provides such functionality, the wrapper  does not add this information.","If the application attempts to access a data item which is not in cache and the data type is associated with rule  (does not exist retrieval), the wrapper  may request that the rules engine  read the data item out of the back office DBMS  via the services of the custom data retriever . The rules engine  returns the desired data to the wrapper  which writes the returned data and appropriate rule type into cache and returns the unwrapped data item to the requesting application. This sequence is said to be a synchronous data manipulation because the data manipulation is performed in direct response to an application action.","Turning now to  the above data flow scenario is explicitly illustrated. The application sends a read request message  for a data item to the wrapper . The wrapper  sends a read request message  for the data item to the IMDBMS plug-in . The data item is not in cache, and the IMDBMS plug-in sends a read request item-not-found message  to the wrapper . The wrapper  sends a read request message  for the data item to the rules engine . The rules engine  sends a read request message  for the data item to the custom data retriever plug-in . The custom data retriever plug-in sends a read request message  for the data item to the back office DBMS . The back office DBMS  looks-up and fetches the data item in action . The back office DBMS  sends the data in a data return message  to the custom data retriever plug-in . The custom data retriever sends the data in a data return message  to the rules engine . The rules engine  sends the data in a data return message  to the wrapper . The wrapper  adds rule type, which may have been received from the application , and also adds date and time information, and optional supplemental information to the data item in action . The wrapper  sends the data constellation in a data write message  to the IMDBMS plug-in ","In some aspects, the wrapper  may be operable to strip off the rule type, date and time information, and sends the simple data item in a data return message  to the application . In some embodiments, as noted above, the date and time information may be supplied by the IMDBMS plug-in rather than the wrapper .","The IMDBMS plug-in provides the wrapped data - to the IMDBMS , which stores the data in cache and associates a component of the rule, such as a rule type, to the data and stores the rule type in the rules event table  or other location. The second rules engine  periodically queries - the IMBDMS server  to apply the rule to the cached data in the IMDBMS . Note that these two messages\u2014- and -\u2014are not part of the synchronous data management action, but are shown to aid comprehension of system operation. Message - occurs as part of the normal operation of the IMDBMS  maintaining synchronization of data cache across all cache users. Message - is an on-going message the second rules engine  periodically sends to the IMDBMS .","If the application requests that a data item be refreshed from the back office DBMS  (data rule ), the wrapper  requests that the rules engine  read the data item out of the back office DBMS  via the services of the custom data retriever plug-in . The rules engine  requests the data from the custom data retriever plug-in . The custom data retriever plug-in reads the data out of the back office DBMS  and returns the data to the rules engine . The rules engine  returns the data to the wrapper . The wrapper  writes the returned data\u2014updated with appropriate rule index, date and time, and supplemental information\u2014into cache and returns the unwrapped data item to the application . In another embodiment the wrapper  may signal the second rules engine  so that the second rules engine  may read the data item out of the back office DBMS  via the services of its custom data retriever . The second rules engine  then writes the returned data\u2014updated with appropriate date and time and optional supplemental information\u2014into cache. The wrapper  then reads the data item out of cache, strips off the rule and optional supplemental information, and returns the simple data to the application . This is said to be a synchronous data manipulation because the data manipulation is performed in direct response to an application action.","If the application marks a data item for removal from cache (data rule ), the wrapper requests the rules engine  to remove the data from cache. The rules engine  then removes the data from cache and removes the rules table entry associated with the data item from the rules table. In another embodiment, the wrapper  may signal the second rules engine  so that the second rules engine  deletes the data item from cache and remove the rules event table  entry associated with the data item from the rules event table . This is said to be a synchronous data manipulation because the data manipulation is performed in direct response to an application action.","An example of an uncommon, non-generic rule will now be discussed briefly. The application  may wish to have a data item stay in cache for a specific length of time and then be removed from cache with part of the data item stored in the back office DBMS  and part of the data item stored in the COTS application . The rule which effects this kind of cache data maintenance is highly specific to the particular application . Such special cases are likely to exist for applications, and the contemplated application cache management system is flexible enough to handle these special cases.","The remaining data manipulation rules may be described as asynchronous, and the associated data manipulations may be handled, according to the present embodiment, by the second rules engine . The second rules engine  has visibility to cached data via its own IMDBMS plug-in and monitors this cache for changes. When a cached data item is modified, the second rules engine  has access to this information. This access may be through a database trigger mechanism if the IMDBMS  supports trigger mechanisms, or the second rules engine  may periodically poll data items.","When a tenure of a data item expires (rules -) the second rules engine  removes the data item from cache and removes the rules table entry associated with the data item from the rules table. If rules  or  are invoked, the second rules engine  writes the data back to the back office DBMS  via its custom data retriever plug-in . If a data item is governed by rule  and is due for its periodic refresh, the second rules engine  reads the data item from the back office DBMS  via its custom data retriever plug-in and then writes the data item into its cache.","If the IMDBMS  supports keeping some portion of cache local\u2014meaning the data in this local area of cache is not accessible outside of the application server  on which the data is local, hence is not visible to the IMDBMS  or other application servers \u2014this data may be managed by the application itself. Alternately, if the IMDBMS  does not support keeping some portion of cache local, information which needs to be kept purely local may be stored in application memory outside of cache. Such local data may comprise machine specific data or application instance specific data.","The software applications described above may be implemented on any general-purpose computer with sufficient processing power, memory resources, and network throughput capability to handle the workload placed upon it.  illustrates a typical, general-purpose computer system suitable for implementing the present invention. The computer system  includes a processor  (which may be referred to as a central processor unit or CPU) that is in communication with memory devices including secondary storage , read only memory (ROM) , random access memory (RAM) , input\/output (I\/O) devices , and network connectivity devices . The processor may be implemented as one or more CPU chips.","The secondary storage  is typically comprised of one or more disk drives or tape drives and is used for non-volatile storage of data and as an over-flow data storage device if RAM  is not large enough to hold all working data. Secondary storage  may be used to store programs which are loaded into RAM  when such programs are selected for execution. The ROM  is used to store instructions and perhaps data which are read during program execution. ROM  is a non-volatile memory device which typically has a small memory capacity relative to the larger memory capacity of secondary storage. The RAM  is used to store volatile data and perhaps to store instructions. Access to both ROM  and RAM  is typically faster than to secondary storage .","I\/O devices  may include printers, video monitors, keyboards, mice, track balls, voice recognizers, card readers, paper tape readers, or other well-known input devices. The network connectivity devices  may take the form of modems, modem banks, ethernet cards, token ring cards, fiber distributed data interface (FDDI) cards, and other well-known network devices. These network connectivity  devices may enable the processor  to communicate with an Internet or one or more intranets. With such a network connection, it is contemplated that the processor  might receive information from the network, or might output information to the network in the course of performing the above-described method steps. Such information, which is often represented as a sequence of instructions to be executed using processor , may be received from and outputted to the network, for example, in the form of a computer data signal embodied in a carrier wave.","The processor  executes instructions, codes, computer programs, scripts which it accesses from hard disk, floppy disk, optical disk (these various disk based systems may all be considered secondary storage ), ROM , RAM , or the network connectivity devices .","Turning now to  the location on computers of programs cooperating in one embodiment is depicted. The application server is executing on general computer system # . The back office DBMS  executes on general computer system # . The second rules engine , which, in some embodiments, may include functionality of rules engine , is executing on general computer system # . The IMDBMS  is executing on general computer system # . The application server is executing on general computer system # . Note that some of these general computer systems may be several computers networked together to increase the collective processing power.","Turning now to  the location on computers of programs cooperating in another embodiment is depicted. The application server is executing on general computer system # . The back office DBMS  executes on general computer system # . The second rule engine  and IMDBMS  are both executing on general computer system # . The application server is executing on general computer system # . Note that some of these general computer systems may be several computers networked together to increase the collective processing power.","Turning now to  the location on computers of programs cooperating in another embodiment is depicted. The application server and the second rules engine  are executing on general computer system # . The back office DBMS  executes on general computer system # . The IMDBMS  is executing on general computer system # . The application server is executing on general computer system # . Note that some of these general computer systems may be several computers networked together to increase the collective processing power.","Turning now to  the location on computers of programs cooperating in another embodiment is depicted. The application server , IMDBMS , and the second rules engine  are executing on general computer system # . The back office DBMS  executes on general computer system # . It should be understood that it is within the spirit and scope of the present disclosure that the rules engine  and second rules engine  are combined, separated or distributed as necessary to achieve desired functionality and efficiency. The application server is executing on general computer system # . Note that some of these general computer systems may be several computers networked together to increase the collective processing power.","In another embodiment, the application server  is a middleware server and the application  is middleware, such a VITRIA BUSINESSWARE or IBM CROSSWORLDS, operable on the middleware server. In this embodiment, the wrapper  resides as an adaptor or connector in the middleware. In such configuration, collaborations or integration models are provided with access to cache data via the wrapper , which is operable as an adapter or connector in the middleware.","While several embodiments have been provided in the present disclosure, it should be understood that the application cache management system may be embodied in many other specific forms without departing from the spirit or scope hereof. The disclosed embodiments are to be considered as illustrative and not restrictive, and the intention is not to be limited to the details given herein, but may be modified within the scope of the appended claims along with their full scope of equivalents. For example, the various elements or components may be combined or integrated in another system or certain features may be omitted, or not implemented.","Also, the techniques, systems, subsystems and methods described and illustrated in the various embodiments as discreet or separate may be combined or integrated with other systems, modules, techniques, or methods without departing from the scope hereof. Other items shown as directly coupled or communicating with each other may be coupled through some interface or device, such that the items may no longer be considered directly coupled to each, but may still be in communication with one another. Other examples of changes, substitutions, and alterations are readily ascertainable by one skilled in the art and could be made without departing from the spirit and scope of the present disclosure."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["For a more complete understanding of the present disclosure and the advantages thereof, reference is now made to the following brief description, taken in connection with the accompanying drawings in detailed description, wherein like reference numerals represent like parts.",{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
