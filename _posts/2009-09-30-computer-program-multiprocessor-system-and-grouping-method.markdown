---
title: Computer program, multiprocessor system, and grouping method
abstract: According to one embodiment, a grouping method for process units, each including basic modules and data, the process units being assigned to processors in a program for a multiprocessor system, the program including the basic modules and a parallel statement describing relationships between parallel processes for the basic modules, the method includes displaying a dataflow graph visually showing a process status of each process unit based on the parallel statement, and specifying a candidate for a connection of process units on the dataflow graph, wherein the dataflow graph displays data entries, nodes in the basic modules, and edges connecting the data entries and the nodes.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08074211&OS=08074211&RS=08074211
owner: Kabushiki Kaisha Toshiba
number: 08074211
owner_city: Tokyo
owner_country: JP
publication_date: 20090930
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND","DETAILED DESCRIPTION"],"p":["This application is based upon and claims the benefit of priority from Japanese Patent Application No. 2008-255295, filed Sep. 30, 2008, the entire contents of which are incorporated herein by reference.","1. Field","One embodiment of the invention relates to a computer program for causing a plurality of processors to perform parallel processing, a multiple processor system, and a grouping method for programming.","2. Description of the Related Art","In order to realize high speed computer processing, multi-thread processing is used, in which a plurality of tasks are processed in parallel. In a parallel processing program incorporating multi-thread processing, a plurality of threads are created and the threads have to take into account simultaneous processing by other threads. For example, to maintain the sequence of operations properly, an additional process to ensure synchronization has to be included in various parts of the program. This makes debugging of the program difficult, etc., thus increasing maintenance costs.","As an example of such a parallel processing programming, a multi-thread execution method has been proposed as described in Patent Document 1 (Jpn. Pat. Appln. KOKAI Publication No. 2005-258920 (Paragraph [0014], FIG. 7). This document discloses a method in which when a plurality of interdependent threads (in which thread 1 can be executed only after thread 2) are created, parallel processing is performed based on the result of the execution of these threads and their interdependence.","In order to perform processing while programs to be processed in parallel maintain an appropriate execution sequence, fixed dependency relationships among the programs and\/or the threads have to be determined in advance. At the same time, it is also preferable to have a mechanism for dynamically adjusting the execution load of each program according to the point in its execution that the program has reached at that moment.","One of the forms for parallel processing includes two elements: runtime processing having a scheduler which assigns a plurality of process units to an execution unit (CPU); and a process unit to be processed by each execution unit. In the context of parallel processing, the size of a process unit is called granularity. Refining the granularity increases opportunities for parallel processing, thereby enhancing the parallel performance. However, if the granularity in parallel processing is too fine, it increases the frequency of scheduler operations and hence overheads. The performance thus obtained is unsatisfactory.","When the number of execution units (CPUs) is sufficient, even if the runtime overhead is increased, an improvement in performance can be sufficient by enhancing the degree of parallelism to such a level that almost all execution units will be used. When the degree of parallelism is sufficient in relation to the number of execution units, the efficiency of execution can be improved by restraining the parallelism, thereby reducing the runtime overhead.","Furthermore, in an environment in which the number of processors may be two-digits or more and in the case where memory hierarchy is multi-layer and the data communication overhead between processors is uneven, process units are assigned to processors so that any process unit involved in data transfer is assigned to the nearest possible processor. Thus the memory band width of shared memory access can be reduced. However, in order that a programmer may explicitly specify the method for assigning process units to processors, a complex task such as program rewriting is required.","A program display method has been developed, by which a program for executing such a plurality of processes in parallel is formed visually and hierarchically using graphics (e.g., Patent Document 2 (Jpn. Pat. Appln. KOKAI Publication No. 6-332689; paragraph [0056], FIG. 16)). This example uses a program development environment as a function realized as a process executed by a parallel computing machine. The program development environment includes, as a program specific to its own process, an editor, debugger and parallelism evaluation program, as described above. Also, the program development environment has a program graphical user interface (GUI) for graphically displaying the content of a source program, and for transmitting commands from a mouse or keyboard to the editor, debugger, and parallelism evaluation program. The program GUI plays the role of controlling the whole program development environment, such as transmitting commands input by a mouse or keyboard to the editor, debugger, parallelism evaluation program, etc.","The program display method as described in Patent Document 2 accepts edition of the hierarchical structure with a plurality of process units composing a program. It does not accept, however, edition involving a change in granularity for parallel execution.","In this manner, in the conventional program display method, it is impossible to edit a program for adjusting the granularity in parallel processing, which is the size for a unit of parallel processing.","Various embodiments according to the invention will be described hereinafter with reference to the accompanying drawings. In general, according to one embodiment of the invention, a grouping method for process units, each process unit including a basic module and data, the process units being assigned to processors in a program for a multiprocessor system, the program including basic modules and a parallel statement describing relationships between parallel processes for the basic modules, the grouping method comprises displaying a dataflow graph visually showing a \u201cdependency\u201d or \u201cexecution order\u201d or \u201cpartial order of execution\u201d of each process unit based on the parallel statement; and specifying a candidate for a connection of process units on the dataflow graph, wherein the dataflow graph displays data entries, nodes in the basic modules, and edges connecting the data entries and the nodes.","According to an embodiment,  shows an example of a multi-processor system for parallel processing according to a first embodiment of the present invention. A number of processors (i=1, 2, 3), a main memory  and a hard disk drive (HDD) , which make parallel processing possible, are connected to an internal bus . The processors interpret the program code stored in various memory devices, such as the main memory  and the HDD , and execute a process written in advance as a program. In , it is assumed that the three processors are identical in terms of processing capability. However, they need not be identical. Among these processors, there may be one with a different processing capability or one intended for processing a different kind of code.","The main memory  is a memory device which is composed of a semiconductor memory such as a dynamic random access memory (DRAM). A program to be run by the processor is read into the main memory , which may be accessed at relatively high speed, before processing. This program is accessed from the processor in accordance with the processing of the program.","Although the HDD  is capable of storing a larger amount of data than the main memory , it is often disadvantageous in terms of access speed. The program code to be processed by the processor is stored in the HDD , and only a part to be processed is read into the main memory .","The internal bus  is a common bus which connects the processors , main memory  and HDD , so that data may be sent and received between them.","A graphic user interface (GUI)  for displaying programs is also connected to the internal bus . An image display unit  for displaying processing results, and a mouse  for entering edit commands for a dataflow graph (described below) may be connected to the GUI . Furthermore, a keyboard for entering data may be connected to the GUI .","Next, the outline of a parallel processing program will be described. In parallel processing, a plurality of programs are processed in parallel. Each program is not processed independently. That is, one program uses the result of the process of another program or, in order to ensure consistency of data, a program has to wait until a specific part of another program has finished. When processing a program having such characteristics in parallel, a system for capturing the status of each of the other related programs being executed has to be incorporated at various points in the program. Inserting this system (also known as a synchronization process) allows the authentication of data and the realization of exclusive-control-based cooperation among programs. However, inclusion of the synchronization process for parallel processing to be written into a program, considerations in addition to main logic are required, complicating the program. Also, resources are wasted while waiting for another program to run through its program. In addition, a minor wrong timing may contribute to a significant change in processing efficiency. This may make it difficult to correct a program later.","To avoid this, in this embodiment, the program is divided into: a serial basic module (also referred to as a serial execution module), which is executable provided that input data is received regardless of the execution status of other programs, and which is then executed in series without synchronization; and a parallel execution control statement, which describes the relationship between the parallel processes of a plurality of serial basic modules by using graph data structure generation information in which a serial basic module is regarded as a node. A program part requiring synchronization or data transfer\/reception is described in the parallel execution control statement, thus encouraging the use of a serial basic module as a separable component and allowing compact management of the parallel execution control statement.  shows the manner in which a program is divided into a serial basic module and a parallel execution control statement.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 2","FIG. 2"],"b":["400","401"]},"The program  executes thread  while the program  executes the thread . The program  executes thread  until it reaches point , at which the program  has to transfer the processing result to the program . Therefore, when the execution of the thread  is done, the program  informs the program  of the processing result as an event . The program  is enabled to execute thread  only after the receipt of the processing results of both the event  and the thread . On the other hand, upon being informed of the completion of the execution of the thread , the program  starts execution of the part of the program beyond the point  as thread .","As described above, there is a point at which processing may be allowed to proceed without preconditions, such as the program  for the thread  and the program  for the thread ; on the other hand, there is a point such as the point , at which the processing result has to be sent to another thread as the processing of the program proceeds, or there is a point at which the processing result from another thread has to be received as a precondition to start processing.","Therefore, as shown in , the program is divided at a point like the point , and, after the division, a unit of program processing is defined as serial basic modules d, d, d, and so on or serial basic modules e, e, e, and so on.  shows two programs D and E that are associated with each other. Even when there are more than two programs associated with one another, a program can be divided in accordance with the same principle. Serial basic modules d, d, d, and so on and serial basic module e, e, e, and so on are those modules which can be executed without a synchronization process.",{"@attributes":{"id":"p-0039","num":"0038"},"figref":["FIG. 3","FIG. 3","FIG. 2"],"b":["1","2","500","1","2","1","2","500","500","501"]},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 3","b":"501"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 5","b":["200","200","198","198","200","203"],"i":["j ","j ","j "]},"Parallel execution control statement  is data referred to for execution. The parallel execution control statement  indicates the dependency relationship between the serial basic modules when parallel processing is performed (see ). The parallel execution control statement is converted into graph data structure generation information  by a translator  prior to execution by the information processing apparatus  in an execution environment. The translator  extracts parts pertaining to each of the plurality of serial basic modules from the parallel execution control statement. The translator  also generates, for the parallel execution control statement, graph data structure generation information which includes at least information that precedes a serial basic module and information that follows this serial basic module. The graph data structure generation information  is stored in a runtime library .","In addition to advance conversion prior to processing of the serial basic module , the translator  may perform processing at the same time as a sequential translation using a runtime task, etc., during execution of the serial basic module .","Software executed by the information processing apparatus  includes the serial basic modules , the runtime library  (which stores the graph data structure generation information ), multi-thread library , operating system  and symmetric multiprocessor .","The runtime library  includes an application programming interface (API) which is required for the execution of the serial basic module on the information processing apparatus . It also has a function for executing exclusive control required for parallel processing by the serial basic module . On the other hand, the function of the translator  may be called from the runtime library ; and when the function of the translator  is called during the processing of the serial basic module , the parallel execution control statement  of a part to be processed next may be converted each time. Such a configuration eliminates the need for a resident task used for translation, making parallel processing more compact.","The operating system  controls the whole system including the hardware and task scheduling of the information processing apparatus . The inclusion of the operating system  has the merit that a programmer is released from the task of miscellaneous control when executing the basic module , enabling him or her to concentrate on programming and, what is more, to develop software of a more general nature that may run even on different types of machines.","In the information processing apparatus according to the present embodiment, a program is divided in accordance with whether or not the part requires synchronization process or data reception\/transfer, and then the association between these is defined as the parallel execution control statement. This encourages the use of the basic module as a separable component, thus making it possible to control the parallel processing definition in a compact manner. Execution load applied to each of the basic modules, formed as a separable component, is dynamically adjustable.","As shown in , by converting the parallel execution control statement  into the graph data structure generation information , and then by executing it in parallel with the runtime processing that interprets and executes it, overhead can be reduced and programming flexibility can be ensured. This runtime processing is executed by threads more than at least the number of processors. The runtime processing interprets a graphic data structure generated dynamically, selects the serial basic module to be executed, and repeats execution of the serial basic module while the graphic data structure is being updated, thereby realizing parallel processing.","An item of graph data structure generation information  may be produced by using a data structure in C language structure, or it may be expressed by byte code sequence, and serves as a virtual machine. When expressed in bytecode, a virtual machine, which is a program execution environment, interprets and executes the bytecode, thereby generating a graphic structure. Graph generation by bytecode is conducted in such a manner that when input operand data of the bytecode is not yet valid and when execution of a thread is required to obtain that input data, its processing is created as a node and then the dependency relationship between the data is added to a dataflow graph as an edge.","For this reason, the GUI  shows on the display unit  a dataflow graph, as shown on the right hand side of , based on the graph data structure generation information  in the information processing apparatus  in the execution environment as shown in . The dataflow graph shows the parallel relationship between data and function (task). In this example, functions \u201ch\u201d and \u201cg\u201d act on data \u201cin\u201d, \u201cin\u201d, and function \u201cf\u201d further acts on the resulting data (array) \u201ca\u201d, \u201cb\u201d. Then function \u201ck\u201d acts on the further resulting data (array) \u201cc\u201d, thereby obtaining the resulting data (array) \u201cout\u201d. Functions \u201cf\u201d, \u201ch\u201d, and \u201cg\u201d correspond to respective serial basic modules. The function corresponding to each of the data in the data array is called a function node.","The left hand side of  shows a parallel execution control statement , on which the dataflow graph, shown on the right hand side, is based. Editing to change granularity in parallel processing can be done by a visual editing process in which nodes of a function on a dataflow graph are connected. However, such editing can also be done by directly editing the text of the parallel execution control statement  and, therefore, a parallel execution control statement  may or may not be shown. However, this control statement  may be displayed in addition to a dataflow graph. The parallel execution control statement  may be displayed together with a dataflow graph on the same display unit , or it may be displayed on a display unit (text editor) other than the display unit .","The parallel execution control statement  shown in  is interpreted by the translator  as described below, which is then converted into the graph data structure generation information  for execution by the information processing apparatus .","Step #: The following three lines are interpreted.","local a[100];","local b[100];","local c[100];","Data arrays \u201ca\u201d, \u201cb\u201d, \u201cc\u201d (each having 100 entries) for memorization which are local-declared are generated (an area is secured and initialized).","Step #: The following three lines are the definition of a function.","a[i]: =h(in[i]);","b[i]: =g(in[i]);","c[i]: =f(a[i], b[i]);","Step #: A \u201cfor\u201d sentence is executed and a variable \u201cj\u201d is initialized to \u201c0\u201d. When the \u201cj\u201d equals 100 or less, the loop main body is executed:","for (j=0; j<100; j++){out[i]=k(c[i]);}","Step #: In order to calculate out[] at the body of loop, function \u201ck\u201d is generated. However, since argument c[] is not defined, a node for function \u201ck\u201d is generated, and an edge connecting the node for function \u201ck\u201d and entry to c[] is generated as data dependence.","Step #: An attempt is made to call function \u201cf\u201d in accordance with c[i]: =f(a[i], b[i]), which is a function definition to obtain c[]. However, since arguments a[], b[] are not defined, a node for function \u201cf\u201d is generated. Then edges that connect the node for function \u201cf\u201d and an entry to a[] and an entry to b[] are generated as data dependence.","Step #: In order to obtain a[], an attempt is made to call function \u201ch\u201d in accordance with a[i]: =h (in[i]), which is a function definition. However, since argument in[] is not defined, a node for function \u201ch\u201d is generated. Then an edge that connects the node for function \u201ch\u201d and an entry to a[] is generated as data dependence. As to b[], an edge that connects the node for function \u201ch\u201d and an entry to b[] is generated as data dependence.","Step #: When in[] and in[] are already defined, the process proceeds to execution of functions \u201ch\u201d and \u201cg\u201d, and then the bytecode interpretation is passed on to the following processor.","Step #: When a series of node generation and connection are complete, the process returns to step #, and continues execution of bytecode where i=1.","Step #: At each phase of the parallel execution control statement , when an input value is determined for each of the nodes on a dataflow graph generated and developed as described above, and when execution becomes possible, the process proceeds to execution of the function (thread) that each of the nodes represents.","The dataflow graph shown on the right hand side of  can be generated by simulating the above operation. It is shown on the display unit  via the GUI  as shown in .","During the execution of the foregoing parallel execution control statement , the runtime processing is taken over each time a function (thread) is called. For this reason, if the threads into which a program is divided are too fine, execution of the runtime processing becomes more frequent, increasing total overhead on overall process.","Meanwhile, when the number of processors is not large, even if parallelism is extracted from fine division, a series of processes will have to be performed on the same processor after all.","When there is a hierarchy of memory, there are cases where efficiency improves by processing a group of specific nodes on the same cluster. Four groups of processors (clusters), each group consisting of eight processors sharing secondary cache, share the tertiary cache to constitute 32 (8\u00d74) multiple processors.","Therefore, as shown in , a system for specifying information for making the granularity of node coarser from the dataflow graph screen is proposed.","On the dataflow graph screen, the programmer specifies a plurality of nodes which he or she wants to process as a batch without runtime intervention.  shows an example of grouping of a plurality of nodes for functions \u201cf\u201d, \u201cg\u201d, and \u201ch\u201d in the direction in which data are parallel.  shows, for convenience of explanation, only one representative function in relation to one data array. As a matter of fact, however, for entries (for example, in[], in[] and so on) to the data array, there are nodes h, h, and so on for the corresponding functions. On the dataflow graph screen, grouping is made by specifying or encircling with a mouse  a node for the functions to be grouped. Grouping for the functions \u201cf\u201d and \u201cg\u201d are completed, and entry of a value to a tab for the strength of association (priority order) of the grouping is also completed. The strength of association is a priority order in which grouping specified through programmer operation is actually carried out. As to function \u201ch\u201d, a plurality of nodes h, h, and so on are shown as being encircled by mouse operation (the arrow in  indicates a mouse cursor). Once encirclement is complete, a tab appears in the encircling oval, prompting entry of value data for the priority order.","In accordance with the grouping carried out on the dataflow graph, the graph data structure generation information changes. The grouping will be also reflected in the parallel execution control statement using reverse translation by the translator . That is, as shown on the left hand side of , annotation conn(function, x) are automatically generated at the ends of the definitions of the corresponding functions \u201ch\u201d, \u201cg\u201d, and \u201cf\u201d. \u201cx\u201d represents strength of association.","a[i]: =h(in[i]); conn(h, );","b[i]: =g(in[i]); conn(g, );","c[i]: =f(a[i], b[i]); conn(f, );",{"@attributes":{"id":"p-0080","num":"0079"},"figref":["FIG. 8","FIG. 8"]},{"@attributes":{"id":"p-0081","num":"0080"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"conn(0){"]},{"entry":[{},"a[i]: = h(in0[i]);"]},{"entry":[{},"b[i]: = g(in1[i]);"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},{"@attributes":{"id":"p-0082","num":"0081"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0083","num":"0082"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"140pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"conn(0){"]},{"entry":[{},"\u2002conn(1){"]},{"entry":[{},"\u2003a[i]: = h(in0[i]);"]},{"entry":[{},"\u2003b[i]: = g(in1[i])"]},{"entry":[{},"\u2002}"]},{"entry":[{},"\u2002c[i]: f(a[i], b[i]);"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"It is to be noted that, other than the grouping in a parallel data direction, as shown in , and the grouping in a parallel task direction, as shown in , there is a third grouping, which is a combination of these two.",{"@attributes":{"id":"p-0085","num":"0084"},"figref":"FIG. 10","b":["12","204","14"]},"If a cycle has not occurred, it is determined in block B whether or not the critical processing path deteriorates significantly due to grouping. This determination can also be made by analyzing the parallel execution control statement obtained from the reverse translation. If the critical path deteriorates significantly, a warning message saying \u201cPARALLELISM IS DETERIORATED BY GROUPING\u201d is displayed (block B), thus urging a review of the necessity of the grouping.","If the critical path does not deteriorate significantly, or after a warning message is displayed in block B, it is determined in block  whether or not the candidate nodes to be connected have the same function. If they have the same function, the grouping of data in a parallel direction, shown in , applies. Therefore, in block B, conn(x) is written after the argument list showing the position, at which the corresponding function is applied, on the parallel execution control statement. If the functions are different, the grouping of tasks in a parallel direction as shown in  applies. Therefore, in block B, the arrangement of functions to be grouped on the parallel execution control statement changes. Then the changed arrangement is enclosed within the scope of conn(x){ . . . }.","In the above-mentioned dataflow graph, the edges that connect nodes for function and data entries are shown by simple lines. However, the thickness of line may be changed according to the volume of data transferred between the nodes and displayed. The edge connecting nodes \u201cg\u201d and \u201cf\u201d, shown , are displayed in a thicker line than the other, indicating a larger amount of data. Grouping candidates can be determined by referring to quantities of data.","Edge lines enabling localization of data transfer between the nodes by grouping may be displayed in different colors and types. Such arrangements will provide references for determination of candidates for grouping. For the data transfer between the data arrays, \u201ca\u201d and \u201cc\u201d, shown in , access to the main memory  is not required. Access to either L1 or L2 cache will suffice, thus enabling localization.","The dataflow graph described above is an example expressed two-dimensionally. However, as shown in , when the relationships between tasks are as complicated as the mesh of a net, a two-dimensional space may be exhausted just in displaying the tasks. In such a case, as shown in , the tasks may be shown two-dimensionally while the data array may be shown in a different dimension from the tasks, that is, three-dimensionally.","With the above configurations, the nodes to be connected together and the strength of association thereof can be specified on the dataflow graph that shows parallel processing for a basic module. Using these data, the parallel execution environment is kept compatible with the number of processors and memory hierarchy. If the overhead on runtime processing is large with sufficient parallelism, nodes are connected according to the priority order of strength of association, thereby reducing the frequency of runtime switching. At the same time, when locality of a hierarchy of memory is required, optimization is possible by assigning a node to a cluster, group by group, etc.","In grouping, if array data becomes superfluous due to the grouping, data transfer cost may be greatly reduced. Highlighting such array data in advance makes the programmer aware of the points at which the effect of grouping is high.","As described above, based on the parallel statement describing parallel processing of basic modules, the present embodiment displays a dataflow graph including: a plurality of data entries; a plurality of nodes for basic modules; and edges that connect the plurality of data entries and the plurality of nodes for basic modules. Specifying with a mouse the candidates for node connection on the dataflow graph makes it easy to change the granularity in parallel processing almost by instinct.","While certain embodiments of the inventions have been described, these embodiments have been presented by way of example only, and are not intended to limit the scope of the inventions. Indeed, the novel methods and systems described herein may be embodied in a variety of other forms; furthermore, various omissions, substitutions and changes in the form of the methods and systems described herein may be made without departing from the spirit of the inventions. The various modules of the systems described herein can be implemented as software applications, hardware and\/or software modules, or components on one or more computers, such as servers. While the various modules are illustrated separately, they may share some or all of the same underlying logic or code. The accompanying claims and their equivalents are intended to cover such forms or modifications as would fall within the scope and spirit of the inventions."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS","p":["A general architecture that implements the various feature of the invention will now be described with reference to the drawings. The drawings and the associated descriptions are provided to illustrate embodiments of the invention and not to limit the scope of the invention.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
