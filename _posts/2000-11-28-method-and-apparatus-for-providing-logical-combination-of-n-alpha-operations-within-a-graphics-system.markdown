---
title: Method and apparatus for providing logical combination of N alpha operations within a graphics system
abstract: A graphics system including a custom graphics and audio processor produces exciting 2D and 3D graphics and surround sound. The system includes a graphics and audio processor including a 3D graphics pipeline and an audio digital signal processor. Logical combination of N alpha compares can be used to provide a wide range of imaging effects including but not limited to cartoon outlining.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07061502&OS=07061502&RS=07061502
owner: Nintendo Co., Ltd.
number: 07061502
owner_city: Kyoto
owner_country: JP
publication_date: 20001128
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND AND SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF EXAMPLE EMBODIMENTS OF THE INVENTION","EXAMPLE"],"p":["This application claims the benefit of U.S. Provisional Application Nos. 60\/226,915 and 60\/226,888 filed Aug. 23, 2000, the entire contents of which are hereby incorporated by reference. This application is related to concurrently-filed application Ser. No. 09\/722,367 of Drebin et al entitled \u201cRecirculating Shade Tree Blender For a Graphics System\u201d.","The present invention relates to computer graphics, and more particularly to interactive graphics systems such as home video game platforms. Still more particularly, this invention relates to the use of logical combination of N alpha channel operations to generate interesting visual graphics effects including but not limited to non-photorealistic images such as cartoon outlining.","Many of us have seen films containing remarkably realistic dinosaurs, aliens, animated toys and other fanciful creatures. Such animations are made possible by computer graphics. Using such techniques, a computer graphics artist can specify how each object should look and how it should change in appearance over time, and a computer then models the objects and displays them on a display such as your television or a computer screen. The computer takes care of performing the many tasks required to make sure that each part of the displayed image is colored and shaped just right based on the position and orientation of each object in a scene, the direction in which light seems to strike each object, the surface texture of each object, and other factors.","Because computer graphics generation is complex, computer-generated three-dimensional graphics just a few years ago were mostly limited to expensive specialized flight simulators, high-end graphics workstations and supercomputers. The public saw some of the images generated by these computer systems in movies and expensive television advertisements, but most of us couldn't actually interact with the computers doing the graphics generation. All this has changed with the availability of relatively inexpensive 3D graphics platforms such as, for example, the Nintendo 64\u00ae and various 3D graphics cards now available for personal computers. It is now possible to interact with exciting 3D animations and simulations on relatively inexpensive computer graphics systems in your home or office.","Most computer graphics research has tended to focus on producing realistic images. This research has been very successful. Computers can now generate images that are so realistic that you can't tell them apart from photographs. For example, many of us have seen very convincing dinosaurs, aliens and other photorealistic computer-generated special effects in movie and television. New pilots train on computer-based flight simulators so realistic that they nearly duplicate actual flying. Low-cost home video game systems can now provide a remarkable degree of realism, giving the game player an illusion of driving a real race car along a track, skiing down a snow and ice covered ski slope, walking through a medieval castle, or the like. For most games, this illusion of realism significantly enhances the game play experience.","One way to enhance realism is to model the opacity (transparency) of surfaces using a technique called \u201calpha blending.\u201d Using this conventional technique, each image element is assigned an \u201calpha value\u201d representing its degree of opacity. The colors of the image element are blended based on the alpha value\u2014allowing one object to appear to be visible through another object. A further conventional technique called \u201calpha function\u201d or \u201calpha test\u201d can be used to discard an object fragment based on comparing the fragment's alpha value with a reference function or value. Alpha test may decide to not blend (i.e., to throw away) a potential part of an image because it is transparent and will therefore be invisible.","Alpha blending and alpha test are especially useful for modeling transparent objects such as water and glass. This same functionality can also be used with texture mapping to achieve a variety of effects. For example, the alpha test is frequently used to draw complicated geometry using texture maps on polygons\u2014with the alpha component acting as a matte. By way of illustration, a tree can be drawn as a picture (texture) of a tree on a polygon. The tree parts of the texture image can have an alpha value of 1 (opaque), and the non-tree parts can have an alpha value of 0 (transparent). In this way, the \u201cnon-tree\u201d parts of the polygons are mapped to invisible (transparent) portions of the texture map, while the \u201ctree\u201d portions of the polygon are mapped to visible (opaque) portions of the texture map.","The alpha component of a texture can be used in other ways\u2014for example, to cut holes or trim surfaces. As one example, an image of a cutout or a trim region can be stored in a texture map. When mapping the texture to the polygon surface, alpha testing or blending can be used to cut the cutout or trimmed region out of the polygon's surface. Additionally, the alpha channel of a computer graphics system can be also be used to provide non-photorealistic image effects such as cartoon outlining. An arrangement described in U.S. patent application Ser. No. 09\/468,109 filed Dec. 21, 1999 uses the alpha channel of a real time rendering system to encode identifications corresponding to different objects or portions of objects. The system renders the objects into a color frame buffer, and writes corresponding object Ids into an alpha frame buffer. An alpha test operation is performed on the alpha frame buffer, and the alpha compare results (i.e., the absolute value of the difference between two alpha values) are used to selectively blend outline coloration around silhouette and other edges defined between image areas encoded with different alpha\/Ids.","Typical generally available 3D graphics application programmer interfaces such as DirectX and OpenGL support alpha compares for transparency or other purposes, e.g., to compare an iterated or texture alpha to a constant and \u201ckill\u201d the pixel in the compare fails. As one example, Direct3D provides a command \u201cD3DRENDERSTATE_ALPHATEST-ENABLE that can be used to enable alpha testing. The command D3DCOMFUNC enumerated type allows the programmer to specify the possible tests used in the alpha compare operation (e.g., never, always, <, >, less than or equal to, greater than or equal to, not equal to, etc.) For example, if the alpha comparison function is set to \u201cgreater than or equal to\u201d, then if the pixel being rasterized is less opaque than the color already at the pixel, Direct3D will skip it completely\u2014saving the time that would have been required to blend the two colors together and preventing the color and z buffers from being updated. It is also possible to compare the incoming alpha with a programmer-specified reference alpha value (e.g., \u201cif (alpha<128\/255) then kill the pixel) by using the D3DRENDERSTATE_ALPHAREF command. See, e.g., Kovach, 3(Microsoft 2000) at 289\u2013291. Similar alpha testing\/comparison capabilities are provided in OpenGL by the GL_ALPHA_TEST, GL_ALPHA_TEST_FUNC and GL_ALPHA_TEST_REF commands. See, e.g., Neider et al, (Addison-Wesley 1993) at 301\u2013302.","An issue that arises when implementing various complex alpha comparisons including but not limited to the cartoon outlining algorithm mentioned above, is how to efficiently perform more complicated alpha comparisons in hardware using a single rendering pass. For example, while arbitrarily complex alpha tests can typically be straightforwardly be performed by a processor executing software, it may be desirable (e.g., for increased speed performance) to use a hardware-based alpha test. Such an arbitrarily complex alpha test capability has not generally been available in the past within the context of a low cost graphics system such as a home video game or a personal computer graphics card.","The present invention solves this problem by providing a hardware-based pixel shader capable of performing plural alpha comparisons that can be logically combined to achieve a wide range of alpha test functionality. In accordance with one aspect of the invention, the pixel shader can be used to provide a transparency tree analogous to a shade tree. In particular, alpha functionality can be used to provide N logical alpha operations on M alpha inputs, where N and M can be any integers.","One aspect of the invention provides a method of generating a graphics image comprising generating information representing a surface to be imaged, said information including alpha; performing, within the same rendering pass, plural alpha comparisons on said alpha information to provide corresponding plural alpha comparison results; logically combining said plural alpha comparison results; and rendering said graphics image based at least in part on said logical combination. The rendering step may include selecting whether or not to kill a pixel based on said logical combination. The performing step can be performed in hardware and\/or using a recirculating shader.","In accordance with a further aspect provided by the invention, a graphics system comprises a texture unit including a texture coordinate matrix multiplier; a shader including an alpha channel; an embedded frame buffer that can store an alpha image; and a copy-out pipeline for copying an alpha image from said frame buffer for use as a texture by said texture unit, wherein said graphics system performs plural alpha comparisons in a single rendering pass.","The combination of alpha compares and alpha logical operations can be used for a wide range of additional alpha-based effects. For example, dual alpha comparisons can be used to provide non-photorealistic effects such as cartoon outlining (e.g., to efficiently determine whether to blend a cartoon outline color based on said logical combination by implementing an absolute value function).",{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 1","b":["50","50"]},"In this example, system  is capable of processing, interactively in real time, a digital representation or model of a three-dimensional world. System  can display some or all of the world from any arbitrary viewpoint. For example, system  can interactively change the viewpoint in response to real time inputs from handheld controllers , or other input devices. This allows the game player to see the world through the eyes of someone within or outside of the world. System  can be used for applications that do not require real time 3D interactive display (e.g., 2D display generation and\/or non-interactive display), but the capability of displaying quality 3D images very quickly can be used to create very realistic and exciting game play or other graphical interactions.","To play a video game or other application using system , the user first connects a main unit  to his or her color television set  or other display device by connecting a cable  between the two. Main unit  produces both video signals and audio signals for controlling color television set . The video signals are what controls the images displayed on the television screen , and the audio signals are played back as sound through television stereo loudspeakers L, R.","The user also needs to connect main unit  to a power source. This power source may be a conventional AC adapter (not shown) that plugs into a standard home electrical wall socket and converts the house current into a lower DC voltage signal suitable for powering the main unit . Batteries could be used in other implementations.","The user may use hand controllers , to control main unit . Controls  can be used, for example, to specify the direction (up or down, left or right, closer or further away) that a character displayed on television  should move within a 3D world. Controls  also provide input for other applications (e.g., menu selection, pointer\/cursor control, etc.). Controllers  can take a variety of forms. In this example, controllers  shown each include controls  such as joysticks, push buttons and\/or directional switches. Controllers  may be connected to main unit  by cables or wirelessly via electromagnetic (e.g., radio or infrared) waves.","To play an application such as a game, the user selects an appropriate storage medium  storing the video game or other application he or she wants to play, and inserts that storage medium into a slot  in main unit . Storage medium  may, for example, be a specially encoded and\/or encrypted optical and\/or magnetic disk. The user may operate a power switch  to turn on main unit  and cause the main unit to begin running the video game or other application based on the software stored in the storage medium . The user may operate controllers  to provide inputs to main unit . For example, operating a control  may cause the game or other application to start. Moving other controls  can cause animated characters to move in different directions or change the user's point of view in a 3D world. Depending upon the particular software stored within the storage medium , the various controls  on the controller  can perform different functions at different times.","Example Electronics of Overall System",{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 2","b":"50","ul":{"@attributes":{"id":"ul0001","list-style":"none"},"li":{"@attributes":{"id":"ul0001-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0002","list-style":"none"},"li":["a main processor (CPU) ,","a main memory , and","a graphics and audio processor ."]}}}},"In this example, main processor  (e.g., an enhanced IBM Power PC 750) receives inputs from handheld controllers  (and\/or other input devices) via graphics and audio processor . Main processor  interactively responds to user inputs, and executes a video game or other program supplied, for example, by external storage media  via a mass storage access device  such as an optical disk drive. As one example, in the context of video game play, main processor  can perform collision detection and animation processing in addition to a variety of interactive and control functions.","In this example, main processor  generates 3D graphics and audio commands and sends them to graphics and audio processor . The graphics and audio processor  processes these commands to generate interesting visual images on display  and interesting stereo sound on stereo loudspeakers R, L or other suitable sound-generating devices.","Example system  includes a video encoder  that receives image signals from graphics and audio processor  and converts the image signals into analog and\/or digital video signals suitable for display on a standard display device such as a computer monitor or home color television set . System  also includes an audio codec (compressor\/decompressor)  that compresses and decompresses digitized audio signals and may also convert between digital and analog audio signaling formats as needed. Audio codec  can receive audio inputs via a buffer  and provide them to graphics and audio processor  for processing (e.g., mixing with other audio signals the processor generates and\/or receives via a streaming audio output of mass storage access device ). Graphics and audio processor  in this example can store audio related information in an audio memory  that is available for audio tasks. Graphics and audio processor  provides the resulting audio output signals to audio codec  for decompression and conversion to analog signals (e.g., via buffer amplifiers L, R) so they can be reproduced by loudspeakers L, R.","Graphics and audio processor  has the ability to communicate with various additional devices that may be present within system . For example, a parallel digital bus  may be used to communicate with mass storage access device  and\/or other components. A serial peripheral bus  may communicate with a variety of peripheral or other devices including, for example:\n\n","A further external serial bus  may be used to communicate with additional expansion memory  (e.g., a memory card) or other devices. Connectors may be used to connect various devices to busses , , .","Example Graphics And Audio Processor",{"@attributes":{"id":"p-0045","num":"0050"},"figref":"FIG. 3","b":["114","114","114"],"ul":{"@attributes":{"id":"ul0005","list-style":"none"},"li":{"@attributes":{"id":"ul0005-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0006","list-style":"none"},"li":["a processor interface ,","a memory interface\/controller ,","a 3D graphics processor ,","an audio digital signal processor (DSP) ,","an audio memory interface ,","an audio interface and mixer ,","a peripheral controller , and","a display controller ."]}}}},"3D graphics processor  performs graphics processing tasks. Audio digital signal processor  performs audio processing tasks. Display controller  accesses image information from main memory  and provides it to video encoder  for display on display device . Audio interface and mixer  interfaces with audio codec , and can also mix audio from different sources (e.g., streaming audio from mass storage access device , the output of audio DSP , and external audio input received via audio codec ). Processor interface  provides a data and control interface between main processor  and graphics and audio processor .","Memory interface  provides a data and control interface between graphics and audio processor  and memory . In this example, main processor  accesses main memory  via processor interface  and memory interface  that are part of graphics and audio processor . Peripheral controller  provides a data and control interface between graphics and audio processor  and the various peripherals mentioned above. Audio memory interface  provides an interface with audio memory .","Example Graphics Pipeline",{"@attributes":{"id":"p-0048","num":"0061"},"figref":"FIG. 4","b":["154","154","200","180","110","200","110","115","111","114","111","114"]},"Command processor  receives display commands from main processor  and parses them\u2014obtaining any additional data necessary to process them from shared memory . The command processor  provides a stream of vertex commands to graphics pipeline  for 2D and\/or 3D processing and rendering. Graphics pipeline  generates images based on these commands. The resulting image information may be transferred to main memory  for access by display controller\/video interface unit \u2014which displays the frame buffer output of pipeline  on display .",{"@attributes":{"id":"p-0050","num":"0063"},"figref":"FIG. 5","b":["154","110","210","212","214","112","200","150","110","210","110","200"],"ul":{"@attributes":{"id":"ul0007","list-style":"none"},"li":{"@attributes":{"id":"ul0007-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0008","list-style":"none"},"li":["command streams from main memory  via an on-chip FIFO memory buffer  that receives and buffers the graphics commands for synchronization\/flow control and load balancing,","display lists  from main memory  via an on-chip call FIFO memory buffer , and","vertex attributes from the command stream and\/or from vertex arrays  in main memory  via a vertex cache ."]}}}},"Command processor  performs command processing operations that convert attribute types to floating point format, and pass the resulting complete vertex polygon data to graphics pipeline  for rendering\/rasterization. A programmable memory arbitration circuitry  (see ) arbitrates access to shared main memory  between graphics pipeline , command processor  and display controller\/video interface unit .",{"@attributes":{"id":"p-0052","num":"0068"},"figref":"FIG. 4","b":"180","ul":{"@attributes":{"id":"ul0009","list-style":"none"},"li":{"@attributes":{"id":"ul0009-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0010","list-style":"none"},"li":["a transform unit ,","a setup\/rasterizer ,","a texture unit ,","a texture environment unit , and","a pixel engine ."]}}}},"Transform unit  performs a variety of D and D transform and other operations (see ). Transform unit  may include on or more matrix memories for storing matrices used in transformation processing . Transform unit  transforms incoming geometry per vertex from object space to screen space; and transforms incoming texture coordinates and computes projective texture coordinates (). Transform unit  may also perform polygon clipping\/culling . Lighting processing also performed by transform unit provides per vertex lighting computations for up to eight independent lights in one example embodiment. Transform unit  can also perform texture coordinate generation () for embossed type bump mapping effects, as well as polygon clipping\/culling operations ().","Setup\/rasterizer  includes a setup unit which receives vertex data from transform unit  and sends triangle setup information to one or more rasterizer units () performing edge rasterization, texture coordinate rasterization and color rasterization.","Texture unit  (which may include an on-chip texture memory (TMEM) ) performs various tasks related to texturing including for example:\n\n","Texture unit  outputs filtered texture values to the texture environment unit  for texture environment processing (). Texture unit  is recirculating, and is able to perform both direct and indirect texturing and providing a sequence of texture mapping outputs to texture environment unit  for blending during a single rendering pass. See U.S. patent application Ser. No. 09\/722,382 entitled \u201cMethod And Apparatus For Indirect Texture Referencing In A Graphics System\u201d, and its corresponding provisional application Ser. No. 60\/226,891, filed Aug. 23, 2000, both of which are incorporated herein by this reference.","Texture environment unit  blends polygon and texture color\/alpha\/depth, and can also perform texture fog processing () to achieve inverse range based fog effects. Texture environment unit  can provide multiple stages to perform a variety of other interesting environment-related functions based for example on color\/alpha modulation, embossing, detail texturing, texture swapping, clamping, and depth blending. For example, the texture environment unit  of system  includes a recirculating shader providing a separately controllable alpha channel that processes alpha information independently of color information without slowing down the graphics pipeline. The recirculating shader design of texture environment unit  makes it possible to implement alpha transparency \u201cshade trees\u201d providing arbitrarily complex alpha blending and comparison functions. See commonly assigned U.S. patent application Ser. No. 09\/722,367 entitled \u201cRecirculating Shade Tree Blender For A Graphics System\u201d, and its corresponding provisional application, Ser. No. 60\/226,888, filed Aug. 23, 2000, both of which are incorporated herein by this reference.","Pixel engine  performs depth (z) compare () and pixel blending (). In this example, pixel engine  stores data into an embedded (on-chip) frame buffer memory . Graphics pipeline  may include one or more embedded DRAM memories  to store frame buffer and\/or texture information locally. Z compares \u2032 can also be performed at an earlier stage in the graphics pipeline  depending on the rendering mode currently in effect (e.g., z compares can be performed earlier if alpha blending is not required). The pixel engine  includes a copy operation that periodically writes on-chip frame buffer  to main memory  for access by display\/video interface unit . This copy operation can also be used to copy embedded frame buffer  contents to textures in the main memory  for dynamic texture synthesis effects. Anti-aliasing and other filtering can be performed during the copy-out operation. The frame buffer output of graphics pipeline  (which is ultimately stored in main memory ) is read each frame by display\/video interface unit . Display controller\/video interface  provides digital RGB pixel values for display on display . A copy-out pipeline that may be part of pixel engine  permits, within a single rendering pass, some or all of embedded frame buffer  to be copied out into main memory  as a texture. Texture unit  may then read the copied-out texture into texture memory  for use in texture mapping additional visualization into the frame buffer contents. It is possible for system  to copy out, for example, alpha information rendered into embedded frame buffer  and apply this alpha information as a texture for texture mapping to add to the contents of the embedded frame buffer\u2014all within the same rendering pass. See U.S. patent application Ser. No. 09\/722,663 entitled \u201cGraphics System With Copy-Out Conversions Between Embedded Frame Buffer And Main Memory\u201d, and its corresponding provisional application Ser. No. 60\/227,030, filed Aug. 23, 2000, both of which are incorporated herein by this reference.","Logical Combination of N Alpha Comparisons","As described in copending application Ser. No. 09\/722,367 of Drebin et al entitled \u201cRecirculating Shade Tree Blender For a Graphics System\u201d (the entire disclosure of which including the drawings of which is incorporated herein by reference), the example embodiment recirculating shader  (see ) supports different alpha functions including a logical combination of plural alpha test results within a single rendering pass. In the example embodiment, the alpha function compares the source alpha with a reference alpha using any one of the following operations:\n\n","The two functions are combined in the example embodiment using:\n\n","Example 1\n\n0 1\n","Example 2\n\n0 1\n","Example 3\n\n\n","The alpha functionality of recirculating shader  (e.g., in combination with the non-recirculating alpha compare) can thus be used to provide a transparency tree analogous to a shade tree. In particular, recirculating shader 's alpha functionality can be used to provide N logical alpha operations on M alpha inputs, where N and M can be any integers. The combination of alpha compares and alpha logical operations can be used, for example, to provide non-photorealistic effects such as cartoon outlining.","Example Cartoon Outlining Technique",{"@attributes":{"id":"p-0065","num":"0102"},"figref":["FIGS. 13 and 14","FIG. 13"],"b":["1300","1302","1302"]},{"@attributes":{"id":"p-0066","num":"0103"},"figref":["FIG. 13","FIG. 13"],"b":["1300","1300","1302"]},"To make cartoon character  appear as if it were hand-drawn, it would be helpful to apply border lines to silhouette edges as well as to certain internal edges \u2014i.e., those internal edges in this example that define the character's hand, wrist and portion of forearm that the character is holding in front of himself.  shows character  with a border line applied to these internal edges . These internal edges  would be silhouette edges if the character  was holding its arm in an outstretched position, but are internal edges in the arm orientation shown in .","A way to solve this problem is to assign different ID values to different objects or portions of an object, and to keep track of which pixels represent different objects or portions of an object by associating the ID values with the pixels during a rendering process. Such identification values can be assigned, as one example, by allocating bits within frame buffer  that are normally used to encode Alpha information. The assigned identification values may be used to determine whether or not to draw a border line at that pixel location. For example, the system may compare the identification value of a pixel to the identification value of a nearby (e.g., adjacent) pixel. If the identification values of two adjacent pixels have a certain predetermined relationship, then no border line is drawn. If the identification values are the same, then the two pixels are on the same surface and no border line is drawn. If the identification values of two adjacent pixels have a certain other predetermined relationship indicating an overlap of different objects or different portions of an object, then a border line is drawn.",{"@attributes":{"id":"p-0069","num":"0106"},"figref":["FIGS. 15A\u201315C","FIG. 15A","FIG. 15B","FIG. 15A"],"b":["1319","1320","1322","1324","1319","1320","1322","1324","330","1324","1320","1322"]},"In this example, pixels within square , circle  and cone  are coded with different respective identification values. By way of example, pixels within square  can be coded with an identification value of \u201c1\u201d; pixels within circle  can be coded with \u201c2\u201d; and pixels within cone  can be coded with \u201c3\u201d.  shows an example Alpha portion of frame buffer  storing the coded information, The shaded cells indicate those cells to which a border line color may be applied, based on a difference of 2 (or more) between neighboring alpha\/id values.","During a pixel post-processing phase after an alpha and color image has been rendered into the frame buffer , the various identification values within the frame buffer can be tested. No border line is drawn for pixels having the same identification value as adjacent pixels (all such pixels are on the same surface). Also, no border line is drawn if a pixel has an identification value that differs by a predetermined criteria or set of criteria from the identification value of adjacent pixels (e.g., if the identification value of pixel k differs by less than 2 from the identification value of pixel k+1, then no border line is drawn). However, a border line is drawn if a pixel has an identification value that differs by a further predetermined criteria or set of criteria from the identification value of adjacent pixels (e.g., if the identification value of pixel k differs by 2 or more from the identification value of pixel k+1, then a border line may be drawn at pixel k).",{"@attributes":{"id":"p-0072","num":"0109"},"figref":"FIG. 16","b":["1350","1350","1352","1362","702","1350","1350","1352","1352","1354","1350","1356","1350","1358","1352","1358","1360","1362"],"br":[{},{},{}],"in-line-formulae":[{},{},{},{}],"i":["diffX=ABS","Alpha[i][j]\u2212Alpha[i\u2212","][j","diffX=ABS","Alpha[i][j]\u2212Alpha[i][j\u2212"]},"In one variation of routine , certain objects can be coded with a special Alpha identification value (e.g., 0x00) to specify that the pixels within the object are to be ignored for the purpose of drawing border lines (see ). This could be useful, for example, to render a non-border-lined object as a bit map (e.g., for explosion animation).",{"@attributes":{"id":"p-0074","num":"0111"},"figref":["FIG. 17","FIGS. 13 and 14"],"b":["1350","1300","1300","1300","1311","1311","1309","1313","1315","1312","1308","1310","1317"],"i":["a","b "]},{"@attributes":{"id":"p-0075","num":"0112"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"center"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Body Part","Alpha ID"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"left hand 1313a","1"]},{"entry":[{},"left wrist 1315a","2"]},{"entry":[{},"left lower arm 1312a","3"]},{"entry":[{},"left elbow 1308a","4"]},{"entry":[{},"left upper arm 1310a","5"]},{"entry":[{},"left shoulder 1317a","6"]},{"entry":[{},"torso 1309","7"]},{"entry":[{},"right shoulder 1317b","8"]},{"entry":[{},"right upper arm 1310b","9"]},{"entry":[{},"right elbow 1311b","10"]},{"entry":[{},"right lower arm 1312b","11"]},{"entry":[{},"right wrist 1315b","12"]},{"entry":[{},"right hand 1313b","13"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"With the example Alpha ID coding above, routine  will draw border lines as shown with dark lines in , but will not draw border lines at the other (dotted line) intersections between objection portions.","The coding above can also be used to apply a border line to intersections between connected portions of the same object . Conventional coloring books, hand-drawn animated cartoons and the like sometimes apply cartoon outlining to such self-intersections in order to give greater definition to the articulated joint, create the illusion of muscle development, and the like. For example,  show a close-up of the articulated joint  (i.e., elbow) of character  joining the character's upper arm  with forearm . Using the coding described above, when the articulated joint  is bent so that appendages ,  are oriented adjacent to (e.g., in contact with) one another as illustrated in , routine  will (based on the difference between Alpha ID of lower arm  and Alpha ID of upper arm  being greater than one) apply a border line segment  to the intersection of body segments ,  intersect.","Example Cartoon Outlining Process Implemented On System ",{"@attributes":{"id":"p-0078","num":"0115"},"figref":["FIG. 19","FIG. 20"],"b":["50","50"]},"Referring to , to perform cartoon outline imaging or other similar effects, the application sets up frame buffer  to include an alpha channel (block ). See U.S. patent application Ser. No. 09\/722,380 entitled \u201cEmbedded DRAM Frame Buffer With Reconfigurable Pixel Format\u201d, and its corresponding provisional application Ser. No. 60\/226,910, filed Aug. 23, 2000, both of which are incorporated herein by this reference. System  then is controlled to draw a scene into frame buffer  (block ). During this operation, however, object identifiers that may be provided by main processor  as part of per-vertex information, for example, are written into the alpha channel of system  for storage into the alpha locations within frame buffer .","Some attention to detail should be used when assigning IDs to surfaces. The example embodiment alpha channel is limited to eight bits, so it is possible that IDs may need to be reused if there are more than 256 different objects in a scene. In one example implementation, only seven bits of alpha are available, with the eighth bit being used as a sign bit for the threshold operation. This is acceptable so long as different objects with identical IDs do not overlap. If silhouettes are desired on overlapping sections of concave objects, a more complex ID and threshold system can be used. One way to implement this is to assign IDs that vary by one to different parts of the same object, with a total difference of at least two for possibly overlapping sections. The threshold function then only needs to create silhouettes for differences of at least two. See  above. Of course, different implementations will have different limitations, and these particular arrangements are illustrative only.","Once the desired portion of the image has been rendered into frame buffer , pixel engine  is controlled to copy the alpha image of the frame buffer to a texture in the external frame buffer or other buffer (block ; see ). Such copy out can be into IA8 texture format, for example. Appropriate precautions are taken to ensure synchronization and memory coherence. See the synchronization token technique described in U.S. patent application Ser. No. 09\/726,227 entitled \u201cDynamically Reconfiguring of Hidden Surface Processing Based on Rendering Mode\u201d, and its corresponding provisional application, Ser. No. 60\/226,890, filed Aug. 23, 2000, both of which are incorporated herein by this reference.","Once the alpha texture has been successfully copied out of the internal frame buffer and then read into texture memory  (see ), system  configures the graphics processor  to write outline color to pixels within frame buffer  based on differences between neighboring pixel alphas (block ). See  above. Such a draw cartoon outline operation may, for example, involve reading out pixel alpha values, modifying those alpha values, and then writing back alpha as a blend parameter. Neighboring alpha values can be looked up from the alpha texture using one set of texture coordinates and two different texture matrices. One matrix can be set to the identity matrix, while the other is set to the identity matrix plus a translation. The blend test\/comparison can be implemented using two general alpha compare functions combined with a third logical operation such as OR or AND. This allows us to do inside-outside range testing instead of just greater\/less than.","In more detail, to perform the difference computation (e.g., the absolute value of [a\u2212a] where ais the alpha value for a given pixel and ais the alpha value for a neighboring pixel), texture environment unit  can be set up to subtract one alpha value from the other and to write the unclamped result to the texture environment unit output register. The alpha compare or other value comparator within texture environment unit  can be set up to detect alpha values that exceed the threshold, i.e.:\n\n12\n\n1\n\n2\n\n1 2.\n","In one particular implementation, unclamped negative results from texture environment unit  may turn into alpha values with the most significant bit set. Thus, for an alpha difference threshold of 2, the application can write the outline color to pixels with an alpha difference greater than 1 and smaller than (max\u22122) where max might equal 255. Texture environment unit  can be set up to blend in a color value from a register based upon the results of the comparison. Main processor  can set this color value register to any desired value (e.g., black for a black outlining effect, blue for a blue outlining effect, etc.).","In one particular example, writing outlines can be performed in two recirculation passes of recirculating shader within texture environment unit . In the first pass (block ), horizontal outlining is drawn into frame buffer  based on a texture coordinate transformation matrix multiplication performed by transform unit  that is set up to shift the alpha texture image one pixel (texel) vertically. In a second pass (block ) used for writing vertical outlines, the texture matrix can be modified to shift the alpha image one pixel (texel) horizontally. Thicker outlines can be achieved by making the shifts larger than one pixel, but visual anomalies may result if the outlines are made too thick.","Once both horizontal and vertical outlines have been written into frame buffer , the frame buffer can be copied out for display (block ).","The following shows an example set of application programming interface calls that can be used to control system  to perform cartoon outlining:",{"@attributes":{"id":"p-0088","num":"0125"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"84pt","align":"left"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Function","Parameters","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["GXSetTexCopySrc","xOrig, yOrig,","0, 0, SCREEN_WD,"]},{"entry":[{},"width, height","SCREEN_HT"]},{"entry":["GXCopyTex","copy buffer","referred by"]},{"entry":[{},{},"GXLoadTexObjPreLoaded"]},{"entry":[{},"texture format","GX_TF_IA8"]},{"entry":[{},"mipmap filter","GX_DISABLE"]},{"entry":[{},"clear on copy","GX_DISABLE"]},{"entry":["GXLoadTexObjPreLoaded","texture map ID","GX_TEXMAP0"]},{"entry":[{},"texture object","defined by"]},{"entry":[{},"ptr","GXInitTexObj\/TexObjLOD"]},{"entry":[{},"texture region","defined by"]},{"entry":[{},"ptr","GXInitTexRegion"]},{"entry":["GXInitTexObj","texture object","for output"]},{"entry":[{},"ptr"]},{"entry":[{},"pointer for","outputted by GXCopyTex"]},{"entry":[{},"bitmap"]},{"entry":[{},"width","SCREEN_WD"]},{"entry":[{},"height","SCREEN_HT"]},{"entry":[{},"texture format","GX_TF_IA8"]},{"entry":[{},"clamp_s,","GX_CLAMP,"]},{"entry":[{},"clamp_t","GX_CLAMP"]},{"entry":[{},"mipmap enable","GX_DISABLE"]},{"entry":["GXInitTexObjLOD","texture object","same as GXInitTexObj's"]},{"entry":[{},"ptr"]},{"entry":[{},"min_filter","GX_NEAREST"]},{"entry":[{},"max_filter","GX_NEAREST"]},{"entry":[{},"min_lod,","0.0f, 0.0f, 0.0f (don't care)"]},{"entry":[{},"max_lod,"]},{"entry":[{},"lod_bias"]},{"entry":[{},"bias_clamp,","GX_DISABLE, GX-"]},{"entry":[{},"do_edge_lod","DISABLE (don't care)"]},{"entry":[{},"max_aniso","GX_ANISO_1"]},{"entry":[{},{},"(don't care)"]},{"entry":["GXInitTexPreloadRegion","texture_region","for output"]},{"entry":[{},"tmem_even","0"]},{"entry":[{},"size_even","0 (don't care)"]},{"entry":[{},"tmem_odd","0 (don't care)"]},{"entry":[{},"size_odd","0 (don't care)"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":"Texture Environment"},{"entry":"Blend\/Alpha Compare commands"},{"entry":"((See \u201cRecirculating Shade Tree Blender For A Graphics System\u201d referenced above."}]}}}},"br":{}},"Description","This function sets the source parameters for the Embedded Frame Buffer (EFB) to texture image copy. This feature is useful when creating textures using the Graphics Processor (GP).","The GP will copy textures into the tiled texture format specified in GXCopyTex. The GP always copies tiles (B) so image widths and heights that are not a multiple of the tile width will be padded with undefined data in the copied image. Also, the allocated image size in main memory must be a multiple of 32 B, see GXGetTexBufferSize.","Arguments\n\n","Description","This function copies the Embedded Frame Buffer (EFB) to a texture image buffer, dest, in main memory. This is useful when creating textures using the Graphics Processor (GP). If the clear flag is GX_TRUE, the EFB will be cleared to the current clear color (see GXSetCopyClear) during the copy operation. The source image is described by GXSetTexCopySrc. The EFB is converted to the texture format during the copy. The texture format and an optional box filter enable are set using GXSetTexCopyDst.","The allocated buffer is padded to texture tiles (32 B\/tile) in X and Y. The function GXGetTexBufferSize is provided to determine the padded size.","The clear flag indicates the frame buffer should be cleared during the copy operation. The frame buffer is cleared to the constant values specified by GXSetCopyClear.","Arguments\n\n","Description","This function loads the state describing a preloaded texture into one of eight hardware register sets. Before this happens, the texture object, obj, should be initialized using GXInitTexObj or GXInitTexObjCI. The id parameter refers to the texture state register set. The texture should be loaded beforehand using GXPreLoadEntireTexture.","Once loaded, the texture can be used in any Texture Environment (Tev) stage using the GXSetTevOrder function. GXInit initially calls GXSetTevOrder to make a simple texture pipeline that associates GX_TEXMAP with GX_TEVSTAGE, GX_TEXMAP with GX_TEVSTAGE, etc.","Note that GXLoadTexObjPreLoaded will not call the functions set by GXSetTexRegionCallBack (and GXSetTlutRegionCallBack if the texture is color index format) because the region is set explicitly. However, these callback functions must be aware of all regions that are preloaded. The default callbacks set by GXInit assume there are no preloaded regions.","Arguments\n\n","Description","This function is used to initialize or change a texture object for non-color index textures. Texture objects are used to describe all the parameters associated with a texture, including size, format, wrap modes, filter modes, etc. It is the application's responsibility to provide memory for a texture object. Once initialized, a texture object can be associated with one of eight active texture IDs using GXLoadTexObj.","To initialize a texture object for color index format textures, use GXInitTexObjCI.","If the mipmap flag is GX_TRUE, then the texture is a mipmap and the texture will be trilerped. If the mipmap flag is GX_FALSE, the texture is not a mipmap and the texture will be bilerped. To override the filter modes and other mipmap controls, see GXInitTexObjLOD.","Arguments",{"@attributes":{"id":"p-0108","num":"0154"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Arguments"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["obj","Pointer to a texture object."]},{"entry":["image_ptr","Pointer to the image data for a texture, aligned to 32B."]},{"entry":["width","Width of the texture or LOD 0 for mipmaps. Max value"]},{"entry":[{},"is 1024. Mipmaps must be a power of two."]},{"entry":["height","Height of the texture or LOD 0 for mipmaps. Max value"]},{"entry":[{},"is 1024. Mipmaps must be a power of two."]},{"entry":["format","Texel format."]},{"entry":["wrap_s","Describes how texture coordinates will be wrapped in"]},{"entry":[{},"the s direction. Accepted values are: GX_CLAMP,"]},{"entry":[{},"GX_REPEAT, GX_MIRROR."]},{"entry":["wrap_t","Describes how texture coordinates will be wrapped in"]},{"entry":[{},"the t direction. Accepted values are: GX_CLAMP,"]},{"entry":[{},"GX_REPEAT, GX_MIRROR."]},{"entry":["mipmap","If mipmap = GX_TRUE, the texture is a mipmap and will"]},{"entry":[{},"have trilinear filtering; otherwise, it is not a mipmap and will"]},{"entry":[{},"use bilinear filtering."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},{"@attributes":{"id":"p-0109","num":"0155"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]},{"entry":[{},"C Specification"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"# include <dolphin\/gx.h>"]},{"entry":[{},"void GXInitTexObjLOD("]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"91pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"GXTexObj*","obj,"]},{"entry":[{},"GXTexFilter","min_filt,"]},{"entry":[{},"GXTexFilter","mag_filt,"]},{"entry":[{},"f32","min_lod,"]},{"entry":[{},"f32","max_lod,"]},{"entry":[{},"f32","lod_bias,"]},{"entry":[{},"GXBool","bias_clamp,"]},{"entry":[{},"GXBool","do_edge_lod,"]},{"entry":[{},"GXAnisotropy","max_aniso );"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"Description","This function sets texture Level Of Detail (LOD) controls explicitly for a texture object. It is the application's responsibility to provide memory for a texture object. When initializing a texture object using GXInitTexObj or GXInitTexObjCI, this information is set to default values based on the mipmap flag. This function allows the programmer to override those defaults. Note that this function should be called after GXInitTexObj or GXInitTexObjCI for a particular texture object.","The LOD computed by the graphics hardware can be biased using the lod_bias parameter. The lod_bias is added to the computed lod and the result is clamped between min_lod and max_lod. If bias_clamp is enabled, the effect of lod_bias will diminish as the polygon becomes more perpendicular to the view direction. This prevents over-sharpening the texture in this situation, but allows LOD biasing for oblique polygons.",{"@attributes":{"id":"p-0113","num":"0159"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Arguments"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["obj","Pointer to a texture object."]},{"entry":["min_filt","Filter mode to use when the texel\/pixel ratio is >= 1.0."]},{"entry":[{},"Accepted values: GX_NEAR, GX_LINEAR,"]},{"entry":[{},"GX_NEAR_MIP_NEAR, GX_LIN_MIP_NEAR,"]},{"entry":[{},"GX_NEAR_MIP_LIN, GX_LIN_MIP_LIN."]},{"entry":["mag_filt","Filter mode to use when the texel\/pixel ratio is < 1.0."]},{"entry":[{},"Accepted values are: GX_NEAR, GX_LINEAR."]},{"entry":["min_lod","Minimum LOD value. The hardware will use"]},{"entry":[{},"MAX(min_lod, lod). Range is 0.0 to 10.0."]},{"entry":["max_lod","Maximum LOD value. The hardware will use"]},{"entry":[{},"MIN(max_lod, lod). Range is 0.0 to 10.0."]},{"entry":["lod_bias","Bias to add to computed LOD value."]},{"entry":["bias_clamp","If GX_ENABLE, clamp the (LOD + lod_bias) so that"]},{"entry":[{},"it is never less than the minimum extent of the pixel"]},{"entry":[{},"projected in texture space. Prevents over-biasing the"]},{"entry":[{},"LOD when the polygon is perpendicular to the view"]},{"entry":[{},"direction."]},{"entry":["do_edge_lod","Compute LOD using adjacent texels when GX_TRUE,"]},{"entry":[{},"else use diagonal texels."]},{"entry":["max_aniso","The maximum anisotropic filter to use."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Description","This function initializes a Texture Memory (TMEM) region object for preloading. The region is allocated in TMEM by the application and can be used only as a pre-loaded buffer. Cache regions must be allocated by using GXInitTexCacheRegion. For pre-loaded textures, the size of the region must match the size of the texture. An application can create many region objects and some of them can overlap; however, no two overlapping regions can be active at the same time.","The maximum size of a region is 512K.","GXInit creates no region for preloading. So the application should allocate appropriate regions if preloading is necessary. It is also required to create cache regions and its allocator by using GXInitTexCacheRegion and GXSetTexRegionCallBack because new regions may destroy the default texture memory configuration.",{"@attributes":{"id":"p-0118","num":"0164"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Arguments"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["region","Pointer to a GXTexRegion structure. The memory for this"]},{"entry":[{},"structure must be allocated by the application."]},{"entry":["tmem_even","Base pointer in Texture Memory for even LODs of a"]},{"entry":[{},"mipmap. Must be in the opposite bank relative to"]},{"entry":[{},"tmem_odd and aligned to 32 bytes."]},{"entry":["size_even","Size of the the even cache in bytes. The size should be a"]},{"entry":[{},"multiple of 32B (OSAlloc allocates memory in 32B"]},{"entry":[{},"chunks)."]},{"entry":["tmem_odd","Base pointer in Texture Memory for the odd LODs of a"]},{"entry":[{},"mipmap. Must be in the opposite bank relative to"]},{"entry":[{},"tmem_even and aligned to 32 bytes."]},{"entry":["size_odd",".Size of the the odd cache in bytes. The size should be a"]},{"entry":[{},"multiple of 32B (OSAlloc allocates memory in 32B"]},{"entry":[{},"chunks)."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"The following program fragment can be used to control the graphics pipeline to provide a cartoon outlining effect:",{"@attributes":{"id":"p-0120","num":"0166"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"266pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/---------------------------------------------------------------------------"},{"entry":"\/\/ Cartoon outline settings"},{"entry":"\/\/---------------------------------------------------------------------------"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["#define","ASFT(x)","((x) <<2)","\/\/ ID step size ( 6bit alpha )"]},{"entry":["#ifdef","EPPC"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"238pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["#define","GXInitTexRegionPreLoaded( region, is_32b_mipmap, tmem_even, tmem_odd"]},{"entry":")\\"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"GXInitTexRegion(","(region), GX_FALSE, (is_32b_mipmap), \\"]},{"entry":[{},{},"(tmem_even), 0, 0, (tmem_odd), 0, 0 )"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"266pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"\/\/ If exFB can be usable, Use exFB instead of this buffer"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"217pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["u16","alphaBuffer[SCREEN_WD*SCREEN_HT] ATTRIBUTE_ALIGN(32);"]},{"entry":["GXTexObj","eFBTexObj;"]},{"entry":["GXTexRegion","eFBTexRegion;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"266pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/*---------------------------------------------------------------------------"},{"entry":"*"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Draw Cartoon outline for HW"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"266pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"*---------------------------------------------------------------------------"},{"entry":"*\/"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["void","DrawCartoonOutline( void )"]},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"static s32 initialized = 0;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"238pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\/\/","CopyOut eFB as IA8 texture format"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"GXSetTexCopySrc( 0, 0, SCREEN_WD, SCREEN_HT );"]},{"entry":[{},"GXCopyTex( alphaBuffer, GX_TF_IA8, GX_DISABLE, GX_DISABLE );"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"238pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\/\/","Load the bitmap into TMEM"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"if ( !initialized )"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"GXInitTexObj(","&eFBTexObj, alphaBuffer, SCREEN_WD, SCREEN_HT,"]},{"entry":[{},{},"GX_TF_IA8, GX_CLAMP, GX_CLAMP, GX_DISABLE );"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"GXInitTexObjLOD(","&eFBTexObj, GX_NEAR, GX_NEAR, 0.0f, 0.0f, 0.0f,"]},{"entry":[{},{},"GX_DISABLE, GX_DISABLE, GX_ANISO_1 );"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"GXInitTexRegionPreLoaded(","&eFBTexRegion, GX_FALSE, 0, 0 );"]},{"entry":[{},"initialized = 1;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"}"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"GXLoadTexObjPreLoaded(","&eFBTexObj, &eFBTexRegion, GX_TEXMAP0 );"]},{"entry":[{},"return;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"266pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":"#else"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["u8","alphaBuffer[SCREEN_WD*SCREEN_HT];"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"266pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/*---------------------------------------------------------------------------"},{"entry":"*"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Draw Cartoon outline for OpenGL"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"266pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"*---------------------------------------------------------------------------"},{"entry":"*\/"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["void","DrawCartoonOutline( void )"]},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"231pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"u32","i;"]},{"entry":[{},"u8","a00, a01, a10, d01, d10;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\/\/ Read out pixel alpha"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"glReadPixels(","0, 0, SCREEN_WD, SCREEN_HT,"]},{"entry":[{},{},"GL_ALPHA, GL_UNSIGNED_BYTE, alphaBuffer );"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ Modify alpha"]},{"entry":[{},"for ( i = 0; i < SCREEN_WD*(SCREEN_HT\u22121); i ++ )"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"238pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"a01 = a00;"]},{"entry":[{},"a00 = alphaBuffer[i];"]},{"entry":[{},"a10 = alphaBuffer[i+SCREEN_WD];"]},{"entry":[{},"d01 = (u8) (a01 \u2212 a00 + ASFT(1));"]},{"entry":[{},"d10 = (u8) (a10 \u2212 a00 + ASFT(1));"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"if ( d01 > ASFT(2) || d10 > ASFT(2) )","alphaBuffer[i] = 0x00;"]},{"entry":[{},"else","alphaBuffer[i] = 0xff;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"\/\/ Write back alpha as blend parameter"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"glBlendFunc","(","GL_ZERO, GL_SRC_ALPHA );"]},{"entry":[{},"glAlphaFunc","(","GL_ALWAYS, 0.0f );"]},{"entry":[{},"glViewport","(","0, 0, SCREEN_WD, SCREEN_HT );"]},{"entry":[{},"glScissor","(","0, 0, SCREEN_WD, SCREEN_HT );"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"glDrawPixels","(","SCREEN_WD, SCREEN_HT,"]},{"entry":[{},{},{},"GL_ALPHA, GL_UNSIGNED_BYTE, alphaBuffer );"]},{"entry":[{},"return;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"266pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":"#endif"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Certain of the above-described system components  could be implemented as other than the home video game console configuration described above. For example, one could run graphics application or other software written for system  on a platform with a different configuration that emulates system  or is otherwise compatible with it. If the other platform can successfully emulate, simulate and\/or provide some or all of the hardware and software resources of system , then the other platform will be able to successfully execute the software.","As one example, an emulator may provide a hardware and\/or software configuration (platform) that is different from the hardware and\/or software configuration (platform) of system . The emulator system might include software and\/or hardware components that emulate or simulate some or all of hardware and\/or software components of the system for which the application software was written. For example, the emulator system could comprise a general purpose digital computer such as a personal computer, which executes a software emulator program that simulates the hardware and\/or firmware of system .","Some general purpose digital computers (e.g., IBM or MacIntosh personal computers and compatibles) are now equipped with 3D graphics cards that provide 3D graphics pipelines compliant with DirectX or other standard 3D graphics command APIs. They may also be equipped with stereophonic sound cards that provide high quality stereophonic sound based on a standard set of sound commands. Such multimedia-hardware-equipped personal computers running emulator software may have sufficient performance to approximate the graphics and sound performance of system . Emulator software controls the hardware resources on the personal computer platform to simulate the processing, 3D graphics, sound, peripheral and other capabilities of the home video game console platform for which the game programmer wrote the game software.",{"@attributes":{"id":"p-0124","num":"0170"},"figref":"FIG. 21A","b":["1201","1303","62","1201","1303","1201","62","1201","1303","50","62","1201"]},"As one example, in the case where the software is written for execution on a platform using an IBM PowerPC or other specific processor and the host  is a personal computer using a different (e.g., Intel) processor, emulator  fetches one or a sequence of binary-image program instructions from storage medium  and converts these program instructions to one or more equivalent Intel binary-image program instructions. The emulator  also fetches and\/or generates graphics commands and audio commands intended for processing by the graphics and audio processor , and converts these commands into a format or formats that can be processed by hardware and\/or software graphics and audio processing resources available on host . As one example, emulator  may convert these commands into commands that can be processed by specific graphics and\/or or sound hardware of the host  (e.g., using standard DirectX, OpenGL and\/or sound APIs).","An emulator  or other platform implementing the  outlining process might not have a recirculating shader, but might instead implement the alpha compare operation using a pipeline of discrete shading\/blending stages. Similarly, an alternative implementation might not store alpha and color information in the same frame buffer, but might instead store this information in different frame buffers. For example, the alpha \u201cimage\u201d providing object Ids might be stored as a map in main memory. Post processing need not be performed through use of texturing, but could be performed instead by a general purpose processor. Rendering outlines in two passes might not be needed; some implementations might render both horizontal and vertical outlines in the same pass.","An emulator  used to provide some or all of the features of the video game system described above may also be provided with a graphic user interface (GUI) that simplifies or automates the selection of various options and screen modes for games run using the emulator. In one example, such an emulator  may further include enhanced functionality as compared with the host platform for which the software was originally intended.",{"@attributes":{"id":"p-0128","num":"0174"},"figref":"FIG. 21B","b":["1201","1303","1201","1203","1205","1207","1205","1203","1207","1207","1252","1254","1256","1201","1252","1201","1209","1211","1213","1215","1217","1219","1209","1217","1207","1221","1225","1201"]},"A number of program modules including emulator  may be stored on the hard disk , removable magnetic disk , optical disk  and\/or the ROM  and\/or the RAM  of system memory . Such program modules may include an operating system providing graphics and sound APIs, one or more application programs, other program modules, program data and game data. A user may enter commands and information into personal computer system  through input devices such as a keyboard , pointing device , microphones, joysticks, game controllers, satellite dishes, scanners, or the like. These and other input devices can be connected to processing unit  through a serial port interface  that is coupled to system bus , but may be connected by other interfaces, such as a parallel port, game port Fire wire bus or a universal serial bus (USB). A monitor  or other type of display device is also connected to system bus  via an interface, such as a video adapter .","System  may also include a modem  or other network interface means for establishing communications over a network  such as the Internet. Modem , which may be internal or external, is connected to system bus  via serial port interface . A network interface  may also be provided for allowing system  to communicate with a remote computing device  (e.g., another system ) via a local area network  (or such communication may be via wide area network  or other communications path such as dial-up or other communications means). System  will typically include other peripheral output devices, such as printers and other standard peripheral devices.","In one example, video adapter  may include a 3D graphics pipeline chip set providing fast 3D graphics rendering in response to 3D graphics commands issued based on a standard 3D graphics application programmer interface such as Microsoft's DirectX 7.0 or other version. A set of stereo loudspeakers  is also connected to system bus  via a sound generating interface such as a conventional \u201csound card\u201d providing hardware and embedded software support for generating high quality stereophonic sound based on sound commands provided by bus . These hardware capabilities allow system  to provide sufficient graphics and sound speed performance to play software stored in storage medium .","The entire contents of all patents, patent applications and other documents referenced above are expressly incorporated herein.","While the invention has been described in connection with what is presently considered to be the most practical and preferred embodiment, it is to be understood that the invention is not to be limited to the disclosed embodiment. For example, although the object of the illustrated embodiment is to provide images with cartoon outlining, the flexible alpha compare operation described herein can be used for a number of different imaging applications. Furthermore, while dual alpha comparisons are described above, the present invention is not limited to just two alpha comparisons. Additionally, while the preferred embodiment uses a recirculating shader, a parallel arrangement having plural alpha comparators could be used. Accordingly, the invention is intended to cover various modifications and equivalent arrangements included within the scope of the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["These and other features and advantages provided by the invention will be better and more completely understood by referring to the following detailed description of presently preferred embodiments in conjunction with the drawings, of which:",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 5","FIG. 4"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIGS. 12A and 12B"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIGS. 13\u201318C"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 19","b":"50"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 20","b":"50"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIGS. 21A and 21B"}]},"DETDESC":[{},{}]}
