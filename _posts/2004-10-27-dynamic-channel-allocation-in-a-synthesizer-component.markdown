---
title: Dynamic channel allocation in a synthesizer component
abstract: An audio generation system receives audio instructions that have instruction channel designations and dynamically allocates synthesizer channels in groups of sixteen channels that support the MIDI standard to receive the audio instructions. The synthesizer channels are assigned to receive the audio instructions such that audio instructions having the same instruction channel designations are assigned to be received by synthesizer channels in different synthesizer channel groups. The audio instructions are routed to the synthesizer channels in accordance with the instruction channel designations of the audio instructions and the synthesizer channel assignments via mapping channels in a mapping component, where an individual mapping channel corresponds to a particular synthesizer channel.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07005572&OS=07005572&RS=07005572
owner: Microsoft Corporation
number: 07005572
owner_city: Redmond
owner_country: US
publication_date: 20041027
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","CONCLUSION"],"p":["This application is a continuation of U.S. patent application Ser. No. 09\/802,323 entitled \u201cDynamic Channel Allocation in a Synthesizer Component\u201d filed Mar. 7, 2001 U.S. Pat. No. 6,806,412, to Fay, and claims priority to each of (1) U.S. patent application Ser. No. 09\/802,323, and to copending applications (2) U.S. patent application Ser. No. 09\/801,922 entitled \u201cAudio Generation System Manager\u201d filed Mar. 7, 2001, to Fay et al.; (3) U.S. patent application Ser. No. 09\/802,111 entitled \u201cSynthesizer Multi-Bus Component\u201d filed Mar. 7, 2001, to Fay et al.; and (4) U.S. patent application Ser. No. 09\/801,938 entitled \u201cAccessing Audio Processing Components in an Audio Generation System\u201d, filed Mar. 7, 2001, to Fay et al., the disclosures of which are all incorporated by reference herein.","This invention relates to audio processing and, in particular, to dynamic channel allocation in a synthesizer component.","Multimedia programs present data to a user through both audio and video events while a user interacts with a program via a keyboard, joystick, or other interactive input device. A user associates elements and occurrences of a video presentation with the associated audio representation. A common implementation is to associate audio with movement of characters or objects in a video game. When a new character or object appears, the audio associated with that entity is incorporated into the overall presentation for a more dynamic representation of the video presentation.","Audio representation is an essential component of electronic and multimedia products such as computer based and stand-alone video games, computer-based slide show presentations, computer animation, and other similar products and applications. As a result, audio generating devices and components are integrated with electronic and multimedia products for composing and providing graphically associated audio representations. These audio representations can be dynamically generated and varied in response to various input parameters, real-time events, and conditions. Thus, a user can experience the sensation of live audio or musical accompaniment with a multimedia experience.","Conventionally, computer audio is produced in one of two fundamentally different ways. One way is to reproduce an audio waveform from a digital sample of an audio source which is typically stored in a wave file (i.e., a .wav file). A digital sample can reproduce any sound, and the output is very similar on all sound cards, or similar computer audio rendering devices. However, a file of digital samples consumes a substantial amount of memory and resources for streaming the audio content. As a result, the variety of audio samples that can be provided using this approach is limited. Another disadvantage of this approach is that the stored digital samples cannot be easily varied.","Another way to produce computer audio is to synthesize musical instrument sounds, typically in response to instructions in a Musical Instrument Digital Interface (MIDI) file. MIDI is a protocol for recording and playing back music and audio on digital synthesizers incorporated with computer sound cards. Rather than representing musical sound directly, MIDI transmits information and instructions about how music is produced. The MIDI command set includes note-on, note-off, key velocity, pitch bend, and other methods of controlling a synthesizer.","The audio sound waves produced with a synthesizer are those already stored in a wavetable in the receiving instrument or sound card. A wavetable is a table of stored sound waves that are digitized samples of actual recorded sound. A wavetable can be stored in read-only memory (ROM) on a sound card chip, or provided with software. Prestoring sound waveforms in a lookup table improves rendered audio quality and throughput. An advantage of MIDI files is that they are compact and require few audio streaming resources, but the output is limited to the number of instruments available in the designated General MIDI set and in the synthesizer, and may sound very different on different computer systems.","MIDI instructions sent from one device to another indicate actions to be taken by the controlled device, such as identifying a musical instrument (e.g., piano, flute, drums, etc.) for music generation, turning on a note, and\/or altering a parameter in order to generate or control a sound. In this way, MIDI instructions control the generation of sound by remote instruments without the MIDI control instructions carrying sound or digitized information. A MIDI sequencer stores, edits, and coordinates the MIDI information and instructions. A synthesizer connected to a sequencer generates audio based on the MIDI information and instructions received from the sequencer. Many sounds and sound effects are a combination of multiple simple sounds generated in response to the MIDI instructions.","A MIDI system allows audio and music to be represented with only a few digital samples rather than converting an analog signal to many digital samples. The MIDI standard supports different channels that can each simultaneously provide an output of audio sound wave data. There are sixteen defined MIDI channels, meaning that no more than sixteen instruments can be playing at one time. Typically, the command input for each channel represents the notes corresponding to an instrument. However, MIDI instructions can program a channel to be a particular instrument. Once programmed, the note instructions for a channel will be played or recorded as the instrument for which the channel has been programmed. During a particular piece of music, a channel can be dynamically reprogrammed to be a different instrument.","A Downloadable Sounds (DLS) standard published by the MIDI Manufacturers Association allows wavetable synthesis to be based on digital samples of audio content provided at run time rather than stored in memory. The data describing an instrument can be downloaded to a synthesizer and then played like any other MIDI instrument. Because DLS data can be distributed as part of an application, developers can be sure that the audio content will be delivered uniformly on all computer systems. Moreover, developers are not limited in their choice of instruments.","A DLS instrument is created from one or more digital samples, typically representing single pitches, which are then modified by a synthesizer to create other pitches. Multiple samples are used to make an instrument sound realistic over a wide range of pitches. DLS instruments respond to MIDI instructions and commands just like other MIDI instruments. However, a DLS instrument does not have to belong to the General MIDI set or represent a musical instrument at all. Any sound, such as a fragment of speech or a fully composed measure of music, can be associated with a DLS instrument.","Conventional Audio and Music System",{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1","b":["100","102","104","106","102","108","1","16","102"]},"A MIDI instruction, such as a \u201cnote-on\u201d, directs a synthesizer  to play a particular note, or notes, on a synthesizer channel  having a designated instrument. The General MIDI standard defines standard sounds that can be combined and mapped into the sixteen separate instrument and sound channels. A MIDI event on a synthesizer channel corresponds to a particular sound and can represent a keyboard key stroke, for example. The \u201cnote-on\u201d MIDI instruction can be generated with a keyboard when a key is pressed and the \u201cnote-on\u201d instruction is sent to synthesizer . When the key on the keyboard is released, a corresponding \u201cnote-off\u201d instruction is sent to stop the generation of the sound corresponding to the keyboard key.","A MIDI input is typically a serial data stream that is parsed in the synthesizer into MIDI commands and synthesizer control information. A MIDI command or instruction is represented as a data structure containing information about the sound effect or music piece such as the pitch, relative volume, duration, and the like. The output of a synthesizer channel  is a sound waveform that is mixed and input to a buffer (not shown). A buffer in this instance is typically an allocated area of memory that temporarily holds sequential samples of audio wave data that will be subsequently delivered to a sound card or similar audio rendering device to produce audible sound.","The MIDI input  has a sound effect instruction  to generate a dog bark sound on MIDI channel  in synthesizer . The MIDI input  is a music piece having instructions (\u2013) to generate musical instrument sounds. Instruction () designates that a flute sound be generated on MIDI channel , instruction () designates that a horn sound be generated on MIDI channel , and instruction () designates that drums be generated on MIDI channel  in synthesizer .","The MIDI channel assignments are designated when the MIDI inputs  and  are authored, or created. The limited number of available MIDI channels in a synthesizer results in the problem of one input overriding and canceling out another input, or the problem of overlapping content when playing back the designated sounds of MIDI inputs. For example, channel () in synthesizer  receives two inputs at the same time\u2014instruction  to generate the dog bark sound effect and instruction () to generate a flute sound. The synthesizer  might first receive the flute instruction (), then the dog bark instruction  which overrides the first input, and then an associated flute instruction to play a particular note. The undesirable output is a flute note that is played as a dog bark.","A conventional software synthesizer that translates MIDI instructions into audio signals does not support distinctly separate sets of MIDI channels. The number of sounds that can be played simultaneously is limited by the number of channels and resources available in the synthesizer. In the event that there are more MIDI inputs than there are available channels and resources, one or more inputs are suppressed by the synthesizer.","Another problem with having only a limited number of synthesizer channels is that content intended to be played multiple times for the same sound effect, such as two dogs barking, cannot be faded one over the other. A pre-authored dog bark sound effect is assigned to a designated MIDI channel, as with input , for example. Rather than being able to play two distinct dog barks from the same source at or near the same time, two instances of the sound effect will be input to synthesizer channel  and only one dog bark will be rendered as audible sound at one time. This also precludes initiating two of the same sound effect and fading one over the other.","An audio generation system receives audio instructions that have instruction channel designations. The audio instructions are formatted as MIDI instructions and have MIDI channel designations that designate MIDI channels from the pre-defined range of sixteen MIDI channels.","A synthesizer component has dynamically allocated synthesizer channels that receive the audio instructions. The synthesizer channels are allocated in channel groups of sixteen channels that support the MIDI standard. The synthesizer channels are assigned to receive the audio instructions such that audio instructions having the same instruction channel designation are assigned to be received by synthesizer channels in different synthesizer channel groups.","A mapping component has dynamically allocated channel blocks that correspond to the synthesizer channel groups, and the channel blocks each have sixteen mapping channels that also support the MIDI standard. A mapping channel in a channel block corresponds to a synthesizer channel in the synthesizer channel group that corresponds to the mapping component channel block.","The audio instructions are routed to the synthesizer channels in accordance with the instruction channel designations of the audio instructions and the synthesizer channel assignments. Audio instructions are routed to a synthesizer channel via the corresponding mapping channel in the mapping component.","The following describes systems and methods to receive and independently process MIDI inputs in a synthesizer when more than one of the inputs designate the same synthesizer channel, or when more than the standard sixteen MIDI channels are needed to receive multiple MIDI inputs. Groups of sixteen synthesizer channels are dynamically allocated as needed to avoid overlapping channel inputs.","Exemplary Audio Generation System",{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 2","b":["200","200"]},"Audio generation system  includes an application program , audio sources , and an audio processing system . Application program  is one of a variety of different types of applications, such as a video game program, some other type of entertainment program, or an application that incorporates an audio representation with a video presentation.","Audio sources  provide digital samples of audio data such as from a wave file (i.e., a .wav file), message-based data such as from a MIDI file or a pre-authored segment file, or an audio sample such as a Downloadable Sound (DLS). Although not shown, the audio sources  can be stored and incorporated in the application program  as a resource rather than in a separate file.","Application program  initiates that an audio source  provide input to the audio processing system . The application program  interfaces with the audio processing system  and the other components of the audio generation system  via application programming interfaces (APIs). The various components described herein are implemented using standard programming techniques, including the use of OLE (object linking and embedding) and COM (component object model) interfaces. COM objects are implemented in a system memory of a computing device, each object having one or more interfaces, and each interface having one or more methods. The interfaces and interface methods can be called by application programs and by other objects. The interface methods of the objects are executed by a processing unit of the computing device. Familiarity with object-based programming, and with COM objects in particular, is assumed throughout this disclosure. However, those skilled in the art will recognize that the audio generation systems and the various components described herein are not limited to a COM and\/or OLE implementation, or to any other specific programming technique.","The audio generation system  also includes a mapping component , a synthesizer component , and audio rendering components . The audio processing system  produces audio instructions for input to the audio generation system components. For example, the audio processing system produces MIDI instructions that are formatted for input to synthesizer component . Additional information regarding the audio data processing components described herein can be found in the concurrently-filed U.S. Patent Application entitled \u201cAudio Generation System Manager\u201d, which is incorporated by reference above. However, any audio processing system can be used to produce audio instructions for input to the audio generation system components.","Mapping component  maps MIDI instructions from the audio processing system  to the synthesizer component . The mapping component can be implemented in hardware or software, and although not shown, can be integrated with the audio processing system . The mapping component allows MIDI instructions from multiple sources (e.g., multiple audio sources , or multiple audio processing systems ) to be input to one or more synthesizer components .","Synthesizer component  receives MIDI instructions from audio processing system  via the mapping component . The synthesizer component  can also use the sampling technologies described, or algorithmic technologies such as FM or physical modeling synthesis. The form of the input source to synthesizer component  does not limit the scope of dynamic synthesizer channel allocation. The synthesizer component  generates sound waveforms from stored wavetable data in accordance with the received MIDI instructions. The sound waveforms are input to the audio rendering components  which are hardware and\/or software components, such as a speaker or soundcard, that renders audio from the audio sound wave data. Additional information regarding the audio data processing components described herein can be found in the concurrently-filed U.S. Patent Application entitled \u201cSynthesizer Multi-Bus Component\u201d, which is incorporated by reference above.","Exemplary Synthesizer and Mapping Component",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 3","FIG. 3","FIG. 4"],"b":["208","210","302","304","302","306","1","3","1","2","4","304","308","1","4","1","2","3","10","208","306","1","3","308","1","4","210","208"]},"Synthesizer component  has two channel groups () and (), each having sixteen MIDI channels (\u2013) and (\u2013), respectively. Those skilled in the art will recognize that a group of sixteen MIDI channels can be identified as channels zero through fifteen (\u2013). For consistency and explanation clarity, groups of sixteen MIDI channels described herein are designated one through sixteen (\u2013).","To support the MIDI standard, and at the same time make more MIDI channels available in a synthesizer  to receive MIDI inputs, channel groups  are dynamically created as needed. Up to 65,536 channel groups, each containing sixteen channels, can be created and can exist at any one time for a total of over one million channels in a synthesizer component . The MIDI channels are dynamically allocated for one or more synthesizers to receive multiple inputs. The multiple inputs can then be processed at the same time without channel overlapping and without channel clashing.","The two sources in , MIDI inputs  and , have MIDI channel designations that designate the same MIDI channel. For example, both sources have audio instructions (\u2013) and (\u2013) that designate MIDI channels  and . When the mapping component  receives audio instructions from one or more sources that designate the same MIDI channel, the audio instructions are routed to a synthesizer channel  or  in different channel groups () or (), respectively.","In this instance, mapping component  receives the audio instructions  from the first source, MIDI input , and routes the audio instructions to synthesizer channels  in the first channel group (). That is, audio instruction () which designates MIDI channel  is routed to synthesizer channel (), audio instruction () which designates MIDI channel  is routed to synthesizer channel (), and audio instruction () which designates MIDI channel  is routed to synthesizer channel ().","When the mapping component  receives the audio instructions  from the second source, MIDI input , the mapping component routes the audio instructions to synthesizer channels  in the first channel group () that are not currently in use, and to synthesizer channels  in the second channel group (). That is, audio instruction () which designates MIDI channel  is routed to synthesizer channel () in the second channel group () because the first MIDI channel () in the first channel group () already has an input from the first source audio instruction (). Similarly, audio instruction () which designates MIDI channel  is routed to synthesizer channel () in the second channel group ().","The mapping component  routes audio instruction () from the second source, which designates MIDI channel , to synthesizer channel () in the first channel group () because the channel is available and not currently in use. Similarly, audio instruction () which designates MIDI channel  is routed to synthesizer channel () in the first channel group ().",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 4","FIG. 3"],"b":["208","210","316","210","310","1","310","2","312","1","16","314","1","16","316","318","320","320","316","314","210","310","1","210"]},"The mapping component  has three channel blocks (\u2013), each having sixteen audio instruction channels that are mapping channels to receive audio instructions from input sources and route the audio instructions to the synthesizer components  and . The first channel block () has channels (\u2013), the second channel block () has channels (\u2013), and the third channel block () has channels (\u2013). The channel blocks  are dynamically created as needed to receive audio instructions from input sources. The channel blocks each have sixteen channels to support the MIDI standard and the channels are identified sequentially. For example, the first channel block () has channels \u2013, the second channel block () has channels \u2013, and the third channel block () has channels \u2013.","Each channel block  corresponds to a synthesizer channel group, and each mapping channel in a channel block maps directly to a synthesizer channel in the synthesizer channel group. For example, the first channel block () corresponds to the first channel group () in synthesizer component . Each mapping channel (\u2013) in the first channel block () corresponds to each of the sixteen synthesizer channels (\u2013) in channel group (). Additionally, channel block () corresponds to the second channel group () in the first synthesizer component , and each mapping channel (\u2013) corresponds to synthesizer channels (\u2013). Channel block () corresponds to the first channel group  in the second synthesizer component , and each mapping channel (\u2013) corresponds to synthesizer channels (\u2013), respectively.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 5","b":["500","208","500","502","1","502"]},"For example, the first mapping () associates the first channel block () () of mapping component , and the first mapping channel () of the first channel block (), with the first synthesizer component , the first channel group () in synthesizer , and the first synthesizer channel () in the first channel group (). Those skilled in the art will recognize that various techniques are available to implement the mapping list  as a data structure.","Mapping component  allows multiple sources to share available synthesizer channels, and dynamically allocating synthesizer channels allows multiple source inputs at any one time. For example, the first source, MIDI input  (), only designates three MIDI channels , , and  in the audio instructions (\u2013). These are mapped to the first channel group () in the first synthesizer component  via the first channel block () in mapping component . When the second source, MIDI input , is received, the mapping component  recognizes that only three of the sixteen mapping channels  in the first channel block () are in use. Thus, the mapping component also maps audio instructions () and (), which designate MIDI channels  and , respectively, to the first channel group () in the first synthesizer component  via the first channel block ().","When particular synthesizer channels are no longer needed to receive MIDI inputs, the resources allocated to create the synthesizer channels are released as well as the channel group containing the synthesizer channels. Similarly, when unused synthesizer channels are released, the resources allocated to create the channel block corresponding to the synthesizer channel group are released to conserve resources.","Mapping component  can allocate a channel block with a broadcast channel to designate that all audio instructions received from a particular source will be processed together according to the broadcast channel instruction. For example, mapping channel () in the first channel block () can be designated as a broadcast channel having a volume fade instruction that will auto-fade the volume of every instruction received on the mapping channels (\u2013) in channel block (). Additionally, an audio instruction can be received at the mapping component  that designates that all audio channels associated with a particular source be processed according to the broadcast channel instruction. That is, all of the mapping channels in all of the channel blocks will be processed with the same instruction.","File Format and Component Instantiation","The mapping component  and a synthesizer component, such as synthesizer , can be implemented as a programming object. Configuration information for mapping component  and synthesizer component  is stored in a file format such as the Resource Interchange File Format (RIFF). A RIFF file includes a file header that contains data describing the object followed by what are known as \u201cchunks.\u201d Each of the chunks following a file header corresponds to a data item that describes the object, and each chunk consists of a chunk header followed by actual chunk data. A chunk header specifies an object class identifier (CLSID) that can be used for creating an instance of the object. Chunk data consists of the data to define the corresponding data item.","A RIFF file for the mapping component  and synthesizer component  has configuration information that includes identifying the synthesizer technology designated by source input audio instructions. An audio source can be designed to play on more than one synthesis technology. For example, a hardware synthesizer can be designated by some audio instructions from a particular source, for performing certain musical instruments for example, while a wavetable synthesizer in software can be designated by the remaining audio instructions for the source.","The configuration information also includes identifying whether a synthesizer channel  will be designated as a drums channel. Typically, MIDI devices such as synthesizer  designate MIDI channel  for drum instruments that map on to it. However, some MIDI devices do not. The mapping component  identifies whether a synthesizer channel  in a particular channel group will be designated for drum instruments when instantiated. The configuration information also includes a configuration list such as mapping list  that contains the information to allocate and map audio instruction input channels to synthesizer channels.","The mapping and synthesizer component configurations support COM interfaces for reading and loading the configuration data from a file. To instantiate a mapping component  or a synthesizer component , an application program  first instantiates a component using a COM function. The application program then calls a load method for a mapping object or a synthesizer object, and specifies a RIFF file stream. The object parses the RIFF file stream and extracts header information. When it reads individual chunks, it creates synthesizer channel group objects and corresponding channel objects, and mapping channel blocks and corresponding channel objects based on the chunk header information. However, those skilled in the art will recognize that the audio generation systems and the various components described herein are not limited to a COM implementation, or to any other specific programming technique.","Methods Pertaining to an Exemplary Audio Generation System",{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIG. 6","FIGS. 2\u20135"]},"At block , a synthesizer component is provided. For example, the synthesizer component can be instantiated from a synthesizer configuration file format (e.g., a RIFF file as described above) as a programming object having an interface that is callable by a software component to receive audio instructions. Alternatively, a synthesizer component can be created from a file representation that is loaded and stored in a synthesizer configuration object that maintains the synthesizer configuration information.","At block , a mapping component is provided. For example, the mapping component can be instantiated from a mapping component configuration file format (e.g., a RIFF file) as a programming object having an interface that is callable by a software component to route audio instructions to a synthesizer component. Alternatively, a mapping component can be created from a file representation that is loaded and stored in a configuration object that maintains configuration information for a mapping component.","At block , audio instructions are received from one or more sources. The audio instructions have instruction channel designations to indicate a routing destination for the audio instructions. For example, the audio instructions are MIDI instructions that have MIDI channel designations. A MIDI channel designation indicates a MIDI channel from a pre-defined range of sixteen channels in accordance with the MIDI standard.","At block , synthesizer channel groups are dynamically allocated for the synthesizer component, and each channel group has sixteen synthesizer channels that support the MIDI standard. The synthesizer channel groups are allocated as needed to receive the audio instructions. If the audio instructions have instruction channel designations that designate the same instruction channel, channel groups and synthesizer channels are allocated to receive the audio instructions on different synthesizer channels.","At block , channel blocks are dynamically allocated in the mapping component, and each channel block has sixteen mapping channels. The channel blocks are allocated as needed and correspond to the synthesizer channel groups. A mapping channel in a channel block corresponds to a synthesizer channel in a synthesizer channel group. At block , a mapping list is created, such as the mapping channel block-to-synthesizer channel group mapping list , to indicate which channel block channels correspond to which synthesizer channels.","At block , synthesizer channels are assigned to receive the audio instructions corresponding to the respective instruction channel designations. The audio instructions that designate the same instruction channel are assigned to different synthesizer channels. At block , the audio instructions are routed to the synthesizer channels in accordance with the instruction channel designations of the audio instructions and the synthesizer channel assignments. The audio instructions are routed to the synthesizer channels via the corresponding mapping channels in the mapping component.","Exemplary Computing System and Environment",{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 7","b":["700","700","700","700"]},"The computer and network architectures can be implemented with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use include, but are not limited to, personal computers, server computers, thin clients, thick clients, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, gaming consoles, distributed computing environments that include any of the above systems or devices, and the like.","Dynamically allocated synthesizer channels and the mapping component described herein may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. The invention described herein may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote computer storage media including memory storage devices.","The computing environment  includes a general-purpose computing system in the form of a computer . The components of computer  can include, by are not limited to, one or more processors or processing units , a system memory , and a system bus  that couples various system components including the processor  to the system memory .","The system bus  represents one or more of any of several types of bus structures, including a memory bus or memory controller, a peripheral bus, an accelerated graphics port, and a processor or local bus using any of a variety of bus architectures. By way of example, such architectures can include an Industry Standard Architecture (ISA) bus, a Micro Channel Architecture (MCA) bus, an Enhanced ISA (EISA) bus, a Video Electronics Standards Association (VESA) local bus, and a Peripheral Component Interconnects (PCI) bus also known as a Mezzanine bus.","Computer system  typically includes a variety of computer readable media. Such media can be any available media that is accessible by computer  and includes both volatile and non-volatile media, removable and non-removable media. The system memory  includes computer readable media in the form of volatile memory, such as random access memory (RAM) , and\/or non-volatile memory, such as read only memory (ROM) . A basic input\/output system (BIOS) , containing the basic routines that help to transfer information between elements within computer , such as during start-up, is stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently operated on by the processing unit .","Computer  can also include other removable\/non-removable, volatile\/non-volatile computer storage media. By way of example,  illustrates a hard disk drive  for reading from and writing to a non-removable, non-volatile magnetic media (not shown), a magnetic disk drive  for reading from and writing to a removable, non-volatile magnetic disk  (e.g., a \u201cfloppy disk\u201d), and an optical disk drive  for reading from and\/or writing to a removable, non-volatile optical disk  such as a CD-ROM, DVD-ROM, or other optical media. The hard disk drive , magnetic disk drive , and optical disk drive  are each connected to the system bus  by one or more data media interfaces . Alternatively, the hard disk drive , magnetic disk drive , and optical disk drive  can be connected to the system bus  by a SCSI interface (not shown).","The disk drives and their associated computer-readable media provide non-volatile storage of computer readable instructions, data structures, program modules, and other data for computer . Although the example illustrates a hard disk , a removable magnetic disk , and a removable optical disk , it is to be appreciated that other types of computer readable media which can store data that is accessible by a computer, such as magnetic cassettes or other magnetic storage devices, flash memory cards, CD-ROM, digital versatile disks (DVD) or other optical storage, random access memories (RAM), read only memories (ROM), electrically erasable programmable read-only memory (EEPROM), and the like, can also be utilized to implement the exemplary computing system and environment.","Any number of program modules can be stored on the hard disk , magnetic disk , optical disk , ROM , and\/or RAM , including by way of example, an operating system , one or more application programs , other program modules , and program data . Each of such operating system , one or more application programs , other program modules , and program data  (or some combination thereof) may include an embodiment of a synthesizer having dynamically allocated channels and the mapping component described herein.","Computer system  can include a variety of computer readable media identified as communication media. Communication media typically embodies computer readable instructions, data structures, program modules, or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared, and other wireless media. Combinations of any of the above are also included within the scope of computer readable media.","A user can enter commands and information into computer system  via input devices such as a keyboard  and a pointing device  (e.g., a \u201cmouse\u201d). Other input devices  (not shown specifically) may include a microphone, joystick, game pad, satellite dish, serial port, scanner, and\/or the like. These and other input devices are connected to the processing unit  via input\/output interfaces  that are coupled to the system bus , but may be connected by other interface and bus structures, such as a parallel port, game port, or a universal serial bus (USB).","A monitor  or other type of display device can also be connected to the system bus  via an interface, such as a video adapter . In addition to the monitor , other output peripheral devices can include components such as speakers (not shown) and a printer  which can be connected to computer  via the input\/output interfaces .","Computer  can operate in a networked environment using logical connections to one or more remote computers, such as a remote computing device . By way of example, the remote computing device  can be a personal computer, portable computer, a server, a router, a network computer, a peer device or other common network node, and the like. The remote computing device  is illustrated as a portable computer that can include many or all of the elements and features described herein relative to computer system .","Logical connections between computer  and the remote computer  are depicted as a local area network (LAN)  and a general wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet. When implemented in a LAN networking environment, the computer  is connected to a local network  via a network interface or adapter . When implemented in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the wide network . The modem , which can be internal or external to computer , can be connected to the system bus  via the input\/output interfaces  or other appropriate mechanisms. It is to be appreciated that the illustrated network connections are exemplary and that other means of establishing communication link(s) between the computers  and  can be employed.","In a networked environment, such as that illustrated with computing environment , program modules depicted relative to the computer , or portions thereof, may be stored in a remote memory storage device. By way of example, remote application programs  reside on a memory device of remote computer . For purposes of illustration, application programs and other executable program components, such as the operating system, are illustrated herein as discrete blocks, although it is recognized that such programs and components reside at various times in different storage components of the computer system , and are executed by the data processor(s) of the computer.","The dynamic allocation of MIDI channels for one or more synthesizers allows the synthesizers to receive multiple MIDI channel inputs and avoid overlapping channel inputs. Additionally, the mapping component allows multiple MIDI channel inputs to share available synthesizer channels, thereby conserving system resources.","Although the systems and methods have been described in language specific to structural features and\/or methods, it is to be understood that the subject matter in the appended claims is not necessarily limited to the specific features or methods described. Rather, the specific features and methods are disclosed as exemplary implementations of dynamic channel allocation in a synthesizer component."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The same numbers are used throughout the drawings to reference like features and components.",{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 4","FIG. 2"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 5","FIG. 4"]},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
