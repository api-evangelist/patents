---
title: Dynamic gamut mapping selection
abstract: The present invention is directed to a mechanism of dynamically selecting a gamut mapping component for use in a color management system which transforms colors specified in image data from a first color space to a second color space, the method comprising automatically generating prediction information for use in selecting from a plurality of gamut mapping components, wherein the prediction information is based on determined gamut mapping preferences corresponding to at least one characteristic of the image data, and automatically selecting at least one of the plurality of gamut mapping components based on the prediction information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06947589&OS=06947589&RS=06947589
owner: Canon Kabushiki Kaisha
number: 06947589
owner_city: Tokyo
owner_country: JP
publication_date: 20010920
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["1. Field of the Invention","The present invention relates to the dynamic selection of a gamut mapping component of a color management system, and more particularly, to dynamic gamut mapping selection based on characteristics of image data and predictions with regard to a suitable GMA, the predictions based on determined preferences corresponding to the characteristics.","2. Description of the Related Art","A color device processes a color image using the range of colors that are available to it. Unfortunately, the same range of colors are not available across color devices. A color device typically uses a color management system, or module, to transform colors from one color space (e.g., RGB or CMYK) to another. Transformation of color image data into a device's color space typically entails the use of a gamut mapping algorithm (GMA) that maps the colors of an image to the gamut of colors of the color device.","Since it is not often the case that all of the colors of an image are reproducible within a color output device's gamut of colors, a color management system uses a GMA to transform each of the original colors in the device's color space to an appearance space. In addition to transforming the colors of a device's gamut of colors, the color management system usually transforms the colors into the output device's color space. These transformations of colors are ordinarily given in the form of mathematical expressions or as look-up tables.","In one example of a color management system, a CreateTransform program module is used to produce a color transform that includes color space and gamut transformations. The CreateTransform module normally takes as input a list of color device characterizations, called profiles. The GMA is contained in the output device's color profile. The color transform which is produced by CreateTransform becomes input to a TransformColors program module that operates on the input color data using the color transform. A FreeTransform program module returns system resources, such as memory, to the system and is executed once the transform is no longer needed.",{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},"Input device  may be, for example, a color scanner which uses the RGB (Red, Green and Blue) color space. In the example, output device , which may be a color printer, uses a different color space such as the CMYK (Cyan, Magenta, Yellow and Black) color space. Image data generated by input device  using the RGB color space must be converted to CMYK color space for use by output device . In addition, those colors in the image data that are not able to be represented in the gamut of colors of output device  must be converted to the gamut of output device .","Blocks  to  illustrate a transformation pipeline that is used to perform the color space and gamut transformations. In block , the color data received from input device  is converted to a color appearance space, or a device-independent color space, such as CIELab. Block  performs gamut mapping from the gamut of input device  to the gamut of output device  using a GMA. Thereafter, the color data is converted from color appearance space to the color space of output device . Output device  can then generate output using the color data.","Block  uses a GMA to perform the gamut mapping, and the same GMA is used to transform an input image regardless of the image. Ideally, one GMA would be able to produce high quality output regardless of the image data; however, there is no known GMA that works best for all image data. For example, one GMA may be best suited for photographic image data but is not desirable when the image data contains graphics or text.","Therefore, it would be beneficial to be able to select a GMA that best fits particular image data. However, conventional approaches require that a user either directly specify a gamut mapping preference, or specify preferences which effect the resulting appearance of the image produced by the color management module.","In one conventional approach, which is described in U.S. Pat. No. 5,704,021 to Smith, et al. and U.S. Pat. No. 5,579,446 to Naik et al., a user specifies color matching options for different types of objects (i.e., text, photo and graphics) via a user interface. For example, the user may identify, for each object type, the type of adjustments to be made between the displayed image and the printed image. This approach is designed for use by a sophisticated user and\/or someone willing to experiment with different option selections, or combinations thereof, to achieve a desired result. However, it is less than optimal for the user who either does not know enough, or does not wish to take the time, to specify the appropriate option designations to achieve a desired result.","In U.S. Pat. No. 6,006,013 to Rumph, et al., a PDL (Page Description Language) document creator may specify, in the form of a rendering tag associated with an object within the document, a gamut mapping preference. Based on the creator-generated gamut mapping preference as well as automatically-generated rendering tags, meta-data is generated for the objects in the PDL document that are intended to optimize the printing characteristics of an output device. Since gamut mapping information must be specified by someone, the same drawbacks exist as with the first-described approach.","Therefore, what is needed is an ability to automatically select a GMA based on characteristics of the color image data, and to provide a mechanism whereby a color management system is able to use the automatically-selected GMA.","The present invention addresses the foregoing problems and provides a mechanism for dynamically selecting a gamut mapping component for use in a color management system.","In one aspect of the invention, a method is provided of dynamically selecting a gamut mapping component for use in a color management system that transforms colors specified in image data from a first color space to a second color space, the method comprising automatically generating prediction information for use in selecting from a plurality of gamut mapping components, wherein the prediction information is based on determined gamut mapping preferences corresponding to at least one characteristic of the image data, and automatically selecting at least one of the plurality of gamut mapping components based on the prediction information","In so doing, there is no need for a user to either identify an appropriate gamut mapping, or identify options from which gamut mapping is selected. The present invention may be used by unsophisticated users with no knowledge of gamut mapping and\/or the effects that various option selections will have on given image data.","In another aspect of the invention, a system is provided for dynamically selecting a gamut mapping component for use in a color management system to transform colors specified in image data from a first color space to a second color space, the system comprising at least one image characterizer configured to automatically identify a characteristic of image data, a selection engine configured to generate prediction information for use in selecting from a plurality of gamut mapping components, wherein the prediction information is based on determined gamut mapping preferences corresponding to the characteristic of the image data, the selection engine is configured to automatically select at least one of the plurality of gamut mapping components based on the prediction information.","This brief summary has been provided so that the nature of the invention may be understood quickly. A more complete understanding of the invention can be obtained by reference to the following detailed description of the preferred embodiment(s) thereof in connection with the attached drawings.",{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 2","FIG. 2"],"b":["1","2","4","1","5","2","1","6","1","7","1","8","18","18","100","8","102","10","1"]},"Computer  may be connected to a network such as World Wide Web  via connection  to World Wide Web . While the invention is described with reference to the World Wide Web  (also referred to as the Internet), it should be apparent that the invention may be practiced with other types of networks such as an intranet, local area network, etc. Connection  may be formed, for example, via a serial modem (not shown) connected to computer  and a telephone line which, in turn, is connected to World Wide Web . It should be noted that computer  may be connected to World Wide Web  by other types of connections. Display page for display on monitor  as well as other data or applications for use by computer  can be received from World Wide Web  over connection .","Also connected to World Wide Web , via a connection , is web server , which receives requests for web pages and\/or data from applications (e.g., a web browser application) running on computer  and sends a response (e.g., Web page, data, program code, etc.) to computer  over World Wide Web . It should be apparent while only one server  is shown in , additional instances of server  may be accessible via World Wide Web .","Like computer , web server  is a computing system that is executing an operating system, and may include a display monitor , keyboard  for entering text and commands and mouse  for manipulating and for selecting objects displayed on display monitor . Web server  further includes one or more disk drives (e.g., fixed disk drive , floppy disk drive  and\/or a CD-ROM drive), in which are stored application programs, data and files, and device drivers for controlling peripheral devices.","A floppy disk drive, such as floppy disk drive  may be used to read data from and write data to floppy disks inserted therein. Data and\/or applications may also be accessed from a CD-ROM via a CD-ROM drive (not shown) or over a network to which web server  may be connected.",{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIG. 3","FIG. 3"],"b":["1","20","22","22","25","1","8","29","1","27","2","28","4","23","5","21","26","10","31","6","1","10","29"]},"Read only memory (ROM)  stores invariant computer-executable process steps for basic system functions such as basic I\/O, start up, or reception of keystrokes from keyboard .","Main random access memory (RAM)  provides CPU  with memory storage which can be accessed quickly. In this regard, computer-executable process steps of program code are transferred from disk  over computer bus  to RAM  and executed therefrom by CPU .","Also shown in  is disk  which, as described above, includes a windowing operating system, a color management system which includes, or in some manner interfaces with, program code used to dynamically select a GMA according to the present invention. The program code may be stored on computer system  in RAM, disk , or on floppy disks readable by floppy disk drive . In addition, program code may be downloaded from server  via the World Wide Web . Other applications may include word processing, spreadsheet, graphics, and gaming applications. Disk  further includes data files and device drivers as shown.","Image data which includes pixel (or color component) data, and may include other data such as metadata, is examined in the present invention to extract characteristics of the image that are used to select a GMA for use in generating an output image using the gamut transformation provided by the selected GMA. The characteristics are used along with one or more weights associated with the GMAs to generate prediction information for each GMA, the prediction information is in turn used to select a GMA. As is described in more detail below, the prediction information is based on determined preferences that correspond to the characteristics.",{"@attributes":{"id":"p-0042","num":"0041"},"figref":["FIG. 4","FIG. 4"],"b":["400","402","403","404","403","404"]},"Examples of metadata  include, but are not limited to descriptional information such as a title, subject description, keywords or tags, image capture conditions (e.g., capture source, date\/time of capture, aperture, exposure time, flash use), etc. The \u201cDIG35 Specification\u201d, which is incorporated herein by reference, provides examples of metadata for use with digital images. File formats such as the MPEG 7, JPEG and EXIF file formats may include metadata in one form or another. However, any file format that accommodates the use of metadata may be used with the present invention.","Pixel data  comprise one or more bytes that represent a color, grayscale or bi-level representation of the pixel. In a color representation, each pixel defined by pixel data  comprises color component definitions for each component that makes up a color. For example, where color is defined in the RGB color space, each pixel is represented by red, green and blue color component data. Similarly, if the CMYK color space is used, a color is represented by cyan, magenta, yellow and black color component data. Pixel data  may be defined in other color spaces in addition to the RGB and CMYK color spaces. For example, a device independent color space (e.g., CIE XYZ, Lab and Luv) may be used to represent a color within pixel data . Pixel data may also be represented in a palletized format.","Metadata  is passed to image characterizer A and is parsed using a natural language interpreter or other interpreter. That is, image characterizer A analyzes metadata  to identify information contained therein so as to determine characteristics of image data  (e.g., a type such as a picture or business graphics) and passes its findings to selection engine . Selection engine  combines the information with known strengths and\/or weaknesses of GMAs to select a GMA. For example, if metadata A contains aperture data, the image can be identified as a photograph, and a GMA that has been determined by the present invention to be preferred with photos may be selected by selection engine .","Image characterizers may include either statistical characteristics, semantic characteristics or both.","In semantic characterization approaches, pixel image data is interpreted to determine what pixel data  and\/or metadata  represents. For example, a semantic characterizer may look for objects such as faces or landscapes in the pixel data  or examine metadata  to interpret what is represented by image .","In addition to the findings supplied by image characterizer A, findings from image characterizer B are supplied to selection engine . Image characterizer B operates on pixel data  to generate image characteristics. Image characterizers A and B may implement a semantic approach (described above), a statistical approach, or both.","A statistical approach compiles statistics by examining each pixel of image data to generate histograms or other statistical results (e.g., center of gravity or mean chroma). Examples of statistical characteristics include examination of pixels to detect redness, contrast, hue, chroma, colorfulness, flesh tones, clusters of colors, etc. Other examples of statistical characteristics that suggest business graphics include the presence of flat shaded areas (or a number of pixels of the same color), very smooth gradients or gradients used with known business-graphics imaging applications such as PowerPoint. Other statistical characterizers may determine when an image is high, mid or low key, determine the amount of texture in the image, or the texture at high saturation versus the texture at a low saturation within the image.","For example, as a redness characterizer, image characterizer B may determine a CIELAB metric hue angle and a CIELAB metric chroma for each pixel of pixel data , and determine the proportion of pixels that have a hue angle within a given range (e.g., between 22.5 and 67.5 degrees) and a CIELAB metric chroma that is equal to or exceeds a given threshold (e.g., 5.0). A hue image characterizer collects hue information for each of the pixels of pixel data  in a frequency table. Similarly, a chroma histogram image characterizer collects chroma information for each of the pixels in a frequency table. A colorfulness image characterizer determines the proportion of pixels with CIELAB metric chromas greater than or equal to a threshold value (e.g., 80). The above are meant as examples only, and it should be apparent that image characterizers A and B may be used to generate any type of image characteristics. In addition, any number of image characterizers A and B may be used with the present invention.","The findings of image characterizers A to B become input to selection engine  and are used to select a GMA to generate output image . That is, selection engine  uses the findings of image characterizers A to B to select a GMA, from GMAs , that is likely to provide a preferred output image from image  based on determined preferences for GMAs . Examples of GMAs  include, but are not limited to, Carisma, CLLIN, CINC, LLIN, LNLIN, LCLIP, LSLIN and GCUSP. A discussion of such gamut mapping algorithms may be found in the doctoral dissertation of Jan Marovic entitled \u201cTo Develop a Universal Gamut Mapping Algorithm\u201d (University of Derby, 1997), which is incorporated herein by reference. The selected GMA is used by Color Management Module  to generate output image  from image .","The selection that is made by selection engine  is based on the characteristics of image  as well as weights . Weights  are generated based on the preferences of one or more observers for output images generated by GMAs  from input images having the same, or similar, characteristics as image . As is explained in more detail below, image characteristics are coupled with weights  to generate predictions for GMAs  that are used by selection engine  to select a GMA from GMAs .","Weights  are determined based on an empirical testing involving the collection of observer preferences to output images generated by GMAs  from input test images whose characteristics have been determined according to the present invention.  provides a process overview for collecting empirical information that is used to generate weights  according to the present invention. It should be apparent that the number of images, GMAs and image characterizers used is for illustrative purposes, and that the present invention is not limited to those shown in FIG. .","Briefly, test images such as images A and B are input to empirical testing  and image characterization  to generate preferences  and image characteristics , respectively, which are used to generate weights .","Images A and B, which may comprise metadata , pixel data , or both, are each input to GMAs  and  as part of a image transformation such as that described with reference to blocks  to  of FIG. . Output images A and A are generated from input image A using GMAs  and , respectively. Similarly, output images B and B are generated from input image B and GMAs  and , respectively.","Output images A, B, A and B are viewed by observer(s)  to determine their preferences . That is, for example, the percentage of observer(s)  that prefer output image A over output image A is identified, and vice versa. Both output images A and A were generated from input image A using different GMAs (i.e., GMAs  and ). Preferences  comprise a preference of observer(s)  to output images A and A and are combined with the characteristics of input images  A to identify the strengths and\/or weaknesses associated with a particular GMA given particular image characteristics. Preferences  also include preferences with respect to output images B and B.","To obtain image characteristics , images A and B are input to image characterization . Image characterization  may comprise any number and type of characterizers that determine characteristics of images A and B. Image A is input to image characterizers  and  to yield image characteristics A and A. Similarly, image B is input to image characterizers  and  to yield image characteristics B and B.","The empirical data, which comprises preferences  and image characteristics , are used to generate weights for a GMA and image characteristic combination. The weights are used to generate prediction information. The empirical data corresponding to the GMAs is gathered that reflects the strengths and weaknesses of particular GMAs with regard to characteristics of image data. For a given characteristic, input images which vary with respect to the degree or amount of characteristic (e.g., input images that vary with respect to the degree of redness of the images) are input to each of the GMAs, and for a given input image a percentage of observer(s)  that prefer a given output image (i.e., images generated for each GMA from the input) is recorded along with the value of the characteristic for the input image. The recorded preferences, which may be recorded as a percentage of observer(s)  that prefer a given image, are then used to generate a scoring for each GMA relative to the characteristic.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 6"},"At step S, a determination is made whether all of the characteristics for which weights  are to be generated have been processed. If so, processing ends. If not, processing continues at step S to determine whether all of the input images for a given characteristic have been processed. If not, processing continues at step S to generate a value for a characteristic of the input image using a characterizer (e.g., image characterizers A and B).","At step S, an output image is generated using each of the GMAs from the input image. At step S, preferences (e.g., preferences ) of observer(s)  are recorded. That is, from the output images that are generated in step S, the output image that is preferred by each of observer(s)  is recorded. Processing continues at step S to process any remaining input images. For example, another input image that contains a different level of the characteristic, or that has a particular combination of characteristics, may be processed to obtain observer(s) preferences .","If it is determined, at step S, that all of the input images have been processed, processing continues at step S to initialize a slope summary variable that is updated to include an aggregate of the slopes for each GMA for the characteristic. At step S, a determination is made whether a slope has been determined for each of the GMAs.","If not, processing continues at step S. As is described below with reference to , the data that is collected for a given GMA and characteristic may be plotted with the preference on one axis and characteristic value on another axis. At step S, a straight line is calculated (e.g., using a straight line fit function) from the characteristic and preference data collected for a given GMA and characteristic. At step S, a slope is determined for the line generated in step S. At step S, the slope is added to the aggregate slope variable, and processing continues at step S to calculate a slope for any remaining GMAs.","If it is determined, at step S, that there are no more GMAs for the given characteristic, processing continues at step S to generate a score for each GMA. A GMA's score is determined to be the ratio of the GMA's slope to the aggregate slope value (i.e., the sum of the slopes generated in step S from the slopes determined for each of the GMAs in step S).",{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 7","b":["510","604","605"]},"The redness characteristic may be based on the CIELAB metric hue angle of pixel data . A range of hue angles may be used to identify a high, medium and low amount of redness. Images  to , which contain varying degrees of redness, are transformed using GMAs  to . Output images A, A and A are generated from image A (which contains a high degree of redness), and based on observations of observer(s) , the output image generated by GMA  was preferred by 50% of observer(s)  and was preferred more frequently than the images generated by GMAs  and . That is, with respect to images that have a high degree of redness, GMA  is preferred over GMAs  and .","As indicated in , a similar approach may be repeated with images that contain medium and low degrees of redness. As a result, it is possible to identify which one of GMAs  to  is preferable for images that contain high, medium and low amounts of redness. Based on the results indicated in , if redness is the only characteristic used to select a GMA, GMA  is preferred in a case that an image has a high level of redness, GMA  is preferred with a medium amount of redness and GMA  is preferred for images with a low redness level.","Of course, in the above example, only the redness characteristic is used to identify preferences  associated with a given GMA, and then to select a GMA based on these preferences. It is possible using the present invention to determine preferences for combinations of image characteristics. Thus, for example, a colorfulness characteristic may also be determined for images A to C. In so doing, it is possible that another set of preferences may be derived from preferences  of observer(s) , which corresponds to a combination of a redness characteristic (e.g., a high degree of redness) and a colorfulness characteristic (e.g., a low degree of colorfulness), for example.","Preferences  of observer(s)  are used to generate one or more weights associated with a GMA that are used to predict an optimal GMA for an image with a given set of characteristics. Referring again to , once it is determined at step S that all of the test input images have been processed to obtain GMA preferences , processing continues at step S to generate a weight for each GMA and tested characteristic.","Various techniques may be used to generate the weights. An exemplary technique is described above with reference to , which involves determining, for each characteristic and GMA combination, a slope of a straight line generated from \u201cx\u201d and \u201cy\u201d values, where the x-values correspond to values of the characteristic and the y-values correspond to the percentage of observer(s)  that selected the GMA for a given characteristic value. In this example, the prediction score for a given GMA relative to a specific characteristic is a ratio of the GMA's slope to the sum of the slopes for all of the GMAs.","Using the technique described in , once all of the test images have been processed for a given characteristic, a slope is determined for each GMA based on the preferences  of observer(s) , and a weighting is generated based on a ratio of the GMA's slope to the aggregate of the slopes of all of the GMAs. For each GMA, a straight line is determined using the recorded preferences  associated with a GMA. A slope is determined for the line, and the GMA's line slope is added to the aggregate slope. Once all of the GMAs have been processed, a weight is determined for each GMA that is the ratio of a GMA's slope to the aggregate slope.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 8A","b":["510","507","510","507","802","804","510","801","507","802","804","802","804"]},{"@attributes":{"id":"p-0073","num":"0072"},"figref":["FIG. 8B","FIG. 8B"],"b":"510"},"For the sake of example, line graphs  to  of  have slopes of ,  and , respectively. Referring to first-order weights , for example, if the characteristic plotted in  is redness, line graphs  to  correspond to GMA, GMA and GMA, respectively. The value in weights  that corresponds to GMA is determined to be the slope of line graph  over the sum of the slopes of lines graphs  to , 1\/10 or 0.1. The remaining values in weights  are calculated in the same manner. Referring to weights , if the characteristic plotted on the x-axis of  is colorfulness, based on the values of weights  that correspond to colorfulness, line graphs  to  represent GMA, GMA and GMA, respectively. If the x-axis is used to plot the sky blue characteristic, line graphs  to  represent GMA, GMA and GMA, respectively.","Weights  are used with determined characteristics of an image to derive a weighted score, or predictor, which is in turn used to select a GMA. In the example of , redness, colorfulness and sky blue characteristics of the image are used to predict a preferred GMA. Predictors A are obtained from image characteristics A and weights . Based on predictors A, GMA has the best score for the given image characteristics A and is selected.","To derive predictors A according to the present invention, for each GMA, each characteristic's value in image characteristics A is multiplied by its corresponding weight in weights , and the products are summed. A predictor is obtained for GMA using the following exemplary formula:\n\nRedness Char. Value*GMA's Redness weighting+Colorfulness Char. Value*GMA's Colorfulness Weighting+Sky Blue Char. Value*GMA's Sky Blue Weighting\n\nIn the case of GMA, a predictor score of 0.39 is obtained as follows:\n\n0.3*0.1+0.2*0.3+0.5*0.6=0.39\n","Predictor scores for GMA and GMA based on image characteristics A and weights , which are obtained in a similar fashion, are 0.26 and 0.35, respectively. Accordingly, GMA is selected, since it has the best score of predictors A.","Using image characteristics B and weights , predictors B are obtained for GMA, GMA and GMA. Similarly, predictors C are derived from image characteristics C and weights . Based on predictors B, GMA is selected for an image having image characteristics B. GMA is selected based on predictors C for an image with image characteristics C.","Each column in weights  represent a single characteristic, and each row corresponds to a given GMA. It is possible for a column to reflect more than one characteristic, or a combination of characteristics. Second-order weights  provide an example of a combined weight. Weight  represents a combination of the redness characteristic and the sky blue characteristics. The Redness-Sky Blue second-order weighting is determined for each GMA as follows:\n\nRedness Char. Value*GMA's Redness Weighting\u2212Sky Blue Char. Value*GMA's Sky Blue Weighting\n","For GMA, the Redness-Sky Blue weighting is determined as follows:\n\n0.3*0.1\u22120.5*0.6, or \u22120.27\n\nA similar approach is taken to derive the second-order weights A for GMA and GMA, and for deriving weights B and C for GMA, GMA and GMA.\n","Predictors A are derived using first-order weights  and second-order weights . In this example, each GMA's predictors A is derived by subtracting the GMA's second-order weight A from its corresponding predictor A.","Based on predictors A, GMA is selected, since it has the best score. Predictors B and C are derived in the same manner as predictors A, and reflect both second-order and first-order weights.","In the example of , use of second-order weights A to C to derive predictors A to C, respectively, results in a different GMA being selected in the case of predictors B and C. That is, a different GMA is selected than that selected when using predictors B and C.","Weights  and  are given in the form of a matrix in  with each column containing a coefficient (i.e., or weighting) that is applied to a value of the same characteristic found in an input image to generate predictor score as discussed above. A coefficient may represent a linear term (e.g., a single term such as colorfulness or redness) or a non-linear term which represents some combination of linear terms (e.g., a combination of redness and sky blue terms).","A neural network may be used by selection engine . A neural network is typically organized in layers, with each layer comprising a number of interconnected nodes with associated functions. According to the present invention, an input layer receives the characteristics of an image which are operated on by one or more internal layers of the neural network to generate prediction information which is in turn used to select a GMA. In the training phase, each of the nodes of the internal layer(s) generates a weight which the neural network determines based on initial weights (e.g., weights ,  and\/or results based on a threshold comparison) and error corrections performed by the neural net.","Once the neural network is \u201ctrained\u201d, it switches to become a selection tool that receives as input the characteristics of an image (e.g., image ) and provides as output a selected GMA.","For example, a \u201credness node\u201d of the input layer can generate a predictor based on an image's level of redness and a weighting associated with the redness characteristic. Similarly, a \u201ccolorfulness node\u201d may generate a weighting based on whether (and\/or to what extent) the image's colorfulness characteristic value exceeded a colorfulness threshold. Output can then be used by other nodes in the same or a subsequent layer to arrive at a selected GMA.","A GMA that is selected according to the present invention is in turn used to generate an output image.  illustrates a flow diagram of process steps to select a GMA and generate an output image from an input image using the selected GMA according to the present invention.","At step S, an input image (e.g., image ) is characterized using image characterizers (e.g., A and\/or B) to generate image characteristics. In order to perform the image characterizations, image  may be converted to an intermediate form (e.g., an appearance form such as that operated on in block  of FIG. ), but need not be. That is, according to the present invention, image characterizers A and B may use the raw input image data, or some form thereof.","At step S, the collected image characteristics are input to selection engine  to select a GMA. As discussed above, the collected image characteristics are coupled with weights  to generate scoring which is in turn used to select a GMA. At step S, a transform is created based on the selected GMA and device characteristics, or profiles. At step S, input image  is gamut transformed using the transform created in step S. In order to perform the transformation, input image  is preferably converted to an appearance form (or device independent form) before it is transformed using the transformation created in step S.","A color management system may provide an application programming interface (API) to be used by an application program to perform the steps of FIG. .  illustrate examples of an application programming interface (API) which provide an interface to functions which perform the process steps of FIG. .","Referring first to , a function, named ANALYZE_IMAGE, receives as input the image (input image ) and generates image characteristics as output. The ANALYZE_IMAGE function causes input image  to be characterized by one or more image characterizers (e.g., image characterizers A and\/or B). The image characteristics output by ANALYZE_IMAGE become input to the SELECT_GMA function, which uses the image characteristics and weights  to select a GMA as discussed above. The SELECT_GMA function outputs a GMA selection (i.e., an identification of the selected GMA). The GMA selection and device profile information become input to the SEQUENCE_TRANSFORM function, which outputs a transformation. The APPLY_GMA function uses the transformation generated by SEQUENCE_TRANSFORM to output a transformed image.","In the API example of , each of steps S to S is performed in a separate call the API. In so doing, it is possible for a program developer to have some visibility into the functionality of the API. In addition, the data that is output by the functions may be made available to the calling program for some other use. For example, the image characteristics that are output by the ANALYZE_IMAGE function may be retained so that the image characterization need not be repeated. For example, the image characteristics may be saved as metadata in input image . Similarly, other data, which is generated by the API, (e.g., the transform output of SEQUENCE_TRANSFORM) may be retained separately or as part of input image .","While a separate function is used for each of steps S to S in the example of , it is possible to combine the functionality. For example, steps S may be performed by ANALYZE_IMAGE, and steps S to S may be performed in a single function. As another alternative, the steps of  may be combined to achieve performance advantages. For example, steps S and S may be performed by a personal computing system such as computer , and steps S and S may be performed by a raster image processor (RIP) which is dedicated to performing the tasks associated with steps S and S. In such a case, for example, an ASIC may be used to process the image data to perform steps S and S.","An application that uses the color management capabilities of the present invention may use the functionality of the API provided in  by including the appropriate syntax in the application's program code for invoking the functions provided. However, there may be a desire not to alter the program code of existing applications in order to make use of the functionality of the present invention. In such a case, it is possible to use an API such as that provided in FIG. B.","In the example of , it is assumed that an application program makes calls to two functions (i.e., CREATE_TRANSFORM and TRANSFORM_PIXELS) to generate a gamut transformed output image. In order to make use of the present invention's capabilities without the need to alter existing application program code, dynamic selection of a GMA according to the present invention may be embedded within the TRANSFORM_PIXELS API function. In addition, the same data structures are used in the invocation of the functions. By doing so, there is no need to alter existing application program code in order to dynamically select a GMA according to the present invention.","For example, a call to the CREATE_TRANSFORM function includes as input a device profile (or profiles) and an \u201cintent\u201d data structure, which identifies preferences (e.g., calorimetric, saturation and perceptual preferences). According to the present invention, the same information is input to the CREATE_TRANSFORM function. However, instead of creating a transform using the profile and intent input, CREATE_TRANSFORM outputs a transform data structure which contains the profile and intent data. In this example, the CREATE_TRANSFORM function operates to pass its input on to the TRANSFORM_PIXELS function.","The TRANSFORM_PIXELS function uses the profile and intent information stored in the transform data structure and the image as input to perform steps S to S. That is, a call to the TRANSFORM_PIXELS function results in the generation of image characteristics, selection of a GMA, creation of a transform using the selected GMA, and application of the transform to the selected image.","Using the modules as described above, dynamic selection of a GMA occurs within an existing function (i.e., TRANSFORM_PIXELS) of the API. Therefore, an application program that calls the API need not be aware that a GMA is being dynamically selected. Thus, the dynamic selection is transparent to the application program that invokes the program interfaces of the color management system. Advantageously, there is therefore no need to alter the application programs that invoke the program color management system's modules.","In  to B, device profile(s) which are used may be particular to a given imaging device, and comprise settings or other information that are used to calibrate the device so that output of the device is consistent across time and across devices. A device profile is generated using a device characterization process that maps desired results with the capabilities of the device. For example, through characterization, it is possible to take into account the gamut boundaries of the device, and to map known colors to the device's color gamut.","Color profiles such as an ICC (International Color Consortium) profile provides a format for storing device characterizations and include tags that identify the characterization data. In the present invention, a new tag may be used to store the matrix values (e.g., weights  and ) and\/or information used to train the neural network.","Advantageously, if the weights are different for each device, storing the weightings in each device's profile allows the present invention, and the color management system that uses the present invention, to be customized to a particular device. If, however, the weightings are the same across devices, they may be stored external to the device profile(s) and accessed to initialize selection engine  for use with any device.","In this regard, the invention has been described with respect to particular illustrative embodiments. However, it is to be understood that the invention is not limited to the above-described embodiments and that various changes and modifications may be made by those of ordinary skill in the art without departing from the spirit and the scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 8B"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIGS. 10A and 10B","b":"9"}]},"DETDESC":[{},{}]}
