---
title: Method and apparatus for latency based thread scheduling
abstract: A method and apparatus for providing latency based thread scheduling. A thread attribute, e.g., latency of a process, is used in effecting the scheduling of the thread.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08180943&OS=08180943&RS=08180943
owner: NVIDIA Corporation
number: 08180943
owner_city: Santa Clara
owner_country: US
publication_date: 20040319
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATION(S)","FIELD OF THE INVENTION","BACKGROUND OF THE DISCLOSURE","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This application claims priority from commonly owned provisional U.S. Patent Application No. 60\/458,191 entitled \u201cMETHOD AND APPARATUS FOR LATENCY BASED THREAD SCHEDULING,\u201d filed Mar. 27, 2003, having common inventor and assignee as this application, which is incorporated by reference as though fully set forth herein.","The present invention relates to a novel method and apparatus for scheduling threads. More specifically, the present invention provides a method that schedules threads based on latency.","In programming, a \u201cthread\u201d can be thought of as a minimum \u201cunit of execution\u201d or a basic unit of CPU utilization. The thread model is a flexible process organization mechanism that allows individual processes to access common resources, thereby increasing program efficiency. Namely, a process that has multiple threads of control can perform more than one task at a time. For example, on a single processor machine, this means processing threads on a time-interleaved basis, thereby requiring scheduling. Although the thread model provides the benefit of concurrency of processes, it is up to the operating system or kernel to perform thread scheduling to properly exploit this concurrency.","For example, most operating systems schedule threads to handle interrupts by simply placing them into a queue. The threads are then processed in the order that the threads were scheduled (e.g., threads scheduled to be performed in the order the corresponding interrupts were received). However, this approach does not distinguish the priority of the underlining processes that are performed by the threads in the queue. For example, interrupt threads will be mixed with non-interrupt threads for scheduling.","To address the issue of priority, some advanced operating systems have two queues, where one queue is dedicated to high priority processes and one queue is dedicated to address low priority processes. In this approach, an interrupt thread can be scheduled by being placed in either queue. The threads in the queues are then processed in the order that they were placed in each queue. Although this approach allows the operating system some flexibility in prioritizing the execution of threads, it is still insufficient to allow the operating system to finely schedule threads to account for other parameters, e.g., latency requirement of a particular process.","For example, some real-time devices have \u201cisochronous\u201d requirements, where isochronous denotes \u201cat the same rate\u201d, e.g., where a data flow is tied to time. To illustrate, from the perspective of a hardware device that is receiving a stream of real-time data (e.g., audio and video), the hardware device must handle a plurality of interrupts efficiently to address various functions such as buffer management (e.g., detecting fullness of a first buffer, setting up a second buffer, switching from the full buffer to an available empty buffer and the like). In other words, there is a fixed time limit when the first buffer is full and the second buffer must be ready to receive the continuous data stream. Since the data stream is directed toward the hardware device in real time, the hardware device must handle the interrupts skillfully to avoid a \u201cpop\u201d in the audio or a noticeable \u201cglitch\u201d in presenting the video if data packets are lost due to the inability of the hardware device to keep up with the continuous data stream.","Unlike a \u201cclosed\u201d system where timing constraints are known a priori, the above timing criticality is further amplified in an open system, where additional hardware devices or boards can be optionally added. The operating system (OS) for the open system must skillfully balance the timing constraints of these different hardware devices so that they can all operate properly without accidental loss of data due to improper handling of interrupt events.","Additionally, operating systems that are designed to distinguish high priority events from low priority events are often defeated by selfish motives of hardware manufacturers. Specifically, device drivers for hardware devices that are deployed in an open system are often written such that their interrupts will always be considered by the operating system to be high priority. Since each hardware device is competing for service by the operating system, there is little incentive to design a device driver that will cause its interrupts to be considered by the operating system as being low priority.","Additionally, even if interrupts from competing hardware devices are truly equal in terms of being in the same priority class, the operating system will not have any additional information to discriminate between numerous interrupt events. In such instances, the interrupts will likely be processed in the order that they are received in the queue, thereby limiting the ability of the operating system to flexibly rearrange the scheduled threads.","Therefore, a need exists for a novel method and apparatus that provides a thread scheduling approach that allows the operating system to finely schedule threads to account for thread parameters or attributes such as latency of a process and the like.","In one embodiment of the present invention, a novel method and apparatus for providing latency based thread scheduling is disclosed. Specifically, a thread attribute, e.g., latency of a process, is used in effecting the scheduling of the thread.","Using interrupt handling as an example, if an interrupt requests that a thread be scheduled to process the interrupt, then the interrupt scheduler will pass a latency value (e.g. in usec) to the operating system. The operating system will, in turn, apply this thread attribute to correctly organize all pending threads in an efficient order such that a thread that needs to be processed the soonest will be scheduled first.","In one embodiment, the operating system may take the latency value and add it to the current time to acquire an absolute time that the thread will need to be woken up. Using this novel approach, low priority processes, e.g., non-interrupt based scheduled threads, will have a very high (e.g. infinite) latency value such that these low priority threads will always be scheduled after high priority threads (e.g., interrupt threads). This novel approach provides a very finely tuned thread scheduling method, where the operating system can exploit a thread attribute such as latency in arranging the order in which pending threads will be processed.","To facilitate understanding, identical reference numerals have been used, where possible, to designate identical elements that are common to the figures.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 1","FIG. 1"],"b":["100","100","110","140","130","120"]},"In brief, an operating system , device drivers  and user applications  are loaded into the memory  and operated by the CPU . In one embodiment, the operating system  comprises a plurality of software modules, including by not limited to a thread scheduler  and an interrupt handler . The thread scheduler  is employed to schedule threads for supporting multithreaded applications, whereas the interrupt handler  is employed to implement an interrupt service routine. It should be noted that although the thread scheduler  and the interrupt handler  are illustrated as separate modules, the present invention is not so limited. Namely, those skilled in the art will realize that the functions performed by these modules can be implemented in a single module, e.g., within an \u201cinterrupt scheduler\u201d, or serving as a part of a much larger software module.","In operation, a thread attribute, e.g., latency of a process, is used in affecting the scheduling of the thread. Although the present invention is described below within the context of coordinating thread scheduling to handle interrupts, those skilled in the art will realize that the present invention can be adapted to address thread scheduling in general. Any multithreaded real-time computing environment can make use of this invention. The invention is particularly useful for multimedia applications.","Using interrupt handling as an example, if an I\/O device  issues an interrupt request via a device driver , the thread scheduler  will schedule a thread to process the interrupt. Specifically, in one embodiment of the present invention, the interrupt handler  or optionally, the device driver , will pass a latency value (e.g. in usec) to the operating system . The operating system will, in turn, apply this thread attribute to correctly organize all pending threads in an efficient order such that a thread that needs to be processed the soonest will be scheduled first.","In one embodiment, the operating system may take the latency value and add it to the current time to acquire an absolute time that the thread will need to be woken up and processed. Using this novel approach, low priority processes, e.g., non-interrupt based scheduled threads, will have a very high (e.g. infinite) latency value such that these low priority threads will always be scheduled after high priority threads (e.g., interrupt threads). This novel approach provides a very finely tuned thread scheduling method, where the operating system can exploit a thread attribute such as latency in arranging the order in which pending threads will be processed.","Thus, it should be understood that the thread scheduler , interrupt handler  and the device drivers  can be implemented as one or more physical devices (e.g., registers and ROMs) that are coupled to the CPU  through a communication channel. Alternatively, the thread scheduler , interrupt handler  and the device drivers  can be represented by one or more software applications (or even a combination of software and hardware, e.g., using application specific integrated circuits (ASIC)), where the software is loaded from a storage medium, (e.g., a magnetic or optical drive or diskette) and operated by the CPU in the memory  of the computer. Alternatively, the thread scheduler , interrupt handler  and the device drivers  can be represented by Field Programmable Gate Arrays (FPGA) having control bits. As such, the thread scheduler , interrupt handler  and the device drivers  (including associated methods and data structures) of the present invention can be stored on a computer readable medium, e.g., RAM memory, magnetic or optical drive or diskette and the like.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 2","FIG. 2"],"b":["200","210","220","270"],"i":["a","b "]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 2","b":["270","272","274","270"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 2","b":["210","260","260","262","264","266","266","1","220","266","2","220"],"i":["a ","a ","a","b ","b "]},"Unique changes or operational constraints affecting a particular chip will be handled and noted by its corresponding hardware dependent code . Thus, the hardware dependent code  can accurately identify the latency associated with its own hardware device. This is due to the fact that latency may be associated with clock rate, display rate, buffer size and so on. These important information are tracked by the hardware dependent code  stored in a ROM in one embodiment. The use of this latency information to effect latency based thread scheduling will be further described below.","Each of the hardware devices is provided with a direct interrupt line  to the OS kernel  (or more accurately, to the controller circuitry that is in communication with the OS kernel). Once the interrupt line  is set by a hardware device, a series of communication will follow between the device driver  and the OS kernel . In one embodiment, this communication is implemented via various \u201ccalls\u201d.","The first call is known as \u201cINTERRUPT_ALLOC\u201d (nvOsCallback(NvOs8a0 Parameters *)) which is a callback to allocate an interrupt. The allocation nvOsCallback( ) normally occurs when a device is allocated for the first time, e.g., when the hardware is being initialized.","In operation, the NV Architecture code  calls the operating system dependent code  to allocate a real-time interrupt. Normally the operating system dependent code  allocates appropriate data structures and then connects the interrupt. The NV Architecture allows multiple interrupts per device since each device contains many real-time engines. Some non-real-time operating systems can only schedule one thread or one thread per device. Real-time operating systems should create a thread for each interrupt allocated. The operating system  should attempt to service each allocated interrupt separately to ensure more predictable results.","The NV Architecture can make an nvOsCallback( ) with the following parameter members:","NvOs8a0 Parameters",{"@attributes":{"id":"p-0035","num":"0000"},"ul":{"@attributes":{"id":"ul0001","list-style":"none"},"li":{"@attributes":{"id":"ul0001-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0002","list-style":"none"},"li":"This data structure contains the input and output parameters for the nvOsCallback( ) function."}}}},"\u201cfunction\u201d","This field contains the function number.","The argument is a 32 bit void number. Legal argument values are:","0x000008A0 NVOS 8A0_INTERRUPT_ALLOC","The argument is returned unchanged.","\u201cstatus\u201d","This field returns the status.","The argument is a 32 bit void number. All argument values are legal.","Possible returned values are:\n\n","\u201cinterruptId\u201d\n\n","The second call is known as \u201cINTERRUPT_FREE\u201d (nvOsCallback(NvOs8a1 Parameters *)) which is a callback to free an interrupt. Specifically, the NV architecture code  calls the operating system dependent code to free a real-time interrupt. The free nvOsCallback normally occurs when the last usage of a device is freed. Namely, if a hardware device is being shut down, it is necessary to free up all those resources and data structures that were created and validated for the hardware device.","NvOs8a1 Parameters",{"@attributes":{"id":"p-0047","num":"0000"},"ul":{"@attributes":{"id":"ul0007","list-style":"none"},"li":{"@attributes":{"id":"ul0007-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0008","list-style":"none"},"li":"This data structure contains the input and output parameters for the nvOsCallback( ) function."}}}},"\u201cfunction\u201d","This field contains the function number.","The argument is a 32 bit void number. Legal argument values are:","0x000008A1 NVOS 8A1_INTERRUPT_FREE","The argument is returned unchanged.","\u201cstatus\u201d","This field returns the status.","The argument is a 32 bit void number. All argument values are legal.","Possible returned values are:\n\n","\u201cinterruptId\u201d\n\n","The third call is known as \u201cINTERRUPT_SCHEDULE\u201d (nvOsCall(NvOs0a0 Parameters *)) which is a call to schedule interrupts. This call is an nvOsCall( ) from the operating system dependent code  to the NV Architecture code  to schedule interrupts. Specifically, the nvOsCall( ) should be made when the operating system  notifies the operating system dependent code  that a device  may have some pending interrupts that require servicing. In advanced operating systems, a thread should be scheduled with a priority corresponding to NvOs0a0 Parameters.latency for each interrupt that needs servicing. INTERRUPT_SCHEDULE should be continuously called until NvOs0a0 Parameters.status returns ERROR_NO_MORE_INTERRUPTS.","NvOs0a0 Parameters","This data structure contains the input and output parameters for the nvOsCall( ) function.","\u201cfunction\u201d","This field contains the function number.","The argument is a 32 bit void number. Legal argument values are:","0x000000A0 NVOS 0A0_INTERRUPT_SCHEDULE","The argument is returned unchanged.","\u201cstatus\u201d","This field returns the status.","The argument is a 32 bit void number. All argument values are legal.","Possible returned values are:\n\n","\u201cinterruptId\u201d\n\n","\u201clatency\u201d\n\n","The fourth call is known as \u201cINTERRUPT_SERVICE\u201d","(nvOsCall(NvOs0a1 Parameters *)) which is a call to service interrupts. This call is an nvOsCall( ) from the operating system dependent code  to the NV Architecture code  to service an interrupt. Specifically, the nvOsCall( ) should be used to request servicing of the specified interrupt as determined by a previous call to INTERRUPT_SCHEDULE. Namely, the operating system is simply calling to each device driver  to go ahead and process your interrupts.","NvOs0a1 Parameters",{"@attributes":{"id":"p-0073","num":"0000"},"ul":{"@attributes":{"id":"ul0019","list-style":"none"},"li":{"@attributes":{"id":"ul0019-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0020","list-style":"none"},"li":"This data structure contains the input and output parameters for the nvOsCall( ) function."}}}},"\u201cfunction\u201d","This field contains the function number.","The argument is a 32 bit void number. Legal argument values are:","0x000000A1 NVOS 0A1_INTERRUPT_SERVICE","The argument is returned unchanged.","\u201cstatus\u201d","This field returns the status for this operation.","The argument is a 32 bit void number. All argument values are legal.","Possible returned values are:\n\n","\u201cinterruptId\u201d\n\n","It should be noted that the various calls and their structures as disclosed above are only illustrative. In fact, the specific structure of the device driver  as having an OS dependent code , an NV Architecture code  and a hardware dependent code  are illustrative of one particular embodiment. Those skilled in the art will realize that these modules or codes can be implemented in different manners, e.g., being partially or wholly incorporated within the OS kernel .",{"@attributes":{"id":"p-0085","num":"0115"},"figref":["FIG. 3","FIG. 3"]},"Specifically,  illustrates a time line diagram that describes the scheduling of a latency based thread for swapping buffers, e.g., as in a vertical retrace operation.  illustrates at time line  where buffer A is being read and is reaching the point of being emptied at point , where the read operation transitions from buffer A to buffer B as shown in time line . Namely, at point , buffer A is completely emptied and data is now being read from buffer B instead.","In time line , the hardware device triggers an interrupt to the OS, e.g., via interrupt line . Responsive to the hardware device, the OS in time line  toggles all the other interrupt lines -to the \u201coff\u201d position briefly to record the interrupt number on interrupt line . During this short period, the OS will not acknowledge any other interrupt lines. Once the interrupt information is captured, the OS will toggle all the interrupt lines back to the \u201con\u201d position so that it can detect and receive the next interrupt. This approach accords the OS the ability to minimize the amount of time where interrupt lines are actually turned off.","It should be noted that most CPUs have two interrupt request lines. One is the \u201cnonmaskable\u201d interrupt, which is reserved for events such as unrecoverable memory errors. The second interrupt line is \u201cmaskable\u201d, where it can be turned off by the CPU before the execution of critical instruction sequences that must not be interrupted. The maskable interrupt is typically used by device controllers to request service. Thus, the present invention only masks interrupts for the short period during of logging of the interrupt events, minimizing the likelihood of that a maskable or nonmaskable interrupt will be received and ignored. Furthermore, subsequent processing steps such as computing a latency value or the scheduling of a thread are performed without masking interrupts. In some embodiments of the invention, nonmaskable interrupts are not masked during the logging of the interrupt events.","In time line , the hardware dependent code will acquire and provide latency information or a latency value associated with setting up the next buffer. This latency information can be a predefined value associated with a particular interrupt number or it can be calculated in accordance with an equation. In the present example, the equation can be formulated as having parameters associated with \u201cbuffer size\u201d, \u201csampling rate\u201d, \u201cdata transmission rate\u201d and the like.","In time line , the latency information provided by the hardware dependent code is used by the thread scheduler of the operating system to schedule the thread to be serviced at some future time. In other words, the thread scheduler  has now exploited the latency information such that interrupts are not necessarily serviced in the order that they are received by the operating system. In fact, the thread scheduler has the necessary information to now rearrange various threads in the queue such that threads that require faster service based on latency will be processed ahead of other threads that can wait a bit longer.","In time line , the thread is actually awoken to perform the interrupt service. Finally, time line  illustrates various time segments that can be used to formulate the latency information. For example, the time duration between points \u201ca-g\u201d can be used as the latency information in scheduling the thread because it represents the maximum time allowed before buffer B will be emptied and the read operation will switch back to buffer A. Alternatively, the time duration between points \u201ce-f\u201d can be used as the latency information in scheduling the thread because it represents the time necessary to service the interrupt, i.e. process the thread. Yet another alternative is to use the time duration between points \u201ca-d\u201d because it represents the time duration that is necessary to setup a thread to service the interrupt. In fact, the latency information can be derived from various segments of this time line or other criteria to implement the present latency based thread scheduling.",{"@attributes":{"id":"p-0092","num":"0122"},"figref":"FIG. 4","b":["405","120","16","150","405","1","220","2","220","222","222","210"],"i":["a ","b ","a ","b"]},"In step  operating system  or operating system kernel  masks, i.e. turns off, any other interrupt lines not corresponding to the interrupt line which was set in step . In step , a series of communication between the device driver  and operating system  occurs to in order for the scheduler  to acquire the latency information related to the hardware device generating the interrupt. In some embodiments the scheduler  may compute a latency value based on the latency information. In other embodiments the latency information includes a latency value.","Alternatively, in step  a series of communication between the device driver  and the operating system kernel  occurs to acquire the latency information. The communication may include calls requesting allocation of an interrupt, freeing of an interrupt, scheduling of an interrupt, or the like. In step  the operating system  or the operating system kernel  unmasks, i.e. turns on, the interrupt lines turned off in step . In step  the scheduler  or a thread scheduler within the operating system dependent code  schedules a thread to process the interrupt received in step . Specifically, in one embodiment of the present invention, the interrupt handler  or optionally, the device driver , passes a latency value specified in real time units, e.g., nanoseconds, microseconds, or the like, to the scheduler . The scheduler  will, in turn, apply this thread attribute to organize all pending threads in an efficient order such that the thread and the pending threads will be processed within the latency constraints specified for each thread.","In step  the scheduler  or the thread scheduler with the operating system dependent code  determines if the thread scheduled in step  should be activated based on the latency information or an absolute time determined using a latency information, and, if not, step  is repeated. Otherwise, the scheduler  or the thread scheduler within the operating system dependent code  activates the thread scheduled in step , for example by communicating a service interrupt from the operating system  to the I\/O devices  or from the operating system dependent code  to the hardware device associated with the thread.","Although various embodiments which incorporate the teachings of the present invention have been shown and described in detail herein, those skilled in the art can readily devise many other varied embodiments that still incorporate these teachings. In the claims, elements of method claims are listed in a particular order, but no order for practicing of the invention is implied, even if elements of the claims are numerically or alphabetically enumerated."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The teachings of the present invention can be readily understood by considering the following detailed description in conjunction with the accompanying drawings, in which:",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
