---
title: System and method for creating unclassified line drawings from classified NTM images
abstract: A system and method of automatically creating a NIMA certified line drawing from a National Imagery Transmission Format (NITF) image file. A grayscale (electro-optical) image and its associated metadata from a NITF file is input into the computer based system. Pre-screening operations are performed on the metadata prior to image processing to ensure that National Imagery and Mapping Agency (NIMA) requirements and criteria are met. Image processing algorithms then perform filtering, encoding, edge detection, and custom edge pattern classification procedures to create a declassified line drawing. The line drawing can then be saved in any number of standard commercial file formats.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07003155&OS=07003155&RS=07003155
owner: The John Hopkins University
number: 07003155
owner_city: Baltimore
owner_country: US
publication_date: 20020926
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","STATEMENT OF GOVERNMENTAL INTEREST","FIELD OF THE INVENTION","SUMMARY","DETAILED DESCRIPTION"],"p":["This application is related to and claims the benefit of U.S. Provisional Patent Application Ser. No. 60\/325,396, filed Sep. 27, 2001 entitled \u201cTactical Image Rendering Tool Image Processing Algorithm for Creation of Unclassified Line Drawings from Classified National Technical Means Imagery\u201d.","This invention was made with Government support under a Navy contract no. 98-C-6663.","The present invention is related to a system and method of security downgraded image derived product (IDP) creation. More specifically, the present invention processes classified National Technical Means (NTM) imagery, in an automated manner, to create line drawings that are eligible to be labeled as unclassified.","The National Imagery and Mapping Agency (NIMA) maintains National Technical Means (NTM) imagery for use by various United States Department of Defense Agencies and Commands. The security classification of the images, and sometimes the inherently large file sizes, prohibit the images from being used in certain operations. One common means for addressing the security classification issue is to create image derived products that are eligible for security classification downgrade. One type of IDP is a line drawing, a simple, street map-like rendering. NIMA maintains the criteria that govern the creation of line drawings. Moreover, NIMA approval is required for any new technique for creating line drawings.","Traditionally, line drawings were created manually using CAD-like procedures in which analysts traced lines and polygons (in an overlay) over regions or objects of interest in an NTM image. Line drawings can also be made by manually tracing lines on stencil paper over images. These annotations can then be saved or printed separately to serve as the line drawing. The process can be tedious and can take hours to complete.","What is needed is a NIMA certified automated means for creating image derived product line drawings from NTM image data.","The present invention comprises a computer based automated means of creating unclassified line drawings from National Technical Means (NTM) image data. With the present invention, an operator can create a line drawing in just a few seconds. Most importantly, the present invention is the first automatic tool for producing line drawings that has been certified by the National Imagery and Mapping Agency (NIMA).","The present invention has been certified by NIMA for processing Electro-Optical image types and takes as input a grayscale image and associated metadata from a National Image Transmission Format (NITF) file. Prior to processing, however, pre-screening steps are required to ensure that rigid security constraints are met. Once the pre-screening has been successfully completed, the image processing algorithm(s) that create the line drawings perform filtering and encoding operations. The line drawing can then be saved in a variety of commercial file formats (i.e., tif, png, jpg, nitf).","A line drawing is a street map like image that reveals boundaries of buildings, roads, rivers, regions, and other items of interest in an image scene. A line drawing is one form of a NIMA NTM image derived product (IDP). There are numerous potential public uses for unclassified NIMA line drawings including unclassified maps, terrain revealing diagrams, GIS style drawings, drawings for forest-fire management, drawings of urban environments, drawings for farmland and forest regions. The present invention also has the ability to semi-automatically identify and emphasize regions of interest for display in the line drawings.",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1","b":["10","10"]},"The key image processing components are the line drawing generation process  and the region identification process . Prior to performing line drawing and\/or region identification, however, an NITF file parser process  pre-screens the NTM image data for security reasons. The line drawing process  then creates lines and the region identification process  facilitates specification of regions of interest that can be highlighted in the line drawings. The line drawings can subsequently be saved in multiple file formats using a file writer process  including, but not limited to, tif, png, jpg, and nitf.",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2","b":["16","20","22","24","26","24","28","24","30","24","32"]},"The GSD parameter is a spatial resolution measurement that determines the clarity of the image data. It essentially represents the size of a pixel with respect to the ground. For instance, if each side of a 10\u00d710 square foot building is represented by 5 pixels in the image data, then the GSD parameter would be (10 ft*12 inches\/ft)\/5=24 inches. If the side of a 10\u00d710 square foot building is represented by 8 pixels in the image data, then the GSD parameter would be (10 ft*12 inches\/ft)\/8=15 inches. Thus, a smaller GSD implies more detailed image data and a better quality image.","If the GSD parameter cannot be read, processing is stopped . If the GSD parameter can be read then the bit depth of the file is determined . The bit depth of the input image can range from 8 to 16 bits. If the bit depth is larger than 8 bits, then the images are requantized to 8 bits . Utilizing an 8 bit depth aids in allocating and using computer memory and also expedites certain algorithmic processing steps. Once the images have been set to 8 bit depth the file parsing process produces an output  comprising an image, a GSD parameter, and a security classification.","The pre-screening process is performed to meet NIMA security requirements and criteria. To date, the present invention is the only NIMA certified computer based tool for automatically creating image derived product line drawings from NTM image data.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 3","b":"40"},"The technique setting allows the user to select, via one of the windows under the GUI, one of three techniques for generating the line drawings. The techniques are comprised of a standard technique, a context sensitive technique, and a noise filtered technique.","The standard technique produces a line drawing for which no extra processing has been applied for emphasizing the local features of objects (e.g., windows in a building). The context sensitive technique applies custom processing which attempts to detect and emphasize local object features. This process works by generating edges based on local edge-gradient statistics collected from a square mask that scans the image along with the edge detection operator. The noise filtered technique applies custom processing that tends to generate less noise ( i.e., line fragments) in a scene as well as attempts to emphasize local object features. This process works by first, applying a low pass filter to the image and then generating edges based on local edge-gradient statistics. The statistics are collected from a circular mask (as opposed to a square mask) that scans the image along with the edge detection operators.","The appearance setting includes a more depth option or a less depth option. The more depth option invokes a custom edge thinning algorithm that tends to reveal two or more lines around certain object boundaries. This results in relatively strong edges that have a large gradient magnitude. Also, more local features of objects in the image tend to be revealed. The multiple edges, and additional local detail help the viewer's depth perception for vertical structure objects such as buildings. The less depth option invokes an edge thinning algorithm published by \u201cNevatia and Babu, Computer Graphics and Image Processing, vol 13, 1980\u201d. This algorithm results in only a single edge for object boundaries leading to more of a profile view of buildings and other objects.","The detail level setting is the main setting that the user uses to control the algorithm. This setting directly relates to the threshold that is used to create a binary edge image (i.e., edges on a solid color background). A higher detail level corresponds to a lower threshold, causing more edges (and subsequently, lines) to appear. A lower detail setting does the opposite.","The first step in the line drawing process  is a resolution adjustment  routine performed on the input image based on the GSD parameter. To perform resolution adjustment, an anti-aliasing filter is applied to the image file to blur the image. A bilinear sub-sampling subroutine then reduces the spatial resolution of the image to approximately 1.2 times the NIMA requirement for minimum resolvable distances. The sub-sampling factor is calculated by dividing the original GSD (in inches) by the 1.2 times NIMA requirement value. Next, a bicubic super-sampling subroutine is applied to bring the image back to its original dimensions. This removes visual blockiness from the image.","The next routine in the line drawing process is a contrast stretch  on the resolution adjusted image. The contrast stretching routine  performs a linear contrast stretching of pixel intensities to the extreme ranges. The purpose of contrast stretching is to improve the contrast of the image so that edges can better be captured in the following steps. A threshold determination  based on the user parameters, generation type and detail setting is the next routine. There are three threshold determination methods that can be applied based on the user parameters. These methods correspond directly to the generation techniques that the user selects via the GUI. One method is a constant global threshold technique that corresponds to the standard technique setting. Another method is a local statistical based threshold technique that corresponds to the context sensitive technique setting. And, the third method is a local statistical based threshold with additional noise filtering techniques that corresponds to the noise filtered technique setting.","An edge detection routine  follows the threshold determination routine . The edge detection routine  used by the present invention is the absolute value version of the Sobel edge detection technique. The Sobel algorithm produces an edge gradient image . This is followed by an edge thinning routine  on the gradient image based on the appearance parameter that the user inputs or selects via the GUI. There are two edge thinning methods to choose between based on the depth setting. The edge thinning methods were described earlier.","The next routine in the line drawing process  is a chain coding routine . An 8-directional chain coding technique is applied to the thinned, binary edge image to vectorize the edges. Single pixels are discarded and chain-coded lines are filtered based on length. Only lines with at least a set number of pixels are retained. The final routine in the line drawing process  is a decluttering routine . It is a custom chain code based edge image decluttering algorithm designed to remove small isolated edges, edges that encircle a single pixel, and edges that contain just a links which form a compact feature. The output of the line drawing process  is a line drawing  that can be saved by the file writer process  in a variety of file formats.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 4"},"The input  for the region identification process  is comprised of the raw image, the GSD, and seed points, and a sensitivity setting. Seed points refer to x,y coordinates in the image that the user selected manually via an input device to the computer. The collection of seed points form a region of interest. The user adjustable sensitivity setting governs the precision with which the algorithm attempts to detect the region defined by the seed points. A low sensitivity setting may result in only partially highlighting a region, or no detection of the region at all. A high sensitivity setting may result in too large of a region being highlighted.","The image is then requantized  to 16 graylevels using an equal probability quantization technique. Next, the image block size is determined  based on the GSD. The block size is at least 8\u00d78 pixels with smaller GSD values having a larger block size. This is followed by a computation of the global level co-occurrence matrix (GLCM)  that captures the spatial statistical dependency of pixels in each block. Texture features are computed  depending on the region selected. This is followed by determining the threshold based on the sensitivity setting . The threshold is applied to determine image blocks that are classified as the specified region. The last routine in the region identification process is to segment the image by region growing . The segmenting is done in the statistical feature space instead of the pixel intensity space. The output  of the region identification process  is a segmented image.","In the following claims, any means-plus-function clauses are intended to cover the structures described herein as performing the recited function and not only structural equivalents but also equivalent structures. Therefore, it is to be understood that the foregoing is illustrative of the present invention and is not to be construed as limited to the specific embodiments disclosed, and that modifications to the disclosed embodiments, as well as other embodiments, are intended to be included within the scope of the appended claims. The invention is defined by the following claims, with equivalents of the claims to be included therein."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
