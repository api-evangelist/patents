---
title: Method, system and computer program product for batched virtual memory remapping for efficient garbage collection of large object areas
abstract: A method, system and computer program product for batched remapping of virtual memory addresses for garbage collection in a large object area. A mapping from a table having a first set of virtual memory addresses and sizes of non-contiguous, page-aligned large objects in a large object area to a remapping table having a second set of virtual memory addresses is determined. In a single batch, a request is received that includes the second set of virtual addresses and requests a remapping of the large objects to the second set of virtual memory addresses. The second set of virtual memory addresses is validated, and the large objects are remapped to the second set of virtual memory addresses according to the request. The remapping results in a compaction so that the large objects are contiguous in the large object area. The remapping does not require copying data in physical memory.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08327111&OS=08327111&RS=08327111
owner: International Business Machines Corporation
number: 08327111
owner_city: Armonk
owner_country: US
publication_date: 20090330
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION","Overview","Remapping Example"],"p":["The present invention relates to automatic memory management of large object areas, and more particularly to a method, system and computer program product for performing garbage collection in large object areas by remapping virtual memory addresses.","Conventional compaction of free space in garbage collection that uses memory copying has a negative performance impact by requiring large amounts of memory to be shifted. These known memory copying compaction techniques are expensive and cause significant paging activity with associated memory thrashing. Other conventional compaction methods are inefficient, including those that rely on virtual memory to exploit page faults to implement operating system supported read and write barriers. Furthermore, a known compaction method uses virtual memory management to decommit free pages and commit uncommitted pages, but the resulting number of pages needed, the use of three types of pages (i.e., free, live, and uncommitted), and the intermingling of uncommitted pages with live pages indicate deficiencies in complexity, effectiveness, and efficiency (e.g., additional management is required for the interspersed uncommitted pages and the need to reserve the uncommitted pages requires a reduction in the maximum heap size). Thus, there exists a need to overcome at least one of the preceding deficiencies and limitations of the related art.","The present invention may provide a computer-implemented method of batched remapping of virtual memory addresses for garbage collection in large object areas. The method comprises:","determining a mapping from a first table to a second table, wherein the first table includes a plurality of identifiers of a plurality of page-aligned large objects included in a large object area of a virtual memory, a first plurality of virtual memory addresses to which the page-aligned large objects are initially assigned, and a plurality of virtual memory sizes of the page-aligned large objects, wherein the second table includes a second plurality of virtual memory addresses to which the page-aligned large objects are assigned for a compaction of the plurality of page-aligned large objects, and wherein the page-aligned large objects are not contiguous in the large object area;","receiving a request in a single batch, wherein the request includes the second plurality of virtual memory addresses and requests a remapping of the plurality of page-aligned large objects to the second plurality of virtual memory addresses;","validating the second plurality of virtual memory addresses included in the request; and","remapping the plurality of page-aligned large objects to the second plurality of virtual memory addresses according to the request, wherein a result of the remapping is the compaction that includes the plurality of page-aligned large objects being contiguous in the large object area, and wherein the remapping is performed by a processor of a computer system.","A system and computer program product corresponding to the above-summarized method are also described and claimed herein.","One or more embodiments of the present invention advantageously use virtual memory management to reduce fragmentation without requiring the copying of data in memory.","One or more embodiments of the present invention are directed to a compaction method, system and computer program product that use virtual memory management to change virtual memory address ranges in a large object area to align contiguous locations of free virtual memory and to align contiguous locations of live virtual memory by adjusting virtual memory mapping on physical memory. Aligning free virtual memory as contiguous locations and aligning live virtual memory as contiguous locations may include using remapping operations to swap free and live pages. The compaction technique disclosed herein may reduce fragmentation without requiring the resource-intensive copying of data in memory. One embodiment of the compaction method, system and computer program product disclosed herein utilizes a kernel memory management driver, also known as (\u201ca.k.a.\u201d) kernel driver or kernel mode driver, that allows multiple virtual memory remappings to be performed in a single kernel transition so that page-aligned large objects become contiguous in a large object area. As used herein, a kernel transition is defined as a sequence of steps that are required for a thread executing in user mode space to transition to executing code in kernel mode space. The kernel driver may have direct access to underlying kernel application programming interfaces (APIs).","System for Batched Remapping of Virtual Memory Addresses for Garbage Collection in Large Object Areas",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1","b":["100","102","104","102","106","108","110","112","112","106","114","116","118","120","114","100","114"]},"Garbage collector  performs automatic memory management that includes identifying objects in a program that cannot be accessed in the future by the program and reclaiming the memory used by the identified objects. Every object has a unique identifier and has a contiguous location in virtual memory. The number of bytes required by an object is arbitrary, but the memory manager rounds up the allocation size to a multiple of the virtual memory page size. Therefore, the virtual size of an object is always greater than or equal to the actual size of the object. A memory manager (not shown) page aligns large objects in a large object area (LOA) in preparation for a compaction phase of garbage collection that includes remapping virtual memory addresses of the large objects. As used herein, a large object is defined as any object allocation that exceeds a predefined threshold value. For example, MICROSOFT\u00ae Common Language Runtime (CLR) defines a large object as any object allocation exceeding 85K bytes. As used herein, a large object area is defined as a memory address space reserved for large objects. The LOA has a base virtual address. A LOA may be a portion of a heap or a portion of virtual memory in which large objects are stored and segregated from other objects that are not large objects. The boundaries of a large object area are specified by the garbage collector .","System  also includes a kernel driver . Garbage collector  sends a single batched remapping request  to kernel driver  to perform one or more remappings in a single kernel transition. Request  specifies the virtual memory addresses of virtual memory pages on which large objects are aligned, where the virtual memory addresses are to be remapped to perform the compaction of the large objects. Kernel driver  validates the virtual memory addresses included in request  and remaps the virtual memory pages (i.e., remaps the virtual memory addresses) so that the large objects are contiguous in the large object area. In one embodiment, the remapping performed by kernel driver  is facilitated by the kernel driver's direct access to underlying kernel APIs (e.g., ZwMapViewOfSection, ZwOpenSection, ZwUnmapViewOfSection, and ZwClose, which are routines in a kernel mode library that supports kernel mode drivers in the WINDOWS\u00ae Driver Kit (WDK) offered by MICROSOFT\u00ae Corporation located in Redmond, Wash.). The functionality of the components of system  is also described below relative to the discussion of .","Process of Batched Remapping of Virtual Memory Addresses for Garbage Collection in Large Object Areas",{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 2","FIG. 1","FIG. 1","FIG. 1"],"b":["200","110","202","114"]},"In step , the garbage collector  (see ) determines a first set of one or more large objects that a program uses or will use and a second set of one or more large objects that the program is not using and will not use. The garbage collector  (see ) garbage collects the large object(s) that were determined to be in the aforementioned second set. The garbage collection of the large object(s) in step  results in a fragmentation of virtual memory address space, including a fragmentation of large object area  (see ). That is, the garbage collection in step  results in large object area  (see ) including one or more free virtual memory pages (a.k.a. free pages) interspersed among the page-aligned large objects.","In step , the garbage collector  (see ) also identifies and collates the memory remapping that the garbage collector requires for a compaction of page-aligned large objects (e.g., large object  in ) included in large object area  (see ). Collating the memory remapping in step  also includes determining a mapping from the aforementioned object size and address table to a new layout of large objects in the LOA, so that the ranges of virtual memory addresses of the large objects are contiguous in the LOA. In one embodiment, the garbage collector executes the algorithm presented below to accumulate virtual addresses to determine the mapping in step .","Algorithm:",{"@attributes":{"id":"p-0022","num":"0000"},"ul":{"@attributes":{"id":"ul0001","list-style":"none"},"li":{"@attributes":{"id":"ul0001-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0002","list-style":"none"},"li":["Initialize the next virtual address to the LOA base address","Initialize the next large object as a first large object in the aforementioned first set of large object(s)","While there is at least one live large object in the first set that has not been assigned to a virtual address by this algorithm, do the following three steps:\n        \n        "]}}}},"The \u201cAssign\u201d step in the algorithm presented above re-assigns large objects from previously assigned virtual addresses (i.e., the virtual addresses associated with the large objects by the object size and address table) to the virtual addresses determined by the algorithm. Furthermore, the garbage collector may store the virtual addresses assigned by the algorithm in a second table (a.k.a. a remapping table). In step , the garbage collector  (see ) defines a remapping between the large objects in the aforementioned object size and address table and the virtual addresses assigned by the algorithm presented above (e.g., by mapping large objects identified in the object size and address table to the virtual addresses in the remapping table).","In step , garbage collector  (see ) sends batched remapping request  (see ) in a single batch to kernel driver  (see ). Batched remapping request  (see ) indicates virtual memory addresses of virtual memory pages that are to be remapped in the large object area  (see ) according to the remapping defined in step . The remapping of the virtual memory addresses ensures that all large objects in the large object area become contiguous (i.e., the large objects are in contiguous virtual memory locations) and all free pages in the large object area become contiguous. In one embodiment, step  includes the garbage collector  (see ) sending the aforementioned remapping table to the kernel driver  (see ) in a single call. The remapping table may include one or more objects that are no longer required by the program. In one embodiment, the garbage collector omits from the remapping table one or more objects that do not need to be moved (i.e., object(s) that were not re-assigned to different virtual addresses in step ).","In step , kernel driver  (see ) validates virtual memory addresses of virtual memory pages included in batched remapping request  (see ). The validation in step  includes (1) verifying that there are no overlapping objects in the virtual memory address space and (2) verifying that the virtual memory address space of each large object has not changed.","In step , kernel driver  (see ) remaps the virtual memory pages according to the batched remapping request  (see ), which results in the large objects in the large object area  (see ) being contiguous and the free pages in the large object area  (see ) being contiguous. Allocated to each large object are zero or more physical memory pages (or locations in a page file if the large object has been paged out). Each resident physical page has a location in virtual memory. For a large object that is being moved according to the remapping request sent in step , the kernel driver gives each resident physical page of the large object a different location in virtual memory by updating a virtual memory page table through one or more operating system calls.","In one embodiment, the kernel driver  (see ) receives the remapping table in the single call in step  and then makes all of the virtual memory page table changes in one operation. That is, a single kernel transition is performed (e.g., in step ) by loading and executing a kernel driver prior to the kernel driver performing a single operation that makes the multiple virtual memory page table changes in step .","In one embodiment, a kernel transition is a sequence of steps that are required for a thread executing in user mode space  (see ) to transition to executing code in kernel mode space  (see ). A kernel transition may be achieved through a special software interrupt. A kernel transition is relatively slow and therefore it is advantageous in a high performance system to perform as few kernel transitions as possible. Furthermore, the facilities available to code running in kernel mode space  (see ) are more privileged than code running in user mode space  (see ). For example, it is not possible to manipulate virtual memory page tables in user mode space  (see ). An application running in user mode space  (see ) that wants to perform a privileged operation such as manipulating virtual memory page tables in step  must perform a kernel transition and then perform the privileged operation in kernel mode space  (see ). The application that needs to perform a kernel transition loads and executes a set of code (i.e., kernel driver  in ) in kernel mode space  (see ).","The large object area garbage collection that utilizes virtual memory address remapping ends at step .","The post-compaction fix up phase of garbage collection is unaltered by the process of . The application memory must still be scanned to identify large object references that have moved position in memory. The process disclosed herein does not introduce any change to the performance characteristics of the fix up phase of garbage collection.","Table 1 presented below includes the virtual addresses, actual sizes and virtual sizes of four large objects having the identifiers (IDs) , ,  and  (see the description of the object size and address table stored prior to step  in ).",{"@attributes":{"id":"p-0032","num":"0036"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"63pt","align":"center"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"LARGE",{},{},{}]},{"entry":[{},"OBJECT","VIRTUAL","ACTUAL","VIRTUAL"]},{"entry":[{},"ID","ADDRESS","SIZE","SIZE"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"310","VA","AS","VS"]},{"entry":[{},"311","VA","AS","VS"]},{"entry":[{},"312","VA","AS","VS"]},{"entry":[{},"314","VA","AS","VS"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}}},"Garbage collector  (see ) determines that objects having IDs ,  and  are in use by a program, but that the object having ID  is not in use and will not be in use by the program. Garbage collector  (see ) garbage collects the object having ID , which results in virtual memory becoming fragmented, as shown in the virtual memory on the left side of .",{"@attributes":{"id":"p-0034","num":"0038"},"figref":["FIG. 3","FIG. 2","FIG. 3"],"b":["300","302","304","300","306","308","304","310","312","314","310","312","314","310","312","314","304"]},"Virtual memory  includes a large object area , which stores large objects ,  and . The arrows between physical memory locations  and virtual memory  indicate mappings of large object  to large object , large object  to large object , and large object  to large object . For example, the arrow from object  to object  indicates a mapping of a range of memory addresses of object  to a range of virtual addresses of object . The left side of  (i.e., to the left of the arrow labeled \u201cRemap\u201d) illustrates the mappings between physical memory locations  and virtual memory  prior to a remapping performed according to the process of . Virtual memory  to the left of the arrow labeled \u201cRemap\u201d illustrates non-contiguous live pages. For example, there is a free (i.e., unmapped) range of virtual addresses  between object  and object , thereby making the live pages of object  non-contiguous with the live pages of object  (i.e., virtual memory  to the left of the \u201cRemap\u201d arrow is fragmented).","Before the remapping occurs, the algorithm presented above in the discussion of  is executed to perform the following re-assignments and the re-assigned virtual addresses are stored in the remapping table:","VA(see Table 1) is re-assigned as the LOA base address","VA(see Table 1) is re-assigned as the address: LOA base address+VS","VA(see Table 1) is re-assigned as the address: LOA base address+VS+VS","After the garbage collector  (see ) sends a batched remapping request to the kernel driver  (see ) in a single call, where the remapping request specifies the large objects to be remapped according to the remapping table (see step  in ) and after the kernel driver validates the virtual memory addresses in the remapping table (see step  in ), then the kernel driver remaps the large objects by updating the virtual memory page tables according to the remapping table (see step  in ).","The right side of  (i.e., to the right of the arrow labeled \u201cRemap\u201d) illustrates mappings between physical memory locations  and virtual memory  after a remapping performed according to step  in the process of . Virtual memory  to the right of the arrow labeled \u201cRemap\u201d illustrates contiguous live pages resulting from a swap of pages in range  with the pages in object . Virtual memory  to the right of the arrow labeled \u201cRemap\u201d results from a remapping in step  of , in which the object  is remapped to the object in the range of virtual addresses - (a.k.a. object -) (which was the free range of virtual addresses  prior to the remapping) and the address range  is remapped to the range of virtual addresses - (which was the range of virtual addresses for object  prior to the remapping). As illustrated by the virtual memory  to the right of the arrow labeled \u201cRemap\u201d, the remapping in  results in all live pages of the large objects in large object area  being contiguous and all free pages in large object area  being contiguous. That is, the virtual memory  resulting from the remapping of the process of  includes no free pages and\/or uncommitted pages interspersed with the live pages of objects -,  and . The resulting contiguous live pages and contiguous free pages in virtual memory  on the right side of  are attained by the process of  without requiring copying data in memory.","Prototype Code","Compaction through virtual memory remapping is prototyped in this section to explore its performance characteristics. The C++ code in this section shows a piece of physical memory (page file backed) being allocated through the WINDOWS\u00ae API CreateFileMapping. The prototype in this section then maps the allocated memory into the application's virtual address space using MapViewOfFileEx. At any time, the block of memory in the prototype can be unmapped from the address space using UnmapViewOfFile. The code in this section simply tries a few different virtual addresses to map the memory starting at 0x640000.",{"@attributes":{"id":"p-0043","num":"0047"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"HRESULT Commit(ULONG TotalSize)"},{"entry":"{"},{"entry":"\u2003HANDLE hMapping = CreateFileMapping("},{"entry":"\u2003\u2003(HANDLE) 0xFFFFFFFF,\u2003\u2003\/\/ Page file backed block"},{"entry":"\u2003\u2003NULL,\u2003\u2003\u2003\/\/ No security attributes"},{"entry":"\u2003\u2003PAGE_READWRITE,\u2003\u2003\u2003\/\/ Desired access mode"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003\u2003(DWORD) 0,","\/\/ Size high order 32 bits"]},{"entry":["\u2003\u2003TotalSize,","\/\/ Low order 32 size bits"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u2003\u2003(LPCTSTR) NULL);\u2003\u2003\/\/ Unnamed mapping object"},{"entry":"\u2003\/\/ Construct HRESULT from error"},{"entry":"\u2003if (hMapping == NULL) {"},{"entry":"\u2003\u2003DWORD Error = GetLastError( );"},{"entry":"\u2003\u2003HRESULT hr = HRESULT_FROM_WIN32(Error);"},{"entry":"\u2003\u2003return (HRESULT) hr;"},{"entry":"\u2003}"},{"entry":"\u2003LPBYTE pMappedAddress, pStartAddress = (LPBYTE) 0x640000;"},{"entry":"\u2003for (LONG Loop = 0;Loop < 99;Loop++,pStartAddress += TotalSize)"},{"entry":"\u2003{"},{"entry":"\u2003\u2003pMappedAddress = (PBYTE) MapViewOfFileEx("},{"entry":"\u2003\u2003\u2003hMapping,\u2003\u2003\/\/ Previously opened file mapping"},{"entry":"\u2003\u2003\u2003FILE_MAP_WRITE,\u2003\u2002\/\/ Access mode must also match"},{"entry":"\u2003\u2003\u2003(DWORD) 0,\u2003\u2003\/\/ High order 32 bits of the size"},{"entry":"\u2003\u2003\u2003(DWORD) 0,\u2003\u2003\/\/ Also start the mapping at base"},{"entry":"\u2003\u2003\u2003TotalSize,\u2003\u2003\/\/ Total number of bytes to map"},{"entry":"\u2003\u2003\u2003pStartAddress);\u2003\u2002\/\/ Virtual memory start address"},{"entry":"\u2003\u2003if (pMappedAddress != NULL) break;"},{"entry":"\u2003}"},{"entry":"\u2003\/\/ Construct HRESULT from error"},{"entry":"\u2003if (pMappedAddress == NULL) {"},{"entry":"\u2003\u2003DWORD Error = GetLastError( );"},{"entry":"\u2003\u2003HRESULT hr = HRESULT_FROM_WIN32(Error);"},{"entry":"\u2003\u2003return (HRESULT) hr;"},{"entry":"\u2003}"},{"entry":"\u2003return NOERROR;"},{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"Implementing a real large object area garbage collection using the prototype in this section would be inefficient because each of the WINDOWS\u00ae APIs utilized in the prototype requires a separate kernel transition, thereby making the process too expensive for the remapping of many large objects after a collection.","Computer System",{"@attributes":{"id":"p-0045","num":"0049"},"figref":["FIG. 4","FIG. 2"],"b":["400","402","404","406","408","400","410","412","402","400","402"]},"Memory  may comprise any known type of computer data storage media, including bulk storage, magnetic media, optical media, random access memory (RAM), read-only memory (ROM), a data cache, etc. In one embodiment, cache memory elements of memory  provide temporary storage of at least some program code (e.g., code for program ) in order to reduce the number of times code must be retrieved from bulk storage during execution. Moreover, similar to CPU , memory  may reside at a single physical location, comprising one or more types of data storage, or be distributed across a plurality of physical systems in various forms. Further, memory  can include data distributed across, for example, a local area network (LAN) or a wide area network (WAN).","I\/O interface  comprises any system for exchanging information to or from an external source. I\/O devices  comprise any known type of external device, including a display device (e.g., monitor), keyboard, mouse, printer, speakers, handheld device, facsimile, etc. Bus  provides a communication link between each of the components in computer system , and may comprise any type of transmission link, including electrical, optical, wireless, etc.","I\/O interface  also allows computer system  to store and retrieve information (e.g., data or program instructions such as code of program ) from an auxiliary storage device such as computer data storage unit  or another computer data storage unit (not shown). Computer data storage unit  may be a non-volatile storage device, such as a magnetic disk drive (i.e., hard disk drive) or an optical disc drive (e.g., a CD-ROM drive which receives a CD-ROM disk).","Memory  includes computer program code for the program  for large object area garbage collection by virtual memory address remapping (e.g., logic for the process of ). Further, memory  may include other systems not shown in , such as an operating system (e.g., Linux) that runs on CPU  and provides control of various components within and\/or connected to computer system .","Memory , storage unit , and\/or one or more other computer data storage units (not shown) that are operatively coupled to computer system  may store the addresses of large objects in large object area  (see ). The process of  may result in a transformation that: (1) transforms a computer data storage unit from a store of addresses in a large object area that includes non-contiguous large objects to a store of addresses in a large object area that includes only contiguous large objects.","As will be appreciated by one skilled in the art, the present invention may be embodied as a system, method or computer program product. Accordingly, an embodiment of the present invention may be an entirely hardware embodiment, an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to herein as a \u201csystem\u201d (e.g., system  in  or computer system ). Furthermore, an embodiment of the present invention may take the form of a computer program product embodied in any tangible medium of expression (e.g., memory  or computer data storage unit ) having computer-usable program code (e.g., code for program ) embodied or stored in the medium.","Any combination of one or more computer-usable or computer-readable medium(s) (e.g., memory  and\/or computer data storage unit ) may be utilized. The computer-usable or computer-readable medium may be, for example but not limited to, an electronic, magnetic, optical, or semiconductor system, apparatus or device. A non-exhaustive list of more specific examples of the computer-readable medium includes: an electrical connection having one or more wires, a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a portable compact disc read-only memory (CD-ROM), an optical storage device, or a magnetic storage device. Note that the computer-usable or computer-readable medium could even be paper or another suitable medium upon which the program  is printed, as the program  can be electronically captured via, for instance, optical scanning of the paper or other medium, then compiled, interpreted, or otherwise processed in a suitable manner, if necessary, and then stored, respectively, in a computer memory . In the context of this document, a computer-usable or computer-readable medium may be any medium that can store the program for use by or in connection with the instruction execution system, apparatus, or device. The computer-usable program code may be transmitted using any appropriate medium, including but not limited to wireless, wireline, optical fiber cable, radio frequency (RF), etc.","Computer program code (e.g., code of program ) for carrying out operations of the present invention may be written in any combination of one or more programming languages, including an object oriented programming language such as JAVA\u00ae, Smalltalk, C++ or the like and conventional procedural programming languages, such as the \u201cC\u201d programming language or similar programming languages. The program code may execute entirely on a user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. Any one of the aforementioned computers or servers may be computer system . In the latter scenario, the remote computer may be connected to the user's computer through any type of network (not shown), including a LAN, a WAN, or the connection may be made to an external computer (e.g., through the Internet using an Internet Service Provider).","The present invention is described herein with reference to flowchart illustrations (e.g., ) and\/or block diagrams of methods, apparatus (systems) (e.g.,  and ), and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and\/or block diagrams, and combinations of blocks in the flowchart illustrations and\/or block diagrams, can be implemented by computer program instructions (e.g., code of program ). These computer program instructions may be provided to a processor (e.g., CPU ) of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, when executed by the processor of the computer or other programmable data processing apparatus, implement the functions\/acts specified in the flowchart and\/or block diagram block or blocks.","These computer program instructions may also be stored in a computer-readable medium (e.g., memory  or computer data storage unit ) that can direct a computer (e.g., computer system ) or other programmable data processing apparatus to function in a particular manner, such that storing the instructions in the computer-readable medium produces an article of manufacture including instructions which implement the function\/act specified in the flowchart and\/or block diagram block or blocks.","The computer program instructions may also be loaded onto a computer (e.g., computer system ) or other programmable data processing apparatus to cause a series of operational steps to be performed on the computer or other programmable apparatus to produce a computer-implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions\/acts specified in the flowchart and\/or block diagram block or blocks.","Any of the components of an embodiment of the present invention can be deployed, managed, serviced, etc. by a service provider that offers to deploy or integrate computing infrastructure with respect to the process for batched remapping of virtual memory addresses for garbage collection in large object areas. Thus, an embodiment of the present invention discloses a process for supporting computer infrastructure, comprising integrating, hosting, maintaining and deploying computer-readable code (e.g., code of program ) into a computer system (e.g., computer system ), wherein the code in combination with the computer system is capable of performing the process of batched remapping of virtual memory addresses for garbage collection in large object areas.","In another embodiment, the process steps of the invention are provided to customers on a subscription, advertising and\/or fee basis. That is, a service provider, such as a Solution Integrator, can offer to create, maintain, support, etc. processes for batched remapping of virtual memory addresses for garbage collection in large object areas. In this case, the service provider can create, maintain, support, etc. a computer infrastructure that performs the process steps of the invention for one or more customers. In return, the service provider can receive payment from the customer(s) under a subscription and\/or fee agreement, and\/or the service provider can receive payment from the sale of advertising content to one or more third parties.","The flowchart in  and the block diagrams in  illustrate the architecture, functionality, and operation of possible implementations of systems, methods, and computer program products according to various embodiments of the present invention. In this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of code (e.g., code of program ), which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and\/or flowchart illustration, and combinations of blocks in the block diagrams and\/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.","While embodiments of the present invention have been described herein for purposes of illustration, many modifications and changes will become apparent to those skilled in the art. Accordingly, the appended claims are intended to encompass all such modifications and changes as fall within the true spirit and scope of this invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 4","FIG. 2"]}]},"DETDESC":[{},{}]}
