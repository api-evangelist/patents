---
title: System and method utilizing an editing initialization block in a part program editing environment in a machine vision system
abstract: A method is provided for defining and utilizing an editing initialization block for a part program. The part program comprises a plurality of steps for taking measurements of a part and is displayed in an editing interface. An option is provided in the editing interface for selecting which steps are in an editing initialization block. After the part program has been saved, at a later time when the part program is recalled for editing, the editing initialization block may be run before additional steps are added to the part program. At least some of the data that would have been obtained by one or more of the initial part program steps that are not in the editing initialization block may be based on estimated data that is related to (e.g., modified based on) data determined from running the editing initialization block.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09223306&OS=09223306&RS=09223306
owner: Mitutoyo Corporation
number: 09223306
owner_city: Kawasaki-shi
owner_country: JP
publication_date: 20111115
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The invention relates generally to machine vision inspection systems, and more particularly to methods for creating and editing part programs in such systems.","Precision machine vision inspection systems (or \u201cvision systems\u201d for short) can be utilized to obtain precise dimensional measurements of inspected objects and to inspect various other object characteristics. Such systems may include a computer, a camera and optical system, and a precision stage that is movable in multiple directions so as to allow the camera to scan the features of a workpiece that is being inspected. One exemplary prior art system that is commercially available is the QUICK VISION\u00ae series of PC-based vision systems and QVPAK\u00ae software available from Mitutoyo America Corporation (MAC), located in Aurora, Ill. The features and operation of the QUICK VISION\u00ae series of vision systems and the QVPAK\u00ae software are generally described, for example, in the 3, published January 2003, and the 3, published September 1996, each of which is hereby incorporated by reference in their entirety. This product, as exemplified by the QV-302 Pro model, for example, is able to use a microscope-type optical system to provide images of a workpiece at various magnifications, and move the stage as necessary to traverse the workpiece surface beyond the limits of any single video image. A single video image typically encompasses only a portion of the workpiece being observed or inspected, given the desired magnification, measurement resolution, and physical size limitations of such systems.","Machine vision inspection systems generally utilize automated video inspection. U.S. Pat. No. 6,542,180 teaches various aspects of such automated video inspection and is incorporated herein by reference in its entirety. As taught in the '180 patent, automated video inspection metrology instruments generally have a programming capability that allows an automatic inspection event sequence to be defined by the user for each particular workpiece configuration. This can be implemented by text-based programming, for example, or through a recording mode which progressively \u201clearns\u201d the inspection event sequence by storing a sequence of machine control instructions corresponding to a sequence of inspection operations performed by a user with the aid of a graphical user interface, or through a combination of both methods. Such a recording mode is often referred to as \u201clearn mode\u201d or \u201ctraining mode.\u201d Once the inspection event sequence is defined in \u201clearn mode,\u201d such a sequence can then be used to automatically acquire (and additionally analyze or inspect) images of a workpiece during \u201crun mode.\u201d","Video tools (or \u201ctools\u201d for short) and other graphical user interface features may be used manually to accomplish manual inspection and\/or machine control operations (in \u201cmanual mode\u201d). Their set-up parameters and operation can also be recorded during learn mode, in order to create automatic inspection programs, or \u201cpart programs.\u201d Video tools may include, for example, edge\/boundary detection tools, autofocus tools, shape or pattern matching tools, dimension measuring tools, and the like. Other graphical user interface features may include dialog boxes related to data analysis, step and repeat loop programming, and the like. For example, such tools are routinely used in a variety of commercially available machine vision inspection systems, such as the QUICK VISION\u00ae series of vision systems and the associated QVPAK\u00ae software, discussed above.","The machine control instructions including the specific inspection event sequence (i.e., how to acquire each image and how to analyze\/inspect each acquired image) are generally stored as a \u201cpart program\u201d or \u201cworkpiece program\u201d that is specific to the particular workpiece configuration. For example, a part program defines how to acquire each image, such as how to position the camera relative to the workpiece, at what lighting level, at what magnification level, etc. Further, the part program defines how to analyze\/inspect an acquired image, for example, by using one or more video tools such as edge\/boundary detection video tools.","Editing a part program can be a complex task. For example, if a user saves a partially completed part program and has to return at a later time to finish the programming, if changes have occurred in the interim (e.g., changes in environmental conditions, the part being inadvertently moved on the stage, etc.), then the entire part program may need to be rerun before any additional steps are added. A need exists for editing operations and features which overcome these and other deficiencies to allow more efficient, intuitive, and flexible editing of part programs for precision machine vision inspection systems.","This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter.","A method is provided for editing a part program on a machine vision inspection system. The machine vision inspection system includes an imaging portion, a stage for holding one or more parts in a field of view (FOV) of the imaging portion, a motion control portion that moves the imaging portion relative to the stage, a display that displays a user interface (UI), and a controller.","In accordance with one aspect of the invention, the method begins by defining a plurality of initial part program steps and displaying corresponding part program step representations in an editing interface of the user interface. An editing initialization portion is then provided and operated to define at least some of the plurality of initial part program steps as editing initialization steps for the part program. The editing initialization portion is then operated such that when a part program is recalled for editing, if the part program includes defined editing initialization steps then the editing initialization portion performs at least one of (a) prompting the user with a user interface feature indicating the editing initialization steps may be run, and (b) running the editing initialization steps before allowing the addition of steps to the part program.","In accordance with another aspect of the invention, the editing initialization portion can be configured by a user to define the editing initialization steps. In one embodiment, the editing initialization portion comprises a drop down menu that is provided in the editing interface with a selection for defining the editing initialization steps. In one implementation, the set of the editing initialization steps is defined as an editing initialization block which may be determined by the user indicating the last initial part program step that is an editing initialization step.","In accordance with another aspect of the invention, the editing initialization portion comprises an indicator which is at least one of a color bar, a delimiting pointer, or a text highlighting portion. The user may utilize such an indicator to define in the editing interface which of the initial part program steps are editing initialization steps. In one embodiment, when the part program is recalled for editing, a similar indicator is displayed in the user interface to indicate which steps are the editing initialization steps.","In accordance with another aspect of the invention, a pop-up block is provided as the user interface feature which asks the user whether or not the editing initialization steps should be run. In one embodiment, such a user interface feature may be automatically provided to the user at a time when the part program is recalled and an indication is made that additional part program steps are to be added.","In accordance with another aspect of the invention, the editing initialization steps comprise part program steps that move the imaging portion relative to the stage. In one embodiment, such steps may determine at least one of an origin coordinate or an orientation of the part that is used as a reference for measuring other features on the part. In one particular implementation, such steps may reestablish a part coordinate system for the part so as to compensate for any inadvertent movement of the part on the stage since the last part program steps were performed. In one embodiment, initial part program steps that would otherwise move the imaging portion relative to the stage except that they are not editing initialization steps are not run.","In accordance with another aspect of the invention, when a part program is recalled for editing and the editing initialization steps are run, at least some of the data that would have been obtained by one or more of the initial part program steps that are not editing initialization steps may be based on estimated data that is related to (e.g., modified based on) data determined from running the editing initialization steps. In the absence of the defined editing initialization steps, placing such \u201cnon-initialization steps\u201d in an acceptable condition for editing would otherwise require certain time consuming processes (e.g., hardware interactions such as moving the stage, edge detection operations, focusing operations, lighting adjustments, pattern matching, etc.) to be interactively controlled in an awkward and error-prone time consuming manner.","It should be appreciated that providing a simple, time-efficient and robust editing environment for machine vision part programs is significantly more difficult than providing an adequate editing environment for editing simple computer programs, because potentially dangerous motions and mechanical collisions must be revealed and considered during the program editing process. In addition, providing a simple, time-efficient and robust editing environment for editing machine vision part programs is significantly more difficult than providing an adequate editing environment for editing assembly robot programs and the like (e.g., programs which control a robot's geometric motions and actuators, and the like), because unique workpiece geometries and surface finishes require that unpredictable and subtle lighting and imaging effects be revealed and considered and customized during the program editing process. In addition, machine vision inspection systems are required to perform operations that determine relationships between features that are measured and inspected at different locations on a workpiece and at different points in time, by respective operations that may be dispersed throughout a part program. Thus, providing a robust editing environment that allows a relatively unskilled user to edit an existing part program beginning at an arbitrary point within the program is a difficult task. It should be appreciated based on the disclosure herein that the editing initialization portion and methods disclosed herein are of particular utility in contributing to a solution to the combination of problems outlined above, which are unique to providing a time-efficient and robust editing environment for part programs for a general purpose machine vision inspection system.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 1","b":["10","10","12","14","14","16","18","22","24","26","16","10"]},"The vision measuring machine  includes a moveable workpiece stage  and an optical imaging system  which may include a zoom lens or interchangeable lenses. The zoom lens or interchangeable lenses generally provide various magnifications for the images provided by the optical imaging system . The machine vision inspection system  is generally comparable to the QUICK VISION\u00ae series of vision systems and the QVPAK\u00ae software discussed above, and similar state-of-the-art commercially available precision machine vision inspection systems. The machine vision inspection system  is also described in commonly assigned U.S. Pat. Nos. 7,454,053 and 7,324,682, and U.S. Patent Application Publication Nos. 2010\/0158343 and 2011\/0103679, which are each incorporated herein by reference in their entireties.","With regard to the editing of part programs for machine vision systems such as that shown in , the refined editing interface features and related methods disclosed herein, can provide for more efficient, intuitive, and flexible editing operations, particularly for novice or infrequent users.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 2","FIG. 1"],"b":["120","200","100","120","200","200","205","220","230","240","210","212","210","20","205","260","250","280","286","288","205","294"]},"A workpiece , or a tray or fixture holding a plurality of workpieces , which is to be imaged using the machine vision inspection system  is placed on the workpiece stage . The workpiece stage  may be controlled to move relative to the optical assembly portion , such that the interchangeable objective lens  moves between locations on a workpiece , and\/or among a plurality of workpieces . One or more of a stage light , a coaxial light , and a surface light  may emit source light , , or , respectively, to illuminate the workpiece or workpieces . The source light is reflected or transmitted as workpiece light , which passes through the interchangeable objective lens  and the turret lens assembly  and is gathered by the camera system . The image of the workpiece(s) , captured by the camera system , is output on a signal line  to the control system portion . The light sources , , and  may be connected to the control system portion  through signal lines or busses , , and , respectively. To alter the image magnification, the control system portion  may rotate the turret lens assembly  along axis  to select a turret lens, through a signal line or bus .","In various exemplary embodiments, the optical assembly portion  is movable in the vertical Z-axis direction relative to the workpiece stage  using a controllable motor  that drives an actuator, a connecting cable, or the like, to move the optical assembly portion  along the Z-axis to change the focus of the image of the workpiece  captured by the camera system . The term Z-axis, as used herein, refers to the axis that is intended to be used for focusing the image obtained by the optical assembly portion . The controllable motor , when used, is connected to the input\/output interface  via a signal line .","As shown in , in various exemplary embodiments, the control system portion  includes a controller , the input\/output interface , a memory , a workpiece program generator and executor , and a power supply portion . Each of these components, as well as the additional components described below, may be interconnected by one or more data\/control busses and\/or application programming interfaces, or by direct connections between the various elements.","In various embodiments according to this invention, the workpiece program generator and executor  includes an editing portion , which provides or activates various operations and user interface features related to editing a part program, as will be described in greater detail below. It will be appreciated that the terms \u201cworkpiece program\u201d and \u201cpart program\u201d may be used interchangeably herein. In general, the editing portion  includes an editing operations controller  which controls the operations for the editing functions, and an editing interface  that provides the user interface features for the editing functions. The editing operations controller  includes an editing initialization portion  that provides editing initialization features for the editing functions, as will be described in more detail below. The editing initialization portion  includes editing initialization indicators , which define certain editing initialization parameters that are utilized by the editing operations controller , as will be described in more detail below. The editing initialization portion  and the editing initialization indicators  are also linked to the editing interface , wherein indicators are provided in the editing interface of the respective editing initialization parameters and\/or other related parameters.","It will be appreciated that in certain embodiments, the editing initialization indicators  may have certain features and operations similar to those of a video tool. In other words, as will be described in more detail below with respect to , when a user sets one of the indicators, doing so may both define parameters that are utilized by the editing operations controller  (e.g., defining which part program steps are within an editing initialization block), while at the same time providing an indicator in the editing interface  on the screen that indicates the respective parameter (e.g., indicating the final part program step and\/or what part program steps are within an editing initialization block). In certain implementations, certain of the editing initialization indicators  may be provided as user interface features in the editing interface  on the screen that define parameters for, and receive parameters from, a user interaction (e.g., defining which part program steps are within an editing initialization block, receiving an indication from the user as to whether the editing initialization block should be run, etc.).","As shown in , the input\/output interface  includes an imaging control interface , a motion control interface , a lighting control interface , and a lens control interface . The motion control interface  may include a position control element , and a speed\/acceleration control element , although such elements may be merged and\/or indistinguishable. The lighting control interface  includes lighting control elements -, which control, for example, the selection, power, on\/off switch, and strobe pulse timing if applicable, for the various corresponding light sources of the machine vision inspection system .","The memory  includes an image file memory portion , a workpiece program memory portion  that may include one or more part programs, or the like, and a video tool portion . The video tool portion  includes video tool portion and other video tool portions (e.g., ), which determine the GUI, image processing operation, etc., for each of the corresponding video tools. Many known video tools are included in commercially available machine vision inspection systems, such as the QUICK VISION\u00ae series of vision systems and the associated QVPAK\u00ae software, discussed above. The video tool portion  also includes a region of interest (ROI) generator that supports automatic, semi-automatic and\/or manual operations that define various ROIs that are operable in various video tools included in the video tool portion .","In general, the memory portion  stores data usable to operate the vision system components portion  to capture or acquire an image of the workpiece  such that the acquired image of the workpiece  has desired image characteristics. The memory portion  may also store inspection result data, may further store data usable to operate the machine vision inspection system  to perform various inspection and measurement operations on the acquired images (e.g., implemented, in part, as video tools), either manually or automatically, and to output the results through the input\/output interface . The memory portion  may also contain data defining a user interface operable through the input\/output interface .","The signal lines or busses ,  and  of the stage light , the coaxial light , and the surface light , respectively, are all connected to the input\/output interface . The signal line  from the camera system  and the signal line  from the controllable motor  are connected to the input\/output interface . In addition to carrying image data, the signal line  may carry a signal from the controller  that initiates image acquisition.","One or more display devices  (e.g., the display  of ) and one or more input devices  (e.g., the joystick , keyboard , and mouse  of ) can also be connected to the input\/output interface . The display devices  and input devices  can be used to display a user interface, which may include various user interface features that are usable to perform inspection operations, and\/or to create and\/or modify part programs, to view the images captured by the camera system , and\/or to directly control the vision system components portion . In particular, according to various exemplary embodiments of the present invention, the display devices  and input devices  are used to present various user interface features usable to allow efficient, intuitive, and flexible editing of part programs on the machine vision inspection system .","In various exemplary embodiments, when a user utilizes the machine vision inspection system  to create a part program for the workpiece , the user generates part program instructions either by explicitly coding the instructions automatically, semi-automatically, or manually, using a workpiece programming language, and\/or by generating the instructions by operating the machine vision inspection system  in a learn mode to provide a desired image acquisition training sequence. For example, a training sequence may comprise positioning a workpiece feature in the field of view (FOV), setting light levels, focusing or autofocusing, acquiring an image, and providing an inspection training sequence applied to the image (e.g., using video tools). The learn mode operates such that the sequence(s) are captured or recorded and converted to corresponding part program steps (i.e., instructions). These part program steps, when the part program is executed, will cause the machine vision inspection system to reproduce the trained image acquisition and inspection operations to automatically inspect a workpiece or workpieces matching the workpiece used when creating the part program.","Related editing features and functions are also described in patent applications entitled \u201cMachine Vision System Program Editing Environment Including Real Time Context Generation Features\u201d (Ser. No. 13\/297,232); \u201cMachine Vision System Program Editing Environment Including Synchronized User Interface Features\u201d (61\/560,278); and \u201cMachine Vision System Editing Environment For A Part Program In Which A Continuous Stream Of Image Acquisition Operations Are Performed During A Run Mode\u201d (Ser. No. 13\/297,220), each of which is filed concurrently herewith and hereby incorporated by reference.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":["FIG. 3","FIG. 4"],"b":["300","310","351","364","300","320","310"]},{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 4","FIG. 3"],"b":["400","410","415","400","420","440","430","450","460","415","3","4","3","4","2"]},"The following description will make reference to both the initial part program step representations - of , and the corresponding features on the workpiece  of . The part program  begins with the step representations  and , which indicate that the user manually selects a location on the workpiece  to act as a rough origin point ROP, and then aligns the origin to the rough origin point ROP. More specifically, the substeps A, B, C and D indicate that the user sets up and utilizes a manual tool to define the rough origin point ROP and the step representation  aligns the origin with the rough origin point ROP. The step representation  then measures the line XLINE. More specifically, the sub-steps A and B indicate that the user sets up and utilizes a box tool to determine the edge points PTX. The functions and operations of box tools and other edge detection video tools are known in the art and are described in more detail in the previously incorporated references. The edge points PTX that are determined by the box tool are then utilized by the sub-step C to define the line XLINE. Similarly, the step representation  measures the line YLINE, wherein the sub-step A indicates that the user utilizes a box tool to determine the edge points PTY, which are then utilized by the sub-step B to define the line YLINE.","The step representation  then constructs an intersection point XYORIGIN at the intersection of the lines XLINE and YLINE. The step representation  then commands the machine vision system to align the origin to the point XYORIGIN. The step representation  then commands the machine vision system to align the X axis for the workpiece  to the line XLINE. As will be described in more detail below with respect to , and as indicated by the comment line , the operations of the step representations - establish the correct location and orientation of the workpiece  for performing additional measurements.","The step representation  then measures the line L. More specifically, the sub-steps A and B indicate that the user sets up and utilizes a box tool to determine the edge points PT, which are then utilized by the sub-step C to define the line L. Similarly, the step representation  measures the line L, wherein the sub-step A indicates that the user utilizes a box tool to determine the edge points PT, which are then utilized by the sub-step B to define the line L. The step representation  indicates that the user defines a selected position tolerance and the step representation  constructs an intersection point I where the previously determined lines L and L intersect. Once these initial part program steps - have been programmed by a user, the user may elect to set an editing initialization block marker, as will be described in more detail below with respect to .",{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 5","FIG. 3","FIG. 5","FIG. 5","FIG. 5"],"b":["500","310","520","520","530","535","520","357","357","357","540"]},"Once the user designates the step representation  with the editing initialization block marker, this designates that all of the steps preceding and up to step representation  (i.e., step representations -) are editing initialization steps which make up an editing initialization block . The step representation  is therefore determined to be the last initial part program step that is an editing initialization step. In one embodiment, an editing initialization indicator may be provided in the editing interface  that indicates that each of the step representations - are editing initialization steps. In the specific example illustration of , a color bar  (shown with cross hatch) is provided next to the step representations - to indicate that they are in the editing initialization block . In alternative embodiments, other editing initialization indicators may be utilized for indicating the editing initialization steps (e.g., a delimiting pointer, delineating markers, highlighting of the actual steps rather than a bar next to the steps, etc.). In one embodiment, when the part program  is saved, the indication of which steps are editing initialization steps is also saved.","In some embodiments, the editing initialization steps comprise part program steps that move the imaging portion relative to the stage. For example, as shown in , the step representations A, B and A may involve steps that move the imaging portion relative to the stage.","It will be appreciated that the remaining initial part program step representations - which follow the editing initialization block marker indicated by the selector box  and which are therefore not included in the editing initialization block , may not be run in the same manner when the editing initialization block  is run, as will be described in more detail below. In one embodiment, the step representations - are designated as being in a remaining steps block .","As will be described in more detail below, in one embodiment, the editing initialization block  may be utilized to address certain changes in conditions that may occur during the editing process for a part program. For example, if after a user saves a part program, the user leaves the work station and returns at a later time, in the interim certain changes may have occurred (e.g., the part being inadvertently moved on the stage, etc.) that may affect the editing of the part program. However, due to the amount of time that may be required for rerunning all of the previous steps of a part program (particularly those steps that require certain time-consuming processes such as hardware interactions, etc.), a user may desire to only rerun the steps that are required for establishing the desirable conditions for continuing the edits. In accordance with the present invention, a user may designate the editing initialization block  which comprises steps that have been determined to be necessary for returning to the desirable conditions for continuing the edits. The editing initialization steps of the editing initialization block  comprise initial part program steps that will reestablish a part coordinate system for the part, so as to compensate for any inadvertent movement of the part on the stage since the last part program steps were performed.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 6","FIG. 3","FIG. 6","FIGS. 7 and 8"],"b":["600","310","620","620","630","630","630","550","630","550","310"]},"It will be appreciated that in an alternative embodiment, the editing initialization block  may be set to run automatically when the part program  is recalled for editing. In one implementation, this may be done by a default setting, or a user may be provided with an option when the part program is saved for whether or not to have the editing initialization block run automatically when the part program is recalled for editing. In certain implementations, it may be desirable to not have the editing initialization block be run automatically (e.g., it may be startling to a user if the machine vision system begins to move on its own without any prompting or warning, etc.).",{"@attributes":{"id":"p-0055","num":"0054"},"figref":["FIG. 7","FIG. 3","FIG. 8"],"b":["700","310","770","771","774","550","550","771","774"]},{"@attributes":{"id":"p-0056","num":"0055"},"figref":["FIG. 8","FIG. 7","FIG. 8"],"b":["800","415","550","550","415","415","351","357","415","415","310","550","415"]},"In contrast, in one embodiment, the initial part program steps - in the remaining steps block , which are not editing initialization steps, are not run in the same manner. Instead, in certain implementations, estimated sets of points PT\u2032 and PT\u2032 may be provided based on the relative locations of those points as determined from the initial performance of the part program steps - as illustrated in . In other words, the relative locations of the points PT and PT in  (e.g., as referenced to the point XYORIGIN) are saved when the part program  is initially performed and saved. Thereafter, when the part program  is recalled for editing and the editing initialization block  is run so as to reestablish the location of the point XYORIGIN as shown in , rather than also reestablishing the locations of the points PT and PT, the previously saved relative locations to the point XYORIGIN are used to determine the locations of the estimated points PT\u2032 and PT\u2032.","In other words, the locations of the estimated points PT\u2032 and PT\u2032 may not be based on the running of the sub-steps A, B, and A, all of which require hardware interaction and edge detection and would take a relatively long time to perform. In one embodiment, any sub-steps which are not in the editing initialization block and which would generally require certain designated time-consuming operations (e.g., hardware interactions such as moving the stage, edge detection, focusing, lighting changes, pattern matching, etc.) are not performed. Instead, any resulting data (e.g., redetermined edge points, etc.) that would have been provided is based on estimated data (e.g., the locations of the estimated points PT\u2032 and PT\u2032 relative to the point XYORIGIN). As noted above, the correct location of the point XYORIGIN has been reestablished by running the editing initialization block .","It will be appreciated that by not running certain designated time consuming sub-steps, significant time savings may be achieved. This is due to the fact that such processes may take a relatively long time to perform, particularly in comparison to processes which only require calculations to be performed by the controller of the machine vision system. It will be appreciated that while in the example of  only a few such sub-steps (e.g., sub-steps A, B, and A) of this type have been illustrated, in a more detailed part program, significantly more sub-steps of this type may be utilized, for which the time savings may be significant.","In one embodiment, the sub-steps C and B (which do not require relatively time-consuming operations and only require the relatively fast processing of the controller of the machine vision system to utilize the estimated points PT\u2032 and PT\u2032 to establish the locations of the estimated lines L\u2032 and L\u2032) may still be run when the editing initialization block  is run. Similarly, the additional step representation  (which only requires the relatively fast processing of the controller) may also be run to determine the estimated intersection point I\u2032 at the intersection of the estimated lines L\u2032 and L\u2032. It will be appreciated that the calculations performed by the sub-steps C, B and  are all of a type that can be performed relatively quickly on the estimated edge points PT\u2032 and PT\u2032, without requiring significant time or input from the user. Thus, certain portions of the initial part program steps - in the remaining steps block  may also be run (e.g., to establish certain additional part features that may be used for additional part program step measurements) when the editing initialization block  is run.","With regard to the additional part program step representations - that are added to the part program  so as to create the edited part program , the specific operations of the step representations will also be described with respect to . As shown in , the step representation  measures a line L. More specifically, the sub-steps A and B indicate that a user sets up and utilizes a box tool to determine the edge points PT, which are then utilized by the sub-step C to define the line L. Similarly, the step representation  measures a line L, wherein the sub-step A indicates that the user utilizes a box tool to determine the edge points PT, which are then utilized by the sub-step B to define the line L.","The step representation  determines an intersection point I at the intersection of the lines L and L. The step representation  determines a distance D between the intersection point I and the estimated intersection point I\u2032 that was determined at the step representation . It will be appreciated that the step representation  thus illustrates how a new measurement of the distance between the intersection point I and the estimated intersection point I\u2032 may rely on the estimated positions provided after the running of the editing initialization block . More specifically, the location of the estimated intersection point I\u2032, which as described above was able to be determined relatively quickly and with a reasonable assurance of accuracy based on the running of the editing initialization block , can be utilized for the new distance measurement D to the intersection point I.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 9","b":["900","910","920","930","940"]},"While various preferred and exemplary embodiments of the invention have been illustrated and described, it will be appreciated that various changes can be made therein without departing from the spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF THE DRAWINGS","p":["The foregoing aspects and many of the attendant advantages of this invention will become more readily appreciated as the same become better understood by reference to the following detailed description, when taken in conjunction with the accompanying drawings, wherein:",{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 5","FIG. 3"]},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 6","FIG. 3"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 7","FIG. 3"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
