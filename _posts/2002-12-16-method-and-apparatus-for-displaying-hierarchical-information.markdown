---
title: Method and apparatus for displaying hierarchical information
abstract: A method of visualizing and exploring tree structures whose interior nodes represent substantial amounts of logically related textual information. The method includes methods for partitioning tree-structured textual material into topically related clusters of adjacent items, then developing digests of each cluster. The digests include both shorter overviews and arbitrarily long summaries. The tree-structured material involved could be for example, but is not limited to, trees containing the messages and postings of an archived discussion within a newsgroup, discussion list, or on-line forum. This invention also provides methods for partitioning a two-dimensional tree visualization, called a treetable, into conveniently sized segments for detailed exploration.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07111253&OS=07111253&RS=07111253
owner: Palo Alto Research Center Incorporated
number: 07111253
owner_city: Palo Alto
owner_country: US
publication_date: 20021216
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","INCORPORATION BY REFERENCE","BACKGROUND","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This patent application is related to:","U.S. patent application Ser. No. 10\/321,416, titled \u201cA Method and Apparatus for Normalizing Quoting Styles in Electronic Mail\u201d, by Newman, filed concurrently herewith,","U.S. Pat. No. 7,007,069, titled \u201cA Method and Apparatus for Clustering Hierarchically Related Information\u201d, by Newman et al. filed concurrently herewith,","U.S. patent application Ser. No. 10\/321,420, titled \u201cA Method and Apparatus for Generating Overview Information for Hierarchically Related Information\u201d, by Newman et al. filed concurrently herewith,","U.S. Pat. No. 7,031,970, titled \u201cA Method and Apparatus for Generating Summary Information for Hierarchically Related Information\u201d, by Blitzer filed concurrently herewith, and","U.S. patent application Ser. No. 10\/320,930, titled \u201cMethod and Apparatus for Segmenting Hierarchical Information for Display Purposes\u201d, by Newman filed concurrently herewith.","The following patents and\/or patent applications are herein incorporated by reference:","U.S. patent application Ser. No. 09\/732,024, titled \u201cMethod and System for Presenting Email Threads as Semi-connected Text by Removing Redundant Material\u201d, by Paula Newman and Michelle Baldonado, filed Dec. 8, 2000.","U.S. patent application Ser. No. 09\/732,029, titled \u201cMethod and System for Display of Electronic Mail, by Paula Newman, filed Dec. 8, 2000","U.S. patent application Ser. No. 09\/954,388, titled \u201cMethod and Apparatus for the Construction and use of Table-like visualizations of Hierarchic Material, by Paula Newman and Stuart Card, filed Sep. 10, 2001","U.S patent application Ser. No. 09\/954,530, titled \u201cMethod and Apparatus for the Viewing and Exploration of the Content of Hierarchical Information, by Paula Newman and Stuart Card, filed Sep. 10, 2001.","U.S. patent application Ser. No. 09\/717,278, titled \u201cSystems and Methods for Performing Sender-Independent Managing of Electronic Messages, by Michelle Baldonado, Paula Newman, and William Janssen, filed Nov. 22, 2000","U.S. patent application Ser. No. 09\/732,028 titled \u201cMethod and System for presenting semi-linear hierarchy displays\u201d by Paula Newman, filed Dec. 8, 2000","U.S. patent application Ser. No. 09\/747,634, titled \u201cSystem and Method for Browsing Node-Link Structures Based on Estimated Degree of Interest\u201d, filed on Dec. 12, 2000 by Stuart Card","U.S. patent application Ser. No. 10\/103,053, titled \u201cSystems and Methods for Determining the Topic Structure of a Portion of a Text\u201d by Ioannis Tsochantaridis, Thorsten Brants, and Francine Chen, filed Mar. 2, 2002","U.S. patent application Ser. No. 10\/164,587, titled \u201cAuthoring Tools, Including Content-Driven Treetables for Fluid Text\u201d by Polle Zellweger, Paula Newman, and Maribeth Back (D\/A2017)","The present invention relates generally to the field of information analysis and display. More specifically, it provides methods for partitioning tree-structured textual material into topically related clusters of adjacent items, then developing digests of each cluster. The digests include both shorter overviews and arbitrarily long summaries. The tree-structured material involved could be for example, but is not limited to, trees containing the messages and postings of an archived discussion within a newsgroup, discussion list, or on-line forum. This invention also provides methods for partitioning a two-dimensional tree visualization, called a treetable, into conveniently sized segments for detailed exploration. The segments may be grouped into regions corresponding to the topically related clusters.","To establish some terminology, a \u201ctree\u201d or \u201ctree structure\u201d is a standard term denoting an abstract data structure that models information as a set of nodes connected by directed edges such that: (a) there is exactly one element having no incoming edges, called the \u201croot\u201d; and (b) all other nodes have exactly one incoming edge. A leaf node is a node with no outgoing edges. All nodes besides the root node and the leaf nodes can be called \u201cinterior nodes\u201d. The \u201cparent\u201d of a node is the source of its incoming edge, and the \u201cchildren\u201d of a node are the targets of its outgoing edges. A \u201csubtree\u201d of a tree is a set of nodes consisting of a \u201csubtree root\u201d node that has no parent in the subtree, and other nodes all having parents in the subtree.","The present invention is intended for use in connection with tree structures whose interior nodes represent substantial amounts of logically related textual information. For example, in the tree-structures formed by archived discussions, the nodes represent individual messages or contributions, and a message represented by a child node is a response to the message represented by its parent. The creation of the parent-child links in archived discussions can be established by a combination of conventional means utilizing header information, and deeper means, as described in U.S. patent application Ser. No. 09\/732,024, titled \u201cMethod and System for Presenting Email Threads as Semi-connected Text by Removing Redundant Material\u201d, by Paula Newman and Michelle Baldonado, incorporated by reference hereinabove.","Tree-structured archived discussions on a particular subject are usually represented for exploration by indented lists. Each contribution is represented by some identification information, such as contributor name and date, indented under the identification information for its parent. The individual contributions may then be accessed for reading by selecting one of the list items. However, archived discussions pay varying amounts of attention to the ostensible subject and initial contribution, and often branch into several subtopics, so the reader cannot assume, based only on the ostensible subject, whether any portion of the discussion is actually of interest, and, if so, what parts of the discussion. A more informative representation of the overall content of an archived discussion is described in U.S. patent application Ser. No. 09\/732,029, titled \u201cMethod and System for Display of Electronic Mail, by Paula Newman, incorporated by reference hereinabove. In that representation, initial substantive fragments of each contribution, containing actual text of the message rather than quotes or quote introduction, are embedded within a reduced-width linear tree tailored to text embedding. This representation is suitable as a level of presentation of the discussion, and also as the content of an emailed digest summarizing activity in the discussion list, or as a client side digest of such activity. Client-side accumulation of email from discussion lists, involving concatenating, or sampling, messages from all mail received in a particular period, is introduced in U.S. patent application Ser. No. 09\/717,278, titled \u201cSystems and Methods for Performing Sender-Independent Managing of Electronic Messages, by Michelle Baldonado, Paula Newman, and William Janssen, incorporated by reference hereinabove.","Yet another method of representing the overall content of an archived discussion is described in U.S. patent application Ser. No. 09\/954,388, titled \u201cMethod and Apparatus for the Construction and use of Table-like visualizations of Hierarchic Material, by Paula Newman and Stuart Card, and U.S. patent application Ser. No. 09\/954,530, titled \u201cMethod and Apparatus for the Viewing and Exploration of the Content of Hierarchical Information, by Paula Newman and Stuart Card, both incorporated by reference hereinabove. In this method, the conversation tree is presented in a two dimensional tabular form called a \u201ctreetable\u201d. In such a treetable, each cell represents a single node and exactly spans the cells representing its children if any, and a substantive initial fragment of the message associated with the node is displayed in the cell, to the extent that space allows. The individual columns and subtrees of the treetable may be selected for expansion (reducing other parts of the tree), to view more of the associated texts, and the full texts of each column may be selected for display in auxiliary windows or frames. (Note that a similar representation is described in an article entitled \u201cStructured Graphs: a visualization for scalable graph-based case tools\u201d by M. Sifer and J. Potter, in the Australian Computer Journal, Volume 28 Number 1, and also in later papers authored by M. Sifer and other colleagues, but in these references the potential of the structure is not exploited for purposes of exploring trees whose nodes have associated significant text.)","While the latter two methods (reduced-width linear trees and treetables) with embedded initial fragments are useful methods of providing overviews for smaller discussions and other tree-structured textual material, they are less useful for larger discussions. For example, for a stored conversation consisting of 93 messages, a reduced-width linear tree containing initial fragments requires over 11 standard-size display windows. Alternatively, if such a conversation is represented in a treetable that can be contained in a single window, the cells are too small to contain any indicative content, and there are too many columns to expand individually to determine if there is content of interest.","Therefore, more accessible digests of such larger discussions are needed. Current approaches to text processing address some related problems. Methods have been developed for segmenting individual documents into extents dealing with different approximate subtopics, and for identifying the topics covered by the most indicative words, as described in U.S. patent application Ser. No. 10\/103,053, titled \u201cSystems and Methods for Determining the Topic Structure of Portion of a Text\u201d by Ioannis Tsochantaridis, Thorsten Brants, and Francine Chen, incorporated by reference hereinabove. Methods have also be developed for summarizing identified topic extents by collections of extracted sentences, and for associating summary elements with the text extents covered, as described, for example, in a paper by Branimir Boguraev and Mary Neff entitled \u201cDiscourse Segmentation in Aid of Document Summarization\u201d, in the Proceedings of the Hawaii International Conference on System Sciences (2000). Methods have also been developed for summarizing collections of separate documents by grouping them by topic, generally using centroid-based clustering methods, and then extracting sentences dealing with each topic. An example of such an approach is described by Dragomir Radev, Hongyan Jing, and Malgorzata Budzikowska in the paper \u201cCentroid-based summarization of multiple documents: sentence extraction\u201d in the 2000 (Seattle, Wash., April 2000) pages 21\u201329. However, tree-structured discussions are neither single documents nor collections of independent documents, and specialized methods are needed for their segmentation and summarization.","Two limited approaches seem to have been developed, to date, relating to segmenting tree-structured discussions, but none, as far as can be ascertained at this time, to summarizing those discussions. A paper by K. Tajima, Y. Mizuuchi, M. Kitagawa, and K. Tanaka entitled \u201cCut as a querying unit for WWW, Netnews, and E-mail\u201d, in the Proceedings of the 9ACM Conference on Hypertext and Hypermedia (1998) descries a method for identifying overlapping subtrees of a discussion as units of information retrieval, to put retrieved messages into a useful context. The clustering method processes the thread tree bottom-up and, at each step, combines a parent with currently open child subtrees, separately or together, if the similarity between the parent word vector and the centroid vector of the child subtree or subtrees exceeds an (unspecified) absolute input threshold. The word vectors used to represent the vectors handle quoted passages by reducing the weights of quoted words, in order to keep inter-message distances from being too small. While no results are given, if the threshold is set relatively high, this method would probably lead to shallow subtrees, suitable as query results. However, it is unlikely that the method would lead to clustering results suitable for subtopic identification or digesting. Based on our experiments, quoted words require more detailed treatment, and some trials of a similar single-link clustering method using distances between a node and the centroid of an adjacent cluster produced unsatisfactory results.","Another approach related to discussion tree segmentation is described in a paper by H. Ozaku, K. Uchimoto, M. Murata, and H. Isahara entitled \u201cTopic Search for Intelligent Network News Reader HISHO\u201d, in the Proceedings of the 2000 ACM Symposium on Applied Computing. This paper describes a method for retrieving many discussions relating to a query topic, and then attempting to filter out discussion subtrees irrelevant to the topic. The method uses, for the most part, noun keywords to represent messages, and tries to find \u201ctopic changing articles\u201d where the proportion of never-seen-keywords shifts, and \u201ctopic branching articles\u201d where a message gives rise to several responses distinguished by their keyword usage and their referenced quotes. This strategy is reported as of limited success in finding topic-changing articles (recall=57%) and larger success in finding topic branching articles.","The present invention incorporates methods of dividing a tree-structured discussion into major subtopics, and of developing digests containing segments for each such subtopic. Two types of digests are developed, that may be inspected in sequence. Shorter digests, which we will call \u201coverviews\u201d, choose a set of texts in each subtopic based on topic-relevance and potential for providing coherent sequences, and represent each such text by one or more extracted sentences. Potentially longer digests, which we will call \u201csummaries\u201d, choose a set of extracted sentences representing a proportion of the text associated with a subtopic, by a combination of features resting on inherent properties of the sentences, and on the content of a developing summary.","The present invention also provides methods for pre-segmenting a large tree or treetable for purposes of visualization and deeper exploration of individual nodes, with the segments sized so as to allow inclusion of at least some amount of content-indicative text for each node. There have been many approaches developed to allow investigation of detailed areas of large visualizations, usually distinguished as either \u201cfisheye\u201d approaches, that expand part of visualization at the expense of other parts, or \u201cfocus plus context\u201d approaches that extract and expand part of visualization into another window. Some examples of these approaches as applied to trees and treetables are: (a) in-situ expansions of nodes in the neighborhood of a selected node within a \u201cDegree of Interest Tree\u201d, described in U.S. U.S. patent application Ser. No. 09\/747,634, titled \u201cSystem and Method for Browsing Node-Link Structures Based on Estimated Degree of Interest, by Stuart Card, incorporated by reference hereinabove, (b) in-situ expansion of treetable columns and complete subtrees (all nodes descended from a given node, and extraction of sets of columns and complete subtrees into another window, as described in U.S. patent application Ser. No. 09\/954,388, titled \u201cMethod and Apparatus for the Construction and use of Table-like visualizations of Hierarchic Material, by Paula Newman and Stuart Card, incorporated by reference hereinabove, and (c) iterative restriction of the display to subtrees or user-defined sets of nodes, is provided in a treetable-like visualization described in the papers \u201cThe SGF metadata framework and its support for social awareness on the World Wide Web\u201d, by O. Liechti et.al. in World (Baltzer), 1999. 2(4., and \u201cM. Sifer and O. Liechti, \u201cZooming in One Dimension Can Be Better Than Two: An Interface for Placing Search Results in Context with a Restricted Sitemap\u201d by M. Sifer and O. Liechti, In Proceedings of the 1999 IEEE Symposium on Visual Languages (Tokyo, Japan) 72\u201379.","These methods all have some problems when used in connection with large trees. In-situ expansion of neighborhoods, columns, or subtrees can be disorienting when the expanded nodes are to contain significant amounts of text, because the shape of the tree changes dramatically, and little space is left for unexpanded nodes. Also, for large trees, subtree extraction (or restriction of the display to a subtree) tends to be an iterative process. This may be suitable when the tree represents a generalization hierarchy, so that higher level nodes provide good cues as to the content of lower level ones, but not otherwise, for example when the trees represent discussions, or the network of linked nodes on a website, reduced to a tree by removing cyclic paths. Finally, leaving the specification of sets of nodes to be extracted to users is problematic both because it is laborious, and because successive extractions are still generally needed to make sufficient node-identification information visible to permit an intelligent selection.","For this reason, the methods provided in this invention pre-partition a tree or treetable into segments of related nodes whose approximate maximum dimension permits significant text to be presented for each node. The segments can be visually differentiated in an outline depiction of the tree or treetable as a whole, and individual segments then extracted for deeper exploration. The segments may also be constrained to represent only nodes within the same logical grouping, which may be an identified subtopic, or collection of less-focused material, or other type of grouping. When the segments are so constrained, regions of adjacent segments associated with each such grouping can also be visually differentiated from other such regions.","The method for partitioning is related to, but different from, the large body of work on partitioning graphs (collections of nodes linked by edges, but not necessarily hierarchic) into a roughly equal-size subgraphs, given either the number of subgraphs to be found or a maximum size per subgraph, and possibly some additional constraints on the subgraphs, with the purpose being to minimize the number of edges between subgraphs. Much of the work derives from an algorithm described by B. W. Kernighan and S. Lin in the paper \u201cAn efficient heuristic procedure for partitioning graphs\u201d, in , 49(2) 1970, in which a greedy algorithm obtains an initial partitioning, and then nodes are iteratively moved among subgraphs to improve the quality of the partition. Such methods have applications in VLSI design, distribution of processes and data among processors, and sparse matrix representations. The problem addressed by the methods of the present invention is different, in that the permissible subgraphs are far more constrained; subgraphs must represent either subtrees or sets of subtrees whose roots have a common parent (and sometimes are part of the same logical grouping), and must largely respect a given layout dimensionality. This, in turn, permits the careful initial partitioning algorithm described in this invention to be sufficient to the purpose.","Further advantages of the invention will become apparent as the following description proceeds.","Briefly stated and in accordance with the present invention, there is provided a method for partitioning a tree-structured discussion or other tree structured collections of texts into clusters dealing with identifiable subtopics, if such subtopics exist, or into manageable partitions if not. The partitioning method uses a variant of a standard method of agglomerative, single link (\u201cnearest neighbor\u201d) clustering described by G. Salton in , Addison Wesley (1989). In that method, each document is represented by a vector containing one position for each unique word to be taken into account in the combined texts, and is initially placed in a cluster containing only that document. Then a sequence of cluster combinations is performed, at each step combining the most similar two clusters, where the most similar two clusters are the clusters related by the most similar pair of document vectors, into a new cluster. The process can be halted before all clusters are combined based on application-specific criteria. In the partitioning method of this invention, the vector positions for a particular node are generally also filled in well known ways, namely, by \u201cstemming\u201d the words of the associated text, to lemma (root word) forms, and ignoring words occurring in a \u201cstop list\u201d of very common words, and representing each word by a tf.idf weighted frequency (a weighting of a term frequency tf by the \u201cinverse document frequency\u201d idf, which is basically the quotient of the number of documents in a collection divided by the number of documents in which the word appears, thus giving preference to words occurring less frequently in the collection, and has many variations, also described by Salton in . Addison Wesley (1989)","The word vectors can also optionally be converted into vectors reflecting some semantic relationships, by methods such as Probabilistic Latent Semantic analysis (PLSA), as described by Thomas Hofmann in the paper titled \u201cProbabilistic Latent Semantic Indexing\u201d, in '99 (Berkeley, Calif., August 1999) 50\u201357.","However, the clustering method is unique to grouping tree-structured texts, especially message texts, both in processing that occurs before. constructing word vectors, and within the clustering process proper. In this invention, before constructing the word vector for a node,\n\n","It should be noted that this type of message adjustment is also suitable for use in representing message content for other applications, for example, in finding messages dealing with a particular topic, or finding inter-conversation topic groupings via centroid-based clustering methods.","The other divergences from standard clustering practice are within the clustering process proper. First, the inter-node relationships considered in the single-link clustering are restricted to parent-child and sibling relationships within the tree, so that a cluster consists either of a subtree, or of several subtrees whose roots have a common parent external to the cluster. Second, the final clusters used for summary purposes are isolated in the following tree-specific ways:\n\n","After clustering for digesting purposes is halted, clusters are selected that probably represent subtopics and are closed to further combination. The selection may be based on a function of the number of nodes in the cluster and in the tree as a whole. Not all such clusters may actually be represented in a displayed digest, which may further select among the subtopic-associated clusters based on absolute and tree-relative cluster size and other factors such as average text lengths. Clustering then continues to obtain secondary clusters that form less-closely related \u201ccollections\u201d, which can also be reflected as regions within a partitioned treetable. The results of such a clustering, as reflected in a segmented treetable, are shown in , discussed hereinbelow.","Two methods are also provided for digesting the content of individual clusters. One method, which obtains relatively short overviews, selects a proportion of representative nodes from the cluster, and then extracts and organizes one or more sentences from the text associated with each selected node. For text trees representing archived discussions, the basic intuition underlying the selection of nodes and sentences is that comment\/response sequences drawn from lexically central nodes will capture those aspects of the discussion considered most important to discussion participants.","The nodes are selected based on their centrality to all or part of the cluster, and also for their potential for providing some degree of fluency in reading. They comprise central nodes and auxiliary nodes. Central nodes comprise\n\n","Auxiliary nodes are generally non-central nodes that are parents of central nodes or parents having more than a given number of children. It is from these nodes that passages quoted in central nodes, or in many nodes, will be drawn; thus auxiliary nodes both fulfill the coverage potential of their more central children, as well as supplying continuity. For some clusters, specifically those containing or descending from the root of the entire conversation, auxiliary nodes may also include the root text and a proportion of its children. This allows the overview to be more informative with respect to what is generally the most important topic of the discussion.","The total number of nodes represented in the overview is determined by the number of central nodes selected, and the number of auxiliary nodes added for any of the reasons given above.","After nodes are selected to represent a cluster, sentences are extracted from their associated texts for use in the overview so as to provide coherent comment\/response sequences. The sentences extracted depend on the whether the node is a central node or an auxiliary node. For all selected nodes, if the associated text been has been quoted, sentences are extracted that correspond to the most germane quote (or quotes, depending on an input parameter) in each of the texts associated with each of its child nodes. In the current embodiment, a germane quote is a quote preceding a relatively long non-quoted sequence. Also,\n\n","If an extracted sentence is very short it is extended with additional text material, using material to the left if it is a quoted sentence, and to the right if not.","After sentences are extracted to represent a node they are sorted based on their position in the text associated with a node, duplicates are eliminated, and the remaining sentences are concatenated into a string representing the node in the overview, with intervening gap indicators such as ellipsis symbols \u201c. . . \u201d to represent sentences in the text not included in the overview. These strings are then arranged in the tree order of the cluster to form the cluster overview, using either a reduced width tree, such as shown in , representing a completed overview for a discussion, or an indented tree, such as shown in , representing the part of the summary (see below) associated with group  of the same discussion. In both cases, the cluster overview may be prefaced with a list of the most frequent words occurring in the cluster, that serve to further illustrate the concerns of the cluster. The word lists are obtained by standard methods, e.g., by adding the idf-weighted word-vectors obtained for each text within the cluster and then selecting the words having the largest value in the resultant sum vector.","Another cluster digesting method is also provided that can obtain longer, more readable, and more informative summaries of clusters whose contained texts are well focused and longer. This method selects a percentage of the sentences associated with nodes in the cluster, in the current embodiment 10%, or, or, to accommodate to clusters containing many short texts, a percentage of the nodes in the cluster, in the current embodiment 60%, whichever number is larger, to obtain reasonably sized, informative summaries. The sentences are selected from the cluster as a whole using a staged, feature based method that builds on methods well known to practitioners of the art, such as the methods described by M. White, and C. Cardie, C. in the paper \u201cSelecting sentences for multi-document summaries using randomized local search\u201d, in the 2002 (Philadelphia, Pa., July 2002). However, many of the features used, and the specifics of the staging, are specific to obtaining coherent summaries of tree-structured discussions.","The method initially assigns an intrinsic score to each sentence based on its lexical centrality in the cluster, its ordinal position in its containing text, and the number of nodes in the tree descended from the node associated with that text in the tree, and chooses the sentence with the best intrinsic score as the first sentence to be included in the summary. Then the process iterates until the desired number of summary sentences is found. In each iteration, each not-yet-chosen sentence is given an extract score that modifies its intrinsic score by features concerned with the relationship of the sentence to sentences already in the extract, and the sentence with the highest extract score is added to the summary. The conventional features used to form the extract score measure the adjacency of the sentence being tested to sentences already in the summary (adjacency being desirable), and the redundancy of the sentence with sentences in the summary (redundancy being undesirable). The discussion specific features used in the process test whether the sentence is from a node that is a parent or child of a node already represented in the summary, and whether the sentence is quoted immediately before a sentence in the summary, or immediately follows a quote of a sentence represented in the summary. After the summary sentences are chosen by this method, they are organized in the same way as sentences in the overview, as described above","A method is also provided for dividing a tree of texts into segments for purposes of visualization within a display window or frame, with each segment either a subtree or a set of subtrees whose roots have the same parent external to the segment, and each segment sized such that extracting a visualization of the segment into another window or frame permits significant text to be associated with each node in the segment. The segments may also be constrained to be associated with the same logical grouping of nodes, which may be a cluster obtained by the method described hereinabove, or some other logical grouping, such as the set of nodes associated with a given time period.","The division of the tree into segments may be obtained by a method that operates bottom up within the tree. A desirable maximum width and height is set for segments. Then for each node in the tree, starting with the leaves and not processing a node until all of its children have been processed, the method proceeds as follows:\n\n","Companion methods are also provided to visualize and explore the result of the segmentation. The visualizations place a two dimensional representation of the full tree in either a classic \u201cnode plus edge\u201d representation, or a treetable representation, in one window or frame, and a representation of a selected segment in another window or frame. The visualization of the full tree may take one of several forms. It may be an outline treetable in which all cells are represented. In that case, the segments, as well as collections of adjacent segments within the same logical grouping, which we will call regions, can be visually differentiated as shown in , by visually separating regions, and differentiating segments within the same region by heavy outlining and or different cell backgrounds. Alternatively, the visualization of the full tree may be in the form of an abstracted segmented tree or treetable in which entire segments are represented as nodes, visually grouped into regions, and represented as a standard treetable, or a classic \u201cnode+edge\u201d tree representation, or as a content-driven treetable as described in U.S. patent application Ser. No. 10\/164,587, titled \u201cAuthoring Tools Including, Content-Driven Treetables for Fluid Text\u201d by Polle Zellweger, Paula Newman, and Maribeth Back (D\/A2017) incorporated by reference hereinabove.","While the present invention will be described in connection with a preferred embodiment and\/or method of use, it will be understood that it is not intended to limit the invention to that embodiment and procedure. On the contrary, it is intended to cover all alternatives, modifications and equivalents as may be included within the spirit and scope of the invention as defined by the appended claims.","Turning now to the figures, this embodiment of the invention presents a discussion list review tool using overviews, summaries, and segmented treetable visualizations for the exploration of long discussions.  illustrate some summary and overview material produced by the methods making up the invention. The texts underlying these figures represent messages of the Usenet rec.motorcycles newsgroup.  illustrate aspects of the segmented treetable visualization. The visualizations are obtained by submitting display specifications to a display processor. In this case an Internet Explorer browser was utilized. However, the methods of the invention can be used to create specifications for many kinds of display processors, such as those embedded within graphic user interface (GUI) toolkits associated with many programming languages.  illustrate the methods used to develop the overview, summary, and segmented treetable outputs.","It should also be noted that although this particular embodiment is directed to a review tool for a stored discussion, the methods of this invention could be used, in whole or in part, to analyze and present other types of tree structured texts, in particular the content of tree-structured websites, and other tree-structured hypertext documents.",{"@attributes":{"id":"p-0086","num":"0098"},"figref":["FIGS. 1","FIG. 1"],"b":["2","3","130","130"]},"Group overview  comprises a group header , and a collection of node overview strings , , , , , , and . Group header  identifies the group by:\n\n","The group header  is linked to a display of a segmented treetable, an example of which is illustrated in , which shows the tree as a whole in the upper frame, and an expanded view of a group, or the first segment of a group, in the lower frame.","The node overview strings , , , , ,  and  each represent a different node selected from the group for representation in the overview. It should be noted that overview strings for only a portion of the nodes that might be selected to represent the associated group are shown in . This is for illustrative purposes only and, in practice, more overview strings might be included and viewable, although some scrolling may be necessary. Each node overview string comprises one or more sentences selected from the node-associated text. If the entire text is not included in the node overview string, gap indicators , such as ellipsis symbols \u201c. . . \u201d, are used to indicate omitted sentences. In all overviews and summaries associated with this invention, strings representing individual nodes are organized to reflect the tree structure of the subtree or subtrees associated with the group. In this example, the structure is reflected by an adaptation of reduced-width trees, introduced in U.S. patent application Ser. Number 09\/732,028 titled \u201cMethod and System for presenting semi-linear hierarchy displays\u201d, by Paula Newman, incorporated by reference hereinabove. In the adaptation, a string representing a node that has no predecessors in the group is represented unindented, and prefixed by an initial indicator , chosen in this example to be a solid bullet. If a selected node n has selected descendants along only one path, the node overview string associated with the nearest such descendant is listed under the node overview string for node n, unindented, and prefixed by a no-sibling indicator , chosen in this example to be an outline bullet. All other strings are prefixed by a sibling indicator , in this example a solid bullet, and indented under the strings representing their closest selected parent in the group. Thus the nodes associated with node overview strings , , , and  all have the initial node as their closest parent represented in the group. The node associated with node overview string  is the single selected descendant of the node associated with node overview string , and node overview string  bears the same relationship to the node associated with node overview string .",{"@attributes":{"id":"p-0090","num":"0105"},"figref":["FIG. 2","FIG. 1","FIG. 1","FIG. 1"],"b":["1","2","150","160","150","160","151","152","153"]},{"@attributes":{"id":"p-0091","num":"0106"},"figref":["FIG. 3","FIGS. 1 and 2","FIGS. 1 and 2"],"b":["3","4","170","180"]},{"@attributes":{"id":"p-0092","num":"0107"},"figref":["FIG. 4","FIG. 3","FIGS. 23 through 27","FIG. 3"],"b":["300","170","3","300","170"]},"Group summary  comprises group header , a set of text summary strings , , , and , and a gap indicator . The text summary strings are slightly different in structure from the message overview strings of , in that they include the text author, for example, text-author . However, this is an arbitrary difference; either type of text representation string could include or not include a text author or other text identifier. The text summary strings are also organized slightly differently from the text overview strings of , in that a simple indented tree is used to portray the tree structure. In the indented tree, a summary string for a text is indented under the summary string for the nearest parent node that is represented in the summary. Gap indicators, such as gap indicator , indicate texts in the group not represented in the summary, and occurring in a tree path between the start of the group and some represented message, or between two represented texts. It should be noted that the two methods of organizing a set of text representation strings, namely via the reduced-width trees of , , and , or the indented trees used in , can be used interchangeably for overviews and summaries alike. The reduced-width trees are useful for limiting the width of the digests when the text representation strings are deeply nested, and allow convenient \u201cdown the page\u201d reading. The indented trees are a more familiar form that may be desirable in certain applications.",{"@attributes":{"id":"p-0094","num":"0109"},"figref":["FIG. 5 through 8","FIG. 5","FIG. 7","FIG. 6","FIG. 8"],"b":["500","510","570","520","540","550","520","530","560"]},{"@attributes":{"id":"p-0095","num":"0110"},"figref":["FIG. 6","FIG. 5","FIG. 5"],"b":["600","520","530","600","610","620","630","640","610","620","630","640","610","520","612","622","632","642","612","622","0","632","2","611","631","641","611","621","641"],"sup":["th ","st "]},{"@attributes":{"id":"p-0096","num":"0111"},"figref":["FIG. 7","FIG. 5","FIG. 6","FIG. 6","FIG. 6"],"b":["570","510","710","720","730","710","610","620","0","720","730","640","630"]},{"@attributes":{"id":"p-0097","num":"0112"},"figref":["FIG. 8","FIG. 6","FIG. 5","FIG. 5","FIGS. 5 and 6","FIG. 5"],"b":["630","540","800","860","810","820","830","840","850","822","800","801","821","540","520","500","520"]},"Now moving to the methods for developing the subtopic groupings, overviews, summaries, and segmented treetable visualizations,  describes the interactions among the major processes in one embodiment of this invention. The control routine, having received a request for an overview, summary, or segmented treetable presentation of tree-structured texts, enters at box , where it accesses the text tree and associated information from data storage . Data storage  can be part of the main memory of the processing node, or a local or shared storage device accessible from the processing node, or a storage device accessed by request to another processing node across a network. The control routine then moves to decision box  where it checks whether the associated information includes clustering information. If so, the control routine moves to decision box . Otherwise, the control routine moves to box , described in more detail with respect to , to obtain the primary clusters and secondary collections for the tree. The control routine then moves to box  where it stores the clustering result information, and then moves to decision box .","At decision box  the control routine checks the type of input request. If the request is for a tree summary, it moves to box , where it sets digesting parameters for a summary of the primary clusters, and then moves to box . If the request is for a tree overview, the control routine moves to box  where it sets digesting parameters for an overview of primary clusters, and then moves to box . If the request is for a segmented treetable linking to digests of all regions, the control routine moves to box  where it sets digesting parameters for an overview of all clusters, both primary clusters and the secondary collections also represented in the treetable, and then the control routine moves to box .","At box , described in detail in conjunction with , the control routine forms a digest of the desired type. It then moves to box  to check if the request was for a segmented treetable. If not, the control routine returns at box . Otherwise the control routine moves to box , described in more detail with respect to , where it forms the treetable and links it to the full overview, and then returns at box .",{"@attributes":{"id":"p-0101","num":"0116"},"figref":["FIGS. 10 through 13","FIG. 9","FIG. 10","FIG. 11"],"b":["930","1010","1020"],"ul":{"@attributes":{"id":"ul0013","list-style":"none"},"li":{"@attributes":{"id":"ul0013-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0014","list-style":"none"},"li":["a) First, using the initial word vectors associated with a collection as input, a second vector is obtained for each text representing it as a mixture of latent semantic classes, that is, a probability distribution over the set of such classes. This second vector is called a class probability vector.","b) Then, these class probability vectors are converted into word-probability vectors. A word-probability vector for a text may have non-zero probabilities in positions for words that are associated with words in the text, but do not actually appear there."]}}}},"After computing word vectors for each text, the control routine moves to box  where it finds the node pairs related in either a parent-child or sibling relationship in the tree. It then moves to box  where it computes the lexical distance between the texts of each such node pair. If the word vectors for the texts contain raw or weighted counts, the distance measure used is the standard cosine distance. If the word vectors for the texts contain probabilities obtained by PLSA processing, the distance measure used in one embodiment is the Hellinger similarity, namely the sum of the square roots of the products of the positionally matching vector elements",{"@attributes":{"id":"p-0103","num":"0120"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"n"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msqrt":{"mrow":{"msub":[{"mi":"v","msub":{"mn":"1","mi":"j"}},{"mi":"v","msub":{"mn":"2","mi":"j"}}],"mo":"\u00b7"}}},"mo":","}}},"br":{}},"The control routine them moves to box , discussed in more detail hereinbelow with respect to , where it obtains primary clusters representing groupings of more closely related nodes that may be used in a digest, and, if needed, secondary clusters of less closely related nodes that may be used for groupings within other tree visualizations. The control routine then moves to box  where it may make some minor adjustments at cluster boundaries based on structural considerations involving nodes with many children. In particular:\n\n",{"@attributes":{"id":"p-0105","num":"0125"},"figref":["FIG. 11","FIG. 10"],"b":["1010","1110","1120","1130","1130","1140","1150","1150","1180","1160","1160","1170","1180","1180","1190","1130","1190"]},{"@attributes":{"id":"p-0106","num":"0126"},"figref":["FIG. 12","FIG. 10"],"b":["1060","1210","1220","1230","1230","1","2","1","2","1","2"],"ul":{"@attributes":{"id":"ul0017","list-style":"none"},"li":{"@attributes":{"id":"ul0017-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0018","list-style":"none"},"li":["a) computing the cluster distance between each pair of clusters linked by at least one node pair as a function of the node distances of all node pairs linking the two clusters, and the distance between the lexical centroids of the two clusters, and selecting the pair of clusters with the smallest so-computed cluster distance,","b) Computing the cluster distance between each pair of clusters linked by at least one node pair as a function of the smallest node distance of the node pairs linking the two clusters and the distance between the lexical centroids of the two clusters, and selecting the pair of clusters with the smallest so-computed cluster distance, and","c) Computing the cluster distance between each pair of clusters linked by at least one node pair as a function of the largest node distance of the node pairs linking the two clusters and the distance between the lexical centroids of the two clusters, and selecting the pair of clusters with the smallest so-computed cluster distance."]}}}},"After finding the most similar cluster pair, the control routine moves to box . At box , discussed in more detail with respect to , the control routine determines the action to be taken for clusters c and c, and moves to decision box . At box  the control routine checks what action has been determined. It no action is to be taken, the control routine moves directly to decision box . If the required action is \u201ccombine\u201d, the control routine moves to box  where it combines clusters c and c and moves to decision box . If the required action is \u201ccombine and close\u201d, the control routine moves to box  where it combines clusters c and c and moves to box . If the required action is to just \u201cclose\u201d the primary clusters, the control routine moves directly to box . At box  the control routine examines the current set of clusters and identifies as \u201cprimary\u201d, for use in constructing digests, all current clusters larger than a given minimum size, and identifies the remaining clusters as secondary. In this embodiment the minimum size for primary clusters is 5 texts, but it could equally well be set as a function of the number of texts in the tree. After closing primary clusters at box , the control routine moves to box . At box  the control routine may combine all adjacent secondary clusters, and, when all adjacent secondary clusters are combined, may also combine very small secondary clusters with adjacent primary clusters. This is done, for example, to permit the visualization of the tree within a treetable as divided between groups representing primary clusters, and other collections of less closely related nodes. After possibly combining secondary clusters at box  the control routine moves to box .","At decision box  the control routine determines whether there are clusters that have not yet been closed. If so, it moves to box  where it gets the next most similar cluster pair <c, c>and moves to box  to continue iterating. If not, the control routine moves to box . At box  the control routine checks whether primary clusters have been identified as yet and, if not, marks as \u201cprimary\u201d all current clusters larger than a given minimum size, and moves to box .","At box  the control routine returns the primary and secondary clusters found.",{"@attributes":{"id":"p-0110","num":"0133"},"figref":["FIG. 13","FIG. 12","FIG. 12","FIG. 12"],"b":["1240","1310","1","2","1210","1360","1","2","1230","1390","1365","1","2","1355","1380","1","2","1390","1380","1","2","1385"]},{"@attributes":{"id":"p-0111","num":"0134"},"figref":["FIG. 14","FIG. 9","FIG. 15","FIG. 22"],"b":["970","1410","1420","1430","1440","1460","1450","1460","1460","1470","1430","1460","1480","1490"]},{"@attributes":{"id":"p-0112","num":"0135"},"figref":["FIGS. 15 through 18","FIG. 14","FIG. 15","FIG. 16"],"b":["1440","1510","1520","1530","1530","1540"]},"The control routine then moves to box , described in more detail with respect to , where it finds the quoting interactions to be used in extracting sentences for the cluster overview. Specifically, it finds a quoted set QD of quoted nodes and associated quoted sentences, and a quoting set QG of quoting nodes and quoting sentences, such that the quoting sentences in quoting set QG match quoted sentences in quoted set QD. The eventual overview construction method will use this information to create extracted sequences of quoted sentences and responses to those sentences in the summary. After finding quoting interactions in box , the control routine moves to box  where it gets a node n in extraction set EN and moves to box . At box , described in more detail with respect to , the control routine obtains the string to be used to represent node n in the overview, and moves to decision box  where it checks whether there are more nodes in extraction set EN to be processed. If so, the control routine moves to box , where it gets another node n in extraction set EN and moves to box . Otherwise the control routine moves to box , described in more detail with respect to , where it combines and formats the node representation strings obtained for the nodes in extraction set EN into a single overview digest for the cluster, and then to box  where it returns that digest.",{"@attributes":{"id":"p-0114","num":"0137"},"figref":["FIG. 16","FIG. 15"],"b":["1520","1610","1620","1630","1630","1640","1640","1670","1650","1660","1660","1670"]},"At decision box  the control routine checks whether more representation is to be given to early nodes in the cluster and, if not, moves to box . Otherwise it moves to box  where, if the tree root is part of the cluster it is added to the set of central nodes CN and the control routine moves to box . At box  the control routine determines whether any children of the overall tree root are also part of the cluster and, if so, adds a proportion of them to the set of central nodes CN, and moves to box . At box  the control routine returns the set of central nodes CN.",{"@attributes":{"id":"p-0116","num":"0139"},"figref":["FIG. 17","FIG. 15"],"b":["1550","1710","1720","1730","1740","1785","1750","1760","1760","1765","1765","1770","1770","1775","17","60","1770","1780","1780","1785","1785","1790","1740","1785"]},{"@attributes":{"id":"p-0117","num":"0140"},"figref":["FIG. 18","FIG. 15"],"b":["1570","1810","1820","1830","1840","1845","1830","1845","1845","1850","1850","1855","1870"]},"At box , entered for central nodes, the control routine adds more sentences to sentence set S, specifically sentences following important quoting passages, that is, sentences immediately following quoting passages node n, selective quote q> recorded in quoting set QG. If a sentence s to be added is very short, then one or more sentences following s in node text nt are added as well. If a sentence to be added is very long, it may be truncated. After adding sentences following quoting passages, if any, at box , the control routine moves to decision box . At decision box  the control routine checks if any sentences have yet been added to sentence set S. If sentence set S contains some sentences, the control routine moves to box . Otherwise, the control routine moves to box  where it adds to sentence set S either the first sentence in node text nt, or the sentence in node text nt having a word vector that is closest to the word vector for node text nt as whole, and then the control routine moves to box ","At decision box , entered for non-central (auxiliary) nodes, the control routine checks whether sentence set S is still empty. If so, it moves to box  where it adds the last sentence of node text nt to S, making the assumption that if there are no explicit quotes of node n, then responses to node n probably relate to the last sentence. If the last sentence s of node text nt is very short, then one or more sentences preceding sentence s in node text nt are added as well; if sentence s is very long it may be truncated. After the last sentence or sentences of node text nt have been added to S at box , the control routine moves to box .","At box  the control routine sorts the sentences in sentence set S by their position in node text nt and eliminates duplicates, and then moves to box . At box  the control routine concatenates the sentences in sentence set S to form the string representing node n in the overview. Sequences of sentences in node text nt but not in sentence set S are represented in the string by gap markings such as ellipsis symbols \u201c . . . \u201d. The control routine then returns the overview string for node n at box .",{"@attributes":{"id":"p-0121","num":"0144"},"figref":"FIG. 19","b":["1905","1905","1910","1911","1912","1913","1914","1915","1916","1917","1918","1919","1920","1921","1910","1913","1918","1912","1916","1911","1914","1915","1917","1919","1920","1921","1910","0","1","2","1916","7","2","2","1910","8"]},"Quoted set  shows the quoted set QD obtained after analyzing the quote interactions of the cluster. It contains two pairs: <, S> and <, S>, indicating when extracting sentences for use in representing node , sentence S will be included, and that when extracting sentences representing node , sentence S will be included. Similarly, the quoting set  shows the quoting set QG after analyzing the quote interactions. It contains the two pairs <, Q> and <, Q>, indicating that quote Q of node , and quote Q of node , are considered to be important quotes, and that sentences following them in their containing nodes might, although not necessarily, be included in the overview.","The overview schematic  shows the overview that would result from the central and auxiliary node identification together with quote interaction analysis. The schematic lists the sentences that would be included in the overview, the nodes from which they are extracted, and a brief rationale for their inclusion. As in an actual overview, sentences are concatenated into strings representing their source nodes, with ellipsis symbols \u201c . . . \u201d indicating gaps, and the strings are arranged in an indented tree reflecting the structure of the cluster. Thus node , which is a central node, is represented in the overview by two sentences, S and S. The first sentence S is used because  is a central node, and there is no entry for  in quoting set QG. Sentence S is used because it is represented in quoted set QD. Node , which is an auxiliary node, is represented in the overview by sentence S, which is represented in quoted set QD. And node , which is a central node, is represented by sentence S, because it follows a quote represented in quoting set QG.",{"@attributes":{"id":"p-0124","num":"0147"},"figref":["FIGS. 20 and 21","FIG. 15","FIG. 23","FIG. 20","FIG. 4","FIG. 1","FIG. 1"],"b":["1590","2380","2010"]},"The control routine enters at box  where it builds a reduced tree for the cluster containing only the nodes to be represented in the digest. In the reduced tree,\n\n","The control routine then moves to box  where it initializes the indent level to (\u22121), and the digest to empty. The control routine then moves to decision box  where it checks whether the cluster has a dummy root node. If so, it moves to decision box . Otherwise, it moves to box , described in more detail with respect to , where it formats the digest for the subtree rooted in the subtree root, and then moves to box .","At decision box  the control routine checks whether the dummy subtree root node has any remaining unprocessed children in the reduced tree. If not it moves to box . Otherwise, it moves to box  where it gets an unprocessed child and moves to box . At box , described in more detail with respect to , the control routine formats the digest for the subtree rooted in the unprocessed child, and adds it to the cluster digest, and then moves to box .","At box  the control routine returns the completed cluster digest.",{"@attributes":{"id":"p-0129","num":"0155"},"figref":["FIG. 21","FIG. 20","FIG. 20"],"b":["2050","2070","2110","2010","2120","2130","2140"],"ul":{"@attributes":{"id":"ul0021","list-style":"none"},"li":{"@attributes":{"id":"ul0021-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0022","list-style":"none"},"li":["(a) The specified format is a reduced-width tree, and","(b) The node has no siblings in the reduced tree, and","(c) The current indent level is larger than \u22121, that is, the node is neither the root of the cluster nor a child of the dummy root.\n\nIf so, the control routine moves to box  where it sets the new indent level equal to the input indent level, which will result in the current node not indented under its parent, and adds a no-sibling indicator to the node representation string, and then moves to box . However, if at decision box  the control routine determines that the node is not a child without siblings in a reduced-width tree format, or the current indent level is \u22121, it moves to box  where it sets the new indent level as one more than the current indent level, adds a sibling indicator, for example, a solid bullet as shown by sibling indicator  in , and then moves to box .\n"]}}}},"At box  the control routine adds the node representation string to the digest, indenting some multiple of the new indent level, and moves to decision box . At decision box  the control routine checks whether the current node has any unprocessed children in the reduced tree, and, if not, moves to box  where it returns. Otherwise the control routine moves to box  where it gets an unprocessed child of the current node and moves to box . At box  the control routine formats the part of the digest for the subtree headed by the unprocessed child node, recursively invoking the current process from box . When the recursively invoked execution of the current process returns, the control routine moves to box .",{"@attributes":{"id":"p-0131","num":"0160"},"figref":["FIGS. 22 through 26","FIG. 14","FIGS. 23 through 26"],"b":"1450","i":["Proceedings of the ANLP\/NAACL ","Workshop on Automatic Summarization "]},{"@attributes":{"id":"p-0132","num":"0161"},"figref":["FIG. 22","FIG. 14"],"b":["1450","2210"],"br":[{},{}],"in-line-formulae":[{},{}],"i":["{right arrow over (s)}=","p","z","|s","p","z","|s","p","z","|s","Proceedings of SIGIR "],"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00001","he":"2.46mm","wi":"1.02mm","file":"US07111253-20060919-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00002","he":"2.46mm","wi":"1.02mm","file":"US07111253-20060919-P00002.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}],"sub":["1","2","n","i","i "]},"After obtaining sentence vectors for each sentence in the cluster in box , the control routine moves to box  where it obtains the centroid of the sentence vectors for the cluster, that is, a vector where each position contains the average of the values in that position across the cluster. The control routine then moves to box  where it gets a sentence in the cluster, and moves to box . At box , described in more detail with respect to , the control routine assigns an intrinsic score to the sentence, reflecting lexical centrality and position features, and then moves to box  where it checks whether there are any more sentences in the cluster. If so, the control routine moves to box  where it gets another sentence, and then moves to box . Otherwise the control routine moves to box .","At box  the control routine adds the sentence with the highest intrinsic score to the summary, and moves to box . At box  the control routine determines the number of sentences to be used in the summary. This is computed using an assumed percentage, usually 10%, and then using the larger of that percentage of the number of sentences in the cluster as a whole, and that percentage of the number of texts in the cluster times a nominal standard text size, whichever is greater. The control routine then moves to box .","At box  the control routine determines whether the summary contains the desired number of sentences. If so, it moves to box . If not, the control routine moves to box , described in more detail with respect to , where it gets the sentence not already in the summary with the highest extract score, a score that combines the intrinsic score with features relating the candidate sentence to sentences already in the summary. The control routine then moves to box  where it adds the sentence with the highest extract score to the summary and then moves to box .","At box , described in more detail with respect to , the control routine formats the summary for the cluster, and then moves to box  where it returns the summary for the cluster.",{"@attributes":{"id":"p-0137","num":"0166"},"figref":["FIG. 23","FIG. 22","FIG. 20"],"b":["2285","2310","2320","2330","2340","2340","2350","2350","2360","2370","2340","2360","2380","2380","2390"]},{"@attributes":{"id":"p-0138","num":"0167"},"figref":["FIG. 24","FIG. 22"],"b":["2230","2410","2420","2430","2440","2450","10","10","2460"],"br":[{},{}],"in-line-formulae":[{},{}],"i":["ws","m"]},"The control routine then moves to box  where it computes a centroid similarity score csim for the sentence, measuring its similarity to the cluster centroid. This is computed differently depending on whether the sentence vectors are simple word vectors, or PLSA-based class probabilities. In the former case the similarities are (1-distance), where the distance is the absolute value of the cosine of the angle between the word vector and the lexical centroid for the cluster. In the case where the vectors represent PLSA class probabilities, the similarity is the Hellinger similarity between vectors. The control routine then moves to box  where it computes the overall intrinsic score is(s) for the sentence s as the weighted sum of the overall position score pos and the centroid similarity score csim using is(s)=\u03b1*pos+(1\u2212\u03b1)*sim, where \u03b1 is between 0 and 1. Then control routine then moves to box  where it associates the computed intrinsic score with the sentence, and then moves to box  where it returns.",{"@attributes":{"id":"p-0140","num":"0169"},"figref":["FIG. 25","FIG. 22","FIG. 26"],"b":["2270","2510","2520","2530","2540","2540","2560","2560","2560","2570","2530","2580"]},{"@attributes":{"id":"p-0141","num":"0170"},"figref":["FIG. 26","FIG. 25"],"b":["2530","2610","2620","2630","2640","2650","2660","1","2","3","4","2670","2680"]},{"@attributes":{"id":"p-0142","num":"0171"},"figref":["FIGS. 27 through 32","FIGS. 5","FIG. 27","FIG. 9","FIG. 28","FIG. 29"],"b":["6","7","8","980","2710","2720","2730","2740","2750","2770","2740","2755","2770"]},"Box  describes input to the process when entered when the outline treetable has already been developed, and a particular segment is to be displayed in conjunction with the outline table, probably because of a link from the outline table. The input comprises the outline treetable and an indication of the detail segment to be displayed. The control routine, when entered to obtain a detail segment table associated with an existing outline table, enters at box . At box  the control routine builds a treetable for that portion of the tree composed of nodes in the specified detail segment, plus possibly one additional node for any segment containing children of nodes in the specified detail segment. The treetable is built using essentially the same method as that used to build a full treetable, as described in the US patent application described in U.S. patent number U.S. patent application Ser. No. 09\/954,388, titled \u201cMethod and Apparatus for the Construction and use of Table-like visualizations of Hierarchic Material, by Paula Newman and Stuart Card, included by reference hereinabove, differing in that the background of the detail segment treetable is set to the same background as that used for the segment in the outline treetable. An example of the result is illustrated in . After building a detail segment treetable in box , the control routine moves to box  where it constructs a two-frame display, with the upper half containing the outline treetable, and the lower half the detail segment treetable, and then moves to box  where it returns.",{"@attributes":{"id":"p-0144","num":"0173"},"figref":["FIG. 28","FIG. 27"],"b":["2720","2810","2820","0","2830","2850","2840","2850","2850","2870","2860"]},"At box  the control routine combines the current node n with the content of any open segments. If node n has no children, the width of the resulting segment is 1 and its height is 1. If there are open child segments, the width of the resulting segment is a proportion of the number of its closed child segments plus the widths of remaining open segments, and its height is the maximum of the heights of the remaining open segments plus one. The control routine then moves to decision box . At decision box  the control routine checks whether the new segment exceeds the maximum dimensions for a segment. If not, the control routine moves to decision box . Otherwise, the control routine moves to box  where it closes the new segment unless doing so would foster some very small segments. Two such cases are (1) where the height dimension has been reached and there are very few nodes in the same cluster above the current one in the tree, and (2) where the width dimension has been reached but the current node has siblings in the same cluster. In the latter case the decision of whether to close the current segment is left to processing at higher node levels. The control routine then moves to decision box .","At box  the control routine checks whether there are more nodes in the bottom-up ordering of the tree. If not, the control routine returns at box . Otherwise, the control routine moves to box  where it gets the next node n in the ordering and moves to box .",{"@attributes":{"id":"p-0147","num":"0176"},"figref":["FIG. 29","FIG. 27","FIG. 4","FIG. 30","FIG. 31"],"b":["2730","2910","2920","2930","2950","2920","2940","2950","2950","2960","2980","2980","2990"]},{"@attributes":{"id":"p-0148","num":"0177"},"figref":"FIG. 30","b":["3010","1","11","12","13","111","112","131","3020","3030","3040","3050","1","3030","1","1","3040","11","12","13","11","12","13","11","2","1","3050","111","112","111","112","3051","131","131","13","13"]},{"@attributes":{"id":"p-0149","num":"0178"},"figref":["FIGS. 31 and 32","FIG. 31","FIG. 29","FIG. 32","FIG. 32"],"b":["2980","3245","3110","3120","3130","3140","3145","3145","3190","3150","3155","3155","3160","3160","3170","3165","3170"]},"At box  the control routine checks if there are more cells in the current row of the layout. If so, it moves to box  where it gets the next cell in the current row and moves to box . Otherwise, it moves to box  where it generates a tiny spacer cell representing part of the vertical margin for the region, and a row-end indicator, and moves to decision box . At decision box  the control routine checks whether there are any more rows in the layout after the current row. If not, it moves to box  where it generates a table end indicator and then to box . If, however, at decision box  the control routine determines that there are more rows in the layout, it moves to box  where it gets the next outline row, and then to box .","At box  the control routine returns the nested treetable for the cluster.",{"@attributes":{"id":"p-0152","num":"0181"},"figref":["FIG. 32","FIG. 31","FIG. 31"],"b":["3165","3210","3220","3230","3240","3245"]},"At box , described in detail with respect to , the control routine recursively constructs an outline treetable for the layout cell cluster, and moves to box . At box  the control routine adds a cell to the current treetable whose width equals the column count cc, and which contains the recursively constructed outline treetable and moves to box .","If, however, at decision box  the control routine finds that the input layout cell is associated with the current cluster, it moves to box . At box  the control routine checks whether the input layout cell is a spacer cell, that is, one representing part of the empty space in the treetable. If so, it moves to box  where it fills a table cell having the same width as that of the layout cell with the table background, and moves to box . However, if at decision box  the control routine finds that the layout cell is not a spacer cell, it moves to box . At box , if the tree has been clustered and the outline layout cell is in the first row of the treetable representing the cluster, the control routine indicates that a link to an overview segment for the cluster is to be inserted into the new cell, and then the control routine moves to box . At box  the control routine produces a new treetable cell having the same width in columns as the input layout cell, a background that has been identified for the segment associated with the layout cell, a labeled link to the detail segment treetable for the segment and, if a link to an overview segment is to be inserted, a labeled link to the overview as well. The control routine then moves to box .","At box  the control routine returns."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0051","num":"0063"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0052","num":"0064"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0053","num":"0065"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0054","num":"0066"},"figref":["FIG. 4","FIG. 3"],"b":"3"},{"@attributes":{"id":"p-0055","num":"0067"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0056","num":"0068"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0057","num":"0069"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0058","num":"0070"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0059","num":"0071"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0060","num":"0072"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0061","num":"0073"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0062","num":"0074"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0063","num":"0075"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0064","num":"0076"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0065","num":"0077"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0066","num":"0078"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0067","num":"0079"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0068","num":"0080"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0069","num":"0081"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0070","num":"0082"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0071","num":"0083"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0072","num":"0084"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0073","num":"0085"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0074","num":"0086"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0075","num":"0087"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0076","num":"0088"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0077","num":"0089"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0078","num":"0090"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0079","num":"0091"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0080","num":"0092"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0081","num":"0093"},"figref":"FIG. 31"},{"@attributes":{"id":"p-0082","num":"0094"},"figref":"FIG. 32"}]},"DETDESC":[{},{}]}
