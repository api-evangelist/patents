---
title: Method and system for recovering from abnormal interruption of a parity update operation in a disk array system
abstract: Data associated with the state of a parity update operation in a disk array system such as a RAID-6 system is stored during performance of the operation so that, in the event the operation is interrupted, recovery may be initiated using the stored data. The stored data may include a state indicator that is indicative of the status of the parity update operation, and snapshot data (e.g., a delta value indicative of a difference between new and old data) captured during the parity update operation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07392428&OS=07392428&RS=07392428
owner: International Business Machines Corporation
number: 07392428
owner_city: Armonk
owner_country: US
publication_date: 20041119
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This application is related to the following U.S. Patent Applications all filed on even date herewith by Carl Edward Forhan, Robert Edward Galbraith and Adrian Cuenin Gerhard: Ser. No. 10\/994,088, entitled \u201cMETHOD AND SYSTEM FOR ENHANCED ERROR IDENTIFICATION WITH DISK ARRAY PARITY CHECKING,\u201d Ser. No. 10\/994,099, entitled \u201cRAID ENVIRONMENT INCORPORATING HARDWARE-BASED FINITE FIELD MULTIPLIER FOR ON-THE-FLY XOR,\u201d Ser. No. 10\/994,098, entitled \u201cMETHOD AND SYSTEM FOR IMPROVED BUFFER UTILIZATION FOR DISK ARRAY PARITY UPDATES,\u201d and Ser. No. 10\/994,098, entitled \u201cMETHOD AND SYSTEM FOR INCREASING PARALLELISM OF DISK ACCESSES WHEN RESTORING DATA IN A DISK ARRAY SYSTEM\u201d Each of these applications is incorporated by reference herein.","The present invention relates to data protection methods for data storage and, more particularly, to systems implementing RAID-6 and similar data protection and recovery strategies.","RAID stands for Redundant Array of Independent Disks and is a taxonomy of redundant disk array storage schemes which define a number of ways of configuring and using multiple computer disk drives to achieve varying levels of availability, performance, capacity and cost while appearing to the software application as a single large capacity drive. Typical RAID storage subsystems can be implemented in either hardware or software. In the former instance, the RAID algorithms are packaged into separate controller hardware coupled to the computer input\/output (\u201cI\/O\u201d) bus and, although adding little or no central processing unit (\u201cCPU\u201d) overhead, the additional hardware required nevertheless adds to the overall system cost. On the other hand, software implementations incorporate the RAID algorithms into system software executed by the main processor together with the operating system, obviating the need and cost of a separate hardware controller, yet adding to CPU overhead.","Various RAID levels have been defined from RAID-0 to RAID-6, each offering tradeoffs in the previously mentioned factors. RAID-0 is nothing more than traditional striping in which user data is broken into chunks which are stored onto the stripe set by being spread across multiple disks with no data redundancy. RAID-1 is equivalent to conventional \u201cshadowing\u201d or \u201cmirroring\u201d techniques and is the simplest method of achieving data redundancy by having, for each disk, another containing the same data and writing to both disks simultaneously. The combination of RAID-0 and RAID-1 is typically referred to as RAID-0+1 and is implemented by striping shadow sets resulting in the relative performance advantages of both RAID levels. RAID-2, which utilizes Hamming Code written across the members of the RAID set is not now considered to be of significant importance.","In RAID-3, data is striped across a set of disks with the addition of a separate dedicated drive to hold parity data. The parity data is calculated dynamically as user data is written to the other disks to allow reconstruction of the original user data if a drive fails without requiring replication of the data bit-for-bit. Error detection and correction codes (\u201cECC\u201d) such as Exclusive-OR (\u201cXOR\u201d) or more sophisticated Reed-Solomon techniques may be used to perform the necessary mathematical calculations on the binary data to produce the parity information in RAID-3 and higher level implementations. While parity allows the reconstruction of the user data in the event of a drive failure, the speed of such reconstruction is a function of system workload and the particular algorithm used.","As with RAID-3, the RAID scheme known as RAID-4 consists of N data disks and one parity disk wherein the parity disk sectors contain the bitwise XOR of the corresponding sectors on each data disk. This allows the contents of the data in the RAID set to survive the failure of any one disk. RAID-5 is a modification of RAID-4 which stripes the parity across all of the disks in the array in order to statistically equalize the load on the disks.","The designation of RAID-6 has been used colloquially to describe RAID schemes that can withstand the failure of two disks without losing data through the use of two parity drives (commonly referred to as the \u201cP\u201d and \u201cQ\u201d drives) for redundancy and sophisticated ECC techniques. Although the term \u201cparity\u201d is used to describe the codes used in RAID-6 technologies, the codes are more correctly a type of ECC code rather than simply a parity code. Data and ECC information are striped across all members of the RAID set and write performance is generally lower than with RAID-5 because three separate drives must each be accessed twice during writes. However, the principles of RAID-6 may be used to recover a number of drive failures depending on the number of \u201cparity\u201d drives that are used.","Some RAID-6 implementations are based upon Reed-Solomon algorithms, which depend on Galois Field arithmetic. A complete explanation of Galois Field arithmetic and the mathematics behind RAID-6 can be found in a variety of sources and, therefore, only a brief overview is provided below as background. The Galois Field arithmetic used in these RAID-6 implementations takes place in GF(2). This is the field of polynomials with coefficients in GF(2), modulo some generator polynomial of degree N. All the polynomials in this field are of degree N\u22121 or less, and their coefficients are all either 0 or 1, which means they can be represented by a vector of N coefficients all in {0,1}; that is, these polynomials \u201clook\u201d just like N-bit binary numbers. Polynomial addition in this Field is simply N-bit XOR, which has the property that every element of the Field is its own additive inverse, so addition and subtraction are the same operation. Polynomial multiplication in this Field, however, can be performed with table lookup techniques based upon logarithms or with simple combinational logic.","Each RAID-6 check code (i.e., P and Q) expresses an invariant relationship, or equation, between the data on the data disks of the RAID-6 array and the data on one or both of the check disks. If there are C check codes and a set of F disks fail, F\u2266C, the failed disks can be reconstructed by selecting F of these equations and solving them simultaneously in GF(2) for the F missing variables. In the RAID-6 systems implemented or contemplated today there are only 2 check disks\u2014check disk P, and check disk Q. It is worth noting that the check disks P and Q change for each stripe of data and parity across the array such that parity data is not written to a dedicated disk but is, instead, striped across all the disks.","Even though RAID-6 has been implemented with varying degrees of success in different ways in different systems, there remains an ongoing need to improve the efficiency and costs of providing RAID-6 protection for data storage. The mathematics of implementing RAID-6 involve complicated calculations that are also repetitive. Accordingly, efforts to improve the simplicity of circuitry, the cost of circuitry and the efficiency of the circuitry needed to implement RAID-6 remains a priority today and in the future.","For example, one drawback associated with existing RAID-6 systems relates to recovery from abnormal events such as unexpected losses of power, media errors or storage device failures, etc. that complicate keeping data and parity synchronized. In particular, during a parity update operation, where new data is written to a disk in a disk array and the parity for the associated parity stripe is updated accordingly, a risk exists that the operation may be interrupted at an intermediate point, and prior to completion.","In a RAID-6 environment, for example, a parity update operation typically incorporates reading in the old data that will be overwritten by new data, XOR'ing the old data with the new data to create a delta value, writing the new data to the disk array, multiplying the delta value by a constant K, reading and XOR'ing the old P parity value with the product of the delta value and the constant Kto generate the new P parity value, writing the new P parity value to the disk array, multiplying the delta value by a constant K, reading and XOR'ing the old Q parity value with the product of the delta value and the constant Kto generate the new Q parity value, and writing the new Q parity value to the disk array. Interruption of the parity update operation prior to completion of the above steps often results in the parity and data becoming out of sync, and risking the corruption of the data, parity or both.","Furthermore, when a disk array becomes exposed, i.e., where the data or parity stored on at least one disk can no longer be trusted or is no longer available, recovery from interruptions becomes even more problematic. If, for example, in a RAID-6 disk array, one disk is exposed, recovery from interruption of a parity update operation directed to another disk cannot rely on the data stored on the exposed disk as such data is not trusted or available.","The invention addresses these and other problems associated with the prior art by storing data associated with the state of a parity update operation during performance of the operation so that recovery may be initiated using the stored data. In particular, embodiments consistent with the invention maintain a state indicator during a parity update operation that is indicative of the status of the parity update operation, and capture and store snapshot data (e.g., a delta value indicative of a difference between new and old data) during the parity update operation in non-volatile memory. Then, should the parity update operation be interrupted, the state indicator and snapshot data may be used to synchronize parity and data in the disk array in connection with recovering from the interrupted parity update operation.","The embodiments discussed hereinafter store state data associated with a parity update operation during performance of the parity update operation to facilitate recovery in the event of an abnormal event that interrupts the parity update operation. The stored data includes a state indicator that indicates the current status of the parity update operation at various points during the progress of the operation. The stored data also includes snapshot data captured during the parity update operation and stored in non-volatile memory. The snapshot data may include any number of types of data that may be of use in rolling forward or rolling back an interrupted parity update operation, e.g., delta data, delta data multiplied by a constant, old data, old parity, new parity, etc.","While other types of snapshot data may be captured, the embodiments discussed hereinafter capture and store a delta value, which is representative of the difference between new data being written to a disk by the parity update operation, and the old data previously stored on the disk and being overwritten by the new data in connection with the parity update operation. In the embodiments discussed hereinafter, this difference is generated via an XOR operation between the old and new data.","Presented hereinafter are a number of embodiments of a disk array environment implementing parity update operations and recovery techniques therefor consistent with the invention. However, prior to discussing such embodiments, a brief background on RAID-6 is provided, followed by a description of an exemplary hardware environment within which such operations and techniques may be implemented.","General RAID-6 Background","The nomenclature used herein to describe RAID-6 storage systems conforms to the most readily accepted standards for this field. In particular, there are N drives of which any two are considered to be the parity drives, P and Q. Using Galois Field arithmetic, two independent equations can be written:\n\n\u03b1+\u03b1+\u03b1+ . . . +\u03b1=0\u2003\u2003(1)\n\n\u03b1+\u03b1+\u03b1+ . . . +\u03b1=0\u2003\u2003(2)\n\nwhere the \u201c+\u201d operator used herein represents an Exclusive-OR (XOR) operation.\n","In these equations, \u03b1is an element of the finite field and dis data from the xdisk. While the P and Q disk can be any of the N disks for any particular stripe of data, they are often noted as dand d. When data to one of the disks (i.e., d) is updated, the above two equations resolve to:\n\n\u0394=(old )+(new )\u2003\u2003(3)\n\n(new )=(old )+((\u03b1+\u03b1)\/(\u03b1+\u03b1))\u0394\u2003\u2003(4)\n\n(new )=(old )+((\u03b1+\u03b1)\/(\u03b1+\u03b1))\u0394\u2003\u2003(5)\n","In each of the last two equations the term to the right of the addition sign is a constant multiplied by the change in the data (i.e., \u0394). These terms in equations (4) and (5) are often denoted as K\u0394 and K\u0394, respectively.","In the case of one missing, or unavailable drive, simple XOR'ing can be used to recover the drive's data. For example, if dfails then dcan be restored by\n\n=d+ . . . \u2003\u2003(6)\n","In the case of two drives failing, or being \u201cexposed\u201d, the above equations can be used to restore a drive's data. For example, given drives 0 through X and assuming drives A and B have failed, the data for either drive can be restored from the remaining drives. If for example, drive A was to be restored, the above equations reduce to:\n\n=((\u03b1+\u03b1)\/(\u03b1+\u03b1))+((\u03b1+\u03b1)\/(\u03b1+\u03b1))+ . . . +((\u03b1+\u03b1)\/(\u03b1+\u03b1))\u2003\u2003(7)\n\nExemplary Hardware Environment\n","With this general background of RAID-6 in mind, attention can be turned to the drawings, wherein like numbers denote like parts throughout the several views.  illustrates an exemplary computer system in which a RAID-6, or other disk array, may be implemented. For the purposes of the invention, apparatus  may represent practically any type of computer, computer system or other programmable electronic device, including a client computer, a server computer, a portable computer, a handheld computer, an embedded controller, etc. Moreover, apparatus  may be implemented using one or more networked computers, e.g., in a cluster or other distributed computing system. Apparatus 10 will hereinafter also be referred to as a \u201ccomputer\u201d, although it should be appreciated the term \u201capparatus\u201d may also include other suitable programmable electronic devices consistent with the invention.","Computer  typically includes at least one processor  coupled to a memory . Processor  may represent one or more processors (e.g., microprocessors), and memory  may represent the random access memory (RAM) devices comprising the main storage of computer , as well as any supplemental levels of memory, e.g., cache memories, non-volatile or backup memories (e.g., programmable or flash memories), read-only memories, etc. In addition, memory  may be considered to include memory storage physically located elsewhere in computer , e.g., any cache memory in a processor , as well as any storage capacity used as a virtual memory, e.g., as stored on the disk array  or on another computer coupled to computer  via network  (e.g., a client computer ).","Computer  also typically receives a number of inputs and outputs for communicating information externally. For interface with a user or operator, computer  typically includes one or more user input devices  (e.g., a keyboard, a mouse, a trackball, a joystick, a touchpad, and\/or a microphone, among others) and a display  (e.g., a CRT monitor, an LCD display panel, and\/or a speaker, among others). Otherwise, user input may be received via another computer (e.g., a computer ) interfaced with computer  over network , or via a dedicated workstation interface or the like. For additional storage, computer  may also include one or more mass storage devices accessed via a storage controller, or adapter, , e.g., removable disk drive, a hard disk drive, a direct access storage device (DASD), an optical drive (e.g., a CD drive, a DVD drive, etc.), and\/or a tape drive, among others. Furthermore, computer  may include an interface with one or more networks  (e.g., a LAN, a WAN, a wireless network, and\/or the Internet, among others) to permit the communication of information with other computers coupled to the network. It should be appreciated that computer  typically includes suitable analog and\/or digital interfaces between processor  and each of components , , ,  and  as is well known in the art.","In accordance with the principles of the present invention, the mass storage controller  advantageously implements RAID-6 storage protection within an array of disks .","Computer  operates under the control of an operating system , and executes or otherwise relies upon various computer software applications, components, programs, objects, modules, data structures, etc. (e.g., software applications ). Moreover, various applications, components, programs, objects, modules, etc. may also execute on one or more processors in another computer coupled to computer  via a network , e.g., in a distributed or client-server computing environment, whereby the processing required to implement the functions of a computer program may be allocated to multiple computers over a network.","In general, the routines executed to implement the embodiments of the invention, whether implemented as part of an operating system or a specific application, component, program, object, module or sequence of instructions, or even a subset thereof, will be referred to herein as \u201ccomputer program code,\u201d or simply \u201cprogram code.\u201d Program code typically comprises one or more instructions that are resident at various times in various memory and storage devices in a computer, and that, when read and executed by one or more processors in a computer, cause that computer to perform the steps necessary to execute steps or elements embodying the various aspects of the invention. Moreover, while the invention has and hereinafter will be described in the context of fully functioning computers and computer systems, those skilled in the art will appreciate that the various embodiments of the invention are capable of being distributed as a program product in a variety of forms, and that the invention applies equally regardless of the particular type of computer readable signal bearing media used to actually carry out the distribution. Examples of computer readable signal bearing media include but are not limited to recordable type media such as volatile and non-volatile memory devices, floppy and other removable disks, hard disk drives, magnetic tape, optical disks (e.g., CD-ROM's, DVD's, etc.), among others, and transmission type media such as digital and analog communication links.","In addition, various program code described hereinafter may be identified based upon the application within which it is implemented in a specific embodiment of the invention. However, it should be appreciated that any particular program nomenclature that follows is used merely for convenience, and thus the invention should not be limited to use solely in any specific application identified and\/or implied by such nomenclature. Furthermore, given the typically endless number of manners in which computer programs may be organized into routines, procedures, methods, modules, objects, and the like, as well as the various manners in which program functionality may be allocated among various software layers that are resident within a typical computer (e.g., operating systems, libraries, API's, applications, applets, etc.), it should be appreciated that the invention is not limited to the specific organization and allocation of program functionality described herein.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 2","FIG. 1"],"b":["16","202","208","12","210","212","218","204","212","218","212","218","212","218","202","210","210","212","210","212","218","202","206","206","202","206"]},"It will be appreciated that the embodiment illustrated in  is merely exemplary in nature. For example, it will be appreciated that the invention may be applicable to other disk array environments where parity update operations are performed. It will also be appreciated that a disk array environment consistent with the invention may utilize a completely software-implemented control algorithm resident in the main storage of the computer, or that some functions handled via program code in a computer or controller can be implemented in hardware logic circuits, and vice versa. Therefore, the invention should not be limited to the particular embodiments discussed herein.","Recovering from Abnormal Interruption of Parity Update Operations","While RAID-6 systems, under normal circumstances, effectively provide protection against two disk failures, there are some abnormal events that might introduce conditions in which there is uncertainty whether the parity and data information is properly synchronized. For example, unexpected loss of power or media errors can occur at times that affect the synchronization of the data. One of the most vulnerable times is when new data has been written to a disk and the P and Q parity data are being updated.","In RAID 6, six I\/O operations are generated for every standard parity update operation:\n\n","If an abnormal event, such as unexpected loss of power, occurs at any time during this process, the state of the data and the parity information may be unknown. Upon the restoration of power the controller is configured to automatically detect the abnormal state of the previous update operation and initiate a recovery process. Thus, a RAID-6 controller, in accordance with the principles of the present invention, is able to automatically resynchronize the data and parity information even after an abnormal interruption",{"@attributes":{"id":"p-0040","num":"0045"},"figref":"FIG. 3","b":["304","306","308","310"]},"When no drives are exposed, recovering from abnormal events is relatively straightforward. For example, if disk D  is completely updated with the new data  and P is in the process of being modified when an abnormal event occurs, then the following facts are known about the data:","1) D on the disk  is the new data;","2) P is in doubt, it may be correct or it may not;","3) Q is correct but is for the old data that was on disk D; and","4) E is known and is unchanged.","Using the new D and the unchanged E, the controller can calculate the new P and Q as if the abnormal event never occurred using equation (7) and treating P and Q as if they were exposed. However, if one of the drives is exposed, then the task becomes more complicated. In the above example, if disk E  is exposed, then calculating P and Q is not the same straightforward exercise. Accordingly embodiments of the present invention relate to a RAID-6 controller that permits synchronizing of data and parity after an occurrence of an abnormal event during parity updating, even when one or more drives are exposed.","The controller uses two pieces of nonvolatile information: a \u201cparity update footprint\u201d and a snapshot of the data during the parity update in order to recover from an abnormal event. Conventional RAID-6 implementations already include functionality of a normal parity update footprint that stores information about a particular update operation in non-volatile memory while an update operation is being performed. This typical footprint includes information about the logical block address of the update, the length of the update, the device ID, etc. In addition to this information, embodiments of the present invention advantageously include information within the footprint about the state of the ongoing update operation.","In accordance with one embodiment of the present invention, there are four valid states of the parity update operation:","1) Data in Doubt\u2014data is in doubt and P and Q are old;","2) P in Doubt\u2014D is new, Q is old, P is in doubt;","3) P in doubt and \u0394\u2014D is new, Q is old, P is in doubt, but the delta value (\u0394) is known;","4) Q in Doubt\u2014D is new, P is new, Q is in doubt.","Returning to , the following sequence of events occur during a parity update in accordance with the principles of the present invention:","a) when new data D,  is to be written to the data disk D , the controller acquires a semaphore for the footprint and the delta value (\u0394); thus these values cannot be changed by another process while the semaphore is being held;","b) the controller XOR's old D with new D and stores this delta value (\u0394) in a buffer;","c) the controller sets the footprint state to Data in Doubt;","d) the controller writes the new D to the data disk D ;","e) desirably, if there is an exposed disk, the delta value \u0394 is written to non-volatile memory, e.g., to disk D, the location desirably a default location so that during a recovery operation, the controller automatically can retrieve the saved \u0394 value;","f) the controller multiplies \u0394 by the constant K;","g) the controller XOR's the old P with K\u0394 and stores the new P in a buffer;","h) the controller sets the footprint state to P in doubt (or P in doubt with \u0394, if there is an exposed drive);","i) the controller writes the new P on disk ;","j) the controller sets the footprint state to Q in doubt;","k) the controller multiplies \u0394 by the constant K;","l) the controller XOR's the old Q with K\u0394 and stores the new Q in a buffer;","m) the controller stores the new Q on disk ;","n) the controller releases the semaphore.","Table I below summarizes the possible failure scenarios that may occur given the steps of the parity update process and the different \u201cstates\u201d that are defined for an update process. In particular, the table refers to an update process involving writing new data to disk D, . Thus, in the table the reference \u201cother\u201d refers to some disk other than D , P  and Q  (e.g., disk E ). The columns of the table indicate the different states and the rows indicate different conditions that may be present within the RAID array. The value of each element of the table represents the corrective procedure that will resynchronize the data and the parity information. \u201cResync P and Q\u201d refers to using the data devices (e.g., D and E) to regenerate P and Q parity. \u201cRebuild D\u201d refers to using the devices (except disk D) to regenerate D data. \u201cRebuild Q\u201d refers to using the devices except disk Q to regenerate Q (P can be rebuilt in an analogous manner as well).",{"@attributes":{"id":"p-0069","num":"0074"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"56pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE I"},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":[{},{},"P in Doubt or,",{}]},{"entry":["Exposed",{},"if E is exposed,"]},{"entry":["Device(s)","Data in Doubt","P in Doubt with \u0394","Q in Doubt"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["None","Resync P and Q","Resync P and Q","Resync P and Q"]},{"entry":["D","None","Resync P and Q","Rebuild Q"]},{"entry":["P","Resync P and Q","Resync P and Q","Resync P and Q"]},{"entry":["Q","Resync P and Q","Resync P and Q","None"]},{"entry":["Other","Rebuild D","ACTION","Rebuild Q"]},{"entry":["D and P","None","Resync P and Q","Resync P and Q"]},{"entry":["D and Q","None","Resync P and Q","None"]},{"entry":["P and Q","None","Resync P and Q","None"]},{"entry":["D and Other","None","Resync P and Q","Resync P and Q"]},{"entry":["P and Other","Resync P and Q","Resync P and Q","Resync P and Q"]},{"entry":["Q and Other","Resync P and Q","Resync P and Q","None"]},{"entry":["2 Others","Resync P and Q","Resync P and Q","Resync P and Q"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}}}},"In almost all the failure scenarios that may occur during the parity update operation, enough information is known about the data that parity information can be easily resynchronized or data from the data drives can be rebuilt using the traditional equations for calculating P and Q, such that the data and parity are returned to synchronization. In one particular failure scenario, however, recovery is not straightforward. If, in , Disk E  is exposed, it is complicated to resync all the data and parity if P is in doubt.","If such a failure occurs, then E is unavailable, the new value of D is known, Q is an old value and P is uncertain. This combination of values does not permit use of any of the conventional parity calculation equations to resynchronize the data and the parity information without loss of data for E. In the above table this recovery solution is labeled \u201cACTION\u201d. In this case, recovery is accomplished according to the following steps:","a) the new data value D is read from the disk into a buffer;","b) the new data value D is XOR'ed with the \u0394 that was written to disk D and recovered (alternatively, \u0394 may be written to a variety of different non-volatile storage areas, e.g., on another disk, or in a non-volatile memory in the controller, an adapter, or other component);","c) the buffer now contains the old data value D;","d) the old D is then written to the data disk D; and","e) parity P is then rebuilt.","Thus, the parity and data are once again synchronized. From this point, the controller can once again attempt to update the disk D with the new data value.","In many RAID control systems, routines exist that perform resynchronization of P and Q when needed. Thus, in some instances, if only P needs to be resynchronized, the controller still performs a resync of both P and Q. The table above employs a similar convention; in some recovery scenarios only one of the P and Q values actually need resyncing. However, the table indicates that both P and Q are re-synced. Even in instances where P or Q may be an exposed drive, RAID control systems typically perform a \u201cresync P and Q\u201d that results in P and Q being generated but any data for an exposed drive is simply not written out. One of ordinary skill will recognize that the above table relies on some of these conventional controller routines but that resynchronization of P and Q could be performed separately without departing from the scope of the present invention.","It will be appreciated that in the event that two disks are exposed, a resynchronization of P and Q may potentially result in known data loss in some embodiments of the invention. However, in contrast to conventional designs, when only one disk is exposed, P and Q may be resynchronized in embodiments consistent with the invention without a risk of data loss.",{"@attributes":{"id":"p-0080","num":"0085"},"figref":"FIG. 4","b":["402","404","406"]},"In the event that an abnormal event occurs that interrupts the completion of the parity update, then the controller will need to restore the data and parity information to a state in which they are synchronized.","The ease in which such resynchronization can occur depends on whether the disk array has an exposed drive or not. If there is no exposed drive, then, in step , the controller uses the state indicator to determine which information that is known to be good and to resynchronize the data and parity using this information. If there is an exposed drive, however, then, in step , the controller uses the state indicator and the saved A to resynchronize the data and parity information. Once the data and parity are restored to a synchronized state, then the controller may try once again, in step , to perform the update of D if necessary.","Thus, embodiments of the present invention provide a method and system, within a RAID-6 or similar disk array environment, that can correctly recover from an abnormal interruption of a parity update operation even when a disk in the array is exposed. Various modifications may be made to the illustrated embodiments without departing from the spirit and scope of the invention. Therefore, the invention lies in the claims hereinafter appended."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
