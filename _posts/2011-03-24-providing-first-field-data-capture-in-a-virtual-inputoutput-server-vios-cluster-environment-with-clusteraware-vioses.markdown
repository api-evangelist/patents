---
title: Providing first field data capture in a virtual input/output server (VIOS) cluster environment with cluster-aware vioses
abstract: A first virtual I/O server (VIOS) provides a cluster aware (CA) operating system (OS) executing on a processor resource of the first VIOS to register the first VIOS within a VIOS cluster. The first VIOS comprises a first field/failure data capture (FFDC) module that executes within the first VIOS and performs the functions of: receiving from an event listener a signal indicating that an FFFDC event/condition has been detected by the first VIOS; and automatically transmitting FFDC data to the shared storage repository for storage of the FFDC data within the shared storage repository. The FFDC module further performs the functions of: transmitting to one or more second VIOSes within the VIOS cluster, one or more messages to inform the one or more second VIOSes of an occurrence of the FFDC event/condition that was detected by the first VIOS.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08615676&OS=08615676&RS=08615676
owner: International Business Machines Corporation
number: 08615676
owner_city: Armonk
owner_country: US
publication_date: 20110324
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","BRIEF SUMMARY","DETAILED DESCRIPTION"],"p":["1. Technical Field","The present invention relates in general to distributed data processing systems and in particular to distributed data processing systems with cluster-aware virtual input\/output servers (VIOSes). Still more particularly, the present invention relates to a method, data processing system and computer program product that implements first field data capture in a VIOS cluster.","2. Description of the Related Art","Virtualized data processing system configuration, which provides the virtualization of processor, memory and Operating System (OS) resources are becoming more and more common in the computer (and particularly the computer server) industry. To a lesser extent, storage virtualization is also known and provided in limited environments. However, within the virtualization computing environment, storage virtualization and management is implemented as a separate virtualization model from server virtualization and management. Thus, different client logical partitions (LPARs) associated with different virtualized server systems may access the same storage access network (SAN) storage. However, the client LPARs on one server do not have any \u201cknowledge\u201d of whether the SAN disk that the client LPAR is trying to access is being used by some other client LPAR belonging to the same server or another server.","Thus, the increase in the utilization of virtualization technology also leads to an increase in the potential problems and issues involved with implementing new hardware\/software stacks. Included in such problems are those conditions that can prevent system input\/output (I\/O) operations from progressing due to new bugs that exist or manifest themselves in either the new hardware\/software stacks or in legacy hardware\/software stacks (e.g., due to compatibility issues. When these error conditions (or incompatibility scenarios) arise, system administrators potentially can be required to manually capture information in order to provide sufficient first field data capture (FFDC) information to a companies support department. This manual capture of FFDC is a time consuming process and susceptible to user errors.","Disclosed are a method, a data processing system, and a computer program product which provide first failure\/field data capture (FFDC) and centralized storage of FFDC data within a DPS configured with cluster aware Virtual Input\/Output (I\/O) Servers (VIOSes) within a VIOS cluster. In a first VIOS partition, the method provides: a cluster aware (CA) operating system (OS) executing on a processor resource within the first VIOS partition to register the first VIOS within a VIOS cluster and enable communication of the first VIOS with one or more second VIOSes within the VIOS cluster and to a shared VIOS database; and a first field\/failure data capture (FFDC) module that executes within the first VIOS and which performs the functions of: receiving from an event listener an signal indicating that an FFFDC event\/condition has been detected by the first VIOS; and automatically transmitting FFDC data to the shared storage repository for storage of the FFDC data within the shared storage repository.","The above summary contains simplifications, generalizations and omissions of detail and is not intended as a comprehensive description of the claimed subject matter but, rather, is intended to provide a brief overview of some of the functionality associated therewith. Other systems, methods, functionality, features and advantages of the claimed subject matter will be or will become apparent to one with skill in the art upon examination of the following figures and detailed written description.","The above as well as additional objectives, features, and advantages of the present invention will become apparent in the following detailed written description.","The illustrative embodiments provide a method, data processing system, and computer program product that enable first failure\/field data capture (FFDC) and centralized storage of FFDC data within a DPS comprising a Virtual Input\/Output (I\/O) Server (VIOS) cluster in which the VIOSes are cluster aware. In a first virtual I\/O server (VIOS) partition, the method provides: a cluster aware (CA) operating system (OS) executing on a processor resource within the first VIOS partition to register the first VIOS within a VIOS cluster and enable communication of the first VIOS with one or more second VIOSes within the VIOS cluster and to a shared VIOS database; and a first field\/failure data capture (FFDC) module that executes within the first VIOS and which performs the functions of: receiving from an event listener an signal indicating that an FFDC event\/condition has been detected by the first VIOS; and automatically transmitting FFDC data to the shared storage repository for storage of the FFDC data within the shared storage repository.","In the following detailed description of exemplary embodiments of the invention, specific exemplary embodiments in which the invention may be practiced are described in sufficient detail to enable those skilled in the art to practice the invention, and it is to be understood that other embodiments may be utilized and that logical, architectural, programmatic, mechanical, electrical and other changes may be made without departing from the spirit or scope of the present invention. The following detailed description is, therefore, not to be taken in a limiting sense, and the scope of the present invention is defined by the appended claims and equivalents thereof.","Within the descriptions of the different views of the figures, similar elements are provided similar names and reference numerals as those of the previous figure(s). The specific numerals assigned to the elements are provided solely to aid in the description and are not meant to imply any limitations (structural or functional or otherwise) on the described embodiment.","It is understood that the use of specific component, device and\/or parameter names (such as those of the executing utility\/logic\/firmware described herein) are for example only and not meant to imply any limitations on the invention. The invention may thus be implemented with different nomenclature\/terminology utilized to describe the components\/devices\/parameters herein, without limitation. References to any specific protocol or proprietary name in describing one or more elements, features or concepts of the embodiments are provided solely as examples of one implementation, and such references do not limit the extension of the invention to embodiments in which different element, feature or concept names are utilized. Thus, each term utilized herein is to be given its broadest interpretation given the context in which that terms is utilized. For example, as utilized herein, the term cluster-aware refers to the operational state of each VIOS within the cluster where the VIOSes contain information about which other VIOSes are connected within the cluster, the configuration of the different CECs within the DPS supported by the cluster, information about which client LPARs are supported by each VIOS, and other state and operating information and data related to performing VIO operations using the physical I\/O devices of the DPS and those of the distributed storage repository (storage repository). Cluster awareness is supported by both a shared, networked VIOS database and locally maintained copies of VIOS cluster data within each VIOS.","As further described below, implementation of the functional features of the invention is provided within processing devices\/structures and involves use of a combination of hardware, firmware, as well as several software-level constructs (e.g., program code). The presented figures illustrate both hardware components and software components within example data processing architecture having a specific number of processing nodes (e.g., computing electronic complexes). The illustrative and described embodiments assume that the system architecture may be scaled to a much larger number of processing nodes.","In the following descriptions, headings or section labels are provided to separate functional descriptions of portions of the invention provided in specific sections. These headings are provided to enable better flow in the presentation of the illustrative embodiments, and are not meant to imply any limitation on the invention or with respect to any of the general functions described within a particular section. Material presented in any one section may be applicable to a next section and vice versa. The following sequence of headings and subheadings are presented within the specification:","A. General Architecture","B. Cluster-Aware VIOS","C. VIOS Shared DB for Cluster Management","D. FFDC within a VIOS Cluster Environment\n\n","With specific reference now to , there is depicted a block diagram of an example cluster-aware (CA), distributed data processing system (DPS) architecture , within which the functional aspects of the described embodiments may advantageously be implemented. For simplicity, cluster-aware, distributed DPS architecture  shall be referred to herein simply as DPS . DPS  comprises a plurality of computing nodes, each referred to herein as a computing electronic complex (CEC), of which CECs A and B are illustrated. The number of CECs within DPS  may vary, ranging from a single CEC in a smaller system extending up to hundreds or thousands of CECs, in larger scaled systems. For simplicity, the embodiments shall be described from the perspective of a single CEC (CEC A) or two CECs (CECs A, B). Each CEC A-B comprises at least one (and in most instances a plurality of) Virtual Input\/Output Server  (also referred to herein as a VIO Server or VIOS), with functionality as described below. The actual number of VIOSes  within each CEC  of DPS  is a design feature and may vary. Also supported within each CEC A-B are client logical partitions (interchangeably referred to as client LPARs or \u201cclients\u201d), of which a first two clients, clientA and clientB , are illustrated. As described below, with reference to , client LPARs  are logical partitions of a virtualized (or operating system partitioned) computing system. The actual number of clients within each CEC  may vary and could range from a single client to hundreds or thousands of clients, without limitation. For efficiency in presenting the inventive concepts herein, only two clients are presented within each CEC  of the various illustrative and described embodiments.","DPS  also comprises a distributed storage facility, accessible to each of the CECs  and the components within the CECs . Within the described embodiments, the distributed storage facility will be referred to as distributed storage repository , and the distributed storage repository  enables several of the client level functional features provided by the embodiments described herein. Distributed storage repository  provides a single view of storage that is utilized by each CEC  and for each client  of each CEC  within a cluster-aware, distributed system. Distributed storage repository  comprises local physical storage  and network storage , both of which comprise multiple physical storage units  (e.g., disks. solid state drives, etc.). The physical disks making up distributed storage repository  may be distributed across a storage network (e.g., a SAN). Additionally, distributed storage repository  provides a depository within which is stored and maintained the software utility, instruction code, OS images, client images, data (system, node, and client level), and\/or other functional information utilized in maintaining the client-level, system management, and storage-level operations\/features of DPS . In addition to distributed storage repository , DPS  also comprises a VIOS database (DB) , which may also be a distributed storage facility comprising physical disks across a storage network. VIOS DB (or DB)  is a repository that stores and provides access to various cluster configuration data and other functional components\/modules and data structures that enable the various cluster-aware functionality described herein. In one embodiment, portions of distributed storage repository  may be allocated to provide storage pools for a cluster. Each VIOS  of the cluster maintains a local view of the DB  and updates the cluster level information\/data\/data structures within DB  as such information\/data is created or updated.","Communication between each VIOS  of each CEC  as well as with the VIOSes of at least one other CEC  is generally supported via a plurality of inter-CEC interconnects, illustrated as bi-directional, dashed lines connecting pairs of VIOSes . The arrows indicated two way data exchange or communication between components. In addition to the inter-CEC interconnects, each VIOS  is also connected to distributed storage repository  via VIOS-to-Store or CEC-to-Store interconnects, which are also illustrated as full lined bi-directional arrows. Also, each VIOS  is connected to DB  via VIOS-to-DB interconnects, presented as dashed and dotted lines. With the exception of the inter-CEC connectors running from a first VIOS (e.g., VIOS ) of a first CEC to a second VIOS (e.g., VIOS ) on the same CEC, the various interconnects represent a network level connectivity between the VIOS nodes of the cluster and the DB  and the distributed storage repository . As utilized herein, references to one or more \u201cnodes\u201d, are assumed to refer specifically to a VIOS within the cluster. DPS  also comprises a management console  on which a management tool (not shown) executes.","Turning now to , there is illustrated another view of DPS  illustrating the network-based connection of the CECs  to the distributed storage repository  and DB .  illustrates in greater detail the network connectivity of VIOSes and CECs to each other and to Distributed storage repository . With this view, CEC_A (Node_A) A and CEC_B (Node_B) B comprise similar constructs as presented in . Each CEC  within DPS  connects to distributed storage repository  via one or more networks and\/or I\/O interconnect\/switch fabric (generally illustrated as interconnect\/network fabric ). The descriptions and illustrations assume that at least some of the CECs  of DPS  and distributed storage repository  are located remotely from each other, including being located in different countries, for example, such that no direct physical connectivity exists between the respective devices. For simplicity, the embodiments are described as having primary interconnect\/network  comprising a private wide area network (WAN) or a public WAN (such as the Internet), although other network types (e.g., a local area network) are possible and supported.","As depicted, in one or more embodiments, each CEC  is also connected to one or more neighbor CECs , in order to provide efficient fail-over and\/or mobility support and other functions, as described hereinafter. As utilized herein, the term neighbor refers to a connected second CEC with which a first CEC is able to communicate, and references to a neighbor CEC is not limited to a second CEC in geographic proximity to the first CEC. CEC_A A and CEC_B B are illustrated connected to each other via some connecting medium, which may include a different network (such as a local area network)  or some type of direct interconnect (e.g., a fiber channel connection) when physically close to each other. The connection between neighbor CECs A and B is illustrated as a direct line connection or a secondary network connection () between CECs A and B. However, it is appreciated that the connections are not necessarily direct, and may actually be routed through the same general interconnect\/network  as with the other CEC connections to distributed storage repository . In one or more alternate embodiments, the connections between CECs may be via a different network (e.g., network , ), such as a local area network (LAN).","As depicted, each CEC  comprises one or more network interfaces  and one or more I\/O adapters  to enable the CEC  and thus the other components (i.e., client partitions) of the CEC  to engage in network level communication, as described below. Specifically, each VIOS  emulates virtual client I\/O adapters to enable communication by the client LPARs  with distributed storage repository  and\/or other clients, within the same CEC or on a different CEC. The VIOSes  emulate virtual I\/O adapters and communicates with distributed storage repository  by connecting with corresponding virtual sever I\/O adapters at distributed storage repository . The VIOSes  within each CEC  are thus able to support client level access to distributed storage  and enable the exchange of system level and client level information with distributed storage repository .","In addition, each VIOS  also comprises the functional components\/modules and data to enable the VIOSes  within DPS  to be aware of the other VIOSes anywhere within the cluster (DPS ). From this perspective, the VIOSes  are referred to herein as cluster-aware, and their interconnected structure within DPS  thus enables DPS  to also be interchangeably referred to as cluster-aware DPS . As a part of being cluster-aware, each VIOS  also connects to DB  via network  and communicates cluster-level data with DB  to support the cluster management functions described herein.","Also illustrated by  is an initial view of the component make-up of an example distributed storage repository  and an initial listing of some components of DB . To support the virtual I\/O operations with the VIOSes  and the associated virtual client I\/O adapters, distributed storage repository  comprises communication infrastructure . Communication infrastructure  comprises network interface(s)  and a plurality of server I\/O adapters  utilized for cluster-level communication and enabling access to data\/code\/software utility stored on distributed storage repository  to complete I\/O operations thereto. Specifically, these server I\/O adapters are also presented as virtual sever I\/O adapters, which are paired with virtual I\/O adapters (via emulation of physical I\/O adapters ) that are assigned to specific clients  of CECs .","As shown, distributed data store  generally comprises general storage space  (the available local and network storage capacity that may be divided into storage pools) providing assigned client storage  (which may be divided into respective storage pools for a group of clients), unassigned, spare storage , and backup\/redundant CEC\/VIOS\/client configuration data storage . In one embodiment, the assigned client storage is allocated as storage pools, and several of the features related to the sharing of a storage resource, providing secure access to the shared storage, and enabling cluster-level control of the storage among the VIOSes within a cluster are supported with the use of storage pools. When implemented within a VIOS cluster, storage pools provide a method of logically organizing one or more physical volumes for use by the clients supported by the VIOSes making up the VIOS cluster.  illustrates an example configuration of a storage pool utilized within a cluster aware DPS . Specifically,  provides details on how these physical volumes are used within the storage pool. As shown, storage pool  within the cluster contains one or more Disk Groups . Disks Groups  provide administrators the ability to provide access policies to a given subset of physical volumes  within the storage pool . Once a disk group  has been defined, administrators can further categorize the subset into Storage Tiers  based on disk characteristics. Once a Disk Group  and Storage Tier  have been defined, administrators carve Logical Units (LU)  to be exported to client partitions ().","With the capability of virtual pooling provided herein, an administrator allocates storage for a pool and deploys multiple VIOSes from that single storage pool. With this implementation, the SAN administration functions is decoupled from the system administration functions, and the system administrator can service customers (specifically clients  of customers) or add an additional VIOS if a VIOS is needed to provide data storage service for customers. The storage pool may also be accessible across the cluster, allowing the administrator to manage VIOS work loads by moving the workload to different hardware when necessary. With the cluster aware VIOS implementation of storage pools, additional functionality is provided to enable the VIOSes to control access to various storage pools, such that each client\/customer data\/information is secure from access by other clients\/customers.","Returning now to , located within storage  of distributed storage repository (DSR)  is FFDC data store , within which FFDC Data  is stored. Specific functionality of FFDC data store  is provided (or described) in greater detail in Section D of the present disclosure. In an alternate embodiment, the FFDC Data  can be stored within VIOS DB . Regardless of the implementation, both storage locations ( or ) are accessible to management tool  and enable access by system administrative tools\/personnel to the FFDC data .","As illustrated, DSR  further comprises a plurality of software, firmware and\/or software utility components, including DSR configuration utility , DSR configuration data  (e.g., inodes for basic file system access, metadata, authentication and other processes), and DSR management utility .","To support the cluster awareness features of the DPS , and in accordance with the illustrative embodiment, DPS  also comprises VIOS database (DB) , in which is stored various data structures generated during set up and\/or subsequent processing of the VIOS cluster-connected processing components (e.g., VIOSes and management tool). DB  comprises a plurality of software or firmware components and\/or and data, data modules or data structures, several of which are presented in , for illustration. Among these components are cluster management (CM) utility , VIO AdapterID data structure , cluster configuration data , Client identifying (ID) data , active nodes list , and I\/O redundancy data , among others. These various components support the various clustering functionality and cluster-aware I\/O operations of the one or more VIOSes , as described herein. Additional features of DB  and distributed storage repository  as well as the specific components or sub-components that enable the various clustering functionality are presented within the description of the remaining figures and throughout the description of the various presented embodiments.","The various data structures illustrated by the figures and\/or described herein are created, maintained and\/or updated, and\/or deleted by one or more operations of one or more of the processing components\/modules described herein. In one embodiment, the initial set up of the storage pools, VIOS DB  and corresponding data structures is activated by execution of a cluster aware operating system by management tool  and\/or one or more VIOSes . Once the infrastructure has been established, however, maintenance of the infrastructure, including expanding the number of nodes, where required, is performed by the VIOSes  in communication with DB  and the management tool .","Also associated with DPS  and communicatively coupled to distributed storage repository  and DB  and VIOSes  is management console , which may be utilized by an administrator of DPS  (or of distributed storage repository  or DB ) to access DB  or distributed storage repository  and configure resources and functionality of DB  and of distributed storage repository  for access\/usage by the VIOSes  and clients  of the connected CECs  within the cluster. As shown in  and described throughout the specification, management tool  is implemented within management console . However, it is appreciated that (resources of) any node within DPS  may be selected\/elected to perform the functions of management tool , and the selected node would then perform one or more of the below described cluster creation and the other cluster monitoring and management functions, utilizing the availability of the resources provided by DB  and distributed storage repository .","In an alternate embodiment, management tool  is an executable module that is executed within a client partition at one of the CECs within DPS . In one embodiment, the management tool  controls the operations of the cluster and enables each node within the cluster to maintain current\/updated information regarding the cluster, including providing notification of any changes made to one or more of the nodes within the cluster. In one embodiment, management tool  registers with a single VIOS and is thus able to retrieve\/receive cluster-level data from VIOS, including FFDC data () of the entire cluster. In one implementation, the management tool  registers with a primary node of the cluster, as defined in greater details in Section D below.","With reference now to , there is presented a third view of an example DPS , emphasizing a processing system architecture  (i.e., architecture of the individual CECs, and specifically CEC_A A). CEC_A A (CEC A) serves as the example CEC that is described in greater detail in  and throughout the specification. CEC A is presented as a server that comprises hardware components and software\/firmware\/OS components that are logically partition to create a plurality of virtualized machine partitions, which are assigned as client logical partitions (LPARs) and virtual I\/O servers (VIOSes). Hardware components  of example CEC A comprises one or more processors A-P, one or more memories A-M, and local storage . The processors A-P are interconnected with one or a plurality of memories A-M and with local storage  via a bus, interconnect\/switch or an interconnect fabric (not specifically shown). The specific internal connectivity of components, which may be distributed across a large scale interconnect fabric, is not germane to the described embodiments, and no further detail is presented regarding the particular type of interconnectivity between the system hardware components.","Also included within hardware components  are one or more physical network interfaces  by which CEC_A A connects to an external network, such as network , among others. Additionally, hardware components  comprise a plurality of I\/O adapters A-E, which provides the I\/O interface for CEC_A A. I\/O adapters A-E are physical adapters that enable CEC_A  to support I\/O operations via an I\/O interface with both locally connected and remotely (networked) connected I\/O devices, including SF storage . Examples of I\/O adapters include Peripheral Component Interface (PCI), PCI-X, or PCI Express Adapter, and Small Computer System Interconnect (SCSI) adapters, among others. CEC  is logically partitioned such that different I\/O adapters  are virtualized and the virtual I\/O adapters may then be uniquely assigned to different logical partitions.","Logically located above the hardware level () is a virtualization management component, provided as a Power Hypervisor (PHYP)  (trademark of IBM Corporation), as one embodiment. While illustrated and described throughout the various embodiments as PHYP , it is fully appreciated that other types of virtualization management components may be utilized and are equally applicable to the implementation of the various embodiments. PHYP  has an associated service processor  coupled thereto within CEC . Service processor  may be used to provide various services for one or more logical partitions. PHYP  is also coupled to hardware management controller (HMC) , which exists outside of the physical CEC . Operations of the different logical partitions may be controlled through HMC , which is a separate data processing system from which a system administrator may perform various functions, such as reallocation of resources to different logical partitions.","CEC_A A further comprises a plurality of user-level logical partitions (LPARs), of which a first two are shown, represented as individual client LPARs A-B within CEC A. According to the various illustrative embodiments, CEC A supports multiple clients and other functional operating OS partitions that are \u201ccreated\u201d within a virtualized environment. Each LPAR, e.g., client LPAR A, receives an allocation of specific virtualized hardware and OS resources, including virtualized CPU A, Memory A, OS A, local firmware  and local storage (LStore) . Each client LPAR  includes a respective host operating system  that controls low-level access to hardware layer () of CEC A and\/or to virtualized I\/O functions and\/or services provided through VIOSes . In one embodiment, the operating system(s) may be implemented using OS\/400, which is designed to interface with a partition management firmware, such as PHYP , and is available from International Business Machines Corporation. It is appreciated that other types of operating systems (such as Advanced Interactive Executive (AIX) operating system, a trademark of IBM Corporation, Microsoft Windows\u00ae, a trademark of Microsoft Corp, or GNU\u00ae\/Linux\u00ae, registered trademarks of the Free Software Foundation and The Linux Mark Institute) for example, may be utilized, depending on a particular implementation, and OS\/400 is used only as an example.","Additionally, according to the illustrative embodiment, CEC A also comprises one or more VIOSes, of which two, VIOS A and B, are illustrated. In one embodiment, each VIOS  is configured within one of the memories A-M and comprises virtualized versions of hardware components, including CPU , memory , local storage  and I\/O adapters , among others. According to one embodiment, each VIOS  is implemented as a logical partition (LPAR) that owns specific network and disk (I\/O) adapters. Each VIOS  also represents a single purpose, dedicated LPAR. The VIOS  facilitates the sharing of physical I\/O resources between client logical partitions. Each VIOS  allows other OS LPARs (which may be referred to as VIO Clients, or as Clients ) to utilize the physical resources of the VIOS  via a pair of virtual adapters. Thus, VIOS  provides virtual small computer system interface (SCSI) target and shared network adapter capability to client LPARs  within CEC . As provided herein, VIOS  supports virtual real memory and virtual shared storage functionality (with access to distributed storage repository ) as well as clustering functionality. Relevant cluster level data is stored within local storage  of each VIOS . For example, as illustrated within , local storage (LS)  comprises cluster configuration data , cluster state data , active nodes list , and in one embodiment FFDC data , where the \u201ca\u201d is provided to distinguish that FFDC data of VIOS () from other FFDC data () that would be stored locally to other VIOSes () with in the cluster. Other features and\/or functionality of  are described below.","Within CEC A, VIOSes  and client LPARs  utilize an internal virtual network to communicate. This communication is implemented by API calls to the memory of the PHYP . The VIOS  then bridges the virtual network to the physical (I\/O) adapter to allow the client LPARs  to communicate externally. The client LPARs  are thus able to be connected and inter-operate fully in a VLAN environment.","Those of ordinary skill in the art will appreciate that the hardware, firmware\/software utility, and software components and basic configuration thereof depicted in , B and  may vary. The illustrative components of DPS  and specifically those within CEC A are not intended to be exhaustive, but rather are representative to highlight some of the components that are utilized to implement certain of the described embodiments. For example, different configurations of data processing systems\/CECs devices may be provided, containing other devices\/components, which may be used in addition to or in place of the hardware depicted, and may be differently configured. The depicted example is not meant to imply architectural or other limitations with respect to the presently described embodiments and\/or the general invention. The CEC  depicted in the various figures may be, for example, an IBM eServer pSeries system, a product of International Business Machines Corporation in Armonk, N.Y., running the Advanced Interactive Executive (AIX) operating system or LINUX operating system.","B. Cluster-Aware VIOS","Certain of the features associated with the implementation of a cluster aware VIOS (e.g., VIOS  of , B and ) are introduced above with reference to the description of the previous figures, and particularly . Descriptions of the specific functionality of the VIOS  will continue to be provided with reference to the illustrations of , B and . As presented by , each VIOS  is a virtual machine instance that emulates hardware in a virtualized environment. The VIOS  is tasked with emulating SCSI storage devices, and the VIOS  provides client LPARs  with access to distributed storage repository  in cooperation with the PHYP . Configuration of the VIOS  is performed through the hardware management tools of HMC . SCSI storage devices support a set of commands that allow SCSI initiators the ability to control access to storage (). Database programs, for example, may manage access to distributed storage repository  through a set of SCSI commands commonly referred to as persistent reserve. Other types of reserves are also supported by VIOS , and the collective group of such commands is referred to herein as reserve commands.","As provided herein, each VIOS  allows sharing of physical I\/O resources between client LPARs, including sharing of virtual Small Computer Systems Interface (SCSI) and virtual networking These I\/O resources may be presented as internal or external SCSI or SCSI with RAID adapters or via Fibre-Channel adapters to distributed storage repository . The client LPAR , however, uses the virtual SCSI device drivers. In one embodiment, the VIOS  also provides disk virtualization for the client LPAR by creating a corresponding file on distributed storage repository  for each virtual disk. The VIOS  allows more efficient utilization of physical resources through sharing between client LPARs, and supports a single machine (e.g., CEC ) to run multiple operating system (OS) images concurrently and isolated from each other.","In one or more embodiments, the VIOS operating system(s) is an enhanced OS that includes cluster-aware functionality and is thus referred to as a cluster aware OS (CA_OS). One embodiment, for example, utilizes cluster aware AIX (CAA) as the operating system. According to one embodiment, cluster-awareness enables multiple independent physical systems to be operated and managed as a single system. With reference now to both  and , which provides an expanded view of functional components\/modules within example VIOS . As provided within VIOS  of CEC A, VIOS  comprises cluster aware (CA) OS kernel  (or simply CA_OS ), as well as LPAR function code  for performing OS kernel related functions for the VIOS LPARs . When executed within two or more nodes of DPS, CA_OS  enables various clustering functions, such as forming a cluster, adding members to a cluster, and removing members from a cluster, as described in greater detail below. CA_OS  manages the VIOS LPARs  and enables the VIOSes within a cluster to be cluster aware. CA_OS  comprises several functional modules. In one or more embodiments, CA_OS  can comprise cluster management (CM) utility , which supports the configuration of the VIOS to enable cluster-awareness and cluster-level functionality, such as redundant virtual I\/O. Each of the additional software components\/modules of CA_OS  may be presented as a functional module within CM utility, in one embodiment, and each module may thus be described as being associated with or a component within CM utility  throughout the remainder of this specification. In one embodiment, CM utility  may be a separate utility that is locally installed or downloaded (from DB , for example) as an enhancement to an existing OS within a CEC  or VIOS , when the VIOS  is initially being configured for operation within a VIOS cluster. CM utility  is then executed when configuring the individual VIOS to create or join a cluster and\/or become a cluster-aware node within the VIOS cluster. With this implementation methodology, CM utility  executes within VIOS  and enables the OS to support the various cluster-awareness and other cluster-level features and functionality. In an alternate embodiment, CA_OS  includes all the clustering features and functionality and establishes the various clustering functions\/features when the VIOS  joins the cluster and\/or during configuration of VIOS  to become cluster-aware.","In one implementation, functional components of CM utility  are encoded on local device storage (L_Store ) of a corresponding VIOS , and these components are automatically executed on VIOS start up or initiation such that the VIOS  becomes automatically configured as a part of the VIOS cluster when the VIOS  is initially activated. On initial set up of the VIOS, VIOS API, kernel extensions and virtual adapters are configured within VIOS to enable communication with the other VIOSes, the VIOS DB , and with the distributed storage repository . During this initial setup of the VIOS , the VIOS  executes a registration module of CM utility  to register VIOS  with the cluster. The registration module enables VIOS  to retrieve\/download or have forwarded from DB  (on successful registration with the cluster) any additional CM software components and\/or cluster-level information and\/or data required to establish full cluster awareness when the VIOS has completed installation and is activated within the CEC . Thus, in one embodiment, in addition to the locally stored CA_OS components and software modules of CM utility , other functional components of CM utility  may be downloaded from DB  when CEC is powered on or when one or more VIOSes  are enabled on CEC . Once the VIOS  has completed its setup, one or more client LPARs  that are activated within CEC  may be assigned to VIOS , and VIOS  subsequently performs the various I\/O operations initiated by the client  (as initiator) or directed to the client  (as target). Updates to the local VIOS data may periodically be made as changes are made within the VIOS cluster and\/or as one or more new client LPARs  are added to the CEC  requiring VIOS support. In one embodiment, CM utility  may also enable retrieval and presentation of a comprehensive view of the resources of the entire cluster.","Returning now to the figures as further presented by the illustrative embodiments (i.e., , with emphasis on ), VIOS  includes one or more additional functional modules\/components, such as VIO adapter(s) (interface) , and virtual I\/O drivers\/utility , which provides I\/O functionality to VIOS  and enables VIOS  to route data traffic to and from data structures and storage within distributed storage repository  and\/or DB . Virtual I\/O adapter(s)  and CM utility  also enable the VIOS  to provide each client LPAR  with access to the full range of storage accessible within distributed storage repository  and other cluster-supported functionalities, as described herein. CA_OS kernel  comprises three layers of software stack, OS kernel software stack , storage virtualization software stack , VIOS clustering software stack .","The illustrative embodiment of  also presents several of the components\/modules of CM utility . Included among this non-exclusive list of components\/modules are: primary node election utility , utilized during a primary node election process to allow VIOS  to register as a primary node of the VIOS cluster; node monitoring and reporting utility  utilized to enable registration by a management tool (e.g., management tool ); I\/O redundancy data , which specifies neighboring VIOSes to hand off I\/O operations to when a condition at the VIOS or on the connection fabric prevents the VIOS from performing I\/O operations for one or more of the registered clients; and cluster registration (or configuration data request) module , which initiates and controls the registration of the VIOS with the VIOS cluster during initialization of the VIOS within the DPS  (). In addition to these components, CM Utility  also comprises components specific to event monitoring and FFDC operations. Included among these components are the following non-exclusive list of components: lifecycle (LC) events module , which tracks events or conditions at the VIOS that are considered (or pre-defined to be) life cycle events; resource alert reporting module , which detects when an allocated, shared resource (e.g., an amount of storage within a storage pool assigned to one or more clients serviced by the VIOS) reaches some pre-established threshold condition (e.g., a percentage usage of the storage pool); events listener , which monitors for the occurrence of one or more events detected by the LC events module  and\/or the Resource module  and\/or any other module that may report events of interest to the VIOS, to the cluster, or to system administrators; and FFDC module , which responds to a triggered from events listener  by forwarding associated FFDC data () to an appropriate data store within a shared storage that is accessible to all VIOSes\/nodes within the cluster. According to one or more embodiments, FFDC module  also generates and transmits, in response to certain events, one or more alerts to other nodes within the cluster to inform the other nodes of the occurrence of the specific event.","Returning to the illustrative embodiment of , each client LPAR  communicates with VIOS  via PHYP . VIOS  and client LPAR A-B are logically coupled to PHYP , which enables\/supports communication between both virtualized structures. Each component forwards information to PHYP , and PHYP  then routes data between the different components in physical memory (A-M). In one embodiment, a virtualized interface of I\/O adapters is also linked to PHYP , such that I\/O operations can be communicated between the different logical partitions and one or more local and\/or remote I\/O devices. As with local I\/O routing, data traffic coming in and\/or out of I\/O adapter interface or network interface from a remote I\/O device is passed to the specific VIOS  via PHYP .","It is appreciated that while various functional aspects of the clustering operations are described as separate components, modules, and\/or utility and associated data constructs, the entire grouping of different components\/utility\/data may be provided by a single executable utility\/application, such as CA_OS  or CM utility . Thus, in one embodiment, CA_OS  executes within VIOS  and generates a plurality of functional components within VIOS  and within DB . Several of these functional components are introduced within ,  and  and others are described throughout the various embodiments provided herein. For simplicity in the descriptions which follow, references to CM utility  and CA_OS  will be assumed to be referring to the same general component (i.e., CM utility  being a subcomponent of CA_OS ), and the terms can be utilized interchangeably throughout the specification.","With the above introduced system configuration of , B,  and , a first VIOS (through a communication channel established via PHYP ), grants access to another VIOS through one or more virtual adapters. VIOS  includes the functionality to query PHYP  for the identity of the Client LPAR  on the CEC  where the VIOS  is currently running.","With the cluster aware VIOS infrastructure, different VIOSes  associated with different CECs  access the distributed storage repository  and cluster-level information is shared\/communicated across the VIOS cluster (via VIOS DB ) while each client I\/O process is being performed. In this manner the VIOS associated with a first client on a first CEC is aware of which SAN disk resources are being accessed by a second client on a second CEC (or on the same CEC). With this awareness factored into the I\/O exchange with the distributed storage repository , the VIOS associated with the first client can avoid accessing the same storage resource that is concurrently being utilized by the second client, thus preventing data integrity issues, which could potentially cause data corruption and client partition crashes.","As described herein, a cluster is a set of one or more networked VIOS partitions, where each VIOS within the cluster has access to a common set of physical volumes. The physical volume resides within the VIOS cluster and is utilized to provide block storage. Implementation of the cluster awareness with the VIOSes of the cluster enables the VIOSes to provide cluster storage services to virtual clients (client LPARs ). The VIOS software stack provides the following advanced capabilities, among others: Storage Aggregation and Provisioning; Thin Provisioning; Virtual Client Cloning; Virtual Client Snapshot; Virtual Client Migration; Distributed Storage Repository; Virtual Client Mirroring; and Server Management Infrastructure integration. More generally, the VIOS protocol allows distributed storage to be viewed as centralized structured storage with a namespace, location transparency, serialization, and fine grain security. The VIOS protocol provides storage pooling, distributed storage, and consistent storage virtualization interfaces and capabilities across heterogeneous SAN and network accessible storage (NAS). In order to provide block storage services utilizing the distributed repository, each VIOS configures virtual devices to be exported to virtual clients. Once each virtual device is successfully configured and mapped to a virtual host (VHOST) adapter, the clients may begin utilizing the devices as needed. In one embodiment, the virtualization is performed utilizing POWER\u2122 virtual machine (VM) virtualization technology, which allows the device configuration process to occur seamlessly because the physical block storage is always accessible from the OS partition.","C. VIOS Shared DB for Cluster Management","As described herein, implementation of the cluster awareness with the VIOSes of the cluster enables the VIOSes to provide cluster storage services to virtual clients (). The VIOS software stack provides the following advanced capabilities, among others: Storage Aggregation and Provisioning; Thin Provisioning; Virtual Client Cloning; Virtual Client Snapshot; Virtual Client Migration; Distributed Storage Repository; Virtual Client Mirroring; and Server Management Infrastructure integration. More generally, the VIOS protocol allows distributed storage to be viewed as centralized structured storage with a namespace, location transparency, serialization, and fine grain security. The VIOS protocol provides storage pooling, distributed storage, and consistent storage virtualization interfaces and capabilities across heterogeneous SAN and network accessible storage (NAS). In order to provide block storage services utilizing the distributed repository, each VIOS configures virtual devices to be exported to virtual clients. Once each virtual device is successfully configured and mapped to a virtual host (VHOST) adapter, the clients may begin utilizing the devices as needed. In one embodiment, the virtualization is performed utilizing POWER\u2122 virtual machine (VM) virtualization technology, which allows the device configuration process to occur seamlessly because the physical block storage is always accessible from the OS partition. When a virtual target device is removed, the local OS cache (local storage) data entries are deleted. Within the clustered environment, removal of any of the LUs is noticed to the other VIOSes. According to the described method, a distributed device repository and local repository cache are utilized to ensure the nodes within the cluster become device level synchronized from each node (VIOS) in the cluster.","According to one embodiment, information needed to configure a virtual target device (VTD) is stored in DB . This database (DB ) can be accessed by all the nodes in the VIOS cluster, utilizing services provided by Cluster-Aware OS, such as, but not limited to Cluster-Aware AIX (CAA). Additionally, certain small levels of cluster data are stored in a local database (ODM) (e.g., virtualized portions of storage , ) on each node for the devices which exist on that node. This local storage is necessary in order for the processes running on the local node to be able to match the VIOS device with the correct information in the distributed database.","In one embodiment, DB  receives VIOS generated data from each VIOS across the cluster and DB  populates its various data structures with the received data. According to one embodiment, VIOS  creates a unique identifier (ID) (i.e., a ClientID) for each client that is mapped to the VIOS for I\/O processing. The VIOS  then stores the unique ClientID in ClientID data structure  () within DB . The DB  and by extension the ClientID data structure  are accessible to each VIOS partition in the cooperating cluster (DPS ). The VIOS  also generates an identifier for each virtual IT nexus (virtual I\/O AdapterID) that is utilized for each virtual adapter assigned to the client LPAR . These vio AdaptedIDs are stored in the AdapterID data structure  and are associated with their corresponding clientIDs (block ). With this use of DB  to maintain clientID-to-VIO Adapter mappings, each clientID can be associated with a corresponding one or more vio AdapterIDs, and every VIOS within the cluster is aware of the I\/O adapter mappings across the entire cluster.","In one embodiment, VIOS functionality is enhanced to enable assigning of client identifiers (ID) and unique virtual I\/O adapter IDs in a secure manner, while enabling storage pooling within virtual storage (within distributed storage repository ). According to the described implementation, the different clientID-vioAdapterID pairings are unique throughout the cluster, so that no two clients throughout the entire cluster can share a same virtual adapter and no two vioAdapterIDs are the same within a single client.","With information about each device being stored in the DB , operations on those devices can be performed from any VIOS node in the cluster, not just the node on which the device resides. When an operation on a device is performed on a \u201cremote\u201d (non-local) node (i.e. one other than the node where the device physically resides), the operation is able to make any changes to the device's information in the DB , as necessary. When corresponding changes are needed in the device's local database, the corresponding CM utility  enables the remote node to send a message (using cluster services) to the local node to notify the local node to make the required changes. Additionally, when a node in the cluster is booted up, or when the node rejoins the cluster after having been lost for any period of time, the node will autonomously reference the DB  in order to synchronize the data there with the local data of the node.","As an example, if an operation to delete a VIOS device from the local node is executed on a remote node, the operation will remove the information associated with that device from the DB , and send a message to the local node to tell the local node to remove the device from the local database. If the local node is down or not currently a part of the cluster, when the local node first boots up or rejoins the cluster, the local node will automatically access the DB , retrieve current data\/information that indicates that the information for one of the local devices has been removed, and delete that device from the local database records.",{"@attributes":{"id":"p-0070","num":"0071"},"figref":["FIG. 5","FIG. 5","FIG. 1B"],"b":["140","140","140","340","140","140","112","405","140","140","525","140","530","530","140","535","525","535","140","122","525","530","110","112","140","505","510","140","140","186","188","159","140","191","140","140"]},"In one embodiment, data stored within VIOS DB  is accessible to management tool  via a cluster communication infrastructure. When FFDC data  is stored at VIOS DB , this direct connection of management tool  enables management tool  to efficiently access all FFDC data  across the entire VIOS cluster from DB . In an alternate embodiment, management tool  is provided access to FFDC data  from any one or VIOSes  within DPS . In the illustrative embodiment, management tool  has a communication link  with VIOS , which servers as a primary node for the cluster. In one example scenario, different clients LPARs associated with different VIOS access different storage devices and do not have visibility to the storage accessed by other client LPARS and\/or to the data stored or accessed by those other client LPARS. Without implementation of the functionality of the described embodiments herein, this scenario can lead to duplication of data on different client LPARs and result in a waste of storage space. Additionally, if there is a need to update the data with the system, then the update function will have to be synced up on all the storage devices having the same data.","According to one embodiment, the VIOSes that are part of the cluster can query each other to get information regarding the storage and data seen by the other VIOS. This VIOS level query leads to efficient data discovery and substantially reduces (or eliminates) duplication of data. In one implementation, the events and alerts infrastructure enables a node (VIOS) to know which other node could potentially have access to the storage that has the required data, in the event that a node goes down. Further, the queries can be executed on any node in the cluster and still dynamically retrieve real time data. Thus, any one of the VIOSes can be queried by the management tool  to provide all the information for some other VIOS or for all the nodes within the cluster. The flexibility provided to the management tool further enhances the management tool's performance, as the management tool  can obtain all the data by querying just a single node, instead of having to query each node in the cluster, in sequence. As further illustrated by , management tool  may also retrieve or access FFDC data  from FFDC data store  within distributed storage repository .","D. First Failure\/Field Data Capture in VIOS Cluster Environment","According to one embodiment, when a virtual client (client LPAR ) experiences error conditions (e.g., problems due to a VIOS the client LPAR  is logically connected to or to side affects from issues affecting other nodes within the cluster), system administrators no longer have to manually capture information from each node within the cluster in order to provide sufficient first field data capture (FFDC) information to a support department. The clustered VIOS topology and other functionality associated therewith reduce the time consumption and the susceptibility of the manual process to user errors. Functional aspects of cluster-aware VIOS provide a mechanism that can simultaneously initiate and capture cluster wide FFDC information and store it within a single repository.","The below described embodiments are implemented within the various configurations of DPS  () having VIOSes  of one or more CECs  arranged in a VIOS cluster and supporting the I\/O operations of the client LPARs located on the one or more CECs . As provided herein, the VIOSes are cluster aware and share cluster-level data via VIOS DB . Further, the VIOSes  provide the VIO operations that enable access to distributed storage repository (storage repository) . The various presented embodiments further provide application of management tool () functionality and descriptions of the messaging and communication protocols (of the clustered VIOSes ) that collectively enable cluster-awareness and efficient I\/O and storage virtualization and I\/O and storage management within the DPS. These embodiments are supported\/provided by additional functionalities of (i.e., encoded within) the CA_OS  and\/or specifically CM utility .","According to one embodiment, CM utility  comprises functional modules that execute on the respective VIOS processor to enable efficient completion of FFDC functions within the DPS . The described embodiments enable system administrators to configure clustered environments FFDC techniques based on specific cluster entity life cycle events and alerts. This methods decreases the amount of manual FFDC capturing required by legacy software stacks which in turn reduces the amount of time, money, and resources required to capture such information within a clustered environment. As presented herein, one described embodiment provides Virtual-Cluster software stack  with FFDC data collecting and reporting functions that are added to further enhance the Storage Virtualization Stack  ().","D.1 VIOS Fabric Loss and Other FFDC Events","Specific examples of FFDC events or conditions for which FFDC data is generated and alerts and or notifications issued to nodes within the cluster are presented with reference to . Turning now to , there is illustrated a block diagram representation of the DPS  comprising a VIOS cluster having two or more VIOSes, namely VIOS1 A and VIOS2 B. The figure specifically provides an illustration of the interconnectivity between VIOSes and between each VIOS and shared block storage  and VIOS DB . Specifically,  provides a graphical representation of different types of connectivity losses that may occur within a cluster system and that can generate corresponding FFDC data, according to various embodiments.","As illustrated by , virtual I\/O (VIO) architecture  comprises two interconnected VIOSes, VIOS1 A and VIOS2 B. Each VIOS  connects to block storage  via respective system-level storage interconnect fabric and . While illustrated as a single interconnect, the connection between the VIOSes and block storage  is generally referred to herein as a storage interconnect fabric  since the actual connection may be a complex switch or network of wires. It is further appreciated that one or more communication hops within storage interconnect fabric  can be a wireless connection. The term fabric loss thus refers to any type of degradation or stoppage in the ability of a VIOS  to transmit (or receive) data over any portion of storage interconnect fabric  to\/from block storage .","As utilized herein, block storage  (or block storage facility) represents any type of storage that is generally accessible from any one of multiple VIOSes within a VIOS cluster. This, block storage  may be the distributed storage repository , other network accessible storage, or local storage (e.g., storage  of ). When block storage  is distributed storage repository , block storage may be a SAN or NAS, in one embodiment. Block storage  includes shared storage pool  that is accessible by one or more VIOSes within the VIOS cluster . Conditions occurring within storage pool  can be reported back to each VIOS (B) in response to receipt from that VIOS of an I\/O operation. The information related to the conditions are embedded within the I\/O response packet  in one embodiment.","Each of VIOS1 A (first VIOS) and VIOS2 B is interconnected via intra-cluster interconnect fabric , which connects each VIOS (e.g, VIOS_A A) with one or more other VIOSes (e.g., VIOS B) to create the VIOS cluster . VIOS Cluster  also comprises VIOS DB  to which each VIOS  within the cluster is connected via respective cluster-level interconnect fabric . Notably, within the described embodiments, the first and second VIOSes (A\/B) can exist on the same CEC or on different CECs within the cluster.","Each VIOS A, B includes internal software structures within respective software stacks by which the VIOSes A, B are able to communicate with each other as well as with VIOS DB  and distributed storage repository . For example, illustrated within first VIOS A are the following software structures, without limitation: (1) cluster kernel extension (CKE) , which is a kernel extension that allows the each VIOS (e.g., first VIOS A) to communicate with other VIOS nodes (e.g., second VIOS B) within the VIOS cluster ; (2) distributed storage access (DSA) , which is also a virtual interface that monitors the connectivity of a storage fabric from the VIOS; and (3) virtual server adapter (VSA) , which is the virtualized I\/O adapter that the VIOS assigns to a specific client to communicate I\/O requests between the client LPAR  and the assigned VIOS(es). During I\/O operation, VSA  handles the communication of the I\/O request from the client and the communication of I\/O response to the client. DSA  checks the connection status of the storage interconnect  of the VIOS and signals CKE when a fabric loss condition is detected on the interconnect . CKE  handles the propagation of the I\/O request to another VIOS when a fabric loss condition is detected by DSA  and is communicated by DSA  to CKE . According to one or more embodiments, CKE  also handles the transmittal of FFDC data from first VIOS A to other VIOSes within VIOS cluster , e.g., second VIOS B. Also, when a fabric loss condition occurs with first VIOS A that prevents access by first VIOS A to block storage , CKE of first VIOS transmits the handling of the reporting function of the associated FFDC data generated by the fabric loss condition to the FFDC module  of the second VIOS B. FFDC module  of second VIOS B then handles transmission of the FFDC data to the block storage . Thus, illustrated within second VIOS B are numbered blocks , , , and  respectively representing lifecycle events module, resource alert module, events listener, and FFDC module or . The additional functionality associated with and\/or manner of usage of the above set of software structures are presented in detail below.","Three different types of fabric losses, which can trigger the FFDC response mechanisms and generate FFDC data are illustrated by . For illustrative purposes, a loss of VIOS connectivity (or access) to the block storage  (which in one embodiment is synonymous with distributed storage repository ) is described as loss of physical connection (or connectivity) to the block storage , and is illustrated with an \u201cX1\u201d marking a premature termination of the specific interconnect (). This fabric loss of connectivity is further illustrated and indicated by the presence of dashed lines. In a second scenario, the first VIOS A itself fails or has an internal error condition that prevents the first VIOS A from being able to provide\/fulfill the I\/O operations to\/of the client LPAR . In this scenario, the loss may be software related, and one such loss is illustrated within  with a \u201cX2\u201d representing an inability of the VIOS to communicate I\/O operations from\/to the client LPAR . In another scenario, a third type of fabric loss involves a loss of VIOS fabric connection () to\/with VIOS DB  and is indicated by \u201cX3\u201d. Notably, when any one of these condition occurs, VIOS redundancy functionality of the CM utility  enables the I\/O operations to be transferred to different VIOSes within the VIOS cluster for handling.",{"@attributes":{"id":"p-0082","num":"0083"},"figref":"FIG. 6","b":["114","212","150","114","225","114","112","225","114","635","112","112","112","114","112","114","112","150","114","640","112","225","112","114","150","625","625","150","625","650","112","112","114","225"],"i":["a ","a","a","a "]},"As shown by , the communication path between client LPAR  and second VIOS A has been degraded (perhaps due to internal software\/hardware issues) and is currently unusable for the client's storage software stack. The path through PHYP  between client LPAR  and VSAT (of VIOS1 A) is available. However the physical connection (via storage interconnect ) to the block storage  has been degraded as VIOS1 is no longer connected to the block storage . Any one of the above fabric loss conditions can trigger an FFDC response. Additionally, failure of an I\/O due to reasons other than a fabric loss can also trigger one or more FFDC data events.","In addition to the three fabric loss conditions, additional events\/conditions that would trigger one or more FFDC responses include events\/conditions that can be considered as life cycle events. Among these life cycle events are: (a) a complete failure of a VIOS (e.g., VIOS A becomes non-functional); (a) an addition of a third VIOS (e.g., VIOS C) to the cluster; and (3) a removal of a third VIOS (VIOS C) from the VIOS cluster. These life cycle events generate FFDC data  that is shared with other VIOSes within the cluster, in one or more embodiments. The FFDC data  can be stored within VIOS DB  and then relevant portions of that data are retrieved by one or more other VIOSes within the VIUOS cluster . In one or more embodiments, the other VIOSes are registered Nodes  that have registered within VIOS DB  for receipt of notification of the specific occurrence of the condition\/event that causes generation of the FFDC data .","D2. Detecting and Responding to FFDC events",{"@attributes":{"id":"p-0085","num":"0086"},"figref":["FIGS. 7 and 8","FIGS. 7 and 8","FIGS. 1-6","FIG. 1"],"b":["220","222","206","112","2","110","112","140","150","222","222","112"]},"Referring now to , there is illustrated a high level logical flowchart of an example method that performs of functions of initiating and capturing simultaneous multi-node cluster OS first field\/failure data within a virtual clustered environment, according to one embodiment. Within the clustered VIOS environment, VIOS partitions and Client partitions may experience system errors due to new software stacks introduced into the data center. From the VIOS perspective, a VIOS may encounter errors that prevent the processing of I\/O requests to virtual clients due to issues within new\/legacy software stacks. From the client perspective, the client LPAR  may experience errors due to errors encountered by the VIOS which prevented I\/O requests from being processed successfully.","According to one or more embodiments, execution of functional modules within the CA_OS  or CM utility , in addition to direct programming of a system administrator, can configure FFDC data collection of each VIOS and\/or within the cluster as a whole. This FFDC data collection operation can be based on (a) node lifecycle events, (b) resource alerts, or (c) periodic system data collection. Examples of the node lifecycle events can include adding or removing a node to\/from the cluster. Both of these two operations are considered life cycle events within the cluster, according to the illustrative embodiment. In one implementation, resource alerts represent alerts that are autonomously reported back to a management tool when a resource threshold has been breached. As an example, a storage pool within the distributed storage repository  can be configured to notify subscribers when the pools capacity exceeds 70% of used blocks. System administrator may also configure one or more VIOSes to perform periodic collection and dumps of other types of FFDC data.","When such events\/conditions are encountered or detected within the cluster, one or more embodiments enables the node of the cluster that detects the occurrence of the event\/condition to autonomously react and initiate a cluster-wide operation in response to the detection of the event\/condition. The cluster-wide operation comprises capturing all relevant system information from each node within the cluster as needed and storing that information within a single pre-assigned storage location. According to the illustrative embodiments and with reference to , CA_OS generates an event listener  within each VIOS. As illustrated, the event listener  can be a functional module within CM utility , and event listener  interacts with other functional modules of CM utility  to provide the method illustrated by .","The method of  begins at initiation block  and proceeds to block , which illustrates the CM utility  initiating event listener (, ) during initialization\/set up\/boot up of VIOS . During or following the initiating of event listener  at the VIOS, the event listener  registers with the VIOS DB  for receipt of notification of cluster level FFDC data, such as lifecycle (block ). The event listener  actively monitors the node operations, client LPAR operations and\/or cluster management operations (e.g., when the node is a primary node) and\/or local system conditions, and the event listener  listens for one or more pre-defined life cycle events as well as resource alerts (e.g., within the distributed storage repository ) (block ). When a life cycle event is encountered, as determined at block , the event listener  automatically notifies the FFDC module  within the VIOS to capture system event data (block ). The FFDC module  generates and broadcasts a notification message to inform other FFDC modules running on remote nodes to initiate an FFDC data capture operation (block ). If, as determined at decision block , the FFDC module  operates within a primary notification node, the FFDC module  updates the VIOS DB  with the FFDC data (block ) before messaging the other nodes of the cluster to retrieve copies of or information about the stored FFDC data . According to one embodiment, in order to inform other nodes to perform the FFDC data capture operations, the FFDC module  broadcasts FFDC messages to the appropriate nodes that are registered with the VIOS DB  to receive notification of the specific type of event\/condition. Once the message is broadcasted, and received by the kernel extensions of the other \u201cremote\u201d VIOSes, the received message request can be propagated up to the FFDC module of the respective remote nodes for processing.","Following the check for detection of life cycle events, event listener  determines at block  whether a resource event or alert condition is detected. , describe hereafter, provides a more detailed method of one embodiment by which an I\/O resource event is detected. Within the present method, when the event listener  detects a resource event\/condition (e.g., received from resource alert reporting module ), the event listener  again forwards the information to the FFDC module , which captures the event data (block ). The FFDC module  then issues a notification to management tool  with information about the resource event\/condition and the collected FFDC\/resource data (block ). At block , the FFDC Module  also forwards the captured FFDC data to the FFDC data store  within the distributed storage repository  (and\/or to VIOS DB , in some embodiments). When other types of pre-identified FFDC events are encountered or detected within the node or CEC, those other types of FFDC events are treated similarly to the life cycle events and\/or the resource events\/condition. Additionally, when FFDC event notifications are received at the local node from other nodes within the cluster, as determined at block , the kernel extension receiving the notification forwards the received FFDC data to the FFDC module  for processing (block ). The FFDC module  initiates processing of the received FFDC data (block ), but the FFDC module  does not perform any notification as the FFDC data was received from another node. In one alternate embodiment, however, when the FFDC module  exists within a primary notification node (see, e.g., block ), whose function is to broadcast notifications of specific types of life cycle events to one or more nodes within the cluster, the FFDC module  forwards a copy of the FFDC data to one or both of: (a) the VIOS DB  and (b) each other node (that may or may not be registered to receive such notifications, depending on the specific implementation) within the cluster.","Within the FFDC module , operations including Live System Dumps and Component Trace capturing can be initiated. All FFDC information collected by the FFDC module  will then be stored within the specific location (FFDC data store ) within the distributed storage repository . In one or more embodiments, this location is FFDC event specific, and can be structured to enable\/allow FFDC information to be grouped based on the time the recorded event occurred. In the described embodiments, all nodes within the VIOS cluster store their FFDC information within a single location (FFDC data store  and\/or VIOS DB ) to allow an administrator to efficiently access and analyze or package the system wide FFDC data, as needed.","Given the autonomic nature of the FFDC data capture and storage within the described embodiments, (i.e., the FFDC data capture does not require manual operations from the administrator), the described FFDC data capture provides more comprehensive set of FFDC data, which are accurately recorded at substantially the same time (or immediately after the time) that the FFDC event occurs. Further, according to one embodiment, an administrator can utilize a management tool  to send a cluster FFDC data dump request even if a drastic event has not been encountered within the cluster.","Turning now to , there is illustrated the method by which the modules of CM utility  detects and respond to a resource event related to I\/O operations within a LU of a shared storage pool. The method begins at block  which illustrates the VIOS receiving an I\/O request from a client LPAR (assigned to that VIOS directly or via a redundant assignment) to perform an I\/O operation that accesses the assigned LU within the shared storage pool. The VIOS (through its various kernel extensions and application programming interface, API) forwards the I\/O request to the distributed storage repository  (block ). The VIOS receives a response to the I\/O request that contains storage pool status information (block ). The storage pool status information (or relevant portions of that data) is forwarded to the resource alert (reporting) module , which compares the received data with certain pre-set\/pre-established thresholds and alert conditions. For example, the storage pool status information can include data bout the amount of storage space utilized or remaining within the storage pool (e.g., 80% utilized or 20% available) and the resource alert module  compares this data to a pre-set 75% utilization threshold value at which a resource alert condition is triggered. In response to the result of that comparison indicating that a resource alert condition is detected (as determined at block ), the event listener  forwards the FFDC data to the FFDC module  for processing (block ). The FFDC module  stores the FFDC data in the FFDC event storage location  within distributed storage repository  (block ), and the FDC module  forwards the cluster-relevant FFDC data to VIOS DB  (block ). The FFDC module  also transmits a notification message of the resource event and\/or resource alert condition to the other VIOSes within the cluster that utilize the specific storage pool resource (block ). The FFDC module  also transmits a notification to the management tool  to trigger a response to the detected resource alert condition (block ). The process then ends at block .","In one embodiment, the management tool  can register with a primary notification VIOS for receipt of resource alert conditions. In another embodiment, the management tool  can periodically receive data about the occurrence of such events directly from VIOS DB  by reading the information from VIOS DB . In one embodiment, in response to receipt of a resource alert condition, the management tool  may dynamically perform operations to resolve the resource condition (e.g., the management tool  may allocate additional storage to the storage pool to bring the amount of assigned storage below 75%). In alternate embodiments, the management tool  may alert a system administrator of the occurrence of the detected resource event providing the system administrator with advance notice to enable the system administrator to manually correct the condition.","The flowcharts and block diagrams in the various figures presented and described herein illustrate the architecture, functionality, and operation of possible implementations of systems, methods and computer program products according to various embodiments of the present invention. In this regard, each block in the flowcharts or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and\/or flowchart illustration, and combinations of blocks in the block diagrams and\/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.","In the flow charts above, one or more of the methods are embodied in a computer readable medium containing computer readable code such that a series of steps are performed when the computer readable code is executed (by a processing unit) on a computing device. In some implementations, certain processes of the methods are combined, performed simultaneously or in a different order, or perhaps omitted, without deviating from the spirit and scope of the invention. Thus, while the method processes are described and illustrated in a particular sequence, use of a specific sequence of processes is not meant to imply any limitations on the invention. Changes may be made with regards to the sequence of processes without departing from the spirit or scope of the present invention. Use of a particular sequence is therefore, not to be taken in a limiting sense, and the scope of the present invention extends to the appended claims and equivalents thereof.","As will be appreciated by one skilled in the art, aspects of the present invention may be embodied as a system, method or computer program product. Accordingly, aspects of the present invention may take the form of an entirely hardware embodiment, an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to herein as a \u201ccircuit,\u201d \u201cmodule\u201d or \u201csystem.\u201d Furthermore, aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium(s) having computer readable program code embodied thereon.","Any combination of one or more computer readable medium(s) may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be, for example, but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, or device, or any suitable combination of the foregoing. More specific examples (a non-exhaustive list) of the computer readable storage medium would include the following: an electrical connection having one or more wires, a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a portable compact disc read-only memory (CD-ROM), an optical storage device, a magnetic storage device, or any suitable combination of the foregoing. In the context of this document, a computer readable storage medium may be any tangible medium that can contain, or store a program for use by or in connection with an instruction execution system, apparatus, or device.","A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein, for example, in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms, including, but not limited to, electro-magnetic, optical, or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate, propagate, or transport a program for use by or in connection with an instruction execution system, apparatus, or device.","Program code embodied on a computer readable medium may be transmitted using any appropriate medium, including but not limited to wireless, wireline, optical fiber cable, R.F, etc., or any suitable combination of the foregoing. Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages, including an object oriented programming language such as Java, Smalltalk, C++ or the like and conventional procedural programming languages, such as the \u201cC\u201d programming language or similar programming languages. The program code may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).","Aspects of the present invention are described below with reference to flowchart illustrations and\/or block diagrams of methods, apparatus (systems) and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and\/or block diagrams, and combinations of blocks in the flowchart illustrations and\/or block diagrams, can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions\/acts specified in the flowchart and\/or block diagram block or blocks.","These computer program instructions may also be stored in a computer readable medium that can direct a computer, other programmable data processing apparatus, or other devices to function in a particular manner, such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function\/act specified in the flowchart and\/or block diagram block or blocks. The computer program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other devices to cause a series of operational steps to be performed on the computer, other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions\/acts specified in the flowchart and\/or block diagram block or blocks.","As will be further appreciated, the processes in embodiments of the present invention may be implemented using any combination of software, firmware or hardware. As a preparatory step to practicing the invention in software, the programming code (whether software or firmware) will typically be stored in one or more machine readable storage mediums such as fixed (hard) drives, diskettes, optical disks, magnetic tape, semiconductor memories such as ROMs, PROMs, etc., thereby making an article of manufacture in accordance with the invention. The article of manufacture containing the programming code is used by either executing the code directly from the storage device, by copying the code from the storage device into another storage device such as a hard disk, RAM, etc., or by transmitting the code for remote execution using transmission type media such as digital and analog communication links. The methods of the invention may be practiced by combining one or more machine-readable storage devices containing the code according to the present invention with appropriate processing hardware to execute the code contained therein. An apparatus for practicing the invention could be one or more processing devices and storage systems containing or having network access to program(s) coded in accordance with the invention.","Thus, it is important that while an illustrative embodiment of the present invention is described in the context of a fully functional computer (server) system with installed (or executed) software, those skilled in the art will appreciate that the software aspects of an illustrative embodiment of the present invention are capable of being distributed as a program product in a variety of forms, and that an illustrative embodiment of the present invention applies equally regardless of the particular type of media used to actually carry out the distribution.","While the invention has been described with reference to exemplary embodiments, it will be understood by those skilled in the art that various changes may be made and equivalents may be substituted for elements thereof without departing from the scope of the invention. In addition, many modifications may be made to adapt a particular system, device or component thereof to the teachings of the invention without departing from the essential scope thereof. Therefore, it is intended that the invention not be limited to the particular embodiments disclosed for carrying out this invention, but that the invention will include all embodiments falling within the scope of the appended claims. Moreover, the use of the terms first, second, etc. do not denote any order or importance, but rather the terms first, second, etc. are used to distinguish one element from another.","The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the invention. As used herein, the singular forms \u201ca\u201d, \u201can\u201d and \u201cthe\u201d are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms \u201ccomprises\u201d and\/or \u201ccomprising,\u201d when used in this specification, specify the presence of stated features, integers, steps, operations, elements, and\/or components, but do not preclude the presence or addition of one or more other features, integers, steps, operations, elements, components, and\/or groups thereof.","The corresponding structures, materials, acts, and equivalents of all means or step plus function elements in the claims below are intended to include any structure, material, or act for performing the function in combination with other claimed elements as specifically claimed. The description of the present invention has been presented for purposes of illustration and description, but is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the invention. The embodiment was chosen and described in order to best explain the principles of the invention and the practical application, and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The described embodiments are to be read in conjunction with the accompanying drawings, wherein:",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 1B","FIG. 1A"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
