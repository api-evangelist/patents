---
title: Systems and methods for media summarization
abstract: A stream of ordered information, such as, for example, audio, video and/or text data, can be windowed and parameterized. A similarity between the parameterized and windowed stream of ordered information can be determined, and a probabilistic decomposition or probabilistic matrix factorization, such as non-negative matrix factorization, can be applied to the similarity matrix. The component matrices resulting from the decomposition indicate major components or segments of the ordered information. Excerpts can then be extracted from the stream of ordered information based on the component matrices to generate a summary of the stream of ordered information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07424150&OS=07424150&RS=07424150
owner: Fuji Xerox Co., Ltd.
number: 07424150
owner_city: Tokyo
owner_country: JP
publication_date: 20031208
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS"],"p":["1. Field of Invention","This invention relates to systems and methods for generating summaries of media stream that are representative of the structural character of the entire steam.","2. Description of Related Art","Media summarization technologies have numerous applications in e-commerce and information retrieval. Many such applications use summaries and\/or proxies of longer works, because of the large file sizes and high bandwidth requirements of multi media data. The summary of the media work is reduced in some manner, typically by excerpting a segment or segments that are a good representation of the longer work. To identify segments that are a good representation of the longer work, the structure of the media stream must be determined.","U.S. Published patent application 2003\/0048946, which is incorporated herein by reference in its entirety, discloses a method for assessing structure in media streams that includes three steps. In a first step, each window, which is either a single frame, or a short time unit, of the media stream, is parameterized by calculating a feature vector for that window. In a second step, a similarity measure is determined for every pair of windows based on the windows feature vectors. The similarity measures are embedded in a similarity matrix for analysis. In a third step, the similarity matrix is factored using Singular Value Decomposition (SVD) to determine the major structural elements of the media stream. The major structural elements or basis vectors are processed to determine segment boundaries and clusters of similar segments.","Once the major structural segments and the clusters of structural segments are identified, a single excerpt can be identified to represent each structural segment cluster by maximizing, for each excerpt, that excerpt's similarity to other members of the corresponding segment cluster. An excerpt for each significantly different segment of the media is generated, while redundant excerpts for similar structural segments in the same cluster are eliminated.","U.S. Published Patent Application 2003\/0161396, which is incorporated herein by reference in its entirety, discloses a method for selecting a summary excerpt of a longer media source using similarity analysis. In that method, the similarity matrix is generated as outlined above in the first two steps of the incorporated 946 published application. The similarity matrix is then processed to determine the excerpt with maximal similarity to the entire source stream.","The singular basis vectors generated when using the singular value decomposition method of the 946 published patent application provide a low-dimensional set of orthonormal directions that express the essential modes of variation in the data. However, the singular value decomposition method has shortcomings. From an analysis standpoint, identifying the singular basis vectors is not deterministic and identifying the correct structural segments is not reliable.","This invention provides systems and methods that use probabilistic factorization of the similarity matrix to identify the basis vectors of the similarity matrix.","This invention separately provides systems and methods that use non-negative matrix factorization of the similarity matrix to identify the basis vectors of the similarity matrix.","This invention separately provides systems and methods that determine the optimal length of summaries representing each major structural element or segment cluster of a media stream.","This invention separately provides systems and methods that determine the starting point of summaries representing each major structural element or segment cluster of a media stream.","This invention separately provides systems and methods that generate summaries representing a multi-modal media stream.","In various exemplary embodiments of systems and methods according to this invention, a media stream is parameterized by calculating a feature vector for all of the windows or frames in the media stream. A similarity measure is determined for each possible pair of windows or frames. The similarity measures are then collected into a similarity matrix. The similarity matrix is then factored using one or more probabilistic methods to identify each major structural component or basis vector of the media stream and to generate, for each component, a component matrix representing that component. The component matrix that represents a particular major structural element or basis vector is processed to determine segment boundaries and clusters of similar segments.","In various exemplary embodiments, systems and methods according to this invention generate a summary containing excerpts from each identified major structural element. The excerpts are extracted or otherwise generated by determining an optimal or appropriate length of each excerpt, then finding an optimal or appropriate starting point for each excerpt that tends to increase or maximize the similarity measure between the frames or windows in the excerpt and the frames or windows in the major structural element that the excerpt represents.","In various exemplary embodiments, systems and methods according to this invention generate summaries from media streams containing a plurality of modes. Summaries of multi-mode media streams are generated by combining the similarity matrices generated from each mode, then performing probabilistic factorization on the combined matrix. Summaries are then generated from the matrix representing each major structural element or basis vector using the same method as used for a single mode media stream.","These and other features and advantages of this invention are described in, or are apparent from, the following detailed description of various exemplary embodiments of systems and methods according to this invention.","Various exemplary embodiments of systems and methods for summarizing a media stream according to this invention are usable to summarize any known or later-developed type of media stream, such as, for example, video streams, audio streams, audio\/video streams, text documents, and the like. The following detailed discussion may refer to specific types of media streams, such as video streams or audio streams, at various points for familiarity and ease of understanding. This should not be understood to imply that only those types of media streams are appropriately used in systems and methods according to this invention.","One exemplary application for the media summarization systems and methods according to this invention is in summarizing a video stream that is to be sold and distributed over the Internet. In this exemplary application, a prospective Internet video purchaser reviews an audio and\/or video work before deciding to purchase the work. The user requests a summary of the work, which activates a summarizing system according to this invention to generate the summary of the audio and\/or video work. The summarizing system determines each of the major components in the video work and generates a summary based on samples of the determined major components","To avoid disclosing all of the work, such as, for example, a surprise ending of an audio and\/or video work, the determined summary may reflect only a percentage of the determined major components in the beginning, middle and\/or end of the work. Since the summarizing system may be used to determine boundaries of the major components, the length of each determined major component may be determined and only an appropriate portion of the total length of each component included in the summary. It should be apparent that, in various exemplary embodiments of systems and methods according to this invention, summarizing an audio\/video work includes summarizing only the audio components, only the video components and\/or both of the audio and video components.","A user of an audio and\/or video editing system may also use an exemplary embodiment of summarizing systems and methods according to this invention to provide smart cut\/paste functions and other enhanced editing capabilities based on the determined major component boundaries. For example, a user of the video editing system retrieves a video work. The video work is then summarized by the summarizing system to identify the major components of the video work.","The determined major components of the video work are then used to determine the boundaries of the major video components or segments. The determined major component or segment boundaries are then be used provide smart cut and paste operations and\/or other enhanced video operations for the determined major components within the video work. The time and expertise required to accomplish the editing of the video work are reduced since important components, such as major scenes of the video work, have been determined. It should be apparent that, in various other exemplary embodiments of systems and methods according to this invention, the summarizing system may be located in the video editing system and\/or any accessible location. In various exemplary embodiments, major components of audio, text or any other ordered information may be similarly determined.","In various exemplary embodiments of systems and methods according to this invention, the audio\/video information may be encoded into a streaming audio\/video protocol such as MPEG-3, MPEG-4, MPEG-J, PNM-RealNetworks protocol, RealVideo protocols from RealNetworks, Microsoft Media Streaming Protocol in the Windows Media\u00ae Player from Microsoft Corporation or any other known or later-developed audio and\/or video protocol. Various exemplary embodiments of systems and methods according to this invention also provide for operating upon MPEG-4 or any other encoded information to directly access the windowing and parameterizations encoded within the encoded information stream or protocol without requiring separate decoding and encoding.","The ordered information may include audio, video, text or any other information having an ordering dimension, such as time for audio and\/or video information and position for text information.","The retrieved and\/or received information is analyzed to determine an appropriate type of parameterization to be applied to the received and\/or retrieved information. For example, different windowing and parameterization may be applied to audio information, video information, textual information or other types of ordered information. In a first exemplary embodiment according to this invention, audio information, such as an audio waveform, is windowed into frames or the frames associated with the video information accompanying the audio information in the work are used as windows.","A parameterization of the windowed audio information is then determined. The windowed audio information may be parameterized using a Short Time Frame Fourier Transform (STFT), a Fourier Transform, a Mel-Frequency Cepstral Coefficients analysis, a spectrogram, a Fast Fourier Transform (FFT), wavelet decomposition or any other known or later-developed analysis technique without departing from the spirit and scope of this invention.","Similarly, other ordered information such as video and text information may also be windowed. For example, the video information may be windowed by selecting individual frames of video information and\/or selecting groups of frames, which are averaged together to determine an average value. Text information may be windowed or framed by selecting words, sentences, paragraphs, an arbitrary number of words, by selecting words based on attributes such as parts of speech, meta-data, XML and \/or HTML encoding, importance, term frequency and\/or inverse document frequency or any other known or later-developed technique for windowing the text.","A parameterization of the other windowed ordered information is then determined. For example, parameterizing the video information may include use of color histograms, as disclosed in Zhang et al, \u201cVideo Parsing, Retrieval and Browsing: an Integrated and Content-Based Solution\u201d in Intelligent Multimedia Information Retrieval, AAA Press, MIT Pres, 1997, which is incorporated herein by reference in its entirety. Alternatively, parameterized decimated video information may be derived from DC coefficients of compression macroblocks, discrete cosine transforms (DCT) may be applied to the video information, or any other known or later-developed method of parameterization of the ordered information may be used.","The parameterized data may be compressed or otherwise reduced in size to reduce the memory storage requirements of the parameterized information. For example, the storage requirements may be reduced by any of the methods discussed in Girgensohn et al. \u201cVideo Classification Using Transform Coefficients\u201d in Proc ICASSP '99 Vol. 6 p. 3045-3048, Phoenix, Ariz., IEEE, 1999, which is incorporated herein by reference in its entirety. Alternatively, truncation, principal component analysis, ordered discriminant analysis or any other known or later-developed method of data reduction may be used, either alone or in combination, to create a reduced representation of the parameterized information that preserves salient information about the original windows or frames. For example, the reduced representation of the parameterized audio\/video information can reflect a compact feature vector of reduced coefficients for each audio and\/or video frame. Since the reduced representation is used for analysis rather than reproduction of the original ordered information, the reduced representation does not need to be able to recover the original information but is used to indicate major components. Thus, the reduced representation may be further reduced.","A similarity measure d may be determined based on the Euclidean distance between the parameterized information vectors a for frames or windows i and j, as:\n\n()\u2261\u2225\u2225.\u2003\u2003(1a)\n","In various other exemplary embodiments, the similarity measure d may be determined based on the dot product of the parameterized information vectors comprising the similarity matrix. For example, the dot product of two large similarity vectors is:\n\n()\u2261.\u2003\u2003(1b)\n","The similarity measure d may be determined using the cosine angle between parameterized information vectors, functions of vector statistics such as the Kullback-Leibler distance or any other known or later-developed method of determining similarity of information vectors without departing from the spirit or scope of this invention. The distance measures or metrics d are incorporated into a similarity matrix such that the similarity measures or elements d(i,j) on the diagonal represents the similarity of each measure or element d to itself. Thus, self-similarity is at a maximum on the diagonal.","The value of each similarity measure or element d(i,j) can be assigned a determined color information value based on comparison to a maximum feature value such as a maximum brightness. Each of the similarity measures or elements d(i,j), i=j having high self-similarity have corresponding higher brightness values and appear along the diagonal.","Thus, as outlined above, in the media summarization method described in the 946 published patent application, the first step is parameterization of the media. In the 946 published patent application, for a video data stream, the feature vectors are computed based on low-order discrete cosine transform (DCT) coefficients. The individual RGB frames are sampled at 1 Hz and transformed into a color space where the three-color channels are approximately decorrelated. The discrete cosine transform (DCT) of each transformed channel is computed and a feature vector is formed by concatenating the resulting low frequency coefficients of the three channels. It should be appreciated that any number of alternate parameterization methods may be employed.","Once the media has been parameterized, as outlined above, the second step described in the 946 published patent application is to calculate the similarity between the feature vectors of different frames and embed the result in a two-dimensional representation. The key is a measure d of the similarity between a pair of feature vectors vand vcalculated from frames i and j. In various exemplary embodiments according to this invention, a useful similarity distance measure is the cosine angle between the parameter vectors:\n\n()=<\u2003\u2003(1c)\n\nThis similarity distance measure d(v,v) has the property that it yields a large similarity score even if the vectors are small in magnitude.\n",{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIG. 1","FIG. 1"],"sub":["k ","c","i","j","c","i","j","c","i","j"],"b":["110","110","110","111"],"br":[{},{}],"in-line-formulae":[{},{}]},"In the similarity matrix  shown in , various media segments , ,  and  can be identified. In particular, in the similarity matrix , those positions S(i,j) where i and j are in the same segment show a high similarity score. Additionally, in the similarity matrix , those positions S(i,j) where the frame i is in one segment, such as the segment , and the frame j is in another segment, such as the segment , can also show a high similarity score. This indicates that the segments  and  form a cluster and can be treated as a single basis vector or structural component of the media corresponding to the similarity matrix .","The third step of the media summarization method described in the 946 published patent application, as outlined above, is matrix factoring using singular value decomposition (SVD). In this step, new matrices or terms such as ,  and  shown in  are generated that represent the basis vectors or segment clusters B, Band Bof the media being summarized. Each position in the factorized matrices - are defined as:\n\nB(i,j)=\u03c3U(i,k)V(k,j),\u2003\u2003(3a)\n\nwhere:\n","U(i,k) is an N\u00d7K matrix with orthonormal columns;","V(k,j) is a K\u00d7N matrix with orthogonal rows;","N is the number of frames;","K is the number of basis vectors;","k=1 to K; and",{"@attributes":{"id":"p-0054","num":"0053"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"S","mo":"\u2245","mrow":{"mi":["U","\u03a3"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"msup":{"mi":["V","T"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","msub":{"mi":["B","K"]}}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mrow":{"mn":"3","mo":"\u2062","mi":"b"}}}]}}}},"br":{},"sub":"i"},"It should be appreciated that, in various exemplary embodiments, the value of K is determined as the effective rank of S, based on the singular values \u03c3using an absolute threshold either applied directly to the singular values or applied to the ratio of the ksingular value to the largest singular value. The value of K can also be set by the user, determined based on prior information and\/or knowledge about the content of the ordered information that is being summarized. It should also be appreciated any other known or later-developed technique that is appropriate for determining the value of K can be used.","The K columns of the matrix U(i,k) are the basis vectors of the factorization and the K rows of the matrix V(k,j) are the coefficient representations of the columns of the similarity matrix  onto this basis. See M. Berry et al., \u201cUsing Linear Algebra for Intelligent Information Retrieval\u201d SIAM Review, 37(4):573-595, 1995, for further details on how \u03c3, U(i,k) and V(k,j) are determined.","The x-axis of the factorized matrices , and  shown in  represents the frame i and the y-axis represents the frame j. The scale  of the factorized matrix  correlates the position value B(i,j) to a gray scale, such as white for a maximum score of 1.0 and black for a score of 0.5. The factorized matrix  indicates high scores in the regions where i and j are both in the segment  or both in the segment . The factorized matrix  also indicates high scores in regions where i is in the segment  and j is in the segment , identifying these segments as a basis vector or cluster.","The scale  of the factorized matrix  correlates the position value B(i,j) to a gray scale, such as white for a maximum score of 0.4 and black for a score of \u22120.4. The factorized matrix  indicates high scores in regions where i is in the segment  and j is in the segment , identifying these segments as a basis vector or cluster. The factorized matrix  also indicates high scores in regions where i is in the segment  and j is in the segment , incorrectly identifying these segments as a basis vector or cluster. The scale  of the factorized matrix  correlates the position value B(i,j) to a gray scale, such as white for a maximum score of 0.5 and black for a score of \u22120.5. The factorized matrix  indicates high scores in the regions where i and j are both in the segment  or both are in the segment . The factorized matrix  also indicates negative scores in regions where i is in the segment  and j is in the segment , indicating that the segments  and  are not part of the same cluster.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 2","b":["110","120","140","210","110","210","110","220","120","120","220","114","118","114","118"],"sup":"th ","sub":"1"},"The rowsums  of the factorized matrix  are the sums of all the values B(i,j) in the i rows of the factorized matrix , plotted as a function of i. The values of the rowsums  for the frames i in the segments  and  are significantly greater than that of the other frames, making it possible to mistakenly identify the segments  and  as a basis vector cluster in analysis. The rowsums  of the factorized matrix  are the sums of all the values B(i,j) in the i rows of the factorized matrix , plotted as a function of i. The values of the rowsums  for the frames i in the segments , ,  and  are extremely small and are not reliable for analysis.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 3","FIG. 3"],"sub":["k ","c","i","j"],"b":["310","310","311"],"br":[{},{}],"in-line-formulae":[{},{}],"i":["S","i,j","d","v",",v"]},"It should be appreciated that the non-negative factorization maximizes a log-likelihood function that assumes that the similarity data is generated according to a Poisson noise model. The maximization is performed subject to non-negativity constraints. That is, the non-negativity constraints imply that the resulting basis vectors are combined to approximate the columns of S without canceling one another. The non-negative factorization of an N\u00d7N matrix S defines a linear approximation to S, which is denoted as S=WH. Using an iterative approach, Sconverges to a local maximum of the function:",{"@attributes":{"id":"p-0063","num":"0062"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["L","NMF"]},"mo":"=","mrow":{"mrow":[{"munder":{"mo":"\u2211","mrow":{"mi":["i","j"],"mo":","}},"mo":"\u2062","mrow":{"mrow":[{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["S","b"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.6em","height":"0.6ex"}}}}},{"msub":{"mi":["S","b"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}],"mo":"-"}},"mo":",","mi":"and"}},{"mrow":{"mo":["(",")"],"mn":"5"}}]},{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["S","b"]},"mo":"=","mi":"WH"},"mo":";"}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}]}}},"br":{}},"W is a N\u00d7K matrix whose columns are the basis vectors for the factorization and;","H is as K\u00d7N matrix of coefficient representations of the columns of S onto the basis vectors.","By determining the non-negative matrix factorization of the similarity matrix S, each component matrix A, as defined below, represents a cluster of segments with high similarity. These terms A of the matrix sum of Eq. 5 represent the structural components of the similarity matrix S. In the singular value decomposition, the columns of W are orthonormal and the rows of H are orthogonal. As a result, when combined, they both add and cancel. In contrast, the combinations of the non-negative matrix factorization basis vectors and coefficients are strictly additive.","In the similarity matrix  shown in , a number of media segments , ,  and  can be identified. Each segment , ,  and  corresponds to a square region along the main diagonal of the similarity matrix , in which those positions S(i,j) where the frames i and j are in the same segment show a high similarity score. Additionally, in the similarity matrix , those positions S(i,j) where the frame i is in one segment, such as the segment , and the frame j is in another segment, such as the segment , can also show a high similarity score. This indicates that the segments  and  form a cluster and can be treated as a single basis vector or structural element of the source stream.","The similarity matrix  is then factored using non-negative matrix factorization (NMF). In this step, new matrices ,  and  are generated that represent the basis vectors Aor segment clusters of the media. This factorization is used to generate the terms Athat represent a structural decomposition of S. A given factorized matrix ,  or , corresponding to the terms A, Aand A, respectively, is defined as:\n\nA(i,j)=W(i,k)H(k,j)\u2003\u2003(7a)\n\nwhere:\n","W(i,k) is an N\u00d7K matrix;","H(k,j) is a K\u00d7N matrix;","N is the number of frames or separable portions of the stream being summarized;","K is the number of basis vectors; and","k is an integer between 1 and K, inclusive; and",{"@attributes":{"id":"p-0074","num":"0073"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["S","WH"],"mo":"\u2245"},{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","mrow":{"msub":{"mi":["A","k"]},"mo":"."}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mn":"7","mo":"\u2062","mi":"b"}}}]}}}}},"It should be appreciated that, in various exemplary embodiments, the value of K is determined by first estimating the effective rank K of S, and then by estimating the K-term of the probabilistic factorization of S. The terms A, A, . . . Aare then processed to determine the desired, or ideally, optimal, length L summaries with respect to within-class similarity, as is discussed in greater detail below.","The K columns of the matrix W(i,k) are the basis vectors of the factorization and represent the significant parts of S, i.e., the significant block of high similarity. The K rows of the matrix H(k,j) are the coefficients representing the columns of the similarity matrix  onto this basis. The factorization is performed subject to non-negativity constraints that insure that the resulting basis vectors can be combined to approximate the columns of the similarity matrix  without canceling one another. D. Lee et al., \u201cLearning the parts of objects by non-negative matrix factorization\u201d Nature, 401:788-791, 1999, which is incorporated herein by reference in its entirety, provides for further details on how the matrices W(i,k) and H(k,j) are determined.","It should be appreciated that probabilistic clustering (PC), as described in T. Hoffman, \u201cThe Cluster-Abstraction Model: Unsupervised Learning of Topic Hierarchies from Text Data,\u201d Proc. IJCAI, 1999, can be used instead of the non-negative matrix factorization (NMF) to factorize the similarity matrix . It should also be appreciated that probabilistic latent semantic analysis (PLSA), as described in T. Hoffman, \u201cUnsupervised Learning by Probabilistic Latent Semantic Analysis,\u201d Machine Learning 42:177-96, 2001, can be used instead of the non-negative matrix factorization (NMF) to factorize the similarity matrix . In general, in systems and methods according to this invention, any other known or later-developed probabilistic decomposition or probabilistic matrix factorization can be used to factor the similarity matrix.","The x-axis of the factorized matrices , and  shown in  represents the frame i and the y-axis represents the frame j. The scales ,  and  of the factorized matrices ,  and , respectively correlate the position value A(i,j) to a gray scale, such as white for a maximum score of 1.2 and black for a score of 0. The factorized matrix  indicates high scores in the regions where the frames i and j are both in the segment  or are both in the segment . The factorized matrix  also indicates high scores in regions where the frame i is in the segment  and the frame j is in segment  correctly identifying the segments  and  together as a first basis vector or cluster.","The factorized matrix  indicates high scores in the regions where the frames i and j are both in the segment , identifying the segment  as a second basis vector. The factorized matrix  indicates high scores in the regions where the frames i and j are both in the segment , identifying the segment  as a third basis vector.",{"@attributes":{"id":"p-0080","num":"0079"},"figref":["FIG. 4","FIG. 4"],"sub":"k ","b":"410"},{"@attributes":{"id":"p-0081","num":"0080"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mover":{"mi":["S","_"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","mrow":{"mrow":{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},"mo":"."}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mn":"7","mo":"\u2062","mi":"c"}}}]}}}},"br":{},"b":["410","310","310"],"sub":"k "},{"@attributes":{"id":"p-0082","num":"0081"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mover":{"mi":["A","_"]},"mi":"k"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":["A","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},"mo":"."}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mn":"7","mo":"\u2062","mi":"d"}}}]}}}},"br":{},"b":["410","300","420","320","320","420","320","314","318","314","318"],"sub":"1"},"The rowsums  of the factorized matrix  are the sums of all the values A(i,j) in the i rows of the factorized matrix , plotted as a function of i. The values of the rowsums  of the factorized matrix  for the frames i in the segment  are significantly greater than that of the other frames, making it easy to identify the segment  as a second basis vector cluster by analysis. The rowsums  of the factorized matrix  are the sums of all the values A(i,j) in the i rows of the factorized matrix , plotted as a function of i. The values of the rowsums  of the factorized matrix  for the frames i in the segment  are significantly greater than that of the other frames, again making it easy to identify the segment  as a third basis vector cluster by analysis.",{"@attributes":{"id":"p-0084","num":"0083"},"figref":["FIG. 5","FIG. 5"],"sub":["k","k","k","k"],"b":["320","340","520","520","520"]},{"@attributes":{"id":"p-0085","num":"0084"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mover":{"mi":["A","_"]},"mi":"k"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["q","r"],"mo":","}}},{"mfrac":{"mn":"1","mrow":{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["r","q"],"mo":"-"}}}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":["m","q"],"mo":"="},"mi":"r"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","mrow":{"msub":{"mi":["A","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"8"}}]}}}},"br":{}},"r is the ending frame of the excerpt; and","q is the starting frame of the excerpt.","The average within-class(basis vector) component matrix \u0100(q,r) is determined for excerpts with all possible starting points r, and possibly for all desired lengths L. The excerpt that has the starting point, and possibly the length, that results in the highest average within-class(basis vector) component matrix \u0100(q,r) is selected as the optimal or desired excerpt for that basis vector. The process is then repeated for each basis vector.","It should be appreciated that each component matrix Aquantifies the within-class similarity since each component matrix Arepresents that part of the similarity matrix corresponding to the segment cluster that the selected excerpt must represent in the final summary. It should be appreciated that, in various exemplary embodiments of systems and methods according to this invention, to select the summary excerpt for a given component matrix A, a score Q(i) for the istarting position of the kcomponent is defined as:",{"@attributes":{"id":"p-0090","num":"0089"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msubsup":{"mi":["Q","L"],"mrow":{"mo":["(",")"],"mi":"k"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},{"mfrac":{"mn":"1","mi":"NL"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":["m","i"],"mo":"="},{"mi":["i","L"],"mo":"+"}]},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","mrow":{"msub":{"mi":["A","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}}}}},"The rowsums corresponding to the inner sums of Eq. (7) are shown in . It should be appreciated that, in various exemplary embodiments of systems and methods according to this invention, a starting point qfor the excerpt to be extracted from the kcomponent is determined. In various exemplary embodiments, the starting point qis that point that maximizes the score Qfor the kcomponent. That is:",{"@attributes":{"id":"p-0092","num":"0091"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msubsup":{"mi":["q","L"],"mrow":{"mo":["(",")"],"mi":"k"}},"mo":"=","mrow":{"munder":{"mi":"ArgMax","mrow":{"mn":"1","mo":["\u2264","\u2264"],"mi":"i","mrow":{"mi":["N","L"],"mo":"-"}}},"mo":"(","mrow":{"msubsup":{"mi":["Q","L"],"mrow":{"mo":["(",")"],"mi":"k"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}}}},{"mrow":{"mo":["(",")"],"mn":"10"}}]}}}}},"The excerpt for the kth component matrix Ais then the excerpt of the ksegment of the media stream being summarized that extends between a start point or time qand an end point or time q+L. In various exemplary embodiments of systems and methods according to this invention, the summary is then combined or compiled by concatenating the k excerpts obtained from the k segments.","It should be appreciated that, in various exemplary embodiments, the length L, rather than being a fixed value, can vary according to an importance attached to the component that the excerpt is a part of. For example, in various exemplary embodiments the desired total length Lof the summary can be defined. Then, the lengths lof the various components K are determined so that the lengths lsum to the total lengths Land the length lof each component k is related in some way to an importance of that component k. In various exemplary embodiments, the length lof a given component k is:",{"@attributes":{"id":"p-0095","num":"0094"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["l","k"]},"mo":"=","mrow":{"msub":{"mi":["L","T"]},"mo":"\u2062","mfrac":{"mrow":[{"munder":{"mo":"\u2211","mrow":{"mi":["i","j"],"mo":","}},"mo":"\u2062","mrow":{"msub":{"mi":["A","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}},{"munder":{"mo":"\u2211","mi":"k"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":["i","j"],"mo":","}},"mo":"\u2062","mrow":{"msub":{"mi":["A","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}]}}}},{"mrow":{"mo":["(",")"],"mn":"11"}}]}}}},"br":{},"sub":["T ","T ","T "]},"It should also be appreciated that, in the exemplary embodiments outlined above, minimal assumptions about the characteristics of the stream of ordered information were made. However, in various exemplary embodiments, it may be appropriate to base the decomposition of the stream of ordered information on one or more such characteristics. In various exemplary embodiments, this can be accomplished by applying a weighting function to emphasize specific portions or parts of the stream of ordered information. In such exemplary embodiments, a weighted score Scan be generated by altering Eq. (7c) as:",{"@attributes":{"id":"p-0097","num":"0096"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mover":{"mi":["S","_"]},"mi":"w"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["q","r"],"mo":","}}},{"mrow":[{"mn":"1","mo":"\/","mrow":{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["r","q"],"mo":"-"}}}},{"munderover":{"mo":"\u2211","mrow":{"mi":["m","q"],"mo":"="},"mi":"r"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","mrow":{"mrow":[{"mi":"w","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"mrow":{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},"mo":"."}],"mo":"\u2062"}}}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}}},"When using non-negative matrix factorization (NMF), multi-mode media, such as a multimedia stream that contains both video and audio portions, can be summarized similarly. In such exemplary embodiments, a similarity matrix for each mode is generated portions and combined as:\n\nS(i,j)=[S(i,j)S(i,j)],\u2003\u2003(13)\n\nwhere:\n","S(i,j) is a combined N\u00d72N similarity matrix;","S(i,j) is an N\u00d7N audio similarity matrix; and","S(i,j) is an N\u00d7N video matrix.","Then, a joint likelihood model for the clustering can be created as:",{"@attributes":{"id":"p-0103","num":"0102"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["L","NMF"]},"mo":"=","mrow":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"j","mo":"=","mn":"1"},{"mn":"2","mo":"\u2062","mi":"N"}]},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["S","C"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["S","b"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.6em","height":"0.6ex"}}}}}},{"msub":{"mi":["S","b"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}],"mo":"-"}},"mo":",","mi":"and"}},{"mrow":{"mo":["(",")"],"mn":"14"}}]},{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["S","b"]},"mo":"=","mi":"WH"},"mo":";"}},{"mrow":{"mo":["(",")"],"mn":"15"}}]}]}}},"br":{}},"W is a N\u00d7K matrix whose columns are the basis vectors for the factorization and;","H is as K\u00d72N matrix of encodings of the columns of Sonto the basis vectors.","It should be appreciated that this is a straightforward extension of Eq. 5. The above-outlined summarization process can be applied to the larger matrix using an N\u00d7K matrix W and a K\u00d72N matrix H to generate K different N\u00d72N factorization matrices A.",{"@attributes":{"id":"p-0107","num":"0106"},"figref":["FIG. 6","FIG. 6"],"b":["100","200","300","400","500"]},"In step S, the similarity matrix S(i,j) is factored using one or more probabilistic techniques, such as, for example, a non-negative matrix factorization (NMF) technique, to generate one or more factorized matrices. In this case, the similarity matrix S(i,j) is factored using Eq. (5). Next, in step S, excerpts representing each basis vector of the media are identified using the resulting factorized matrix or matrices. Then, in step S, the identified excerpts are extracted from the media stream and collected into a summary of the media stream. Operation then continues to step S, where operation of the method ends.",{"@attributes":{"id":"p-0109","num":"0108"},"figref":["FIG. 7","FIG. 7"],"b":["600","610","620","630","640"]},"In step , an optimal or desired starting point for the excerpt of the selected basis vector is determined by choosing the excerpt that generated the highest score in step S. Then, in step S, a determination is made whether excerpts have been generated for all basis vectors. If excerpts have not been generated for all basis vectors, operation returns to step S. Otherwise, operation continues to step S, where operation returns to step S.",{"@attributes":{"id":"p-0111","num":"0110"},"figref":["FIG. 8","FIG. 8","FIG. 8"],"b":["600","600","610","620","630","640","650","660","670","680","700","800","600","710","810"]},"In general, the data source  shown in  can be any known or later-developed device that is capable of supplying a media stream to be summarized to the media summarizing system . In general, the data source  can be any one of a number of different sources, such as a scanner, a digital copier, a facsimile device, a digital camera, a digital video recorder or the like that is suitable for generating electronic data as a media stream, or a device suitable for storing and\/or transmitting electronic data as a media stream, such as a client or server of a network, or the Internet, and especially the World Wide Web. In general, the data sink  can be any known or later-developed device that is usable to display, store, transmit or otherwise receive media summaries from the media summarizing system .","The data source  and\/or the data sink  can be integrated with the media summarizing system . In addition, the media summarizing system  may be integrated with devices providing additional functions in addition to the data source  and\/or the data sink .","Each of the links  and  connecting the data source  and data sink , respectively, to the media summarizing system , can be and\/or include a direct cable connection, a modem, a local area network, a wide area network, an intranet, an extranet, the Internet, the public switched telephone network, any other distributed processing network, or any other known or later developed connection device. It should be appreciated that each of the links  and  may include one or more wired and\/or wireless portions. In general, each of the links  and  can be of any known or later-developed connection system or structure usable to connect the respective devices to the media summarizing system . It should be understood that the links  and  do not need to be of the same type.","As shown in , the memory  can be implemented using any appropriate combination of alterable, volatile, or non-volatile memory or non-alterable, or fixed memory. The alterable memory, whether volatile or non-volatile can be implemented using any one or more of static or dynamic RAM, a floppy disk and disk drive, a writeable or rewriteable optical disk and disk drive, a hard drive, flash memory or the like. Similarly, the non-alterable or fixed memory can be implemented using any one or more of ROM, PROM, EPROM, EEPROM, and gaps an optical ROM disk, such as a CD-ROM or DVD-ROM disk and disk drive or the like.","It should be understood that various embodiments of the media summarizing system  can be implemented as software stored on a computer readable medium that is executable on a programmed general purpose computer, a special purpose computer, a microprocessor or the like. Such a computer readable medium includes using a carrier wave or the like to provide the software instructions to a processing device. It should also be understood that each of the circuits, routines, applications, managers, procedures, objects or the like shown in  can be implemented as portions of a suitably programmed general-purpose computer. Alternatively, each of the circuits, routines, applications, managers, procedures, objects or the like shown in  can be implemented as physically distinct hardware circuits within an ASIC, using a digital signal processor (DSP), using a FPGA, a PDL, a PLA and\/or a PAL, or using discrete logic elements or discrete circuit elements. The particular form of the circuits, routines, applications, managers, procedures, objects or the like shown in  will take is a design choice and will be obvious and predictable to those skilled in the art. It should be appreciated that the circuits, routines applications, managers, procedures, objects or the like shown in  do not need to be of the same design.","It should be appreciated that a routine, application, manager, procedure, object or the like can be a self-consistent sequence of computerized steps that lead to a desired result. These steps can be defined by and\/or in one or more computer instructions stored in a computer readable medium, which should be understood to encompass using a memory, a carrier wave or the like to provide the software instructions to a processing device. These steps can be performed by a computer executing the instructions that define the steps. Thus, the terms \u201croutine\u201d, \u201capplication\u201d, \u201cmanager\u201d, \u201cprocedure\u201d, and \u201cobject\u201d can refer to, for example, a sequence of instructions, a sequence of instructions organized within a programmed-procedure or programmed-function, and\/or a sequence of instructions organized within programmed processes executing in one or more computers. Such routines, applications, managers, procedures, objects or the like can also be implemented directly in circuitry that performs the procedure. Further, computer-controlled methods can be performed by a computer executing one or more appropriate programs, by special purpose hardware designed to perform the method, or any combination of such hardware, firmware and software elements.","In operation, the media summarizing system  receives a media data stream from the data source  over the link . The input\/output interface  inputs the received media data stream, and under the control of the controller , forwards it to an input media stream portion  of the memory  and\/or directly to the media stream parameterization circuit, routine or application . The media stream parameterization circuit, routine or application  then generates feature vectors for each frame of the received media stream. The media stream parameterization circuit, routine or application  then stores, under control of the controller , the generated feature vectors in a similarity parameter portion  of the memory  or forwards the generated feature vectors directly to similarity matrix generating circuit, routine or application .","The similarity matrix generating circuit, routine or application  inputs, under control of the controller , feature vectors from the similarity parameter portion  of the memory  or the media stream parameterization circuit, routine or application . Using the generated feature vectors, the similarity matrix generating circuit, routine or application  determines a similarity distance for each pair of frames and adds the determined similarity distances into a similarity matrix. The similarity matrix generating circuit, routine or application  then stores, under control of the controller , the similarity matrix to a similarity matrix portion  of the memory , or outputs the similarity matrix directly to the similarity matrix factorizing circuit, routine or application . It should be appreciated that the similarity matrix generating circuit, routine or application  can generate the similarity matrix using any appropriate known or later-developed technique, including the various techniques outlined above.","The similarity matrix factorizing circuit, routine or application , inputs, under control of the controller , the similarity matrix from the similarity matrix portion  of the memory , or from the similarity matrix generating circuit, routine or application . The similarity matrix factorizing circuit, routine or application  generates a basis vector term for each basis vector or significant structure or the media using a probabilistic matrix factorization technique. The similarity matrix factorizing circuit, routine or application , under control of the controller , stores the basis vector terms in the basis vector term portion , of the memory , or outputs the basis vector terms directly to the media summary generating circuit, routine or application . It should be appreciated that the similarity matrix factorizing circuit, routine or application  can factorize the similarity matrix using any appropriate known or later-developed probabilistic matrix factorization technique, including the various techniques outlined above.","The media summary generating circuit, routine or application , inputs, under control of the controller , the basis vector terms from the basis vector term portion  of the memory  or from the similarity matrix factorizing circuit, routine or application . The media summary generating circuit, routine or application  generates a desired media summary from the basis vector term for each basis vector or significant structure or the media, by extracting a representative excerpt from each basis vector, and by combining the extracted excerpts into a summary. The media summary generating circuit, routine or application  stores, under control of the controller , the media summary in the media summary portion  of the memory , or outputs the media summary directly to the data sink , via the input\/output interface , and over the link . It should be appreciated that the media summary generating circuit, routine or application  can generate the media summary using any appropriate known or later-developed technique, including the various techniques outlined above. In particular, the media summary generating circuit, routine or application  can use any appropriate known or later developed technique for determining the various representative excerpts, including the various techniques outlined above.","While this invention has been described in conjunction with the exemplary embodiments outlined above, various alternatives, modifications, variations, improvements, and\/or substantial equivalents, whether known or that are or may be presently unforeseen, may become apparent. Accordingly, the exemplary embodiments of the invention, as set forth above, are intended to be illustrative, not limiting. Various changes may be made without departing from the spirit and scope of the invention. Therefore, the invention is intended to embrace all known or later-developed alternatives, modifications, variations, improvements, and\/or equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Various exemplary embodiments of systems and methods according to this invention will be described in detail, with reference to the following figures, wherein:",{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
