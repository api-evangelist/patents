---
title: Disk drive employing a disk command data structure for tracking a write verify status of a write command
abstract: A disk drive is disclosed including a disk having a plurality of tracks, wherein each track comprises a plurality of data sectors. A microprocessor executes a write command associated with a disk command data structure by inserting the disk command data structure into a dirty queue, and then executing the write command using the disk command data structure by writing data blocks to a plurality of target data sectors. The disk command data structure is then inserted into a write verify queue, and the disk command data structure is used to perform a write verify operation. The disk command data structure is inserted into an available queue if the target data sectors pass the write verify operation, and the disk command data structure is inserted back into the dirty queue if at least one of the target data sectors fails the write verify operation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07120737&OS=07120737&RS=07120737
owner: Western Digital Technologies, Inc.
number: 07120737
owner_city: Lake Forest
owner_country: US
publication_date: 20060120
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","CROSS REFERENCE TO RELATED APPLICATIONS AND PATENTS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["This application is a continuation of U.S. patent application Ser. No. 10\/329,152 entitled \u201cDISK DRIVE EMPLOYING A DISK COMMAND DATA STRUCTURE FOR TRACKING A WRITE VERIFY STATUS OF A WRITE COMMAND\u201d filed on Dec. 24, 2002, which is incorporated by reference herein in its entirety.","This application is related to U.S. Pat. No. 6,854,022 entitled \u201cDISK DRIVE USING ROTATIONAL POSITION OPTIMIZATION ALGORITHM TO FACILITATE WRITE VERIFY OPERATIONS\u201d filed on Feb. 2, 2002, co-pending U.S. patent application Ser. No. 10\/286,127 entitled \u201cDISK DRIVE EMPLOYING A MULTI-PHASE ROTATIONAL POSITION OPTIMIZATION (RPO) ALGORITHM\u201d filed on Oct. 31, 2002, U.S. Pat. No. 6,711,635 entitled \u201cDISK DRIVE EMPLOYING THRESHOLDS FOR CACHE MEMORY ALLOCATION\u201d filed on Sep. 30, 2002, U.S. Pat. No. 6,961,814 entitled \u201cDISK DRIVE MAINTAINING A CACHE LINK ATTRIBUTE FOR EACH OF A PLURALITY OF ALLOCATION STATES\u201d filed on Sep. 30, 2002, U.S. Pat. No. 6,965,966 entitled \u201cDISK DRIVE PRE-COMPUTING SEEK PARAMETERS FOR A CONTINUATION TRACK AND A NEXT COMMAND TO FACILITATE CONTINUING A READ-AHEAD OR ABORTING THE READ-AHEAD\u201d filed on Oct. 31, 2002, U.S. Pat. No. 6,845,405 entitled \u201cDISK DRIVE EXECUTING PART OF A LINKED DISK COMMAND\u201d filed on Dec. 24, 2002, and U.S. Pat. No. 6,996,501 entitled \u201cDISK DRIVE EXECUTING A MANUFACTURING PROGRAM INTERNALLY BY EXECUTING DISK COMMANDS THROUGH A VECTOR\u201d filed on Dec. 24, 2002, the disclosures of which are incorporated herein by reference.","1. Field of the Invention","The present invention relates to disk drives for computer systems. More particularly, the present invention relates to a disk drive employing a disk command data structure for tracking a write verify status of a write command.","2. Description of the Prior Art","It has been suggested to perform a write verify operation in a disk drive in order to verify the recoverability of recently written data before the write data is purged from the cache buffer. If a write-verify fails, the write command is typically re-executed and re-verified. If the write verify fails a number of times, the marginal data sector is typically relocated.","The cache buffer typically comprises a valid queue for caching read data read from the disk, a dirty queue for buffering write data to be written to the disk, and an available queue for buffering the write data after it has been written to the disk. The write data in the available queue is typically de-allocated for use by new commands prior to de-allocating read data from the valid queue or flushing write data from the dirty queue. However if a write verify policy is implemented, it is necessary to verify a write command before purging the write data from the cache buffer.","There is, therefore, a need to track the status of write data in a disk drive so that it is not purged from the cache buffer until passing a write verify operation.","An embodiment of the present invention comprises disk drive including a disk having a plurality of tracks, wherein each track comprises a plurality of data sectors and each data sector for storing a data block. The disk drive further comprises a head actuated radially over the disk, and a disk command data structure comprising a pointer to a plurality of data blocks to be written to a corresponding plurality of target data sectors. A dirty queue stores disk command data structures associated with write commands comprising write data to be written to the disk, a write verify queue stores disk command data structures associated with write commands comprising write data to be verified, and an available queue stores disk command data structures associated with write commands comprising write data written to the disk and verified. A microprocessor within the disk drive executes a write command associated with the disk command data structure by inserting the disk command data structure into the dirty queue, and then executing the write command using the disk command data structure by writing the data blocks to the plurality of target data sectors. The disk command data structure is then inserted into the write verify queue after executing the write command, and the disk command data structure is used to perform a write verify operation to verify recoverability of each of the target data sectors. The disk command data structure is inserted into the available queue if the target data sectors pass the write verify operation, and the disk command data structure is inserted back into the dirty queue if at least one of the target data sectors fails the write verify operation.","Another embodiment of the present invention comprises a method of executing a write command associated with a disk command in a disk drive. The disk drive comprises a disk having a plurality of tracks, wherein each track comprising a plurality of data sectors and each data sector for storing a data block. The disk drive further comprises a head actuated radially over the disk, and a disk command data structure comprising a pointer to a plurality of data blocks to be written to a corresponding plurality of target data sectors. A write command associated with the disk command data structure is executed by inserting the disk command data structure into the dirty queue, and then executing the write command using the disk command data structure by writing the data blocks to the plurality of target data sectors. The disk command data structure is then inserted into the write verify queue after executing the write command, and the disk command data structure is used to perform a write verify operation to verify recoverability of each of the target data sectors. The disk command data structure is inserted into the available queue if the target data sectors pass the write verify operation, and the disk command data structure is inserted back into the dirty queue if at least one of the target data sectors fails the write verify operation.",{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 1A","FIG. 1B"],"b":["1","4","20","20","1","6","4","8","4","6","10","10","3","10","5","7","10","9","11","10","13","15","10","17","13","10","5","7","9","10","17","19","7"]},"In the embodiment of  the disk  comprises a plurality of tracks , where each track  comprises a plurality of data sectors and a plurality of embedded servo sectors  recorded at a periodic interval around the circumference of the track . The embedded servo sectors  are aligned radially to form a plurality of servo wedges. Each embedded servo sector  comprises coarse head positioning information (e.g., a track number) processed by the microprocessor  to position the head  over a target track, and fine head positioning information (e.g., servo bursts) processed by the microprocessor  to maintain the head  over a centerline of the target track during read and write operations. The disk  shown in  comprises radially spaced, concentric tracks , however, any suitable track format may be employed including a spiral track format.","Any suitable disk command data structure may be employed in the embodiments of the present invention. In an embodiment disclosed below with reference to , the disk command data structure comprises a segment descriptor (SD) for storing various parameters associated with each disk command, including a number of optional parameters which may be employed in the embodiments of the present invention.",{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 1C","b":["2","10","12","14","16","18","12","8","14","18","4","16","14","18","12"]},"Any suitable microprocessor  may be employed in the embodiments of the present invention, including the ARM 966E-S microprocessor manufactured by licensees of ARM Incorporated.","The priority level of the tasks shown in  is from highest priority on the top (disk task ) to lowest priority on the bottom (background task ). Since the host task  has a higher priority level than the background task , the background task  does not interfere with the host interface operation. Further, the execution task  gives priority to the disk commands received from the host task  over disk commands received from the background task . This allows the background task  to be interrupted (suspended) when a host command is received from the host computer. After processing the disk command generated by the host task , the background task  continues the operation it was performing.","In one embodiment, the execution task  executes a rotational position optimization (RPO) algorithm for selecting a next disk command to execute relative to a location of the head  with respect to the disk . Any suitable RPO algorithm may be employed. In general, an RPO algorithm evaluates the mechanical latency of the disk drive (seek and rotational latencies) in order to select disk commands in an order which minimizes the latency. In one embodiment, the RPO algorithm is implemented in multiple phases relative to non-real-time parameters and real-time parameters. Further details of the embodiment employing a multiple phase RPO algorithm are disclosed in the above reference U.S. patent application entitled \u201cDISK DRIVE EMPLOYING A MULTI-PHASE ROTATIONAL POSITION OPTIMIZATION (RPO) ALGORITHM\u201d.",{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 2","FIG. 1C","FIG. 1C","FIG. 2"],"b":["24","14","24","26","12","26","28","12","28","16","28","30","22","30","30","12","28"],"ul":{"@attributes":{"id":"ul0001","list-style":"none"},"li":{"@attributes":{"id":"ul0001-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0002","list-style":"none"},"li":["DISK TASK  is responsible mainly for disk formatting operations for read\/write commands, such as determining the track format including number and location of defects and configuring the read\/write channel circuitry with appropriate parameters. The DISK TASK  runs in response to disk formatting hardware (DF IRQ ) and wedge event interrupt (WE IRQ ) indicating that a requested seek has completed.","HOST TASK  is responsible for receiving commands from the host. It runs in response to commands received from the host bus interface (HBI) hardware via the HBI IRQ .","EXECUTION (EXEC) TASK  is responsible for arbitrating the disk commands generated by the host task  and the background task  and for transmitting the arbitrated disk commands to the disk task . In one embodiment, the EXEC TASK  implements the multi-phase rotational position optimization (RPO) algorithm for selecting the next command to be executed by the DISK TASK . The RPO algorithm typically runs after the DISK TASK  has emptied a pipeline slot.","BACKGROUND TASK  is responsible for implementing background operations. It typically initiates read\/write commands not initiated by the host, for example, while performing diagnostic, calibration, or manufacturing procedures.\n\nThere are also a number of event flags associated with each of the tasks:\n","HOST COMMAND EVENT set by the HBI interrupt  service routine when a new command is received from the host.","DISK STOPPED EVENT set by the DF interrupt  service routine in connection with a data formatting operation for a current command.","DISK INSERT EVENT set by the EXEC TASK  when a next command is inserted into the \u201cnext\u201d pipeline slot for the DISK TASK . This signals the DISK TASK  to pipeline the next command behind the current command being executed.","EXEC DISK COMPLETE EVENT set by the DISK TASK  when it moves the next disk command from the \u201cnext\u201d pipeline slot into the \u201ccurrent\u201d pipeline slot. This signals the EXEC TASK  to execute the RPO algorithm to select the next disk command to execute.","EXEC CALLBACK EVENT set by the DISK TASK  after completing the command requested by the EXEC TASK .","EXEC INSERT EVENT set by the HOST TASK  and BACKGROUND TASK  to execute the RPO algorithm based on desired criteria, for example, flushing write commands to free-up cache resources.","EXEC CANCEL EVENT set by the HOST TASK  to cancel a command sent to the EXEC TASK .","BACKGROUND CALLBACK EVENT set by the EXEC TASK  after processing the command requested by the BACKGROUND TASK .","BACKGROUND CANCEL EVENT set by the EXEC TASK  to cancel the command requested by the BACKGROUND TASK .","DISK CANCEL EVENT set by the EXEC TASK  to cancel the command in the \u201cnext\u201d pipeline slot.","SEEK COMPLETE EVENT set by the wedge event interrupt (WE IRQ ) to signal the DISK TASK  that the requested seek operation has been completed.","WEDGE COUNT VALID EVENT set by the wedge event interrupt (WE IRQ ) to signal the EXEC TASK  that the wedge count is valid and that the second phase of the RPO algorithm may commence.","BACKGROUND INSERT EVENT set by the HOST TASK  to start background processing such as diagnostic, calibration, or manufacturing procedures."]}}}},"In one embodiment, the background task  executes manufacturing procedures during manufacture of the disk drive, such as a defect scan of the disk  in order to identify and relocate marginal data sectors to spare data sectors. Further details of this embodiment are disclosed in the above referenced U.S. patent application entitled \u201cA DISK DRIVE EXECUTING A MANUFACTURING PROGRAM INTERNALLY BY EXECUTING DISK COMMANDS THROUGH A VECTOR\u201d.",{"@attributes":{"id":"p-0035","num":"0051"},"figref":"FIG. 3","b":["14","18","0","1","2"]},"The NEXT SD INDEX of the SD specifies an index value for a next SD, and the PREV. SD INDEX specifies an index value for a previous SD. These fields facilitate linking SDs together to form linked disk commands in order to improve the RPO algorithm. This embodiment is described in more detail in the above referenced U.S. patent application entitled \u201cDISK DRIVE EXECUTING PART OF A LINKED DISK COMMAND\u201d.","The STATE of the SD indicates an allocation state for the cache segments allocated to the SD. The allocation states in this embodiment include:","free\u2014an unallocated cache segment;","available\u2014an allocated cache segment storing write data that has been written to the disk;","valid\u2014an allocated cache segment storing cached read data; and","dirty\u2014an allocated cache segment storing write data not yet written to the disk.","The STATE is used by the execution task  to implement various operations, such as allocating\/de-allocating cache segments, linking SDs, executing the RPO algorithm, executing a write verify operation, etc.","The CYLINDER and HEAD of the SD specify the starting cylinder and head for accessing the disk  to perform the disk command. These fields are used by the RPO algorithm. The SEEK LATENCY of the SD is also used by the RPO algorithm and specifies the number of servo wedges required to seek the head to the cylinder\/head (CH) from the current reference wedge. The ROTATIONAL LATENCY field is used by the RPO algorithm and specifies the number of wedges required to reach the first target data sector after the seek. In one embodiment, these fields are updated by the multi-phase RPO algorithm as disclosed in more detail in the above referenced U.S. patent application entitled \u201cDISK DRIVE EMPLOYING A MULTI-PHASE ROTATIONAL POSITION OPTIMIZATION (RPO) ALGORITHM\u201d.","The REWRITE\/VERIFY COUNT of the SD tracks the number of times a write verify procedure has failed for the SD. If the SD is a write command, after executing the write command the SD is placed in a write verify queue in order to verify the write operation was successful. If the write verify fails, the SD is processed to re-execute the write command. If the number of write verify failures exceeds a threshold, the data block stored in the marginal data sector associated with the SD is relocated to a spare data sector. The RESTART LBA OFFSET of the SD stores the LBA corresponding to the marginal data sector where the write verify failed. This allows the write command and write verify operation to be restarted at the marginal data sector. More details of this embodiment are described below with reference to .","When the execution task  selects an SD to execute according to the RPO algorithm, a command descriptor (CD) data structure shown in  is used to append additional information to the SD. The CDD POINTER of the CD points to a command deviation descriptor (CDD) described below with reference to . The PRE-READ COUNT specifies the number of data sectors to read prior to the first target data sector of the current command, and the POST-READ COUNT specifies the number of data sectors to read after the last target data sector of the current command. The LAD INDEX of the CD is used by the RPO algorithm to setup an intelligent abort descriptor (IAD) for the command. The IAD is used to abort the previous command and begin executing the current command. Further details of this embodiment are disclosed in the above referenced U.S. patent application entitled \u201cDISK DRIVE PRE-COMPUTING SEEK PARAMETERS FOR A CONTINUATION TRACK AND A NEXT COMMAND TO FACILITATE CONTINUING A READ-AHEAD OR ABORTING THE READ-AHEAD\u201d.",{"@attributes":{"id":"p-0045","num":"0061"},"figref":["FIG. 5","FIG. 5"],"b":"18"},"The FINE TRACK OFFSET of the CDD of  specifies a tracking offset for the head during the disk command (the default tracking offset is zero). The ERROR RECOVERY FLAGS of the CDD enable\/disable various features of the error recovery system, such as off-track retries, simple jogging retries, preamp corner shift retries, thermal asperity (TA) detection, firmware error correction code (ECC) processing, finite-impulse-response (FIR) calibration, high-fly write, on-the-fly ECC features, relocations, sync mark, etc. Other configuration parameters in the CDD of  include a seek retry limit, seek time-out limit, file verify limit, wedge offset, wedge length, relocate after retry, and sync mark pattern code. A detailed description of the various configuration parameters shown in  is unnecessary to understand the embodiments of the present invention and has been omitted so as not to obscure the disclosure.","In one embodiment, the CDD is configured by the background task  executing a background program. For example, the defect scan manufacturing program executed by the background task  may issue a disk command as well as a configuration command to modify the configuration parameters of the configuration data structure (the CDD). Both commands are issued through a vector implementing a vendor specific command (VSC) as described in more detail in the above referenced U.S. patent application entitled \u201cDISK DRIVE EXECUTING A MANUFACTURING PROGRAM INTERNALLY BY EXECUTING DISK COMMANDS THROUGH A VECTOR\u201d. In another embodiment, a task may modify the configuration parameters of the CDD directly. For example, the disk task  may modify the configuration parameters while performing retry error recovery. With each retry operation, the disk task  may modify certain configuration parameters, such as certain read\/write channel  parameters, in an attempt to recover a marginal data sector. Once the marginal data sector is recovered (or relocated), the disk task  reverts to the configuration parameters prior to executing the retry error recovery and continues with the current disk command. This embodiment is disclosed in greater detail below with reference to .","In another example embodiment, the disk task  implements a track caching algorithm wherein a number of data blocks stored in the spare data sectors of a track are read and cached in order to expedite access to the data blocks for disk commands that would otherwise access the spare data sectors. Since it is unknown whether some of the data blocks in the spare data sectors will be requested, the disk task  modifies the configuration parameters of the configuration data structure so that less stringent error recovery is performed while reading the spare data sectors. This improves performance by skipping unrecoverable spare data sectors rather than perform full error recovery, and only loads the track cache with data blocks from the spare data sectors that are recoverable using the less stringent error recovery. If a data block for a spare data sector is requested that is not loaded into the track cache, the disk task  will attempt to recover the spare data sector using full error recovery.","In one embodiment, a transport descriptor (TD) data structure shown in  is used to pass commands between the tasks. Each task has a first-in first-out (FIFO) command queue for receiving and processing TDs. If needed, an SD and\/or CD is attached to the TD to facilitate disk commands as illustrated in . In one embodiment, when the operating system is initialized a number of TDs are allocated and used as needed. The REQ CODE of the TD allows a client (i.e., a first task) to specify a routine to execute in another task. The QUEUED TO DISK FLAG of the TD is set by the media request manager (MRM) in the execution task  when the TD has been queued to the disk task . This flag enables the MRM to determine when a requested disk command has completed. The PARAMETER of the TD specifies a user routine parameter if needed. The CALL BACK ADDRESS of the TD specifies an address of the routine to execute when the client's request is completed by the task. The NEXT TD points to the next TD in the queue to execute next (if one exists). The SD INDEX of the TD specifies a SD (if one exists), and the CD INDEX specifies a CD (if one exists). The TASK ID of the TD identifies the client (task) that initiated the TD.",{"@attributes":{"id":"p-0050","num":"0066"},"figref":"FIG. 8A","b":"18"},{"@attributes":{"id":"p-0051","num":"0067"},"figref":"FIG. 8B","b":["32","34","36","38","40","42","44","36"]},"If the write verify fails at step  for at least one of the target data sectors, then at step  the write verify counter of the SD is incremented (or in alternative embodiment decremented or otherwise modified). If at step  the write verify counter of the SD does not exceed a predetermined threshold, then at step  the RESTART LBA OFFSET of the SD is set to the marginal data sector where the write verify failed, and at step  the SD is inserted back into the dirty queue so that the write command will be re-executed and re-verified starting with the marginal data sector.","If at step  the write verify counter of the SD exceeds the threshold, then at step  the marginal data sector where the write verify failed is relocated. In one embodiment, the marginal data sector is relocated inline by immediately writing the data block to the spare data sector, and in an alternative embodiment, the data block is inserted into a write cache and written to the spare data sector while the disk drive is idle. In one embodiment, an SD is used to write the data blocks stored in the write cache to the spare data sectors, wherein the SD is placed in the dirty queue and write verified according to . If at step  there are no other target data sectors to verify for the SD, then at step  the SD is inserted into the available queue indicating the cache memory may be reused for other disk commands. Otherwise, at step  the RESTART LBA OFFSET of the SD is set to the data sector following the marginal data sector where the write verify failed, and at step  the write verify counter of the SD is reset. At step  the SD is inserted back into the write verify queue so that the write verify operation for the SD will continue starting with the data sector following the marginal data sector where the write verify operation failed.","Encapsulating the write verify counter into the SD simplifies tracking the number of times a write verify fails for a particular write command. The write verify counter remains with the SD as it is transferred between the write verify queue and the dirty queue, and triggers a relocation of a marginal data sector if the write verify counter exceeds the predetermined threshold.",{"@attributes":{"id":"p-0055","num":"0071"},"figref":"FIG. 9","b":["16","12","64","66","68","18","70","18","16","66","70","72","74","16"]},"The execution task  communicates with the disk task  using TDs described above with reference to . The disk task  comprises a top level disk task  which decodes the TDs, performs limited processing such as performance optimized read and write operations (or cache requests), and distributes other processing to one or more of a plurality of disk task modules including a file read\/write module , an auto-relocation module , a check disk module , an error recovery module , and a relocation read\/write module . The file read\/write module  handles reading and writing system files located in a reserved area of the disk  or in semiconductor memory (e.g., FLASH). The auto-relocation module  relocates data blocks from marginal data sectors to spare data sectors. In one embodiment, the auto-relocation module  relocates a data block for a marginal data sector detected during the write verify operation described above with reference to . In an alternative embodiment, a relocation request may be issued by a client (e.g., host computer or manufacturing program executed internally) through a VSC operation. The check disk module  contains the physical low level disk access routines, including to centralize the error recovery algorithm. The error recovery module  is invoked by the check disk module  and implements various error recovery techniques, including retry error recovery and firmware error correction code (ECC) processing (e.g., erasure pointer or Turbo code processing) when an error is detected while accessing the disk. In an alternative embodiment described below with reference to , the firmware ECC processing is implemented by a separate error recovery task . The relocation read\/write module  is invoked by the check disk module  when a data block stored in a spare data sector needs to be accessed. As described above, in one embodiment the data blocks read from the spare data sectors of a track are cached in a track cache to expedite subsequent disk commands.","In the embodiment of , the various modules in the disk task  communicate with each other using a disk activity block (DAB) data structure, an example for which is shown in . The PARENT DAB field points to a parent DAB which generated the current DAB for the current disk command. This embodiment facilitates performing disk commands using custom configuration parameters through a custom CDD. For example, the disk task  may modify the configuration parameters while performing retry error recovery. To facilitate modifying the configuration parameters, a new DAB is generated for the current disk command and the configuration parameters in the CDD of the current DAB (the parent DAB) are copied into the CDD for the new DAB. The configuration parameters in the CDD of the new DAB are then modified with appropriate values (e.g., adjusting the fine tracking offset) and the current disk command re-executed using the custom CDD. Once the marginal data sector is recovered (or relocated), the parent DAB is re-assigned to the current disk command so that the current disk command continues execution using the configuration parameters in the original CDD.","The CDD POINTER of the DAB in  points to the CDD data structure described above with reference to . The NEXT TRACK LBA of the DAB specifies the first LBA of the next track. The COUNT of the DAB specifies the total number of data blocks for the current request. The REMAINING COUNT of the DAB specifies the remaining number data blocks for the current request to be processed. The SERVO RETRY COUNTER of the DAB indicates the number of times the servo has failed for the current data sector. The READ RETRY COUNTER of the DAB indicates the number of times the read retry has failed for the current data sector, and the WRITE RETRY COUNTER indicates the number of times the write retry has failed for the current data sector. The SD POINTER of the DAB points to the SD data structure described above with reference to , and the CD POINTER points to the CD data structure described above with reference to . The ZONE of the DAB identifies the ZONE for the next LBA to process, and the CHW identifies the cylinder\/head\/wedge for the next LBA to process.","Any suitable number of tasks may be employed in the embodiments of the present invention. In addition, certain operations performed by existing tasks may be implemented in a separate task.  shows an embodiment of the present invention comprising a separate error recovery task  for implementing firmware error recovery algorithms. In one embodiment, some or all of the firmware ECC processing performed by the error recovery module  of the disk task  () is moved to the error recovery task . In another embodiment, the error recovery task  performs firmware ECC processing, such as using erasure pointers or performing multiple passes of a Turbo code, concurrent with the disk task  performing retry error recovery. In the embodiment shown in , the error recovery task  is executed at the lowest priority level, but it may be assigned any suitable priority level such as above the background task .  shows an embodiment of the present invention comprising a separate RPO task  rather than implement the RPO algorithm in the execution task . The RPO task  is assigned a priority level higher than the background task , but it may be assigned any suitable priority level, such as above the execution task  or the host task ."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIGS. 1A\u20131B"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1C"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 8B"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 10","FIG. 9"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
