---
title: Activity triggered photography in metaverse applications
abstract: A system, method and program product for collecting image data from within a metaverse. A system is provided that includes: a graphical user interface (GUI) for allowing a user to install and administer a camera within the metaverse; a system for collecting image data from the camera based on an occurrence of a triggering event associated with the camera; and a system for storing or delivering the image data for the user.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08893047&OS=08893047&RS=08893047
owner: International Business Machines Corporation
number: 08893047
owner_city: Armonk
owner_country: US
publication_date: 20091109
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This disclosure is related to metaverse applications, and more particularly is related to collecting image data from a metaverse application in response to triggering events within the metaverse.","Metaverses, also referred to as virtual universes or worlds, are computer-based simulated environments intended for its users to inhabit, traverse, and interact via avatars, which are personas or representations of the users of the metaverse, and generally take the form of two-dimensional or three-dimensional human or fantastical representations of a person's self. Metaverses, are now most common in massive multiplayer online games, such as Second Life (a trademark of Linden Research, Inc. in the U.S., other countries or both), the Sims Online (a trademark of Electronic Arts Inc. in the U.S., other countries, or both), and World of Warcraft (a trademark of Blizzard Entertainment, Inc. in the U.S., other countries, or both). A feature of such applications is that are persistent, i.e., the virtual worlds exist continuously, even when a given user is not logged in. Avatars in these types of metaverses, which can number well over a million, have a wide range of business and social experiences.","Current metaverse applications allow a user to cause an avatar to take a photograph or video of a nearby scene using, e.g., keystrokes. The photographs or video can then be saved to an avatar's inventory for instance. This however requires the user to be logged in and active in the metaverse.","The present invention relates to a metaverse application that allows a user to collect image data from the metaverse without being logged in or active in the metaverse at the time the image data is taken. Instead, facilities are provided for allowing the user to selectively place cameras in the metaverse and define triggering events, which when detected, cause image data to be collected. Accordingly, once the camera is installed, image data is collected for the user in an automatic fashion independently of any actions of the user or the user's avatar.","In one embodiment, there is a metaverse system having a camera system for capturing image data from within a metaverse, comprising: a computer system comprising: an interface for installing and administering a camera within the metaverse; a system for collecting image data from the camera based on an occurrence of a triggering event associated with the camera; and a system for storing or delivering the image data.","In a second embodiment, there is a computer readable storage medium having a computer program product stored thereon for capturing image data from within a metaverse, comprising: program code for implementing an interface for installing and administering a camera within the metaverse; program code for collecting image data from the camera based on an occurrence of a triggering event associated with the camera; and program code for storing or delivering the image data.","In a third embodiment, there is a method for capturing image data from within a metaverse, comprising: providing an interface for installing and administering a camera within the metaverse; collecting image data from the camera based on an occurrence of a triggering event associated with the camera; and storing or delivering the image data.","In a fourth embodiment, there is a method of capturing data from within a metaverse for at least one user, comprising: receiving an installation of a recording device within the metaverse; receiving a specification of at least one triggering event associated with the recording device; collecting a resulting set of data; and storing the resulting set of data for at least one user.","The illustrative aspects of the present invention are designed to solve the problems herein described and other problems not discussed.","The drawings are merely schematic representations, not intended to portray specific parameters of the invention. The drawings are intended to depict only typical embodiments of the invention, and therefore should not be considered as limiting the scope of the invention. In the drawings, like numbering represents like elements.","Described herein is a solution for capturing images within a metaverse. More particularly, the solution allows a camera to capture images for a user independently of the user or the user's avatar, e.g., while the user is not logged into the metaverse application or while the user is logged in, but not controlling a camera. Note that for the purposes of the disclosure, the term \u201cimage data\u201d may refer to any type of image, e.g., a still photograph, a video stream, infrared data, etc. In addition, it is understood that the term \u201ccamera\u201d refers to a virtual camera for capturing rendered image data in a virtual image space.",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 1","b":["10","20","22","20","20","10","11","38","40"]},"Camera system  includes: a GUI (graphical user interface)  for allowing a user  to install and administer cameras in the metaverse and define triggering events for causing the cameras to collect image data; camera management system  that provides a mechanism for tracking and managing cameras in the metaverse; triggering event identification system  that provides a mechanism for determining when triggering events occur in the metaverse and causing an associated camera to collect image data; notification system  that provides a mechanism for notifying a user  that image data has been collected from the metaverse from one of the user's cameras; and storage\/delivery system  that provides a mechanism for storing collected images and\/or delivering images to the user.","As noted, GUI  provides an interface for allowing an end user to install and administer one or more cameras in the metaverse. This may include:","(1) Placing a camera at selected location in the metaverse;","(2) Selecting a type of camera;","(3) Defining a field of view and orientation for the camera;","(4) Defining one or more triggering events to cause the camera to collect image data;","(5) Defining whether\/how the user  is to be notified when image data is collected;","(6) Defining whether\/how the image data is to be stored; and","(7) Defining whether\/how image data is to be delivered.","Note that while the described embodiment utilizes a GUI  to perform the above functions, any type of interface may be utilized, e.g., a application programming interface (API) that allows a third party application to perform the above.","Camera management system  tracks and manages all cameras in the metaverse installed by the different users . Camera management system  stores all settings for each camera, e.g., location, orientation and direction, field of view, image type (e.g., still images, video, high definition, widescreen, infrared, color, black and white, etc), how many images are to be taken, how long a video sequence should be, whether the camera is active at a given point in time, etc. Camera management system  maintains a camera database  of all the cameras in the metaverse, as well which avatar\/user each camera belongs to, and the settings of each camera.","Camera management system  may also track and determine when a camera is active (or enabled). For instance, it may be the case that a camera is only to be enabled when a user  is logged off, or when a user's avatar is away from the location of the camera, or when a user's avatar is at a particular location in the metaverse, etc. In addition, cameras can be enabled and disabled by the user  at any time, e.g., via a set of keystrokes.","Triggering event identification system  provides an engine for determining when a triggering event associated with a particular camera has occurred within the metaverse. A triggering event is essentially a rule for dictating when a given camera should capture image data. Triggering events can be defined by a user  when they administer a camera via GUI . Triggering events may be selected\/implemented in any manner, e.g., via a drop down box, based on a set of user entered rules, based on a natural language (NL) input, etc.","In a simple user friendly embodiment, the user  can simply select a triggering event from a set of triggering events, e.g., via a drop down box, etc. More complex triggering events may be provided with logical ANDs, ORs, etc., that allows the user  to select and combine multiple triggering events. The resulting definition can then be embodied as a rule which the triggering event identification system  can continuously analyze.","In a different approach, a user  may be able to enter rules directly using a structured command set that follows a predefined protocol\/syntax. For instance, a user  could define a triggering event via a user entered rules dialog box in GUI  such as:\n\n","In this example, the user entered command has defined a triggering event to collect image data if an avatar enters the field of view of camera (i.e., is detected) and the detected avatar is a friend and the detected avatar is engaged in a transaction.","In still a further embodiment, the user  could simply enter a natural language input that would be parsed and turned into a rule by a natural language engine. For instance, rather than typing in the above rule, the user  could simply enter the natural language input \u201ctake a picture if a friendly avatar is engaged in a transaction.\u201d A natural language engine would then automatically convert the input into a rule (such as the command sequence above) that could be analyzed by triggering event identification system . An interactive natural language system could be utilized to resolved ambiguities or ensure the interpreted command is what the user  intended.","Triggering events may comprise any type of actions that occur with the metaverse. Moreover, triggering events may be implemented independently of a user action, e.g., when the user is not logged in or resides elsewhere in the metaverse. Illustrative triggering events include, but are not limited to:","An avatar\/user having a particular criteria (e.g., co-worker) walking by a location;","The detection of the avatar's friends, where a friend is defined as those associated with the user who placed the camera;","A transaction, for example a, payment action between one or more avatars or retailers, an exchange;","The use of an object;","The act of an avatar attempting to access a secure virtual location, for example a private land parcel;","An avatar in a location performing a particular gesture;","Events\/meeting\/classes in which filming begins and ends in synch with these activities;","Multiple avatars being within a certain proximity of each other (to capture activities of \u201cgroups\u201d);","The occurrence of an undesirable activity;","Detection of avatars who have been denoted as \u201crepeat public offenders\u201d;","etc.","Upon the detection of a triggering event, triggering event identification system  causes an associated camera to collect image data in a manner defined within GUI  by the user . In a typical embodiment, the triggering event comprises an action occurring within a field of view of the camera, e.g., a friendly avatar passing by, a gesture being detected, etc. However, in other cases, the triggering event could be an occurrence not associated with an action in the field of view, e.g., a clock striking midnight may trigger image data collection within a social club. In any case, the triggering event for a user's camera is generally independent of actions of the user  and the user's avatar.","Notification system  is responsible for notifying a user  when image data has been captured. Notifying can be done in any manner, and can be done via a third party application  such as email, text messaging, instant messaging, via a social networking application, etc. In another embodiment, the notification may occur when a user  logs in.","Storage and delivery system  is responsible for storing and\/or delivering image data. Image data may be stored in an image database  or elsewhere and\/or be delivered to the user  in any manner, e.g., via a third party application . For instance, image data may be stored in a user's inventory, through which the user  can view the image data. Image data may be sent to an external application, for example email, for which the user  already has an association, be streamed to an external web application allowing the avatar to consume the image data from a browser application, etc.",{"@attributes":{"id":"p-0049","num":"0049"},"figref":"FIG. 2","b":["24","50","48","50","48","56","54"]},"Once a desired location is displayed in the map interface , the user locates camera  within the scene at a desired location. In this example, an outdoor scene is selected that includes two adjacent buildings (Bldg  and Bldg ) and the user has set the camera  at the entrance to Bldg , e.g., to capture images of avatars coming in and out. Various camera tools  may be provided for locating the camera  in the scene, setting a field of view, zooming, etc. In addition, a thumbnail image  may be presented that depicts a real time view of the camera  at its current location. In this case, the map interface  shows the scene in a two dimensional (2D) top view. However, three dimensional (3D) views and controls could also be presented for locating the camera . Other controls for setting the field of view  may also be provided.","In addition, in this GUI , the user is able select a camera type  (still, video, HD, etc.), select a triggering event setting , and select a notification and delivery setting  using drop down boxes. It is understood that GUI  of  is depicted for illustrative purposes only, and many variations, functional additions, etc., could be provided and fall within the scope of the invention.",{"@attributes":{"id":"p-0052","num":"0052"},"figref":"FIG. 3","b":["1","2","3","4","5","6","7"]},"Referring again to , it is understood that metaverse application  may be implemented using any type of computing device e.g., computer system ). Such a computing device generally includes a processor , input\/output (I\/O) , memory , and bus . The processor  may comprise a single processing unit, or be distributed across one or more processing units in one or more locations, e.g., on a client and server. Memory  may comprise any known type of data storage, including magnetic media, optical media, random access memory (RAM), read-only memory (ROM), a data cache, a data object, etc. Moreover, memory  may reside at a single physical location, comprising one or more types of data storage, or be distributed across a plurality of physical systems in various forms.","I\/O  may comprise any system for exchanging information to\/from an external resource. External devices\/resources may comprise any known type of external device, including a monitor\/display, speakers, storage, another computer system, a hand-held device, keyboard, mouse, voice recognition system, speech output system, printer, facsimile, pager, etc. The bus  provides a communication link between each of the components in the computing device and likewise may comprise any known type of transmission link, including electrical, optical, wireless, etc. Although not shown, additional components, such as cache memory, communication systems, system software, etc., may be incorporated.","Access to computer system  may be provided over a network such as the Internet, a local area network (LAN), a wide area network (WAN), a virtual private network (VPN), etc. Communication could occur via a direct hardwired connection (e.g., serial port), or via an addressable connection that may utilize any combination of wireline and\/or wireless transmission methods. Moreover, conventional network connectivity, such as Token Ring, Ethernet, WiFi or other conventional communications standards could be used. Still yet, connectivity could be provided by conventional TCP\/IP sockets-based protocol. In this instance, an Internet service provider could be used to establish interconnectivity. Further, as indicated above, communication could occur in a client-server or server-server environment.","It should be appreciated that the teachings of the present invention could be offered as a business method on a subscription or fee basis. For example, a computer system comprising a metaverse application  could be created, maintained and\/or deployed by a service provider that offers the functions described herein for customers. That is, a service provider could offer to deploy or provide the ability to utilize a camera in a metaverse as described above.","Moreover, while the present invention is described with reference to collecting image data, the system and processes described herein could be utilized to capture any type of data within a metaverse, and such applications are within the scope of the invention.","It is understood that in addition to being implemented as a system and method, the features may be provided as a program product stored on a computer-readable storage medium, which when run, enables a computer system to provide a metaverse application  with a camera system . To this extent, the computer-readable storage medium may include program code, which implements the processes and systems described herein when executed by a computer system. It is understood that the term \u201ccomputer-readable storage medium\u201d comprises one or more of any type of physical embodiment of the program code. In particular, the computer-readable storage medium can comprise program code embodied on one or more portable storage articles of manufacture (e.g., a compact disc, a magnetic disk, a tape, etc.), on one or more data storage portions of a computing device, such as memory and\/or a storage system.","As used herein, it is understood that the terms \u201cprogram code\u201d and \u201ccomputer program code\u201d are synonymous and mean any expression, in any language, code or notation, of a set of instructions that cause a computing device having an information processing capability to perform a particular function either directly or after any combination of the following: (a) conversion to another language, code or notation; (b) reproduction in a different material form; and\/or (c) decompression. To this extent, program code can be embodied as one or more types of program products, such as an application\/software program, component software\/a library of functions, an operating system, a basic I\/O system\/driver for a particular computing and\/or I\/O device, and the like. Further, it is understood that terms such as \u201ccomponent\u201d and \u201csystem\u201d are synonymous as used herein and represent any combination of hardware and\/or software capable of performing some function(s).","The block diagrams in the figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods and computer program products according to various embodiments of the present invention. In this regard, each block in the block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that the functions noted in the blocks may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be run substantially concurrently, or the blocks may sometimes be run in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams can be implemented by special purpose hardware-based systems which perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.","Although specific embodiments have been illustrated and described herein, those of ordinary skill in the art appreciate that any arrangement which is calculated to achieve the same purpose may be substituted for the specific embodiments shown and that the invention has other applications in other environments. This application is intended to cover any adaptations or variations of the present invention. The following claims are in no way intended to limit the scope of the invention to the specific embodiments described herein."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["These and other features of this invention will be more readily understood from the following detailed description of the various aspects of the invention taken in conjunction with the accompanying drawings.",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"}]},"DETDESC":[{},{}]}
