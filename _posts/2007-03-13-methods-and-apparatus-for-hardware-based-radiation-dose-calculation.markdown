---
title: Methods and apparatus for hardware based radiation dose calculation
abstract: Disclosed is an example method to calculate radiation dose. The method includes receiving a tissue matrix in which the tissue matrix includes a plurality of voxels. The example method also includes producing a first plurality of transport lines with a direction controller in which each transport line is indicative of a cone of irradiated energy, and calculating at least one radiation dose with at least one deposit engine substantially in parallel with producing a second plurality of transport lines with the direction controller.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08494115&OS=08494115&RS=08494115
owner: The University of Maryland, Baltimore
number: 08494115
owner_city: Baltimore
owner_country: US
publication_date: 20070313
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATION","GOVERNMENT INTEREST STATEMENT","FIELD OF THE DISCLOSURE","BACKGROUND OF RELATED ART","Dose Calculation","DETAILED DESCRIPTION","Homogeneous and Inhomogeneous Media","Dose Calculation","Fast Fourier Transform (FFT)","Monte Carlo","Convolution\/Superposition","Collapsed Cone","Kernel Calculation","Field Programmable Gate Arrays","Dose Calculation Hardware","Direct Convolution","Collapsed Cone","Convolution and Collapsed Cone Analysis","Multi-Level Parallel Dose Calculation","Ray Tracing","System Memory","Parallel Structure Implementation"],"p":["This application is a non-provisional application claiming priority from U.S. Provisional Application Ser. No. 60\/782,125, filed Mar. 14, 2006, entitled \u201cMethods and Apparatus for Hardware Based Radiation Dose Calculation\u201d and incorporated herein by reference in its entirety.","This disclosure was made, in part, with United States government support from the National Institutes of Health, grant No. R01 CA92263, and the National Science Foundation, grant No. CCF-0515203. The United States government has certain rights in this invention.","The present disclosure relates to the treatment planning step of radiation therapy, and in particular to radiation dose calculation.","Radiation therapy is a common form of cancer treatment that involves the use of certain types of energy (called ionizing radiation) to kill cancer cells and shrink tumors. There are two main types of radiation therapy, internal radiation (brachytherapy) and external radiation (systemic).","Systemic therapy includes radiation that is delivered from a device external to the patient, and is typically delivered from a linear accelerator, a synchrotron, or a cyclotron, and can be used to treat most types of solid tumors. Typically, external radiation therapy is performed over multiple sessions to maximize the amount of radiation delivered to the tumor and minimize the amount delivered to the surrounding healthy tissue.","The radiation delivered to a patient is called radiation dose or dosage. A radiation dose is measured using a unit called a gray (Gy) and\/or centigrays (cGy). Different tissues and organs are capable of withstanding different amounts of dosage and still functioning correctly. For example, the liver can withstand approximately 3,000 cGy, while the kidneys can only withstand approximately 1,800 cGy.","Planning and delivery of radiation therapy typically involves many different team members. Four of these members may include a radiation oncologist, a dosimetrist, a radiation physicist, and a radiation therapist. A radiation oncologist is a doctor who specializes in the treatment of cancer using radiation and typically participates in many steps of the treatment process. The dosimetrist determines the proper radiation dose for the patient. The radiation physicist, who may participate in both the planning and treatment phases, ensures that the equipment delivers the prescribed amount of radiation to the proper location. The radiation therapist, who also typically participates in the planning and treatment phases, delivers the actual treatment.","During a typical planning stage, a patient lies still on a table while the therapist uses an x-ray machine to define the treatment locations (based on patient contours and tumor location(s). A CT (Computed Tomography) device or an MRI (Magnetic Resonance Imaging) device is typically used in this stage to identify the location of the tumor and identify surrounding healthy tissue and organs. During the treatment process, the areas where radiation will be delivered are marked, such as with a temporary or permanent marker, tiny dots, and\/or a tattoo. These locations are then defined for future sessions. For some forms of treatment, especially where the patient may be likely to move, molds may be made to ensure that the patient remains motionless.","Once a treatment plan has been devised, it is typically tested to ensure that the radiation delivered by the plan matches the prescribed dosage from the radiation oncology, which is at least one goal of radiation dose calculation. If there is too little dosage delivered to the target site a tumor may persist, and if there is too high a dosage delivered healthy tissue may be harmed.","Generally speaking, radiation dose calculation involves computing the amount of energy, released via a photon beam that is deposited within a region of interest within a patient. These areas of interest are typically further broken down into small cubic volume elements referred to as voxels. The size of these voxels changes depending on many different factors, including the calculation algorithm along with size and location of the tumor. The amount of energy deposited in each voxel is typically accumulated and then the final dose may be calculated by dividing the total energy per voxel by the average density of the matter in that voxel. In other words, radiation dose typically depends not only on the amount of energy, but also on the density of the tissue.","The main methods of photon dose deposition are typically via the Compton effect, pair production, and photoelectric effects. All of these refer to the process of a photon interacting with either an electron or the nucleus of an atom.","The photoelectric effect refers to when an incoming photon undergoes a collision with a tightly bound electron. The photon transfers its energy to the electron and ceases to exist. The electron then ionizes particles around it. The probability of the photoelectric effect depends on the initial energy of the photon and the atomic number of the tissue. The probability increases for low energy photons in tissue with a high atomic number.","The Compton effect typically occurs most frequently (of the three methods) in a clinical setting. The Compton effect occurs when a photon collides with a free electron. Both the photon and the electron are scattered. The photon continues on at a slightly different trajectory and with less energy, while the electron begins to ionize. The probability of this effect occurring is inversely proportional to the energy of the photon and is independent of the atomic number of the tissue.","Pair production occurs when a photon interacts with the nucleus of an atom. The photon gives up its energy to the nucleus. This process creates a pair of electrons, one with a positive charge and one with a negative charge. The positive electron (positron) ionizes until combining with a free electron. This then generates two photons, which scatter in opposite directions. The probability of this effect occurring is proportional to the log of the energy of the photon and is also dependent on the atomic number of the tissue.","Radiation dose calculation is an important step in the treatment of patients requiring radiation therapy. It ensures that the physician prescribed dose agrees with the dose delivered to the patient. At least two methods of dose calculation are in use today. One class of algorithms is known as convolution\/superposition, and the other is known as Monte Carlo analysis. Monte Carlo methods are typically the most accurate and also the most computationally intensive methods available. These are not usually used in clinical practice due to the computational load they generate. Convolution\/superposition methods are slightly less accurate, but can typically be computed in much less time than Monte Carlo methods. While the overall computational power available continues to increase, it may not efficiently facilitate Monte Carlo analysis techniques in a clinically feasible time.","For example, the University of Maryland Medical Center in Baltimore uses two different software packages to compute radiation dose. One such package includes the PINNACLE\u00ae system from Philips, and another package includes PROWESS PANTHER\u00ae from Prowess, Inc. However, with these software systems it can take anywhere from 5 to 45 minutes to calculate the dosage from a treatment plan. After the calculation phase, the plan may be examined, and if changes are required another calculation is typically performed before the plan can be reviewed again. Additionally, after an MRI is taken of the patient, the tumor and other organs do not remain in a fixed position. A patient's breathing and\/or change of posture may cause a corresponding change in the location of the patient's organs and\/or tumor. As a result, additional time is consumed by re-calculating dose.","The methods and apparatus described herein provide a simple addition to existing host computer and\/or processor with moderate cost, but with fewer facilities concerns. Some of the designs presented herein may be implemented as SoPCs (Systems on a Programmable Chip). SoPCs enable rapid prototyping and implementation of new systems. SoPCs typically feature some form of embedded processor (such as the NIOS II\u00ae processor from Altera) along with dedicated hardware subsystems. SoPC use has increased in recent years due in part to better software tools, larger FPGA chips, and improvements in embedded and soft-core processors. Many SoPCs have advantages over other solutions due to their programmability, ease of implementation, and lack of additional required hardware.","The methods and apparatus described herein include hardware designs of radiation dose calculation methods. These designs have been shown to outperform existing software dose calculation implementations. They incorporate several different hardware design techniques, including pipelining, double buffering, and ideas from array processing. With one example design, an embedded soft-core processor is utilized, and both designs may access off-chip memory subsystems and\/or networked data, without limitation.","Radiation dose calculation may be performed on homogeneous or inhomogeneous media. Homogeneous media means that there is only one type of tissue present in the region of interest. This situation would not typically occur in practice, but certain portions of the body can be assumed to be nearly homogeneous with little loss of accuracy. Inhomogeneous, or heterogeneous media, refers to situations where there are multiple types of tissue present in the region of interest. An example would be a mediastinum (chest region) region of interest. This region may include the lungs, the heart, bone, etc.","If radiation dose calculation can be performed on homogeneous media, then it is typically not necessary to perform inhomogeneity corrections and the use of direct convolution can be applied. As such, a direct convolution implementation (e.g., by using the NIOS\u00ae soft-core processor by Altera) that functions on an FPGA (Field Programmable Gate Array) using integer arithmetic is described herein. This convolution may be quicker than a commodity CPU by up to a factor of 35.12 for the convolution of a 100\u00d7100\u00d7100 matrix with a 100\u00d7100\u00d7100 kernel and illustrates the effectiveness of using an FPGA over a CPU. This implementation does not actually calculate radiation dose, but instead performs operations similar to those required as an evaluation of the potential speed increase. If the dose calculation must be performed in inhomogeneous media, as is usually the case, direct convolution does not typically yield accurate enough results for clinical practice. For these situations, another dose calculation method is implemented, as described in further detail below.","For inhomogeneous media, a three dimensional convolution\/superposition collapse cone algorithm is described herein for an FPGA to achieve performance above that obtainable using a traditional CPU. The dose calculation algorithm described herein makes use of an exponential kernel and the collapse cone approximation for calculating dose, as discussed in further detail below.","Simulations of the designs described herein have shown to outperform a commodity CPU by a factor of 21.6 for a reasonable calculation size. The methods and apparatus described herein assume that both the TERMA (Total Energy per unit MAss) and kernel are provided. The calculation of both the TERMA and kernel require 0.25 seconds on an example computer used for concept verification purposes. With that same computer, the entire calculation requires 61.198 seconds for an 11\u00d711\u00d730 region of interest. Therefore, the portions of the software not placed in a hardware implementation account for only about 0.4% of the calculation time for a decently sized region of interest. Accordingly, approximately 99.6% of the calculation time is spent performing tasks converted to hardware. As described in further detail below, the hardware implementation(s) perform the task of using a collapse cone superposition algorithm to calculate the dose using the available TERMA and kernel.","Results of the dose calculation hardware have been verified against a software dose calculation algorithm provided by the University of Maryland Medical Center. The results of the hardware algorithm are within 1.15% on average of the software algorithm and demonstrate the correct functioning of the hardware implementation.","In general, dose calculation is about determining the amount of energy deposited within a phantom (material used for the absorbing medium in experimental dose measurement) by the photon beam produced by a linear accelerator. The photons in this beam travel to the phantom and then either interact within the phantom, or pass through it. If an interaction occurs within the phantom, energy is released through the collision of photons with other particles. This energy is not all deposited at the site of the interaction, but rather in a type of tear drop shape slanted in the direction of the interacting photon.","To accurately calculate radiation dose, there are many different factors to consider. For example, the source of the radiation is typically considered, and one such machine that delivers radiation is an example linear accelerator , as shown in . In the illustrated example of , the linear accelerator is a VARIAN CLINAC 2100C\u00ae machine operated in photon mode.  illustrates, in part, electrons hitting the target , which produces a photon stream . These photons then pass through a primary collimator , a flattening filter , a monitor chamber , a secondary collimator , and finally through jaws  before they proceed on to a patient.","Once the composition of tissues is known, and the energy (fluence) of the photon beam is known, the distribution of radiant energy released locally in a patient may be calculated. This local distribution is known as the primary energy distribution because the energy is released by the primary (or initial) interaction of photons with the patient. Typically, this primary energy is then further distributed by secondary particles (electrons, positrons, and photons) until it is absorbed as a dose or it escapes from the bounds of the patient and is no longer of interest. This two step process is the basis for several methods of dose calculation where this distribution of primary energy is convolved with a kernel. The kernel is a three dimensional matrix that describes the distribution of primary energy by the secondary particles. Primary energy released by interaction with a photon does not remain at the interaction site, but is further distributed, and the method of that distribution is known as the kernel. The primary energy distribution is typically referred to as the TERMA, while the kernel is known by many different names (e.g., depending on the author and\/or the method). Some names for the kernel include, but are not limited to, differential pencil beams, point spread functions, and\/or energy deposition kernels.","Changes in any of the previous components affect the calculation of the TERMA. There are many different TERMA calculation methods which can include a variety of correction factors. It should be noted that the TERMA is, by nature, an approximation of the energy received in a voxel and not an exact measurement. As the TERMA represents an intermediate dose calculation step, it should also be noted that Monte Carlo based radiation dose calculation algorithms have no need to calculate TERMA because they follow the path of each individual photon and only accumulate dose.","A general TERMA calculation is shown in Equation 1.",{"@attributes":{"id":"p-0058","num":"0057"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"T","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}},{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":"r","mo":"\/","msub":{"mi":"r","mn":"0"}}},"mn":"2"},"mo":["\u2062","\u2062","\u2062"],"mfrac":{"mrow":[{"mover":{"mi":["\u03bc","_"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}},{"mi":"\u03c1","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}}]},"mrow":[{"mi":"\u03a8","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"r","mn":"0"}}},{"mrow":{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mo":"-","mrow":{"msubsup":{"mo":"\u222b","msub":{"mi":"r","mn":"0"},"mi":"r"},"mo":"\u2062","mrow":{"mrow":[{"mover":{"mi":["\u03bc","_"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"l"}},{"mo":"\u2146","mi":"l"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}}}},"mo":"."}]}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"1"}}]}}}}},"Equation 1 represents an approximate TERMA distribution. In this equation, \u03c1(r) is the density of the medium at r and \u03c8(r) is the fluence at r. Of the scalars, r is the current calculation radius (representing the radius of the current point at which the TERMA is being calculated) and ris the radius at the phantom surface. Also,  is the mean linear attenuation coefficient calculated for the medium present at r using the initial, unhardened spectrum through Equation 2.",{"@attributes":{"id":"p-0060","num":"0059"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mover":{"mi":["\u03bc","_"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}},{"mfrac":{"mn":"1","mrow":{"mi":"\u03c8","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"r","mn":"0"}}}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"msub":{"mi":["\u03c8","i"]},"mo":"\u2062","mrow":{"mrow":{"mi":"\u03bc","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["E","i"]},"mo":",","mi":"r"}}},"mo":"."}}}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"2"}}]}}}}},"Discussed below are inhomogeneity concerns, which are important for the collapse cone implementation, and different physical factors affecting how dose is deposited. The human body includes many different types of tissues, all of which have varying densities and properties. These inhomogeneous tissues may affect the calculation of the radiation dose when using the convolution\/superposition methods of dose calculation, and are typically the main reason that faster software implementations have not yet been developed. With Monte Carlo methods, dose deposition factors are statistically modeled and inherently included. However, extending the convolution\/superposition methods to heterogeneous media is not as simple. To be rigorous, a different kernel would need to be generated for every heterogeneous situation that could be encountered. This is obviously unreasonable as the number of heterogeneous possibilities is significant. Therefore, an acceptable compromise between accuracy and speed\/memory use may be employed.","One solution employed is to use range scaling to approximate a new kernel in heterogeneous phantoms. This is typically known as the density scaling method. Persons having ordinary skill in the art will appreciate that results obtained using this method can be off by as much as 50% when compared to the Monte Carlo calculations. However, this difference is much less severe when using realistic photon beams in representative tissue(s).",{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 2","FIG. 2"],"b":["202","204","206","208"]},"Density scaling works by finding the average  (tissue density) between the interaction and deposition voxels. Kernels computed for a specific \u03c1 (normally water, where \u03c1 1.0), thus is typically adjusted (scaled) when the  of the tissue is different from the p of the kernel. Computing this is typically a matter of scaling the distance by a factor of \u03c1\/ . In homogeneous media, simply using a physical distance indicator l is usually sufficient, but with heterogeneous media, a scaling factor is typically used (p*l) to get the radiological path length (rather than the physical path length). Physical path length represents the physical length between an interaction and deposition voxel. Radiological path length represents the radiological distance (relative to that of the available kernel) between the interaction and deposition voxels, and depends on both average density of the material and physical distance.","There are several different methods by which the energy of photon beams created as bremsstrahlung, which is the photon radiation emitted by the deceleration of an electron in the Coulomb field of an atom and deposited within a phantom. Once a photon imparts some energy to an electron, the energy from the electron is deposited locally when viewed in relation to the photon. A photon may pass through a patient and only interact at one or two locations, but once the interaction occurs, the energy released to the electron is deposited in a region local to the interaction site (described by the kernel).","As discussed above, there are many different methods used to perform dose calculation. The methods described herein include the FFT (Fast Fourier Transform) method, the Monte Carlo analysis, and convolution\/superposition methods. Additionally, details regarding the collapse cone method are described herein, which is a specialized convolution\/superposition method.","It has long been known that convolution in the spatial domain is equivalent to multiplication in the frequency domain. FFTs are a way of converting data given in the spatial domain to the frequency domain. A convolution equation typically would resemble that given in Equation 3.",{"@attributes":{"id":"p-0068","num":"0067"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j","k"],"mo":[",",","]}}},{"mfrac":{"mn":"1","mrow":{"mi":"\u03c1","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j","k"],"mo":[",",","]}}}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","msup":{"mi":["i","\u2032"]}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","msup":{"mi":["j","\u2032"]}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","msup":{"mi":["k","\u2032"]}},"mo":"\u2062","mrow":{"mrow":[{"mi":"T","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msup":[{"mi":["i","\u2032"]},{"mi":["j","\u2032"]},{"mi":["k","\u2032"]}],"mo":[",",","]}}},{"mi":"H","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"i","mo":"-","msup":{"mi":["i","\u2032"]}}}}],"mo":"\u2062"}}}}}],"mo":"="},{"mo":["(",")"],"mrow":{"mi":"j","mo":"-","msup":{"mi":["j","\u2032"]}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"k","mo":"-","msup":{"mi":["k","\u2032"]}}},"mo":"."}],"mo":[",",","]}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"3"}}]}}}}},"In Equation 3, D(i, j, k) is the value of the dose, T(i\u2032, j\u2032, k\u2032) is the TERMA at the interaction site, and H(i-i\u2032), (j-j\u2032), (k-k\u2032) is the value of the energy deposition kernel at the deposition site. Also, \u03c1(i, j, k) represents the density of the medium at (i, j, k). This summation is performed over all voxels in the medium where both T(i\u2032, j\u2032, k\u2032) and H(i-i\u2032), (j-j\u2032), (k-k\u2032) are not equal to 0. In convolution calculations, it should be noted that the kernel used needs to be invariant, and it can be seen in Equation 3 that the kernel satisfies this constraint. Moreover, the method of dose calculation illustrated above is computationally expensive.","One alternate approach is to take the FFT of both the TERMA matrix and the kernel matrix, which may be accomplished by using any number of FFT conversion algorithms, each of which has benefits of its own. As a result, instead of performing convolution, an element by element multiply of the transformed matrices may be performed, in which the inverse FFT of the resulting matrix is performed to obtain the dose. As it is typically less computationally intense to perform two FFTs, a multiply, and an inverse FFT, this method is quicker that other algorithms.","The FFT algorithm, while quick, does suffer from a number of drawbacks. One such drawback includes a requirement that the kernel used be invariant. Therefore, it becomes more difficult to obtain an accurate dose with heterogeneous media.","The Monte Carlo method of radiation dose calculation follows the path of individual particles through the accelerator, beam modifiers, and the patient to determine dose, fluence, and other distributions in patients and phantoms. It uses basic physics interaction probabilities to determine the fate of each particle. As this method is based on probability, there must be a sufficient number of representative particles transported to produce statistically acceptable results.","The Monte Carlo method follows particles recording quantities of interest, such as energy deposition (dose) and fluence. It follows these particles until they are no longer of interest, i.e., they escape the region of interest, the particle is absorbed, or the particle drops below the energy cut-off. To get a statistically valid result, approximately 100 million particles are used during a simulation. Increasing the number of particles simulated increases the computation time linearly, but only improves the accuracy by the square root of the number of particles. Due to repeated use of the same calculation, Monte Carlo methods may also be candidates for hardware implementation.",{"@attributes":{"id":"p-0074","num":"0073"},"figref":["FIG. 3","FIG. 4","FIG. 4"],"b":["402","404","406","408","402"]},"The convolution\/superposition method of radiation dose calculation can be thought of as a convolution between the TERMA and the kernel. This convolution can be defined in the manner described by Equation 4\n\n()=[1\/\u03c1()]\u222b\u222b\u222b\u222b()\u03c1()()\u2003\u2003Equation 4\n","Typically an algorithm is known as a convolution algorithm if it does not address heterogeneous media, and is known as a superposition algorithm if it does address heterogeneous media. As the general idea is the same between them, they are typically classified together as convolution\/superposition algorithms.","When the kernel must be scaled depending on the density of the media, a straight forward convolution approach can no longer be used. Because of this, the convolution method may be changed to allow a varying kernel and the new algorithms use superposition.","Equation 4 shows the calculation of dose in a continuous integral form. In this equation, the (monoenergic) kernel h(E,s,r) of energy E is defined as the fraction of radiant energy released by primary photons at the initial interaction site s which is imparted per unit volume at r. In homogeneous media, the point spread function is spatially invariant and h(E,s,r) is replaced by h(E,s-r). In view of the definition of the TERMA, the radiant energy released from a volume element ds of density \u03c1(s) irradiated by photons of energy E, is T(s)\u03c1(s)ds and hence the absorbed dose at r is given by integration over volume and energy as above. The final division by \u03c1(r) converts the energy imparted per unit volume to energy imparted per unit mass, or dose.","However, it is not typically efficient or feasible to integrate over energy, so the dependence on energy is taken out by using a polyenergetic kernel and calculating TERMA for all energies. The kernel h(E, s, r) presented in Equation 4 is a monoenergetic kernel, while the kernel h(s, r), presented as Equation 5, is polyenergetic.\n\n()=()[1\/\u03c1()]\u222b\u222b\u222b()\u03c1()()\u2003\u2003Equation 5\n","In Equation 5, f(r) is a dose hardening correction factor. The above equations provide a general idea of how dose is computed using a superposition approach. While the equations involve integrals, it should be noted that in a discrete implementation, the integrals would be replaced by summations, and the continuously varying functions (TERMA, density, etc.) would be replaced by discrete intervals over which the function would be assumed to be constant. Using discrete intervals, dose would then be accumulated into voxels, rather than continuous points.","The purpose of the collapsed cone convolution algorithm was initially to make it practical to implement the function described in Equation 5. The equation illustrates that the integrals must be evaluated for all combinations of scattering and receiving points, which are time consuming. For each interaction point, there are Nscattering points or points where dose could be \u201cscattered\u201d to consider, where N is the number of voxels along one side of the matrix. Equation 5 also takes up to N operations to ray-trace between a scattering and receiving point. Therefore, the complexity of this approach would be between Nand Noperations.","Similar to all kernel-based superposition methods, the collapsed-cone algorithm models the radiation energy release as a two-phase process. Phase 1 considers the interaction of photons with the tissue. If an interaction occurs within the phantom, it is assumed that this energy is all deposited at the interaction site. Phase 2 examines energy diffusion. As shown in , the radiation energy is considered to be diffused in a teardrop shape slanted in the direction of the interacting photon . A normalized kernel may be used to describe how this energy is distributed in the phantom. The kernel is depicted as isodose curves  as shown in .","As described above, there must be a discretation of the components mentioned in Equation 5. In dose planning, the target spatial resolution of this discretation is typically between 0.1 to 1 cm. In this range, the TERMA is slowly varying and no sizable errors are introduced with its discretation. The energy deposition kernels have very steep gradients within the same range. Therefore, the discretation of the kernel typically results in very small gradients close to the interaction site and larger gradients as distance from the interaction site increases.","Collapsed cone approximation is shown in . The \u201cCollapsed Cone\u201d approximation is made in the manner described below. All energy released into coaxial cones, of solid angle \u03a9from volume elements on the axis are rectilinearly transported, attenuated and deposited in elements on that axis. This allows for accurate computation of the dose deposited to all voxels while performing fewer computations: The dose may be calculated using M*Ncalculations, where M is the number of cones (typically between 48 and 384) and N is the number of Cartesian voxels along one side (i.e., there are Nvoxels). The FFT Method previously described requires (2N)*log2N and has the problem of requiring an invariant kernel. In the illustrated example of , a collapsed cone approximation  illustrates all energy released from primary photos at elements on a cone axis  of direction (\u03b8\u03a6) and flowing in coaxial cones  of solid angle \u03a9, is rectilinearly transported and deposited on an axis . In the illustrated example, to transport all energy released, several cone axes are used such that \u03a3\u03a9=4\u03c0, and parallel axes of each direction cover the irradiated volume. While the example collapsed cone approximation  of  illustrates one axis, an infinite number of axes, where \u03a9\u21920, yields a continuous case of rectilinear motion. An interaction point  is shown in , in which a cone covers only a fraction of a Cartesian voxel, as shown by voxel \u201cA\u201d  and voxel \u201cA\u2032\u201d . Additionally,  illustrates off-axis voxel \u201cB\u201d  and off-axis voxel \u201cB\u2032\u201d . In the collapsed cone approximation, the energy that should have been deposited in voxel \u201cB\u2032\u201d  from interactions at the vertex of the lower cone is deposited in voxel \u201cB\u201d , and vice-versa. As a result, the relative accuracy of the calculated energy deposition decreases with the distance from the scattering point. The error is small because the magnitude of polyenergetic point spread functions decreases rapidly with the distance from the interaction point.","Several equations are described below to accurately compute dose using the collapsed cone approximation, which relate to hardware implementation. Described below are two example methods used to calculate the kernel for the convolution\/superposition class of dose calculation algorithms. A first example method includes using Monte Carlo analysis. A second method employs exponential functions for reproducing a kernel. It should be noted that even with the exponential kernel, Monte Carlo may still be used to generate the original data points, and then regression may be applied to find the exponential values used for the kernel.","EGS (Electron Gamma Shower) Monte Carlo code may be used to generate energy deposition kernels. The EGS code is a general purpose photon-charged-particle transport simulation system, which may be used for medical physics. It was originally developed at SLAC (Stanford Linear Accelerator Center) to describe the transport through matter of photons and charged particles from very high-energy linear accelerators and cosmic rays.","The EGS code may generate monoenergetic kernels of energies varying from 0.1 to 50 MeV. These kernels can then be used in convolution calculations to produce dose distributions. Additionally, they may be repeated for each spectral component of the photon beams. Photon beams are not monoenergic, but rather contain multiple different energies. Polyenergetic kernels may also be composed for a spectrum by weighting multiple monoenergetic kernels by their respective contribution to the spectrum. These kernels can then be scaled to other mediums.","The zone dominated by scattered photons of monoenergetic kernels is described accurately by an exponential, B exp(\u2212b|r|)\/|r|, where B and b depend on the energy and the angle of r versus the direction of the impinging primary photon, and r is the radius from the interaction point. Polyenergic kernels may be described by a similar function shown in Equation 6.\n\n(,\u03b8)=()\/\u2003\u2003Equation 6\n","In this equation, A, a, B, and b are functions of the scattering angle \u03b8 and the accelerating potential (e.g., 10 MV). Scattering angle refers to the angle that the receiving point is (in spherical coordinates) at in relation to the interaction point, while the accelerating potential is a function of the particular linear accelerator used.  illustrates that there is good agreement between the exponentially calculated kernel and one generated using Monte Carlo analysis. A 6 MV energy plot  and a 15 MV energy plot  are shown in . These figures illustrate deposition kernels for photons in water, in which the thin, hatched lines were calculated with Monte Carlo, and the thick, solid lines are corresponding analytical fit curves.","Typically, kernels are stored in memory and then loaded each time they are required. However, FPGAs typically contain very limited memory bandwidth, thereby illustrating a benefit to calculate a kernel rather than loading one.  also illustrates that using the exponentially calculated kernel does not adversely affect calculation accuracy. To use the kernel in heterogeneous mediums, a density scaling method is applied, as shown in Equation 7.",{"@attributes":{"id":"p-0091","num":"0090"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["r","\u03b8","\u03d5"],"mo":[",",","]}}},{"mrow":[{"mi":"\u03b7","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["r","\u03b8","\u03d5"],"mo":[",",","]}}},{"mrow":[{"mo":["(",")"],"mrow":{"mrow":[{"msub":{"mi":["A","\u03b8"]},"mo":"\u2062","msup":{"mi":"\u2147","mrow":{"mrow":[{"mo":"-","mi":"a"},{"msubsup":{"mo":"\u222b","mn":"0","mi":"r"},"mo":"\u2062","mrow":{"mrow":[{"mi":"\u03b7","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["t","\u03b8","\u03d5"],"mo":[",",","]}}},{"mo":"\u2146","mi":"t"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}],"mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03b8"}}},{"msub":{"mi":["B","\u03b8"]},"mo":"\u2062","msup":{"mi":"\u2147","mrow":{"mrow":[{"mo":"-","mi":"b"},{"msubsup":{"mo":"\u222b","mn":"0","mi":"r"},"mo":"\u2062","mrow":{"mrow":[{"mi":"\u03b7","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["t","\u03b8","\u03d5"],"mo":[",",","]}}},{"mo":"\u2146","mi":"t"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}],"mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03b8"}}}],"mo":"+"}},{"msup":{"mi":"r","mn":"2"},"mo":"."}],"mo":"\/"}],"mo":"\u2062"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"7"}}]}}}}},"Here, \u03b7(r, \u03b8, \u03a6) is a spatially varying function representing the ratio of electrons per unit volume (relative to water) and the r value previously in the exponent has been changed from the physical path length to a quantity representing the radiological path length.","The collapsed cone algorithm differs from other existing work in dose calculation in at least two aspects. First, analytical kernels are used, which may be approximated analytically (in homogeneous media) as shown in Equation 8.",{"@attributes":{"id":"p-0094","num":"0093"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["r","m"],"mo":","}}},{"mi":"\u03b7","mo":"\u2062","mrow":{"mfrac":{"mrow":{"mrow":[{"msub":{"mi":["A","m"]},"mo":"\u2062","msup":{"mi":"\u2147","mrow":{"mrow":{"mo":"-","msub":{"mi":["a","m"]}},"mo":["\u2062","\u2062","\u2062"],"mi":["\u03b7\u0394","r"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},{"msub":{"mi":["B","m"]},"mo":"\u2062","msup":{"mi":"\u2147","mrow":{"mrow":{"mo":"-","msub":{"mi":["b","m"]}},"mo":["\u2062","\u2062","\u2062"],"mi":["\u03b7\u0394","r"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":"+"},"msup":{"mi":"r","mn":"2"}},"mo":"."}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"8"}}]}}}}},"In Equation 8, q is the relative electrons density (relative to water), m is the zenith angle, A, a, B, and , are fitting coefficients depending on m. The dose equation for monoenergetic irradiation of a homogeneous phantom is shown in Equation 9.\n\n()=\u222b\u222b\u222b()()\u2003\u2003Equation 9\n","In Equation 9, T(s) is the TERMA from the primary photon energy fluence in the volume element ds. The second key feature of the collapsed cone algorithm is its assumption that the energy released into a cone can be approximated by the energy deposited on the cone's axis. Based on this assumption, the collapsed cone algorithm may reduce the computational complexity of the dose calculation to O(NM), where N is the number of voxels along one side of the tissue matrix, and M is the number of cones used.","To further accelerate the dose calculation by the collapsed cone algorithm, the cone axes from different voxels may be overlapped. Instead of building individually the local polar system for each voxel with non-zero TERMA, a lattice structure, referred to as transport lines, may be used to represent the cone axes for each cone direction in the computation of energy deposited into the area of interests (AOI). For a given direction cosine {d, d, d}, to ensure that the transport lines are able to cover the whole AOI, the concept of a seed plane from which the transport lines originate is used. An example seed plane and some of the transport lines originated from the plane is shown in  for an AOI with the dimensions w\u00d7l\u00d7h.","The placement and area of the seed planes may have an impact on hardware resource usage and performance. In particular, at least one goal includes minimizing the area of each seed plane such that the transport lines originating from the plane cover all of the voxels in the AOI as few times as possible. A first step may include selecting the tissue surface for which an \u201cinward\u201d normal maximizes a scalar product with a direction cosine vector {dx, dy, dz}. For example, in , assume that the |d| is the largest. As such, the top surface of the AOI is selected because d is positive. A second step may include generating a seed plane by expanding the tissue surface identified above along the other two directions. If the direction cosine is negative, the tissue surface is expanded towards the positively increasing direction, and vice versa. For example, in , the top tissue surface is expanded along the positive s and y directions by",{"@attributes":{"id":"p-0099","num":"0098"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"h","mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mfrac":{"msub":[{"mi":["d","x"]},{"mi":["d","z"]}]}}}}},"br":{}},{"@attributes":{"id":"p-0100","num":"0099"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":"h","mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mfrac":{"msub":[{"mi":["d","y"]},{"mi":["d","z"]}]}}},"mo":","}}},"br":{},"sub":["x ","y "]},"Based on the ideas of the seed plane and lattice, the radiation energy deposited into the voxels along the transport lines can be computed iteratively. The dose is considered to include at least two parts: the primary dose and the scattering dose. The former mainly comes from charged particles released by the first interaction of a primary photon, whereas the latter is the result from charged particles set in motion by secondary photons. The final dose for the voxel at r(i) is the sum of the primary dose and the scattering dose, as shown below in Equation 10.\n\n()=()+().\u2003\u2003Equation 10\n","The primary dose D(r) for a voxel Vat ris shown in Equation 11.",{"@attributes":{"id":"p-0103","num":"0102"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msubsup":{"mi":["D","mn","p"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["r","i"]}}},{"mrow":[{"mrow":{"msubsup":{"mi":["D","mn","s"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"r","mrow":{"mi":"i","mo":"-","mn":"1"}}}},"mo":["\u2062","\u2062"],"msub":{"mi":["a","m"]},"msup":{"mi":"\u2147","mrow":{"mrow":{"mo":"-","msub":{"mi":["a","m"]}},"mo":["\u2062","\u2062","\u2062"],"mi":["\u03b7\u0394","r"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},{"mi":"T","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u03a9","mn"]},"mfrac":{"msub":[{"mi":["A","m"]},{"mi":["a","m"]}]},"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msup":{"mi":"\u2147","mrow":{"mrow":{"mo":"-","msub":{"mi":["a","m"]}},"mo":["\u2062","\u2062","\u2062"],"mi":["\u03b7\u0394","r"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},"mo":"."}}],"mo":"+"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"11"}}]}}}}},"The first term is the dose contribution to Vfrom the voxels previous to Valong the transport line, which attenuates exponentially along the line. The second term is the dose contribution from voxel Vto itself, where T is the TERMA and \u03a9, is the solid angle of the cone. Similarly, the scattering dose for the voxel can be calculated as shown in Equation 12.",{"@attributes":{"id":"p-0105","num":"0104"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msubsup":{"mi":["D","mn","s"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["r","i"]}}},{"mrow":[{"mrow":{"msubsup":{"mi":["D","mn","s"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"r","mrow":{"mi":"i","mo":"-","mn":"1"}}}},"mo":["\u2062","\u2062"],"msub":{"mi":["b","m"]},"msup":{"mi":"\u2147","mrow":{"mrow":{"mo":"-","msub":{"mi":["b","m"]}},"mo":["\u2062","\u2062","\u2062"],"mi":["\u03b7\u0394","r"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},{"mi":"T","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u03a9","mn"]},"mfrac":{"msub":[{"mi":["B","m"]},{"mi":["b","m"]}]},"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msup":{"mi":"\u2147","mrow":{"mrow":{"mo":"-","msub":{"mi":["b","m"]}},"mo":["\u2062","\u2062","\u2062"],"mi":["\u03b7\u0394","r"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},"mo":"."}}],"mo":"+"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"12"}}]}}}}},"One or more FPGAs may be used for implementation of radiation dose calculation in hardware. An FPGA is a FPD (Field Programmable Device) featuring a general structure that allows very high logic capacity. Unlike CPLDs (Complex Programmable Logic Devices), which offer a wide number of functional inputs, FPGAs typically offer narrower logic resources. In addition, FPGAs typically possess many more flip-flops than do CPLDs.","FPGAs usually possess logic blocks surrounded by interconnect resources. These logic blocks may be configured to perform different functions by the end user through programming A typical FPGA structure is shown in . In the illustrated example of , logic blocks  are arranged so that they are bordered by interconnect resources . Pin inputs and outputs  are arranged along the outside of the chip. Additionally,  illustrates an example of a XILINIX\u00ae CLB (Configurable Logic Block). In the illustrated example of , the CLE is implemented with lookup tables . In general a k-input logic function may be realized with a 2\u00d71 bit lookup table by programming a truth table into the memory. The configuration of the XILINIX\u00ae CLBs allow for a single nine-input function, two separate four-input functions, or other possibilities. In this way, the CLBs are very flexible and adaptable to a wide variety of applications.","In addition to simple logic blocks, many modern FPGAs also incorporate embedded memory and embedded arithmetic units. For example, Altera FPGAs contain embedded (Tri-Matrix) memory in varying amounts on different chips along with embedded arithmetic units (Digital Signal Processing Blocks). The structure of an example STRATIX II\u00ae device 1100 manufactured by Altera showing these embedded memories and arithmetic blocks can be seen in .","Until recent years, FPGAs were not considered viable candidates for floating point arithmetic because such floating point operations typically require excessive time and area (silicon) to implement. However, through recent advances in technology (e.g., embedded memory, increased logic density, or the addition of embedded arithmetic blocks), significant increases now exist in the ability of the FPGA to compete with the microprocessor in terms of floating point performance.","Previously, FPGAs were considered alternative candidates to the CPU only if a fixed point algorithm or an algorithm using only a small dynamic range were used. However, starting in 1995, people began to believe that FPGAs could compete in the floating point domain. Various developments resulted including, but not limited to, floating point adders, subtracters, multipliers, and dividers using 16 and\/or 18 bit floating point formats. The introduction of high level languages such as VHDL, along with advancements in technology helped make feasible the implementation of these floating point operations on FPGAs.","Persons having ordinary skill in the art will appreciate that floating point calculation is typically more efficient than fixed point calculations when the dynamic range of the numbers used are large. Libraries typically offer the user the ability to customize their design to a particular floating point format.","Many such libraries offer compliance with an IEEE-754 standard for floating point arithmetic, while at the same time allowing the user the flexibility to break that compliance when unnecessary. For example, a large number of logic elements are typically needed to implement certain features of the IEEE-754 standard. These features include gradual underflow (especially in a multiplier), overflow protection, and the use of different rounding modes. If these functions are not needed, as gained by knowledge of the input operations or processing flow, then they can be excluded from the implementation of floating point units, thus decreasing both latency and area.","In the future FPGAs may be more efficient, in terms of peak MFLOPS (Millions of Floating Point Operations Per Second), than CPUs in performing all types of floating point operations and that currently they are capable of performing more MFLOPS than CPUs at most floating point operations. Currently, FPGAs usually beat out CPUs in performing the floating point operations of addition\/subtraction, division, and multiplication. However, some FPGAs lag behind in the DSP operation of multiply-accumulate. According to Moore's law, there is a 2\u00d7 increase in the density of logic every two years and a 2\u00d7 increase in the clock rate every two years, leading one to expect a 1\u00d7 increase in performance for FPGAs. This is higher than the 4\u00d7 increase in CPU performance every three years. Also, things such as embedded 18\u00d718 multipliers on some chips have enabled substantial gains in floating point multiplication. Floating point multiplication in FPGAs in terms of peak MFLOPS has been growing at the rate of 5\u00d7 per year over the past six years.","FPGAs are able to implement some algorithms substantially faster than CPUs. They allow the user to perform several operations in parallel and hence speed up the computation. However, this is not the only reason that FPGAs are faster than CPUs. While it is true that FPGAs obtain performance increases due to extraction of parallelism from algorithms, it should also be noted that FPGAs typically run at much slower clock speeds than CPUs. A typical speed for an FPGA is from 30-100 MHz, and embedded processors run between approximately 100-600 MHz. Even after accounting for the frequency differences, the speedup of FPGAs over CPUs was still one to two orders of magnitude.","FPGAs offer advantages over CPUs in the areas of iteration parallelism, the number of necessary operations, efficiency, and number of memory operations. Iteration parallelism refers to the fact that an FPGA could execute many iterations of a loop at once provided there are no loop carry dependencies. FPGAs also decrease the number of necessary operations. Operations such as a shift or a multiply by a power or two are accomplished without the use of a clock cycle on an FPGA. The efficiency advantage is gained since there are no support instructions that need to be executed.","The reduction in memory operations may come from the large number of embedded registers and on-chip memory that allow the FPGA to avoid continuous reads from slower off-chip memory that may need to be performed in a CPU. FPGAs allow the user to configure on-chip storage at will and customize it for each loop. In particular, this storage can be used to efficiently reduce the number of memory accessing by reusing data, which results in an 8-14\u00d7 reduction in memory use.","During development and testing of the methods and apparatus described herein, three different image processing applications were evaluated: Prewitt edge detection, wavelet transform, and maximum filter. For the three applications, the use of an FPGA resulted in speedups of 312 times (Prewitt), 210 times (wavelet transform), and 226 times (maximum filter) over a PENTIUM\u00ae processor performing the applications. Accordingly, even though FPGAs have a much slower clock speed than a CPU, they are much more efficient at performing arithmetic operations. As such, persons having ordinary skill in the art will appreciate that the methods and apparatus described herein may have applications beyond dose calculation algorithms. While creating radiation dose calculation is described herein as one objective, the methods and apparatus described herein may be applied, without limitation, to many other objectives. For example, other such processing objectives may include image processing.","Direct convolution may be applicable in situations involving homogeneous media. While these conditions do not necessarily occur often in practice, it is useful to have a fast convolution model that is capable of handling these situations when they do occur. For situations involving inhomogeneous media, the collapse cone algorithm may be used, as described in further detail below.","In the convolution algorithm(s) described herein, the parallelism inherent in convolution may be exploited. These solutions can also take advantage of future improvements in hardware, employ variations of the algorithms described herein, and may be easily ported to alternate FPGAs, as needed. Here, large decreases in convolution time have been achieved when compared with a typical single processor computer system. As described in further detail below, dose calculations based on FPGA hardware implementations allow calculation speed improvements in view of direct convolution\/superposition methods, collapsed cone methods from an interaction point of view, and\/or collapsed cone methods from a deposition point of view.","A three-dimensional (3-D) convolution system is described herein and configured as an SoPC that may include various elements to make up the entire system. Additionally, a two level parallel structure is described in further detail below. Persons having ordinary skill in the art will appreciate that either of these systems may be employed to calculate radiation dose, depending on, for example, particular hardware availability and\/or capability.","As shown in , some of the elements of the example 3-D convolution system include an embedded soft-core processor , embedded memories , a register file , an AVALON\u00ae interface  (which is a proprietary high-bandwidth interconnect structure from Altera), and a convolver .  also illustrates a general overview of the system and shows the connections between the different components.","In the illustrated example of , the embedded soft-core processor  is implemented as a NIOS II\u00ae soft-core processor, which serves as a bridge between the convolver  and external memory , as well as a bridge between the convolver  and any external off-chip communication. Accesses to off-chip memory (e.g., SDRAM, SRAM, etc.) and the use of input or output pins (such as use of the Ethernet interface on the development board) may be controlled by the NIOS II\u00ae processor. The NIOS II\u00ae processor also controls which embedded memory the convolver can access along with when the convolver begins its computation.","The convolver  is a block which computes a single two-dimensional (2-D) convolution. Accordingly, the convolver  utilizes data in one of the embedded memories  and information contained within the register file to complete this convolution. Communication with the NIOS II\u00ae processor  may be handled by, for example, the AVALON\u00ae interface , as described in further detail below. The register file  simply contains a bank of registers that are used to communicate information either to or from the convolver .","The embedded memories  in the convolution system may store a single plane of the convolution matrix, the kernel matrix, and the result matrix. In view of the possibility that the size for each 3-D matrix can reach 100\u00d7100\u00d7100, the embedded memories  need to be able to store three matrices of size 100\u00d7100 each. In the illustrated example of , the current maximum number of bits that can be used to represent a result in any of the memories  is 32. As shown below, Equation 13 can be used to calculate the size of one of the two on-chip memories  illustrated in the example SoPC of .",{"@attributes":{"id":"p-0125","num":"0124"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":"\u2003","mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mi":["Memory_Size",{}],"mo":["=","\u2062"],"mrow":{"mi":["Number_Of","_Matrices"],"mo":["\u2062","*"]}}}},{"mtd":{"mrow":{"mi":{},"mo":"\u2062","mrow":{"mi":["Size_Of","_Matrices"],"mo":["\u2062","*"]}}}},{"mtd":{"mrow":{"mi":{},"mo":"\u2062","mrow":{"mi":["Number_Of","_Bits"],"mo":"\u2062"}}}},{"mtd":{"mrow":{"mo":["=","\u2062"],"mi":{},"mrow":{"mn":["3","32"],"mo":["*","*"],"mrow":{"mo":["(",")"],"mrow":{"mn":["100","100"],"mo":"\u00d7"}}}}}},{"mtd":{"mrow":{"mrow":[{"mo":["=","\u2062"],"mi":{},"mn":"960"},{"mn":"000","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":"bits","mo":"."}}],"mo":","}}}]}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"13"}}]}}}}}},"As can be seen in , there are two example embedded memories  present in the example convolver system that are used in a manner similar to that of a double buffer. At any given time, only one of the memories  can be accessed by the NIOS II\u00ae processor , while the other memory is used by the convolver . The task of the system is to record the results of the previous convolution and fill the memory  with the necessary data to compute the next convolution. The convolver  uses registers  to identify starting locations of the convolution, kernel, and result matrices. These registers  may be used to determine where to load and store data in the embedded memory to perform a 2-D convolution.","The example embedded memories  used in the convolution may be constructed using the Altera altsyncram megafunction, which implements a parameterized true dual-port RAM using embedded memory blocks on the example FPGA. Parameters and their values that differ from the defaults are listed in Table 1. On-chip memory may be used due to its lower latency compared to off-chip memory.",{"@attributes":{"id":"p-0128","num":"0127"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Description of the Parameters Used for the ALTSYNCRAM"},{"entry":"Megafunction"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Parameter","Description","Value"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["NUMWORDS_A","Number of words stored in memory","30,000"]},{"entry":["NUMWORDS_B","Number of words stored in memory","30,000"]},{"entry":["WIDTH _A","Specifies the width of the data_a[ ]","32"]},{"entry":[{},"input port",{}]},{"entry":["WIDTH _B","Specifies the width of the data_b[ ]","32"]},{"entry":[{},"input port",{}]},{"entry":["WIDTHAD_A","Specifies the width of the address_a[ ]","15"]},{"entry":[{},"input port",{}]},{"entry":["WIDTHAD_B","Specifies the width of the address_b[ ]","15"]},{"entry":[{},"input port"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"Based on the size of the example embedded memories, 3 clock cycles are consumed to access a particular location. Such accesses are pipelined, so the latency of the access is 3 cycles\/word, while the throughput is 1 cycle\/word given the example current cycle speed of 20 ns (50 MHz). As the access pattern of the memory is known in advance and due to the nature of the convolution, the latency of the memory may be completely shadowed.","In the illustrated example, the embedded memories  are controlled through the register file  and the example NIOS II\u00ae processor . The processor  sends a command to the register file  instructing it as to which embedded memory  the processor  will control and which embedded memory  the convolver  will control.","The operation of convolution typically has regular memory access patterns. It can also be memory bandwidth intensive if not utilized correctly. As discussed in further detail below, it is first determined if placement of an entire 2-D convolver will work with the example FPGA. Second, the situation is examined by which only a single 1-D convolver may be accommodated by the FPGA.","Initially, it is assumed that an entire 2-D convolver may fit on the FPGA chip. The ability to do this is typically dependent on the logic elements available on-chip rather than the memory. Additionally, it is assumed that the logic elements are available and simply look at the memory required to overshadow memory access latency with computation. If the example convolution matrix is of size k\u00d7i\u00d7j and the example kernel is of size t\u00d7r\u00d7s, then the maximum size for each of these matrices are 100\u00d7100\u00d7150. Given those sizes, and the sizes of some on-chip memories in FPGAs, it may not be possible to place the entire matrix on-chip. For example, some FPGA chips currently possess around a maximum of 9 Mb of on-chip memory. Assuming that each reference is 32 bits, a single matrix would consume approximately 45.8 Mb, which is a factor of 5 larger than the amount of memory currently available on some of the largest FPGA chips to date.","The on-chip memory needed to perform a 2-D convolution may be much less than that required for the entire matrix. Adequate memory may be needed to create shift registers, and to store one plane of the kernel matrix, the convolution matrix, and the result matrix. The number of bits for each type of matrix, and the amount of memory needed for each of the above is presented in Table 2.",{"@attributes":{"id":"p-0134","num":"0133"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Representation of Bits Required for Different Convolution Matrices"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Matrix Name","Number of Bits"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"kernel","kernel_bits"]},{"entry":[{},"matrix","matrix_bits"]},{"entry":[{},"result","result_bits"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},{"@attributes":{"id":"p-0135","num":"0134"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 3"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Amount of On-Chip Memory Required to Perform One Plane of"},{"entry":"Convolution"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Memory Use","Amount Required"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"right"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"133pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"1","plane of kernel","s * r * kernel_bits"]},{"entry":[{},"1","plane of matrix","i * j * matrix_bits"]},{"entry":[{},"1","plane of result","i * j * res_bits"]},{"entry":[{},{},"shift registers","(s \u2212 1)*(i \u2212 r + 2 * [r\/2])*res_bits"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}]}}},"Memory reuse occurs because it is typically not possible to fit the entire 3-D convolution onto the FPGA chip. However, any such limitations of the state of the art of FPGAs are not to be construed as a limitation to the methods and apparatus described herein. Each matrix plane is reused O(k) times throughout this example convolution. However, the amount of memory accessed between each reuse is O(k*i*j*matrix_bits) bits. For example, if matrix_bits is 32, this amount of memory may be too great to be placed on-chip for some FPGAs.","Although some FPGAs may not accommodate adequate on-chip memory for the next plane, it is possible to utilize other memory to prepare the next plane for the convolution function. In the illustrated example, every convolution result takes O() clock cycles to compute, and two cycles are used to compute each convolution result. While this might change to one or three or more clock cycles were the implementation changed, it would still require a constant number of cycles to compute the convolution and return a result. Therefore, awareness is maintained to track the number of convolution results that must be obtained before a new plane is needed.","A new plane of the result and matrix matrices is needed after every i*j convolution results. That means that after O(i*j) clock cycles there is a transfer of approximately 2*I*j*(matrix_bits+results_bits) memory bits. In view of the speed of memory devices placed on some FPGA boards, this may be difficult to achieve.","Continuing with the example constraint that an FPGA cannot fit an entire 2-D convolution on-chip, the 1-D convolver approach is described further. With this method, there are no shift registers needed. The memory required for data that needs to be placed in memory is shown below in Table 4. As shown below, only one row of the kernel, one row of the matrix, and one row of the result is needed.",{"@attributes":{"id":"p-0140","num":"0139"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 4"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Amount of On-Chip Memory Required to Perform One Row of"},{"entry":"Convolution"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Memory Use","Amount Required"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"right"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"112pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"1","row of kernel","r * kernel_bits"]},{"entry":[{},"1","row of matrix","I * matrix_bits"]},{"entry":[{},"1","row of result","i * result_bits"]},{"entry":[{},{},"shift registers","none required"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}]}}},"In the illustrated example, convolution can be performed only on one row at a time, thus each row of the matrix and kernel is now reused more times. Each matrix and result row is used O(j*k) times. Each kernel row is used O(k) times. In the illustrated example, the number of convolution elements that must be computed between each reuse of matrix and result is now only O(i*j). Therefore, to experience the benefits of data reuse, at least one plane of result and matrix must be stored on-chip. If this amount of memory cannot be fit on an example chip, then the data would have to be reloaded every time. Assuming that an entire plane of matrix and result can be stored on-chip, then each row may be reused O(j) times.",{"@attributes":{"id":"p-0142","num":"0141"},"figref":["FIG. 13","FIG. 13"],"b":"1302"},"A new row of the result and matrix matrices is needed after every i convolution results. As such, after O(i) clock cycles, there is a transfer of approximately 2*i*(matrix_bits+results_bits) memory bits. This is essentially a linear decrease from the amount of time required in the 2-D convolver case described above. This means that if the memory bandwidth is capable of handling the above case, then it should also be able to handle this case.","The register file contains the registers needed to control the convolver. In the illustrated example, there are a total of 9 different registers that ensure correct functioning of the convolver. The names and purpose of each register are shown below in Table 5, and referring once again to , it can be seen how the register file fits into the overall convolver system.",{"@attributes":{"id":"p-0145","num":"0144"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 5"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Description of the Registers Used in the Convolution System"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Register Name","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["conv_start","Signals the convolver to start"]},{"entry":["cony_finished","Indicates whether the convolver is finished"]},{"entry":["matrix_start","Starting address of the convolution matrix"]},{"entry":["kernel_start","Starting address of the kernel matrix"]},{"entry":["result_start","Starting address of the results matrix"]},{"entry":["conv_height","Number of rows for the next convolution"]},{"entry":["conv_width","Number of columns for the next convolution"]},{"entry":["kernel_height","Number of kernel rows for the next convolution"]},{"entry":["kernel_width","Number of kernel columns for the next convolution"]},{"entry":["mem_select","Controls the connection of the embedded memories"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"Table 6, shown below, defines parameters used in describing the width and acceptable value of the registers. In Table 7, more information about the different registers is shown, including width and acceptable input values. The column labeled \u2018Accepted Values\u2019 lists all accepted values for the register, or presents an integer range of acceptable values.",{"@attributes":{"id":"p-0147","num":"0146"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 6"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Parameters Describing the Function of the Register File"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"119pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Parameter Name","Value"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Width_Address","15"]},{"entry":[{},"Max_Conv_Height","25"]},{"entry":[{},"Max_Conv_Width","25"]},{"entry":[{},"Max_Kernel_Height","25"]},{"entry":[{},"Max_Kernel_Width","25"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},{"@attributes":{"id":"p-0148","num":"0147"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 7"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Values of Different Parameters for Each Register"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Register Name","Width (bits)","Accepted Values"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["conv_start","1","0,1"]},{"entry":["conv_finished","1","0,1"]},{"entry":["matrix_start","Width_Address","{0..30,000}"]},{"entry":["kernel_start","Width_Address","{matrix_start..30,000}"]},{"entry":["result_start","Width_Address","{kernel_start..30,000}"]},{"entry":["conv_height","log Max_Conv_Height","{0..Max_Conv_Height}"]},{"entry":["conv_width","log Max_Conv_Width","{0..Max_Conv_Width}"]},{"entry":["kernel_height","log Max_Kernel_Height","{0..Max_Kernel_Height}"]},{"entry":["kernel_width","log Max_Kernel_Width","{0..Max_Kernel_Width}"]},{"entry":["mem_select","2","00,01"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"The NIOS II\u00ae processor is able to read and write to all of the registers in the design, with the exception of conv_finished, from which it may only read. The convolver may read all registers, but only affect the value of the convolution_finished register. In this manner, the convolver is able to signal to the processor that it is finished, and the processor is able to communicate all necessary information to the convolver.","The approach to 3-D convolution described herein involves the repeated use of a single 1-D convolver. The 1-D convolver may be first used to compute a 2-D convolution. A number of 2-D convolutions may then be repeated to complete the entire 3-D convolution.  presents a picture of an example implementation for a 1-D convolver employed to compute 2-D and 3-D convolutions. In the illustrated example of , n represents the width of the convolution matrix. For a matrix of size m\u00d7n, there would be n individual convolution elements that would be used to compute the 2-D convolution. The algorithm for implementing a 1-D convolution can be seen in the algorithm presented in . Note that many of the operations in the algorithm may be performed in parallel and, in the hardware implementation of the algorithm, are performed in parallel. To give a clear presentation of the general idea, the steps are described sequentially below.","In addition to being able to calculate many different convolution results in parallel, the convolver is very efficient in terms of memory bandwidth. The convolver requires only one new matrix element every clock cycle, thus memory access latency can be completely masked by computation. Persons having ordinary skill in the art will appreciate that memory bandwidth, rather than computation power, are typically the bottlenecks encountered with convolvers.",{"@attributes":{"id":"p-0152","num":"0151"},"figref":["FIG. 16","FIG. 17"]},{"@attributes":{"id":"p-0153","num":"0152"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["num_","d"],"mo":["\u2062","\u2062"],"mn":"2"},{"mo":"\u2003","mrow":{"mn":"2","mo":"*","mrow":{"mo":"(","mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mn":"1","mo":["+","+"],"mrow":[{"mrow":[{"mo":["\u230a","\u230b"],"mfrac":{"mi":"n","mn":"2"}},{"mo":["\u2308","\u2309"],"mfrac":{"mi":"n","mn":"2"}}],"mo":"*"},{"mfrac":{"mrow":{"mo":["\u230a","\u230b"],"mfrac":{"mi":"n","mn":"2"}},"mn":"2"},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["\u230a","\u230b"],"mfrac":{"mi":"n","mn":"2"}},"mo":"+","mn":"1"}}}]}},{"mrow":{"mi":"n","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"N","mo":"-","mrow":{"mn":"2","mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["\u230a","\u230b"],"mfrac":{"mi":"n","mn":"2"}},"mo":"+","mn":"1"}}}}}},"mo":"."}],"mo":"+"}}}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"14"}}]}}}}},"In Equation 14, n is used to represent kernel_depth, or the number of planes present in the convolution kernel, and N is used to represent convolution_depth, or the number of planes present in the convolution matrix.","A more detailed version of  is presented as . This figure provides additional information relating to example signals used and gives a more specific view of the implementation of the entire system.","As mentioned earlier, the kernel used in an implementation using collapsed cone techniques is an exponentially calculated kernel. Along with the kernel, calculation of radiation dose may be realized when given an initial TERMA matrix in Cartesian coordinates. The exponentially calculated kernel is composed of at least two different components. One component calculates the primary energy (which has a rather sharp falloff as distance from the interaction point increases) and the other component calculates the scatter energy (which does not have near as sharp a drop-off as the primary energy). Equations to calculate the primary energy are shown below in Equations 15 and 16, and the equation to calculate the scatter energy is shown below as Equation 17.",{"@attributes":{"id":"p-0157","num":"0156"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"\u0394","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msubsup":{"mi":["R","mn","p"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["r","i"]}}}},{"mrow":[{"msub":[{"mi":["T","i"]},{"mi":["\u03c1","i"]},{"mi":["\u03a9","mn"]}],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"msup":{"mi":"d","mn":"2"},"mi":"u","mrow":{"msubsup":{"mo":"\u222b","mrow":{"msub":{"mi":["r","i"]},"mo":"-","mn":"1"},"msub":{"mi":["r","i"]}},"mo":"\u2062","mrow":{"mfrac":{"msub":[{"mi":["A","m"]},{"mi":["a","m"]}]},"mo":["\u2062","\u2062","\u2062"],"msup":{"mi":"\u2147","mrow":{"mrow":[{"mo":"-","msub":{"mi":["a","m"]}},{"msub":{"mi":["\u03b7","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["r","i"]},"mo":"-","mi":"s"}}}],"mo":"\u2062"}},"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}},"mrow":{"mo":"\u2146","mi":"s"}}}},{"msub":[{"mi":["T","i"]},{"mi":["\u03c1","i"]},{"mi":["\u03a9","mn"]}],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"msup":{"mi":"d","mn":"2"},"mi":"u","mfrac":{"msub":{"mi":["A","m"]},"mrow":{"msub":{"mi":["\u03b7","i"]},"mo":"\u2062","msubsup":{"mi":["a","m"],"mn":"2"}}},"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msup":{"mi":"\u2147","mrow":{"msub":[{"mi":["a","m"]},{"mi":["\u03b7","i"]}],"mo":["\u2062","\u2062","\u2062","\u2062"],"mi":["\u0394","r"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},"mo":"."}}],"mo":"="}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"15"}}]}}}},"br":{},"in-line-formulae":[{},{}],"i":["R","r","R","r","e","+\u0394R","r"],"sub":["mn","i","mn","i-1","mn","i"],"sup":["p","p","\u2212a",{"sub2":"m"},"\u03b7",{"sub2":"i"},"\u0394r","p"]},{"@attributes":{"id":"p-0158","num":"0157"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msubsup":{"mi":["R","mn","s"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["r","i"]}}},{"mrow":[{"mrow":[{"msubsup":{"mi":["R","mn","s"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"r","mrow":{"mi":"i","mo":"-","mn":"1"}}}},{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mrow":{"msub":[{"mi":["b","m"]},{"mi":["\u03b7","i"]}],"mo":["\u2062","\u2062","\u2062","\u2062"],"mi":["\u0394","r"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":"\u2062"},{"msub":[{"mi":["T","i"]},{"mi":["\u03c1","i"]},{"mi":["\u03a9","mn"]}],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"msup":{"mi":"d","mn":"2"},"mi":["u","\u0394"],"mfrac":{"msub":[{"mi":["B","n"]},{"mi":["b","m"]}]},"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"r","mo":"."}}],"mo":"+"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"17"}}]}}}}},"In the above equations, T represents the TERMA, \u03c1represents the mass density, and \u03b7represents the relative electron volume density of the segment i. Also, mn represents the current cone being calculated, and du represents a volume associated with the receiving voxel element. Equation 15 calculates the amount of primary energy released from the segment i, where r goes from rto r, into the cone of solid angle \u03a9. Equation 16 represents the radiant primary energy through all segments on a line. Equation 17 is used to calculate the scatter energy. It does not explicitly require the exponentials because the scatter energy is only a small fraction of the total energy, hence the scatter energy can be approximated by the first two terms of the serial expansion. These equations serve to determine the amount of energy deposited in different voxels, which can then be used in calculating the final dose shown in Equation 18 below.",{"@attributes":{"id":"p-0160","num":"0159"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}},{"mfrac":[{"mrow":[{"mi":"\u03b7","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}},{"mi":"\u03c1","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}}]},{"mn":"1","mrow":{"msup":{"mi":"d","mn":"2"},"mo":"\u2062","mi":"u"}}],"mo":["\u2062","\u2062"],"mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"mrow":{"mo":["[","]"],"mrow":{"mrow":[{"msub":{"mi":["a","m"]},"mo":"\u2062","mrow":{"msubsup":{"mi":["R","mn","p"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}}},{"msub":{"mi":["b","m"]},"mo":"\u2062","mrow":{"msubsup":{"mi":["R","mn","s"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}}}],"mo":"+"}},"mo":"."}}}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"18"}}]}}}}},"In Equation 18, \u03b7(r) is divided by \u03c1(r) to convert energy per voxel into dose per voxel. These equations allow computation of the dose in a phantom, provided values are given for the TERMA, the mass density, and the relative electron volume density. Suitable values for A, a, B, and are assumed to be available, and the value of \u03a9may be calculated using Equation 19, shown below.",{"@attributes":{"id":"p-0162","num":"0161"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["\u03a9","mn"]},"mo":"=","mrow":{"mfrac":{"mrow":[{"mn":"4","mo":"*","mi":"\u03c0"},{"mi":"max","mo":"\u2062","mrow":{"mo":["{","}"],"mi":"mn"}}]},"mo":"."}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"19"}}]}}}}},"In Equation 19, the 4\u03c0 radians of the solid sphere are divided by the number of cones used. These equations serve to compute the dose, but may not be the best method for implementation in an FPGA. They involve a lattice of parallel lines which must be computed and laid out. Generally speaking, if there are 48 cones emanating from each dose calculation point (\u0394\u03b8=3.75\u00b0, \u0394\u03a6=360\u00b0), then 48 different lattices would need to be constructed such that, for each lattice, no voxel was crossed by more than one line for that lattice. Additionally, for each line in the lattice, starting at the point where that line intersects with a voxel in the region of interest, Equations 15, 16, and 17 would be run. When these equations finished, the final dose could be calculated using Equation 18. Persons having ordinary skill in the art will appreciate that this lattice computation introduces additional calculations and hardware into the dose calculation phase, and use of the lattice does not allow for easy use of dose correction factors.","One of the correction factors this method does not easily allow for is kernel tilting, which allows for the computation kernel to be tilted in various ways to allow more accurate dose calculation(s). The calculation method described herein differs from that requiring the parallel lattice of lines described above. This is done for at least two different reasons. One main reason is that by using the lattice of lines, it is typically difficult to implement dose correction factors that would be required for a clinical implementation. Another reason is that Equations 15 and 16 require a constant \u0394r to be used if accurate results are expected.","With the example interaction point of view implementation described herein, the cones are extended from each voxel with a nonzero TERMA value. TERMA indicates the energy released, and the kernel describes how that energy is dissipated from the interaction site. Therefore, if a voxel contains no TERMA, then there is no reason to ray-trace from it as there will be no energy deposited.  illustrates an example algorithm to describe how the primary energy distribution may be calculated. With the example algorithm of , there are more variables that must be tracked throughout the calculation. However, it enables a much more flexible implementation than Equations 15 and 16. In the illustrated example of , kernel tilting may be implemented by providing different Aand a, values. Persons having ordinary skill in the art will appreciate that similar methods may be used to handle kernel hardening and other dose correction factors.","As described above, Equations 15 and 16 require a constant \u0394r. Assuming T, \u03c1, \u03a9, \u03b7, A, and aremain constant for each of these examples, then only \u0394r may change. For example, assume that the original \u0394ris large (e.g., \u0394r>>1) and the second \u0394ris small (e.g., \u0394r<<1). As a result, the (1\u2212e) factor in Equation 15 is essentially (1\u2212e\u2212\u0394r) or \u22481. Accordingly, the initial \u0394Rused to calculate Rwould be very large as most of the energy would have been deposited within the cone. The exponential factor in Equation 16 is meant as an attenuation factor, thus if \u0394ris small, such that the exponential factor is \u22481, then nearly the same amount of energy will be deposited in the region of \u0394ras was deposited in \u0394r, which is not sensible.","In another example, assume that \u0394ris small and \u0394ris large. In this case, almost the opposite effect occurs. Very little energy is released into the cone at \u0394ras the exponential is \u22480, and then that small value is further attenuated for the large region when \u0394ris used. Conceptually, a large amount of energy should be deposited in the region of \u0394r, however this is not true due to the use of different \u0394r's.","However, by using 2 \u0394r's, \u0394rand \u0394rwhere \u0394r=\u0394r, the equations will yield consistent results. That is, the same amount of energy will be deposited by Equations 15 and 16 as would be deposited by Equation 15 assuming that a \u0394rwas used where \u0394r=\u0394r+\u0394r.  illustrates a graph showing the processing of this function. The example graph of  shows initial inputs along with various steps required to produce an output. The function is fully pipelined and capable of producing a result every clock cycle after an initial period of latency.","Equation 17 was modified also to be equivalent to that of the algorithm presented in . The reason that Equation 17 was simpler than Equations 15 and 16 was due to the fact that scatter dose has less impact on the total dose than does the primary dose. However, in the case of dedicated hardware, because it is fully pipelined, it requires the same amount of time to compute the scatter dose using the complex or the simple method. Additionally, the more complex example method illustrated in the algorithm of  yields more accurate results than a potentially simpler implementation.","The calculations used in this collapse cone method require a \u0394r value as shown in the algorithm presented in . This \u0394r value is the length of the physical path that a ray travels through a particular voxel. The \u0394r value may then be used to determine a radiological path length. Persons having ordinary skill in the art will appreciate that it is important to accurately calculate this physical path length, which is accomplished by the example methods and equations described below.","Ray-tracing includes determining the distance a line travels between a starting point and its first intersection with a voxel wall boundary. That is, given a starting point {right arrow over (position)} and direction vector {right arrow over (direction)}, a line l is created originating at {right arrow over (position)} and traveling to infinity in the direction described by {right arrow over (direction)}. Next, a determination is made as to which voxel wall boundary has been crossed first by 1. Calling this intersection point {right arrow over (INTERSECTION)}, it is then a simple calculation to determine the distance between the originating point {right arrow over (position)} and the intersection point {right arrow over (INTERSECTION)}. Discussed in further detail below are example equations used in this ray-tracing calculation, and a description of its pipelined implementation in hardware.","To calculate a path length, there must be some values which are available at the beginning of the calculation. The following include some required values and provide a description of the function each example value serves. {right arrow over (voxel_size)}, for example, describes the size of each voxel in the x, y, and z directions. Additionally, the value offset describes the x, y, and z offsets of voxel numbers. {right arrow over (position)} describes a vector representing the current position of the interaction site, and {right arrow over (direction)} describes a vector representing the direction the photon was traveling.","At least one of the initial values is {right arrow over (position)}, thus if the point of intersection with a voxel wall boundary can be calculated, then it is a simple task to compute distance. Determining the current voxel in which the ray is positioned may be accomplished by using the initial position and the knowledge that the center top point of the matrix has a location of (0, 0, 0). Equations 20, 21, and 22 present example calculations for this step.",{"@attributes":{"id":"p-0174","num":"0173"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mo":"\u2003","mrow":{"mi":"voxels_x","mo":"=","mrow":{"mo":"{","mrow":{"mfrac":{"mrow":[{"mfrac":{"mrow":[{"mi":["postion","x"],"mo":"."},{"mi":["voxel_size","x"],"mo":"."}]},"mo":"-","mrow":{"mn":["1","2"],"mo":"\/"}},{"mfrac":{"mrow":[{"mi":["position","x"],"mo":"."},{"mi":["voxel_size","x"],"mo":"."}]},"mo":"+","mrow":{"mn":["1","2"],"mo":"\/"}}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mi":"if","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":["position","x"],"mo":"."}},"mo":"\u2265","mn":"0"}}},{"mtd":{"mi":"otherwise"}}]},"mo":"."}}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"20"}}]},{"mtd":[{"mrow":{"mo":"\u2003","mrow":{"mi":"voxels_y","mo":"=","mrow":{"mo":"{","mrow":{"mfrac":{"mrow":[{"mfrac":{"mrow":[{"mi":["postion","y"],"mo":"."},{"mi":["voxel_size","y"],"mo":"."}]},"mo":"-","mrow":{"mn":["1","2"],"mo":"\/"}},{"mfrac":{"mrow":[{"mi":["position","y"],"mo":"."},{"mi":["voxel_size","y"],"mo":"."}]},"mo":"+","mrow":{"mn":["1","2"],"mo":"\/"}}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mi":"if","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":["position","y"],"mo":"."}},"mo":"\u2265","mn":"0"}}},{"mtd":{"mi":"otherwise"}}]},"mo":"."}}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"21"}}]},{"mtd":[{"mrow":{"mi":"voxels_z","mo":"=","mrow":{"mfrac":{"mrow":[{"mi":["postion","z"],"mo":"."},{"mi":["voxel_size","z"],"mo":"."}]},"mo":"."}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"22"}}]}]}}}},"The current voxel may be taken to be [voxels_x+offset_x, voxels_y+offset_y, voxels_z+offset_z]. After determining the current voxel location, the locations of the boundary walls for this voxel are determined. Even though there are six boundary walls, only three of them are of particular interest due to x, y, and z having either a positive or negative direction. Example calculations used to determine the boundary planes are shown below as Equations 23a, 23b, 24a, 24b, 25a, and 25b.",{"@attributes":{"id":"p-0176","num":"0175"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mo":"\u2003","mrow":{"msub":{"mi":"x","mn":"0"},"mo":"=","mrow":{"mo":"{","mrow":{"mtable":{"mtr":[{"mtd":{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"voxels_x","mo":"*","mrow":{"mi":["voxel_size","x"],"mo":"."}},"mo":"+","mfrac":{"mrow":{"mi":["voxel_size","x"],"mo":"."},"mn":"2"}}}}},{"mtd":{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"voxels_x","mo":"*","mrow":{"mi":["voxel_size","x"],"mo":"."}},"mo":"+","mfrac":{"mrow":{"mi":["voxel_size","x"],"mo":"."},"mn":"2"}}}}}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mi":"if","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":["direction","x"],"mo":"."}},"mo":"\u2265","mn":"0"}}},{"mtd":{"mi":"otherwise"}}]},"mo":"."}}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"23"}}]}}}}},{"@attributes":{"id":"p-0177","num":"0176"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mtable":[{"mtr":{"mtd":[{"mrow":{"mo":"\u2003","mrow":{"msub":{"mi":"y","mn":"0"},"mo":"=","mrow":{"mo":"{","mrow":{"mtable":{"mtr":[{"mtd":{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"voxels_y","mo":"*","mrow":{"mi":["voxel_size","y"],"mo":"."}},"mo":"+","mfrac":{"mrow":{"mi":["voxel_size","y"],"mo":"."},"mn":"2"}}}}},{"mtd":{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"voxels_y","mo":"*","mrow":{"mi":["voxel_size","y"],"mo":"."}},"mo":"+","mfrac":{"mrow":{"mi":["voxel_size","y"],"mo":"."},"mn":"2"}}}}}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mi":"if","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":["direction","y"],"mo":"."}},"mo":"\u2265","mn":"0"}}},{"mtd":{"mi":"otherwise"}}]},"mo":"."}}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"24"}}]}},{"mtr":{"mtd":[{"mrow":{"mo":"\u2003","mrow":{"msub":{"mi":"z","mn":"0"},"mo":"=","mrow":{"mo":"{","mrow":{"mtable":{"mtr":[{"mtd":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"voxels_z","mo":"*","mrow":{"mi":["voxel_size","z"],"mo":"."}},{"mi":["voxel_size","z"],"mo":"."}],"mo":"+"}}}},{"mtd":{"mrow":{"mo":["(",")"],"mrow":{"mi":"voxels_z","mo":"*","mrow":{"mi":["voxel_size","z"],"mo":"."}}}}}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mi":"if","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":["direction","z"],"mo":"."}},"mo":"\u2265","mn":"0"}}},{"mtd":{"mi":"otherwise"}}]},"mo":"."}}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"25"}}]}}],"mo":"\u2062"}}}},"Examination of the direction vector and position vector, and either adding or subtracting voxel_size for the appropriate direction, allow verification that x, y, or zfall exactly on the boundary of the voxel. In that case, the boundary of the next voxel may be examined instead of the current one. After determining the boundaries for the x, y, and z directions, a determination may be made regarding where the rays crossed on each of these planes. Equation 26 shows an example calculation for determining the amount of \u201ctime\u201d taken before the plane for the x direction is crossed. Calculations for they and z directions are similar. The boundary crossed is indicated by min{cross_x, cross_y, cross_z} and is designated p_c. Using this information, Equations 27, 28, and 29 show example calculations for determining the actual point at which the ray crossed the voxel boundary. The distance is calculated using Equation 30.",{"@attributes":{"id":"p-0179","num":"0178"},"maths":{"@attributes":{"id":"MATH-US-00019","num":"00019"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"4.4em","height":"4.4ex"}}},"mo":"\u2062","mrow":{"mi":"cross_x","mo":"=","mrow":{"mfrac":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mi":"x","mn":"0"},"mo":"-","mrow":{"mi":["position","x"],"mo":"."}}},{"mo":["\uf603","\uf604"],"mrow":{"mi":["direction","x"],"mo":"."}}]},"mo":"."}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"26"}}]},{"mtd":[{"mrow":{"mrow":[{"mi":["cross_pt","x"],"mo":"."},{"mo":"{","mrow":{"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":["position","x"],"mo":"."},{"mrow":{"mi":["direction","x"],"mo":"."},"mo":"*","mi":"p_c"}],"mo":"+"}},{"mi":"if"},{"mrow":{"mi":["p_c","cross_x"],"mo":"\u2260"}}]},{"mtd":[{"msub":{"mi":"x","mn":"0"}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":"otherwise"}]}]},"mo":"."}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"27"}}]},{"mtd":[{"mrow":{"mrow":[{"mi":["cross_pt","y"],"mo":"."},{"mo":"{","mrow":{"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":["position","y"],"mo":"."},{"mrow":{"mi":["direction","y"],"mo":"."},"mo":"*","mi":"p_c"}],"mo":"+"}},{"mi":"if"},{"mrow":{"mi":["p_c","cross_y"],"mo":"\u2260"}}]},{"mtd":[{"msub":{"mi":"y","mn":"0"}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":"otherwise"}]}]},"mo":"."}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"28"}}]},{"mtd":[{"mrow":{"mrow":[{"mi":["cross_pt","z"],"mo":"."},{"mo":"{","mrow":{"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":["position","z"],"mo":"."},{"mrow":{"mi":["direction","z"],"mo":"."},"mo":"*","mi":"p_c"}],"mo":"+"}},{"mi":"if"},{"mrow":{"mi":["p_c","cross_z"],"mo":"\u2260"}}]},{"mtd":[{"msub":{"mi":"z","mn":"0"}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":"otherwise"}]}]},"mo":"."}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"29"}}]},{"mtd":[{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"4.4em","height":"4.4ex"}}},"mo":"\u2062","mrow":{"mrow":[{"mi":"dx","mo":"=","msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":["cross_pt","x"],"mo":"."},{"mi":["position","x"],"mo":"."}],"mo":"-"}},"mn":"2"}},{"mi":"dy","mo":"=","msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":["cross_pt","y"],"mo":"."},{"mi":["position","y"],"mo":"."}],"mo":"-"}},"mn":"2"}},{"mi":"dz","mo":"=","msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":["cross_pt","z"],"mo":"."},{"mi":["position","z"],"mo":"."}],"mo":"-"}},"mn":"2"}},{"mi":"distance","mo":"=","mrow":{"msqrt":{"mrow":{"mi":["dx","dy","dz"],"mo":["+","+"]}},"mo":"."}}],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mtext":{}},{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}},{"mtext":{}},{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}},{"mtext":{}},{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}}]}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"30"}}]}]}}}},{"@attributes":{"id":"p-0180","num":"0179"},"figref":["FIG. 21","FIG. 21"],"b":["2100","2102","2104","2104","2104","2100","2106","2108","2110"],"i":["a","b","c "]},{"@attributes":{"id":"p-0181","num":"0180"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 8"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Parameters and Initial Memory Locations"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Variable Name","Initial Location"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"matrix dimensions","0"]},{"entry":[{},"voxel size","6"]},{"entry":[{},"\u03a9","9"]},{"entry":[{},"A","10"]},{"entry":[{},"a","58"]},{"entry":[{},"B","106"]},{"entry":[{},"b","154"]},{"entry":[{},"region of interest","203"]},{"entry":[{},"number of cones","209"]},{"entry":[{},"offset","210"]},{"entry":[{},"voxel size\/2","213"]},{"entry":[{},"number \u03a6","216"]},{"entry":[{},"TERMA","300"]},{"entry":[{},"\u03b7","1,000,300"]},{"entry":[{},"\u03c1","2,000,300"]},{"entry":[{},"dose output","3,000,300"]},{"entry":[{},"direction vectors","4,000,300"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"Most of the values are used in the Ror Rcalculations discussed above. Some of the other values, such as the direction vectors and voxel sizes, are typically used in the ray-tracing calculations.","Implementation of the direct convolution system and the collapse cone include various hardware design languages including, but not limited to, software packages from ALTERA\u00ae and CELOXICA\u00ae. However, persons having ordinary skill in the art will appreciate that other software packages and\/or hardware may be implemented to employ the methods and apparatus described herein, without limitation.","The HANDEL-C\u00ae design language by CELOXICA\u00ae was used in the construction of many components to implement, for example, the main convolver and the direct convolution system. The collapse cone system also made use of a channel object provided by CELOXICA\u00ae. Channels were used in the collapse cone system to communicate between different objects. Channels are an object provided in HANDEL-C\u00ae to synchronize processing and communicate across object and clock domains. In the case of the system described herein, there is only one example clock domain, but persons having ordinary skill in the art will appreciate that different components could be moved into different clock domains for processing. Using channels, it is a fairly simple task to synchronize the communication between all of the different components and ensure correct functionality.","The example collapsed cone algorithm uses IEEE-754 floating point arithmetic. As discussed above, there has been a lot of work in the industry in the area of floating point processing on FPGAs. Such work allows for many different floating point libraries available for use. In the illustrated example methods and apparatus described herein, a floating point library was selected that is provided by CELOXICA\u00ae as part of their Platform Developers Kit (PDK). This library may afford efficient implementation and allow relative ease of integration within HANDEL-C\u00ae code. A list of example pipelined floating point functions provided by the PDK is shown in Table 9. All functions presented take as input, and produce as output, IEEE 32-bit floating point numbers.",{"@attributes":{"id":"p-0186","num":"0185"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 9"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Floating Point Functions Provided By CELOXICA\u2009\u00ae"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Function Name","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["FloatPipeAdd","Add two floating point numbers"]},{"entry":["FloatPipeMultiply","Multiply two floating point numbers"]},{"entry":["FloatPipeDiv","Divide two floating point numbers"]},{"entry":["FloatPipeSub","Subtract two floating point numbers"]},{"entry":["FloatPipeSqrt","Take the square-root of a floating point number"]},{"entry":["FloatPipeEq","Perform equality test"]},{"entry":["FloatPipeGt","Perform greater-than comparison"]},{"entry":["FloatPipeLs","Perform less-than comparison"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"In the illustrated Table 9, each function listed requires a specific number of clock cycles before returning a result. The number of cycles may be determined by taking the function name and adding the word Cycles to it, i.e., FloatPipeAdd requires FloatPipeAddCycles of latency before producing an initial result.","Another design language used in the construction of these systems includes VHDL (VHSIC Hardware Description Language). All components of the direct convolution system (except for the convolver itself) have been written in VHDL. Additionally, the VHDL version of the NIOS processor provided by Altera was used in the example methods and apparatus described herein. For the collapse cone system, only the high level module combining the components was written in VHDL.","SOPC Builder by ALTERA\u00ae was used to connect all of the components of the direct convolution system together. Components that were unneeded (such as the 7-segment display) were removed and a new convolver component was constructed. This new component included the embedded memories, the register file, and the convolver itself. It was combined with the NIOS II\u00ae processor using three different slave ports. Two of these slave ports were used by the NIOS II\u00ae processor solely to communicate with the embedded memories (only one was allowed to be used at a time), while the other port was used to communicate with the register file. Connections between the register file, the embedded memories and the convolver were coded in VHDL prior to combining them into a component.","In the illustrated examples, communication between the NIOS II\u00ae processor and the direct convolution system was accomplished via the AVALON\u00ae interface created by ALTERA\u00ae. It can account for wait states, different clock domains, and inherently handles bus arbitration between master and slave peripherals.","Described herein are results and analysis related to the performance and accuracy of example methods of dose calculation. The design flow used for the creation and testing of these designs is shown in , which illustrates various languages used along with the simulation and compilation stages. All of the example direct convolution designs were run on an ALTERA\u00ae development board featuring a STRATIX\u00ae EP1S40 chip, but persons having ordinary skill in the art will appreciate that other chips may be employed. The designs were compiled using the QUARTUS II\u00ae software version 5.0. Different levels of fitter effort and goals were used at different times as described below.","The convolution subsystem runs at the same speed as the NIOS II\u00ae processor on the STRATIX\u00ae chip. Accordingly, multiple clock domains may be avoided, which would otherwise necessitate additional testing and precautions. Persons having ordinary skill in the art will appreciate that future clocks of higher speed may operate with the example convolver without limitation. The timing requirements for the clock of the convolution system were set to a minimum of 50 MHz. The compilation was for a 25 element convolver and allowed the convolution system to run at 52.28 MHz, utilizing 18,529 LEs (Logic Elements), all 112 available DSP blocks, and 1,920,000 on-chip memory bits. With maximum fitter effort, the compilation took 5 times longer and yielded a new maximum clock frequency was 57.76 MHz and used 20,889 LEs. The usage of other components remained the same.","The equations used to determine the amount of time needed (in terms of clock cycles) to perform a single 2-D convolution using the constructed convolver include:","A time per convolution element (element_time), which consumes 2 clock cycles, and a number of convolution elements (num_element), which equals conv_height*(conv_width+2[kernel_width\/2])* kernel_height. Additionally, a time between convolution rows (time_conv_row) consumes 3 clock cycles, and a number of rows (num_rows) equals cony height*kernel_rows. A time between kernel rows (time_kernel_row) consumes 15 clock cycles, a time to load kernel_row (time_load) consumes the same amount of clock cycles as kernel_width, and a time after load of kernel row before the convolution starts (time_after) consumes 13 clock cycles. Variables used are further explained in Table 10.",{"@attributes":{"id":"p-0195","num":"0194"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 10"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Variables Used in the Convolution Speed Calculation"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Variable Name","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["conv_height","Number of rows in the convolution matrix"]},{"entry":["conv_width","Number of columns in the convolution matrix"]},{"entry":["kernel_height","Number of rows in the kernel matrix"]},{"entry":["kernel_width","Number of columns in the kernel matrix"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"The total time to perform a single 2-D convolution can be estimated by Equation 31, which helps to enable further optimization. It enables evaluation of the different amounts of time needed by various parts of the calculation.\n\nConvolution_Time=element_time*num_elements+\n\ntime_conv_row*num_rows+(time_load+\n\ntime_kernel_row+time_after)*kernel_rows.\u2003\u2003Equation 31\n","Table 11 illustrates times obtained using these example calculations, which closely match those obtained by simulation. The simulation results are obtained by using ModelSim with the correctly sized matrix and kernel.",{"@attributes":{"id":"p-0198","num":"0197"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 11"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Time Difference Between Simulated and Calculated Convolution Times"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Matrix Size","Kernel Size","Sim. Cycles","Calc. Cycles","% Diff."]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["10x10","5x5","1,682","1,715","1.96%"]},{"entry":["20x20","10x10","12,784","12,990","1.61%"]},{"entry":["100x100","100x100","4,032,601","4,042,800","0.25%"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"In addition to using the FPGA board to perform the convolution, the same 2-D convolution was performed using a computer. The specifications for the computer are shown in Table 12. Comparisons of the running time between the computer and the FGPA board are shown in Table 13. The results illustrate that the larger the overall convolution is, the more speedup the FPGA may be able to obtain over the computer. For example, a matrix of size 10\u00d710 and a kernel of size 5\u00d75 results in an FPGA speedup of 1.56\u00d7 over the computer, but with a matrix and kernel each of size 100\u00d7100, the FPGA can achieve a speedup of \u2248218\u00d7. This additional speedup with the larger matrices is typically due to the increased size of the 1-D convolver, which illustrates that more operations are performed in parallel.",{"@attributes":{"id":"p-0200","num":"0199"},"tables":{"@attributes":{"id":"TABLE-US-00012","num":"00012"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 12"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Specifications for Host PC"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Component","Description"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"CPU","Intel Pentium M 1.4 GHz"]},{"entry":[{},"Memory","512 MB in 2-256 MB DIMM modules"]},{"entry":[{},"Hard Drive","Fujitsu 40 GB, 5400 RPM"]},{"entry":[{},"Graphics Card","NVIDIA 64 MB"]},{"entry":[{},"Ethernet","10\/100 Ethernet card"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},{"@attributes":{"id":"p-0201","num":"0200"},"tables":{"@attributes":{"id":"TABLE-US-00013","num":"00013"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 13"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Specifications for Host PC"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Matrix","Kernel",{},{},{}]},{"entry":["Size","Size","FPGA Time","Computer Time","Speedup"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}},{"entry":["10x10","5x5","\u2003\u2002\u200933,640 ns","\u2003\u2003\u2003\u2009\u200952,580 ns","\u20031.56"]},{"entry":["20x20","10x10","\u2003\u2009255,680 ns","\u2003\u2003\u2002\u2009\u2009788,100 ns","\u20033.08"]},{"entry":["100x100","100x100","80,652,000 ns","17,648,070,000 ns","218.82"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"Using Equation 9 to determine the required number of 2-D convolutions, the amount of time needed by the FPGA is extrapolated to perform a 3-D convolution. The results of this are shown in Table 14.",{"@attributes":{"id":"p-0203","num":"0202"},"tables":{"@attributes":{"id":"TABLE-US-00014","num":"00014"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 14"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"3-D Convolution Times Using Repeated 2-D Convolutions"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"56pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Matrix Size","Kernel Size","# 2-D Convolutions","3-D Conv. Time"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"right"}},{"@attributes":{"colname":"5","colwidth":"14pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["10x10","5x5","\u200244","1,480,160 ","ns"]},{"entry":["20x20","10x10","170","43,465,600 ","ns"]},{"entry":["100x100","100x100","7450\u2002","600.8574 ","s"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"Additionally, the information shown in Table 15 shows a comparison of using the FPGA, with the extrapolated data to perform a 3-D convolution compared to using a computer. As with the 2-D convolution comparisons, it can be seen that as the size of the overall convolution grows, so does the advantage of using the FPGA over the computer.",{"@attributes":{"id":"p-0205","num":"0204"},"tables":{"@attributes":{"id":"TABLE-US-00015","num":"00015"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 15"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Comparison of Estimated 3-D Convolution Times with those of a CPU"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Matrix","Kernel",{},{},{}]},{"entry":["Size","Size","FPGA Time","CPU Time","Speedup"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"5","colwidth":"49pt","align":"right"}},{"@attributes":{"colname":"6","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"7","colwidth":"28pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["10x10","5x5","1,480,160","ns","3,070,000","ns","2.074"]},{"entry":["20x20","10x10","43,465,600","ns","188,241,000","ns","4.331"]},{"entry":["100x100","100x100","600.8574","s","21,103.916","s","35.12\u2003"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}}]}}},"While the speedup over the computer is only \u22482\u00d7 for the smallest convolution, it rises to \u224835\u00d7 for the largest convolution performed. This is a substantial improvement over the computer implementation.","To test the correct functioning of the convolution system on hardware and\/or simulation, the design was compiled for and executed on the NIOS II\u00ae Development Kit, STRATIX\u00ae Professional Edition development board. For this example board, the 100\u00d7100 convolver cannot fit on the FPGA chip due to the amount of multipliers needed for the convolver. However, a 100\u00d7100 convolver was able to be compiled for a larger chip, the STRATIX\u00ae EP1S80.","In addition to comparing the speedup between the hardware and software convolution systems for specific sizes of convolvers, the speedup of the system was also compared in terms of logic elements used. QUARTUS\u00ae was used to compile the system for different sizes of convolvers and the number of logic elements used was compared against the speedup of the system. These results are shown in . It can be seen that the speedup is nearly linear with the increase in processing elements.","The example hardware design for this algorithm may handle one new input every clock cycle. Persons having ordinary skill in the art will appreciate that the development board is used for demonstrative purposes and has limited memory bandwidth. For each calculation performed there are 5 different values that must be obtained from memory. Given that the only memories available from the board are one SDRAM memory bank of 32 MB, and one SRAM bank of 1 MB, it is infeasible to expect that all 5 values could be obtained in one clock cycle. However, running the memory at twice the speed of the convolution system may allow buffering of data. In this manner, the delay for accessing data values could decrease from a maximum of 5 clock cycles to 2 cycles for performing a calculation.","Table 16 presents the total number of cycles required for the calculation of components used in this system. As each component is fully pipelined, the given latency can be masked by computation. Additionally, as the size of the overall calculation grows, this initial latency becomes negligible.",{"@attributes":{"id":"p-0211","num":"0210"},"tables":{"@attributes":{"id":"TABLE-US-00016","num":"00016"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 16"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Cycles Required for Computation of Different Components"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Component","Number of Cycles"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Exponential calculation","110"]},{"entry":[{},"R","163"]},{"entry":[{},"R","163"]},{"entry":[{},"Ray-Tracing","212"]},{"entry":[{},"Entire Calculation","428"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"For the row of the table representing the entire calculation, it should be noted that memory latency is ignored. It is assumed that data is available as it is needed. In reality, the data is typically obtained from memory with some delay, and that delay may be included in the final computation results. Also, the calculation of Rand R, usually uses an exponential function that requires the number of cycles reported. The actual number of cycles required for Rand Rmay be calculated by subtracting the number given from the cycles required for the exponential calculation.","A software implementation of the collapse cone algorithm has been developed and compared with dose calculation software. In the example test case used, the developed software algorithm has a maximum off-axis error of 5.83% and an average error of only 1.15% compared to the dose calculation software.  presents a graph comparing the software collapse cone implementation results with the dose calculation reference code. The results are presented for the center axis of the phantom and show very close agreement between the two implementations. Due to the near overlapping of the lines in , the software was judged to be correctly implemented.","The hardware created performs exactly the same calculation as the collapse cone software, which employs 32-bit floating point operations, and were used in the C++ software created, as well as in the Celoxica floating point functions provided. In this way it was easy to check the accuracy of the hardware and to determine whether or not the final calculation was correct. The number of times the calculation was performed has been taken from the software implementation.","Presented in Table 17 are the results of using the collapse cone hardware and software. The number of cones computed for each voxel directly affects the number of calculations.",{"@attributes":{"id":"p-0216","num":"0215"},"tables":{"@attributes":{"id":"TABLE-US-00017","num":"00017"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 17"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Calculation Times for Hardware and Software "},{"entry":"Collapse Cone Implementation"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},{},{},"Ave. time\/","Ave time\/"]},{"entry":["# of ","# ","Software","Hardware","calc (ns)","calc (ns) "]},{"entry":["Cones","Calculations","Time (s)","Time (s)","for SW","for HW"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["\u200348","\u20037,655,573","7.2","0.306","940.49","40"]},{"entry":["\u2002384","\u200270,909,088","67.79","2.836","956.01","40"]},{"entry":["1152","209,969,888","209.52\u2002","8.399","997.86","40"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}]}}},"If the number of cones increases by a factor of 2, the number of calculations increases proportionally. There is not an exact doubling due to differences in the number of voxels encountered during ray-tracing. The number of cones is calculated as the number of radial divisions multiplied by the number of azimuthal divisions (\u0394\u03a6). The table presents how the number of calculations varies depending on the number of cones. It can be seen that the hardware is much more efficient at performing this calculation than the software implementation.","To compute the required amount of time for the hardware implementation, simulation data was used. Ignoring initial latency, it requires 2 cycles to complete a result. Therefore, to obtain the hardware calculation time, a clock cycle rate of 20 ns was chosen (50 MHz) and final calculation time was based on that clock rate. The individual components (ray-tracing, Rand R) have been compiled using the QUARTUS\u00ae software for the STRATIX\u00ae EP1S40 chip on currently available development boards. These components were able to achieve a cycle time of 10 us (100 MHz). As the STRATIX II\u00ae chip on the new development board is both larger and faster than current STRATIX\u00ae chip, once the components are combined, a cycle rate of 20 ns may result. The total time for the hardware is shown in Equation 32. For the size of the calculations performed (the smallest requires 7 million computations) the setup time along with initial and final latency are negligible.",{"@attributes":{"id":"p-0219","num":"0218"},"maths":{"@attributes":{"id":"MATH-US-00020","num":"00020"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"t","mo":"=","mrow":{"mi":["SetupTime","InitLatency"],"mo":["+","+","+"],"mfrac":{"mi":["Num_Calculations","Frequency"]},"mrow":{"mi":"FinalLatency","mo":"."}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"32"}}]}}}}},"As noted in Table 17, the computation time varies with the number of cones, as shown graphically in . Additionally, the computation time varies as the size of the matrix changes. When the matrix is larger, there are typically more voxels that must be ray-traced through, and more voxels where dose is deposited.  shows the impact that changing the matrix size has on the computation time. The x-axis lists total number of voxels and the graph illustrates how changing the number of voxels results in increased computation time.","A software based dose calculation includes a dose deposition point of view, where the dose is only calculated for voxels within a region of interest and at no other locations. On the other hand, a collapse cone hardware implementation is typically calculated from a dose interaction point of view, in which the calculation is performed originating at every non-zero TERMA value. There are advantages to each different method of dose calculation. For the dose interaction point of view, it is possible to determine the effect of changed beams on the dose without recalculating the entire beam. The dose deposition point of view is usually more efficient if only a few voxels are required, but is at a disadvantage for a large number of voxels due to additional information that must be pre-calculated and stored. Because of these algorithm differences, the hardware and software versions of the collapse cone algorithm are compared and the reasons for the speedup of the hardware version are analyzed.","The maximum sustained floating point performance for both the hardware implementation and the CPU shows that some advantages are gained. The maximum floating point performance in MFLOPS for an INTEL\u00ae PENTIUM M\u00ae 1.6 GHz is 694.9. This was obtained by performing a matrix multiply that fit entirely in the cache of the processor. Calculations done for the hardware implementation show that it is capable of running at approximately 5600 MFLOPS. The number of floating point units of different types present in the hardware implementation are shown in Table 18.",{"@attributes":{"id":"p-0223","num":"0222"},"tables":{"@attributes":{"id":"TABLE-US-00018","num":"00018"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 18"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Number and Type of Floating Point"},{"entry":"Units in Collapse Cone HW Implementation"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Unit Type","# Present"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Multiply","45"]},{"entry":[{},"Add","36"]},{"entry":[{},"Subtract","17"]},{"entry":[{},"Divide","13"]},{"entry":[{},"Sqrt","\u20021"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"The number of MFLOPS was obtained by assuming that each floating point unit ran at 50 MHz and the knowledge that each unit is completely pipelined. If NumFP stands for the number of floating point units present and f represents the frequency they are running at, then total FLOPS is NumFP*f. Dividing the result by 10yields MFLOPS. The difference in MFLOPS between the hardware and software implementations leads to a factor of 8 increase in the number of floating point operations which can be performed.","FPGAs exhibit speed advantages over CPUs in more ways than simply performing calculations in parallel, such as by controlling software instruction mix. For example, using the Pin binary instrumentation tool provided by INTEL\u00ae, the dynamic instruction counts of the software program were obtained. These instructions were then divided into 4 different categories, integer arithmetic, memory operations, floating point arithmetic, and control instructions. The breakdown of the percentages of total instructions executed by category includes 12.1% for integer arithmetic (IntOps), 46.0% for memory operations (MemOps), 26.6% for floating point arithmetic (FPOps), and 15.3% for control operations (ControlOps). The total number of dynamically executed instructions was 94,024,735,126 with 384 cones.","In view of the mix of instructions with the hardware implementation, neither the memory operations nor the control instructions are of particular significance. The memory operations can be ignored because they are overshadowed by computation. In a normal CPU, memory locations must be loaded before they can be used, but in this implementation, memory is loaded in parallel with computation, so while loads and stores do take place, they do not add to the overall computation time. If needed, these instructions can typically be shadowed by the parallel computation being done. If those are eliminated, then only 38.7% of the original instructions remain. If it is assumed that the integer operations can be run with the same increase in performance as the floating point operations (a factor of 8), then the overall speedup of the hardware over the software would be approximately 20.7\u00d7, as shown in Equation 33. Table 17 shows an overall speedup of between 23.51\u00d7 and 24.95\u00d7. The 20.7\u00d7 speedup is a reasonable estimation of the overall speedup.",{"@attributes":{"id":"p-0227","num":"0226"},"maths":{"@attributes":{"id":"MATH-US-00021","num":"00021"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":"\u2003","mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mi":["Time",{}],"mo":["=","\u2062"],"mrow":{"mn":"1","mo":"\/","mrow":{"mo":"(","mrow":{"mi":"OrigComputationTime","mo":"*"}}}}}},{"mtd":{"mrow":{"mi":{},"mo":["\u2062",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mn":"100","mo":"\u2062","mi":"%"},"mo":["-","-"],"mi":["MemOps","ControlOps"]}},"mo":"\/","mn":"8"}}}},{"mtd":{"mrow":{"mo":["=","\u2062"],"mi":{},"mrow":{"mn":"1","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"*","mrow":{"mrow":{"mo":["(",")"],"mrow":{"mn":"38.7","mo":"\u2062","mi":"%"}},"mo":"\/","mn":"8"}}}}}}},{"mtd":{"mrow":{"mo":["=","\u2062"],"mi":{},"mrow":{"mn":"20.7","mo":"."}}}}]}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"33"}}]}}}}}},"As described above, calculation of radiation dose may also employ a two level parallel structure to implement the collapsed cone algorithm. At a higher of two levels multiple direction modules provide the ability of depositing energy for different directions in parallel. At the lower level, multiple dose deposition engines can be employed to simultaneously compute the energy deposition by multiple radiation rays. In other words, each deposition engine may operate in parallel with one or more other deposition engines, thereby relieving each deposition engine of any co-dependency. Moreover, ray-tracing and energy calculation are separated into independent hardware modules so that data from ray-tracing can be fully reused. These unique design choices lead to a nearly linear speedup. Moreover, the multi-engine architecture is able to alleviate the demand on the computation time due to larger input sizes. The proposed architecture described below can also readily benefit from the computational power provided by multi-FPGA systems.","The collapsed cone algorithm could be implemented either from the \u201cinteraction point of view\u201d or \u201cdeposition point of view.\u201d With the former, energy released from every interaction point in the irradiated volume is computed according to the distribution implied by the kernel. This means that the dose distribution is recalculated for the entire volume, even when the dose distribution for only a few numbers of voxels is of interest. Similar to many treatment planning systems (TPSs), we adopt the deposition point of view for efficiency.","From the deposition point of view, the final dose of a voxel (v, v, v) is the sum of the partial dose from all the transport lines passing through (v, v, v). To ease the hardware design, we elect to use the Cartesian coordinates to perform dose calculation. Let (s, S, s) be the originating point of a transport line passing through (v, v, v), and m, n be the zenith angle index and azimuth angle index, respectively. Equation 34 summarizes the computation for (v, v, v).",{"@attributes":{"id":"p-0231","num":"0230"},"maths":{"@attributes":{"id":"MATH-US-00022","num":"00022"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["v","x"]},{"mi":["v","y"]},{"mi":["v","z"]}],"mo":[",",","]}}},{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","msub":{"mi":["s","i"]}}}],"mo":"="},{"msub":{"mi":["s","k"]},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mo":"\u2208","mi":"seedplane"}},"mo":"\u2062","mrow":{"mrow":{"msubsup":{"mi":["D","mn"],"mrow":{"mo":["(",")"],"mrow":{"mi":["x","y","z"],"mo":[",",","]}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["s","i"]},{"mi":["s","j"]},{"mi":["s","k"]}],"mo":[",",","]}}},"mo":"."}}}],"mo":[",",","],"msub":{"mi":["s","j"]}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"34"}}]}}}}},"In Equation 34, Dis D(r) expressed in Cartesian coordinates. One feature of Equations 34, 11, and 12 is that data dependencies are limited, thus certain operations may be performed in parallel. In particular, a two-level parallel architecture may accomplish the computation of D. At a lower level of the example two-level architecture, for given (s, s, s), m and n values, the partial dose in (v, v, v) contributed by all the voxels along the transport line is accumulated in parallel according to Equations 11 and 12. Note that for a given direction \u03a9, the voxels along the transport line only share the TERMA, \u03c1 and \u03b7 values. At a higher level of the example two-level architecture, multiple transport lines (corresponding to the last summation in Equation 34) can be considered in parallel. This two-level parallel architecture leads to a signification acceleration of the dose calculation process.","The overall structure of the example dose calculation system is shown in . The example system  includes a host PC , a NIOS II\u00ae processor , and dedicated hardware  for dose calculation, with the latter two being implemented on an FPGA chip . The PC  is responsible for handling a user interface and providing certain software based computation. The NIOS II\u00ae processor  functions as a controller for managing the communication between the host PC  and the dedicated hardware . Communication may be achieved through an Ethernet link .","From a data-flow point of view, implementing the collapsed-cone algorithm on an FPGA may be seen as designing a computation accelerator for the host PC . Deciding what computations should be executed on the PC  and on the hardware  contributes to the overall system  performance. Certain functions in the dose calculation, such as calculating TERMA, may not be time-consuming even when realized in software. The parameters \u03c1 and \u03b7 used in Equations 11 and 12 may also be derived from CT images without incurring significant computational overhead. Therefore, these functions may be executed on the host PC .","In the illustrated example of  minimal computation is needed from the NIOS II\u00ae processor . The processor is only responsible for the communication between the host PC  and the FPGA board . After receiving TERMA, \u03c1, and \u03b7 through the Ethernet , the NIOS II\u00ae processor  writes such data into on-board SRAM . After the dedicated hardware  completes the dose calculation, the NIOS II\u00ae processor  may send the dose results stored in SRAM  (shown on the right of the FPGA chip) back to the host PC . An external memory controller  and a dose memory controller  may be used to access the necessary information (\u03c1, \u03b7, TERMA, and dose) stored in the two SRAMs  and .","In the illustrated example of , the dedicated hardware  includes multiple direction modules (DMs)  as well as several miscellaneous controllers. Inside each DM , there are multiple deposit engines (DEs)  and other auxiliary components. Each DE  may be responsible for the calculation of D(s, s, s), and each DM  is designed to calculate \u03a3D(s, s, s, thus realizing the two-level parallel architecture discussed above.","After each DM  is initialized to start a new direction by the Global Controller , a ray-tracing engine (RE)  may generate the seed plane and perform reference ray-tracing. The segment length \u0394r and the next voxel coordinates may be stored into a ray-tracing dual-port memory  for future use by the DEs  in the DM . Once the seed plane is generated, a direction controller  may produce corresponding transport lines and send them to available DES  one by one. The receiving DEs  may then start to calculate the dose according to Equations 11 and 12. Finally, in the illustrated example, the dose results are accumulated and stored in the external SRAM  by the dose memory controller . Persons having ordinary skill in the art will appreciate that multiple 32-bit on-chip buses (Rbus, Cbus, Dbus, Sbus) are implemented to connect different components by exploiting the rich routing resource(s) on FPGA chips. For simplicity, a daisy chain is adopted to handle simultaneous bus-access demands.","Due to resource limitations that may be encountered, which typically depend on available hardware resources, adjustments to the design structure may be appropriate. Table 19 summarizes example logic usage on, for example, a STRATIX II\u00ae 2S180 for different floating-point functions and the DE .",{"@attributes":{"id":"p-0239","num":"0238"},"tables":{"@attributes":{"id":"TABLE-US-00019","num":"00019"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 19"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Logic Usage of Different Functions"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"70pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Function","LE","DSP","Memory"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"Exponential","2762","0","1503\u2002"]},{"entry":[{},"Divider","1632","0","123"]},{"entry":[{},"Multiplier","\u2002344","7","\u20030"]},{"entry":[{},"Adder","\u2002688","0","\u20030"]},{"entry":[{},"DE","2401","0","\u20030"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}]}}},"As shown in Table 19, the floating-point exponential function (exponential component  in ) has a relatively high logic usage. As a result, several DEs  may share the same exponential component . As a rough estimate, STRATIX II\u00ae 2S180 is capable of holding approximately 40 DEs .","Ray-tracing is typically on the critical path of computing D(s, s, s) in each DE . Note that D(s, s, s) in Equation 34 is a function of \u0394r. Rather than calculate \u0394r for every dose, this computation requirement may be greatly reduced by utilizing the seed plane and transport line concepts described above. A simplified 2-dimension example, as shown in , is used to explain this approach. Here, the tissue volume is defined by the area {Tissue|3<x<9, 0<y<8}. The seed plane then regresses to line y=1. In the illustrated example of , there are a total of 9 transport lines marked as A-I, respectively.","Transport lines that may partially fall outside the boundary of the tissue volume must be handled, such as example transport lines A-C in . An example manner of addressing the out-of-boundary issue includes calculating the points at the intersections of the tissue boundary and the transport lines, e.g., {A\u2032, B\u2032, C\u2032}, and then computing the dose deposited in the voxels starting from {A\u2032, B\u2032, C\u2032}. As a result, unnecessary computations for the area(s) outside the tissue are eliminated. However, the method requires that ray-tracing for these transport lines be performed separately. Hence separate ray-tracing is performed by each individual DE , which may be very costly in terms of logic element usage.","Due to the symmetry and parallelism in the voxels under consideration for a group of parallel transport lines, the segment length \u0394r repeats for the parallel transport lines. To exploit this feature, virtual voxels may be padded (shown as dashed lines in ) within the seed plane boundary. The TERMA, \u03c1 and \u03b7 values for these padded voxels are all assumed to be zero. It follows then that each DE  may start \u201cray-tracing\u201d from the voxel residing at the seed plane. The segment length \u0394r and the coordinates of the next voxel that the transport line is going to enter may be calculated by the RE  and stored in the ray-tracing dual-port memory . In the illustrated example, each DE addresses the memory in sequence to get the ray-trace information step by step.","The above design approach also provides the opportunity for the ray-tracing and the partial dose calculation to be performed in parallel. As ray-tracing proceeds, the example RE  updates valid addresses to indicate the voxel on which the example RE  is working. The address(es) issued by the DE  may then be compared with this valid address. If the issued address is less than the valid address, it only costs one clock cycle to retrieve the ray trace information (e.g., by reading the ray-tracing dual-port memory ). Otherwise, the example DE  may wait until the address becomes valid. Because the number of transport lines is usually relatively large, only the first several DEs need to wait for the ray-tracing information. This initialization cost is amortized among the following ray-tracing steps for the current direction. As a result, the average access time may be quite small.","Embedded systems tend to have limited storage space in order to maintain lower cost. Thus, efforts may be employed to optimize the memory usage according to the application and the features provided by the hardware platform. Care should be taken when allocating data between on-chip and on-board memory components. Memory requirements for the dose calculation process may come from several areas. In general, the dose for a given voxel may be expressed by Equation 35.\n\n().\u2003\u2003Equation 35\n","In Equation 35, Dis the dose contribution from previous voxels along the line of the ray-trace. One 32-bit register is sufficient to store Dbecause the DE  calculates the dose along each transport line iteratively. The sizes of TERMA, \u03c1, and \u03b7 depend on the size of the matrix used to represent the voxels in the tissue volume and can be rather large. Therefore, they may be stored in the external off-chip memory. In the illustrated example, for a 100\u00d7100\u00d7100 voxel matrix, each variable needs approximately 32 Mbits of storage space (stored in the 32-bit floating point format).","The coefficients A, a, B, and in Equation 35 are all related to the zenith angles of the cone directions. As number of cones increases, the precision of the dose results increase. Typically, the number of cones is less than 500. The example implementation described herein uses, for example, 384 directions (48 zenith angles and 8 azimuth angles). Accordingly, these coefficients only need about 6 Kbits of memory, which may be stored in the on-chip memory without significantly increasing the overall memory requirement.","The value \u03a9is a constant for a given direction, which may be calculated and\/or tabulated. For example, tabulation may be employed to lower the logic resource usage. Moreover, to avoid evaluating trigonometric functions with logic resources, 384 direction cosines may also be stored in the on-chip memory, which would require approximately 50 Kbits of memory.","As discussed above, \u0394r is the physical distance that the transport line traveled within the voxel. For each ray-tracing step, \u0394r and the coordinates of the next voxel are stored in the memory, which results in approximately 128 bits for every step. To estimate the total memory requirement by the ray-tracing process includes determining how many segments the longest transport line is divided into during the whole calculation process (i.e., the maximum number of ray-tracing steps).","As shown in , the longest transport line is the diagonal of a box with edges",{"@attributes":{"id":"p-0251","num":"0250"},"maths":{"@attributes":{"id":"MATH-US-00023","num":"00023"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":"\u2003","mrow":{"mrow":[{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"msup":{"mi":["h","\u2032"]},"mo":"\u2062","msub":{"mi":["d","x"]}},{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["d","x"]},{"mi":["d","y"]},{"mi":["d","z"]}],"mo":[",",","]}}}]}},{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"msup":{"mi":["h","\u2032"]},"mo":"\u2062","msub":{"mi":["d","y"]}},{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["d","x"]},{"mi":["d","y"]},{"mi":["d","z"]}],"mo":[",",","]}}}]}},{"mi":"and","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"msup":{"mi":["h","\u2032"]},"mo":"\u2062","msub":{"mi":["d","z"]}},{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["d","x"]},{"mi":["d","y"]},{"mi":["d","z"]}],"mo":[",",","]}}}]}}}],"mo":[",",",",","]}}}},"br":{},"sub":["x","y","z"]},{"@attributes":{"id":"p-0252","num":"0251"},"maths":{"@attributes":{"id":"MATH-US-00024","num":"00024"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":"\u2003","mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":["S","K"]},"mo":["=","\u2062"],"mi":{},"mrow":{"mrow":{"mo":["\u2308","\u2309"],"mrow":{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"msup":{"mi":["h","\u2032"]},"mo":"\u2062","msub":{"mi":["d","x"]}},{"mrow":{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["d","x"]},{"mi":["d","y"]},{"mi":["d","z"]}],"mo":[",",","]}}},"mo":"\u2062","msub":{"mi":["L","x"]}}]}}},"mo":"+"}}}},{"mtd":{"mrow":{"mi":{},"mo":"\u2062","mrow":{"mrow":{"mo":["\u2308","\u2309"],"mrow":{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"msup":{"mi":["h","\u2032"]},"mo":"\u2062","msub":{"mi":["d","y"]}},{"mrow":{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["d","x"]},{"mi":["d","y"]},{"mi":["d","z"]}],"mo":[",",","]}}},"mo":"\u2062","msub":{"mi":["L","y"]}}]}}},"mo":"+"}}}},{"mtd":{"mrow":{"mi":{},"mo":"\u2062","mrow":{"mrow":{"mo":["\u2308","\u2309"],"mrow":{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"msup":{"mi":["h","\u2032"]},"mo":"\u2062","msub":{"mi":["d","z"]}},{"mrow":{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["d","x"]},{"mi":["d","y"]},{"mi":["d","z"]}],"mo":[",",","]}}},"mo":"\u2062","msub":{"mi":["L","z"]}}]}}},"mo":"."}}}}]}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"36"}}]}}}}}},"In Equation 36, (L, L, L) is the size of the unit voxel. The capacity of the on-chip ray-tracing dual-port memory  in each DM  is then determined by Equation 37.\n\n=128 max()(bit).\u2003\u2003Equation 37\n","In Equation 37, M is the total number of zenith angles.","To improve the performance of the memory subsystem, several example mechanisms have been introduced in the hardware design. First, for each DE, shadow registers may be employed to pre-fetch necessary information for the next ray-tracing step, which then allows certain memory access to overlap with the calculation. Second, a simple cache may be implemented in the external memory controller to reduce the read access time of the off-chip memory. Similarly, while writing the final dose in the dose memory, a write buffer and a 4-stage accumulation pipeline is designed in the dose memory controller to fully utilize the bandwidth of the dose memory.","In the illustrated example two-level parallel structure described herein, implementation was designed on an Altera DSP development board, which contains a STRATIX II\u00ae EP25180 FPGA and 1 MB SRAM (10 ns speed grade). Persons having ordinary skill in the art will appreciate that other equipment may be employed. Several electronic design automation (EDA) tools were used during the design process, which include QUARTUS II\u00ae, SYNPLIFY PRO\u00ae and ModelSim\u00ae. The design was mainly developed in VERILOG\u00ae. After compilation, the design with one DE may run at 117.2 MHz. The clock frequency is mainly restricted by the performance of the floating-point units. For simplicity, 100 Mhz is used as the hardware working frequency.","To compare with the software implementation option, the collapsed cone algorithm as used in the hardware design was also implemented in the C language. The performance result of the software was obtained for a PC with 2.4 GHz CPU and 512 MB of memory. To test the implementations, a realistic radiation treatment plan was adopted, in which the voxel size was 1 cm\u00d71 cm\u00d71 cm, and a phantom of size 30 cm\u00d730 cm\u00d730 cm (about the size of the human neck area) was used. The irradiated field was 20 cm\u00d720 cm, and the source-to-skin distance was 100 cm. The resultant input data sizes (for TERMA, \u03c1, \u03b7, etc.) may readily fit in the on-board memory of the DSP development board.","Table look-ups were employed in the dose calculation instead of evaluating Equations 10 and 11. This approach reduces the computation time significantly, while most of the CPU time is spent on the ray-tracing task(s). For comparison purposes, the table-look-up operation is simulated by replacing DE with a simple logic (i.e., a fake DE), which simply holds for 3 clock cycles to simulate the table look-up operation in calculating dose. Additionally, a problem scale of 16\u00d716\u00d764 was chosen, which is similar to the matrix size of 30\u00d730\u00d730. The computing platform used in the comparison was a PC with CPU speed of 866 Mhz. To be fair, the computation time on the PC was increased by three times to account for the difference in the CPU frequencies.","Table 20 compares the execution time for hardware and software when tabulated kernel and analytical kernel is adopted separately.",{"@attributes":{"id":"p-0260","num":"0259"},"tables":{"@attributes":{"id":"TABLE-US-00020","num":"00020"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 20"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Comparison of Execution Time"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"91pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"63pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Kernel","Implementation","Time(s)"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Tabulated Kernel","Software","0.333"]},{"entry":["Tabulated Kernel","HW with 1 fake DE","\u20020.0673"]},{"entry":["Analytical Kernel","Software","6.1\u2003"]},{"entry":["Analytical Kernel","HW with 1 fake DE","5.674"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"When the tabulated kernel is used, the hardware is much faster than the software due to the pipelined design of the RE. When the analytical kernel is accepted, the running time for the HW is only slightly less than that of the SW due to the cost of bus access and the stall of the pipeline (the floating-point multiplier and exponential function used, which are the most important operators in DE, do not support pipelining).","Although the design with one DE may not lead to significant speedups compared with the software implementation, the power of the hardware architecture lies in the fact that multiple DEs may be included in a single implementation. By executing these DEs in parallel, greater speedups may be obtained. In Table 21, a summary of five hardware implementations is shown that contain different numbers of DEs. In these implementations, each DE has one independent exponential component.",{"@attributes":{"id":"p-0263","num":"0262"},"tables":{"@attributes":{"id":"TABLE-US-00021","num":"00021"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 21"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Hardware Cost and Performance for Multiple DEs"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["DE","Freq. (MHz)","ALUTs","Mem (Kbits)","Time (s)","speedup"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["1","117.2","10973","2,767","5.674","1\u2003\u2002\u2009"]},{"entry":["2","112.8","14144","2,803","2.937","1.932"]},{"entry":["4","106.1","20616","2,887","1.525","3.720"]},{"entry":["8","\u200299.3","33481","2,958","0.769","7.378"]},{"entry":["12\u2002","\u200293.4","45985","3,179","0.615","9.226"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}]}}},"From Table 21, it may be seen that the hardware cost (Col. 3 and 4) increases and the clock frequency (Col. 2) decreases, but the changes are relatively small with respect to the original values for a single DE. A decrease in the clock frequency is attributed to the increasing pressure of placing and routing larger designs. The total dose calculation time (Col. 5) decreases almost linearly, except the 12 DE case. Accordingly, the speedup (Col. 6) achievable by the architecture increases proportionally with the number of Des, but may slows down gradually because of the impact of accessing shared information. For the given FPGA board, when the number of DEs is greater than 12, performance saturates because the bandwidth of the external memory becomes the bottleneck of the system. That is, there are always some DEs waiting for memory operations. However, persons having ordinary skill in the art will appreciate that other FPGAs may not exhibit similar performance issues, thereby allowing greater than 12 DEs to be employed to improve performance.","Additionally, to alleviate the memory bottleneck, the memory bandwidth could be increased by expanding data bus width, or more efficient memory subsystems may be employed\/designed. At least one straightforward approach may include duplicating the TERMA, \u03c1 and \u03b7 information into several separate memory chips. Each chip may supply (as input for K) direction modules. The dose results of these K direction modules may then be added up and saved into separate memory chips. This architecture may be able to extended into multi-FPGA systems and\/or bring even greater speedup for dose calculation objectives. When the matrix size increases, this feature would still be able to keep relatively low computation times by deploying additional DEs, as needed.","Although the teachings of the invention have been illustrated in connection with certain embodiments, there is no intent to limit the invention to such embodiments. On the contrary, the intention of this application is to cover all modifications and embodiments fairly falling within the scope of the appended claims either literally or under the doctrine of equivalents."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 28"}]},"DETDESC":[{},{}]}
