---
title: Annotations for multiple versions of media content
abstract: Multiple different versions of the same multimedia content are available to a multimedia server. An annotation server maintains annotations corresponding to the multimedia content, each such annotation corresponding to each of the different versions of the multimedia content.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07051275&OS=07051275&RS=07051275
owner: Microsoft Corporation
number: 07051275
owner_city: Redmond
owner_country: US
publication_date: 19990915
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION","CONCLUSION"],"p":["This application claims priority to U.S. Provisional Application No. 60\/100,452, filed Sep. 15, 1998, entitled \u201cAnnotations for Streaming Video on the Web: System Design and Usage\u201d, to Anoop Gupta and David M. Bargeron.","A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure, as it appears in the Patent and Trademark Office patent office file or records, but otherwise reserves all copyright rights whatsoever.","This invention relates to networked client\/server systems and to methods of delivering and rendering multimedia content in such systems. More particularly, the invention relates to systems and methods of maintaining such content.","The advent of computers and their continued technological advancement has revolutionized the manner in which people work and live. An example of such is in the education field, wherein educational presentations (such as college lectures, workplace training sessions, etc.) can be provided to a computer user as multimedia data (e.g., video, audio, text, and\/or animation data). Today, such presentations are primarily video and audio, but a richer, broader digital media era is emerging. Educational multimedia presentations provide many benefits, such as allowing the presentation data to be created at a single time yet be presented to different users at different times and in different locations throughout the world.","These multimedia presentations are provided to a user as synchronized media. Synchronized media means multiple media objects that share a common timeline. Video and audio are examples of synchronized media\u2014each is a separate data stream with its own data structure, but the two data streams are played back in synchronization with each other. Virtually any media type can have a timeline. For example, an image object can change like an animated .gif file, text can change and move, and animation and digital effects can happen over time. This concept of synchronizing multiple media types is gaining greater meaning and currency with the emergence of more sophisticated media composition frameworks implied by MPEG-4, Dynamic HTML, and other media playback environments.","The term \u201cstreaming\u201d is used to indicate that the data representing the various media types is provided over a network to a client computer on a real-time, as-needed basis, rather than being pre-delivered in its entirety before playback. Thus, the client computer renders streaming data as it is received from a network server, rather than waiting for an entire \u201cfile\u201d to be delivered.","Multimedia presentations may also include \u201cannotations\u201d relating to the multimedia presentation. An annotation is data (e.g., audio, text, video, etc.) that corresponds to a multimedia presentation. Annotations can be added by anyone with appropriate access rights to the annotation system (e.g., the lecturer\/trainer or any of the students\/trainees). These annotations typically correspond to a particular temporal location in the multimedia presentation and can provide a replacement for much of the \u201cin-person\u201d interaction and \u201cclassroom discussion\u201d that is lost when the presentation is not made \u201cin-person\u201d or \u201clive\u201d. As part of an annotation, a student can comment on a particular point, to which another student (or lecturer, assistant, etc.) can respond in a subsequent annotation. This process can continue, allowing a \u201cclassroom discussion\u201d to occur via these annotations. Additionally, some systems allow a user to select a particular one of these annotations and begin playback of the presentation starting at approximately the point in the presentation to which the annotation corresponds.","The multimedia presentations available to a user may include different versions of the same underlying multimedia content. These different versions can have, for example, different resolutions, different bandwidth requirements, different presentation lengths, etc. Due to limitations of the user's computer system, or communication bandwidth limitations, different users may choose (or be required to choose) particular versions of the multimedia content, or users may switch between the different versions.","However, annotations typically correspond to a particular multimedia presentation. Since each of the different versions of the multimedia content is a different multimedia presentation, typical annotations correspond to only one of these presentations. This can be problematic because annotations added by a user to one particular version of the multimedia content (e.g., a low-resolution version) would be associated with that version and would not be available to users being presented with other versions (e.g., a high-resolution version).","One solution to this problem is to have a duplicative annotation structure in which each of the annotations that is created for a version of the multimedia content is duplicated in the annotation storage structure for each of the other versions. The necessary repetition in this solution, however, creates a particularly burdensome process in creating the annotations, as well as requiring a substantial amount of storage space to maintain all of the duplicated annotations.","The invention described below addresses this and other disadvantages of annotations, providing an improved way to create and maintain annotations corresponding to multimedia content.","A system has a multimedia server having access to multiple different versions of the same multimedia content. The system also has an annotation server that maintains annotations corresponding to the multimedia content. Each of the annotations maintained by the annotation server corresponds to all of the different versions of the multimedia content. Thus, the annotations are available to users being presented with any of the versions of the multimedia content, even though only one copy of the annotation is maintained by the annotation server.","According to one aspect of the invention, multiple annotations are maintained together as an annotation collection corresponding to particular multimedia content. Each annotation collection has a corresponding list of identifiers (e.g., uniform resource locators) for the different versions of the multimedia content to which it corresponds, and temporal positioning information associating the annotation with a temporal segment of the multimedia content.","General Network Structure",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 1","FIG. 1"],"b":["10","11","12","13","15","16"]},"Streaming media server computer  has access to streaming media content in the form of different media streams. These media streams can be individual media streams (e.g., audio, video, graphical, etc.), or alternatively composite media streams including two or more of such individual streams. Some media streams might be stored as files in a database or other file storage system, while other media streams might be supplied to the server on a \u201clive\u201d basis from other data source components through dedicated communications channels or through the Internet itself. Different versions of the same media content (e.g., low-resolution and high-resolution versions) may be available to server computer .","There are various standards for streaming media content and composite media streams. \u201cAdvanced Streaming Format\u201d (ASF) is an example of such a standard, including both accepted versions of the standard and proposed standards for future adoption. ASF specifies the way in which multimedia content is stored, streamed, and presented by the tools, servers, and clients of various multimedia vendors. Further details about ASF are available from Microsoft Corporation of Redmond, Wash.","Annotation server  controls the storage of annotations and their provision to client computers . The annotation server  manages the annotation meta data store  and the annotation content store . The annotation server  communicates with the client computers  via any of a wide variety of known protocols, such as the Hypertext Transfer Protocol (HTTP). The annotation server  can receive and provide annotations via direct contact with a client computer , or alternatively via electronic mail (email) via email server . The annotation server  similarly communicates with the email server  via any of a wide variety of known protocols, such as the Simple Mail Transfer Protocol (SMTP).","The annotations managed by annotation server  correspond to the streaming media available from media server computer . In the discussions to follow, the annotations are discussed as corresponding to streaming media. However, it should be noted that the annotations can similarly correspond to \u201cpre-delivered\u201d rather than streaming media, such as media previously stored at the client computers  via the network , via removable magnetic or optical disks, etc.","When a user of a client computer  accesses a web page containing streaming media, a conventional web browser of the client computer  contacts the web server  to request a Hypertext Markup Language (HTML) page. The client-based browser also submits requests to the media server  for streaming data, and the annotation server  for any annotations associated with the streaming data. When a user of a client computer  desires to add or retrieve annotations, the client computer  contacts the annotation server  to perform the desired addition\/retrieval.","Exemplary Computer Environment","In the discussion below, the invention will be described in the general context of computer-executable instructions, such as program modules, being executed by one or more conventional personal computers. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. Moreover, those skilled in the art will appreciate that the invention may be practiced with other computer system configurations, including hand-held devices, multiprocessor systems, microprocessor-based or programmable consumer electronics, network PCs, minicomputers, mainframe computers, and the like. In a distributed computer environment, program modules may be located in both local and remote memory storage devices.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 2","FIG. 1"],"b":["20","20","10","13","15"]},"Computer  includes one or more processors or processing units , a system memory , and a bus  that couples various system components including the system memory  to processors .","The bus  represents one or more of any of several types of bus structures, including a memory bus or memory controller, a peripheral bus, an accelerated graphics port, and a processor or local bus using any of a variety of bus architectures. The system memory includes read only memory (ROM)  and random access memory (RAM) . A basic input\/output system (BIOS) , containing the basic routines that help to transfer information between elements within computer , such as during start-up, is stored in ROM . Computer  further includes a hard disk drive  for reading from and writing to a hard disk, not shown, a magnetic disk drive  for reading from and writing to a removable magnetic disk , and an optical disk drive  for reading from or writing to a removable optical disk  such as a CD ROM or other optical media. The hard disk drive , magnetic disk drive , and optical disk drive  are connected to the system bus  by an SCSI interface  or some other appropriate interface. The drives and their associated computer-readable media provide nonvolatile storage of computer readable instructions, data structures, program modules and other data for computer . Although the exemplary environment described herein employs a hard disk, a removable magnetic disk  and a removable optical disk , it should be appreciated by those skilled in the art that other types of computer readable media which can store data that is accessible by a computer, such as magnetic cassettes, flash memory cards, digital video disks, random access memories (RAMs) read only memories (ROM), and the like, may also be used in the exemplary operating environment.","A number of program modules may be stored on the hard disk, magnetic disk , optical disk , ROM , or RAM , including an operating system , one or more application programs , other program modules , and program data . A user may enter commands and information into computer  through input devices such as keyboard  and pointing device . Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, or the like. These and other input devices are connected to the processing unit  through an interface  that is coupled to the system bus. A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video adapter . In addition to the monitor, personal computers typically include other peripheral output devices (not shown) such as speakers and printers.","Computer  operates in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be another personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet. In the described embodiment of the invention, remote computer  executes an Internet Web browser program such as the \u201cInternet Explorer\u201d Web browser manufactured and distributed by Microsoft Corporation of Redmond, Wash.","When used in a LAN networking environment, computer  is connected to the local network  through a network interface or adapter . When used in a WAN networking environment, computer  typically includes a modem  or other means for establishing communications over the wide area network , such as the Internet. The modem , which may be internal or external, is connected to the system bus  via a serial port interface . In a networked environment, program modules depicted relative to the personal computer , or portions thereof, may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Generally, the data processors of computer  are programmed by means of instructions stored at different times in the various computer-readable storage media of the computer. Programs and operating systems are typically distributed, for example, on floppy disks or CD-ROMs. From there, they are installed or loaded into the secondary memory of a computer. At execution, they are loaded at least partially into the computer's primary electronic memory. The invention described herein includes these and other various types of computer-readable storage media when such media contain instructions or programs for implementing the steps described below in conjunction with a microprocessor or other data processor. The invention also includes the computer itself when programmed according to the methods and techniques described below. Furthermore, certain sub-components of the computer may be programmed to perform the functions and steps described below. The invention includes such sub-components when they are programmed as described. In addition, the invention described herein includes data structures, described below, as embodied on various types of memory media.","For purposes of illustration, programs and other executable program components such as the operating system are illustrated herein as discrete blocks, although it is recognized that such programs and components reside at various times in different storage components of the computer, and are executed by the data processor(s) of the computer.","Client\/Server Relationship",{"@attributes":{"id":"p-0042","num":"0041"},"figref":["FIG. 3","FIG. 3"],"b":["15","10","15","10"]},"Client  runs an HTTP services (HttpSvcs) module , which manages communication with server , and an annotation back end (ABE) module , which translates user actions into commands destined for server . A user interface (MMA) module  provides the user interface (UI) for a user to add and select different annotations, and be presented with the annotations. According to one implementation, the user interface module  supports ActiveX controls that display an annotation interface for streaming video on the Web.","Client  also executes a web browser module , which provides a conventional web browsing interface and capabilities for the user to access various servers via network  of . Web browser  also provides the interface for a user to select particular media streams for presentation. The user can select which one of different versions of multimedia content he or she wishes to receive from media server  of . This selection can be direct (e.g., entry of a particular URL or selection of a \u201clow resolution\u201d option), or indirect (e.g., entry of a particular desired playback duration or an indication of system capabilities, such as \u201cslow system\u201d or \u201cfast system\u201d). Alternatively, other media presentation interfaces could be used.","Annotation server  includes the Multimedia Annotation Web Server (MAWS) module , which is an Internet Services Application Programming Interface (ISAPI) plug-in for Internet Information Server (IIS) module . Together, these two modules provide the web server functionality of annotation server . Annotation server  also includes an HTTP Services module  which manages communication with client . In addition, annotation server  utilizes The Windows Messaging Subsystem  to facilitate communication with email server  of , and an email reply server  for processing incoming email received from email server .","Annotation server  further includes an annotation back end (ABE) module , which contains functionality for accessing annotation stores  and , for composing outgoing email based on annotation data, and for processing incoming email. Incoming email is received and passed to the ABE module  by the Email Reply Server . Annotation content authored at client , using user interface , is received by ABE  and maintained in annotation content store . Received meta data (control information) corresponding to the annotation content is maintained in annotation meta data store . The annotation content and meta data can be stored in any of a variety of conventional manners, such as in SQL relational databases (e.g., using Microsoft \u201cSQL Server\u201d version 7.0, available from Microsoft Corporation). Annotation server  is illustrated in  as maintaining the annotation content and associated control information (meta data) separately in two different stores. Alternatively, all of the annotation data (content and meta information) can be stored together in a single store, or content may be stored by another distinct storage system on the network  of , such as a file system, media server, email server, or other data store.","Each of the annotations maintained in annotation stores  and  corresponds to each of the different versions of particular multimedia content available to media server . Thus, regardless of the number of different versions of particular multimedia content available to media server , each annotation created by annotation server  is maintained as a single copy corresponding to all of these different versions.",{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 4","FIG. 4","FIG. 1"],"b":["11","160","162","15"]},"The video streams  can differ in any of a variety of manners. For example, different resolution qualities may exist, such as low (lo), intermediate (med), and high (hi) resolutions. Additionally, the media streams may have timelines that are modified by different degrees, as discussed in more detail below.  illustrates the media streams having different speed factors (1.0 and 1.5), indicating how fast the streams are rendered (and thus how much the streams have been compressed) compared to the original or default stream. For example, a speed factor of 1.5 indicates that the stream is to be rendered at 1.5 times the speed at which the original or default stream is rendered.","Media server  selects a particular combination of a single audio stream and a single video stream to be the \u201cbase\u201d version of the multimedia content. According to one embodiment, the audio and video streams having the speed factors and resolutions as the streams were originally created (or are received in the case of \u201clive\u201d streams) are selected as the base version of the multimedia content. The base version is used as a reference point to identify which segments of the media streams annotations correspond to, as discussed in more detail below.","Timeline modification changes the timeline of the data streams to achieve either time compression or time expansion. With some types of media, such as video streams, this involves either omitting selected frames or modifying the presentation times of the individual data units or video frames. In other cases, such as with audio streams, time-modification is more difficult\u2014simply changing the presentation times would alter the pitch of the original audio and make it unintelligible. Accordingly, some type of audio processing technique is used to time-compress or time-expand audio streams, while maintaining the original pitch of the audio\u2014thereby maintaining the intelligibility of the audio.","There are various known methods of audio time modification, commonly referred to as \u201ctime-scale-modification,\u201d most of which concentrate on removing redundant information from the speech signal. In a method referred to as sampling, short segments are dropped from the speech signal at regular intervals. Cross fading or smoothing between adjacent segments improves the resulting sound quality.","Another method, referred to as synchronized overlap add method (SOLA or OLA), consists of shifting the beginning of a new speech segment over the end of the preceding segment to find the point of highest cross-correlation (i.e., maximum similarity). The overlapping frames are averaged, or smoothed together, as in the sampling method.","Sampling with dichotic presentation is a variant of the sampling method that takes advantage of the auditory system's ability to integrate information from both ears. In improves on the sampling method by playing the standard sampled signal to one ear and the \u201cdiscarded\u201d material to the other ear. Intelligibility and compression increase under this dichotic presentation condition when compared with standard presentation techniques.","The methods mentioned above are considered \u201clinear\u201d because all portions of the speech signal are compressed or expanded uniformly. Other methods are considered non-linear because they non-uniformly remove portions of the time signal. One example of a non-linear time-compression method is referred to as pause removal. When using this method, a speed processing algorithm attempts to identify and remove any pauses in a recording. Media server  can store different streams resulting from linear time-scale modification or non-linear time-scale modification.","More information regarding audio time modification is given in an article that appeared in the March, 1997, issue of \u201cACM Transactions on Computer-Human Interaction\u201d (Volume 4, Number 1, pages 3\u201338) (1997). For purposes of this disclosure, it can be assumed that audio time modification involves some combination of changing individual data stream samples, dropping certain samples, and adjusting presentation times of any samples that are actually rendered.","Annotation Storage Structure",{"@attributes":{"id":"p-0057","num":"0056"},"figref":["FIG. 5","FIG. 3","FIG. 3"],"b":["180","10","18","180","182","184","186","188","190","192","194","196","198","200","202","182","202","180","180","10","18","192","17"]},"Author field  contains data identifying the user who created annotation entry  and who is therefore the author of the annotation. The author is identified by ABE  of  based on the user logged into client  at the time the annotation is created.","Time range field  contains data representing \u201cbegin\u201d and \u201cend\u201d times defining a segment of media timeline to which annotation entry  is associated. Time units field  contains data representing the units of time represented in time range field . Together, time range field  and time units field  identify the relative time range of the annotation represented by annotation entry . This relative time range corresponds to a particular segment of the media content to which annotation entry  is associated. The begin and end times for the annotation are provided by the user via interface  of , or alternatively can be automatically or implicitly derived using a variety of audio and video signal processing techniques, such as sentence detection in audio streams or video object tracking.","The begin and end times stored in time range field  reference the version of the media content being played back when annotation entry  was created, or alternatively reference the base version. The media content can have multiple different versions, some of which may have different presentation timelines (as discussed in more detail below). The particular range of another version, for instance the one currently being viewed by a user, to which the annotation corresponds can thus be readily determined based on the time range field  and time units field , in conjunction with the known relationship among the presentation timeline of the base version, the version being viewed, and the version on which the annotation was originally created.","It should be noted that the time ranges for different annotations can overlap. Thus, for example, a first annotation may correspond to a segment ranging between the first and fourth minutes of media content, a second annotation may correspond to a segment ranging between the second and seventh minutes of the media content, and a third annotation may correspond to a segment ranging between the second and third minutes of the media content.","Alternatively, rather than using the presentation timeline of the media content, different media characteristics can be used to associate the annotation with a particular segment(s) of the media content. For example, annotations could be associated with (or \u201canchored\u201d on) specific objects in the video content, or specific events in the audio content.","Creation time field  contains data specifying the date and time at which annotation entry  is created. The time of creation of annotation entry  is absolute and is not relative to the video or audio content of the media stream to which annotation entry  is associated. Accordingly, a user can specify that annotations which are particularly old, e.g., created more than two weeks earlier, are not to be displayed. ABE  of  stores the creation time and date when the annotation is created.","Title field  contains data representing a title by which the annotation represented by annotation entry  is identified. The title is generally determined by the user and the user enters the data representing the title using conventional and well known user interface techniques. The data can be as simple as ASCII text or as complex as HTML code which can include text having different fonts and type styles, graphics including wallpaper, motion video images, audio, and links to other multimedia documents.","Content field  contains data representing the substantive content of the annotation as authored by the user. The actual data can be stored in content field , or alternatively content field  may store a pointer to (or other indicator of) the content that is stored separately from the entry  itself. In the illustrated example, content field  includes a pointer to (or other identifier of) the annotation content, which in turn is stored in annotation content store . The user enters the data representing the content using conventional and well known user interface techniques. The content added by the user in creating annotation entry  can include any one or more of text, graphics, video, audio, etc. or links thereto. In essence, content field  contains data representing the substantive content the user wishes to include with the presentation of the corresponding media stream at the relative time range represented by time range field  and time units field .","Annotation identifier field  stores data that uniquely identifies annotation entry , while related annotation identifier field  stores data that uniquely identifies a related annotation. Annotation identifier field  can be used by other annotation entries to associate such other annotation entries with annotation entry . In this way, threads of discussion can develop in which a second annotation responds to a first annotation, a third annotation responds to the second annotation and so on. By way of example, an identifier of the first annotation would be stored in related annotation identifier field  of the second annotation, an identifier of the second annotation would be stored in related annotation identifier field  of the third annotation, and so on.","Set identifier(s) field  stores data that identifies one or more sets to which annotation entry  belongs. Media content can have multiple sets of annotations, sets can span multiple media content, and a particular annotation can correspond to one or more of these sets. Which set(s) an annotation belongs to is identified by the author of the annotation. By way of example, media content corresponding to a lecture may include the following sets: \u201cinstructor's comments\u201d, \u201cassistant's comments\u201d, \u201caudio comments\u201d, \u201ctext comments\u201d, \u201cstudent questions\u201d, and each student's personal comments.","Media content identifier field  contains data that uniquely identifies particular multimedia content as the content to which annotation entry  corresponds. Media content identifier  comprises a media version table  that identifies each of the different streams of multimedia content (e.g., streams  of ) to which annotation entry  corresponds. Each annotation corresponding to multimedia content corresponds to each of the different versions of that content via a mapping defined by the media version table , and thus to each of the different media streams for that content. Data stored in identifier field  associates annotation entry  with particular media streams such that annotation server  can synchronize substantive content of annotation entry  with substantive content of the media streams.","The data stored in media version table  can identify media versions in a variety of different manners. According to one embodiment, the data represents a real-time transport protocol (RTP) address of the different media streams (e.g., streams  of ). An RTP address is a type of uniform resource locator (URL) by which multimedia documents can be identified in a network. According to an alternate embodiment, a unique identifier is assigned to the content (e.g., content  of ) rather than to the individual media streams. According to another alternate embodiment, a different unique identifier of the media streams could be created by annotation server  of  and assigned to the media streams. Such a unique identifier would also be used by streaming media server of  to identify the media streams. According to another alternate embodiment, a uniform resource name (URN) such as those described by K. Sollins and L. Mosinter in \u201cFunctional Requirements for Uniform Resource Names,\u201d IETF RFC 1733 (December 1994) could be used to identify the media stream.","User-defined property fields  are one or more user-definable fields that allow users (or user interface designers) to customize the annotation system. Examples of such additional property fields include a \u201creference URL\u201d property which contains the URL of a web page used as reference material for the content of the annotation; a \u201chelp URL\u201d property containing the URL of a help page which can be accessed concerning the content of the annotation; a \u201cview script\u201d property containing JavaScript which is to be executed whenever the annotation is viewed; a \u201cdisplay type\u201d property, which gives the client user interface information about how the annotation is to be displayed; etc.",{"@attributes":{"id":"p-0071","num":"0070"},"figref":["FIG. 6","FIG. 3","FIG. 5"],"b":["10","180","200","180","200","10"]},"Annotation database  includes two annotation collections  and . Annotation server  dynamically adds, deletes, and modifies annotation entries in annotation database  based on commands from client . Annotation entries can be created and added to annotation database  at any time a user cares to comment upon the content of the stream (or another annotation) in the form of an annotation. Annotation server  forms an annotation entry from identification data, content data, title data, and author data of an \u201cadd annotation\u201d request received from the client's ABE  (), and adds the annotation entry to annotation database .","Annotation database  includes fields , , and  that specify common characteristics of all annotation entries of database  or an annotation collection  or . Alternatively, fields \u2013 can be included redundantly in each annotation entry .","Creator field  contains data identifying the user who was responsible for creating annotation database .","RTP address fields  and  contains data representing an RTP address of the media content (e.g., the RTP addresses of each of the different streams contained in version table ) for the annotation collection. An RTP address provides an alternative mechanism, in addition to the data in identifier field  of , for associating the media content with annotation entries . In alternative embodiments, RTP address fields  and  need not be included, particularly embodiments in which media version table  contains the RTP address of the media stream.","User Interface","An annotation can be created by a user of any of the client computers  of . As discussed above with reference to , client  includes an interface module  that presents an interface to a user (e.g., a graphical user interface), allowing a user to make requests of annotation server . In the illustrated example, a user can access annotation server  via an annotation toolbar provided by interface .",{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 7","b":["240","242","254"]},"Selection of an exit or \u201cX\u201d button  causes interface  to terminate display of the toolbar . A server identifier  identifies the annotation server with which client  is currently configured to communicate (annotation server  of  in the illustrated embodiment).","Selection of a connection button  causes ABE  of  to establish a connection with the annotation server identified by identifier . Selection of a query button  causes interface module  to provide a \u201cquery\u201d interface, from which a user can enter search criteria to find particular annotations. Selection of an add button  causes interface module  to open an \u201cadd new annotation\u201d dialog box, from which a user can create a new annotation.","Selection of a show annotations button  causes interface module  to provide a \u201cview annotations\u201d interface, from which a user can select particular annotations for presentation.","Selection of a preferences button  causes interface  of  to open a \u201cpreferences\u201d dialog box, from which a user can specify various UI preferences, such as an automatic server query refresh interval, or default query criteria values to be persisted between sessions.","Annotation Creation",{"@attributes":{"id":"p-0082","num":"0081"},"figref":["FIG. 8","FIG. 7"],"b":["260","250","150","262","260","262"]},"A time strip  is also provided as part of dialog box . Time strip  represents the entire presentation time of the corresponding media stream. A \u201cthumb\u201d  is movable within time strip  to allow a user to set a particular temporal position within the media stream. The annotation being created via dialog box  has a begin time and an end time, which together define a particular segment of the media stream. When \u201cfrom\u201d button  is selected, thumb  represents the begin time for the segment relative to the media stream. When \u201cto\u201d button  is selected, thumb  represents the end time for the segment relative to the media stream. Alternatively, two different thumbs could be displayed, one for the begin time and one for the end time. The begin and end times are also displayed in an hours\/minutes\/seconds format in boxes  and , respectively.","Thumb  can be moved along time strip  in any of a variety of conventional manners. For example, a user can depress a button of a mouse (or other cursor control device) while a pointer is \u201con top\u201d of thumb  and move the pointer along time strip , causing thumb  to move along with the pointer. The appropriate begin or end time is then set when the mouse button is released. Alternatively, the begin and end times can be set by entering (e.g., via an alphanumeric keyboard) particular times in boxes  and .","Dialog box  also includes a \u201cplay\u201d button . Selection of play button  causes interface module  of  to forward a segment specification to web browser  of client . The segment specification includes the target identifier from target display  and the begin and end times from boxes  and , respectively. Upon receipt of the segment specification from interface module , the browser communicates with media server  and requests the identified media segment using conventional HTTP requests. In response, media server  streams the media segment to client  for presentation to the user. This presentation allows, for example, the user to verify the portion of the media stream to which his or her annotation will correspond.","Dialog box  also includes an annotation set identifier , an email field , and a summary . Annotation set identifier  allows the user to identify a named set to which the new annotation will belong. This set can be a previously defined set, or a new set being created by the user. Selection of the particular set can be made from a drop-down menu activated by selection of a button , or alternatively can be directly input by the user (e.g., typed in using an alphanumeric keyboard). According to one embodiment of the invention, annotation server  of  supports read and write access controls, allowing the creator of the set to identify which users are able to read and\/or write to the annotation set. In this embodiment, only those sets for which the user has write access can be entered as set identifier .","Email identifier  allows the user to input the email address of a recipient of the annotation. When an email address is included, the newly created annotation is electronically mailed to the recipient indicated in identifier  in addition to being added to the annotation database. Furthermore, the recipient of the electronic mail message can reply to the message to create an additional annotation. To enable this, the original email message is configured with annotation server  as the sender. Because of this, a \u201creply to sender\u201d request from the recipient will cause an email reply to be sent to annotation server . Upon receipt of such an electronic mail message reply, annotation server  creates a new annotation and uses the reply message content as the content of the new annotation. This new annotation identifies, as a related annotation, the original annotation that was created when the original mail message was sent by annotation server . In the illustrated embodiment, this related annotation identifier is stored in field  of .","Summary  allows the user to provide a short summary or title of the annotation content. Although the summary is illustrated as being text, it could include any of a wide variety of characters, alphanumerics, graphics, etc. In the illustrated embodiment, summary  is stored in the title field  of the annotation entry of .","Dialog box  further includes radio buttons  and , which allow an annotation to be created as text and\/or audio. Although not shown, other types of annotations could also be accommodated, such as graphics, HTML documents, etc. Input controls  are also provided as part of dialog box. The illustrated controls are enabled when the annotation includes audio data. Input controls  include conventional audio control buttons such as fast forward, rewind, play, pause, stop and record. Additionally, an audio display bar  can be included to provide visual progress feedback when the audio is playing or recording.","The exact nature of input controls  is dependent on the type of annotation content being provided. In the case of text content, input controls  may simply include a box into which text can be input by the user via an alphanumeric keyboard. Additionally, a keyboard layout may also be provided to the user, allowing him or her to \u201cpoint and click\u201d using a mouse and pointer to select particular characters for entry.","Upon receipt of an add annotation request (whether by email or from interface  of ), annotation server  of  determines which different versions of multimedia content the annotation corresponds to. Annotation server  receives an indication of the target stream for the annotation. This target stream is a particular version of the multimedia content to which the annotation corresponds, and may be an individual media stream or a composite media stream. Upon receipt of the add annotation request, annotation server  communicates the target stream information to media server  of . Media server , knowing which different media streams correspond to the multimedia content, communicates the identifiers of the different streams of the multimedia content to annotation server . Alternatively, client computer  of  may have identifiers of the different streams and may communicate those identifiers to annotation server , or groups of \u201cequivalent\u201d media streams may have been previously created on the annotation server  by an administrator.","As part of the add annotation request client computer  of  determines the appropriate time range for the annotation and provides the time range to annotation server . Alternatively, annotation server  may make this determination based on information received from client computer . As discussed above, a user indicates the desired time range of the media content to which the annotation corresponds via boxes  and . However, the begin and end times provided by the user refer to particular times of the version of the multimedia content being provided to the user. In embodiments where the time range is stored in range field  of  with reference to a base version, then the user-indicated time range is converted from the timeline of the version being viewed to the base version.","When the version of the multimedia content currently being provided to the user is time compressed using linear time compression, client computer  of  knows the time compression factor of the version of the multimedia content currently being provided to the user of client . Client computer  also knows, or alternatively receives from media server , an indication of the time compression factor of the base version of the multimedia content. Using the relationship between the two time compression factors, client computer  can readily determine the begin and end times with reference to the base version. Specifically, the point in time of the base version that a particular begin time or end time corresponds to can be determined using the following calculation:",{"@attributes":{"id":"p-0094","num":"0093"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"basetime","mo":"=","mrow":{"mi":"currenttime","mo":"\u00d7","mfrac":{"mi":["basefactor","currentfactor"]}}}}}},"In this calculation, basetime is the presentation time in the base version, currenttime is the presentation time in the version currently being presented to the user, currentfactor is the playback speed or factor of the version currently being presented to the user, and basefactor is the playback speed or factor of the base version. Analogous calculations can be performed during playback to determine the points in time of the base version corresponding to the points in time of the version which is being played back.","However, in embodiments where the time range stored in field  of  is in reference to the timeline of the version being presented when the annotation was created, conversions to a base timeline are not needed. Rather, conversion from the stored version to the currently playing version can be made as the current version is played back.","Alternatively, such as when the time compression difference between the version of the multimedia content currently being provided to the user and the base version is nonlinear, a different methodology can be used. Annotation  server of  maintains a record (e.g., a table) of the correlation between the timelines of the non-linearly compressed version and the base version. This record can then be communicated to client computer  in order for client computer  to identify the point in time of the base version to which a particular begin time or end time corresponds.",{"@attributes":{"id":"p-0098","num":"0097"},"figref":["FIG. 9","FIG. 9","FIG. 3"],"b":"10"},"A step  comprises receiving new annotation information. Annotation server  can receive this new annotation information via an add annotation request from interface  of , or alternatively can be received as an email message from email server  of .","A step  comprises creating an annotation entry in an annotation database using the information received in step .","A step  comprises determining which media versions correspond to the annotation. Annotation server  communicates with media server  of  to determine the different versions of the multimedia content to which the annotation corresponds.","A step  comprises adding identifiers of each media version to the annotation. A collection of annotations may have a single record of corresponding media versions, or alternatively each individual annotation may maintain a record of corresponding media versions.","It should be noted that in some embodiments, steps  and  need not be repeated for each new annotation. For example, in embodiments where a single media version table is maintained for a collection of annotation entries, as illustrated in , each new annotation entry in the collection of annotation entries will correspond to the same multiple versions as the previous entries in the collection. Thus, an additional determination and adding of identifiers in steps  and  is not necessary.","Annotation and Media Segment Presentation",{"@attributes":{"id":"p-0104","num":"0103"},"figref":["FIG. 10","FIG. 1"],"b":["450","15","450","454","456","240"]},"Media screen  is the region of the UI within which the multimedia content is rendered. For video content, the video is displayed on screen . For non-visual content, screen  displays static or dynamic images representing the content. For audio content, for example, a dynamically changing frequency wave that represents an audio signal could be displayed in media screen .","Annotation screen  is the region of the UI within which the annotations are rendered. For video, graphical, and text annotations, the video, graphical, or text content of the annotation is displayed on screen . For non-visual content, screen  displays static or dynamic images representing the annotation content, such as the title or summary of the annotation, or a dynamically changing frequency wave in the case of audio content.","The annotations provided by annotation server  of  and the media content provided by media server  are presented to the user of client computer  concurrently via UI window . The annotation server  communicates with the client computer  to determine the presentation timeline (e.g., the speed factor being used) of the media content currently being presented. Given the presentation timeline and other retrieval criteria, annotation server  can compare the current presentation time to the time ranges maintained in annotation entries  of  to determine which annotations are to be provided to the client computer at the current time and what their time range information should be. It should be noted that, since the time range information is maintained in annotation entries  with reference to a base version (or alternatively the version on which the annotation was originally created), additional time conversions may need to be performed (e.g., at the client computer  or annotation server ) in order to accurately compare the presentation timeline of the media version being presented to the base version, for instance, when the time compression ratio for an audio\/video composite stream is altered dynamically by the user of client . These conversions can be performed analogous to those discussed above with reference to creating annotations.",{"@attributes":{"id":"p-0108","num":"0107"},"figref":["FIG. 11","FIG. 11","FIG. 3"],"b":"10"},"A step  comprises receiving, from client computer  of , an indication of the media stream being provided to the client computer  from media server  of .","A step  comprises accessing an annotation collection corresponding to the media stream. Annotation server  determines, based on the indication received in step , the collection of annotations that correspond to the media stream being provided to client computer .","A step  comprises determining the media characteristics (e.g., the playback speed) of the media stream. The media characteristics of the media stream can be provided to annotation server  from client computer  or media server , or can be derived from the version table  in  by comparing the target media stream to other versions of the same content in the table.","A step  comprises converting the media characteristics of the media stream to those of the base version of the content (e.g., current playback time of the media stream to the timeline of the base version). This conversion can be done in a linear calculation or table lookup manner, as discussed above.","A step  comprises identifying one or more annotations to provide to the client computer. The annotations of the collection accessed in step  are compared to the current base version time determined in step . Any annotations with a time range in the neighborhood of the corresponding current base version time are provided to the client computer  for presentation to the user.","The invention described above provides annotations for multiple versions of media content. A single annotation advantageously corresponds to multiple different versions of multimedia content, each such version being a different media stream(s). Thus, different versions of media content can be provided to users and can be annotated, with the annotations corresponding to all of the different versions of the media content.","Although the invention has been described in language specific to structural features and\/or methodological steps, it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or steps described. Rather, the specific features and steps are disclosed as preferred forms of implementing the claimed invention."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings. The same numbers are used throughout the figures to reference like components and\/or features.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
