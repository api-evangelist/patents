---
title: Multi-stage method for object detection using cognitive swarms and system for automated response to detected objects
abstract: A multi-stage method of visual object detection is disclosed. The method was originally designed to detect humans in specific poses, but is applicable to generic detection of any object. A first stage comprises acts of searching for members of a predetermined general-class of objects (such as humans) in an image using a cognitive swarm, detecting members of the general-class of objects in the image, and selecting regions of the image containing detected members of the general-class of objects. A second stage comprises acts of searching for members of a predetermined specific-class of objects (such as humans in a certain pose) within the selected regions of the image using a cognitive swarm, detecting members of the specific-class of objects within the selected regions of the image, and outputting the locations of detected objects to an operator display and optionally to an automatic response system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08515126&OS=08515126&RS=08515126
owner: HRL Laboratories, LLC
number: 08515126
owner_city: Malibu
owner_country: US
publication_date: 20090618
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","STATEMENT OF GOVERNMENT INTEREST","BACKGROUND OFT HE INVENTION","SUMMARY OF INVENTION","DETAILED DESCRIPTION","Gabor Wavelets"],"p":["This application is a Continuation-in-Part application of U.S. application Ser. No. 11\/800,264, filed on May 3, 2007, entitled, \u201cBehavior recognition using cognitive swarms and fuzzy graphs,\u201d","This invention was made with Government support under Contract No. FA9453-05-C-0252, awarded by the Defense Advanced Research Projects Agency. The Government has certain rights in the invention.","(1) Field of Invention","The present invention relates to a method and system for visual object detection and response and, more specifically, to a multi-stage method for generic object detection using cognitive swarms and a system for automated response to the detected objects.","(2) Description of Related Art","Current methods of object detection focus on direct detection of the desired class of objects by searching the entire image window. Such methods substantially fail in detecting highly specific objects, such as a narrow specific-class of a more general-class of objects. A traditional search for a highly specific object, for example, a person in a pose with their arms held vertically upward as would a football referee signaling a touchdown, would require a feature detection algorithm specifically tailored to detecting a person in such a pose. There currently exist object detection algorithms for detecting a human form. Tailoring these algorithms to detect a human form engaged in a specific position would likely be very complex, thereby increasing processing time without a guarantee of accurate results. Such a method is also impractical if the object detection task changes which would require creation of a different highly specific object detection algorithm. As an alternative to creating a highly specific detection algorithm, one could search for the simple double vertical signatures created by the arm position of the object. However, such a method will likely yield a high false alarm rate since it will detect all similar vertical signatures in the scene, including signatures from trees, buildings, and other irrelevant objects.","Thus, a continuing need exists for a method for fast and accurate detection of highly specific objects in large volumes of video imagery.","The present invention relates to a method and system for visual object detection and response and, more specifically, to a multi-stage method for generic object detection using cognitive swarms and a system for automated response to detected entities. A first stage comprises searching for members of a predetermined general-class of objects in an image using a cognitive swarm, detecting members of the general-class of objects in the image, and selecting regions of the image containing detected members of the general-class of objects. A second stage comprises searching for members of a predetermined specific class of objects within, the selected regions using a cognitive swarm, and detecting members of the specific-class of objects within the selected regions of the image, whereby members of the specific-class of objects are located in the image.","In another aspect, the method further comprises an act of cueing an operator with the locations of detected members of the specific-class of objects.","In another aspect, the method further comprises an act of cueing an automatic response system with the locations of detected members of the specific-class of objects.","In yet another aspect, the general-class of objects is humans and the specific-class of objects is humans in a specific pose.","As can be appreciated by one skilled in the art, the present invention also comprises a data processing system having a memory and a processor, the data processing system including computer-readable instructions for causing the data processing system to search for members of a predetermined general-class of objects in an image using a cognitive swarm, detect members of the general-class of objects in the image, select regions of the image containing detected members of the general-class of objects, search for members of a predetermined specific-class of objects within the selected regions using a cognitive swarm, and detect members of the specific-class of objects within the selected regions of the image.","In another aspect, the data processing system is flintier configured to output locations of detected members of the specific-class to an operator display unit.","In yet another aspect, the data processing system is further configured to output locations of detected members of the specific-class to an automatic response system.","The present invention further comprises a complete system for object detection comprising at least one optical sensor for imaging a scene, a data processing sub-system as described above further configured to receive at least one image from the at least one optical sensor, and an operator display sub-system configured to receive locations of detected members of the specific-class of objects from the data processing sub-system and alert an operator to the locations of the detected members of the specific-class of objects.","In yet another aspect of the system, the operator display sub-system comprises a display means selected from a group consisting of illuminating the object, displaying the object location through personal head-worn displays, and displaying the object location on a flat panel display.","In another aspect of the system, the at least one optical sensor comprises a plurality of optical sensors, the data processing subsystem comprises a network of data processors configured to process the images from the plurality of optical sensors in parallel, and the network of data processors are connected with a master processor for coordinating results from the network of data processors.","In yet another aspect, the system further comprises an automatic response sub-system configured to receive locations of detected members of the specific-class of objects from the data processing sub-system.","As can be appreciated by one skilled in the art, the present invention thither comprises a computer program product having computer readable instructions encoded thereon for causing a data processing system to perform the acts of the method of the present invention as previously described.","The present invention relates to a method and system for visual object detection and response and, more specifically, to a multi-stage method for generic object detection using cognitive swarms and a system for automated response to the detected objects. The following description is presented to enable one of ordinary skill in the art to make and use the invention and to incorporate it in the context of particular applications. Various modifications, as well as a variety of uses in different applications will be readily apparent to those skilled in the art, and the general principles defined herein may be applied to a wide range of embodiments. Thus, the present invention is not intended to be limited to the embodiments presented, but is to be accorded the widest scope consistent with the principles and novel features disclosed herein.","In the following detailed description, numerous specific details are set forth in order to provide a more thorough understanding of the present invention However, it will be apparent to one skilled in the art that the present invention may be practiced without necessarily being limited to these specific details. In other instances, well-known structures and devices are shown in block diagram form, rather than in detail, in order to avoid obscuring the present invention.","The reader's attention is directed to all papers and documents which are filed concurrently with this specification and which are open to public inspection with this specification, and the contents of all such papers and documents are incorporated herein by reference. All the features disclosed in this specification, (including any accompanying claims, abstract, and drawings may be replaced, by alternative features serving the same, equivalent or similar purpose, unless expressly stated otherwise. Thus, unless expressly stated otherwise, each feature disclosed is only one example of a generic series of equivalent or similar features.","Furthermore, any element in a claim that does not explicitly state \u201cmeans for\u201d performing a specified function, or \u201cstep for\u201d performing a specific function, is not to be interpreted as a \u201cmeans\u201d or \u201cstep\u201d clause as specified in 35 U.S.C. Section 112, Paragraph 6. In particular, the use of \u201cstep of\u201d or \u201cact of\u201d in the claims herein is not intended to invoke the provisions of 35 U.S.C. 112: Paragraph 6.","Further, if used, the labels left, right, front, back, top, bottom, forward, reverse, clockwise and counter clockwise have been used for convenience purposes only and are not intended to imply any particular fixed direction. Instead, they are used to reflect relative locations and\/or directions between various portions of an object.","(1) Introduction","The present invention generally relates to a method and system for visual object detection and response. More specifically, the present invention is directed to a multi-stage method for generic object detection using cognitive swarms and a system for automated response to the detected objects. For ease of understanding, the following description is divided into two major sections, the first major section, labeled \u201c(2.0 Visual Object Detection of Highly-Specific. Objects,\u201d describes the two-stage search process by which highly-specific objects can be detected in a visual image. The subsequent major section labeled \u201c(3.0) System for Automated Response to Detected Objects,\u201d describes the surrounding system that relays the results of the detection search to operators in a manner that would allow them to take appropriate responsive action and, optionally, to an automatic response system designed to respond automatically.","(2.0) Visual Object Detection of Highly-Specific Objects","As noted above, the present invention includes a multi-stage method of object detection. In particular, the method was designed as an aid in video surveillance for detecting humans engaged in specific activities. However, the methods and processes of the present invention can be applied to generic object detection of any desired class of objects. Therefore, the embodiments described herein for detecting human activities are non-limiting examples that are provided for illustrative purposes only.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 1A","b":["100","102","104","106","107","108","102"]},"Compared to conventional methods, the two-stage object detection method provides much faster object detection capabilities, as well as the ability to detect an object based on the context of its surroundings. For example, the system is capable of detecting the pose of the person holding a small object when the object itself is too small to be detected directly. The conventional processing flow for recognition of objects in images or video using computer vision consists of three steps, as shown in . In the first step , an analysis window is defined to select the portion of the video image  that is to be analyzed for the presence or absence of the object of interest. The analysis window is scanned or otherwise positioned at various locations in the image  in order to find, objects. In the second step , features are extracted from the analysis window that in some way are descriptive of the object of interest. A common type of feature is the inner-product of the analysis window with a two-dimensional (2-D) kernel function. A set of feature values from different locations in the analysis window, each of which may use a different kernel function, are combined into a feature vector. The third step  comprises the classification of the feature vector as representing an object of interest or non-object of interest. These three steps comprise the first stage  of the present invention.","The search or window positioning stage  of the specific object detection system can be implemented using cognitive swarms, which is based on Particle Swarm Optimization (PSO). PSO is known in the art and was described by Kennedy, J., Eberhart, R. C., and Shi, Y. in \u201c,\u201d San Francisco: Morgan Kaufmann Publishers, 2001. PSO was also described by R. C. Eberhart and Y. Shi in \u201cParticle Swarm Optimization: Developments, Applications, and Resources.\u201d 2001. Cognitive swarms are a new variation and extension of PSO. Cognitive swarms search for and recognize objects by combining PSO with an objective function that is based on the recognition confidence. A previous patent application has been filed on cognitive swarms for single-stage detection. The details of the cognitive swarm framework are disclosed in U.S. patent application Ser. No. 11\/367,755, titled \u201cCognitive Swarm Vision Framework with Attention Mechanisms,\u201d which is incorporated by reference as though fully set forth herein.","PSO is a relatively simple optimization method that has its roots in artificial life in general, and to bird flocking and swarming theory in particular. Conceptually, it includes aspects of genetic algorithms and evolutionary programming. A population of potential solutions is maintained as the positions of a set of particles in a solution space where each dimension represents one solution component. Each particle is assigned a velocity vector and the particles then explore cooperatively the solution space in search of the objective function optima. Each particle keeps track of its coordinates in multi-dimensional space that are associated with the best solution (p) it has observed so far. A global best parameter (p) is used to store the best location among all particles. The velocity of each particle is then changed towards p and pin a probabilistic way according to:\n\n(1)=()+\u03c6()\u2212()]+\u03c6()\u2212()],\n\n(1)=()+\u03c7(1)\n\nwhere x(t) and v(t) are the position and velocity vectors at time t of the i-th particle and cand care parameters that weight the influence of their respective terms in the velocity update equation, w is a decay constant which allows the swarm to converge to a solution more quickly, \u03c6and \u03c6are random numbers between 0 and 1 that introduce a degree of random exploration, and \u03c7 is a parameter that controls the convergence properties of the swarm.\n","The above PSO dynamics reflect a socio-psychological model where individual particles change their beliefs in accordance with a combination of their own experience and the best experience of the group. This is in contrast to other models of cognition where an individual changes his beliefs to become more consistent with his own experience only. The random element introduces a source of noise which enables an initial random search of the solution space. The search then becomes more directed after a few iterations as the swarm starts to concentrate on more favorable regions. This type of search is much more efficient than exhaustive or gradient based search methods. PSO relies on the fact that in most practical problems the optimum solution usually has better than average solutions residing; in a volume around it. These good solutions tend to attract the particles to the region where the optimum lies. The swarm becomes more and more concentrated until the optimum is found (e.g., pno longer changes). In cognitive swarms, the PSO objective function is the confidence level of an object classifier. The cognitive swarm locates objects of interest in the scene by maximizing the classifier confidence.","The feature extraction and feature value calculation stage  can be implemented using various types of features known in the art. As a non-limiting example.  provides an illustration showing, various species of Generalized Haar-like Wavelet Features. Each wavelet kernel  is divided into positive  and negative  sections. The wavelet kernel is correlated with the pixel values in the underlying image, then the positive  and negative  sections are summed to yield a feature value for the wavelet kernel . Another type of feature that can be used is Threshold Gabor Wavelet Features. Threshold Gabor Wavelets come in two types and are defined as follows:",{"@attributes":{"id":"p-0055","num":"0054"},"maths":[{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"Type","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":"1:"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mo":"-","mfrac":{"mrow":[{"mo":["(",")"],"mrow":{"msup":{"mi":"x","mn":"2"},"mo":"+","mrow":{"mi":"\u03b3","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mi":"Y","mn":"2"}}}},{"mn":"2","mo":"\u2062","msup":{"mi":"\u03c3","mn":"2"}}]}}}},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":{"mrow":{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03c0"},"mi":"\u03bb"},"mo":"\u2062","mi":"X"}}}],"mo":"\u2062"}],"mo":"="}}},{"@attributes":{"id":"MATH-US-00001-2","num":"00001.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"Type","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":"2:"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mo":"-","mfrac":{"mrow":[{"mo":["(",")"],"mrow":{"msup":{"mi":"X","mn":"2"},"mo":"+","mrow":{"mi":"\u03b3","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mi":"Y","mn":"2"}}}},{"mn":"2","mo":"\u2062","msup":{"mi":"\u03c3","mn":"2"}}]}}}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"},"mi":"\u03bb"},"mo":"\u2062","mi":"X"}}}],"mo":"\u2062"}],"mo":"="}}},{"@attributes":{"id":"MATH-US-00001-3","num":"00001.3"},"math":{"@attributes":{"overflow":"scroll"},"mi":"where"}},{"@attributes":{"id":"MATH-US-00001-4","num":"00001.4"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"X","mo":"=","mrow":{"mrow":[{"mi":["x","cos","\u03b8"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]},{"mi":["y","sin","\u03b8"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]}],"mo":"+"}}}},{"@attributes":{"id":"MATH-US-00001-5","num":"00001.5"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"Y","mo":"=","mrow":{"mrow":[{"mrow":{"mo":"-","mi":"x"},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mi":["sin","\u03b8"]},{"mi":["y","cos","\u03b8"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]}],"mo":"+"}}}}]},{"@attributes":{"id":"p-0056","num":"0055"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mi":["Thresholded","wavelets"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}}},{"mtd":{"mrow":{"mi":["are","limited","to","values"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]}}},{"mtd":{"mrow":{"mrow":[{"mi":"of","mo":["\u2062","-"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"1"},{"mrow":{"mi":"and","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"1"},"mo":":"}],"mo":[",",","],"mn":"0"}}}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"msub":{"mi":["G","TH"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mrow":{"mrow":{"mi":"if","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},"mo":">=","mi":"tval"}}]},{"mtd":[{"mn":"0"},{"mrow":{"mrow":[{"mi":["if","tval"],"mo":["\u2062","-"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}],"mo":["<","<"],"mi":"tval"}}]},{"mtd":[{"mrow":{"mo":"-","mn":"1"}},{"mrow":{"mrow":[{"mi":"if","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},{"mo":"-","mi":"tval"}],"mo":"<"}}]}]}}],"mo":"="}}}},"The parameter tval controls how the continuously-valued version of the Gabor wavelet is converted into a thresholded version that assumes values of \u22121, 0, or 1 only. The Threshold Gabor Wavelet has computational advantages because multiplication is not required to calculate the feature values. All of the adjustable parameters in the above equation are optimized for high recognition rate during the classifier development process.","A third possible feature set is Fuzzy Edge Symmetry Features, which is known in the art and shown in . Fuzzy edge symmetry attempts to classify objects based on the symmetries of their edges. The diagram shows an image containing vertical edges  and horizontal edges  being analyzed against both vertical axes  and horizontal axes , from both vertical projections  and horizontal projections , and across the fuzzy membership functions left , middle , and right , yielding (2 edge types)\u00d7(2 axes)\u00d7(2 projections)\u00d7(3 membership functions=24 dimensional feature.","The feature sets used can be selected by sorting against their importance for a classification task using any of a number of techniques known in the art including, but not limited to, using metrics such as mutual information or latent feature discovery models. The feature sets used for training the first-stage classifiers are different than those used to train the second-stage classifiers. For example, wavelet feature sets for a human\/non-human classification stage are shown in . An image of a potential human  is classified by analyzing, the image with Haar Wavelets  and Threshold Gabor Wavelets . Note the feature sets shown in  are only one example of features that can be used for object detection. As understood by one skilled in the art, the appropriate feature set to use for a given object will largely depend on the type of object being detected.","Once an object has been identified as a member of the human class, it is sent to a second-stage classifier to identify the object as a member of a predetermined specific-class. In this case, the predetermined specific-class is a human holding his arms vertically upward, as would a football referee signaling a touchdown.  shows an image of a potential football referee  and an example of a selection of wavelets  for specific object detection that have objective function values above a specified threshold.  is an illustration showing example poses for use with the second-stage of the method according to the present invention. The examples shown are a person holding their arms outward , a football player in a three-point stance , and a person running .","In order to achieve both high accuracy and speed, a classifier cascade as exemplified in  can be used instead of a single classifier. The cascade of classifiers filters out non-objects of interest in order to achieve both fast response and low false alarm rates. Each classifier is typically a neural network. Other non-limiting examples of classifiers include k-nearest neighbors, support vector machines, and decision trees. In the cascade shown, wavelet features  and edge symmetry features  are extracted from an analysis window . The wavelet features  are fed into a fast object classifier , which quickly sorts out non-objects and passes on potential objects to a slow classifier  which analyzes the wavelet features  in conjunction with edge symmetry features , Potential objects that pass this stage are then fed through a false alarm mitigator  and window diversity test  before being output as a detected object . By using less accurate but faster classifiers  in the early stages of the cascade, non-objects of interest images can be quickly rejected. Only candidate images with higher probability of being true objects of interest are passed on to the later more accurate but also more complex classifiers , , and . Further details regarding the classifier cascade shown in  as applied to cognitive swarms can be found in U.S. patent application Ser. No. 11\/367,755.","Plots of an experimental detection rate versus false alarm rate for the two-stage classification method of the present invention are shown in .  shows the optimal performance point  of a human\/non-human classifier stage while  shows the performance of the combination of the two classifier cascades (a human\/non-human classifier followed by a specific pose\/non-pose classifier). A combination of Haar wavelet, edge-symmetry features, threshold Gabor wavelet features, and a neural network classifier were used to obtain the results.","The detailed algorithm flow for the two-stage detection system is shown in . After loading a video image frame , previously-tracked humans are first detected using local human-classifier cognitive swarms  that were assigned in the previous frame. Any local swarms that are not able to find a human are deleted . A global human-classifier swarm  is then used to find any new humans that may have entered the scene. Local swarms are assigned to any new humans . Humans in a specific pose are then detected  using local pose-classifier cognitive swarms that search the local regions around the humans or, alternatively, by a simple scanning search performed in the local vicinity of the humans. The local search method which is used depends on the localization accuracy of the human-classifier cognitive swarms. If the uncertainty is relatively large, then local pose-classifier cognitive swarms should be used. An image must pass through both the human and pose detection stages in order to be recognized as a specific-class object. A visual, audio, or tactile alert is issued when a specific-class object is detected . An illustration showing detection of a human  in a crowd holding their arms vertically upward is shown in .","(3) System for Automated Response to Detected Objects","The present invention further incorporates the methods described above into a system for display of and automated response to, detected objects.  provides a detailed view of the system components. The sensor subsystem  consists of the optical sensors  used to detect the objects of interest . The sensor subsystem  could consist of a single optical sensor , or an array of multiple sensors (e.g., cameras). One possible array of cameras is an array of six cameras, each with 60 degrees field of view, to provide full coverage across 360 degrees. The images sensed by the cameras are fed into a processing: subsystem , where the computer vision algorithms described in section (2.0) above are used to detect and identify objects of interest . If multiple sensors are used, the system will also require a networked array of multiple computers  processing the camera images in parallel. The multiple computers  can be connected with a master processor for coordinating results from the network of data processors. When objects of interest are detected, their locations are sent to the two output subsystems (i.e., the automated response subsystem  and the display subsystem ).","The automated response subsystem  is an optional component of this system. There may be situations in which a response to identified objects is needed faster than human operators will be able to react to any alert. Non-limiting examples of an automated response subsystem can be automatically re-directing cameras to the location of a recent play in a sporting event, automated contact with law enforcement upon detection of unauthorized personnel, or automated locking\/unlocking of doors in a building.","Another system component, as shown in , is the display system . Once an object of interest is detected, the system has to inform the operators of the location of the detected object. This information must be presented so it is intuitively and rapidly perceived with minimal cognitive effort. This can be a difficult task in situations where the system is mounted on a rapidly moving: vehicle. Typical existing methods of presenting relative location information through synthesized speech will be invalid the moment the vehicle changes direction or even continues forward for a significant distance. Instead, a graphical display method that continuously updates the object location  relative to the rapidly moving vehicle is required.","One display option is to illuminate the object with a spotlight. Another display option is to use Augmented Reality technologies to display the object location through personal head-worn displays  worn by the operators, as shown in . The object  is detected and located relative to the operator's current position. For the case of multiple operators in a single moving vehicle, each operator's display is tracked, so that their positions and orientations with respect to the vehicle are known. Thus, the system has enough information to draw a highlight  in the display directly over where the operator sees the object  in the real world.","A third and more conventional display approach is to display the object information in a head-down display or on a small flat panel display, such as a personal digital assistant (PDA). Possible implementations include two-dimensional (2-D) and three dimensional (3-D) versions of such a display, as shown in , respectively. Both versions render the object position  and the operator's location  from a \u201cGod's eye\u201d perspective (or any other suitable perspective). The operators can quickly look at either version and understand where the object is relative to their own position. These displays can be continuously updated for use in situations where an operator is continuously changing position or orientation.","The data processing system  in  is further illustrated in  in generic form. The data processing system  comprises a memory  and a processor  (or a plurality of processors). The processor(s)  is configured to receive video input  and output detected object locations . The system is further configured to perform the acts of the method of the present invention, including: searching for members of a predetermined general-class of objects in an image, detecting members of the general-class of objects in the image, selecting regions of the image containing detected members of the general-class of objects, searching for members of a predetermined specific-class of objects within the selected regions, detecting members of the specific-class of objects within the selected regions of the image, and outputting the locations of detected objects to an operator display unit and optionally to an automatic response system. While the data processing system  can be configured for specific detection of humans in certain poses, the system  also can be configured for generic object detection.","Finally and as illustrated in , the present invention also comprises a computer program product . The computer program product  comprises computer readable instruction means encoded thereon for causing the data processing system to perform the operations described herein. The term \u201cinstruction means\u201d as used with respect to this invention generally indicates a set of operations to be performed on a computer (or computers), and may represent pieces of a whole program or individual, separable, software modules. Non-limiting examples of \u201cinstruction means\u201d include computer program code (source or object code) and \u201chard-coded\u201d electronics (i.e., computer operations coded into a computer chip). The \u201cinstruction means\u201d may be stored in the memory of a computer or on a computer-readable medium such as a floppy disk, a CD-ROM, and a flash drive. The computer program product  shown in  is an optical disk such as a CD or DVD. However, the computer program product  generally represents computer-readable instructions stored on any compatible computer-readable medium."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The objects, features and advantages of the present invention will be apparent from the following detailed descriptions of the various aspects of the invention in conjunction with reference to the following drawings, where:",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1B"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 8B"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 13A"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 13B"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 15"}]},"DETDESC":[{},{}]}
