---
title: Managing nodes of a synchronous communication conference
abstract: A system and methods for managing nodes of a synchronous communication conference are disclosed. In some embodiments, the system includes one or more processors that receive a mute request from a second conferencing node to mute a first synchronous communication data stream designated for transmission to a first conferencing node. The one or more processors generate a mute authorization request for requesting authorization for the mute request from a third conferencing node and transmit the mute authorization request to the third conferencing node for display by the third conferencing node.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08754926&OS=08754926&RS=08754926
owner: Google Inc.
number: 08754926
owner_city: Mountain View
owner_country: US
publication_date: 20111129
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The present disclosure relates to electronic communication. In particular, the present disclosure relates to managing nodes of a synchronous communication conference.","The popularity and use of video conferencing and other types of electronic communication have grown dramatically in recent years. Traditionally, video conferencing has been somewhat akin to audio conferencing, where participants communicate symmetrically by taking turns speaking, and thus facilitate discussion and negotiation of issues and reduce interruptions and distractions that may otherwise of occur if several participants were to converse in the video conference at the same time. In some cases, participants have muted their own audio and video signals so as not to accidentally interrupt to those actively conversing in the video conference or to prevent the other participants in the video conference from hearing or seeing what they are saying or doing.","Present implementations have been limited in providing a mechanism for participants to communicate asymmetrically during a video conference and allow groups of participants to interact privately or discuss different topics at the same time. For example, in a video conference between multiple parties, remote participants of one party wanting to privately discuss strategy or sensitive topics may be forced to leave the video conference in order to be able to discuss these matters in private. In another example, the participants of one party in a video conference may have to resort to using separate forms of communication, such as a separate conference call or email, to keep other participants from hearing and\/or seeing their communications.","The present disclosure overcomes the deficiencies and limitations of the related art at least in part by providing a system and associated methods for managing nodes of a synchronous communication conference. In one innovative aspect, the system includes one or more processors that receive a mute request from a second conferencing node to mute a first synchronous communication data stream designated for transmission to a first conferencing node. The one or more processors generate a mute authorization request for requesting authorization for the mute request from a third conferencing node and transmit the mute authorization request to the third conferencing node for display by the third conferencing node.","In another innovative aspect, a method includes receiving a mute request from a second conferencing node to mute a first synchronous communication data stream designated for transmission to a first conferencing node. A mute authorization request for requesting authorization for the mute request from a third conferencing node is generated and transmitted to the third conferencing node for display by the third conferencing node. In some embodiments, a mute authorization response is received from the third conferencing node and the first synchronous communication data stream designated for the first conferencing node is muted based at least in part on the mute request and the mute authorization response.","Other innovative aspects described include corresponding systems, methods and apparatus, including computer program products.","Overview","In one embodiment, a system and methods for managing a synchronous communication conference are described. In one aspect, the method includes receiving a mute request from a second conferencing node to mute a first synchronous communication data stream designated for transmission to a first conferencing node. A mute authorization request for requesting authorization for the mute request from a third conferencing node is generated and transmitted to the third conferencing node for display by the third conferencing node. In some embodiments, a mute authorization response is received from the third conferencing node and the first synchronous communication data stream designated for the first conferencing node is muted based at least in part on the mute request and the mute authorization response.","To illustrate an embodiment described above, users , and are participating in a synchronous communication conference, such as an audio-video conference call, and all three parties are communicating with one another. User wants to have a private conversation with user and therefore sends a mute request to the server to mute user . To obtain permission from user to mute user , the server generates and sends a mute authorization request to user . In some embodiments, the mute authorization request is displayed as a prompt on the conferencing screen and viewable only by user . User responds by sending a mute authorization response to the server, for example by selecting a prompt authorizing the mute request. The server then mutes (e.g., augments) the stream being sent to user to prevent user from hearing and\/or seeing users and ","In another aspect, the method includes receiving a mute request to mute a first conferencing node unassociated with a connected group of two or more users and transmitting a mute authorization request to one or more second conferencing nodes associated with the connected group of two or more users. A mute authorization response is received from the one or more second conferencing nodes and a first synchronous communication data stream designated for the first conferencing node is muted based at least in part on the mute request and the mute authorization response.","To illustrate this other aspect, several users are participating in a synchronous communication conference, such as an audio-video conference call. A subset of these users forms a connected group of users. In some embodiments, this group represents a social circle of a social network. The group wants to have a private conversation and thereby wants to prevent those users who are unassociated with the group from hearing\/viewing the conversation. Accordingly, the server receives a mute request requesting the server mute the audio-video data streams designated to be received by the nodes that are unassociated with the group. The server seeks authorization for the mute request from at least one node associated with the group by sending a mute authorization request to that node. In some embodiments, a node associated with the group can authorize the mute request on behalf of all of the other nodes associated with the group. In other embodiments, all of nodes must provide authorization. Upon receiving the mute authorization response from a node associated with the group, the server mutes the streams being sent to the nodes of the users who are unassociated with the group to prevent those users from hearing and\/or seeing the connected users.","System Overview",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1","b":["100","100","101","105","115","115","115","115","115","125","125","125","125","125","120","101","115","120","105","100","105","101"],"i":["a","b","c ","n ","a","b","c ","n "]},"The social network server  is a server for providing a social networking service. In the depicted embodiment, the social network server  is coupled to the network  via signal line . The social network server  may include one or more processors and one or more storage devices storing data or instructions for execution by the one or more processors. For example, the social network server  is a server, a server array or any other computing device, or group of computing devices, having data processing, storing and communication capabilities. The social network server  may also be a virtual server (i.e., a virtual machine) implemented via software. For example, the virtual server operates in a host server environment and accesses the physical hardware of the host server including, for example, a processor, memory, storage, network interfaces, etc., via an abstraction layer (e.g., a virtual machine manager). The social network server  interacts with the other entities , , . . . , and  via the network . It should be understood that the social network server  can be stored in any combination of devices and servers or in one device or server.","The social network server  includes a social network application engine , a synchronous communication engine , and a social graph . The social network application engine  is software including routines for providing functionality for a social network. In some embodiments, the social network application engine  is a set of instructions executable by the processor  (see ) for providing the functionality for the social network. In other embodiments, the social network application engine  is stored in the memory  (see ) of the social network server  and is executable by the processor  (see ). In any of these embodiments, the social network application engine  may be adapted for cooperation and communication with the processor  (see ) and the other components of the social network server  via the bus  (see ). Although only one social network server  is shown, multiple social network servers  may be included in the system .","A social network is any type of social structure where the users are connected by one or more common features. The common features include relationships\/connections, e.g., friendship, family, work, an interest, etc. The common features are provided by one or more social networking systems, such as those included in the system , including explicitly-defined relationships and relationships implied by social connections with other online users, where the relationships form a social graph .","In some examples, the social graph  can reflect a mapping of these users and how they are related. Furthermore, it should be understood that social network server  and social network application engine  are representative of one social network and that there may be multiple social networks coupled to the network , each having its own server, application and social graph . For example, a first social network is more directed to business networking, a second more directed to or centered on academics, a third more directed to local business, a fourth directed to dating and others of general interest or a specific focus. In some embodiments, the social graph  includes a data repository and a set of instructions executable by the processor  to provide the functionality described herein. In other embodiments, the social graph  is stored in the memory  of the social network server  and is accessible and executable by the processor  to provide this functionality. In any of these embodiments, the social graph  may be adapted for cooperation and communication with the processor  and other components of the social network server  via the bus . In yet other embodiments, the social graph  is server hardware and a data repository for managing the data describing the social graphs of the users of various social networks including the social network represented by the social network server  and the social network application engine . In these other embodiments, the social graph  may be coupled to the social network server  via the network  or via a direct data connection for interaction with the social network server .","The synchronous communication engine  is software including routines for managing a synchronous communication conference between a plurality of conferencing nodes . In the depicted embodiment, the synchronous communication engine  is included in and operable on the social network server . However, in practice, any of the depicted devices as well as other devices such as third-party servers could include the synchronous communication engine . A synchronous communication conference herein encompasses its plain and ordinary meaning, including, but not limited to a conference between two or more conferencing nodes  for sharing information synchronously with one another. The synchronous communication conference may include one or more of an audio-video conference, a web conference, a multi-directional webinar, a collaboration session for sharing information, such as documents, computer environments, images, electronic communications, etc. In some embodiments, groups of two of more conferencing nodes  may communicate asymmetric to one another, allowing for those groups to communicate privately or semi-privately within the synchronous communication conference. The synchronous communication conference may be limited to a particular period of time or may persist indefinitely and may allow conferencing nodes  to become active and inactive over various time periods. In some embodiments, each conferencing node of the synchronous communication conference sends and receives a synchronous communication data stream. A synchronous communication data stream herein encompasses its plain and ordinary meeting, including, but not limited to one or more of an audio-video data stream, a media data stream, supplemental audio and\/or video data stream, etc. The synchronous communication data stream may be comprised of a single data stream or multiple data streams of different types. The synchronous communication data stream includes synchronous communication data. Synchronous communication data herein encompasses its plain and ordinary meeting, including, data representing the information being sent and\/or received by a conferencing node participating the synchronous communication conference. The synchronous communication data may include audio-video data, data representing any type of media including documents, images, text, electronic communications, data representing a computing environment, such as screen shots or a shared desktop or dashboard, etc. Additional structure and functionality of the synchronous communication engine  are described below with reference to at least .","The user devices , , . . . (also referred to herein as conferencing nodes) are computing devices having data processing and data communication capabilities. In some embodiments, the user devices  are capable of conferencing (e.g., video conferencing) with one another and with other devices via the synchronous communication engine  as discussed in further detail below. A user device  may be a handheld wireless computing device which is capable of sending and receiving voice and data communications. For example, the user device  may include a processor, a memory, a power source and one or more network interfaces to broadcast and receive data via radio signals. The processor communicates with the other components of the user device  via a data communications bus and may include an arithmetic logic unit, a microprocessor, a general purpose controller or some other processor array to perform computations and optionally provide electronic display signals to a display device. The memory stores instructions and\/or data that may be executed by processor and may include non-volatile and\/or volatile memory.","The user device  may also include one or more of a graphics processor; a high-resolution touchscreen; a physical keyboard; forward and rear facing cameras; sensors such as accelerometers and\/or gyroscopes; a GPS receiver; a Bluetooth module; memory storing applicable firmware; and various physical connection interfaces (e.g., USB, HDMI, headset jack, etc.); etc. Additionally, an operating system for managing the hardware and resources of the user device , application programming interfaces (APIs) for providing applications access to the hardware and resources, a user interface module for generating and displaying interfaces for user interaction and input, and applications such as applications for video conferencing, making phone calls and video calls, web browsing, messaging, social networking, gaming, capturing digital audio, video and\/or images, processing data, etc., may be stored and operable on the user device . A user device  may be a workstation computer, a desktop computer, a laptop computer, a netbook computer, a tablet computer, a smartphone, a set-top box\/unit, a TV with one or more processors embedded therein or coupled thereto and capable of receiving viewer input, accessing video content on computer networks such as the Internet, and executing software routines to provide enhanced functionality and interactivity to viewers, or the like. In some embodiments, different user devices , , . . . may be different types of computing devices. For example, the user device is a smartphone, the user device is a laptop computer and the user device is a tablet computer. In some embodiments, the user device  is a client or terminal device. The user devices , , . . . in  are included by way of example and the present disclosure applies to any system architecture having one or more user devices.","In some embodiments, the user device is coupled to the network  via signal line  and user interacts with the user device via signal line ; the user device is coupled to the network  via signal line  and the user interacts with the user device via signal line ; the user device is coupled to the network  via signal line  and the user interacts with the user device via signal line ; and the user device is coupled to the network  via signal line  and the user interacts with the user device via signal line .","In the depicted embodiment, the user devices , , . . . include a conferencing application . The conferencing application  is software including routines for conferencing with other devices including user devices  (also referred to herein as conferencing nodes ) via the synchronous communication engine . In some embodiments, the conferencing application  is operable to instruct a user device  to render user interfaces, request and receive user input via the user interfaces, obtain and transmit location data, capture video and audio of the user real-time, generate an audio-video data stream from the video and audio being captured real-time and transmit the audio-video data stream to the synchronous communication engine  for distribution to other conferencing nodes  participating in a conference being managed by the synchronous communication engine , collaborate and share media such as documents, text, audio, video, pictures, hypermedia, etc., with other conferencing nodes  participating in the conference, capture and share the computing environment, allow for control of computing environment by other conferencing nodes, etc.","In some embodiments, the conferencing application  is a set of instructions executable by a computer processor (not shown) to provide the functionality described herein. In other embodiments, the conferencing application  is stored in volatile and\/or non-volatile computer memory (not shown) of the user device and is accessible and executable by a computer processor (not shown) to provide the functionality described herein. In any of these embodiments, the conferencing application  may be adapted for cooperation and communication with the computer processor (not shown) and other components of the user device  via a communication bus (not shown) for transferring data between components of the user device . While  illustrates each of the user devices , , . . . as including the conferencing application , in practice, any number of user devices  could include these elements and be coupled to the network .","The conferencing application  may include a user interface engine (not shown) for rendering user interfaces and for receiving user input via the user interfaces. The user interface engine may be a set of instructions executable by a processor (not shown) of the user device or may be stored in a memory (not shown) of the user device and be accessible and executable by the processor, and may be adapted for cooperation and communication with the processor (not shown) and other components of the user device  via a bus. The user interface engine may be is coupled to an input device via the bus to receive input signals from a user . For example, a user  may enter or modify a mute request, define parameters associated with mute request and set user settings by selecting user interface elements included in a user interface rendered by the user interface engine using the input device, and the user interface engine interprets the signals received from the input device relays them for further processing by the conferencing application . The user interfaces generated by the user interface engine can include those described with reference . The user interfaces generated and displayed by the conferencing application  may include user interface elements that allow users  to interact with the user device  and input information and commands, such as text entry fields, selection boxes, drop-down menus, buttons, virtual keyboards and numeric pads, etc. In one example, a dialog for submitting a mute request includes input fields, such as drop-down menus, for inputting the mute parameters. In defining the mute request, a user  can, for example, select from social circles of the user 's social graph retrievable from the social graph . The user interface engine may generate this drop-down menu by querying the social graph  of the social network for all of the social circles defined by the user  of the user device  and populating the drop-down menu with the social circles. As an example, a user 's social circles may include family, friends, acquaintances, work contacts, etc. from his or her contacts on the social network.","The conferencing application  may interact with audio and video capture devices of the user device  to obtain a real-time audio-video synchronous communication data stream of the user . For example, the conferencing application  interfaces with a software driver stored on the user device  that controls the functionality of a microphone and a video camera (e.g., a webcam or forward facing camera) included in the user device . The audio-video data stream captured by a user device may be encoded using various audio and video codecs and then encapsulated into a container. The audio and video codecs and container formats may be open or proprietary, and may include the codecs and formats discussed below with reference to the stream generation module , for example. Additional structure and functionality of the conferencing application  is discussed below with reference to , for example.","The network  is wired or wireless network and may have any number of configurations such as a star configuration, token ring configuration or other known configurations. The network  may include a local area network (LAN), a wide area network (WAN) (e.g., the Internet), and\/or any other interconnected data path across which multiple devices may communicate. The network  may be coupled to or include a mobile (cellular) network including distributed radio networks and a hub providing a wireless wide area network (WWAN), or other telecommunications networks. In some embodiments, the network  may include Bluetooth communication networks for sending and receiving data. The network  may transmit data using a variety of different communication protocols including user datagram protocol (UDP), transmission control protocol (TCP), hypertext transfer protocol (HTTP), dynamic adaptive streaming over HTTP (DASH), real-time streaming protocol (RTSP), real-time transport protocol (RTP) and the real-time transport control protocol (RTCP), short messaging service (SMS), multimedia messaging service (MMS), direct data connection, wireless access protocol (WAP), voice over Internet protocol (VOIP), various email protocols, etc. User devices  may couple to and communicate via the network  using a wireless and\/or wired connection. In some embodiments, the user devices  include a wireless network interface controller for sending and receiving data packets to an access point of the network . For example, the user devices  may be Wi-Fi enabled devices which connect to wireless local area networks (WLANs), such as wireless hotspots, communicatively coupled to the network . The user devices  may also include one or more wireless mobile network interface controllers for sending and receiving data packets via a WWAN of the network .","In some embodiments, the mobile network portion of the network  and user devices  may use a multiplexing protocol or a combination of multiplexing protocols to communicate including frequency division multiple access (FDMA), time-division multiple access (TDMA), code division multiple access (CDMA), space division multiple access (SDMA), wavelength division multiple access (WDMA) and random access protocols, or any derivative protocols such as orthogonal frequency division multiple access (OFDMA), orthogonal frequency-hopping multiple access (OFHMA), etc. The mobile network portion of the network  and user devices  may also employ multiple-input and output (MIMO) channels to increase the data throughput over the signal lines coupling the mobile portion of the network  and user devices . The mobile portion of the network  may be any generation mobile phone network, such as a 2G or 2.5G Global System for Mobile Communications (GSM), IS-95, etc., network; a 3G (Universal Mobile Telecommunications System) UTMS, IS-2000, etc., network; a 4G Evolved High-Speed Packet Access (HSPA+), 3GPP Long Term Evolution (LTE), Worldwide Interoperability for Microwave Access (WiMax\u2122), etc., network; or a hybrid network combining one or more of the foregoing network types.","The position determination system  is a system for determining the geographic location of the user devices . In some embodiments, the position determination system  provides positioning signals to electronic devices configured to receive the signals. The position determination system  may be configured to provide the signals to these devices located anywhere in the world or within prescribed geographic regions. In some embodiments, the position determination system  includes control computers which send and receive control signals via ground antennas to a plurality of strategically positioned satellites located in orbit above the Earth. User devices  may include receivers that receive positioning signals from several of the satellites of the position determination system , and software executable by a computer processor (not shown) of the user devices  processes the positioning signals to determine the geographic location of the user devices  and generates location data describing this geographic location. The position determination system  may also include reference stations located on the ground that provide signals in cooperation with the satellites to improve accuracy, or may be comprised entirely of ground-based reference stations which provide positioning signals for user devices  or a computing station to utilize to determine a geographic location of the user devices . In these or other embodiments, the position determination system  may receive information from other sources, such as the user device  or the network , to improve performance, accuracy, time-to-fix location, etc. For example, the position determination system  could be a global positioning system (GPS), a differential global positioning system (DGPS), an assisted global positioning system (A-GPS), etc. In some embodiments, the conferencing application  is configured to interact with the position determination system , for example, via an application programming interface (API), to receive the location data and transmit the location data to the synchronous communication engine .","It should be understood that the present disclosure is not limited the above-described embodiments of the position determination system , and that any system which is capable of providing location data of the user devices  is contemplated and within the scope of the present disclosure. For example, the position determination system  could include any device location-tracking system, such as constellation systems like \u201chiball,\u201d magnetic tracking systems, optical tracking system, inertial tracking systems, etc. In another example, a geolocation engine (not shown) for determining the geographic location of user devices  may be stored and operable on the position determination system  or another computing device coupled to the network  for communication with the other entities of the system . For example, while not depicted, the geolocation engine may be included in the social network server , the network  and\/or the user devices . In some embodiments, the geolocation engine is configured to determine the geographic location of user devices  based at least on identifying information associated with the user devices. For example, the geolocation engine is capable of determining an approximate geolocation of a user device  using an IP address of a user device  on the network  by cross-referencing the IP address with other information sources, such as internet server provider databases, internet registries, etc. In other embodiments, the geolocation engine processes signaling information transmitted between the user device  and a plurality of transmission nodes of the mobile network using multilateration or triangulation to determine the geographic location of a user device . In these embodiments, the conferencing application  is configured to interact with the geolocation engine, for example, via an API, to receive the location data and transmit the location data to the synchronous communication engine .","Social Network Server ",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 2","b":["101","101","102","103","106","230","232","234","236","102","103","106","230","232","234","236","220","220"]},"The processor  includes an arithmetic logic unit, a microprocessor, a general purpose controller or some other processor array to perform computations and provide electronic display signals to a display device (not shown). The processor  is coupled to the bus  for communication with the other components of the social network server . Processor  processes data signals and may include various computing architectures including a complex instruction set computer (CISC) architecture, a reduced instruction set computer (RISC) architecture, or an architecture implementing a combination of instruction sets. Although only a single processor  is shown in , multiple processors may be included. The processing capability might be sufficient to supporting the display of images and the capture and transmission of images or to perform more complex tasks, including various types of feature extraction and sampling. It should be understood that other processors, operating systems, sensors, displays and physical configurations are possible.","The memory  stores instructions and\/or data that may be executed by processor . The memory  is coupled to the bus  for communication with the other components of social network server . The instructions and\/or data may include code for performing any and\/or all of the techniques described herein. The memory  may be a dynamic random access memory (DRAM) device, a static random access memory (SRAM) device, flash memory or some other known memory device. In some embodiments, the memory  also includes a non-volatile memory or similar permanent storage device and media including, for example, a hard disk drive, a floppy disk drive, a CD-ROM device, a DVD-ROM device, a DVD-RAM device, a DVD-RW device, a flash memory device or some other mass storage device known for storing information on a more permanent basis. For clarity, instructions and\/or data stored by the memory  are described herein as different functional \u201cmodules\u201d or \u201cengines,\u201d where different modules or engines are different instructions and\/or data stored in the memory  that cause the described functionality when executed by the processor .","The communication unit  is coupled to the network  by the signal line  and coupled to the bus . The communication unit  may be a network interface device (I\/F) which includes ports for wired or wireless connectivity. For example, the communication unit  includes an 802.11-compliant wireless network interface, a CAT-5 interface, USB interface, or SD interface, etc. The communication unit  links the processor  to the network  that may in turn be coupled to other processing systems. The communication unit  provides other connections to the network  and to other entities of the system  (e.g., the SMS gateway ) using standard communication protocols including, for example, UDP, TCP, HTTP, HTTPS, SMTP, RTSP, RTP, RTCP, session initiation protocol (SIP), SMS, MMS, XMPP, etc. In some embodiments, the communication unit  includes a transceiver for sending and receiving signals using Bluetooth\u00ae or cellular communications for wireless communication.","Synchronous Communication Engine ","The description of the synchronous communication engine  and methods - includes describing a plurality of conferencing nodes  and a plurality of synchronous communication data streams. To ease the description of these elements, they are categorized using the labels first, second, third, etc. These labels are intended to help to distinguish the nodes  and streams but do not necessarily do not necessarily imply any particular order or ranking unless indicated otherwise.","The synchronous communication engine  is software including routines for managing a synchronous communication conference between a plurality of conferencing nodes . In some embodiments, the synchronous communication engine  is a set of instructions executable by the processor  to provide the synchronous communication conferencing functionality. In other embodiments, the synchronous communication engine  is stored in the memory  of the social network server  and is accessible and executable by the processor  to provide this functionality. In any of these embodiments, the synchronous communication engine  may be adapted for cooperation and communication with the processor  and the other components of the social network server  via the bus . In some embodiments, the synchronous communication engine  manages the establishment of a synchronous communication conference between a plurality of conferencing nodes , receives and sends management data to and from the conferencing nodes , and is capable of receiving, combining, splitting, muting and sending synchronous communication data streams including audio, video, rich media, images, text, etc., to and from the conferencing nodes .","In the depicted embodiment, the synchronous communication engine  includes a stream receiver , a stream transmitter , a stream generation module , a communication module , a parameter module , an authorization module , an association module  and a mute module . The components , , , , , ,  and  of the synchronous communication engine , and the synchronous communication engine  itself, are communicatively coupled to the bus  for communication with each other and the other components , , , ,  and  of the social network server . The synchronous communication engine  interacts and communicates with the social network application engine  via the bus . For example, the synchronous communication engine  can interact with a credentials module (not shown) of the social network application engine  to authenticate users  seeking access to the synchronous communication engine , and to provide the synchronous communication engine  access to information and functionality of the social network application engine  and the social graph . In some embodiments, the synchronous communication engine  is stored and operable on a third-party server (not shown) which is coupled by the network  for communication and interaction with the social network server , the social network application engine  and the social graph . In these embodiments, the synchronous communication engine  may access information and utilize the functionality of the social network application engine  and the social graph  via an API.","The stream receiver  is software including routines for receiving synchronous communication data streams being transmitted by user devices\/conferencing nodes , and relaying the synchronous communication data streams to the stream generation module . In some embodiments, the stream receiver  is a set of instructions executable by the processor  to provide this functionality. In other embodiments, the stream receiver  is stored in the memory  of the social network server  and is accessible and executable by the processor  to provide this functionality. In any of these embodiments, the stream receiver  may be adapted for cooperation and communication with the processor  and other components of the social network server  via the bus .","The stream receiver  may be coupled to the communication unit  via the bus  to receive the synchronous communication data streams being sent by conferencing nodes . In some embodiments, the stream receiver  modifies the synchronous communication data streams as they are being received to prepare them to being combined by the stream generation module . For example, for a synchronous communication data stream being received that includes an audio-video data stream, the stream receiver  un-packages the audio and video data from a container of the stream, un-compresses, compresses, transcodes, etc., the audio and\/or video data and sends the audio and video data of the stream to the stream generation module  for further processing. The stream receiver  may perform similar operations on other types of data\/data streams included in the synchronous communication data streams. In other embodiments, the stream receiver  relays the synchronous communication data streams directly to the stream generation module .","The stream transmitter  is software including routines for transmitting combined synchronous communication data streams to one or more conferencing nodes  participating in a synchronous communication conference (e.g., video conference) being managed by the synchronous communication engine . In some embodiments, the stream transmitter  is a set of instructions executable by the processor  to provide the functionality described herein. In other embodiments, the stream transmitter  is stored in the memory  of the social network server  and is accessible and executable by the processor  to provide this functionality. In any of these embodiments, the stream transmitter  may be adapted for cooperation and communication with the processor  and other components of the social network server  via the bus .","The stream transmitter  may be coupled to the stream generation module  via the bus  to receive the combined synchronous communication data streams generated by the stream generation module . In some embodiments, the stream transmitter  transmits the combined synchronous communication data streams to the participating conferencing nodes  using a multicast delivery system, which may utilize optimal data transmission paths for the most efficient delivery of the data streams to the participating conferencing nodes . In other embodiments, the stream transmitter  transmits the combined synchronous communication data streams using a unicast or anycast delivery system.","The stream generation module  is software including routines for combining synchronous communication data streams. The synchronous communication data streams combined by the stream generation module  may be received from two or more conferencing nodes  participating in a synchronous communication conference (e.g., video conference) being managed by the synchronous communication engine . In some embodiments, the stream generation module  is a set of instructions executable by the processor  to provide this functionality. In other embodiments, the stream generation module  is stored in the memory  of the social network server  and is accessible and executable by the processor  to provide this functionality. In any of these embodiments, the stream generation module  may be adapted for cooperation and communication with the processor  and other components of the social network server  via the bus .","The stream generation module  can generate a combined synchronous communication data stream for each of the conferencing nodes  participating in the synchronous communication conference and provide the combined synchronous communication data streams to the stream transmitter  for transmission to the conferencing nodes , respectively. In some embodiments, a combined synchronous communication data stream may be generated by the stream generation module  by combining two or more synchronous communication data streams being received in a single container file to encapsulate data streams. In some embodiments, the container encapsulates and organizes the synchronous communication data streams using metadata so they can later be decoded and presented by the conferencing application  operating on a conferencing node .","In some embodiments, when generating  a combined synchronous communication data stream, the stream generation module  manipulates the synchronous communication data streams being combined. For example, the stream generation module  may decode and encode the synchronous communication data streams, decrypt and encrypt the synchronous communication data, compress the synchronous communication data, or may transcode the synchronous communication data (e.g., audio-video data) into different formats. In some embodiments, an audio component of each synchronous communication data stream (e.g., audio-video data stream) being combined may be mixed by the stream generation module  into one and used for all of the video components. The transcoding performed by the stream generation module  may be lossy or lossless and may convert the encoding of the synchronous communication data streams from any format to any other format using various known audio and video codes. Example audio formats include ACC, MP3, Vorbis, etc., and example video formats include MPEG-4, H.264, Theora, VP8, etc. The container file used by the stream generation module  may package the synchronous communication data streams or data streams, such as audio-video data streams, included in the synchronous communication data streams in any known format including FLV, WebM, ASF, ISMA, etc. In other embodiments, the transcoding may be performed by other modules of the synchronous communication engine , such as the stream receiver , as previously described, or may be performed by other entities of the system  such as the conferencing nodes .","In some embodiments, each of the combined synchronous communication data streams generated by the stream generation module  includes synchronous communication data received from each of the conferencing nodes  of the synchronous communication conference (e.g., video conference) other than the conferencing node  for which the combined synchronous communication data stream is designated to be received by. For example, in a video conference with users , and , the combined synchronous communication data stream generated for user includes the synchronous communication data streams (e.g., audio-video data streams) captured and provided by users and , the combined synchronous communication data stream generated for user includes the synchronous communication data streams captured and provided by users and , and the combined synchronous communication data stream generated for user includes the synchronous communication data streams captured and provided by users and . In other embodiments, the same combined synchronous communication data stream is generated  the for the participating conferencing nodes  by combining the synchronous communication data streams received from all the participating nodes . The stream generation module  may be communicatively coupled to the stream receiver  via the bus  to receive the synchronous communication data\/data streams being provided by the conferencing nodes  and may be communicatively coupled to the stream transmitter  via the bus  to transmit the combined synchronous communication data streams to the conferencing nodes .","The communication module  is software including routines for sending and receiving data via the communication unit  to the other entities of the system , and interacting with the other components of the synchronous communication engine . In some embodiments, the communication module  is a set of instructions executable by the processor  to provide this functionality. In other embodiments, the communication module  is stored in the memory  of the social network server  and is accessible and executable by the processor  to provide this functionality. In any of these embodiments, the communication module  may be adapted for cooperation and communication with the processor  and other components of the social network server  via the bus .","The communication module  may be communicatively coupled to the communication unit  via the bus  for sending and receiving data to and from conferencing nodes  associated with a synchronous communication conference (e.g., a video conference) being managed by the synchronous communication engine . For example, the communication module  receives mute requests, mute authorization responses, un-mute requests and un-mute authorization responses, etc., from conferencing nodes  and transmits mute authorization requests, un-mute authorization requests, etc., to conferencing nodes . A mute request is a request to mute synchronous communication data streams being provided by two or more conferencing nodes  and being received as a combined synchronous communication data stream by one or more conferencing nodes . A mute authorization response indicates whether permission for the mute request has been granted by the user  of the conferencing node  to which the mute authorization request was sent. In similar fashion, an un-mute request is a request by a conferencing node  receiving a muted combined synchronous communication data stream to have the stream un-muted. An un-mute authorization response requests authorization for the un-mute request from a user  of a conferencing node  capable of providing authorization. An un-mute authorization response indicates whether permission for the un-mute request has been granted by the user  of the conferencing node  to which the un-mute authorization request was sent. In some embodiments, the communication module  is communicatively coupled via the bus  to the parameter module  to send request and response data (also referred to as management data) received from one or more conferencing nodes  for parsing and further processing by the parameter module . For example, the communication module  sends a mute request received from a second conferencing node  to the parameter module  and the parameter module  parses the mute request to verify its type and to determine the parameters of the mute request. In some embodiments, the communication module  may parse header information from the data to identify the type of data being received.","A mute request received by the communication module  may request that one or more (first) synchronous communication data streams respectively designated for one or more (first) conferencing nodes  participating in a synchronous communication conference be muted. The mute request may be intended by the initiator of the request to create a sub-conference within the synchronous communication conference that allows un-muted conferencing nodes  to interact privately without users of the muted conferencing nodes  being able to discern what is being communicated. The mute request may also request muting the synchronous communication data\/data stream(s), such as an audio-video data stream, being received from the one or more first conferencing nodes  to provide the other conferencing nodes  the benefit of not having to listen to and\/or see the user(s) of the first conferencing node(s) . The mute request may be an explicit request or an implicit request. A mute request may be considered to be explicit when it is determined to include express instructions to mute other conferencing nodes  participating in the synchronous communication conference. A mute request may be identified to be explicit from header information parsed by the communication module  identifying it as such, or by the parameter module  parsing mute parameters from the request. In some embodiments, an explicit mute request may include one or more mute parameters describing the individual identity or identities of the conferencing node(s)  to be muted, information identifying a connected group of users that are permitted to participate in the sub-conference, an instruction to mute the synchronous communication data streams being received by any conferencing nodes  unassociated with the group, or a combination of the foregoing. The explicit mute request may also include other parameters describing the scope and manner in which one or more first conferencing nodes  should be muted. A mute request may be considered to be implicit when the parameter module  interprets data it has received as being a mute request even though the data itself does not contain any express mute instructions. For example, the communication module  may receive location data from a second conferencing node  which identifies the geographic location of the second conferencing node  and is associated with mute parameters set by the user  of the second conferencing node . Explicit and implicit mute requests and mute parameters are further discussed below with reference to at least the parameter module  and  and A-D.","The parameter module  is software including routines for determining mute parameters associated with a mute request based at least in part on information associated with the mute request, and for generating and sending an instruction signal. The parameter module  is also configured to receive, store and provide mute parameters. In some embodiments, the parameter module  is a set of instructions executable by the processor  to provide this functionality. In other embodiments, the parameter module  is stored in the memory  of the social network server  and is accessible and executable by the processor  to provide this functionality. In any of these embodiments, the parameter module  may be adapted for cooperation and communication with the processor  and other components of the social network server  via the bus .","In some embodiments, the parameter module  is coupled to the communication module  via the bus  to receive management data from one or more conferencing nodes . To determine if the management data received from the communication module  includes an explicit mute request, the parameter module  may parse information associated with the management data, such as information accompanying the management data and provided by the communication module  or information included in a header or body of the management data, that identifies the management data as a mute request. If the management data is identified as being an explicit mute request, the parameter module  parses one or more mute parameters from the mute request describing how the mute request should be carried out. These or other additional mute parameters may also be predefined by a user , and the parameter module  is capable of associating the predefined mute parameters with the mute request based on unique identifying information associated with the mute parameters and the mute request.","As previously described, a mute request may be considered to be implicit when the parameter module  interprets data it has received as being a mute request even though the data itself does not contain express mute instructions. For example, if a user of a second conferencing node wishes to video conference with other conferencing nodes , . . . differently depending on the location in which the second conferencing node  is located, the user  can define mute parameters which set forth the conferencing node(s)  that should be muted in the different locations. In some embodiments, the parameter module  determines that an implicit mute request has been received by parsing the management data for location information and identifying one or more mute parameters associated with the parsed location data. The associated mute parameters may be identified by the parameter module  by querying the data store  for one or more mute parameters annotated with the location data. If one or more mute parameters are identified, the parameter module  considers the location data and the one or mute parameters to be an implicit mute request. The mute parameters for an implicit mute request may be the same as the mute parameters for an explicit mute request, or may differ from the parameters of an explicit mute request.","In some embodiments, a mute request is associated with mute parameters describing the initiator of the request (e.g., the second conferencing node), the first conferencing node(s)  to receive muted synchronous communication data stream(s), which components of the synchronous communication data stream(s) should be muted, and the manner in which the synchronous communication data streams should be muted. The first conferencing nodes  that are to be muted may be expressly or indirectly identified by a mute parameter. In some embodiments, a mute parameter expressly identifies the first conferencing node(s)  by listing identifying information associated with the conferencing node(s) , and indirectly identifies the first conferencing node(s)  by specifying a connected group of users of a social network. The parameter module , in cooperation with the association module  to which it is communicatively coupled via the bus , determines which conferencing nodes  participating in the synchronous communication conference are associated with a connected group of users, and which conferencing nodes  are unassociated with the connected group of users. For example, the parameter module  provides information identifying the connected group of users to the association module , and the association module  returns identifying information describing the conferencing nodes  participating in the synchronous communication conference that are unassociated and\/or associated with the connected group of users. In these other embodiments, the conferencing nodes  that are unassociated with the connected group of users are determined by the parameter module  to be the first conferencing nodes .","Mute parameters may also be previously defined by a user . For example, a user  may predefine mute parameters by inputting them into an interface of the conferencing application  for transmission via the network  to the synchronous communication engine . The parameter module  is coupled to the communication module  via the bus  to receive the mute parameters in the form of a parameter request and coupled to the data store  to store, update or delete mute parameters based at least in part on the instructions and mute parameters included in the parameter request. Responsive to receiving a request for the mute parameters via the communication module , the parameter module  may retrieve the mute parameters from the data store  and send them to the communication module  for transmission to the user device for display and\/or modification. In some embodiments, the parameter module  receives a mute request via the communication module  and queries the data store  for mute parameters based on identifying information included in the mute request. For example, the identifying information may be a unique identifier, such as a user identifier, associated with the user  who initiated the mute request.","The mute parameters stored in the data store  may be predefined by the user  to control any aspect or functionality associated with the muting performed by the synchronous communication engine . For example, a user  may predefine mute parameters, either for particular synchronous communication conferences (e.g., audio-video conferences) in which the user participates or globally, and the predefined parameters may describe the user 's preferences for muting the synchronous communication data streams of other conferencing nodes . As another example, a user  may predefine mute parameters for muting the audio-video data (i.e., synchronous communication data) that the user  is sending and is being received by others by obscuring the video data to show a silhouette of the user , completely blanking-out the audio or video data, replacing the video data with an image of the user , replacing the audio data with music or other audio data, etc.","In some embodiments, the parameter module  is coupled to the authorization module  via the bus  to send an instruction signal instructing the authorization module  to request authorization for the mute request. The parameter module  may generate and send the instruction signal to the authorization module  upon processing the management data for an explicit or implicit request and any associated mute parameters. The instruction signal may be generated to include information describing the mute request, such as which conferencing nodes  are participating in the synchronous communication conference and which conferencing nodes  are to be muted.","The authorization module  is software including routines for receiving an instruction signal, generating, sending and receiving authorization information based at least in part on the instruction signal, and generating a mute signal. In some embodiments, the authorization module  is a set of instructions executable by the processor  to provide this functionality. In other embodiments, the authorization module  is stored in the memory  of the social network server  and is accessible and executable by the processor  to provide this functionality. In any of these embodiments, the authorization module  may be adapted for cooperation and communication with the processor  and other components of the social network server  via the bus . The authorization module  is communicatively coupled via the bus  to the communication module  to send and receive authorization information to one or more conferencing nodes , to the parameter module  to receive the instruction signal, and to the mute module  to send the mute signal.","In in some embodiments, responsive to receiving an instruction signal from the parameter module , the authorization module  generates and sends a mute authorization request via the communication module  to one or more conferencing nodes . The instruction signal may include information describing the identity and location of the conferencing nodes  on the network, and may identify the one or more conferencing nodes  that are required to provide authorization for the mute request. In some embodiments, the authorization module  generates mute authorization requests based at least in part on information from the mute request and\/or the mute parameters associated with the mute request, which information is included in the instruction signal. For example, the instruction signal may include mute request and parameter information such as information describing the first conferencing nodes  to be muted, the second conferencing node  that initiated the mute request, other second and\/or third conferencing nodes  with which the second conferencing node  wants to engage in a private sub-conference with, the second conferencing nodes  associated with one or more connected groups of users, the first conferencing nodes  unassociated with the one or more connected groups of users, which components of the first synchronous communication data streams designated for the first conferencing node(s)  are to be muted, and\/or the manner in which the components of the data streams are to be muted, etc.; and the authorization module  may generate one or more mute authorization requests describing this information. In some embodiments, the mute authorization requests generated by the authorization module  may be the same for each of the conferencing nodes  designated to receive them, or may be customized for each of the conferencing nodes .","In some embodiments, to determine if a mute request is authorized, the authorization module  may only require a moderator node that is participating in the synchronous communication conference to provide authorization via a mute authorization response, or may require more than one conferencing node  designated to participate in a private sub-conference by virtue of the mute request, to provide authorization for the mute request. The authorization module  may determine a moderator node from mute parameters included in the instruction signal, predefined and stored in the data store  or identified by information provided by the social graph . By way of example, if a second conferencing node  sends a mute request requesting that the synchronous communication data stream(s) being received by one or more first conferencing node(s)  be muted so that the second conferencing node  may form a private sub-conference with a plurality of third conferencing nodes , the authorization module  may generate and send a mute authorization request to one of the third conferencing nodes  having authority to approve the mute authorization request on behalf of the other third conferencing nodes ; or may generate and send a mute authorization request to each of the third conferencing nodes  requesting approval for the mute request. The user  of the second conferencing node  may also want to include other users  participating in the synchronous communication conference that belong to a connected group, and defines the connected group of users in a parameter of the mute request or in a supplemental mute request intended to expand the original mute request. Upon receiving and processing the mute request(s), the instruction signal received from the parameter module  may identify the other second conferencing nodes  associated with the connected group of users and\/or a moderator node that acts as a moderator for the group. The authorization module  generates a mute authorization request for the moderator node or for each of the second conferencing nodes  other than the initiator of the mute request, and then transmits the mute authorization request(s) to the corresponding nodes(s). In other embodiments, the conferencing node that initiated the request is also the moderator for the connected group of users, and the authorization module  determines that the mute request (or un-mute request as the case may be) is authorized without obtaining authorization from any of the other conferencing nodes associated with the connected group of users.","In some embodiments, if the authorization module  determines that mute request is not authorized, the authorization module  may generate and send a failure notification. The failure notification may be sent via the communication module  to the second conferencing node  that initiated mute request or to one or more other second and\/or third conferencing nodes  participating in the synchronous communication conference. For example, a failure notification may be sent to any conferencing node  that was required to provide a mute authorization request.","The authorization module  may be configured to generate one or more un-mute authorization requests based at least in part on an un-mute request received by the communication module , to determine whether one or more un-mute authorization responses received by the communication module  provide authorization for the un-mute request. The un-mute request may include information describing the scope of the request and the conferencing node  or nodes  to be un-muted. For example, the un-mute request may include information describing a connected group of users that an unassociated conferencing node  wishes to be associated with, information describing the conferencing nodes  to be un-muted, and\/or information describing which aspects of the synchronous communication data are being requested to be un-muted, etc. In some embodiments, the un-mute request includes un-mute parameters that are the same or similar to a mute request, and the parameter module  processes the un-mute request in manner similar to the mute request, and generates and provides an instruction signal to the authorization module  which includes information describing the un-mute request and un-mute parameters. In other embodiments, the authorization module  receives the un-mute request from the communication module  and parses information for generating the un-mute authorization request and for determining whether the un-mute request is authorized based on the un-mute request.","In some embodiments, the authorization module  determines if an un-mute request is authorized in a manner similar to how it determines if a mute request is authorized. For example, the authorization module  may only require a moderator node that is participating in the synchronous communication conference to provide authorization via an un-mute authorization response, or may require more than one conferencing node  participating in the synchronous communication conference to provide authorization for the mute request. The authorization module  may determine a moderator node from information included in the un-mute request, predefined and stored in the data store  or identified by information provided by the social graph . Additional structure and functionality of the authorization module  is provided below with reference to at least .","The mute signal generated by the authorization module  and provided to the mute module  informs the mute module  that a mute request or un-mute request is authorized and provides the information necessary for the mute module  to carry out the mute request or un-mute request. For example, the mute signal may include one or more of the following: the mute request, the un-mute request, any associated mute parameters, information describing the association of the conferencing nodes with a connected group of users, information describing the conferencing nodes to be muted or un-muted, etc. The authorization module  is coupled to the mute module  via the bus  to send the mute signal.","The association module  is software including routines for providing information about a connected group of users, determining the conferencing nodes  that are associated\/unassociated with a connected group of users, creating associations between a user  of a conferencing node  and a connected group of users, and generating and providing association information to the other entities of the synchronous communication engine . In some embodiments, the association module  is a set of instructions executable by the processor  to provide this functionality. In other embodiments, the association module  is stored in the memory  of the social network server  and is accessible and executable by the processor  to provide this functionality. In any of these embodiments, the association module  may be adapted for cooperation and communication with the processor  and other components of the social network server  via the bus .","In some embodiments, the association module  is coupled to the parameter module  via the bus  to receive an association signal and to send association information. In other embodiments, the authorization module  generates and provides the association signal to the association module . The association signal may instruct the association module  to determine whether one or more conferencing nodes  are associated with a connected group of users. The association module  may query data received from the social graph  for information associating a connected group of users with the conferencing nodes  participating in the synchronous communication conference. The association module  may then generate association information describing the association of one or more conferencing nodes  with the connected group of users and provide this information to the parameter module . The association information may identify which conferencing nodes  are associated with the connected group of users, unassociated with the connected group of users, or both. If only the associated or unassociated conferencing nodes  are included in the association information, the conferencing nodes  whose association are not described may be derived by the parameter module . The data received by the association module  from the social graph  may be received on demand or may be received and stored in the data store  for later use by the association module. In some embodiments, the association module  is coupled for communication with the social graph  via the bus , and may interact with the social graph  via an API.","By way of example, to determine which conferencing nodes  are associated with the connected group of users and which conferencing node  are unassociated with the group, the association module  may query the data received from the social graph  for user identifiers affiliated with the connected group of users and cross-reference these user identifiers with user identifiers affiliated with the conferencing nodes  participating in a video conference. The association module  may obtain the user identifiers of the conferencing nodes  participating in the synchronous communication conference from a software module of the synchronous communication engine  configured to negotiate and observe participation in the conference. In some embodiments, the stream receiver  manages which conferencing nodes  are participating in the synchronous communication conference. For example, to negotiate sending a synchronous communication data stream to the stream receiver, the user  must provide authentication information to the stream receiver  via the conferencing application . The authentication information may include an authentication token which can be cross-referenced with the credentials module (not shown) of the social networking application engine  to determine the user identifier that is associated with the authentication token.","In some embodiments, the association signal received from the parameter module  may instruct the association module  to associate a user  with a connected group of users. The connected group of users may be a social group included in the social graph , and may be defined by and affiliated with a user  participating in the synchronous communication conference. The users included in the connected group may be interconnected in the social network by a common social feature. For example, connected group may represent a group of friends who use the social network operated by the social network server . To associate the user  with the connected group of users identified in the association signal, the association module  may send a request to the social graph  of the social network instructing the social graph  to add the user  to the connected group of users. In some embodiments, prior to associating the user  with the connected group of users, the association module  obtains permission for doing so from the user  who defined the group and specified that the group be included in the mute request.","The mute module  is software including routines for muting synchronous communication data based at least in part on a mute signal. In some embodiments, the mute module  is a set of instructions executable by the processor  to provide this functionality. In other embodiments, the mute module  is stored in the memory  of the social network server  and is accessible and executable by the processor  to provide this functionality. In any of these embodiments, the mute module  may be adapted for cooperation and communication with the processor  and other components of the social network server  via the bus .","Upon receiving the mute signal, the mute module , may mute one or more of the synchronous communication data streams included in a combined synchronous communication data stream prior to the combined stream being generated, while the combined stream is being generated or after the combined stream has been generated by the stream generation module . Accordingly, the mute module  may be coupled to the stream receiver  or the stream generation module  via the bus  to receive the synchronous communication data stream that is to be muted. In some embodiments, the mute module  determines which synchronous communication data stream to mute based at least in part on the mute signal, and is coupled to the authorization module  via the bus  to receive the mute signal. The mute signal may include information describing the first conferencing nodes that have been designated to receive muted combined synchronous communication data streams, and how the combined synchronous communication data streams should be muted. In some embodiments, the mute signal includes the mute request and associated mute parameters describing the first conferencing nodes to be muted and how the synchronous communication data streams designated for those conferencing nodes should be muted. In other embodiments, the mute signal includes data describing which conferencing nodes are unassociated with a connected group of users and how the synchronous communication data streams designated for those conferencing nodes should be muted. In one or more of embodiments, the mute module  mutes the first synchronous communication data streams based at least in part on the information included in the mute signal.","In some embodiments, the mute module  mutes audio-video data included in a synchronous communication data stream by augmenting an audio component, a video component, or an audio component and a video component of the synchronous communication data stream. The mute module  may augment the audio components, for example by deleting, modifying and\/or replacing the bits of data comprising the audio components. In some embodiments, the mute module  is capable of performing the same or similar modifications to the synchronous communication data stream as the stream receiver  or the stream generation module . For example, the mute module  can un-package the audio components and video components from a container of the stream, un-compress, compress, transcode, the audio and\/or video components, etc. By way of further illustration, the mute module  may mute a synchronous communication data stream by looping the audio-video data in the data stream with a segment of audio-video data, replacing the data in the stream with audio or video data signaling that the audio-video data stream has been muted, freezing the audio and\/or video at a particular segment or frame, obscuring the video to show a silhouette of the user , completely blanking-out the audio and\/or video, replacing the video with an image of the user , replacing the audio with music or other audio, silencing the audio and replacing the video with an image of the user  from the video, etc. The mute module  may mute other aspects of a synchronous communication data stream such as data representing any type of media including documents, images, video, audio, text, electronic communications, data representing a computing environment, such as screen shots or a shared desktop or dashboard, etc. For example, the mute module  may restrict access to documents or other media being shared between conferencing nodes  that are interacting in a private video sub-conference within the synchronous communication conference. These examples are non-limiting and it should be understood that other mechanisms of muting audio, video and other aspects of a synchronous communication conference are contemplated and within the scope of the present disclosure.","In some embodiments, the mute module  determines which muted synchronous communication data streams should be un-muted based at least in part on the mute signal provided by the authorization module . The mute signal may include information describing one or more first conferencing nodes that should be un-muted, and the mute module  may cease to mute the synchronous communication data stream(s) being received by the one or more first conferencing nodes. For example, to deactivate the muting of a first synchronous communication data stream, the mute module  may connect to the data store  to modify boolean data that controls whether a first synchronous communication data stream is being muted, and in response to the boolean data being modified, the mute module  ceases to augment the first synchronous communication data stream.","Additional features, structure and functionality of the conferencing application , the stream receiver , the stream transmitter , the stream generation module , the communication module , the parameter module , the authorization module , the association module  and the mute module  are discussed below with reference to .","Data Store ","The data store  is data storage for storing conference related data. The data store  is coupled for communication with the components , , , , , ,  and  of the synchronous communication engine  and the other components , , ,  and  of the social network server  via the bus . In some embodiments, the data store  stores information received, generated and sent by the other modules of the synchronous communication engine . For example, the data store  stores synchronous communication data (e.g., audio-video data), mute parameter data, mute-related request and response data, authorization information, connection information, data from the social graph , user settings, etc. In some embodiments, data store  is coupled to the other modules of the synchronous communication engine  so these modules can manipulate, i.e., store, query, update and\/or delete, data using programmatic operations. In some embodiments, the data store  is a database management system (DBMS) operable on the social network server  and storable in the memory . For example, the database could be a structured query language (SQL) DBMS. In these embodiments, the social network server , and in particular, the synchronous communication engine  are coupled to the database via the bus  to store data in multi-dimensional tables having rows and columns, and manipulate, i.e., insert, query, update and\/or delete, rows of data using programmatic operations (e.g., SQL queries and statements).","Methods","Referring now to , various embodiments of the methods of the present disclosure are described.  is a flowchart of a method  for muting nodes  of a synchronous communication conference according to some embodiments of the present disclosure. The method  begins by the communication module  receiving  a mute request from a second conferencing node , which is participating in a synchronous communication conference, to mute a synchronous communication data stream designated for one or more first conferencing nodes , which is\/are also participating in the synchronous communication conference. In some embodiments, the synchronous communication data stream(s) designated for the first conferencing node(s)  include synchronous communication data (e.g., audio-video data) received from a second and third conferencing nodes , and the second conferencing node  is, for example, requesting permission to mute this synchronous communication data. For example, a user  of a second conferencing node  wants to have a private conversation within the synchronous communication conference with a user  of a third conferencing node . To do so, the user  of the second conferencing node  sends a mute request to the synchronous communication engine  requesting the synchronous communication data stream designated for a first conferencing node  be muted to prevent the user  of the first conferencing node  from being able to hear and\/or see the users of the second and third conferencing nodes .","In some embodiments, the mute request may be received from the second conferencing node  in response to a user  of the second conferencing node  muting the video and\/or audio of one or more first conferencing nodes  via an interface of the conferencing application . For example, the user  may mute the video and\/or audio by selecting in interface element, such as an audio\/video mute icon, displayed on the second conferencing node . For example, a user  of the second conferencing node  is in a video conference with several other conferencing nodes  and the user  wants to have a private conversation with a subset of the other conferencing nodes  (i.e., third conferencing nodes). On the client side, the user  mutes the conferencing nodes  that the user  wants to exclude from the private conversation (i.e., the first conferencing nodes) using a mute function of the conferencing application , and in response, the conferencing application  generates and sends a mute request to the synchronous communication engine  requesting permission to mute the first synchronous communication data streams designated for the first conferencing nodes  to prevent their users from hearing and\/or seeing the users of the second and third conferencing nodes . In other embodiments, the mute request may be received in response to the user  selecting a user interface element for expressly making the mute request.","Responsive to receiving  the mute request, the method  continues by the authorization module  generating  one or more mute authorization requests requesting authorization for the mute request from one or more third conferencing nodes . The mute authorization request(s) is\/are then transmitted  by the communication module  to third conferencing nodes(s) to request permission to mute the first synchronous communication data stream(s). The mute authorization request may be sent  to all of the third conferencing nodes , some of the third conferencing nodes , one of the third conferencing nodes  acting as a moderator on behalf of the other third conferencing nodes , or a single third conferencing node  if only one is specified by the mute request. For example, the mute authorization request is transmitted  to a third conferencing node  that acts as a moderator for other third conferencing nodes , and has the authority to approve the mute authorization request on behalf of the other third conferencing nodes . In this example, the moderator node may be specified in the mute request or may be predefined. In another example, a user  of a second conferencing node  may want to have a private conversation with the users of other third conferencing nodes , and sends a mute request via the second conferencing node  to the synchronous communication engine  identifying those third conferencing nodes . In response, the authorization module  generates  a mute authorization request for each of the third conferencing nodes  identified by the mute request and the communication module  respectively transmits  the mute authorization requests to those third conferencing nodes .","Next, the communication module  receives  the mute authorization response(s) from the third conferencing node(s)  which received the mute authorization request(s) in block  and the authorization module  determines  whether the mute request is authorized based at least in part on the mute authorization response(s). In some embodiments, a mute authorization response is received  from each third conferencing node  to which the mute authorization request is sent. In other embodiments, a mute authorization response is received  from a third conferencing node  acting as a moderator on behalf of itself and any other third conferencing node(s) . In some embodiments, the mute authorization response grants permission to mute the first synchronous communication data stream(s) in the manner requested by the mute request, and the authorization module  determines  that the mute request is authorized. In other embodiments, the mute authorization response denies permission to mute the first synchronous communication data stream(s) in the manner requested by the mute request, and the authorization module  determines  that the mute request is unauthorized. In yet other embodiment(s), the mute authorization response(s) grant(s) partial permission to mute the first synchronous communication data stream(s). For example, a mute authorization response grants permission to mute an audio component of a first synchronous communication data stream designated for a first conferencing node, but denies permission to mute a video component of this data stream. The method  may continue to proceed to mute the components of the first synchronous communication data stream authorized by the mute authorization response, or may inform the submitter of the mute request, i.e., the second conferencing node  via the communication module , that the mute request was only partially granted by a third conferencing node and requests permission from the second conferencing node  to proceed with the partially granted mute request.","If the mute authorization response is determined  by the authorization module  to be unauthorized, the method  is complete and ends. However, if the mute authorization response(s) are determined  by the authorization module  to authorize the mute request, the mute module  mutes  the first synchronous communication data stream(s) designated for the first conferencing node(s)  based at least in part on the mute request. In some embodiments, the first synchronous communication data stream includes the audio-video data streams received as synchronous communication data streams from the second and third conferencing nodes , and the mute module  mutes  the first synchronous communication data stream by muting an audio component, a video component, or an audio component and a video component of the audio-video data streams received from the second and third conferencing nodes . The mute request may define, at least in part, which components of the first synchronous communication data stream(s) should be muted. The mute request may also define how those components should be muted. The muting performed by the mute module  advantageously allows the users of the second and third conferencing nodes  to interact without the user(s) of the first conferencing node(s)  being able to hear and\/or see the interaction between the users of the second and third conferencing nodes . Additionally, once muted, the first conferencing node(s)  may continue to be associated with the synchronous communication conference and may interact with one another asymmetric to the interaction between the second and third conferencing nodes .","The muted first synchronous communication data stream(s) is\/are then transmitted  to the first conferencing node(s)  for presentation. In some embodiments, the first synchronous communication data stream may be muted in block  by transmitting an empty first synchronous communication data stream or not transmitting at least a portion of the first synchronous communication data stream during the period of time that the mute request is in effect. The method  is then complete and ends.",{"@attributes":{"id":"p-0088","num":"0087"},"figref":["FIGS. 4A and 4B","FIG. 4"],"b":["400","115","400","300","400","208","302","115","115"]},"The method  continues by the parameter module  determining  whether the mute request is an implicit request or an explicit request. In some embodiments, if the mute request includes location data, it is sent to the parameter module  by the communication module  as a potential implicit mute request, and the parameter module  evaluates the location data by parsing  the location data from the mute request and determining  whether any predefined mute parameters may be associated with the location data. A request may be implicit when the parameter module  interprets data provided by the communication module  as being a mute request even though the data itself may not contain express mute instructions. For example, one of the second conferencing nodes  participating in the synchronous communication conference may send location data identifying its geographic location, and the parameter module  may tie the identity of the second conferencing node  (e.g., a user identifier associated with a user  of the conferencing node ) and the location data to mute parameters defined by the user . In some embodiments, the parameter module  queries the data store  for mute parameters which define an implicit mute request. Based on the location data and the mute parameters, the parameter module  may determine which conferencing node(s)  participating in the synchronous communication conference is\/are the first conferencing node(s)  which will have its\/their synchronous communication data streams muted should the mute request be authorized, and which conferencing node(s)  participating in the synchronous communication conference is\/are the third conferencing node(s)  designated to continue to participate in the synchronous communication conference.","By way of further illustration, a second user  of a second conferencing node  arrives at a public place that the second user  frequently visits, such as a favorite coffee shop, and joins a video conference with the first and third users  of the first and third conferencing nodes  who are also at that public place. When the second user  visits that public place, the second user  routinely wants to have a private conversation with the third user , who belongs to a certain interconnected group (e.g., a group defined in the social graph  of the social network to include the second user's close friends). The second user  can set mute parameters that specify the location and the interconnected group of users, and when location data is received from the second user 's conferencing node  that places the second user  in that public place, the location data and mute parameters are interpreted as an implicit mute request requesting that the first user , who is unassociated with the interconnected group of users, be muted from hearing and\/or seeing the second and third users , who are interconnected. The second user  may override the mute parameters by submitting an un-mute request to un-mute the unassociated first user , invite the unassociated first user  to join the private conversation, selectively toggle the private conversation on and off so that the interconnected group of users can selectively interact with the unassociated first user , or submit requests to perform any of the functionality described with reference to the methods , , , , ,  or .","If the mute request is determined  by the communication module  to be an explicit request, the parameter module  parses mute parameters from the mute request and optionally determines  any additional mute parameters associated with the mute request. Mute parameters may define which audio-video data stream(s) being sent by the stream transmitter  to participating conferencing nodes  should be muted, which conferencing node(s)  should continue to participate in the synchronous communication conference, the manner in which the audio-video data stream(s) should be muted, etc. In some embodiments, to determine any additional mute parameters, the parameter module  queries the data store  for predefined mute parameters associated with the mute request. For example, a user  may predefine mute parameters, either for particular audio-video conferences in which the user  participates or globally, and the predefined parameters may define mute preferences, such as a how the user  may wish to mute the audio and\/or video data being received by another conferencing node . By way of further illustration, a user  may predefine mute parameters for muting the audio-video data that the user  is sending and is being received by others as synchronous communication data by obscuring the video data to show a silhouette of the user , completely blanking-out the audio or video data, replacing the video data with an image of the user , replacing the audio data with music or other audio data, etc.","The method  continues by the authorization module  generating  a mute authorization request. In some embodiments, the authorization module  generates the mute authorization request based at least in part on one or more of the location data, the mute parameters, the identity or identities of the first conferencing node(s)  designated to receive the first synchronous communication data stream(s) and the identity or identities of any other third conferencing nodes , etc. Next, the communication module  transmits  one or more mute authorization request(s), receives  one or more mute authorization response(s), and determines  whether the mute request is authorized, as previously described above with reference to .","If the authorization module  determines  that the mute request is unauthorized, the communication module  sends  a failure notification to the second conferencing node  and any third conferencing nodes  that authorized the mute request, to notify these conferencing nodes  that the first synchronous communication data stream(s) could not be muted. However, if the mute authorization response is determined  to be authorized by the authorization module , the mute module  mutes  the first synchronous communication data stream(s) designated for the first conferencing node(s)  based at least in part on the mute parameters. In some embodiments, the first synchronous communication data stream(s) include(s) audio-video data received from the second and third conferencing node(s)  as synchronous communication data, and the mute module  mutes the first synchronous communication data stream(s) by muting an audio component, a video component, or an audio component and a video component of the audio-video data received from the second conferencing node  and the third conferencing node(s) . The mute parameters may define, at least in part, which components of the first synchronous communication data stream(s) should be muted. Next, the method  continues by the muted first synchronous communication data stream(s) being transmitted  to the first conferencing node(s) , as previously described above with reference to . The method  is then complete and ends.",{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIGS. 5A-5D","FIGS. 5A-5D"],"b":["500","500","300","400"]},"The method  begins by the communication module  receiving  a conference request from a conferencing node  to initialize a synchronous communication conference with one or more other conferencing nodes . Provided the other conferencing nodes  elect to participate in the synchronous communication conference, the stream receiver  receives  an synchronous communication data stream from each of the conferencing nodes  participating in the conference. Next, the stream generation module  generates  a combined synchronous communication data stream for each of the conferencing nodes  participating in the synchronous communication conference. In some embodiments, the combined synchronous communication data streams are generated  from the synchronous communication data streams received from the participating conferencing nodes .","In an embodiment where the synchronous communication conference includes more than two participating conferencing nodes , the combined synchronous communication data stream generated  for each participating conferencing node  combines synchronous communication data received from the other conferencing node(s)  participating in the conference. For example, conferencing nodes , and elect to participate in the synchronous communication conference and send synchronous communication data streams to the stream receiver  of the synchronous communication engine . The combined synchronous communication data stream generated  by the stream generation module  for the conferencing node includes the synchronous communication data streams (e.g., audio-video data streams) received from conferencing nodes and , the combined synchronous communication data stream generated  for the conferencing node includes the synchronous communication data streams received from the conferencing nodes and , and the combined synchronous communication data stream generated  for the conferencing node includes the synchronous communication data streams received from conferencing nodes and . In other embodiments, the same output synchronous communication data stream is generated  for each participating conferencing node  by combining the synchronous communication data streams received from all the participating nodes  into one data stream.","Next, the stream transmitter  transmits  the combined synchronous communication data streams generated  by the stream generation module  to the participating conferencing nodes . The method  continues by the communication module  receiving  a mute request from one of the participating nodes  (i.e., a second conferencing node) of the synchronous communication conference to mute the combined synchronous communication data stream(s) being received by one or more other participating nodes  (i.e., one or more first conferencing nodes) of the conference. For example, a user  of the second conferencing node  desiring to have a private conversation with the user  of third conferencing node  sends a mute request to the synchronous communication engine  instructing the mute module  to mute the synchronous communication data being received from the second and third conferencing nodes  and provided to a first conferencing node.","The method  continues by performing blocks , , , , , , , ,  and  as previously described above with reference to , A and B. Next, if the mute request is determined  to be authorized, the mute module  mutes the combined (i.e., first) synchronous communication data stream(s) based at least in part on the one or more mute parameters associated with the mute request. If the mute module  is instructed  to mute the audio, the mute module  mutes it by augmenting  one or more audio components of the synchronous communication data (e.g., audio-video data) received from the second and third conferencing nodes  and included or to be included in the first synchronous communication data stream(s). If the mute module  is instructed  to mute the video, the mute module  mutes it by augmenting  one or more video components of the synchronous communication data received from the second and third conferencing nodes . If the mute module  is instructed  to mute other aspects\/components of the first synchronous communication data stream(s), the mute module  mutes them by augmenting  one or more related components of the synchronous communication data received from the second and third conferencing nodes . For example, the mute module  may augment  the synchronous communication data to prevent the first conferencing node(s) from being able to see shared documents, computing environments, images, hypermedia, supplemental video and audio, etc., being collaborated on within the synchronous communication conference. The synchronous communication data may be augmented in blocks ,  and  by the mute module  after it has been combined into the first synchronous communication data stream(s), while it is being combined, or prior to being combined into the first synchronous communication data stream(s) by stream generation module . In some embodiments, mute parameters associated with the mute request instruct the mute module  on which audio, video and other components to augment, and the on the manner in which they should be augmented. For example, the mute request could include mute parameters instructing the mute module  to mute the video by obscuring it to screen out the user  in the video, and to mute the audio by replacing it with soft music.","Next, the stream transmitter  transmits  the muted first synchronous communication data stream(s) to the first conferencing node(s) , respectively, for presentation. In some embodiments, block  is the same or similar to block . The method  continues by the authorization module  determining  whether the combined synchronous communication data streams designated for the second and third conferencing nodes  should be muted. As previously discussed with reference to blocks  and , the second and third synchronous communication data streams being sent to the second and third conferencing nodes , respectively, include synchronous communication data from the synchronous communication data streams received from the first conferencing node(s) , so that the users of the second and third conferencing nodes  can see the video, audio and other information being sent by the user(s) of the first conferencing node(s) . Muting the second and third synchronous communication data streams is advantageous because it allows the users of the second and third conferencing nodes  to interact without having to listen to, see, be distracted by and\/or be interrupted by the user(s) of the first conferencing node(s) .","If the authorization module  determines  that muting the synchronous communication data from the streams received from the first conferencing node(s)  is not authorized, the stream transmitter  continues to respectively transmit  the combined synchronous communication data streams, which are un-muted, to the second and third conferencing nodes . If the authorization module  determines  that muting of the synchronous communication data from the stream(s) received from the first conferencing node(s)  is authorized, the mute module  evaluates in blocks ,  and  whether the audio, video and\/or other aspects should be muted in blocks ,  and , respectively, based at least in part on the mute parameters. If the audio is to be muted, the mute module  augments  one or more audio components of each of these synchronous communication data stream(s). If the video is to be muted, the mute module  augments  one or more video components of each of these synchronous communication data stream(s). If the mute module  is instructed  to mute other aspects\/components of these synchronous communication data stream(s), the mute module  mutes them by augmenting  one or more related components of the synchronous communication data included in the stream(s). As previously described with respect to block  and the stream generation module , these synchronous communication data stream(s) is\/are included in the combined synchronous communication data stream(s) designated for the second and third conferencing nodes  (i.e., the second and third synchronous communication data streams, respectively). The synchronous communication data included in these streams may be augmented in blocks ,  and  by the mute module  after it has been included in the second and third synchronous communication data streams, while it is being combined, or prior to being combined into the second and third synchronous communication data streams by stream generation module . In some embodiments, the determination whether to mute the audio, video and\/or other aspects of these data streams, and the manner in which these data streams are to be muted, are based at least in part on the mute authorization response and mute parameters associated with the mute request. As an example, the mute parameters can include instructions for the mute module  to augment the audio and video of the streams by silencing the audio and replacing the video with an image of the user  from the video. Next, the method  continues by the stream transmitter  transmitting  the muted second and third synchronous communication data streams to the second and third conferencing nodes , respectively. The method  is then complete and ends.",{"@attributes":{"id":"p-0101","num":"0100"},"figref":"FIG. 6","b":["600","115","600","208","602","115","115","115","115","115","103","208","604","115","208","606","115","212","608","606","115","604","606","115","115"]},"In some embodiments, the mute authorization response grants permission to mute first synchronous communication data stream(s) designated for the first conferencing node(s)  in the manner requested by the mute request, and the authorization module  determines  that the mute request is authorized. In other embodiments, the mute authorization response denies permission to mute the first synchronous communication data stream(s) in the manner requested by the mute request, and the authorization module  determines  that the mute request is unauthorized. In yet other embodiments, the mute authorization response(s) grants partial permission to mute the first synchronous communication data stream(s). For example, the mute authorization response(s) grant(s) permission to mute an audio component of the first synchronous communication data stream(s) (e.g., audio-video data stream(s)) respectively designated for the first conferencing node(s) , but denies permission to mute a video component of this\/these data stream(s). The method  may continue to proceed to mute the components of the first synchronous communication data stream(s) authorized by the mute authorization response, or may inform the initiator of the mute request, e.g., the user  of the second conferencing node , that the mute request was only partially granted by the third conferencing node(s)  and request permission from the user  of the second conferencing node  to proceed with the partially granted mute request.","If the mute authorization response is determined  by the authorization module  to be unauthorized, the method  is complete and ends. However, if the authorization module  determines that the mute request is authorized, the mute module  mutes  the first synchronous communication data stream(s) based at least in part on the mute request. In some embodiments, the first synchronous communication data stream(s) include(s) audio-video data received from the second conferencing node(s)  as synchronous communication data, and the mute module  mutes the first synchronous communication data stream(s) by muting an audio component, a video component, or an audio component and a video component of the audio-video data. The mute request may define, at least in part, which components of the first synchronous communication data stream(s) should be muted. The mute request may also define how those components should be muted. The muting performed by the mute module  advantageously allows the users of the connected group to converse without the users of the unassociated conferencing nodes  being able to hear and\/or see their conversation.","The muted first synchronous communication data stream(s) is\/are then transmitted  to the first conferencing node(s)  for presentation. In some embodiments, the first synchronous communication data stream(s) can be muted by transmitting empty first synchronous communication data stream(s) or not transmitting at least a portion of the data stream(s) during the period of time that the mute request is in effect. The method  is then complete and ends.",{"@attributes":{"id":"p-0105","num":"0104"},"figref":["FIGS. 7A and 7B","FIGS. 7A and 7B"],"b":["115","700","600","700","208","702","115","102","115","115","115","115","103"]},"The method  continues by the parameter module  determining  whether the mute request is an implicit request or an explicit request. In some embodiments, if the mute request includes location data, it is sent to the parameter module  by the communication module  as a potential implicit mute request, and the parameter module  evaluates the location data by parsing  the location data from the mute request and determining  whether any predefined mute parameters may be associated with the location data. As described with reference to , a request may be implicit when the parameter module  interprets data provided by the communication module  as being a mute request even though the data itself may not contain express mute instructions. For example, one of the second conferencing nodes  participating in the synchronous communication conference may send location data identifying its geographic location, and the parameter module  may tie the identity of the second conferencing node  (e.g., a user identifier associated with a user  of the conferencing node ) and the location data to mute parameters defined by the user . The mute parameters may associate the location data with a user  of the second conferencing node  providing the location data, identifying information describing one or more an interconnected group of users in the social network which are associated with the user , the manner in which synchronous communication data stream(s) should be muted, etc.","If the mute request is determined  by the communication module  to be an explicit request, the parameter module  parses mute parameters from the mute request and optionally determines  any additional mute parameters associated with the mute request. For example, the mute parameters describe the second conferencing node  initiating the mute request, a user  associated with the conferencing node , one or more interconnected groups of users in a social network, the manner in which synchronous communication data stream(s) should be muted, etc. In some embodiments, in blocks  and , the parameter module  determines mute parameters by querying the data store  for any predefined mute parameters associated with the mute request. A user  may predefine mute parameters, either for particular synchronous communication conferences in which the user  participates or globally, to establish at least in part the manner and scope of the mute request, such as a how the user  may wish to mute the audio data, video data and\/or other data being received by another conferencing node .","The method  continues by the association module  determining  which conferencing nodes  participating in the synchronous communication conference are the second conferencing nodes , meaning they are associated with the interconnected group of users in the social network, and which are not. The one or more conferencing nodes  determined  by the association module  as being unassociated with the interconnected group of users are determined  to be the first conferencing node(s) . In some embodiments, to facilitate a private sub-conference within the synchronous communication conference between two interconnected conferencing nodes , at least two of the conferencing nodes  participating in the conference should be determined  by the association module  to be second conferencing nodes . As an example, the association module  may use information provided by the social graph  to determine which users are associated with the interconnected group of users, and may cross-reference these users with connection information describing which users are logged into the synchronous communication engine  and participating in the synchronous communication conference.","Next, the method , via the authorization module , generates  mute authorization request(s) based at least in part on the mute parameters. The mute authorization request may be generated  to include information describing the second conferencing nodes , the interconnected group of users, which components of the first synchronous communication data stream(s) designated for the first conferencing node(s)  are to be muted, the manner in which the components of the data stream(s) are to be muted, etc. The mute authorization request may be generated  for and sent  to all of the second conferencing nodes , some of the second conferencing nodes , one of the second conferencing nodes  acting as a moderator on behalf of the other second conferencing nodes , or a single second conferencing node . Then, as previously described above with reference to , the method  transmits  mute authorization request(s), receives  mute authorization response(s) and determines  whether the mute request is authorized.","If the authorization module  determines  that the mute request is unauthorized, the communication module  sends  a failure notification to the initiator of the mute request. The failure notification may also be sent to any second conferencing nodes  that authorized the mute request to notify these conferencing nodes  that the first synchronous communication data stream(s) were not authorized to be muted. However, if the mute authorization response is determined  to be authorized by the authorization module , the mute module  mutes  the first synchronous communication data stream(s) based at least in part on the mute parameters associated with the mute request. In some embodiments, the first synchronous communication data stream(s) include(s) audio-video data received as synchronous communication data from second conferencing nodes , and the mute module  mutes the first synchronous communication data stream(s) by muting an audio component, a video component, or an audio component and a video component of the audio-video data received from the second conferencing nodes . The mute parameters may define, at least in part, which components of the first synchronous communication data stream(s) should be muted. Next, the method  continues by the muted first synchronous communication data stream(s) being transmitted  to the first conferencing node(s) , as previously described above with reference to . The method  is then complete and ends.","To further demonstrate the functionality and advantages of the method , the following additional non-limiting example is provided. A user  of a conferencing node  arrives at a public place that the user  frequently visits, such as a favorite coffee shop, and joins a video conference with other users of other conferencing nodes  who are also at that public place. When the user  visits that public place, the user  routinely wants to have a private conversation with certain other users who belong to a certain interconnected group (e.g., a group defined in the social graph  of the social network to include the user's close friends). The user  can set mute parameters that specify the location and the interconnected group of users, and when location data is received from the user's conferencing node  that places the user  in that public place, the location data and mute parameters are interpreted as an implicit mute request requesting that the users unassociated with the interconnected group of users be muted from hearing and\/or seeing the interconnected users. The user  may override the mute parameters by submitting an un-mute request to un-mute the unassociated users , invite unassociated users  to join the private conversation, selectively toggle the private conversation on and off so that the connected group of users can selectively interact with the unassociated users , or submit requests to perform any of the functionality described with reference to the methods , , , , ,  or .",{"@attributes":{"id":"p-0112","num":"0111"},"figref":["FIGS. 8A-8D","FIGS. 8A-8D"],"b":["800","115","800","600","700"]},"The method  begins by the communication module  receiving a conference request from a user device  (i.e., a conferencing node) to initialize a synchronous communication conference with one or more other user devices  (i.e., other conferencing nodes). Provided the other conferencing nodes  elect to participate in the synchronous communication conference, the stream receiver  receives  synchronous communication data streams from each of the conferencing nodes  participating in the conference. The conferencing nodes  participating in the synchronous communication conference include conferencing nodes  that are associated with an interconnected group of users in a social network and conferencing nodes  that are unassociated with this group. Next, the stream generation module  generates  a combined synchronous communication data stream for each of the conferencing nodes  participating in the synchronous communication conference. In some embodiments, the combined audio-video data streams are generated  from the synchronous communication data streams received from the participating conferencing nodes . When generating  the combined data streams, the stream generation module  may modify them, for example, by compressing them or transcoding them into a different format.","In some embodiments, the combined synchronous communication data stream generated  for each participating conferencing node  combines synchronous communication data received from the other conferencing nodes  participating in the synchronous communication conference. For example, the conferencing nodes , and elect to participate in the synchronous communication conference and send synchronous communication data streams to the stream receiver  of the synchronous communication engine . The combined synchronous communication data stream generated  by the stream generation module  for the conferencing node includes synchronous communication data (e.g., audio-video data) received from the conferencing nodes and , the combined synchronous communication stream generated  for the conferencing node includes synchronous communication data received from the conferencing nodes and , and the combined synchronous communication data stream generated  for the conferencing node includes synchronous communication data received from the conferencing nodes and . In some embodiments, the same output synchronous communication data stream is generated  for each participating conferencing node  by combining the synchronous communication data streams received from all the participating conferencing nodes  into one data stream.","Next, the method  transmits  the combined synchronous communication data streams generated  by the stream generation module  to the participating conferencing nodes . The method  continues by the communication module  receiving  a mute request to mute the combined synchronous communication data stream(s) being received the participating node(s)  of the synchronous communication conference that is\/are unassociated with the interconnected group of users in the social network. The method  continues by performing blocks , , , , , , , , ,  and  as previously described above with reference to , A and B. Next, if the mute request is determined  to be authorized, the mute module  mutes the combined (i.e., first) synchronous communication data stream(s) based at least in part on the one or more mute parameters associated with the mute request. If the mute module  is instructed  to mute the audio, the mute module  mutes it by augmenting  one or more audio components of the synchronous communication data received from the second conferencing nodes  and included or to be included in the first synchronous communication data stream(s). If the mute module  is instructed  to mute the video, the mute module  mutes it by augmenting  one or more video components of the synchronous communication data received from the second conferencing nodes . If the mute module  is instructed  to mute other components\/aspects of the synchronous communication data received from the second conferencing nodes  and included or to be included in the first synchronous communication data stream(s), the mute module  mutes it by augmenting  related components of the synchronous communication data received from the second conferencing nodes . For example, the mute module  may augment  the synchronous communication data to prevent the first conferencing node(s) from being able to see shared documents, computing environments, images, hypermedia, supplemental video and audio, etc., being collaborated on within the synchronous communication conference. The synchronous communication data may be augmented in blocks ,  and  by the mute module  after it has been included in the first synchronous communication data stream(s), while it is being combined, or prior to being combined into the first synchronous communication data stream(s) by stream generation module . In some embodiments, mute parameters associated with the mute request instruct the mute module  on which audio, video and\/or other components to augment, and on the manner in which they should be augmented. For example, the mute request could include mute parameters instructing the mute module  to mute the video by obscuring it to screen out the user  in the video, and to mute the audio by replacing it with soft music.","Next, the method , via the stream transmitter , transmits  the muted first synchronous communication data stream(s) to the first conferencing node(s) , respectively, for presentation. In some embodiments, block  is the same or similar to block . Next, the method  determines  whether the combined (i.e., second) synchronous communication data streams designated for the second conferencing nodes  should be muted. As previously discussed with reference to blocks  and , the second synchronous communication data streams being sent to the second conferencing nodes  include synchronous communication data (e.g., audio-video data) from the synchronous communication data streams received from the first conferencing node(s) , so that the users of the second conferencing nodes  can see the video, audio and other information being sent by the user(s) of the first conferencing node(s) . Muting the second synchronous communication data streams is advantageous because it provides the users of the second conferencing nodes  (e.g., the users belonging to the same social circle in the social network), the benefit of conversing without having to listen to, see, be distracted by, be interrupted by, etc., the user(s) of the first conferencing node(s) .","If the authorization module  determines  that muting the synchronous communication data from the first conferencing node(s)  is not authorized, the stream transmitter  continues to respectively transmit  the second combined synchronous communication data streams, which are un-muted, to the second conferencing nodes . If the authorization module  determines  that muting the synchronous communication data from the stream(s) received from the first conferencing node(s)  is authorized, the mute module  respectively determines in blocks , , and , based at least in part on the one or more mute parameters associated with the mute request, whether to mute the audio, video and\/or other aspects the data in blocks ,  and . If the audio is to be muted, the mute module  augments  one or more audio components of the synchronous communication data received from the first conferencing node(s)  and included or to be included in the second synchronous communication data streams. If the video is to be muted, the mute module  augments  one or more video components of the synchronous communication data received from the first conferencing node(s)  and included or to be included in the second synchronous communication data streams. If other aspects are to be muted, the mute module  augments  one or more related components of the synchronous communication data received from the first conferencing node(s)  and included or to be included in the second synchronous communication data streams. The audio, video and other components of the synchronous communication data received from the first conferencing node(s)  may be augmented in blocks ,  and  by the mute module  after they have been combined in the second synchronous communication data streams, while they are being combined, or prior to being combined into the second synchronous communication data streams by stream generation module . In some embodiments, the determination whether to mute the audio, video and\/or other aspects of the second synchronous communication data streams, and the manner in which these data streams are to be muted, are based at least in part on the mute authorization response and mute parameters associated with the mute request. As an example, the mute parameters can include instructions for the mute module  to augment the audio and video of the streams by silencing the audio and replacing the video with an image of the user  from the video. Next, the method  continues by the stream transmitter  transmitting  the muted second synchronous communication data streams to the second conferencing nodes , respectively. The method  is then complete and ends.",{"@attributes":{"id":"p-0118","num":"0117"},"figref":"FIG. 9","b":["900","115","900","208","115","115","300","800","115","115","600","800","115","115","115","300","500","212","904","208","115","212","904","208","115","115","115"]},"Next, the communication module  receives an un-mute authorization response. In some embodiments, the un-mute authorization response is received from the second conferencing node  and the authorization module  determines  whether the un-mute request was authorized based at least in part on the authorization response. In other embodiments, the authorization request is sent to any or all of the second conferencing nodes , and an un-mute authorization response received by the communication module  from any single second conferencing node  is sufficient to provide authorization for the un-mute request. In yet other embodiments, the authorization request is sent to one or more of the second conferencing nodes  and a un-mute authorization response is required to be received by the communication module  from each of the second conferencing nodes  to which the authorization request was sent in order to provide authorization for the un-mute request. In yet other embodiments, only the second conferencing node  which initiated the mute request described above with reference to methods - may grant permission for the un-mute authorization request via an un-mute authorization response. In still yet other embodiments, any or all of the second and third conferencing nodes  referenced in methods - can be sent the un-mute authorization request and grant permission for it by sending an un-mute authorization response to the communication module  for processing by the authorization module .","The authorization module  may determine  that the un-mute request is authorized if the un-mute authorization response(s) authorize(s) the user  of the first conferencing node  to join the private sub-conference between the connected group of users associated with the second conferencing nodes . The authorization module  may also determine  that the un-mute request is authorized if the un-mute authorization response(s) authorize(s) connecting the user  of the first conferencing node  to the connected group of users. The authorization module  may determine  that the un-mute request is unauthorized if the un-mute authorization response(s) decline to allow the user  of the first conferencing node  to participate in the private sub-conference within the synchronous communication conference or refuse to connect the user  of the first conferencing node  with the connected group of users. If the un-mute request is determined  to be unauthorized, the method  is complete and ends.","If the un-mute request is determined  to be authorized, the association module  optionally connects the user  of the first conferencing node  to the connected group of users if permission to do so is granted by the authorization response(s). For example, to connect the user , the association module  sends a request via the network  to the social graph  of the social network to add the user  of the first conferencing node  to an interconnected group of users. In some embodiments, if the association module  connects the first conferencing node  to the connected group of users, the first conferencing node  is then considered to be associated with the connected group. In other embodiments, block  is skipped and the first conferencing node  is associated with the connected group of users by virtue of the un-mute request being authorized. In these other embodiments, the first conferencing node  may be associated with the connected group of users for the duration of the private sub-conference or the larger synchronous communication conference in which the private sub-conference is taking place.","The method  continues by the mute module  un-muting  the first synchronous communication data stream based at least in part on the un-mute request and the un-mute authorization response. In some embodiments, the mute module  ceases to augment the one or more audio, video and\/or other components being augmented for muting purposes under a mute request received and processed during a previous iteration of one of the methods -. Next, the stream transmitter  transmits  the un-muted first synchronous communication data stream, which includes complete audio, video and other data received from the second and\/or third conferencing nodes  associated with the connected group of users, to the first conferencing node  for presentation to the user  of the first conferencing node  via the conferencing application . The method  is then complete and ends.","The system  and methods - described are particularly advantageous in a number of respects. For example, they can conveniently allow the users of the second conferencing nodes  or second and third conferencing nodes  to converse and interact without having to listen to, see, be distracted by, be interrupted by, etc., the user(s) of the first conferencing node(s) . They can allow one or more users of the first conferencing nodes  being muted to create their own private sub-conference by submitting a mute request to have the second or second and third conferencing nodes  muted. They can provide the initiator of the request a convenient way to distinguish connected users from users who are lesser known or unknown to the connected users, and, in turn, create a sub-conference within the synchronous communication conference for the connected users to converse privately without disengaging from the conference. They can provide a convenient way for several conferencing nodes  to be muted at the same time in one mute request, which can alleviate the initiator from the hassle of having to individually specify which synchronous communication data streams should be muted, which can be particularly burdensome when a large number of conferencing nodes  are participating in the synchronous communication conference. It should be understood that this list of features and advantages is not all-inclusive and many additional features and advantages are within the scope of the present disclosure.","Additionally, it should be understood that the first, second and third conferencing nodes  used to describe the system  and methods - above are referred to by way of example, and a synchronous communication conference may include any number of conferencing nodes . Via one or more iterations of any of the methods -, any number of sub-conferences may be created within the synchronous communication conference using the muting functionality described to facilitate multiple asymmetric conversations within the conference. For example, a first sub-conference for first conferencing nodes  may be created by muting streams being received by second and third conferencing nodes , a second sub-conference for the second conferencing nodes  may be created by muting streams being received by the first and third conferencing nodes , a third sub-conference for third conferencing nodes  may be created by muting streams being received by first and second conferencing nodes , and so on and so forth. Further, reference to the various embodiments in the above description of methods - is not intended to infer that those embodiments are mutually exclusive, as many of the blocks of the methods - are interchangeable.","User Interfaces",{"@attributes":{"id":"p-0125","num":"0124"},"figref":["FIGS. 10A-10C","FIG. 10A"],"b":["1000","117","1002","1006","1008","1004","1002","1000","1004","117","103","117","103","1004","103","103","103","117","117","117"]},"Referring to , the synchronous communication conference user interface  generated by a user interface engine of the conferencing application  is similar to the user interface  in Figure A and includes several of the same or similar elements. For convenience and ease of understanding, those elements have the same reference numerals and the same or similar structure and functionality, and their description will not be repeated in full here. In contrast to , the window  depicted in Figure B includes an un-mute authorization selector  and the lower video region  is shaded and includes a mute icon indicating that user C is being muted. The un-mute authorization selector  is requesting permission from user A to un-mute C. In the depicted embodiment, if user A selects yes, the conferencing application  generates and sends an un-mute authorization response to the synchronous communication engine  indicating that a user A has authorized the un-mute request to un-mute the video and audio being received by user C, and if user A selects no, the conferencing application  generates and sends a mute authorization response to the synchronous communication engine  indicating that user A has declined to authorize the un-mute request. In the depicted embodiment, as a result of user A selecting yes from the mute authorization selector  depicted in , user C is being muted both from hearing and seeing the conversation between users A and B, and from being heard or seen by user A, as illustrated by the shaded area in lower video region . In other embodiments, user C can be muted from being muted from hearing and\/or seeing the conversation between users A and B but can still be heard and\/or seen by users A and\/or B.","Referring to , the synchronous communication conference user interface  generated by a user interface engine of the conferencing application  includes a window  having an upper video region , a lower video region , an un-mute request selector , and mute icons  and . The window  is a container for the other elements of the interface . The upper and lower read video regions are containers for displaying the synchronous communication data (e.g., audio-video data) of users B and A, respectively. In the depicted embodiment, the un-mute request selector  is asking if user C would like to request to be un-muted. In some embodiments, if user C selects yes, the conferencing application  generates and sends an un-mute request to the synchronous communication engine  requesting to have the synchronous communication data stream being received by user C un-muted, and if user C selects no, the conferencing application  cancels the un-mute request and the un-mute request selector is no longer displayed.","It should be understood that other input and display elements can be included in video conference user interfaces , , and . In some embodiments, interface elements controlling any aspect of the conferencing application  or synchronous communication engine  may be included and are within the scope of the present disclosure. For example, windows  and  may include a toolbar with icon elements for displaying and hiding dialogs to add other users to the synchronous communication conference interface, display the users contacts, such as phone contacts, redisplay the un-mute request selector , display selectors to request un-muting other muted users who are part of the conference, display selectors to request muting participating users in the conference, etc. It should also be understood that the synchronous communication conference user interfaces ,  and  are merely examples and that interface elements may have a variety of distinct formats, positions within the window, and combinations, all of which are encompassed by the scope of the present disclosure.","A system and methods for managing nodes of a synchronous communication conference have been described. In the above description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the disclosure. It should be understood that the technology described in the various example embodiments can be practiced without these specific details. In other instances, structures and devices were shown in block diagram form in order to avoid obscuring the disclosure. For example, the present disclosure was described in some embodiments above with reference to user interfaces and particular hardware. However, the present disclosure applies to any type of computing device that can receive data and commands, and any devices providing services. Moreover, the present disclosure was described above primarily in the context of exchanging messages via a social network server . However, it should be understood that the present disclosure applies to any type of other message exchange between endpoints.","Reference in the specification to \u201cone embodiment\u201d or \u201can embodiment\u201d means that a particular feature, structure or characteristic described in connection with the embodiment is included in at least one embodiment of the disclosure. The appearances of the phrase \u201cin one embodiment\u201d in various places in the specification are not necessarily all referring to the same embodiment.","Some portions of the detailed descriptions above are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here, and generally, conceived to be a self-consistent sequence of blocks leading to a desired result. The blocks are those requiring physical manipulations of physical quantities. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers or the like.","It should be borne in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the above discussion, it is appreciated that throughout the description, discussions utilizing terms such as \u201cprocessing\u201d or \u201ccomputing\u201d or \u201ccalculating\u201d or \u201cdetermining\u201d or \u201cdisplaying\u201d or the like, refer to the action and processes of a computer system, or similar electronic computing device, that manipulates and transforms data represented as physical (electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.","A computing device herein encompasses its plain and ordinary meaning, including, but not limited to an apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes, or it may include a general-purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, and magnetic disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, flash memories including USB keys with non-volatile memory or any type of media suitable for storing electronic instructions, each coupled to a computer system bus. Non-limiting embodiments of computing devices include the user devices , the social network server , and the other components of the system , additional examples of which are discussed above.","The disclosure can take the form of an entirely hardware embodiment, an entirely software embodiment or an embodiment containing both hardware and software elements. In a preferred embodiment, the disclosure is implemented in software, which includes but is not limited to firmware, resident software, microcode, etc.","Furthermore, the disclosure can take the form of a computer program product accessible from a computer-usable or computer-readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description, a computer-usable or computer-readable medium can be any apparatus that can contain, store, communicate, propagate or transport the program for use by or in connection with the instruction execution system, apparatus or device.","A data processing system including one or more computing devices suitable for storing and\/or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus. The memory elements can include local memory employed during actual execution of the program code, bulk storage and cache memories which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.","Input\/output or I\/O devices (including but not limited to keyboards, displays, pointing devices, etc.) can be coupled to the system either directly or through intervening I\/O controllers.","Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems, cable modems and Ethernet cards are just a few of the currently available types of network adapters.","Finally, the algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general-purpose systems may be used with programs in accordance with the teachings herein, or it may prove convenient to construct more specialized apparatus to perform the required method blocks. The required structure for a variety of these systems will appear from the description above. In addition, the present disclosure is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the disclosure as described herein.","It is intended that the scope of the disclosure be limited not by this detailed description, but rather by the claims of this application. As will be understood by those familiar with the art, the present disclosure may be embodied in other specific forms without departing from the spirit or essential characteristics thereof. Likewise, the particular naming and division of the modules, routines, features, attributes, methodologies and other aspects are not mandatory or significant, and the mechanisms that implement the present disclosure or its features may have different names, divisions and\/or formats. Furthermore, it should be understood that the modules, routines, features, attributes, methodologies and other aspects of the disclosure can be implemented as software, hardware, firmware or any combination of the three. Also, wherever a component, an example of which is a module, of the present disclosure is implemented as software, the component can be implemented as a standalone program, as part of a larger program, as a plurality of separate programs, as a statically or dynamically linked library, as a kernel loadable module, as a device driver, and\/or in every and any other way. Additionally, the disclosure is in no way limited to implementation in any specific programming language, or for any specific operating system or environment. Accordingly, the disclosure is intended to be illustrative, but not limiting, of the scope of the present disclosure, which is set forth in the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The disclosure is illustrated by way of example, and not by way of limitation in the figures of the accompanying drawings in which like reference numerals are used to refer to similar elements.",{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIGS. 4A and 4B"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIGS. 5A-5D"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIGS. 7A and 7B"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIGS. 8A-8D"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIGS. 10A-10C"}]},"DETDESC":[{},{}]}
