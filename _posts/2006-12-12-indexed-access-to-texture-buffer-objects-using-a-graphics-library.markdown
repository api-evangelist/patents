---
title: Indexed access to texture buffer objects using a graphics library
abstract: A method for generating a texture buffer object configured for storing and manipulating texture data for graphics processing operations includes the steps of creating a buffer object configured to store the texture data, binding the buffer object to a texture buffer object, binding the texture buffer object to one of a plurality of texture targets included within a texture image unit, and binding a shader program to a processing unit within a graphics rendering pipeline. One advantage of the disclosed method is that, once a texture buffer object is bound as the target of a texture image unit, shader programs may read and/or write to the buffer object referenced by the texture buffer object, without having to rebind that texture buffer object.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08189009&OS=08189009&RS=08189009
owner: NVIDIA Corporation
number: 08189009
owner_city: Santa Clara
owner_country: US
publication_date: 20061212
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This application claims priority to the U.S. Provisional Application titled: \u201cAPI Extensions for Advanced Graphics Processing Units,\u201d filed on Jul. 28, 2006 and having U.S. patent application No. 60\/833,978.","1. Field of the Invention","Embodiments of the present invention generally relate to computer programming for graphics processing systems. More specifically, embodiments of the invention relate to techniques for accessing a texture buffer object using a graphics library.","2. Description of the Related Art","Over the past decade, the cost of adding on-chip logic to processors has substantially decreased. Consequently, certain types of processors, such as advanced graphics processing units (GPUs), now include functionality not previously available in earlier GPU designs. For example, a GPU may include multiple texture image units used to store references to texture maps used in graphics rendering operations. One benefit of this new capability is that more efficient texture mapping operations and the like may now be performed on the GPU, thereby increasing overall performance in the graphics pipeline.","To fully realize additional processing capabilities of advanced GPUs, as much GPU functionality as possible needs to be exposed to graphics application developers. Among other things, doing so enables graphics application developers to tailor their shader programs to optimize the way GPUs process graphics scenes and images. Exposing new GPU processing capabilities to graphics application developers requires that the application programming interface (API) be configured with new calls and libraries that make new features and functionalities directly accessible by developers.","Graphics APIs typically expose an interface to graphics application developers that enables an application executing on the host CPU to load image data, in the form of one or more texture maps, into GPU local memory for greater access and processing efficiency by the GPU. Texture map data is commonly represented as one or more intensity values per texture element, called a \u201ctexel.\u201d For example, a texel may include a single intensity value per texel. Alternately, a texel may include four values, corresponding to red, green and blue intensity, and opacity. Each value within a texel is commonly represented using either a floating-point value, such as a standard 32-bit floating-point number, or a fixed-point normalized value. For example, an 8-bit normalized value includes 256 codes, ranging from 0x00 to 0xFF, where 0x00 corresponds to a floating-point value of \u201c0.0\u201d and 0xFF corresponds to a floating-point value of \u201c1.0.\u201d Each incremental code between 0x00 and 0xFF corresponds to 255 increasing floating-point values.","Some prior art graphics APIs provide a set of specific calls used to load and access data from a texture map. Typically, API calls may be used to load a texture map into local memory that is then accessed by a shader engine during rendering operations. In some cases, before the shader engine, which executes the instructions of a shader program, accesses a texture map, the texture map needs to be set to an \u201cactive\u201d state for the rendering pipeline. The graphics hardware typically allows a developer to specify an active set of texture maps to use in rendering operations. However, if the developer changes shader programs, then the set of active texture maps may need to be specified again, even if intervening shader programs do not use a texture of that type. Similarly, if a developer desires to use different texture maps for the same shader program, than the developer may have to set an active map each time a different texture map is needed.","Moreover, to even provide this functionality may require multiple data copies to load data into the GPU. Data output from a graphics rendering pipeline is copied into a frame buffer, and then this data is copied from the frame buffer to other portions of memory. Depending on the configuration of a particular graphics hardware device, the process may require the data to also be copied to memory managed by the CPU and then passed back to the local memory of the graphics hardware.","Additionally, conventional textures are accessed by floating-point texture coordinates and are \u201ctyped\u201d with a texel format that must be followed whenever the texture is accessed. For a one-dimensional (1D) array of textures, this approach fails to accurately represent the texture map as a set of individual, discrete texels. This formatting requirement limits the amount of memory available for a texture. For example, using 32-bit floating-point texture coordinates would limit conventional 1D textures to an image size of roughly 2^24 pixels. Linear filtering makes the maximum practical size with the prior art even smaller. Filtering allows a weighted average between two neighboring texels to be determined, using the floating-point coordinate to generate a filtering weight. However, the larger an image, the less precision available for weights. For example, if an image had 2^24 texels, each texel may be represented directly, but the 32-bit floating-point coordinates would leave no bits for weights. For example, there is no 32-bit floating point number between 2^24-1 and 2^24-2.","As the foregoing illustrates, what is needed in the art is a mechanism to specify and access texture maps that provides greater efficiency and flexibility than prior art techniques.","Embodiments of the invention provide for indexed access to texture buffer objects using a graphics library. An existing buffer object may be loaded using a transform feedback or some other mechanism and use data in the buffer object directly (e.g., as a texture in the shader), without requiring multiple copies of the data from a frame buffer, or coping data back to system memory managed by a CPU. One embodiment of the present invention sets forth a method for generating a texture buffer object configured for storing and manipulating texture data for graphics processing operations. The method includes the steps of creating a buffer object configured to store the texture data, binding the buffer object to a texture buffer object, binding the texture buffer object to one of a plurality of texture targets included within a texture image unit, and binding a shader program to a processing unit within a graphics rendering pipeline.","One advantage of the disclosed method is that, once a texture buffer object is bound as the target of a texture image unit, shader programs may read and\/or write to the buffer object referenced by the texture buffer object, without having to rebind that texture buffer object each time different shader program is loaded. Further, multiple texture image units may be provided and used simultaneously without needless or redundant data copies or the overhead of setting an active texture buffer object each time a different one is to be accessed. For example, if an application is going to use buffer object A with program B and also use buffer object C with program D, the application could bind the texture buffer object using A to image unit # and the texture buffer object using C to image unit #. Program B would refer to unit ; program D would refer to unit .","Embodiments of the invention allow developers of graphics applications to efficiently and effectively manipulate a memory buffer object as a texture map using a graphics library. As described herein, the term \u201ctexture map\u201d broadly refers to texture data that is organized as an array of pixels or texels. \u201cPixels\u201d is usually used when discussing texture image data that is a source image or other data transmitted from an application program or when the texture image data is stored a frame buffer memory local to graphics processing hardware, and \u201ctexels\u201d is usually used when discussing texture image data that is stored in a texture memory local to the graphics processing hardware. The words pixel and texel may be used interchangeably throughout the present application, depending on context, and neither word is intended to limit the scope of the present invention. Texture image data may include conventional image data, such as color components, or may include other types of data also suitable for use as a texture map, e.g., light intensity, height fields, displacement data, and the like. Each pixel or texel making up the texture data may include one or more components.","Generally, embodiments of the invention provide a texture buffer object that may reference data stored in a buffer object as a texture map. A buffer object may be allocated from memory local to graphics processing hardware. Once allocated, an API call may be used to define a reference to the buffer object, referred to as a texture buffer object. The API call may also specify a texture map format for accessing data in the buffer object as a one-dimensional (1D) array of texels. The size of the texture map may be determined from the size of the buffer object and the size of the elements for the specified internal format. For example, a 512 byte buffer object specified as \u201cRGBA8,\u201d that is as texels having red, green, blue, and alpha components of 8 bits each, would include 128 discrete texels accessed as array elements [0.127]. Each texel would take 4 bytes (one each for R, G, B, A values), so 512 bytes would include memory for 128 texels.","Because a graphics API may allow a developer to manipulate the buffer object in a variety of ways, the flexibility of using a buffer object, formatted as a texture buffer object, is superior to using conventional texture maps in various situations. For example, a texel in the buffer object may be accessed using integer indexing, rather than having to determine an appropriate floating-point coordinate to access the texel. At the same time, the texture buffer object may be accessed as a texture map using the internal format specified for the buffer object during graphics rendering operations. The internal format allows the graphics API to decrease memory requirements needed to index a texture buffer object. For example, a conventional \u201cRGBA8\u201d format is intended to encode four floating-point values in the range [0.0.1.0] as integers in the range [0.255]. In such an encoding, a floating point value of 0.0 corresponds to an index value of 0, a floating point value of 0.5 corresponds to an index value of 128, and a floating point value of 1.0 corresponds to a index value of 255. When using this format with a buffer texture, the values returned would be floating-point values in the range [0.0,1.0]. So 32-bit floats per component may be represented, but doing so only requires 8 bits worth of memory bandwidth.","Further, in one embodiment, graphics processing hardware may include a set of texture image units. Each texture image unit may be used to specify a set of \u201cactive\u201d texture objects of different targets, including one-, two-, and three-dimensional texture objects, cube map texture objects, and a new texture buffer object. Because the texture image data in a buffer object is separate from the reference provided by the texture buffer object, this data may be modified without having to \u201crewire\u201d which active texture buffer object is referenced by a particular texture image unit. Additionally, by setting the texture buffer object for multiple texture image units, different texture buffer objects may be used simultaneously without having to rebind a new texture buffer object to a texture image unit each time a different one is needed for rendering operations. Similarly, different texture buffer objects may be used without requiring a developer to change the \u201cactive\u201d texture buffer object during rendering operations each time a different one is needed.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1","b":["100","110","115","104","120","125","120","130","120","121","135","123","115","119","117","119","117","120"]},"The system memory  also includes an application program . The application program  generates calls to the API  in order to produce a desired set of results, typically in the form of a sequence of graphics images. The application program  also transmits one or more high-level shading programs or assembly-level shading programs and texture image data to the API  for processing within GPU driver . The high-level shading programs are typically source code text of high-level programming instructions that are designed to operate on one or more processing units within the GPU .","Local memory  stores, among other things, a frame buffer , a texture buffer object , and buffer object data . In one embodiment, data output from the graphics rendering pipeline  may be stored in a frame buffer . When graphics rendering pipeline  completes rendering a display frame, the contents of frame buffer  may be output to display device  for display. Typically, display device  is a CRT or LCD display. However, the output of rendering operations may not be used for immediate display, such as is the case when graphics rendering pipeline  is used to generate frames for an animation sequence or rendered visual effect. As described in detail herein, texture buffer object  includes a reference to buffer object  which contains buffer object data . In one embodiment, texture buffer object  may also specify an internal format specifying how buffer object data  in buffer object  should be interpreted when accessed as a texture map.","Persons skilled in the art will recognize that any system having one or more processing units configured to implement the teachings disclosed herein falls within the scope of the present invention. For example, computing device  may be, without limitation, a desk-top computer, a laptop computer, a mobile telephone, a set-top box or a personal digital assistant. CPU  generally executes programming instructions stored in the system memory , operates on data stored in system memory  and communicates with GPU  through system interface , which bridges communication between the CPU  and GPU . In alternate embodiments, the CPU , GPU, system interface , or any combination thereof, may be integrated into a single processing unit. Further, the functionality of GPU  may be included in a chipset or in some other type of special purpose processing unit or co-processor.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 2","b":["135","129","116","119","120","135","260","266","270","272","210","135","260","266","270","272","135","280","127"]},"Between vertex processing unit , geometry processing unit  and fragment processing unit  are primitive assembly unit  and primitive assembly and rasterizer unit . The primitive assembly unit  is typically a fixed-function unit that receives processed vertex data from vertex processing unit  and constructs graphics primitives, e.g., points, lines, triangles, or the like, for processing by geometry processing unit . Primitive assembly and rasterizer unit , which is optional in various implementations, receives the graphics primitives output by geometry processing unit , such as a set of triangles, and perform clipping operations to limit the triangles passed to fragment processing unit  to ones that might be viewable on display device . The rasterizer receives individual points, lines, or triangles processed by a primitive assembler and converts them to fragments to be processed by the fragment processing unit . During rendering operations, the processing units of graphics rendering pipeline  may access texel data from a texture buffer object , shown in  by an arrow .","The processing performed by vertex processing unit , geometry processing unit , and fragment processing unit may be defined by shader programs . Illustratively,  shows a vertex shader program , a geometry shader program , and a fragment shader program . In one embodiment, these shader programs may be written using a high-level shading language, such as the Cg or HLSL shader languages, and transmitted to API  for processing within GPU driver . The shader programs are then compiled and linked by a compiler\/linker  included with GPU driver  to produce an assembly code version of the shader programs. The assembly code is then converted into machine code (also referred to as \u201cmicrocode\u201d) by an assembler  also included in GPU driver . Optionally, compiler\/linker  may directly produce machine code, in which case GPU driver  may not include assembler . The machine code versions of the shader programs are then transmitted to the vertex processing unit , the geometry processing unit  and the fragment processing unit , as the case may be, for execution. In alternative embodiments, the vertex shader program , the geometry shader program  and the fragment shader program  may be written in assembly code or may be compiled into assembly code externally to GPU driver . In such embodiments, GPU driver  would not necessarily include compiler\/linker , and GPU driver  would receive assembly code versions of the shader programs directly. Assembler  would then convert the assembly code into machine code and transmit the machine code versions of the shader programs to the appropriate processing units of the graphics rendering pipeline , as set forth above.","Application  may supply buffer object data  to GPU driver  using calls to graphics API . GPU driver  may cause this data to be loaded into buffer object . Graphics processing units , , and  may access the texture buffer object  bound to one of texture image units  during rendering operations using various texel fetch operations. Once loaded, texture buffer object  may reference the buffer object  using an internal format specifying how to interpret texture image data  as a texture map. Texture image unit  may include references to one or more texture targets, including a reference to a texture buffer object. In one embodiment, the texture targets of texture image units  may be stateful. That is, once a texture target is set for a given texture type in one of the texture image is set, that target remains set until expressly changed. Thus, different shader programs  may access the same texture target, without having to bind to a desired texture target individually or having to repeatedly set an active texture. API  may include calls used to write data generated by one of the processing units of the graphics rendering pipeline  into buffer object  (represented in  using arrows  and ). Arrow  represents transformed vertices being recorded into buffer object , and arrow  represents contents of the frame buffer being read directly into buffer object , without first being copied to going to a host CPU.","API  may also include calls used to modify the data in buffer object . As stated, for example, application  may supply texture image data  to be stored in buffer object . API  may also provide calls for writing data to buffer object , including buffer objects referenced by texture buffer object . For example, API  may provide an API call that allows a developer to map the buffer object  to a pointer used by application , allowing application  to write to buffer object  directly.",{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 3","b":["123","129","330","310","123","123","301","302","303","304","305","306","307","308","123","123"]},"Illustratively, 2D texture target  references texture map , which includes an internal format , a size , a number of mipmap levels  and texture parameters . Examples of parameters  include controls for mipmapping, wrapping, border colors, among others. Additionally, the texture map  includes one or more texture images . These elements are known components of a conventional texture map. Texture buffer target  references texture buffer object , which includes an internal format  and a buffer object ID . However, in contrast to texture map , texture buffer object  does not include the texture image data to use in rendering operations. Specifically, texture buffer object  does not include texture images . Instead, texture buffer object  includes internal format  specifying a format to use interpreting data stored a buffer object  as a 1D array of texels. As shown, buffer object  includes a size  and a data store . Data store  stores the texture data  (e.g., the texture image data  supplied by an application program ) to be interpreted as a texture map according to internal format .","Although texture buffer object  does not directly store texture image data, it may be accessed in the same manner as a 1D array of texels. Thus, shader program  may include commands to fetch texels from texture buffer object  as though it were a texture. For example,  shows a command  of an assembly program used to access texture data from texture buffer object . Illustratively, the TXF instruction (short for texel fetch) includes the parameters of R0, R1, TEXTURE(0) and BUFFER. In this example, the \u201cTEXTURE(0)\u201d parameter identifies which one of texture image units  to access, and the \u201cBUFFER\u201d parameter identifies which target of that texture image unit to access. In this case, the \u201cBUFFER\u201d parameter specifies to access the buffer texture object  reference by texture buffer target . The R0 and R1 parameters specify registers on GPU . In this example, the R1 register may store an index value specifying which array location to access from the texture specified by the \u201cTEXTURE(0)\u201d and \u201cBUFFER\u201d parameters, and the R0 register may specify a destination to store the texel data retrieved from this array location. When executed, the TXF instruction causes the GPU  to identify the buffer texture target  bound to image unit  (in this case buffer texture object ). Because the texture target does not store the texture image data directly, GPU  then identifies the buffer object referenced by buffer texture object  using buffer object ID . In turn, GPU  accesses buffer object  as a texture, according to the internal format  specified by the buffer texture object .",{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIG. 4","FIGS. 1-3"],"b":"400"},"Additionally, the method  is described in conjunction with extensions to the OpenGL Shading Language (GLSL) and related API calls used for specifying and loading a texture buffer object using a graphics library. Persons skilled in the art will appreciate that the information in this section should be considered in conjunction with the current OpenGL 2.0 (TM) specification. Importantly, the extensions presented herein introduce API calls to the OpenGL API and the GLSL that may be used to allocate space for a buffer object, create a texture buffer object specifying an internal format for a texture, and write data to, and access data from, the buffer object referenced by a texture buffer object.","The method  begins at step , where an API call is used to create a buffer object with a specified ID and bind it to a buffer object binding point for further manipulation. For example, the OpenGL API includes a call with the following signature:\n\nvoid BindBuffer(enum target,uint buffer);\n\nThe <target> parameter is the name of a buffer object binding point. In one embodiment, in addition to conventional binding points, a new binding point is provided to bind to a texture buffer object. For example, a token such as TEXTURE_BUFFER_EXT may be defined and allowed as a token for the <target> parameter. The <buffer> parameter is an unsigned integer used to identify a buffer object. If <buffer> does not identify an existing buffer object, a new buffer object is created. The API call\n\nBindBuffer(TEXTURE_BUFFER_EXT,42);\n\nbinds a buffer object numbered  to the new TEXTURE_BUFFER_EXT binding point, creating a new object numbered  (provided it doesn't already exist).\n","At step , after a buffer object is created and bound to the TEXTURE_BUFFER_EXT binding point, the buffer object may be initialized and loaded with data using an API call. For example, the OpenGL API includes a call with the following signature:\n\nvoid BufferData(enum target,sizeiptr size,const void*data,enum usage);\n\nThis call may be used to initialize the data store  for a buffer object with texture image data specified by the <data> parameter. The <size> parameter specifies the size  of the buffer object . Additionally, the OpenGL API may provide API calls that may be used to load or modify texture image data into a buffer object in a variety of ways, including, for example, direct CPU writes using the MapBuffer( ) API call or using frame buffer read backs (represented in  as arrow ) as described in the EXT_pixel_buffer_object extension. A buffer object may also be loaded or modified using a transform feedback pathway (represented in  as arrow ), which captures selected transformed attributes of vertices processed by the one of the processing units of graphic rendering pipeline. Examples of transform feedback are described in a commonly owned co-pending patent application titled: \u201cFeedback and Record of Transformed Vertices in a Graphics Library,\u201d filed on Dec. 12, 2006 and having U.S. patent application Ser. No. 11\/609,763.\n","At step , an API call may be used to create a buffer texture object and bind it a texture target of an active texture image unit . For example, the OpenGL API includes a call with the following signature:\n\nvoid BindTexture(enum target,uint texture);\n\nNote this API call may be used to initially create a texture object, as well as to bind an existing texture object, depending on the current state of the graphics rendering pipeline and the parameters passed to the BindTexture( . . . ) call. Using the BindTexture( . . . ) call, the texture specified by the <texture> parameter is bound to the texture target identified by the <target> parameter. If the number passed as the <texture> parameter does not correspond to an existing texture object, a new texture object of the type associated with the <target> parameter is created, which will subsequently be identified by the number passed as the <texture> parameter. For example, if the call glBindTexture(TEXTURE_BUFFER_EXT, 17) is executed and no texture object  exists, a new buffer texture object numbered  is created. That new object will also be bound to the corresponding target of the texture unit at the same time. However, to bind an existing texture object numbered , the exact same API call would be used.\n","In one embodiment, an extension to the OpenGL API allows a developer to specify a token of TEXTURE_BUFFER_EXT target for a call to BindTexture( ) in which case, a texture buffer object is bound to the value supplied as the <texture> parameter. For other texture targets, e.g., one-, two-, three-dimensional textures, and cube maps, existing targets of TEXTURE1D, TEXTURE2D, TEXTURE3D, TEXTURE_CUBE_MAP, may be used. Once created, a texture buffer object remains available until expressly deleted. For example, OpenGL provides an API call with the following signature to free a buffer object:\n\nvoid DeleteTextures(sizei n,uint*textures);\n\nIn this API call, the <textures> parameter is an array of texture object identifiers, and <n> is the number of identifiers in the array. Each of the texture objects corresponding to an identifier in the array is deleted. For example, to delete the texture buffer object #, the following source code could be used:\n\n","At step , the internal format for the texture buffer object and the association between the buffer object and the texture buffer object bound to a texture image unit may be specified using an API call. For example, in one embodiment, the OpenGL API may be extended to include an API call with a signature like the following:\n\nvoid TexBufferEXT(enum target,enum internalformat,uint buffer);\n\nThis call binds the buffer object with a buffer object ID  matching the <buffer> parameter to an active texture buffer object and specifies an internal format  for the data found in the buffer object using the <internalformat> parameter. If the <buffer> parameter is zero, then any buffer object attached to the active buffer texture object is detached, and no new buffer object is attached. If the <buffer> parameter is non-zero, but is not the name of an existing buffer object, then the error INVALID OPERATION is generated. The <target> parameter is set to TEXTURE_BUFFER_EXT. The <internalformat> parameter specifies the storage format to use in interpreting data in the buffer object referenced by a texture buffer object. Table 1 lists a set of examples of internal formats that may be specified for a texture buffer object using the OpenGL API.\n",{"@attributes":{"id":"p-0043","num":"0045"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Internal formats for Texture Buffer Objects"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"8"},"colspec":[{"@attributes":{"colname":"1","colwidth":"105pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"6","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"7","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"8","colwidth":"7pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},"Com-",{},{},{},{},{}]},{"entry":[{},"Base ","po-",{},{},{},{},{}]},{"entry":["Sized Internal Format","Type","nents","Norm","0 ","1 ","2","3"]},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}},{"entry":["ALPHA8","ubyte","1","Y","A",".",".","."]},{"entry":["ALPHA16","ushort","1","Y","A",".",".","."]},{"entry":["ALPHA16F_ARB","half","1","N","A",".",".","."]},{"entry":["ALPHA32F_ARB","float","1","N","A",".",".","."]},{"entry":["ALPHA8I_EXT","byte","1","N","A",".",".","."]},{"entry":["ALPHA16I_EXT","short","1","N","A",".",".","."]},{"entry":["ALPHA32I_EXT","int","1","N","A",".",".","."]},{"entry":["ALPHA8UI_EXT","ubyte","1","N","A",".",".","."]},{"entry":["ALPHA16UI_EXT","ushort","1","N","A",".",".","."]},{"entry":["ALPHA32UI_EXT","uint","1","N","A",".",".","."]},{"entry":["LUMINANCE8","ubyte","1","Y","L",".",".","."]},{"entry":["LUMINANCE16","ushort","1","Y","L",".",".","."]},{"entry":["LUMINANCE16F_ARB","half","1","N","L",".",".","."]},{"entry":["LUMINANCE32F_ARB","float","1","N","L",".",".","."]},{"entry":["LUMINANCE8I_EXT","byte","1","N","L",".",".","."]},{"entry":["LUMINANCE16I_EXT","short","1","N","L",".",".","."]},{"entry":["LUMINANCE32I_EXT","int","1","N","L",".",".","."]},{"entry":["LUMINANCE8UI_EXT","ubyte","1","N","L",".",".","."]},{"entry":["LUMINANCE16UI_EXT","ushort","1","N","L",".",".","."]},{"entry":["LUMINANCE32UI_EXT","uint","1","N","L",".",".","."]},{"entry":["LUMINANCE8_ALPHA8","ubyte","2","Y","L","A",".","."]},{"entry":["LUMINANCE16_ALPHA16","ushort","2","Y","L","A",".","."]},{"entry":["LUMINANCE_ALPHA16F_ARB","half","2","N","L","A",".","."]},{"entry":["LUMINANCE_ALPHA32F_ARB","float","2","N","L","A",".","."]},{"entry":["LUMINANCE_ALPHA8I_EXT","byte","2","N","L","A",".","."]},{"entry":["LUMINANCE_ALPHA16I_EXT","short","2","N","L","A",".","."]},{"entry":["LUMINANCE_ALPHA32I_EXT","int","2","N","L","A",".","."]},{"entry":["LUMINANCE_ALPHA8UI_EXT","ubyte","2","N","L","A",".","."]},{"entry":["LUMINANCE_ALPHA16UI_EXT","ushort","2","N","L","A",".","."]},{"entry":["LUMINANCE_ALPHA32UI_EXT","uint","2","N","L","A",".","."]},{"entry":["INTENSITY8","ubyte","1","Y","I",".",".","."]},{"entry":["INTENSITY16","ushort","1","Y","I",".",".","."]},{"entry":["INTENSITY16F_ARB","half","1","N","I",".",".","."]},{"entry":["INTENSITY32F_ARB","float","1","N","I",".",".","."]},{"entry":["INTENSITY8I_EXT","byte","1","N","I",".",".","."]},{"entry":["INTENSITY16I_EXT","short","1","N","A",".",".","."]},{"entry":["INTENSITY32I_EXT","int","1","N","A",".",".","."]},{"entry":["INTENSITY8UI_EXT","ubyte","1","N","A",".",".","."]},{"entry":["INTENSITY16UI_EXT","ushort","1","N","A",".",".","."]},{"entry":["INTENSITY32UI_EXT","uint","1","N","A",".",".","."]},{"entry":["RGBA8","ubyte","4","Y","R","G","B","A"]},{"entry":["RGBA16","ushort","4","Y","R","G","B","A"]},{"entry":["RGBA16F_ARB","half","4","N","R","G","B","A"]},{"entry":["RGBA32F_ARB","float","4","N","R","G","B","A"]},{"entry":["RGBA8I_EXT","byte","4","N","R","G","B","A"]},{"entry":["RGBA16I_EXT","short","4","N","R","G","B","A"]},{"entry":["RGBA32I_EXT","int","4","N","R","G","B","A"]},{"entry":["RGBA8UI_EXT","ubyte","4","N","R","G","B","A"]},{"entry":["RGBA16UI_EXT","ushort","4","N","R","G","B","A"]},{"entry":["RGBA32UI_EXT","uint","4","N","R","G","B","A"]},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}}]}}]}},"br":[{},{},{}],"in-line-formulae":[{},{}]},"At step , the texture buffer object may be bound to the texture buffer target of a texture image unit, e.g. texture buffer target  of . The BindTexture( . . . ) API call described above may be used. At step , a shader program may be bound to one of the graphics processing engines of the graphics rendering pipeline. At step , rendering operations may be performed that include reading and\/or writing the texture buffer object bound to texture image unit at step . Thus, as described, references to the texture buffer object are mapped to the buffer object referenced by the texture buffer object. And the data store of the buffer object is interpreted as being a 1D array of texels having the internal format of the texture buffer object.","The rendering operations performed at step  may include shader program accesses to texture buffer objects. To access a texture buffer object using a shader program, the shader program may use an API call. For example, the OpenGL Shading Language includes a built-in function with the following with the following signature:\n\nvec4texelFetchBuffer(samplerBuffer sampler,int coord);\n\nThe <sampler> parameter specifies a texture buffer object sampler variable that holds the number of a texture image unit, and the <coord> parameter specifies which element of the texture buffer object referenced by that texture image unit to access. For example, if invoked as \u201ctexelFetchBuffer(sampler,11)\u201d with the value of the uniform <sampler> set to zero, then the texel numbered  in the buffer texture object bound to texture image unit # is accessed and returned. When a shader program includes a call to the texelFetchBufferEXT API call, the GPU driver  may be configured to generate an assembly level instruction executed by GPU . For example, the TXF instruction described above may used. If no buffer object is bound to the particular texture image unit specified by the <target> parameter, then the results of the texelFetchBufferEXT are undefined. Otherwise, the data element specified by the <coord> parameter of the appropriate buffer object is accessed and interpreted as a texel having the internal format of the texture buffer object, and may be returned as a four-component vector or in some other form.\n","In sum, embodiments of the invention provide indexed access to texture buffer objects using a graphics library. In particular, the functionality of API calls used to bind a texture map to a texture image unit may be extended to also allow a texture image unit to reference a texture buffer object. The texture buffer object is itself a reference to a buffer object in the local memory of a graphics hardware device. The texture buffer object specifies a texture format to use in interpreting the data in the buffer object. API calls used to access a texture may be extended to also access the buffer object referenced by a texture buffer object.","Advantageously, once a texture buffer object is bound as the target of a texture image unit, shader programs may read and\/or write to the buffer object referenced by the texture buffer object, without having to rebind that texture buffer object each time different shader program is loaded. Further, because the texture image units maintain state as different shader programs are bound and unbound to the processing units of a graphics rendering pipeline, rendering operations may proceed without having to set a new active texture buffer object target for a texture image unit each time a different texture buffer object is desired for rendering operations.","While the foregoing is directed to embodiments of the present invention, other and further embodiments of the invention may be devised without departing from the basic scope thereof, and the scope thereof is determined by the claims that follow.","In one embodiment of the invention, a computer-readable medium includes a set of instructions that when executed by a processing unit causes the processing unit to generate a texture buffer object configured for storing and manipulating texture data for graphics processing operations, by performing the steps of creating a buffer object configured to store the texture data, binding the buffer object to a texture buffer object, binding the texture buffer object to one of a plurality of texture targets included within a texture image unit, and binding a shader program to a processing unit within a graphics rendering pipeline."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["So that the manner in which the above recited features of the present invention can be understood in detail, a more particular description of the invention, briefly summarized above, may be had by reference to embodiments, some of which are illustrated in the appended drawings. Note, however, that the appended drawings illustrate only typical embodiments of this invention and are therefore not to be considered limiting of its scope, for the invention may admit to other equally effective embodiments.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
