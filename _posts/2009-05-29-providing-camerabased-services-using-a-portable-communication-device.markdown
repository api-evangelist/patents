---
title: Providing camera-based services using a portable communication device
abstract: Camera-based services are provided to a user of a portable communication device by recognizing text contained in an image. An image of an environment is captured using a camera within the portable communication device so as to obtain image data. The image data is processed such that text data is recognized and extracted from the image data. Data related to the text data is then output in a form recognizable by a user of the portable communication device. The text data can be processed on the portable communication device to obtain the data related to the text data. Alternatively, the processing is performed by a processing unit external to the portable communication device. Translated and audio versions of the text data are output to the user. One camera-based service provides price and product information related to a product described in an image captured by the camera.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08218020&OS=08218020&RS=08218020
owner: Beyo GmbH
number: 08218020
owner_city: Potsdam
owner_country: DE
publication_date: 20090529
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATION","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application is based on and hereby claims the benefit under 35 U.S.C. \u00a7119 from European Patent Application No. EP 08169713.8, filed on Nov. 21, 2008, in the European Patent Office, the contents of which are incorporated herein by reference. This application is a continuation-in-part of European Patent Application No. EP 08169713.8.","The present invention relates to a method for providing camera-based services to a user using a portable communication device based on text acquired with a camera of the portable communication device.","Portable communication devices are widely used in daily life by users wishing to communicate easily and independently of any fixedly installed communication terminals.","Nowadays, such portable communication devices offer a great number of services, including WAP services. In order to use a WAP service, the user must input various data related to the WAP service. Inputting the data is troublesome using a numeric keypad if the portable communication device is, for example, a cell phone or using a small alphanumeric keypad if the portable communication device is, for example, a smartphone.","In addition, a user might want to use a plurality of services for evaluating information based on text shown in the user's environment. Such services, such as obtaining information about a product, are available on the Internet from providers of the product. It is cumbersome, however, to input information using the numeric keypad, and to select the required Internet address using the numeric keypad on a cell phone, for example.","A method is sought for accessing services provided on the Internet from a portable communication device without requiring cumbersome data entry via the keypad of the portable device.","A method according to the present invention allows a user to input data including text to a portable communication device in a simple manner and to use inputted data in a plurality of services that are provided in connection with the portable communication device. The method accesses camera-based services using the portable communication device of a user. The method includes the steps of capturing an image, processing text data and outputting data related to the text data.","An image of an environment is captured using a camera of the portable communication device of the user. Image data is obtained and processed such that text data is recognized and extracted from the image data. The text data is further processed to obtain data related to the text data. Data related to the text data is output in a form recognizable by the user of the portable communication device.","The processing and further processing is performed either on the portable communication device or by an external processing unit. The external processing unit can include a server. The text data is transmitted from the portable communication device to the external processing unit and further processed by the external processing unit to form the data related to the text data. The data related to the text data is transmitted from the external processing unit to the portable communication device of the user. The external processing unit includes a first server that communicates with the portable communication device via a communication network. In one embodiment, the external processing unit includes a second server that communicates with the first server via a second network.","The processing and further processing is performed by the first server. The second server provides a service for processing the image data and for further processing the text data. The first server is adapted to receive the image data and text data from the portable communication device via the first communication network and to transmit the received image data and text data to the second server for processing and further processing.","The manner of processing and which server performs the processing depends on the service selected by the user of the portable communication device. The first server stores accounting and billing information regarding the service provided by the second server. The service is selected from a plurality of services displayed on a display of the mobile communication device of the user.","In one embodiment, the second server includes a database server for storing the image data, the text data and the data related to the text data for each captured image. The database server enables the portable communication device to access at least one of the image data, the text data and the data related to the text data for the captured image in real-time.","The first server communicates with a personal computer and accesses via the first server data stored on the database server, including the image data, the text data and the data related to the text data for the captured image. The text data and text related data are archived by classifying the text data and text related data by indexing keywords thereof. An Internet service is displayed on the display of the portable communication device of the user using an icon or text data.","In one embodiment, the portable communication device of the user is mounted on a support with a telescopic pullout. The portable communication device is controlled by a separate control unit.","The camera uses actuating means to capture the image. The actuating means enable the user to focus on a desired portion of the environment and to perform automatic release in capturing the image. The image can be rotated and unwarped before obtaining the image data. A user is informed of the quality of the image to be captured by the manner in which the portable communication device vibrates, by a reticule displayed to the user, or by an audio feedback provided by the portable communication device. The camera captures a first image of a first portion of the environment to be displayed in a transparent or semi-transparent manner and then captures a second image of a second portion of the environment to be displayed in a transparent or semi-transparent manner to thereby enable the user to stitch together the first and second images. The position of the user is determined using a position sensor of the portable communication device of the user.","Block recognition is performed on the acquired image to enable parallel processing in text recognition of obtained blocks and to enhance response time.","By storing the image data, the text data and the data related to the text data on a server, the portable communication device can access the image data, the text data and the data related to the text data in real-time. The image data, the text data and the data related to the text data are stored in connection with position data indicating the position where the associated acquired image was captured.","In another embodiment, a portable communication device includes a camera, a display and means for outputting data related to text data. The camera captures an image of the user's environment. The display displays a plurality of services that are selectable by the user of the portable communication device. The means for outputting outputs the data related to text data in a form recognizable by the user of the portable communication device. The portable communication device performs the method for providing camera-based services when the user selects one of the plurality of services.","The portable communication device also includes worker modules, a service module and a control module. One worker module processes the image data such that text data is recognized and extracted from the image data. Another worker module displays the image to be captured on the display and performs an image analysis for detecting the orientation and distortion of text included in the image. Other worker modules perform text recognition and convert the text data into speech for speech output. The control module controls the worker modules and the service module. The service module communicates with a server to request the performance of a service selected by the user. The worker modules work independently of each other. Each worker module communicates with an operating system of the portable communication device via specific interfaces. The client application with its worker modules can be configured through the server without reinstalling the application on the mobile device such that each worker group can also run on the server.","A server includes a first interface and a second interface. The first interface receives image data and text data from the portable communication device via a first communication network. The second interface transmits the received image data and text data to another server in a data format readable by the other server. The other server processes and further processes the image data and text data. The second interface receives the processed and further processed data from the other server. The first interface transmits the processed and further processed data received from the other server in a data format readable by the portable communication device as data related to text data to the portable communication device.","Other embodiments and advantages are described in the detailed description below. This summary does not purport to define the invention. The invention is defined by the claims.","Reference will now be made in detail to some embodiments of the invention, examples of which are illustrated in the accompanying drawings.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 1","FIG. 1","FIG. 1"],"b":["1","2","3","4","1","5","6","3","7","8","9","10","11","1","9","1","4","4","1","1","3","2","1","2","2","3"]},"External processing unit  includes server  that communicates with other servers within external processing unit  via second network  as shown by the arrows between the servers  and second network . First network  and second network  can be the same network or can be networks different from each other as may be required for a specific application. In one aspect, first network  is a mobile communication network, such as a GSM network, and second network  is a circuit-switched network or a packet-switched network. In other embodiments, different types of networks are chosen as required by the application being provided to the user.","As used herein, the term \u201cserver\u201d sometimes means \u201cservice\u201d, in which case services communicate with each other via second network  when such services are provided on different servers , i.e. different computers or computer systems. Alternatively, \u201cservices\u201d communicate directly with each other when such services are provided on the same server , i.e. the same computer or computer system. In this case, to enable the exchange of data, an appropriate transmission protocol is used, i.e., an appropriate data structure and\/or transmission mechanism.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":["FIG. 2","FIG. 2","FIG. 1"],"b":["12","18","1"]},"In step , the system determines whether or not portable communication device  has captured an image to be processed in order to obtain image data. The image to be processed includes a text object, such as text object \u201ctext to be captured\u201d  shown in  within the scene .","In step , the system determined whether the user has selected to process the image data. In one example, the user of portable communication device  selects the processing of image data by selecting a predetermined processing type from among a plurality of manners of processing shown on display  of portable communication device . The processing types are shown as icons or text data on display  and are selected using keypad  of the portable communication device . If the answer to step  is \u201cNO\u201d, indicating that no processing is selected, the flow returns to step . If the answer of step  is \u201cYES\u201d, indicating that a processing type is selected, the flow proceeds to step . In step , the system performs the processing using the processing type selected by the user.","In step , the system determined whether further processing of data obtained by the processing of step  is required. If the answer to step  is \u201cYES\u201d, the flow proceeds to step  in which the further processing is performed.","In step , data obtained by the processing of step  and\/or data obtained by the further processing of step  are transmitted to portable communication device . If the answer to step  is \u201cNO\u201d, the flow of the method proceeds directly to step , in which data obtained by the processing of step  are transmitted to the portable communication device .","In step , the system again determines whether the user has selected a processing type for the image data. If the answer to step  is \u201cYES\u201d, the flow of the method returns to step . If the answer in step  is \u201cNO\u201d, the flow returns to step , and the system waits to capture a new image.","In the general functional principle described above, the image data that is captured includes a text object within scene , as shown in  by the text object \u201ctext to be captured\u201d . Such text object can be captured in step  using the camera included in portable communication device . The processing in step  is performed within the portable communication device  or in external processing unit  after image data of the captured image is transmitted to external processing unit  via first network . The processing in step  is performed in order to obtain text data by recognizing the text within the text object, such as the text object \u201ctext to be captured\u201d .","The further processing in step , which is an optional feature, can then be performed either in portable communication device  or in external processing unit  after transmitting the text data to external processing unit  via first network . Details of such further processing are described below.","The output of data in step  is performed in portable communication device  such that data either directly or indirectly relating to the text data, i.e. relating to data obtained by processing and\/or further processing of the text data, are outputted in a form recognizable (or convertible to a recognizable form) by the user of portable communication device , such as written text, speech or the like. The processing and further processing can be performed either in portable communication device  or in external processing unit , depending of the application the user is using.","The manner of capturing the image data that includes the text object is described below. First, the image can be captured while portable communication device  is being held in the hand of the user of portable communication device . This is the normal manner of use.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 3","FIG. 3","FIG. 3","FIG. 3","FIG. 3","FIG. 1"],"b":["1","19","20","20","21","22","23","24","21","23","22","21","24","22","1","21","19","20","19","20","1","4"]},{"@attributes":{"id":"p-0054","num":"0053"},"figref":["FIG. 4","FIG. 4"],"b":["6","1","19","1","6","19","6","1","25","26","27","25","1","19","25","1","6"]},"Second line  in  is an inclined continuous line that indicates how a text object would be rotated by portable communication device . When the continuous line  has a first specific color, such as green, the system is indicating that the text object or text objects are aligned in a suitable manner and can immediately be used without any further rotation. If continuous line  has a second specific color, such as red, the system is indicating that the text object or text objects should be rotated by the portable communication device  before being processed.","Third line  in  is an inclined dashed line that indicates the distortion of the text object or objects. Third line  includes a projection point  at one end which helps the user to capture the text object without distortion. Projection point  assists the user to hold camera  as upright as possible with respect to the text object objects to be captured. If the projection point  is exactly in the center of the image shown in display , then camera  is being held exactly upright with respect to the text object or objects to be captured.","Alternatively, in addition to or instead of the reticule displayed to the user, suitable alignment and the resulting quality of the image to be captured can be indicated by actuating a vibrator in portable communication device  or by providing audio feedback from portable communication device . For example, a faster vibrating or a louder audio feedback indicates that the quality of the image to be captured will be poorer. The actuating means enables the user of camera  to focus on the desired portion of the environment. In one embodiment, the actuating means automatically allows the image to be captured when the quality of the image to be captured is acceptable. The actuating means can also include a G-sensor or acceleration sensor to suitably align the image before performing automatic release in capturing the image.","The following processing types can be performed in addition to or instead of the above. In a first processing type, an overall image is acquired by the camera. Using a view finder, an image to be captured is selected from the acquired overall image. Thereafter, image enhancement is performed using adaptive histogram alignment, for example. To correct any error of exposure and to enhance local contrast of the image to be captured, histogram alignment or the like is performed.","Thereafter, rotation analysis is performed. Rotation analysis can include digitization (binarization), differentiation and local Hough analysis. To enhance performance, the image is rescaled to a small size and digitized. Using edge analysis and following local Hough transformation, the system determines the angle at which text in the image to be captured will be rotated as compared to a horizontal line. This can be assisted by displaying an artificial horizon that helps the user of portable communication device  in achieving appropriate alignment of the camera and enhances later processing speed.","Data from the G-sensor or accelerometer are read out and indicate the relative position of camera . The data from the G-sensor or accelerometer is used to generate a specific view that assists the user in appropriate alignment of camera  that avoids distortion if the image to be captured includes a text object for later text recognition.","A second processing type involves segmenting the acquired image into blocks. An image to be captured is acquired by camera . If the image is captured using an auto-focus function, the image is captured after the auto-focus function is applied. The captured image data is then stored for example in a JPEG data structure. Thereafter, image enhancement such as adaptive histogram alignment is performed as described above. Segmentation is then performed on continuous blocks for example using region growing or convex Hulls. To enhance speed of later text analysis and to speed up later read out, continuous blocks are segmented.","Rotation analysis is then performed using, for example, digitization, differentiation or local Hough analysis. Because text recognition is difficult using rotated texts, the rotation angle of the captured image is verified and the captured image is inverse rotated. The system determines whether the segmented block contains text that can be analyzed. To save time in later text analysis, continuous blocks are checked for the probability of containing text.","The order of reading out text is determined from the left upper side to the right lower side. Adaptive digitization is performed to enable later text recognition even if poor lighting conditions are present, such as a hard shadow. The text blocks obtained using the segmentation are then used in the later text recognition.","Another processing type involves stitching two or more images together. A first portion of the environment to be displayed is captured in a transparent or semi-transparent manner and thereafter a second portion of the environment to be displayed is captured in a transparent or semi-transparent manner such that the user is enabled to stitch the first and second images together to obtain an overall image to be used for further processing.","Another processing type involves unwarping the text object or text objects to improve the quality of an image by removing any warping effect of a non-planar surface on which the text is written.","After the text object is selected and adjusted using the processing types mentioned above, the text object is then re-captured by actuating the capturing mode of portable communication device  to obtain image data corresponding to the text object. Block recognition can be performed on captured image data before processing or further processing. For example, text recognition is performed to enable parallel processing of obtained blocks, wherein one block is processed and another block is prepared. By pipelining the processing, the response time of overall processing is reduced. After the text object is re-captured, the processing described in steps - is performed.","After image data has been captured and the processing of steps - has been performed, specific services can be performed. These specific services for processing and\/or further processing are described below. Such specific services, however, are not limiting for the present invention but rather are intended to more fully make clear the specific features shown in  by way of example.",{"@attributes":{"id":"p-0068","num":"0067"},"figref":["FIG. 5","FIG. 5","FIG. 5","FIG. 1"],"b":["6","1","6","1","1","6","7","3"]},"In , the service \u201cSHOOT2MP3\u201d has been selected by the user as indicated by the box around the service \u201cSHOOT3MP3\u201d. In addition, a subitem \u201cNO TRANSLATION\u201d has been selected as indicated by the box around the subitem \u201cNO TRANSLATION\u201d. Although selection options for services are shown in  as being displayed using text data displayed in display , service options may also be indicated in other ways. For example, an icon representing a service can be used if user of portable communication device  is enabled to select an icon from display .","The implementation of the service \u201cSHOOT4TRANSLATE\u201d is described below with reference to . Image data captured as described above are processed in mobile communication device  to recognize and extract text data from the image data. Then, the text data are transmitted to server  of external processing unit , such as a main server designated by the address or name stored during selecting the item \u201cSERVER\u201d beforehand. Alternatively, server  is a preset server, in which case the item \u201cSERVER\u201d can be omitted. The text data can be transmitted to server  via a WLAN, UMTS network or the like.","Server , such as the main server or another service-providing server that receives the text data, then further processes the text data by translating the text data from one language into another language selected beforehand by the user of the portable communication device . Data corresponding to the translated text data are then transmitted from server  to mobile communication device  and are either displayed on display  or are converted to speech and read out by an internal speech synthesizer in the portable communication device . The transmitted data can also be stored on mobile communication device .","The service \u201cSHOOT2DOC\u201d is described below with reference to . Image data captured as mentioned above are transmitted to server  of external processing unit  that was designated by the address stored during selecting the item \u201cSERVER\u201d beforehand. Server  processes the image data to recognize and extract text data from the image data. The text data is analyzed by server  and is converted to a text file in a specific format, such as DOC or PDF. The text file is transmitted from server  to mobile communication device  and is then displayed on display  and\/or stored.","The service \u201cSHOOT2MP3\u201d involves generating speech data in a file format. Image data are captured and transmitting the data to server , which was designated by the address stored during selecting the item \u201cSERVER\u201d beforehand. Server  processes the image data to recognize and extract text data from the image data. A speech synthesizer of server  reads out the text data to obtain speech data in a specific format such as MP3. The speech data are transmitted from server  to mobile communication device , stored and played on mobile communication device  using an appropriate player, such as RealPlayer. Optionally, the text data can be translated into another language by server  before obtaining the speech data.","The service \u201cSHOOT2PRICE\u201d involves determining the price shown on a product display. Image data captured as mentioned above are processed in mobile communication device  to recognize and extract text data from the image data. The text data are then transmitted to server , such as the main server or another service-providing server of external processing unit  that was designated by the address or name stored during selecting the item \u201cSERVER\u201d beforehand. Alternatively, server  is a preset server, and the item \u201cSERVER\u201d can be omitted.","In one example, a specific designation of a product such as \u201cCANON EOS 5D\u201d camera has been recognized and extracted from the image data. Server , such as the main server, analyses online offers for this product in cooperation with another server  of external processing unit . Server  then transmits data indicating the product name and the lowest price from server  to mobile communication device , and this information is displayed on display . Alternatively, instead of showing the user online offers, the user can be shown product offers available near where the user is located. A position sensor such as a GPS sensor integrated into mobile communication device  can be used to select an offer having a low price and being made by a seller near the position of the mobile communication device . Such position sensor can also be used with the other services described herein.","The service \u201cSHOOT2READ\u201d involves converting text data to synthesized speech directed on mobile communication device . Image data captured as mentioned above are processed in mobile communication device  to recognize and extract text data from the image data. The text data is then directly read out by an internal speech synthesizer in mobile communication device . Thus, no interaction with external processing unit  and\/or any server  thereof is necessary. Alternatively, text is displayed on display  of portable communication device  to thereby obtain a service \u201cSHOOT2TEXT\u201d (not shown in ).","In performing the services described above, various information can be stored on server . The image data, the text data and the data related to the text data of a captured image are stored on server  to enable portable communication device  to access the image data, the text data or related data in real-time. This allows archiving of the data at a central site. The data is stored in association with position data indicating the position where the captured image was captured. This position information can be obtained by a GPS sensor, for example. If such data stored in connection with position data are displayed at a site where such data or the image data from which such data are derived have been obtained, so-called \u201cgeo-tagging\u201d can be performed.","In addition to the specific examples of user-selectable services described above, other services can be provided that do not require any interaction between portable communication device  and external processing unit  or one of the servers . For example, the aforementioned services can be modified such that more of the processing is performed on the portable communication device . Furthermore, image data captured at one time can be used for an arbitrary number of services instead of the need to capture image data again before selecting a new service.","The system allows a user to input data to portable communication device  in a simple manner using camera  instead of typing in data using keypad  and to use the inputted data in a great number of services that are provided in connection with portable communication device . Portable communication device  can be a mobile phone, such as a smartphone, having an integrated camera as well as sufficient memory capacity to store and execute a program having functionalities as mentioned above.","The software that performs the aforementioned functionalities is described in European patent application 07122042.0, which is incorporated herein by reference. Such software is ported to the applications as mentioned above.","Although the present invention has been described above as a method, the specific functionalities can be performed using software executing on the processor of a portable communication device and on a server.",{"@attributes":{"id":"p-0082","num":"0081"},"figref":["FIG. 6","FIG. 6"],"b":["29","30","30","31","32","33","31","29","30","32","30","34","30","29","35","35","30"]},"Main server  is also connected to one or more sub-servers, such as a translation server  and a price check server . The sub-servers provide services based on the image data, text data and data processed (pre-processed) in main server , for example. In one embodiment, main server  also stores accounting and billing information for service providers that offer services based on the camera-based service described herein. Therefore, main server  is capable of counting service usage individually for each service provider so that each service provider is able to offer and bill a usage based fee.",{"@attributes":{"id":"p-0084","num":"0083"},"figref":"FIG. 7","b":["29","38","39","40","41","42","38","39","29","42","40","41","29","40","41","42","43","44","45"]},{"@attributes":{"id":"p-0085","num":"0084"},"figref":["FIG. 8","FIG. 8","FIGS. 8A","FIG. 8C"],"b":["29","8","8","46","46"]},"A control module  receives the commands input from the user and auto shoot module , as well as additional commands such as \u201cstart session\u201d and \u201cend session\u201d. Accordingly, control module  controls a plurality of sub modules (worker modules or subsystems), such as a viewfinder module  and a snapshot module , an image-to-text module  (see ), a convert document module  and a speak text module  (see ). Viewfinder module  and snapshot module  are connected to control module  via a user interface . The additional modules relating to further available services for processing and further processing of image data and text data are not shown in . The worker modules are part of a client application that can be configured dynamically through main server  without reinstalling the client application on mobile client  such that each worker module can also run on main server  in such a manner that load balancing can be realized.","Viewfinder module  is responsible for showing a viewfinder when the user directs mobile client  including camera  to an image for shooting. In one example, viewfinder module  shows the image with a reduced resolution of 320\u00d7240 pixels, as compared to the image displayed after shooting. Other reduced resolutions are also possible. For assisting image acquisition, image analysis may be performed that detects the orientation of text in the image and displays it as corresponding lines on a display of mobile client  overlapping the viewfinder image. This is called GyroviewOverlay as was described above with reference to . In order to avoid distortions of the captured image, such as trapezoidal distortions, information from an accelerometer  or G-sensor is used to visualize the horizontal orientation of the mobile client. The feature is called GeocenterOverlay. Snapshot module  freezes an image after the image is captured. While the image is displayed in the background, analyzed text may be overlaid on the image. This feature is called TextOverlay.","The image-to-text module  shown in  performs optical character recognition (OCR) and includes a text recognition module , a block analysis module , a computer vision module , and a text post-processing module . Prior to character recognition, block analysis for finding image areas relevant for optical character recognition, as well as some image processing (pre-processing) is performed. Then, for recognition of characters, conventional OCR software is used. After character recognition, the recognized text is post-processed based on the results of the pre-processing and of the block analysis. If a service offers document conversion but the conversion is not performed by the convert document module  itself, the convert document module  communicates with an external server such as main server  to request a corresponding service such as translation and price check (price search).","The speak text module  shown in  converts text to speech. A text-to-speech engine module  communicates with a TTS synthesizer module , which generates audio data (PCM samples, for example) from the input text data. An audio streamer module  routes the audio data to an audio device  for sound output. TTS synthesizer module  and audio streamer module  may each use or access common TTS software.",{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 8","b":["29","54","19","62"]},{"@attributes":{"id":"p-0091","num":"0090"},"figref":"FIG. 9","b":["63","30","64","65","66","30","67","67","68","68"]},"The reading text function  also invokes the optical character recognition function  for obtaining text data from image data acquired from the \u201cpicking up text\u201d function .","When the user instructs the system to search for a price, the searching for price function  invokes the reading text function , which in turn invokes the optical character recognition function  to obtain text data.","In addition, invoking the searching for price function  requests a corresponding service via main server , such as searching for the lowest price and the nearest reseller (product search). After receiving price text information and\/or product review information, for example, from main server , the information may be read and\/or shown to the user. The searching for lowest price and nearest reseller or sales person may be performed based on the current location of the user, which is provided by the GPS signal or through GSM cell triangulation.","According to the product search result, the user may also decide to buy the product if a service provider provides a \u201cbuy feature\u201d. Main server  records the transaction for billing the product search feature.","According to the embodiment of , at first it is necessary to pick up text, i.e., an image including text, and to perform OCR. The final result is reading of text via a speech synthesizer (TTS). Depending on the service requested by the user, communication with main server  is performed. Main server  is adapted to store the processed data for later access by a personal computer, for example, via internet or other suitable communication means. Main server  may store the data itself and\/or in a separate database server as mentioned above. Other functions corresponding to other services provided by mobile client  itself or by or via main server  may be correspondingly added according to the principles shown in .",{"@attributes":{"id":"p-0097","num":"0096"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0098","num":"0097"},"figref":["FIG. 11","FIG. 1"],"b":["19","30","7"]},{"@attributes":{"id":"p-0099","num":"0098"},"figref":"FIG. 12","b":["30","30","30","30"]},{"@attributes":{"id":"p-0100","num":"0099"},"figref":["FIG. 13","FIG. 13"]},{"@attributes":{"id":"p-0101","num":"0100"},"figref":"FIG. 14"},"The system provides archiving functionality in which text information that is stored on main server  is classified by indexing keywords of the received text information, such that the information can be categorized by common keywords.  illustrates a situation in which documents are scanned using a camera of a mobile phone, and are then archived or stored for exchange between students, for example. The archiving and exchange is performed via a server , such as main server  or another service provider or portal for different services.","Although the present invention has been described in connection with certain specific embodiments for instructional purposes, the present invention is not limited thereto. Accordingly, various modifications, adaptations, and combinations of various features of the described embodiments can be practiced without departing from the scope of the invention as set forth in the claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings, where like numerals indicate like components, illustrate embodiments of the invention.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 7","FIG. 6"]},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIGS. 8A-C","FIG. 7","FIG. 8A","FIG. 8B","FIG. 8C"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 15"}]},"DETDESC":[{},{}]}
