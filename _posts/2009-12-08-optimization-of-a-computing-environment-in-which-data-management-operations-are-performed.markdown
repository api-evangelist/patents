---
title: Optimization of a computing environment in which data management operations are performed
abstract: Described are embodiments of an invention for optimizing a computing environment that performs data management operations such as encryption, deduplication and compression. The computing environment includes data components and a management system. The data components operate on data during the lifecycle of the data. The management system identifies all the data components in a data path, how the data components are interconnected, the data management operations performed at each data component, and how many data management operations of each type are performed at each data component. Further, the management system builds a data structure to represent the flow of data through the data path and analyzes the data structure in view of policy. After the analysis, the management system provides recommendations to optimize the computing environment through the reconfiguration of the data management operation configuration and reconfigures the data management operation configuration to optimize the computing environment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08554743&OS=08554743&RS=08554743
owner: International Business Machines Corporation
number: 08554743
owner_city: Armonk
owner_country: US
publication_date: 20091208
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["The invention relates to computing environments in which data management operations, such as encryption, deduplication and compression are performed.","Recent advances in information technology have lead to the proliferation of data management operations such as data encryption, data deduplication and data compression.","Data compression is the process of encoding information using fewer bits than an unencoded representation would use. Data deduplication generally refers to the elimination of redundant subfiles (e.g. blocks, chunks, or extents) from data objects. Data deduplication and data compression are data management technologies that are useful to reduce the consumption of expensive resources, such as storage space and transmission bandwidth.","Data encryption is the process of transforming information using an algorithm to make it unreadable to anyone except those possessing special knowledge (e.g. a key). Data encryption is used to protect data where it is stored as well as while the data is in transit. For example, data encryption may protect data as it is being transferred via networks.","Administrators are tasked with developing security and data reduction strategies utilizing the data management operations of encryption, deduplication, and compression to optimize the computing environment. Each component of the computing environment may be under the responsibility of a different administrator (e.g. the system\/application administrator, a network administrator, a storage administrator, a security administrator, server administrator, etc.). In most cases, the administrator for one domain does not have sufficient information about the data management operations and the data flow topology at the other domains. As a result, the data management operations applied in one domain may be redundant in light of data management operations applied at another domain, or even in certain circumstances, the data management operations in one data component may be in contention with other data management operations.","Described are embodiments of an invention for optimizing a computing environment that performs data management operations such as encryption, deduplication and compression. The computing environment includes data components and a management system. The data components operate on data during the lifecycle of the data. The management system identifies all the data components in a data path, how the data components are interconnected, the data management operations performed at each data component, and how many data management operations of each type are performed at each data component. Further, the management system builds a data structure to represent the flow of data through the data path and analyzes the data structure in view of policy. After the analysis, the management system provides recommendations to optimize the computing environment through the reconfiguration of the data management operation configuration and reconfigures the data management operation configuration to optimize the computing environment.","For example, an embodiment of a computer implemented method for data management in a computing environment includes discovering data components of the computing environment, such that at least one data component performs a data management operation. The method also creates a data flow topology representing a data path through the data components. Further, the method optimizes the data path by analyzing the data flow topology.","In yet another embodiment, the method for data management in a computing environment analyzes a data flow topology of data components within the computing environment. The data flow topology includes an order of the data management operations performed on the data. The method evaluates the data flow topology in view of data management policy and determines an optimal sequence of the data management operations within the computing environment.","In an embodiment of a computing environment, the environment includes memory coupled to a processor of a management system. The memory includes instructions implemented by the processor to discover data components of the computing environment, such that each data component performs a data management operation. Further, the environment creates a data flow topology representing a data path through the data components and optimizes the data path by analyzing the data flow topology.","In another embodiment of a computing environment, the environment includes memory coupled to a processor of a management system. The memory includes instructions implemented by the process to analyze a data flow topology of the data components with the computing environment, such that the data flow topology includes an order of data management operations performed on the data. Further, the environment evaluates the data flow topology in view of the data management policy and determines an optimal sequence of data management operations within the computing environment.","Features, elements, and aspects of the invention that are referenced by the same numerals in different figures represent the same, equivalent, or similar features, elements, or aspects, in accordance with one or more embodiments.",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1"},"Data components are resources or entities that create, store, transfer, manage, process or in some way operate on data during the lifecycle of the data. For example, data components may include resources or entities that perform encryption, deduplication, and compression upon data. Data components include, but are not limited to, databases, email applications, file systems, operating system software (e.g device drivers), logical host volume managers, various network devices, various storage network devices, network file servers, backup client devices, tape storage devices, virtual tape storage devices, etc. One of ordinary skill in the art would recognize any device, hardware, or software, that has an ability to create, store, transfer, manage, process or in some way operate on data during the lifecycle of data, may be a data component. It should be appreciated that each data component may utilize one or more data management operations such as reading, writing, encryption, deduplication, compression, etc.","The computing environment of  includes a management system . It should be appreciated that management system  may be any system capable of managing data management operations, such as encryption, deduplication, compression read and\/or write operations or the like. For example management system  may be IBM\u00ae Tivoli Storage Productivity Center (TPC). The data management system is coupled to data components, such as database , email application , file system , host volume manager , backup client , network devices , storage devices , file servers , backup servers , archive servers , disk , tape , and virtual tape (with deduplication capability) .","For example, referring to , data management operations, such as encryption, deduplication, and compression, may be performed in a database , email application , file system , host volume manager , and a backup client . In one example, database , email application , file system , host volume manager , and a backup client  are included in the system\/application domain . Therefore, in this example, a system\/application administrator would be responsible for configuring the data management operations within database , email application , file system , host volume manager , and a backup client .","Further, data management operations, such as encryption, deduplication, and compression, may be performed in network devices , storage network devices , file servers , backup servers , archive servers , disk , tape  and virtual tape . In one example, network devices , storage network devices , file servers , backup servers , archive servers , disk , tape  and virtual tape  are included in the storage administrator's domain . Therefore, in this example, a storage administrator would be responsible for configuring the data management operations within network devices , storage network devices , file servers , backup servers , archive servers , disk , tape  and virtual tape .","Subsets of data components that fall under the storage administrator's domain also fall under the network administrator's domain . In one example, network devices  and storage network devices  are included in the network administrator's domain . Therefore, in this example, a network administer would also be responsible for configuring the data management operations within network devices  and storage network devices .","As discussed above, each data component of the computing environment may be under the responsibility of a different administrator (e.g. the system\/application administrator, a network administrator, a storage administrator, a security administrator, server administrator etc.). The administrators are tasked with developing security and data reduction strategies utilizing the data management operations to optimize the computing environment. In most cases, the administrator for one domain does not have sufficient information about the data management operations and the data flow topology at the other domains. As a result, the data management operations applied in one domain may be redundant in light of data management operations applied at another domain, or even in certain circumstances, the data management operations in one data component may be in contention with data management operations in another data component, or a data management operation in a data component may be in contention with another data management operation within the same data component.","Encryption, deduplication, and compression consume significant amounts of computer resources to perform. Performing encryption, deduplication, and compression, redundantly, or in contention with other data management operations, consumes large amounts of system resources (e.g. CPU cycles, memory usage, and disk I\/O activity), and thus, increases processing costs, while adding very little value.","For example, performing redundant data management operations along a data path may be counterproductive and introduce unnecessary processing overhead. As mentioned above, encryption transforms data to make it unreadable without a key. Therefore, performing encryption on data that is already encrypted, and thus unreadable, adds unnecessary processing overhead. Further, deduplication refers to the elimination of redundant data. Thus, performing deduplication on already deduplicated data adds unnecessary overhead. Still further, compression searches for redundant data strings in a file, and replaces the redundant strings with a token. Therefore, performing compression of data that has already been compressed can also introduce unnecessary processing overhead.","Furthermore, the data management operations should be performed in an order that does not create contention between other data management operations. For example, performing encryption before performing deduplication may be counterproductive. The success of deduplication in part hinges on the ability to identify duplicate data. The encryption process randomizes data based on varying encryption keys. Therefore, the randomization of data that results from encryption defeats subsequent deduplication operations.","Further, performing encryption before performing compression may be counterproductive. The compression process typically searches for redundant data strings in a file, and replaces the redundant strings with a token, thus reducing or compressing the size of the file. The encryption process, as discussed above, randomizes data, making it unrecognizable. Therefore, the randomization of data that results from encryption, removes redundancy, and makes subsequent compression either impossible or ineffective.","Accordingly, it is desirable to configure data management operations such as encryption, deduplication, and compression such that they do not contend with one another. Therefore, there is a need for a method and system to identify all the data components in data paths where encryption, deduplication, and compression are being performed, to analyze the interactions and impacts of those operations on each other, and the overall storage system, to notify administrators of any potentially non-optimized configurations, and to make recommendations, and to optimize certain data management operations through reconfiguration of the data management operations at each data component.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 2","b":["100","10","100","220","230","240","250","260","270","280","100","100","132","132","136","136","138","152","168"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 2","b":["10","132","140","152","164","172"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 3","b":["100","100","310","132","134","136","138","140","152","154","162","164","166","168","170","172"]},"In an example of an embodiment of the present invention, the management system  of the computing environment  is able to identify all the data components in a data path where encryption, deduplication and compression are performed. Further, the management system  has the ability to analyze the data management operations and the impacts of the data management operations on other data management operations within the data path and the overall computing environment. Using the analysis, an administrator or user may be notified of potential non-optimal configurations. For example, such non-optimal configurations may include performing encryption before deduplication, performing encryption before compression, performing redundant encryption, performing redundant deduplication, and performing redundant compression. These potential non-optimal configurations may cause loss of data or consume large amounts of system resources. After the analysis is complete, the management system can provide recommendations to potentially optimize the computing environment  through the reconfiguration of the data management operation configuration.","For example, the management system  of computing environment  may include multiple modules, physical and logical. The physical modules may include memory, a processor, and network communication paths. The logical modules may include a discovery module , a build module , an analysis module , a recommendation module , and an execution module . These physical and logical modules work together to enable the discovery, build, analysis, and ultimately, provide recommendations to optimize the computing environment.","Specifically, the discovery module  is used to discover or identify every physical and\/or logical components that are considered data components  of the computing environment . For example, one can have a logical component, such as a database  or an email application  as a data component . From a physical perspective, a network device , such as a router or a switch may be used as a data component . It should be appreciated that each data component  may perform the data management operations of encryption, deduplication, and compression, individually, or in combination. For example, an email application may be performing only encryption, or it may be performing encryption, deduplication and compression. It should also be appreciated that the data management operations at each data component may be configured and be turned on and off according to a determined optimal configuration. Still further, it should be recognized that when a data component is added to, or removed from, the computing environment , a non-optimal configuration may result.","Returning to the discovery module . The discovery module  can identify, using a network, where encryption, deduplication and compression occur in data components  as shown in . Once the data components  and data management operations are identified, the build module  stores the data management operations in the nodes of a data structure representing the data flow topology. For example, the data management operations of encryption, deduplication, and compression are stored within each node of the data structure. Data flow topologies are the networks of data components and their interconnections that represent the path of data during its lifecycle. Various data flow topologies -N, as shown in , may be stored in the management database . These data flow topologies can be represented using any data structure. For example, the data flow topology can be represented with an array, a linked list, or a tree structure. One data flow topology, for example data flow topology , may describe a data path through the data components  that only operate on primary data. Yet another data flow topology, such as data flow topology , may include information from a data path including data components  for data backup operations.","Once the data management operations are stored to within the nodes of the data flow topologies described in , the analysis module  of the management system  gathers the stored information from the data flow topology and applies policy . In the analysis module , for example, gathering each encryption, deduplication, and compression event includes examining each node of the data structure and, identifying whether a variable is set to indicate the presence of such a data management operation. For example there may be an encryption, deduplication or compression variable set.","The analysis module  begins accumulating where these data management operations occur in the data components and the order in which the data management operations are performed in the data components . The analysis module  then applies policy . For example, based on specific policy , the analysis module may determine whether encryption is being performed before deduplication, encryption is performed before compression, and whether redundant encryption, redundant deduplication, or redundant compression is performed. For example, policy  may be a policy to avoid redundant deduplication. Accordingly, by applying the policy , of avoiding redundant deduplication, deduplication will only occur once in the data path. It should be understood by one of ordinary skill in the art that it would be a non-optimal configuration if every component within a primary data path performed deduplication. Deduplication refers to the elimination of redundant data. Thus, performing deduplication on already deduplicated data unnecessarily utilizes system resources, such as processor server time. Therefore, it is important that these non-optimal configurations are identified. In another example, policy  may require that deduplication is performed before encryption. Accordingly, analysis module  identifies where encryption is performed before deduplication along the path of the data flow.","The analysis module  gathers the information stored in the data flow topology, applies the policy , and the recommendation module  provides a recommendation to the administrator or to another module of the management system . Thereafter, an execution module  awaits instructions from an administrator or from another process of the management system  to execute the provided recommendation. The execution module  reconfigures the data components of the data path accordingly, such that it adheres to the recommendations. In another example, the execution module  of the management system  may be configured to automatically reconfigure the data components  in response to the recommendations from recommendation module . For example, the recommendations may include performing deduplication at the first data component of the data path only. Yet another recommendation may be to perform deduplication at a first data component of the data path and performing encryption at a subsequent data component of the data path.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 4","b":["100","420","220","100","310","310","310","310","220","310","11"]},"For example, discovery module  discovers all of the data components  within the computing environment  (as shown in the exemplary computing environment of ) including database , file system , host volume manager , network device, , disk , backup client , backup server , and virtual tape system with deduplication . The discovery module  queries each data component  and discovers configuration information, as described above, of each component.","The discovery module  may discover the data components  and the interconnections between the data components by querying storage resource management (SRM) solutions or configuration management data bases (CMDB). In one embodiment, the IBM\u00ae Tivoli Storage Productivity Center (TPC) may be queried to discover data components . The queries may be done utilizing application programming interfaces (APIs), command line interfaces (CLIs), small computer system interfaces (SCSI), or the like. In another embodiment, all of the data components , and the interconnections between the data components in the environment are manually entered into management database . In yet another embodiment, the discovery module  discovers data components utilizing a combination of the above embodiments. For example, the discovery module  may discover some of the data components  utilizing queries and other data components  may be entered manually into management database .","The discovered data components  and their configuration information may be stored in a database such as management database . In one embodiment, management database  may be a relational database.","In step  the build module  builds a data flow topology. Data flow topologies are the networks of data components and their interconnections that represent the path of data during its lifecycle. For example,  shows an example of a data component topology of a primary data flow for data residing in an exemplary computing environment shown as shown in .","The data flow topology may be represented using a linked list representing the flow of data through the data components. A linked list, as known in the art, is a data structure that includes a sequence of nodes containing fields of information, including a field that contains a reference (e.g. link) to the next node in the sequence. Each data component  is a node in the linked list or data structure.","The linked list begins with a data component that is a high level data representation. A high level representation is the level at which data is created, read, or written. In one embodiment the data flow topology is a linked list representing the primary flow of data and another data flow topology is a linked list representing backup flow of data. Primary flow of data may be defined as the data components that the data flows through from creation of the data to the storage of the data. The backup flow of data may be defined as the data components that the data flows through when creating a copy of the data. It is important to note the difference between the primary flow of data, where data initiates, and the backup flow of data, where data is copied. In primary flow of data, the data is being created and stored, and therefore, at the creation of data, no data management operations have been performed on the data. On the other hand, in some cases, the backup flow may already have data management operations performed on the data. It should be understood by one of ordinary skill in the art that the primary flow topology and the backup flow topology may include the same data components .","While the data flow topology in the present embodiment is described as a linked list, it should be understood by one of ordinary skill in the art, that the data flow topology may be represented by other data structures such as a tree structure, an array, a graphical representation, or other data structure common in the art.","The build module  receives the information that is discovered by the discovery module . In one embodiment, the build module  receives the discovered information about the data components  after all the data components are discovered and subsequently, the data build module builds the data flow topology. In another embodiment, the build module , builds the data flow topology on the fly, while the discovery process is ongoing. For example, the discovery module  may discover a data component  and, subsequently, the build module  receives information about the data component and builds a node that represents that data component. Thereafter, the discovery module  may discover another data component, and the build module  builds a node that represents that data component.","Beginning with a high level data component, the build module  creates a node in the data component structure for the data component. The build module  populates the node with information discovered in step .","The data component structure includes nodes, each node including fields, the fields having information such as: a back pointer that points to the previous data component structure in the linked list; a forward pointer that points to the next data component structure in the linked list; a data component ID which is a unique identifier for the data component; a data component type (e.g. database, email application, file system, etc,); a data component vendor which indicates the vendor associated with the data component (e.g IBM, Microsoft, etc); a data component product which identifies the products associated with the data component (e.g. the IBM\u00ae Tivoli Storage Productivity Center (TPC); a data component location (e.g. source host, network, target host\/media etc); data component processor (e.g. central processing unit (CPU), CPU offload, etc).","In addition, in an embodiment, the node of the data component structure for each data component includes an encryption type field, a deduplication type field, and a compression type field. In one embodiment, these fields are string text fields that indicate the type of encryption, deduplication and compression that is performed at the data component, respectively. The data component structure also includes for each data component an encryption operation field which identifies if data is encrypted or decrypted by the data component, a deduplication operation field which identifies if data is deduplicated or undeduplicated by the data component; a compression operation field which identifies if data is compressed or uncompressed by the data component.","For example, the data structure may indicate that encryption, deduplication, and compression are performed with a value of +1 stored in the corresponding field. Further, the data structure may indicate that encryption, deduplication and compression are not performed with a value of 0 in the corresponding field. Finally, the data structure may indicate that data is decrypted, undeduplicated, and uncompressed with a value of \u22121 in the corresponding field. One of ordinary skill in the art would recognize that the use of +1, 0, and \u22121 is arbitrary in all fields described herein, and that any other method can be used to indicate the presence of encryption, deduplication, and\/or compression within the data component structure.","Further, in an embodiment, the node of the data component structure includes an encryption capability field, a deduplication capability field, and a compression capability field. These fields include information about the capability of the data component to perform encryption, deduplication, and compression, respectively. For example, a value of 1 may be stored in the encryption capability field if the data component is capable of performing encryption. A value of 0 may be stored in the encryption capability field if the data component is not capable of performing encryption. Similarly, a value of 1 may be stored in the deduplication or compression capability field if the data component is capable of performing deduplication or compression, respectively. A value of 0 may be stored in the deduplication or compression capability field if the data component is not capable of performing encryption or compression, respectively.","Still further, in an embodiment, the node of the data component structure also includes an encryption transparency field and a compression transparency field. Transparency refers to whether the data management operations (e.g. encryption and compression) are performed without knowledge or impact to other data components. For example, compression may be transparent to other data components when a data component compresses the data and, then, upon access to the data the data component uncompresses the data. Similarly, encryption may be transparent to other data components when encrypted data is automatically unencrypted upon access to the data. In one embodiment, the encryption transparency field may be null if no encryption is performed by the data component. Similarly, the compression transparency field may be null if no compression is performed by the data component.","For example, referring back to the exemplary computing environment illustrated in , the build module  recognizes database  as a high level data component and creates a node  for database  in a linked list as shown in . An example of a node is shown in . As seen in , the node  includes information about the data component. The data component information includes, but is not limited to: a back pointer ; a forward pointer ; a data component ID ; a data component type ; a data component vendor ; a data component product ; a data component location ; data component processor ; an encryption type ; a deduplication type ; a compression type ; an encryption operation ; a deduplication operation ; a compression operation ; encryption capability ; a deduplication capability ; compression capability ; encryption transparency ; and a compression transparency . One of ordinary skill in the art would realize that the order of information presented within the fields of the node is merely arbitrary and may be presented in any order. Additional information about the data component that might assist in the analysis of the data flow topology might also be stored in the node.","As noted above, the data component information includes a back pointer and a forward pointer that reveals the interconnections between the data components. The forward pointer points to the next data component to which the data flows. Accordingly, the build module  creates another node for the next data component. For example, referring back to , the next node in the primary flow of data is the file system . The build module  creates a node  for file system  in the linked list as shown in . The build module  populates node  with data component information discovered in step . Similarly, the build module creates and populates node  for host volume manager , node  for network device , and node  for storage device  as shown in .","In a similar manner, in step , the build module  builds the data flow topology for the flow of data through a backup process. Beginning with a high level data component, the build module  creates a node in the data structure for the data component. The build module  populates the node with information discovered in step . For example, referring to , the build module  recognizes database  as a high level data component and creates a node  for database  in a linked list as shown in . In the exemplary embodiment, the next node in the backup flow of data is backup client . The build module  creates a node  for backup client  in the linked list as shown in . The build node  populates node  with data component information discovered in step . Similarly, the build module creates and populates node  for network device , node  for backup server , and node  for storage device, such as virtual tape with deduplication capability  as shown in .","In step , of , the build module determines if there are additional high level data components. If there are no additional high level data components the process flows to step . If there are additional high level data components the process flows to step , wherein the build module builds a data flow topology for the remaining high level data components in the same manner as discussed with respect to step  above.","The completed data flow topologies (e.g. , ) provide a picture of the data components within the computing environment, how there are interconnected, the data management operations performed, the order of the data management operations, and how many data management operations of each type are performed at each data component. The build module stores all of the resulting data component topologies (e.g. topology , topology , . . . topology N) in management database . It will be noted that the variable identifier \u201cN\u201d is used to more simply designate the final element (e.g., servers ()-(N)) of a series of related or similar elements.","In step  the analysis module  receives data flow topologies ,  from management database  and analyzes the data flow topologies in view of policy . Policy  may include network security policies (e.g. requiring encryption before data is transmitted across a network), storage residency security policies (e.g. requiring encryption when storing data on a storage device), network bandwidth optimization policies (e.g. requiring deduplication or compression before data is transmitted across a network), system resource optimization policies (specifying whether host system resources should be used for deduplication, encryption or compression), storage space optimization policies (e.g. requiring data be compressed or deduplicated before being stored on a storage device), and data management operation redundancy policies (e.g. avoiding redundant data management operations with a data flow topology). For example, in one embodiment a network security policy may be set up such that data must be encrypted before it is sent over a network. In another example, a data management operation redundancy policy may be set up such that no redundant data management operations are performed. Finally, in another example, a bandwidth optimization policy may be set up such that deduplication or compression is recommended before data is transmitted over the network. Policy  may be created by an administrator, a user, or, alternatively, the management system may include default policy.","In one embodiment, the analysis may be done by utilizing counters or variables. For example, as described above, each node of the data component structure (e.g. a linked list) includes a field that indicates whether encryption, deduplication, or compression is performed with a value of +1, 0, and \u22121 stored in the corresponding field (e.g. field , , and , respectively as shown in ). The analysis module , maintains a count of the nodes within the data path that perform each of the data management operations. For example a count is maintained of the number of time encryption is performed throughout the data flow, a count is maintained of the number of times deduplication is performed throughout the data flow, and a count is maintained of the number of times compression is performed throughout the data flow.","For example, consider the computing environment represented in , and in which the database  is configured to perform encryption, and network device  is configured to perform encryption. Further, in this example, policy  is set such that no redundant data management operations are performed. Referring now to , field  of database node  would hold a value of +1 to indicate that the database  performed encryption. Similarly, field  of network device  would hold a value of +1 to indicate that the network device performed encryption. Thus, in this example the counter monitoring encryption throughout the data flow would indicate a value of +2, signifying that encryption is being performed redundantly.","Once the analysis module  analyzes the data flow topologies ,  the recommendation module , in step , provides recommendations to reconfigure the data components such that the policy  is met. In one embodiment, the recommendations are provided upon a user request. In another embodiment, the recommendations are provided at regular, predetermined intervals. In an embodiment, the regular intervals are set by an administrator or a user. For example, the recommendation module  is configured to provide recommendations every week. Alternatively, the recommendation module  is configured to provide recommendations when an additional data component is added, or when a data component is removed from the data flow.","The recommendations may be provided on a graphical user interface (GUI), as scripted commands, as written recommendations, or via some other communications means well known to those skilled in the art. Alternatively, the recommendations may not displayed and the process flows immediately to step . In one embodiment, the recommendations are provided to the administrator or user such that the administrator or user can indicate if the recommendation should be followed. For example, a GUI interface may indicate that a redundant deduplication operation has been found, and provides a recommendation to remove the second deduplication operation within the data flow. The GUI interface displays a message to the administrator or user asking if the recommendation should be followed. For example, a message of \u201cExecute recommendation?\u201d may be displayed. In step , the administrator or user can indicate that the recommendation should not be followed and the process ends. Alternatively, if the administrator or user indicates that the recommendation should be followed in step  then the process flows to step .","In step  the execution module  executes the recommendation provided by the recommendation module . The execution module  sends commands to the management system  to reconfigure the data components. For example, if a redundant deduplication operation was performed at a network device , upon receiving a recommendation to eliminate the redundant deduplication operation at the network device , the execution module  sends a command to reconfigure the data management operations at the network device .","Once the execution module  executes the recommendations the process flows to step . In step , the discovery module determines whether additional data components have been added. Alternatively, the discovery module  may also determine if any data components have been removed. The addition or removal of a data component may change the data flow topology and, thus may require a reconfiguration of data management operations. If it is determined in step  that additional data components have been added or data components have been removed from the data flow the process returns to step  wherein the data components are discovered. On the other hand if no additional data components are added or no data components have been removed the process ends.","While only one management system is shown, it should be understood by one of ordinary skill in the art that a plurality of management systems may be interconnected.","It should be appreciated that such operations can be embodied as a method implemented as an algorithm having software modules that are implemented by a computing system. Further, the method can be embodied as software on any computer readable media, as dedicated firmware, or as a combination of software and firmware, and the like.","As will be appreciated by one skilled in the art, aspects of the present invention may be embodied as a system, method or computer program product. Accordingly, aspects of the present invention may take the form of an entirely hardware embodiment, an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to herein as a \u201ccircuit,\u201d \u201cmodule\u201d or \u201csystem.\u201d Furthermore, aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium(s) having computer readable program code embodied thereon.","Any combination of one or more computer readable medium(s) may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be, for example, but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, or device, or any suitable combination of the foregoing. More specific examples (a non-exhaustive list) of the computer readable storage medium would include the following: an electrical connection having one or more wires, a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a portable compact disc read-only memory (CD-ROM), an optical storage device, a magnetic storage device, or any suitable combination of the foregoing. In the context of this document, a computer readable storage medium may be any tangible medium that can contain, or store a program for use by or in connection with an instruction execution system, apparatus, or device.","Program code embodied on a computer readable medium may be transmitted using any appropriate medium, including but not limited to wireless, wired, optical fiber cable, RF, etc., or any suitable combination of the foregoing. Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages, including an object oriented programming language such as Java, Smalltalk, C++ or the like and conventional procedural programming languages, such as the \u201cC\u201d programming language or similar programming languages. The program code may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).","Aspects of the present invention are described above with reference to flowchart illustrations and\/or block diagrams of methods, apparatus (systems) and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and\/or block diagrams, and combinations of blocks in the flowchart illustrations and\/or block diagrams, can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions\/acts specified in the flowchart and\/or block diagram block or blocks.","These computer program instructions may also be stored in a computer readable medium that can direct a computer, other programmable data processing apparatus, or other devices to function in a particular manner, such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function\/act specified in the flowchart and\/or block diagram block or blocks. The computer program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other devices to cause a series of operational steps to be performed on the computer, other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions\/acts specified in the flowchart and\/or block diagram block or blocks.","The flowchart and block diagrams in the above figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods and computer program products according to various embodiments of the present invention. In this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and\/or flowchart illustration, and combinations of blocks in the block diagrams and\/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.","The term logic may include, by way of example, software, hardware, firmware, and\/or combinations of software and hardware.",{"@attributes":{"id":"p-0080","num":"0079"},"figref":"FIG. 8","b":["800","10","100","800","800","802","804","804","804"]},"Input\/Output (I\/O) devices ,  (including but not limited to keyboards, displays, pointing devices, etc.) may be coupled to the system either directly or through intervening I\/O controllers .","Network adapters  may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems, cable modem and Ethernet cards are just a few of the currently available types of network adapters .","The computing system  may be coupled to storage  (e.g., a non-volatile storage area, such as magnetic disk drives, optical disk drives, a tape drive, etc.). The storage  may comprise an internal storage device or an attached or network accessible storage. Computer programs in storage  may be loaded into the memory elements  and executed by a processor  in a manner known in the art.","The computing system  may include fewer components than illustrated, additional components not illustrated herein, or some combination of the components illustrated and additional components. The computing system  may comprise any computing device known in the art, such as a mainframe, server, personal computer, workstation, laptop, handheld computer, telephony device, network appliance, virtualization device, storage controller, etc.","The foregoing description of embodiments of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the embodiments to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. It is intended that the scope of the embodiments be limited not by this detailed description, but rather by the claims appended hereto. The above specification, examples and data provide a complete description of the manufacture and use of the composition of the embodiments. Since many embodiments may be made without departing from the spirit and scope of the embodiments, the embodiments reside in the claims hereinafter appended or any subsequently-filed claims, and their equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Embodiments of the present invention are understood by referring to the figures in the attached drawings, as provided below.",{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
