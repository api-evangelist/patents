---
title: Managing recovery virtual machines in clustered environment
abstract: Techniques involving replication of virtual machines of virtual machines in a clustered environment are described. One representative technique includes receiving a replication request to replicate a primary virtual machine. A clustering broker is configured to act on the replication request on behalf of a cluster of recovery nodes, by at least placing a replicated virtual machine corresponding to the source virtual machine on a recovery node and facilitate tracking the migration of the replicated virtual machine within the cluster. The clustering broker returns an address of the recovery node that has been placed or found through tracking for the particular virtual machine.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09176829&OS=09176829&RS=09176829
owner: Microsoft Technology Licensing, LLC
number: 09176829
owner_city: Redmond
owner_country: US
publication_date: 20110701
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["With the heavy reliance on computing needs by businesses and individuals, the need for uninterrupted computing service has become increasingly vital. Many organizations develop business continuity plans to ensure that critical business functions will enjoy continuous operation and remain available in the face of machine malfunctions, power outages, natural disasters, and other disruptions that can sever normal business continuity.","Local disruptions may be caused, for example, by hardware or other failures in local servers, software or firmware issues that result in system stoppage and\/or re-boot, etc. Local solutions may include server clustering and virtualization techniques to facilitate failover. Local failover techniques using virtualization provide the ability to continue operating on a different machine or virtual machine if the original machine or virtual machine fails. Software can recognize that an operating system and\/or application is no longer working, and another instance of the operating system and application(s) can be initiated in another machine or virtual machine to pick up where the previous one left off. For example, a hypervisor may be configured to determine that an operating system is no longer running, or application management software may determine that an application is no longer working which may in turn notify a hypervisor or operating system that an application is no longer running. High availability solutions may configure failover to occur, for example, from one machine to another at a common site, or as described below from one site to another. Other failover configurations are also possible for other purposes such as testing, where failover may even be enabled from one virtual machine to another virtual machine within the same machine.","Disaster recovery relates to maintaining business continuity even in the event of large scale disruptions. For example, certain failure scenarios impact more than an operating system, virtual machine, or physical machine. Malfunctions at a higher level can cause power failures or other problems that affect multiple machines, or an entire site such as a business's information technology (IT) or other computing center. Natural and other disasters can impact an enterprise that may cause some, and often all, of a site's computing systems to go down. To provide disaster recovery, enterprises may replicate information from one or more computing systems at a first or \u201cprimary\u201d site to one or more computing systems at a remote, secondary or \u201crecovery\u201d site. Replicating information may involve continuous, or at least repeated, updates of information from the primary to the recovery site.","To provide high availability, either or both of the primary and recovery sites may utilize failover clustering as described above, where a virtual machine or other information may remain available even when its host server fails. The use of both disaster recovery techniques between sites, in combination with clustering techniques between servers at either\/each site, creates some complexities. For example, the use of failover clustering techniques at the recovery site may involve running another instance of a first recovery server's virtual machine in at least one other recovery server, such as when the first recovery server fails or otherwise becomes unavailable. When this first recovery server, and possibly some or all of the other recovery servers, are offline due to planned or unplanned events, the source or \u201cprimary\u201d server would be unable to send any further replicas (e.g., replicated virtual machine base information and\/or updates thereto) to the offline recovery server(s). The virtual machine replication would be suspended, but the virtual machine at the primary site would continue its workload, which would result in changes to the virtual machine. These changes to the virtual disk will continue to accumulate at the primary site, as the recovery server has become unavailable to receive the otherwise more frequent replicas. When the offline recovery node becomes available again, there would be spikes in the resource utilization as the amount of data to be sent could be very large. In cases of prolonged downtime of the recovery server, a complete replication may need to be started from scratch resulting in loss of data and exposing the business to an extended unprotected period. This could further impact operations as the initial replication may be significantly larger than \u201cdelta\u201d replicas, and the virtual machine may require additional configurations in view of the initial replication. Further, if disaster strikes at the primary site during the time the recovery server is down, business continuity would be lost. A significant amount of data would likely be lost as well, as the data on the recovery server would be substantially behind the primary server due to the interruption of the replication process.","Techniques involving replication of virtual machines in a clustered environment are described. One representative technique includes receiving a replication request(s) to replicate at least a portion of a source or \u201cprimary\u201d virtual machine. A clustering broker is configured to act on the replication request on behalf of a cluster of recovery nodes, by at least facilitating placement of a replicated virtual machine corresponding to the source virtual machine on a recovery node, and enabling the migration of the replicated virtual machine to be tracked within the cluster. The clustering broker returns the network address of the recovery node that has been placed or found through tracking for the particular virtual machine.","In another particular implementation of such a technique, a computer-implemented method for facilitating replication of virtual machines is provided. For example, such a method may facilitate replication of virtual machines in the case of migration of virtual machines at a recovery site. In one embodiment, the computer-implemented method involves receiving a first update request at a targeted recovery node to provide an update to a replicated virtual machine that is hosted by the targeted recovery node. In the event of the replicated virtual machine having migrated from the target recovery node, a second update request is received at a clustering broker that acts on behalf of a cluster of recovery nodes, including the target recovery node. The clustering broker identifies the current recovery node in the cluster to which the replicated virtual machine has migrated, and the address of that current recovery node is returned to the primary server that made the update requests.","Another representative implementation involves another computer-implemented method for facilitating replication of virtual machines. The computer-implemented method includes receiving a request from a source server to establish a relationship to replicate a virtual machine on any recovery server that is part of a cluster of recovery servers. The request is accepted by a clustering broker on behalf of the cluster of recovery servers, which selects one of the recovery servers to host the replicated virtual machine. The clustering broker places the replicated virtual machine on the cluster to configure the replicated virtual machine as highly available. A network address of the selected recovery server that is hosting the replicated virtual machine is sent to the source server.","In one particular embodiment associated with any of the devices and\/or techniques described herein, centralized management may be provided on a cluster of recovery nodes. For example, a user interface may be provided to facilitate establishing, changing or otherwise manipulating configuration settings and propagating such configuration settings to any or all of the nodes of the cluster. In one embodiment, the centralized management may be automated, and may enable, for example, the creation of high-availability virtual machines.","This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.","In the following description, reference is made to the accompanying drawings that depict representative implementation examples. It is to be understood that other embodiments and implementations may be utilized, as structural and\/or operational changes may be made without departing from the scope of the disclosure.","The disclosure is generally directed to data replication. While the principles described herein are applicable to any replication of data from one data storage device or facility to another data device or facility, numerous embodiments in this disclosure are described in the context of disaster recovery where replicated data and processing resources are provided off-site from the primary computing center. It should be recognized, however, that the principles described herein are applicable regardless of the distance or manner in which replicated data is transferred to the recovery site(s).","A virtual machine (VM) running may be running on a first computing device referred to herein as a primary server, at a first site referred to herein as a primary site. The VM can be replicated to at least one second device (recovery server) at a second site (recovery site). An initial replication (IR) is initially performed where the VM is sent either over the network (online IR) or off the network (out-of-band, or OOB IR). When the IR is complete, changes or \u201cdeltas\u201d to the virtual machine are recorded on differencing disks or by other similar means and sent to the recovery site. These updates to the VM's virtual disk may be sent at fixed, changing, or random intervals, but in any event are recurring in one embodiment.","As noted above, the recovery site may employ failover clustering techniques, where computing devices in the cluster can continue running VMs when their respective host devices fail. Where disaster recovery techniques are also used, updates from a primary server to a recovery server might not reach their targeted recovery server if and when that recovery server is down for any reason. This creates complexities, and can adversely impact recovery point objectives (RPO).","For example, when a recovery server goes offline, the primary server would be unable to send any further replicas to the offline recovery server. The virtual machine replication would be suspended, but the virtual machine at the primary site would continue its workload and consequent updates to the virtual storage. These updates will accumulate on the primary server, as the offline recovery server cannot accept the incoming replicas. When the offline recovery node again becomes available, there would be spikes in the resource utilization as the amount of data to be sent could be very large. In cases of prolonged downtime of the recovery server, another IR may be required. Business continuity can be lost where disaster strikes at the primary site during the time the recovery server is down. A significant amount of data would likely be lost as well, as the data on the recovery server would lag that of the primary server as a result of the inability for the primary server to regularly send the virtual disk updates.","As noted above, whenever one of the nodes on the recovery side experiences downtime for maintenance, unplanned events, etc., the VM can be made available in another node, and the VM replication from primary to recovery can continue. However, various circumstances occurring at the clustered recovery site can raise issues and result in complexities. For example, when a VM moves or \u201cmigrates\u201d from one recovery server to another recovery server in a clustered environment, the primary server will be unaware of the move. The primary server would continue to send replication data to the recovery server that was previously set up as the destination (if it is still available), which would reply with a message indicating that the VM is not available. The replication would stop until an administrator intervenes to fix it.","Another issue relates to high availability for the recovery VM and load balancing. Virtual machines that are created on the recovery side may be made to be highly available, so that the administrator can move them around easily for maintenance of the nodes, to achieve load balancing, or other reasons. For example, there is a process to make a particular functionality, whether that be a SQL server, file server, VM, etc. to be made a cluster resource. Typically this is a manual step, and is increasingly tedious as the number of virtual machines at the recovery site increases. Further, the virtual machines will have an initial node where they are placed \u2014if they were all initially placed on one node, the load on that node would be higher than on the rest.","Recovery server configuration synchronization can also be an issue. A recovery server may need to be configured to accept replication. To ensure that the nodes are symmetric in terms of the replication, the configuration steps would need to be repeated on each cluster node. Further, after the initial configuration, configuration changes might occur and these need to be kept in sync, which can be tedious and error-prone.","Another representative problem relates to the initial replication (IR) in the recovery site cluster. The size of the IR data (for virtual machines) may be on the order of many gigabytes, and online IR may not be economical from both a cost and resource perspective. As a result, the primary administrator may perform an out-of-band (OOB) IR on the initial replica. Upon receiving the initial replication payload, the recovery side administrator would have to manually find the recovery node to which the initial copy was made, and perform tasks to complete the initial replication on that node. This can be arduous, especially where the number of virtual machines has grown into the hundreds across large clusters.","These issues increase the cost of operations, and are not uncommon VM migrations are commonly used for optimizing resource consumption and for maintenance. This is true even for recovery virtual machines that are not running. The significance of these problems continues to increase as clustering deployments are increasing in size, both in terms of the number of nodes and the number of virtual machines. Without a good solution to these problems, users may have to cut back on the flexibility of deployment topology and\/or bear additional costs of operations.","To address these and other problems, the present disclosure provides solutions enabling lower total cost of ownership (TCO). Among other things, techniques described in the disclosure enable placement of virtual machines across storage types, creating recovery high-availability virtual machines without administrator intervention, establishing replication after a recovery virtual machine migrates, and unified and centralized management with failover clustering.","Various embodiments below are described in terms of virtual machines. Virtualization generally refers to an abstraction from physical resources, which can be utilized in client and server scenarios. Hardware emulation involves the use of software that represents hardware the operating system would typically interact with. Hardware emulation software can support guest operating systems, and virtualization software such as a hypervisor can establish a virtual machine (VM) on which a guest operating system operates. Much of the description herein is described in the context of virtual machines, but various principles described herein are not limited thereto.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 1","b":["100","120","100","120","100","100","120","100","120","100"]},"The representative primary site  may include one or more primary computing devices or servers, depicted as primary devices P , P  through Pn . These devices may host various types of servers, such as structured query language (SQL) or other database servers, e-mail servers, customer relationship management (CRM) servers, Internet information services (IIS) servers, etc. The devices P , P , Pn  may be coupled via a storage area network (SAN)  to enable storage devices to be accessible to the servers. It should be noted that use of a SAN  is optional, and the principles described herein are equally applicable in connection with any storage. Firewall\/virtual private network (VPN)  or analogous security connection mechanisms may be used to secure the connection(s) between the primary site  and recovery site .","At the recovery site , the example of  assumes a cluster  of recovery computing devices, depicted as recovery devices R , R  through Rn . The multiple devices of the cluster  may provide failover clustering to provide high availability at the recovery site . The recovery devices R , R , Rn  provide the computing resources where replicated information from the first site  may be received and stored, and where recovery computing operations can be initiated in the event of disaster or other event rendering the first site  unable to continue its computing responsibilities.","The first site  and second site  communicate by way of communication links , which can involve any type of electronic communication interface such as direct cabling, wireline networks, wireless networks and the like, and any combination thereof. As noted above, embodiments where disaster recovery is an objective, the communication links  will generally involves expanded networks such as a wide area network (WAN), global area network (GAN) or other network enabling the remote site  to be sufficiently separated from the primary site  to avoid being subjected to the same disaster event. Some or all of the recovery devices R , R , Rn  of the cluster  may be coupled, for example, via a SAN  or other shared storage technology to enable storage devices to be accessible to the recovery servers. Firewall\/VPN  or analogous security connection mechanisms may be used to secure the connection(s) between the primary site  and recovery site .","To address at least the problems described above, a brokering technique is disclosed that provides an intermediary of administrative services for brokering the management of virtual machines between the site requesting replication and the site where replication is conducted. In one embodiment, this resource may be provided at any of a plurality of nodes in the cluster , as depicted by clustering brokers , , , which may provide a high availability clustering broker solution. In one embodiment, a single instance of this clustering broker resource (e.g., clustering broker ) will be running at a recovery cluster but is available to all nodes , , . As a more particular example, the clustering broker  may reside on a particular node , but may be available to all of the notes , , , and may be a highly-available resource in that if node  was to fail or otherwise go down, the clustering broker may be instantiated in another node (e.g., clustering broker  of node ). Thus, while  depicts a clustering broker , ,  at each of the nodes in the cluster , it should be recognized that in one embodiment a single clustering broker is provided at any of the nodes , ,  to provide the clustering broker functionality described herein. Among other things, the functionality of the clustering broker , ,  facilitates placement of virtual machines across storage types, creation of high-availability virtual machines without administrator intervention, management of replication after a recovery virtual machine migrates, and centralized management.","For example, assume that primary device or \u201cnode\u201d  attempts to send a replication update, such as a differencing disk, snapshot or other copy, to the recovery device or \u201cnode\u201d . Where a virtual machine VM A migrates from node  to node  as depicted by migrated VM B, the clustering broker  can serve as an intermediary between the primary server requesting the replication update (P ) and the cluster . The clustering broker  can, for example, notify the requesting primary node P  on behalf of the targeted recovery device R  that the VM A has migrated to node . Further, the clustering broker , ,  can locate a targeted recovery node when an initial replication payload is received at the cluster , which relieves the manual administrative process of manually finding the recovery node to which the initial replication was made and perform the task of completing the initial replication on that node. The clustering broker , ,  can also facilitate moving virtual machines from node to node for maintenance, to achieve load balancing, etc. The clustering broker , ,  can also enable configuration functions to be performed once while propagating the settings to the other nodes, to alleviate configuring each node separately. Configuration settings can also be kept in sync through a single access point when the configuration changes.",{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 2","b":["200","202","205","206","208","201","202","205","210","212","214","216","218","206","208","216","218","220"]},"In accordance with the present disclosure, the functionality of the clustering broker  can be provided at each node -, as depicted by clustering brokers , , , . In one embodiment, only one instance of the clustering broker , - will be running at a time, and the cluster-related activity goes through that active resource instance. In one embodiment, the clustering broker functionality is made highly available, and other nodes can become the node that hosts the running instance of the clustering broker functionality. In one embodiment, this is accomplished at least in part by installing the clustering broker  as a \u201cresource type\u201d of the cluster, wherein a resource type generally refers to a component that provides functionality to the cluster.","The clustering broker provides functionality including any one or more of VM creation, VM placement, and VM tracking, as well as other functionality on behalf of the nodes at the recovery site. For example, the clustering broker  may operate in connection with functionality such as a virtual machine creation module  that assists in the creation of a recovery VM (e.g., VM ) when a request from a primary node requests it. The VM creation module , which in one embodiment includes software executable via the processor  or other controller(s), assists in creating high-availability virtual machines. For example, when a primary node sets up a replication relationship with a recovery node, a virtual machine may be established on the recovery side. The VM creation module  can carry out the process to make the new VM highly available, which ultimately makes the VM capable of moving between the nodes -. The VM creation module  may be implemented, for example, within the operating system  or hypervisor , or as part of the clustering broker .","Another function of the clustering broker  is the VM placement module , which can select a node in which a virtual machine will be placed, and return the recovery node\/server name in which the VM was placed back to the requesting primary node. Load balancing may also be utilized by the VM placement module , whereby VM placement decisions involve distributing or balancing the workload among the nodes -. A VM tracking module  facilitates identification of a recovery node that is currently hosting a targeted VM, after that VM has migrated from a recovery node that was previously known to the sending primary node. These modules ,  may also include software that is executable by the processor  or other controller(s).","In one embodiment, centralized management is provided, and configuration settings may be propagated to each of the nodes - by way of entry of the settings at one node. A management module  is provided to facilitate central management, which too may be a software module executable by the processor  or other controller(s). In one embodiment, the management module  is unified with failover clustering management. Recovery servers can be configured to accept replication via the management module  may be available at a central location of the clustering broker, or with any of the nodes -.","In one embodiment, setting the configuration on the clustering broker can set the same configuration on all of the nodes - using, for example, a cluster database which is a functionality that may be provided by the cluster. For example, a graphical user interface (GUI) may be provided that enables configuration of a recovery server, which can be propagated to other recovery nodes. The GUI may enable entry of information such as whether to enable a particular node to be used as a recovery server, whether to authenticate incoming replication requests, and if so, what authentication type to use, what port numbers to use for incoming replication requests, whether replication requests can be obtained from any (primary) server, or only from those servers associated with a list, etc. It should be noted that the recovery site  may include servers or other computing devices having analogous processing, memory, storage, virtual machine and virtual machine management capabilities as described in .",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 3A","FIG. 3A","FIG. 3A"],"b":["302","304","308","322","324","326","330"]},"In one embodiment, such as the embodiment illustrated in , some clustering broker functionality is placed in a management module(s). One representative example of such a management module is, for example, the virtual machine management service (VMMS) provided as part of HYPER-V\u2122 by MICROSOFT\u00ae Corporation. The VMMS  (or other management module) generally represents a management service that serves as a point of interaction for incoming management requests. Some of the clustering broker functionality is also placed in the VM cluster resource , which is a cluster resource DLL. However, while the description of  is described in terms of a VMMS  and a VM cluster resource , it should be recognized that the principles described herein are equally applicable to any other analogous functionality for managing or interacting with virtual machines. Thus, the functionality described herein may be disassociated with any VMMS  or VM cluster resource .","The representative replica clustering broker (RCB)  runs on the recovery cluster, and serves as a single point of contact in the recovery cluster for the virtual machines being replicated. Among other things, the RCB  provides a recovery server name for initial VM placements, and provides the VM to recovery server mapping. The representative RCB  includes the VM cluster resource  that can create the cluster service. A \u201cresource\u201d generally represents a unit of functionality that can be managed in a cluster, and can migrate as well. Thus, a resource in this regard can be considered high availability (HA). As machines can go down based on various activities (e.g., load balancing or other cluster initiated activity), the RCB  is made highly available (HA) on the recovery cluster. In one embodiment, the interactions with the clustering occur in the VM cluster resource  DLL.","In one embodiment, the communication between the VMMS  and the VM cluster resource  occurs using component object model (COM) calls  and COM events . In one embodiment, COM calls  are used for calling into the VMMS  (or other management entity) from the VM cluster resource , and COM events are used for calling into the VM cluster resource  from the VMMS . The various modules associated with the representative RCB  are now described.","The FR broker resource  is a new resource type added into a VM cluster resource DLL , which makes the FR broker resource  highly available. In one embodiment, the recovery cluster has one instance of the FR broker resource  running, and all of the cluster-related activity comes to that base resource instance. When an instance of this resource type is created, a network resource is also created, which has a client access point (CAP) in the cluster. Generally, a CAP is another resource type of the cluster that represents a combination of a network name and associated IP address resource. Thus, when the FR broker resource  instance is created, the CAP will expose a network name, and one or more addresses such as an IPv4 and\/or IPv6 address. The CAP does not contain the fully-qualified domain name (FQDN), so in one embodiment the domain name service (DNS) name is extracted from the node and appended to the CAP name. Other manners of obtaining the FQDN may similarly be used. It should be recognized that while \u201cFQDN\u201d is used an example herein, other representations of complete domain names may also be used. In any event, this full name may be used as the network name for the recovery cluster (e.g., cluster  of  or cluster  of ), and the primary servers use this name to connect to the recovery cluster. The CAP, FQDN or other unique address of the recovery cluster is different from any of the recovery server names in the cluster. When the FR broker resource  instance becomes active\/online, it triggers FR broker manager  to start the FR network listener , which is described more fully below. Incidentally, when FR broker resource  goes offline, the FR network listener  will be stopped.","Other RCB  modules associated with the VM cluster resource  are the FR broker COM client  and the event handler . These modules communicate with the COM FR broker cluster manager  at the VMMS . In one embodiment, the COM FR broker cluster manager  is a private COM server used for communicating between the VM cluster resource  and VMMS. An interface object of COM FR broker cluster manager , shown as the FR broker COM client , is created in the VM cluster resource  and used to communicate with VMMS . An event sink or handler  is also implemented to receive incoming events provided in the COM FR broker cluster manager . When VMMS  wants to call into the VM cluster resource , it uses these events.","In one embodiment, the FR broker manager  is a singleton object that is activated from the VMMS's  service module (not shown). In one embodiment, the FR broker manager  maintains the FR network listener  and a reference to the COM FR broker cluster manager  in case VMMS  is running in a clustered environment. The FR broker manager  is configured to receive messages from the primary site through the FR network listener , make calls into the VM cluster resource  using the COM FR broker cluster manager , and reply back to the primary site.","In one embodiment, the FR manager  places the virtual machines into nodes, and calls into the FR broker manager  to initiate making the virtual machines highly available by having them placed on the cluster. The FR broker manager  can internally call the FR broker resource  to make the particular VM highly available. For example, a VM that is made highly available will have its files (e.g., VHD, AVHD and\/or other files related to the VM) stored in clustered storage.","When nodes at the primary site want to communicate with nodes at the recovery site, messages from the primary site will arrive at the VMMS . When the FR network listener  has been started in response to the FR broker resource  instance becoming active, the FR network listener  receives those requests, passes them on to the FR broker manager  to ultimately be communicated to the FR broker resource  to obtain the information associated with the request. Thus, the FR network listener  is used to handle the request from nodes at the primary site.","In one embodiment, the network listener can use the same ports as failover recovery, but uses a different network name, which is the RCB  CAP  or other FQDN. This CAP  has a unique IP address associated with it, which the FR network listener  monitors for. The FR network listener , which may be a hypertext transfer protocol (HTTP) network listener referred to herein as FrnHttpServer, may work in stand-alone replication and be re-used in the cluster replication described herein. For example, the FR network listener  FrnHttpServer assumes that it is hosting the local server, and takes the local machine name as part of its uniform resource identifier (URI). The RCB  has a different CAP, and the URI will be different. In one embodiment, both the recovery server and the RCB  can listen using \/frvroot. For example, multiple listeners may be listening on one port, and a URI such as the example frvroot may be used to identify the listener who should pick up the calls. Thus, for purposes of this example, frvroot is merely an example of a name of the listener to which the sending device wishes to send a request or otherwise call. The URI formed will be different because the hostname is different between the two. For example, for a recovery server r1.contoso.com, the recovery server URI may be http:\/\/r1.contoso.com:80\/frvroot. For RCB  running on the same server with CAP name \u201cbrkr,\u201d the URI would be http:\/\/brkr.contoso.com:80\/frvroot.","When a server is enabled as a recovery server, a network listener may be brought up. In one embodiment, this occurs independent of whether the particular server is a stand-alone server or a clustered server. Thus, in a clustered environment made up of X nodes, one embodiment involves providing an FR network listener  on each of the nodes, plus one broker listener for the cluster.  provides an alternative depiction of network listener functionality in the RCB  in accordance with one embodiment. More particularly, as previously noted, when an instance of a FR broker resource  is created, a network resource is also created in one embodiment, which has a CAP  in the cluster. This refers to the broker listener, or the listener that serves as the listener for the cluster. Thus, network listener functionality  communicatively coupled to the FR broker manager  may include the CAP  provided on behalf of the cluster, and the FR listener  that is provided on each of the nodes of the cluster. As noted above, the FR network listener  may take the local machine name as part of its URI, where the RCB  has a different CAP so its URI will be different. The URIs formed will be different because the hostname is different between the two, as noted above. Thus, in one embodiment, there are two entities running on the same port with different URIs.",{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIG. 4","FIG. 3A","FIG. 4"],"b":["330","400","336","330","402","330","304","404","406","330","306","406","406","330","406","406","330","406","406","406","330","406","406","406","406"]},"As shown at block , the FR manager  can call the FR broker manager , who in turn calls the FR broker resource  requesting that the VM be made highly available. In one embodiment, the FR broker manager  calls the FR broker resource  by way of a COM event(s)  from the COM FR broker cluster manager  to the FR broker COM client . Block  shows that the FR broker resource  can then place the VM on the cluster, thereby making it highly available (HA). The FR broker resource  can itself place the VM on the cluster, or in other embodiments it may direct one or more other modules to place the VM on the cluster. The FR broker manager  sends the FQDN or other location identifier of the selected and highly-available recovery node back to the primary server, as shown at block . Since the primary server obtained an FQDN or other unique identifier in response, the primary server will know that it is communicating with an RCB , and will store information, set a flag, or otherwise remember that information as shown at block .","It should be recognized that the functions shown in  are representative of one embodiment, as the broker functionality may involve checking of additional pre-requisites in some embodiments. For example, in one embodiment, the clustering broker can be extensible wherein it can provide for other modules to plug in rules that are run before placing a VM on a node. This may be utilized by management software to do additional logic while placing a VM, and achieve better resource management.","In addition to placing nodes, the RCB  can assist in load balancing by placing VMs in a manner that distributes the VM workload over the nodes of the cluster. By making VMs high availability on the recovery side, the VMs can be moved around easily to achieve load balancing (or for other purposes such as node maintenance). The placement of HA nodes are, in one embodiment, influenced by load balancing criteria. Various manners of effecting load balancing can be employed, such as a round-robin approach. In this approach, nodes are assigned to virtual machines in a round-robin fashion. The last node assigned may be persisted across moves of the RCB  itself. Another representative manner of effecting load balancing is to randomly select nodes, such as by assigning nodes using a random number generation algorithm. Yet another manner involves using a clustering application programming interface (API) that provides for load balancing. Any of these, or other, manners of providing load balancing may be implemented in connection with the placement of high-availability nodes on the cluster.",{"@attributes":{"id":"p-0062","num":"0061"},"figref":["FIGS. 5 and 6","FIG. 3A","FIG. 5"],"b":["500","300","304","502","504","302","322","506","302","508"]},{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 6","b":["600","602","604","602","600","606","608","610","608","612","600","600","614"]},"In response to learning that the VM was not at the recovery node to which a replication relationship had previously existed, the primary node  sends a node location request to the CAP of the clustering broker, since it remembers that it has communicated with a broker. This embodiment is shown at block . The recovery node  receives the node location request at the clustering broker (e.g., RCB) as illustrated at block . As block  shows, the clustering broker finds the node that is the current owner of the VM. In one embodiment, it does this by looking in the cluster database using a unique identifier for the VM, such as a globally unique identifier (GUID), universally unique identifier (UUID) or other unique identifier, and finding the node in the cluster database based on that identifier. Block  shows that the clustering broker sends the FQDN or other unique address of the node that currently owns the VM back to the primary server , which receives the new location identifier as shown at block . As these examples illustrate, these processes can be accomplished without manual administrator efforts.",{"@attributes":{"id":"p-0065","num":"0064"},"figref":["FIG. 7","FIG. 3A"],"b":["700","702","706","708","710","712","322","308","302","304"]},"The VM cluster resource  includes a cluster service (API)  that represents a system component used to control failover cluster activities on a single node. In accordance with the present disclosure, the cluster service  receives an indication to configure the FR broker to come online as depicted at message . The cluster service  calls the online function of the FR broker resource  when it is to be initiated, as shown by message . The FR broker resource  fetches the CAP name from the cluster resource group that it is part of, where the CAP may be configured as part of the clustering broker, and the FR broker resource  then calls into the VMMS  as shown by message . Using the CAP, the call  can start the network listener . More particularly, the call  from the FR broker resource  is provided to the FR broker manager  via the COM FR broker manager  as shown by message . In response, the FR broker manager  creates the network listener  using the given CAP name, as depicted by message . The network listener , which in one embodiment is a secure HTTP server (e.g. HTTP\/S server), is started , and a reply can be provided thereafter. In one embodiment, the HTTP server need not be a secure server, although is depicted as a secure server in . In general,  illustrates that the clustering broker startup generally involves creating an instance of a clustering broker resource type, creating a network resource having a CAP (or other analogous address) in the cluster, obtaining a full FQDN is needed, and triggering the start of the network listener in response to the FR broker resource  coming online.",{"@attributes":{"id":"p-0067","num":"0066"},"figref":["FIGS. 8A-8D","FIGS. 8A-8D","FIGS. 8A-8D"]},"In one embodiment, failover replication does not expose the concept of the recovery cluster to the user on the primary server(s) at the primary site. The representative protocols of  can work with both the cluster and a stand-alone node on the recovery site with no change expected on the user's part, and these figures illustrate a representative example of connection sequences and packet details. More particularly,  illustrates a representative packet  or portion thereof that can be used by the primary server to send a negotiate request packet. The representative packet  has a width , but any packet structure may be implemented. Packet fields such as tag reserved , tag type  and tag length  may be provided. Fields that include information relating to the clustering broker include the protocol version , failover replication capabilities  and authentication type . The protocol version  is provided by the primary server for compatibility issues, and the recovery server can verify the compatibility on its response. Failover capabilities  can be used to determine the capabilities for compression types and encryption levels that the primary server and recovery server supports. The authentication type  indicates the type of authentication used for this connection. As an example, a first value could indicate integrated authentication using Kerberos, a second value could indicate authentication using secure sockets layer (SSL) certificates, etc.","In response to successfully receiving the primary server's negotiate request packet , the recovery server sends a response, such as the negotiate response packet . The response includes at least a recovery protocol version  that provides an indication of whether the protocol version of the primary server is compatible with the recovery server. The values in this field may be, for example, a verification value in which case the communication can continue, or a protocol mismatch error value in which the communication may be closed.","The recovery type  indicates whether the responding recovery server is a clustering broker or a stand-alone recovery server. There may be differences in the communication between a primary site and a recovery site depending on whether the recovery site is operating as a stand-alone recovery server or a recovery cluster. The value provided in this recovery type  field indicates whether the responder is a stand-alone recovery server, or a clustering broker as described herein. A first value could indicate a recovery type of stand-alone, a second value could indicate a recovery type of clustering broker, etc. The sending primary server need not know the type of recovery entity that it will be dealing with when sending it's negotiate request packet . This information can be provided back to the primary server. If the recovery type  is a stand-alone, the primary server can simply communicate to the stand-alone recovery server in a normal process. If the recovery type  is a clustering broker, the primary server is made aware of this by way of the negotiate response packet , the primary server may thereafter send information that is specific to, or at least aware of, the recovery server being associated with a cluster.","In response to receiving the negotiate response packet  with successful status, the primary server looks at the recovery field type . If the recovery type  is set to indicate a clustering broker, in one embodiment the primary server sends a query recovery server packet  to the clustering broker at the recovery site. This packet  includes, among other things, the virtual machine identifier (VMID) ,  of the VM that the primary server wants to replicate, or to find the destination recovery server name for that VM. In one embodiment, the VMID value is a GUID and indicates the identifier of the virtual machine for which the clustering broker is queried for the placement of the VM.","In response to the clustering broker receiving the VMID from the VMID field , , the clustering broker looks up the node where the VM is available or needs to be placed. The clustering broker sends a packet  with the recovery server name  that is the name of the recovery server node in which the VM will be placed. The recovery port  provides the port of the recovery server node in which the connection is to be made. The packet  also includes the existing VM field  that indicates whether the VM already exists in the recovery cluster. This may be used, for example, to determine the deletion of the VM from the recovery server. For example, if the VM is deleted from the recovery server, the clustering broker may return this as a \u201c0\u201d or other set value, and the primary server can decide to go to a state that would trigger administration intervention or other desired actions.","In one embodiment, when the recovery cluster settings get updated, the changes are propagated to all of the nodes of the recovery cluster. The cluster can provide an event mechanism for providing a notification of the changes to all of the nodes. These events may include the resource state changes, property changes, etc.  is a message flow diagram illustrating one embodiment for propagating the settings to the nodes of the recovery cluster. For purposes of this example, it is noted that the FR broker resource , COM FR broker manager  and FR broker manager  respectively correspond to the modules ,  and  of .","The FR broker resource  can receive a message  for the FR broker resource to open or go online. When a change to any private property of a resource happens on any cluster node, a notification of the change can be provided to all of the nodes via the cluster events. The FR broker resource , on each node, listens  to the property change events. The listener will be started at the initialization of the FR broker resource on each node. Upon receiving a property change event as shown by event , the FR broker resource may use the values of the properties to update the settings and check the property name . The FR broker resource  sends the change notification to the FR broker manager  using, in one embodiment, a private COM interface between the FR broker resource  and the VMMS. In a more particular example shown in , the FR broker resource  notifies the VMMS of the property name, which is provided to the FR broker manager  via the COM FR broker manager  as shown by messages  and . The FR broker manager  can fetch the settings . The COM FR broker manager  can internally call into the WINDOWS\u00ae management instrumentation (WMI)  registered callback via FR broker manager . In one embodiment, the WMI  takes these changes  and updates the local registry on a separate thread. While the example of  involves an implementation utilizing WMI, the description is equally applicable to other management infrastructures.","As demonstrated in the foregoing examples, the embodiments described herein facilitate disaster recovery and other replication features for recovery sites that employ failover clustering and\/or other high availability techniques. Among other things, high-availability virtual machines can be properly placed on a recovery server by the clustering broker functionality that serves the recovery cluster. Unified management with existing products can be provided, such as with failover clustering products. No administrator intervention is needed to restart a VM replication if the recovery VM migrates from one recovery node to another. In this manner, VMs may be placed across storage types, centralized management can be provided, high-availability recovery\/replicated VMs can be created without administrator intervention, replication can be established after a recovery\/replicated VM migrates, etc.",{"@attributes":{"id":"p-0076","num":"0075"},"figref":"FIGS. 10 and 11"},{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 10","b":["1000","1002","1004","1006"]},"In other embodiments, receiving the request may involve receiving the request at a network listener that is directed to a client access point (CAP) associated with the cluster of recovery servers. In another embodiment, a domain name service (DNS) name for the recovery server hosting the active instance of the clustering broker may be extracted, and appended to the CAP for use as a network name for the cluster. In another embodiment, the clustering broker may implement load balancing across the recovery servers of the cluster when placing the replicated virtual machine on the cluster. Another representative example involves the clustering broker providing a notification directed to the source server that the request has been received by a clustering broker rather than a stand-alone recovery server that is not associated with the cluster, in order to enable the request to be directed to the clustering broker on behalf of the cluster of recovery servers. The clustering broker can be configured as a resource type of the cluster so that the clustering broker itself is highly available.",{"@attributes":{"id":"p-0079","num":"0078"},"figref":"FIG. 11","b":["1100","1102","1104"]},"In other embodiments, the current recovery node can be identified by receiving a unique identifier of the virtual machine in the second update request, and by using the unique identifier of the virtual machine, locating the current recovery node in a cluster database that provides an association of virtual machine unique identifiers and their current recovery nodes. In another embodiment, receiving a second update request addressed to a clustering broker involves receiving the second update request at a client access point (CAP) of a network listener of the clustering broker instead of at the targeted recovery node. Another embodiment involves receiving a third update request at the current recovery node to provide an update to the replicated virtual machine that migrated to the current recovery node.",{"@attributes":{"id":"p-0081","num":"0080"},"figref":["FIG. 12","FIG. 12","FIG. 12","FIG. 12"],"b":["1200","1212"]},"The representative computing system  includes a processor  coupled to numerous modules via a system bus . The depicted system bus  represents any type of bus structure(s) that may be directly or indirectly coupled to the various components and modules of the computing environment. Among the various components are storage devices, any of which may store the subject to the replication.","A read only memory (ROM)  may be provided to store firmware used by the processor . The ROM  represents any type of read-only memory, such as programmable ROM (PROM), erasable PROM (EPROM), or the like. The host or system bus  may be coupled to a memory controller , which in turn is coupled to the memory  via a memory bus . The exemplary memory  may store, for example, all or portions of a hypervisor  or other virtualization software, an operating system , and a module, such as a replica clustering broker (RCB)  that performs at least those functions described herein. The RCB  may be implemented as part of, for example, the hypervisor  and\/or operating system .","The memory may also store application programs  and other programs , and data . Additionally, all or part of the virtual storage  associated with a virtual machine may be stored in the memory . However, due to the potential size of the virtual storage disks or other virtual storage types, one embodiment involves storing virtual storage disks in storage devices versus memory, as depicted by the virtual storage B associated with any one or more of the representative storage devices , , , . The virtual storage A in the memory  may also represent any part of the virtual storage that is temporarily cached or otherwise stored in memory as an intermediate step to being processed, transmitted, or stored in a storage device(s) , , , .",{"@attributes":{"id":"p-0085","num":"0084"},"figref":"FIG. 12","b":["1230","1232","1234","1230","1234"]},"Similarly, an interface  for removable media may also be coupled to the bus . Drives  may be coupled to the removable storage interface  to accept and act on removable storage  such as, for example, floppy disks, optical disks, memory cards, flash memory, external hard disks, etc. Virtual storage files and other data may be stored on such removable storage .","In some cases, a host adaptor  may be provided to access external storage . For example, the host adaptor  may interface with external storage devices via small computer system interface (SCSI), Fibre Channel, serial advanced technology attachment (SATA) or eSATA, and\/or other analogous interfaces capable of connecting to external storage . By way of a network interface , still other remote storage may be accessible to the computing system . For example, wired and wireless transceivers associated with the network interface  enable communications with storage devices  through one or more networks . Storage devices  may represent discrete storage devices, or storage associated with another computing system, server, etc. Communications with remote storage devices and systems may be accomplished via wired local area networks (LANs), wireless LANs, and\/or larger networks including global area networks (GANs) such as the Internet. Virtual storage files and other data may be stored on such external storage devices , .","As described herein, the primary and recovery servers communicate information, such as negotiating and responding to requests, providing virtual machine base storage, differencing disks, snapshots, etc. Communications between the servers can be effected by direct wiring, peer-to-peer networks, local infrastructure-based networks (e.g., wired and\/or wireless local area networks), off-site networks such as metropolitan area networks and other wide area networks, global area networks, etc. A transmitter  and receiver  are depicted in  to depict the computing device's structural ability to transmit and\/or receive data in any of these or other communication methodologies. The transmitter  and\/or receiver  devices may be stand-alone components, may be integrated as a transceiver(s), may be integrated into or already-existing part of other communication devices such as the network interface , etc. Where the computing system  represents a server or other computing device at the primary site, all or part of the virtual disk or other stored data to be replicated may be transmitted via the transmitter , whether it is a stand-alone device, integrated with a receiver , integral to the network interface , etc. Analogously, where the computing system  represents a server or other computing device at the recovery site, all or part of the virtual disk or other stored data to be replicated may be received via the receiver , whether it is a stand-alone device, integrated with a transmitter , integral to the network interface , etc. Communication between primary and recovery servers will utilize both their transmitters  and receivers . As computing system  can represent a server(s) at either the primary or recovery site, block  represents the primary or recovery server(s) that is communicating with the computing system  that represents the other of the primary or recovery server(s).","Although the subject matter has been described in language specific to structural features and\/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as representative forms of implementing the claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIGS. 5 and 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIGS. 8A-8D"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
