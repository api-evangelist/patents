---
title: Efficient integrated digital video transcoding
abstract: Efficient integrated digital video transcoding is described. In one aspect, an integrated transcoder receives an encoded bitstream. The integrated transcoder transcodes the encoded bitstream by partially decoding the encoded bitstream based on a first transform associated with a first media data format. The decoding operations generate an intermediate data stream. The integrated transcoder then encodes the intermediate data stream using a second transform associated with a second media data format. The first and second transforms are not the same.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08447121&OS=08447121&RS=08447121
owner: Microsoft Corporation
number: 08447121
owner_city: Redmond
owner_country: US
publication_date: 20050914
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION","High-Speed Profile Transcoding","High-Quality Profile Transcoder","Requantization Error Compensation","MV Error Compensation","Chrominance Components"],"p":["Digital video content is typically generated to target a specific data format. A video data format generally conforms to a specific video coding standard or a proprietary coding algorithm, with a specific bit rate, spatial resolution, frame rate, etc. Such coding standards include MPEG-2 and WINDOWS Media Video (WMV). Most existing digital video contents are coded according to the MPEG-2 data format. WMV is widely accepted as a qualified codec in the streaming realm, being widely deployed throughout the Internet, adopted by the HD-DVD consortium, and currently being considered as a SMPTE standard. Different video coding standards provide varying compression capabilities and visual quality.","Transcoding refers to the general process of converting one compressed bitstream into another compressed one. To match a device's capabilities and distribution networks, it is often desirable to convert a bitstream in one coding format to another coding format such as from MPEG-2 to WMV, to H.264, or even to a scalable format. Transcoding may also be utilized to achieve some specific functionality such as VCR-like functionality, logo insertion, or enhanced error resilience capability of the bitstream for transmission over wireless channels.",{"@attributes":{"id":"p-0004","num":"0003"},"figref":["FIG. 1","FIG. 1"]},{"@attributes":{"id":"p-0005","num":"0004"},"figref":["FIG. 2","FIG. 1","FIG. 2","FIG. 1"]},"This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the detailed description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter.","In view of the above, efficient integrated digital video transcoding is described. In one aspect, an integrated transcoder receives an encoded bitstream. The integrated transcoder transcodes the encoded bitstream by partially decoding the encoded bitstream based on a first set of compression techniques associated with a first media data format. The decoding operations generate an intermediate data stream. The integrated transcoder then encodes the intermediate data stream using a second set of compression techniques associated with a second media data format. The first and second sets of compression techniques are not the same.","For purposes of discussion and illustration, color is used in the figures to present the following conventions. A blue solid arrow represents pixel domain signal with respect to real or residual picture data. A red solid arrow represents signal in the DCT domain. An orange dashed arrow represents motion information.","Overview","Systems and methods for efficient digital video transcoding are described below in reference to . These systems and methods utilize information in the input bitstream to allow an application to dynamically control error propagation, and thereby, selectively control speed and quality of video bitstream transcoding. This selective control allows an application to seamlessly scale from close-loop transcoding (high-speed transcoding profile) to open-loop (high-quality transcoding profile) transcoding schemes. In contrast to conventional transcoding architectures (e.g., the CPDT of  and the CDDT of ), the architectures for efficient digital video transcoding are integrated and that they combined different types of Discrete Cosine Transforms (DCTs) or DCT-like transforms into one transcoding module. The systems and methods for efficient video transcoding implement requantization with a fast lookup table, and provide fine drifting control mechanisms using a triple threshold algorithm.","In one implementation, where efficient digital video transcoding transcodes a bitstream data format (e.g., MPEG-2, etc.) to WMV, the high-quality profile transcoding operations support advanced coding features of WMV. In one implementation, high-speed profile transcoding operations implement arbitrary resolution two-stage downscaling (e.g., when transcoding from high definition (HD) to standard definition (SD)). In such two-stage downscaling operations, part of the downscaling ratio is efficiently achieved in the DCT domain, while downscaling ratio operations are implemented in the spatial domain at a substantially reduced resolution.","Exemplary Conceptual Basis",{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 3","FIG. 3","FIG. 3"],"b":"300"},{"@attributes":{"id":"p-0027","num":"0026"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["e","Error of frame (i + 1) to be encoded by encoding"]},{"entry":[{},"portion of the transcoder;"]},{"entry":["{circumflex over (B)}","Reconstructed frame i by MPEG-2 decoder at original"]},{"entry":[{},"resolution;"]},{"entry":["{tilde over (B)}","Reconstructed frame i by the encoder at original"]},{"entry":[{},"resolution;"]},{"entry":["{circumflex over (b)}","Reconstructed frame i by the MPEG-2 decoder at"]},{"entry":[{},"reduced resolution;"]},{"entry":["{tilde over (b)}","Reconstructed frame i by the encoder at reduced"]},{"entry":[{},"resolution;"]},{"entry":["{circumflex over (r)}","Reconstructed residues of frame (i + 1) by MPEG-2"]},{"entry":[{},"decoder;"]},{"entry":["{tilde over (r)}","Reconstructed residues of frame (i + 1) by the"]},{"entry":[{},"encoder"]},{"entry":["MC(B, mv)","Motion compensated prediction with reference"]},{"entry":[{},"picture B and motion vector mv by MPEG-2 decoder,"]},{"entry":[{},"on 16 \u00d7 16 block basis;"]},{"entry":["MC(B, mv)","Motion compensated prediction with reference"]},{"entry":[{},"picture B and motion vector mv by transcoder 308"]},{"entry":[{},"(encoder), either on 16 \u00d7 16 or 8 \u00d7 8 block basis;"]},{"entry":["MC\u2032(b, mv)","Motion compensated prediction with reduced"]},{"entry":[{},"resolution reference b and motion vector mv,"]},{"entry":[{},"using MPEG-2 filtering, on 8 \u00d7 8 or smaller block"]},{"entry":[{},"basis"]},{"entry":["MC\u2032(b, mv)","Motion compensated prediction with reduced"]},{"entry":[{},"resolution reference B and motion vector mv,"]},{"entry":[{},"using transcoder 308 filtering, on 8 \u00d7 8 or smaller"]},{"entry":[{},"block basis;"]},{"entry":["MV","Motion vector in the original frame resolution"]},{"entry":["mv","Motion vector in the reduced frame resolution"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"For purposes of description and exemplary illustration, system  is described with respect to transcoding from MPEG-2 to WMV with bit rate reduction, spatial resolution reduction, and their combination. Many existing digital video contents are coded according to the MPEG-2 data format. WMV is widely accepted as a qualified codec in the streaming realm, being widely deployed throughout the Internet, adopted by the HD-DVD Consortium, and currently being considered as a SMPTE standard.","MPEG-2 and WMV provide varying compression and visual quality capabilities. For example, the compression techniques respectively used by MPEG-2 and WMV are very different. For instance, the motion vector (MV) precision and motion compensation (MC) filtering techniques are different. In MPEG-2 motion precision is only up to half-pixel accuracy and the interpolation method is bilinear filtering. In contrast, in WMV, the motion precision can go up to quarter-pixel accuracy, and two interpolation methods namely bilinear filtering and bicubic filtering are supported. Moreover, there is a rounding control parameter involved in the filtering process. Use of WMV may result in up to a 50% reduction in video bit rate with negligible visual quality loss, as compared to an MPEG-2 bit rate.","In another example, transforms used by MPEG-2 and WMV are different. For instance, MPEG-2 uses standard DCT\/IDCT and the transform size is fixed to 8\u00d78. In contrast, WMV uses integer transforms (VC1-T) where the elements of transform kernel matrix are all small integers. Additionally, transform size can be altered using WMV from blocks to blocks using either 8\u00d78, 8\u00d74, 4\u00d78 and 4\u00d74. MPEG-2 does not support frame level optimization. Whereas, WMV supports various frame level syntaxes for performance optimization. WMV supports many other advanced coding features such as intensity compensation, range reduction, and dynamic resolution change, etc.","In view of the above, to provide bit rate reduction without resolution change, the filtering process bridging the MPEG-2 decoder and the WMV encoder shown in  is an all-pass filter (i.e., not in effect). Therefore, the input to the encoder for frame (i+1) is expressed as:\n\n()\u2212()\u2003\u2003(1)\n","In this implementation, WMV coding efficiency of  gains result from finer motion precision. In WMV, quarter-pixel motion precision is allowed beside the common half-pixel precision as in MPEG-2. Moreover, WMV allows better but more complex interpolation known as bicubic interpolation for MC filtering. Bilinear interpolation is used for MPEG-2 in the MC module (MC) for half-pixel MC. The bilinear interpolation method similar to that used in WMV with the exception that the MPEG-2 bilinear interpolation does not have rounding control. To achieve high speed, half-pixel motion accuracy can be implemented in the encoder portion. One reason for this is the lack of the absolute original frame (i.e., bitstream input data (BS_IN) is already compressed). Thus, in this example, it is difficult to obtain a more accurate yet meaningful motion vector. On the other hand, the motion information obtained from MPEG-2 decoder (i.e. MV=MV) can be reused directly. Since there is no resolution change, there is no MV precision loss with this assumption. If the encoder is further restricted to use bilinear interpolation and force the rounding control parameter to be always off, then under the reasonable assumption that motion compensation is a linear operation and ignoring the rounding error (i.e., MC=MC), Equation 1 is simplified as follows:\n\n()\u2003\u2003(2)\n\nAccording to Equation 2, the reference CPDT transcoder in  can be simplified. Such a simplified architecture is described below in reference to . Prior to describing the simplified architecture, an exemplary system for efficient digital video transcoding is first described.\n\nAn Exemplary System\n","Although not required, efficient digital video transcoding is described in the general context of computer-program instructions being executed by a computing device such as a personal computer. Program modules generally include routines, programs, objects, components, data structures, etc., that perform particular tasks or implement particular abstract data types. While the systems and methods are described in the foregoing context, acts and operations described hereinafter may also be implemented in hardware.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 4","b":["400","400","400","400","400","400"]},"In this implementation, system  includes a general-purpose computing device . Computing device  represents any type of computing device such as a personal computer, a laptop, a server, handheld or mobile computing device, etc. Computing device  includes program modules  and program data  to transcode an encoded bitstream in a first data format (e.g. MPEG-2) to a bitstream encoded into a different data formats (e.g., WMV). Program modules  include, for example, efficient digital video transcoding module  (\u201ctranscoding module \u201d) and other program modules . Transcoding module  transcodes encoded media  (e.g., MPEG-2 media) into transcoded media  (e.g., WMV media). Other program modules  include, for example, an operating system and an application utilizing the video bitstream transcoding capabilities of transcoding module , etc. In one implementation, the application is part of the operating system. In one implementation, transcoding module  exposes its transcoding capabilities to the application via an Application Programming Interface (API) .",{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIG. 5","FIG. 5","FIG. 4","FIG. 5","FIG. 4","FIG. 5","FIG. 3","FIG. 5"],"b":["408","500"]},"Please note that the WMV transform is different from the one used in MPEG-2. In MPEG-2, standard floating point DCT\/IDCT is used whereas the integer transform, whose energy packing property is akin to DCT, is adopted in WMV. As a result, the IDCT in the MPEG-2 decoder and the VC1-T in WMV encoder do not cancel out each other. The integer transform in WMV is different from the integer implementation of DCT\/IDCT. The integer transform in WMV is carefully designed with all the transform coefficients to be small integers. Conventional transcoders are not integrated to transcode a bitstream encoded with respect to a first transform to a second transform that is not the same as the first transform.","Equation 3 provides an exemplary transform matrix for 8\u00d78 VC1-T.",{"@attributes":{"id":"p-0039","num":"0038"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":"T","mn":"8"},"mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"12"},{"mn":"12"},{"mn":"12"},{"mn":"12"},{"mn":"12"},{"mn":"12"},{"mn":"12"},{"mn":"12"}]},{"mtd":[{"mn":"16"},{"mn":"15"},{"mn":"9"},{"mn":"4"},{"mrow":{"mo":"-","mn":"4"}},{"mrow":{"mo":"-","mn":"9"}},{"mrow":{"mo":"-","mn":"15"}},{"mrow":{"mo":"-","mn":"16"}}]},{"mtd":[{"mn":"16"},{"mn":"6"},{"mrow":{"mo":"-","mn":"6"}},{"mrow":{"mo":"-","mn":"16"}},{"mrow":{"mo":"-","mn":"16"}},{"mrow":{"mo":"-","mn":"6"}},{"mn":"6"},{"mn":"16"}]},{"mtd":[{"mn":"15"},{"mrow":{"mo":"-","mn":"4"}},{"mrow":{"mo":"-","mn":"16"}},{"mrow":{"mo":"-","mn":"9"}},{"mn":"9"},{"mn":"16"},{"mn":"4"},{"mrow":{"mo":"-","mn":"15"}}]},{"mtd":[{"mn":"12"},{"mrow":{"mo":"-","mn":"12"}},{"mrow":{"mo":"-","mn":"12"}},{"mn":"12"},{"mn":"12"},{"mrow":{"mo":"-","mn":"12"}},{"mrow":{"mo":"-","mn":"12"}},{"mn":"12"}]},{"mtd":[{"mn":"9"},{"mrow":{"mo":"-","mn":"12"}},{"mn":"4"},{"mn":"15"},{"mrow":{"mo":"-","mn":"15"}},{"mrow":{"mo":"-","mn":"4"}},{"mn":"16"},{"mrow":{"mo":"-","mn":"9"}}]},{"mtd":[{"mn":"6"},{"mrow":{"mo":"-","mn":"16"}},{"mn":"16"},{"mrow":{"mo":"-","mn":"6"}},{"mrow":{"mo":"-","mn":"6"}},{"mn":"16"},{"mrow":{"mo":"-","mn":"16"}},{"mn":"6"}]},{"mtd":[{"mn":"4"},{"mrow":{"mo":"-","mn":"9"}},{"mn":"15"},{"mrow":{"mo":"-","mn":"16"}},{"mn":"16"},{"mrow":{"mo":"-","mn":"15"}},{"mn":"9"},{"mrow":{"mo":"-","mn":"4"}}]}]}}}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}}},"Equation 3 in combination with equations 4 and 5, which are described below, indicate how two different transforms are implemented into a scaling component of transcoding module  (). In one implementation, the accuracy of VC1-T is 16-bit accuracy, which is very suitable for MMX implementation. As a result, the codec complexity can be significantly reduced.",{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 6","FIG. 6","FIG. 4","FIG. 6","FIG. 5","FIG. 6"],"b":["408","600","500"],"sub":["8 ","8\u2032BC","8 ","8","8","88 ","88 ","88","8","8"],"br":[{},{},{},{},{},{}],"in-line-formulae":[{},{},{},{},{},{}],"i":["N","=c","\u00b7c"]},"c=[8\/288 8\/289 8\/292 8\/298 8\/288 8\/289 8\/292 8\/298];","{circumflex over (B)} is directly computed from B, using the following formula:\n\n()\u2003\u2003(4)\n","To verify that TC\u2032 and CT\u2032 are very close to diagonal matrices, if we apply the approximation, then Equation 4 becomes an element-wise scaling of matrix B. That is,\n\n{circumflex over (B)}=BoS\u2003\u2003(5)\n\nwhere\n\n=diag(\u2032)\u00b7diag(\u2032)\n","Equation 5 shows that the VC1-T in WMV encoder and the IDCT in MPEG-2 decoder can be merged. Consequently, the architecture in  can be further simplified to the one shown in . Detailed comparison reveals that the two DCT\/IDCT modules are replaced by two VC1-T and inverse VC1-T modules. In one implementation, a simple scaling module is also added. Two switches are embedded along with and an activity mask in this architecture. These embedded components, as described below, are used for dynamic control of the complexity of transcoding coating operations of transcoder  (). At this point, these components are connected. The 16-bit arithmetic property of the WMV transform lends itself to parallel processing for PC and DSP. In view of this, computation complexities are significantly reduced. Moreover, since all the elements of the scaling matrix, S, are substantially close in proximity with respect to one another, this computation, and one implementation, is replaced by a scalar multiplication.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIGS. 5 and 6","FIG. 1","FIGS. 5 and 6","FIGS. 5 and 6","FIG. 6"]},"More particularly, conventional cascaded transcoder architectures (e.g., the architectures of ) lack complexity flexibility. With respect to computation savings, the most that such conventional architecture can achieve is through MV reuse and mode mapping. On the other hand, accumulated residue error compensation architectures, for example, the architecture of  (and the architectures of , as described below) have built-in scalability in terms of complexity. TABLE 2 shows exemplary meanings of switches in .",{"@attributes":{"id":"p-0047","num":"0046"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Exemplary Switches for Dynamic Control"},{"entry":"of Transcoding Speed and Quality"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"S","Block","Error accumulation switch"]},{"entry":[{},{},"level",{}]},{"entry":[{},"S","Block","Error update switch"]},{"entry":[{},{},"level",{}]},{"entry":[{},"S","Block","Early skip block decision switch"]},{"entry":[{},{},"level"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}]}}},"After transcoding module  of  has implemented drift-free simplification, an application can dynamically trade-off between the complexity and the quality to accelerate transcoding speed. In this implementation, quality can be traded for speed, and vice versa. In other words, some drifting error may be allowed in the further simplified transcoder. With this strategy, the drifting error introduced in the faster method is limited and fully controllable. Based on this consideration, three switches (SS, and S) are provided in the architectures of , , and . The switches are used only to the residue-error compensation based architectures. The switches selectively skip some time-consuming operations to reduce complexity substantially, while introducing only a small amount of error. The meanings of various switches are summarized in TABLE 2. Computational decisions associated with these switches are efficiently obtained according to criteria described below with respect to each switch.","Switch Scontrols when requantization error of a block should be accumulated into the residue-error buffer. As compared to a standard reconstruction selector, the role of switch Sis improved by adopting a fast lookup table based requantization process and by providing a finer drifting control mechanism via a triple-threshold algorithm. As a result, all observations made with respect to switch Sare considered. For example, in one implementation, the DCT domain energy difference may be utilized as the indicator.","Switch Scontrols when the most time-consuming module, MC of the accumulated residue error. In one implementation, switch Sis on. A binary activity mask is created for the reference frame. Each element of the activity mask corresponds to the activeness of an 8\u00d78 block, as determined by",{"@attributes":{"id":"p-0051","num":"0050"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"Activity","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["Block","i"]}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mn":"1","mo":","}},{"mrow":{"mrow":{"mi":"Energy","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["block","i"]}}},"mo":">","mi":"Th"}}]},{"mtd":[{"mrow":{"mn":"0","mo":","}},{"mrow":{"mrow":{"mi":"Energy","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["block","i"]}}},"mo":"\u2264","mi":"Th"}}]}]}}],"mo":"="}}},"br":{},"sub":["i","i","i"]},"Switch Sperforms early detection to determine whether block error should be encoded. This is especially useful in transrating applications where the encoder applies a coarser quantization step size. In this implementation, if the input signal (the sum of the MC of accumulated residue error and the reconstructed residue from MPEG-2 decoder) is weaker than a threshold, then switch Sis turned off so that no error will be encoded.","In one implementation, thresholds for the switches S, S, and Sare adjusted such that earlier reference frames are processed with higher quality and at slower speed. This is because the purpose of the switches is to achieve a better trade-off between quality and speed, and because of the predictive coding nature.","If bit rate change is not significant or the input source quality is not very high, the architecture of  substantially optimizes bit rate reduction when converting MPEG-2 bitstreams to WMV bitstreams. On the other hand, input source may be of high quality and high quality output may be desired, also speed of transcoding may be a moderate requirement (e.g., real-time). A high-quality profile transcoder, such as the cascaded pixel-domain transcoder (CDPT) of  with MV refinement, meets these criteria. With this architecture, we can turn on all the advanced coding features of the WMV encoder to ensure highest coding efficiency can be achieved.","Resolution Change","In conventional media transcoding systems there are generally three sources of errors for transcoding with spatial resolution downscaling. These errors are as follows:\n\n","Let D denote the down-sampling filtering. Referring to the architecture of , input to the VC-1 encoder for frame (i+1) is derived as follows:\n\n()+(())\u2212()\u2003\u2003(6)\n\nAssume that MC=MC, mv=mv=MV\/2. With the approximation that\n\n(())=((), ())=()\u2003\u2003(7),\n\nEquation 6 is simplified to the following:\n\n()+()\u2003\u2003(8)\n","The first term in Equation 8, D({circumflex over (r)}), refers to the downscaling process of the decoded MPEG-2 residue signal. This first term can be determined using spatial domain low-pass filtering and decimation. However, use of DCT-domain downscaling to obtain this term results in a reduction of complexity and better PSNR and visual quality. DCT-domain downscaling results are substantially better than results obtained through spatial domain bi-linear filtering or spatial domain 7-tap filtering with coefficients (\u22121, 0, 9, 16, 9, 0, \u22121)\/32. In this implementation, DCT-domain downscaling retains only the top-left 4\u00d74 low-frequency DCT coefficients. That is, applying a standard 4\u00d74 IDCT on the DCT coefficients retained will result in a spatially 2:1 downscaled image (i.e., transcoded media  of ).","The second term in Equation 8, MC\u2032({circumflex over (b)}\u2212{tilde over (b)}, mv), implies requantization error compensation on a downscaled resolution. In this implementation, the MC in MPEG-2 decoder and the MC in WMV encoder are merged to a single MC process that operates on accumulated requantization errors at the reduced resolution.",{"@attributes":{"id":"p-0059","num":"0061"},"figref":["FIG. 7","FIG. 7","FIG. 4"],"sub":["1 ","4 "],"b":"408"},"For example, let {circumflex over (B)}, {circumflex over (B)}, {circumflex over (B)}, and {circumflex over (B)}represent the four 4\u00d74 low-frequency sub-blocks of B, B, B, and B, respectively; Cbe the 4\u00d74 standard IDCT transform matrix; Tbe the integer WMV transform matrix; and further let T=[T, T] where Tand Tare 8\u00d74 matrices. In this scenario, {circumflex over (B)} is directly calculated from {circumflex over (B)}, {circumflex over (B)}, {circumflex over (B)}, and {circumflex over (B)}using the following equation:\n\n=(\u2032)(\u2032)\u2032+(\u2032)(\u2032)\u2032+(\u2032){circumflex over (B)}(\u2032)\u2032+(\u2032)(\u2032)\u2032\n\nAfter some manipulation, {circumflex over (B)} is more efficiently calculated as follows:\n\n=()\u2032+()\n\nwherein\n\n=(\u2032)\/2\n\n=(\u2032)\/2\n\n()+()\n\n()+()\n\nIn one implementation, both C and D of the above equation are pre-computed. The final results are normalized with N.\n",{"@attributes":{"id":"p-0061","num":"0063"},"figref":["FIG. 8","FIG. 4","FIG. 6","FIG. 8","FIG. 6"],"b":["800","408","800","408"]},"Compared to a conventional drift-low transcoder with drifting error compensation in reduced resolution, the transcoders of  do not include a mixed block-processing module. This is because WMV supports Intra coding mode for 8\u00d78 blocks in an Inter coded macroblock. In other words, an Intra MB at the original resolution is mapped into an Intra 8\u00d78 block of an Inter MB at the reduced resolution. In view of this, the MB mode mapping rule becomes very simple, as shown immediately below:",{"@attributes":{"id":"p-0063","num":"0065"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"mode_new","mo":"=","mrow":{"mo":"{","mtable":{"mtr":[{"mtd":[{"mi":"INTRA"},{"mrow":{"mrow":{"mi":["if","all","mode_orig"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]},"mo":"=","mi":"INTRA"}}]},{"mtd":[{"mi":"SKIP"},{"mrow":{"mrow":{"mi":["if","all","mode_orig"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]},"mo":"=","mi":"SKIP"}}]},{"mtd":[{"mi":"INTER"},{"mi":"otherwise"}]}]}}}}},"br":{}},"Simplified DCT-domain 2:1 resolution downscaling transcoding architecture  is substantially drifting-free for P-frames. This is a result of the four-MV coding mode. The only cause of drifting error, as compared with a CPDT architecture with downscaling filtering, is the rounding of MVs from quarter resolution to half resolution (which ensures mv=mv) and the non-commutative property of MC and downscaling. Any such remaining errors are negligible due to the low-pass downscaling filtering (e.g., achieved in the DCT domain or in the pixel domain).",{"@attributes":{"id":"p-0065","num":"0067"},"figref":["FIG. 9","FIG. 4"],"b":"408"},"Although WMV supports four MV coding mode, it is typically only intended for coding P-frames. As a result, system  () implements the architecture of  when there are no B-frames in the input MPEG-2 stream or the B-frames are to be discarded during the transcoder towards a lower temporal resolution. One reason for this is that WMV allows only one MV per MB for B-frames. In such a scenario, transcoding module  () composes a new motion vector from the four MVs associated with the MBs at the original resolution. Each of the previously mentioned MV composition methods is compatible. In one implementation, transcoding module  implements median filtering. As described, incorrect MV will lead to wrong motion compensated prediction. To make matters worse, no matter how the requantization error is compensated, and no matter how high the bit rate goes, perfect results are difficult to obtain if not re-doing the motion compensation based on the new MVs. Therefore, we provide an architecture that allows such motion errors to be compensated.","Again, referring to the architecture of , input to the VC-1 encoder for frame (i+1), which is assumed to be a B-frame, is derived as follows:\n\n()+(())\u2212()\u2003\u2003(9);\n\nwith the approximation that\n\n(())=((), ())=())\u2003\u2003(10)\n","Equation 9 is simplified to\n\n()+()\u2212()\u2003\u2003(11)\n\nIn view of Equation 11, the following is obtained:\n\n()+()\u2212()=()+[()\u2212()]+()\u2212()=()+[()\u2212()]+()\u2003\u2003(12)\n","The two terms in the square brackets in Equation 12 compensate for the motion errors caused by inconsistent MVs (i.e., mvis different from mv) or caused by different MC filtering methods between MPEG-2 and WMV. The corresponding modules for this purpose are highlighted and grouped into a light-yellow block in .",{"@attributes":{"id":"p-0070","num":"0072"},"figref":["FIG. 10","FIG. 4","FIG. 10"],"b":"408","sub":["mp2","i","mp2","mp2","mp2","vc1","mp2","vc1 "],"i":"{circumflex over (b)}"},"As to the MC, Intra-to-Inter or Inter-to-Intra conversion can be applied. This is because the MPEG-2 decoder reconstructed the B-frame and the reference frames. In this implementation, this conversion is done in the mixed block-processing module in . Two mode composition methods are possible. And one implementation, the dominant mode is selected as the composed mode. For example, if the modes of the four MBs at the original resolution are two bi-directional prediction mode, one backward prediction mode and one forward prediction mode, then bi-directional prediction mode is selected as the mode for the MB at the reduced resolution. In another implementation, the mode that will lead to the largest error is selected. In view of this example, suppose using the backward mode will cause largest error. In this scenario, the backward mode is chosen such that the error can be compensated. Results show that the latter technique offers slightly better quality as compared to the former mode selection technique.","An exemplary architecture according to Equation 12 is shown in . There are four frame-level switches specifically for this architecture, as shown in TABLE 3.",{"@attributes":{"id":"p-0073","num":"0075"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 3"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Exemplary Frame-Level Switches"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["S","Frame","Switch to be closed for I- and P-frames only"]},{"entry":[{},"level",{}]},{"entry":["S","Frame","Switch to be closed for P-frames only"]},{"entry":[{},"level",{}]},{"entry":["S","Frame","Switch to be closed for B-frames only (=!S)"]},{"entry":[{},"level",{}]},{"entry":["S","Frame","Switch to be closed for I- and P-frames only if there"]},{"entry":[{},"level","are B-frames"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"The four frame-level switches ensure different coding paths for different frame types. Specifically, the architecture does not perform: residue-error accumulation for B-frames (S), does not perform MV error compensation for I- and P-frames (S), and does not reconstruct reference frames if there is no B-frames to be generated (S). Please note the frame-level switch Scan be turned into block-level switch since the MV error needs to be compensated only when the corresponding four original MVs are significantly inconsistent.","More particularly, switch Sis closed only for I-frames or P-frames, Switch Sis closed only for P-frames, and switch Sis closed only for B-frames. The resulting architecture is not as complex as the reference cascaded pixel-domain transcoder of . One reason for this is that the explicit pixel-domain downscaling process is avoided. Instead, pixel-domain downscaling is implicitly achieved in the DCT domain by simply discarding the high DCT coefficients. This architecture has excellent complexity scalability achieved by utilizing various switches, as described above with respect to TABLE 2.","For applications that demand ultra-fast transcoding speed, the architecture of  can be configured into an open-loop one by turn off all the switches. This open-loop architecture can be further optimized by merging the dequantization process of MPEG-2 and the requantization process of WMV. The inverse zig-zag scan module (inside VLD) of MPEG-2 can also be combined with the one in WMV encoder.","With respect to chrominance components in MPEG-2 and in WMV, the MV and the coding mode of chrominance components (UV) are derived from those of luminance component (Y). If all the four MBs at the original resolution that correspond to the MB at the reduced resolution have consistent coding mode (i.e., all Inter-coded or all Intra-coded), there is no problem. However, if it is not case, problems result due to different derivation rules of MPEG-2 and WMV. In MPEG-2, the UV blocks are Inter coded when the MB is coded with Inter mode. However, in WMV, the UV blocks are Inter coded only when the MB is coded with Inter mode and there are less than three Intra-coded 8\u00d78 Y blocks. This issue exists for both P-frames and B-frames. Transcoding module  of  addresses these problems as follows:\n\n","Using error concealment operations to handle mode conversion for chrominance component, error introduced into a current frame is negligible and can be ignored, although it may cause color drifting in subsequent frames. Drifting for the chrominance component is typically caused by incorrect motion. To address this and improve quality, in one implementation, transcoding module  uses reconstruction based compensation for the chrominance component (i.e., always applying the light-yellow module for the chrominance component).","Rate Control",{"@attributes":{"id":"p-0079","num":"0083"},"figref":["FIG. 11","FIG. 11"]},"For high bit rate, there is an approximate formula between coding bits (B) and quantization step (QP) which is also used in MPEG-2 TM-5 rate control method.",{"@attributes":{"id":"p-0081","num":"0085"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"B","mo":"=","mrow":{"mi":"S","mo":"\u00b7","mfrac":{"mi":["X","QP"]}}}},{"mrow":{"mo":["(",")"],"mn":"13"}}]}}}},"br":{}},{"@attributes":{"id":"p-0082","num":"0086"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"QP","mrow":{"mi":"vc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}},"mo":"=","mrow":{"mrow":[{"mrow":[{"mo":["(",")"],"mfrac":{"msub":[{"mi":"X","mrow":{"mi":"vc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}},{"mi":"X","mrow":{"mi":["m","p"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mn":"2"}}]}},{"mo":["(",")"],"mfrac":{"msub":[{"mi":"B","mrow":{"mi":"mp","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"}},{"mi":"B","mrow":{"mi":"vc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}]}}],"mo":["\u00b7","\u00b7"],"msub":{"mi":"QP","mrow":{"mi":["m","p"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mn":"2"}}},{"mi":"k","mo":["\u00b7","\u00b7"],"mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":"B","mrow":{"mi":["m","p"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mn":"2"}},{"mi":"B","mrow":{"mi":"vc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}]}},"msub":{"mi":"QP","mrow":{"mi":["m","p"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mn":"2"}}}],"mo":"="}}}},"br":[{},{},{}],"sub":["vc1 ","mp2 ","vc1","mp2","mp2","vc1"],"in-line-formulae":[{},{}],"i":["QP","\/QP","=k","B","\/B","t"]},{"@attributes":{"id":"p-0083","num":"0087"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"center"}},"thead":{"row":{"entry":"TABLE 4"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"EXEMPLARY PARAMETER VALUES FOR"},{"entry":"LINEAR REGRESSION METHODOLOGY"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"210pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Frame Type"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"I frame","P frame","B frame"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Parameters","k","t","k","t","k","t"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Low (<1 Mbps)","0.612861","\u22120.194954","0.016081","3.128561","0.076037","2.264825"]},{"entry":["Med (<3 Mbps)","0.314311","0.070494","0.041140","1.400647","0.207292","0.545977"]},{"entry":["High","0.682409","\u22120.248120","0.057869","1.115930","0.199024","0.441518"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}}]}}},"An exemplary detailed rate control algorithm based on Equation 14 is shown in TABLE 5, where the meanings of various symbols in the algorithm presented in TABLE 5 are defined in following TABLE 6.",{"@attributes":{"id":"p-0085","num":"0089"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 5"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"EXEMPLARY RATE CONTROL ALGORITHM"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"Initialize SumD = 0;"},{"entry":"While (MPEG-2 stream is not end)"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Step 1:\u2003Decode one MPEG2 frame and get Band QP;"]},{"entry":[{},{}]},{"entry":[{},{"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"Step","mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mn":"2","msub":{"mi":["B","pred_vcl"]}},{"msub":{"mi":"B","mrow":{"mi":"mp","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"}},"mo":"\u00b7","mfrac":{"msub":[{"mi":"R","mrow":{"mi":"vc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}},{"mi":"R","mrow":{"mi":"mp","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"}}]}}],"mo":"="}}}}]},{"entry":[{},{}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"B","mrow":{"mi":"vc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}},"mo":"=","mrow":{"msub":{"mi":["B","pred_vcl"]},"mo":"+","mi":"SumD"}}}}}]},{"entry":[{},"If (B< 0) then B= 1;"]},{"entry":[{},{}]},{"entry":[{},{"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":"QP","mrow":{"mi":"vc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}},"mo":"=","mrow":{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"k","mo":"\u00b7","mfrac":{"msub":[{"mi":"B","mrow":{"mi":"mp","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"}},{"mi":"B","mrow":{"mi":"vc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}]}},"mo":"+","mi":"t"}},"mo":"\u00b7","msub":{"mi":"QP","mrow":{"mi":"mp","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"}}}},"mo":";"}}}}]},{"entry":[{},{}]},{"entry":[{},"Round and Clip QPto [1, 31];"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Step3:\u2003Encode this frame into WMV frame using QP;"]},{"entry":[{},{"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":["Step","Obtain","the","actual","coded","WMV","frame","size"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mn":"4","msub":{"mi":"B","mrow":{"mi":"actual_vc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}},"mo":";"}}}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},{"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":["Update","SumD","SumD"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]},{"mi":"SumD","mo":["+","-"],"msub":[{"mi":["B","pred_vcl"]},{"mi":"B","mrow":{"mi":"actual_vc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}]}],"mo":"="},"mo":";"}}}}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0086","num":"0090"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 6"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"DEFINITIONS OF SYMBOLS USED"},{"entry":"IN THE ALGORITHM OF TABLE 5"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"B","MPEG-2 frame size;"]},{"entry":[{},"R","MPEG-2 stream bit rate;"]},{"entry":[{},"R","Target WMV stream bit rate;"]},{"entry":[{},"B","WMV frame size predicted by the ratio of bit rate;"]},{"entry":[{},"B","Expected WMV frame size to encode (new bit rate);"]},{"entry":[{},"B","Actual encoded WMV frame size;"]},{"entry":[{},"SumD","Accumulated differences between the predicted"]},{"entry":[{},{},"and actual WMV frame size from beginning."]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Conversion of contents from HD resolution to SD resolution, for example to support legacy SD receivers\/players, is useful. Typical resolutions of HD format are 1920\u00d71080i and 1280\u00d7720p while those for SD are 720\u00d7480i, 720\u00d7480p for NTSC. The horizontal and vertical downscaling ratios from 1920\u00d71080i to 720\u00d7480i are 8\/3 and 9\/4, respectively. To keep the aspect ratio, the final downscaling ratio is chosen to be 8\/3 and the resulting picture size is 720\u00d7404. Similarly, for 1280\u00d7720p to 720\u00d7480p, the downscaling ratio is chosen to be 16\/9 and the resulting picture size is 720\u00d7404. Black banners are inserted to make a full 720\u00d7480 picture by the decoder\/player (instead of being padded into the bitstream).","According to digital signal processing theory, a substantially optimal downscaling methodology for a downscaling ratio m\/n, would be to first up sample the signal by n-fold (i.e., insert n\u22121 zeros between every original samples), apply a low-pass filter (e.g., a sinc function with many taps), and then decimate the resulting signal by m-fold. Performing such operations, any spectrum aliasing introduced by the down-scaling would be maximally suppressed. However, this process would also be very computationally expensive, and difficult to implement with in real-time because the input signal is high definition. To reduce this computational complexity, a novel two-stage downscaling strategy is implemented.",{"@attributes":{"id":"p-0089","num":"0093"},"figref":["FIG. 12","FIG. 4","FIG. 12","FIG. 12","FIGS. 5"],"b":["408","12","6","8","10"]},"Referring to , system  implements two-stage downscaling operations to achieve any arbitrary downscaling target. Results of the first stage downscaling are embedded into the decoding loop. This reduces the complexity of the decoding operations. For example, to achieve an 8\/3 downscale ratio, downscaling operations are first implemented to downscale by 2\/1. The results of this first stage downscaling are input into the decoding loop, wherein second stage downscaling is performed in the spatial domain. In this example, second stage downscaling operations downscale by 4\/3 to achieve an 8\/3 downscale ratio. In another example, a downscale ratio of 16\/9 is achieved by system  by applying 4\/3 downscaling twice (in two stages). This two-stage downscaling methodology utilizes the previously discussed DCT-domain downscaling strategy, and then fully embeds the first stage downscaling results into the decoding loop. Since resolution is significantly reduced after the first stage downscaling, we can continue to apply the optimal downscaling method on the pixel-domain.","Referring to , please note that multiple MVs",{"@attributes":{"id":"p-0092","num":"0096"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":["(",")"],"mrow":{"mi":["between","and"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":[{"mrow":[{"mo":["\u230a","\u230b"],"mfrac":{"mi":["m","n"]}},{"mo":["\u230a","\u230b"],"mfrac":{"mi":["m","n"]}}],"mo":"\u2a2f"},{"mrow":[{"mo":["\u2308","\u2309"],"mfrac":{"mi":["m","n"]}},{"mo":["\u2308","\u2309"],"mfrac":{"mi":["m","n"]}}],"mo":"\u2a2f"}]}}}},"br":[{},{}]},{"@attributes":{"id":"p-0093","num":"0097"},"figref":["FIG. 13","FIG. 4","FIG. 13","FIG. 4"],"b":["1300","408","1300","1302","412","1304","1306","1308","1306"]},"At block , the data decoded according to the first set of compression techniques is encoded with a second set of compression techniques. In one implementation, procedure  is implemented within a non-integrated transcoding architecture, such as that shown and described with respect to . In this implementation, the second set of compression techniques is the same as the first set of compression techniques. In another implementation, procedure  is implemented within an integrated transcoding architecture, such as that shown and described with respect to , and . In this other implementation, the second set of compression techniques is not the same as the first set of compression techniques. For example, in one implementation, the first set of compression techniques is associated with MPEG-2, and the second set of compression techniques is associated with WMV.","An Exemplary Operating Environment",{"@attributes":{"id":"p-0095","num":"0099"},"figref":["FIG. 14","FIG. 4"],"b":["1400","400","1400","1400"]},"The methods and systems described herein are operational with numerous other general purpose or special purpose computing system, environments or configurations. Examples of well-known computing systems, environments, and\/or configurations that may be suitable for use include, but are not limited to personal computers, server computers, multiprocessor systems, microprocessor-based systems, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and so on. Compact or subset versions of the framework may also be implemented in clients of limited resources, such as handheld computers, or other computing devices. The invention is practiced in a networked computing environment where tasks are performed by remote processing devices that are linked through a communications network.","With reference to , an exemplary system providing efficient digital video transcoding architecture includes a general-purpose computing device in the form of a computer  implementing, for example, initiator operations associated with computing device  of . Components of computer  may include, but are not limited to, processing unit(s) , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example and not limitation, such architectures may include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.","A computer  typically includes a variety of computer-readable media. Computer-readable media can be any available media that can be accessed by computer , including both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer .","Communication media typically embodies computer-readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism, and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation, communication media includes wired media such as a wired network or a direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer-readable media.","System memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example and not limitation,  illustrates operating system , application programs , other program modules , and program data .","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media discussed above and illustrated in , provide storage of computer-readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that they are at least different copies.","A user may enter commands and information into the computer  through input devices such as a keyboard  and pointing device , commonly referred to as a mouse, trackball or touch pad. Other input devices (not shown) may include a microphone, joystick, graphics pen and pad, satellite dish, scanner, etc. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus , but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). In this implementation, a monitor  or other type of user interface device is also connected to the system bus  via an interface, for example, such as a video interface .","The computer  operates in a networked environment using logical connections to one or more remote computers, such as a remote computer . In one implementation, remote computer  represents computing device  of a responder, as shown in . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and as a function of its particular implementation, may include many or all of the elements described above relative to the computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example and not limitation,  illustrates remote application programs  as residing on memory device . The network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Conclusion","Although the above sections describe efficient digital video transcoding architectures in language specific to structural features and\/or methodological operations or actions, the implementations defined in the appended claims are not necessarily limited to the specific features or actions described. Rather, the specific features and operations of the described efficient integrated digital video transcoding architecture are disclosed as exemplary forms of implementing the claimed subject matter.","For example, in one implementation, the described fast and high quality transcoding systems and methodologies, including transcoding, arbitrary sized downscaling, and rate reduction are used for MPEG-2 to MPEG-4 transcoding and MPEG-4 to WMV transcoding. For instance, the simplified closed-loop DCT-domain transcoder in  can be used to transcode MPEG-4 to WMV. One difference between MPEG-2 (IS-13818 Part. 2) is that MPEG-2 only utilizes half pixel element (pel) MV precison and bilinear interpolation in MC; there is such a same mode (half pel bilinear) in WMV. However, MPEG-4 supports both half pel and quarter pel MV precision, as well as interpolation for quarter pel positions (different from that in WMV). To address this difference, when \u00bd pel MV is used by MPEG-4 video, then the transcoding process is the same as MPEG-2 to WMV transcoding, as described above. Additionally, when \u00bc pel MV is contained in MPEG-4 video, then error is introduced due to different interpolation methods in MC as described above with respect to . Additionally, the simplified 2:1 downscaling transcoder with full drift compensation described above with respect to  is applicable to MPEG-4 to WMV 2:1 downsized transcoding independent of change. Moreover, high quality transcoding, including the above described rate reduction and arbitrarily downscaling transcoding operations of  are effective for MPEG-4 to WMV transcoding."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["In the Figures, the left-most digit of a component reference number identifies the particular Figure in which the component first appears.",{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 14"}]},"DETDESC":[{},{}]}
