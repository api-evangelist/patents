---
title: Dynamically balancing memory resources between host and guest system based on relative amount of freeable memory and amount of memory allocated to hidden applications
abstract: A computing device employs a cooperative memory management technique to dynamically balance memory resources between host and guest systems running therein. According to this cooperative memory management technique, memory that is allocated to the guest system is dynamically adjusted up and down according to a fairness policy that takes into account various factors including the relative amount of readily freeable memory resources in the host and guest systems and the relative amount of memory allocated to hidden applications in the host and guest systems.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09176780&OS=09176780&RS=09176780
owner: VMware, Inc.
number: 09176780
owner_city: Palo Alto
owner_country: US
publication_date: 20110823
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Over the past decade, enterprises have experienced a substantial increase in the productivity of its workforce when providing them with business mobile devices. In the past, given their high cost, business mobile devices were mainly allocated to management and focused on providing employees with email access and cellular phone capabilities. However, recent improvements in the computing power, mobile display technologies and connection speeds of mobile devices, combined with the continued decreases in hardware costs, have made powerful mobile devices available even to the general public for personal use. More and more individuals personally own powerful mobile devices, such as smartphones, that, in addition to serving as a cellular phone, can be used in many of the same ways as a desktop or a laptop, such as accessing emails, browsing documents or the internet, game playing, listening to audio or viewing a video, and personal information management (PIM).","Due to the above trends in mobile devices, enterprises are currently experiencing an \u201cinvasion\u201d of personal devices into the workplace. Given the sophisticated capabilities of their personal mobile devices, employees no longer desire possessing a separate personal and business mobile device and continually pressure information technology (IT) departments to support personal devices brought into the workplace. As such, IT departments struggle to maintain a proper balance between enabling a certain level of access to enterprise data (e.g., such as access to email, contacts, documents, and the like) on personal devices and ensuring adequate security measures to protect corporate intellectual property in such enterprise data. This phenomenon has led enterprises to investigate the viability of a \u201cBring Your Own Device\u201d (BYOD) strategy to IT, where a personal mobile device is provisioned by IT departments with the capability of operating as a complete business mobile device in a secure fashion.","Virtualization has been proposed as a solution for consolidating personal and business uses in a single mobile device. With virtualization, personal and work environments remain isolated. As a result, the user need not provide enterprise IT departments any control of the user's personal environment and the enterprise IT departments can retain strict control of the user's work environment. Another important feature of virtualization is that the user's work environment will be platform independent. Regardless of the type of personal mobile device the user chooses, the resulting work mobile device through virtualization will be identical. Therefore, enterprise IT departments need to support only one type of work mobile device.","When a mobile device is provisioned in the manner described above for both personal and work uses, it is not uncommon for the mobile device to encounter memory shortages. For example, the mobile device may have 400 MB of memory and the browser (which may be run in the personal environment on top of an operating system that is consuming about 25 MB of memory or the work environment on top of an operating system that is consuming about 25 MB of memory) may require around 250 MB of memory. Therefore, it would not be possible to partition memory statically to support the browser in both environments. Instead, memory resources will have to be dynamically assigned between the two environments. In addition, mobile device operating systems such as Android\u00ae, which support multitasking of applications, divide up memory resources between applications, prioritizing based on user visibility and recency of use. This adds a layer of complexity to any memory management schemes and makes it challenging to ensure that memory resources are divided fairly between the personal and work environments. It should further be noted that memory models of certain operating systems, such as Android\u00ae, does not rely entirely on swap but also employs asynchronous process termination. As a result, memory management schemes designed for such operating systems will have to ensure that the important processes are not being terminated prematurely in one environment because of memory pressure in the other environment.","One or more embodiments of the invention provide a cooperative memory management technique for a computing device having host and guest systems that share memory resources. In this cooperative memory management technique, memory that is allocated to the guest system is dynamically adjusted up and down according to a fairness policy that takes into account various factors including the relative amount of readily freeable memory resources in the host and guest systems and the relative amount of memory allocated to hidden applications in the host and guest systems.","A method of managing memory in a computing device having host and guest systems, according to an embodiment of the invention, includes detecting a memory pressure condition by the guest system, issuing in response to such detection a request from the guest system to the host system for the host system to generate a target value for allocating memory, and allocating memory to a process running in the guest system in accordance with the target value. The process running in the guest system, in one embodiment, is a kernel driver. Memory that is allocated to this kernel driver according to the target value is pinned and relinquished to the host system for reallocation.","A method of managing memory in a computing device having host and guest systems, according to another embodiment of the invention, includes: when the guest system is in an active state, issuing a request from the guest system to the host system at periodic intervals for the host system to generate a target value for allocating memory; and allocating memory to a process running in the guest system in accordance with the target value. The request may also be issued when a memory pressure event is detected in either the host system or the guest system. When the guest system is in a sleep state, the guest system waits for an interrupt that indicates a memory pressure event occurring in the host system, and responsive to this interrupt, the guest system wakes up and issues a request to the host system to generate the target value for allocating memory.","Further embodiments of the present invention include a non-transitory computer-readable storage medium storing instructions that when executed by a computer system cause the computer system to perform one or more the methods set forth above, and a computer system programmed to carry out one or more the methods set forth above.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 1","FIG. 1","FIG. 1"],"b":["1","30","30","10","10","11","12","13","14"],"sub":["1","n"]},"As further shown in , VM includes virtual system hardware  which includes one or more virtual central processing units (VCPU(s)) , virtual system memory , virtual disk , and various virtual devices . VM also includes guest operating system (OS)  running on virtual system hardware , along with a set of drivers  for accessing virtual devices . One or more software applications (apps)  may execute in VM on guest OS  and virtual system hardware . All of the components of VM may be implemented in software using known techniques to emulate the corresponding components of an actual computer.","As further shown in , VMs -are supported by virtualization software  comprising kernel  and a set of virtual machine monitors (VMMs), including VMM -VMM . In this implementation, each VMM supports one VM. Thus, VMM supports VM , and VMM supports VM . As further shown in , VMM includes, among other components, device emulators , which may constitute virtual devices  accessed by VM . VMM also includes memory manager , the general operation of which is described below. VMM also usually tracks, and either forwards (to some form of system software) or itself schedules and handles, all requests by VM for machine resources, as well as various faults and interrupts. A mechanism known in the art as an exception or interrupt handler  may therefore be included in VMM . VMM will handle some interrupts and exceptions completely on its own. For other interrupts\/exceptions, it may be either necessary or at least more efficient for VMM to call kernel  to have kernel  handle the interrupts\/exceptions itself. VMM may forward still other interrupts to VM .","Kernel  handles the various VMM\/VMs and includes interrupt\/exception handler  that is able to intercept and handle interrupts and exceptions for all devices on the machine. Kernel  also includes memory manager  that manages all machine memory. When kernel  is loaded, information about the maximum amount of memory available on the machine is available to kernel ; part of machine memory  is used for kernel  itself, some are used to store code, data, stacks and so forth, and some are used for guest memory of virtual machines. In addition, memory manager  may include algorithms for dynamically allocating memory among the different VMs.","In some embodiments, kernel  is responsible for providing access to all devices on the physical machine, and kernel  will typically load conventional drivers as needed to control access to devices. Accordingly,  shows loadable modules and drivers  containing loadable kernel modules and drivers. Kernel  may interface with loadable modules and drivers  using an API or similar interface.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 2A","FIG. 2A","FIG. 2B"],"b":["100","101","100","100","105","100","105","100","105","100","100","110","120","135","120"]},"As depicted in , work mobile device  operates as a virtual machine running on hypervisor  and, conceptually, includes a virtual machine monitor (VMM)  and accesses a \u201cvirtual disk,\u201d which is shown as work device image . VMM  may be considered a component of hypervisor  (which itself runs as a high priority user-level application on host OS ) that emulates hardware resources for work mobile device . Work device image  includes a guest OS , which may be any commodity operating system such as the Android\u00ae operating system and applications  running on top of guest OS . In the embodiment of , applications  includes a backdoor service application  that establishes a direct communication channel to hypervisor  (which itself runs on top of host OS ). Backdoor service application  is a \u201cbackdoor\u201d application because typical applications running on top of guest OS  are not aware that they are running in a virtual machine. However, backdoor service application  is aware that it is running in a virtual machine on top of hypervisor  and can therefore request or provide special data and services to and from hypervisor , for example, when certain user interface enhancement as further described below between personal mobile device  and work mobile device  are desirable. In one embodiment, backdoor service  establishes the direct communication channel with hypervisor  by connecting to a unique network port that hypervisor  has opened and is listening on, although it should be recognized that alternative embodiment can establish such a communication channel utilizing different techniques. As will be further discussed, the direct communication channel between backdoor service  and hypervisor  facilitates remote procedure calls (RPC) between components existing in personal mobile device  and work mobile device .",{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 3","FIG. 2A"],"b":["121","120","145","111","112","105","171","170","172","171","162","161","161","135","145","120","120","170"]},"Kernel  manages memory , also referred to herein as machine memory, allocating free memory on demand for use in its caches (e.g., page cache, slabs) and for applications and kernel modules (e.g., drivers). When available free memory is low, e.g., less than a certain threshold, an event known as a slab shrink event occurs. In response to the slab shrink event and other low memory signalling mechanisms, kernel  frees up memory from its caches. If there is insufficient memory in the kernel caches, one or more \u201chidden\u201d applications, which are user-level applications that are no longer visible to the user, may be terminated by a kernel module, known as low memory killer . The termination of the hidden applications is carried out in the order of their priority values (low priority ones being terminated prior to the high priority ones), as assigned by kernel .","Guest OS  supports user-level applications that are executed in the work mobile device  and has a kernel  that manages guest physical memory (e.g., memory  as emulated by VMM ) in the same manner kernel  manages machine memory. Thus, in response to slab shrink events occurring inside the guest, kernel  frees up memory from its caches. If there is insufficient memory in the kernel caches, one or more hidden applications running in the work mobile device  may be terminated by low memory killer  of kernel  in the order of their priority values (low priority ones being terminated prior to the high priority ones), as assigned by kernel .","In the memory management techniques described above, each of kernels, kernel  and kernel , allocate and deallocate memory without knowledge of what the other kernel is doing. For cooperative memory management between the two, a memory management technique known as memory ballooning is employed. According to this technique, kernel  implements memory ballooning by allocating guest physical memory pages to balloon kernel module  and pinning the allocated memory pages so that the machine pages corresponding to the pinned guest physical memory pages can be reallocated by the host. When memory ballooning is operated in reverse, the pinned guest physical memory pages are unpinned so that they become available to be allocated to guest applications and to other modules of kernel .","Memory ballooning is initiated when kernel  polls a controlling thread, shown in  as balloon controller thread , for a balloon adjustment value. In one embodiment, the polling is done using RPC, and includes information on the memory state of the guest, such as the number of memory pages in the guest's free memory pool and the guest's page cache, and the number of memory pages allocated to background processes running in the guest. In response, balloon controller thread  calculates the balloon adjustment value in compliance with a fairness policy which will be described in detail below and returns the balloon adjustment value to kernel . Based on this balloon adjustment value, kernel  determines whether memory ballooning should be implemented in the forward direction (also known as \u201cinflating\u201d the balloon) or in the reverse direction (also known as \u201cdeflating\u201d the balloon). When the balloon adjustment value is greater than zero, kernel  inflates the balloon by allocating additional guest physical memory pages to balloon kernel module  and pinning them. On the other hand, when the balloon adjustment value is less than zero, kernel  deflates the balloon by unpinning some of the guest physical memory pages allocated to balloon kernel module  that were previously pinned.","According to one or more embodiments of the present invention, kernel  may poll balloon controller thread  for a balloon adjustment value to initiate memory ballooning in response to a slab shrink event occurring in the host, which is communicated to kernel  through VMM , or a slab shrink event occurring in the guest. Kernel  may also poll balloon controller thread  for the balloon adjustment value on a periodic basis when slab shrink events are not occurring either in the guest or the host so that memory allocation between the host and the guest can be kept balanced in compliance with the fairness policy. However, the periodic polling is carried out when the guest is awake and not when the guest is asleep so as to conserve battery power.","When the balloon adjustment value is greater than zero, a process in kernel  first attempts to allocate guest memory pages without sleeping (e.g., by using the function GFP_ALLOC_NO_SLEEP). This can be done by allocating guest memory pages from its free memory pool. If the amount of memory pages in the free memory pool is not sufficient, however, the process is permitted to sleep (e.g., by using the function GFP_ALLOC_CANSLEEP) to give kernel  some time to free up guest memory pages, e.g., by writing out dirty pages in its page cache to disk or by allowing its low memory killer to terminate one or more processes. If the amount of memory pages that can be allocated is still not sufficient, kernel  schedules a deferred poll with a set time, e.g., 1 second. If the balloon inflation is successful, the periodic polling described above is scheduled with a variable delay. The purpose of the periodic polling is to determine whether or not further balloon adjustment is required. The delay is calculated such that it is inversely proportional to the rate of change of the balloon adjustment value. If the balloon adjustment value is rapidly increasing or decreasing, the delay is set to a small value, e.g., 200 msec. On the other hand, if only a small net change in the balloon adjustment value has taken place recently, the delay is set to a large value, e.g., 1 second.","When the balloon adjustment value is less than zero, kernel  responds by unpinning some of the guest physical memory pages allocated to balloon kernel module  that were previously pinned. When the balloon adjustment value is equal to zero, kernel  does nothing.","One goal of the fairness policy is to avoid having the low memory killers in the host and the guest from terminating any services and applications currently visible to the user, while there remains freeable memory or hidden applications globally. This goal is achieved by setting the balloon adjustment value to ensure that freeable memory is moved between the host and the guest, taking memory from the side that is rich in freeable memory and giving it to the other side. The fairness policy also gives weight (in the form of a bias) to the amount of memory allocated to hidden applications in the host and the guest, such that the side under memory pressure with a large amount of memory allocated to hidden applications should yield memory to the other side under the same pressure with a smaller amount of memory allocated to hidden applications. This bias is gradually reduced as the number of hidden applications in a system, the host or the guest as the case may be, is reduced, so as to avoid a situation where the system is pushed into an extreme low memory state with only a small amount of applications to terminate.","In one embodiment, the balloon adjustment value, \u0394, is computed as a fraction of an error value, E, that has two components, Elowmem and Ebg. Elowmem is indicative of the imbalance in the freeable memory between the host and the guest, and Ebg is the hidden application memory bias. The balloon adjustment value is taken as a fraction (a value between 0 and 1, e.g., 0.5), Kp, so that the imbalance is gradually (conservatively) corrected. The governing equations is as follows:\n\n\u0394=\n","Elowmem is the difference between low memory distances in the host and the guest, where the low memory distance provides a measure of the number of pages in the free memory pool (represented as FREE) and page cache (represented as FILE) that may be consumed by normal memory allocation until max(FREE, FILE)<Kempty, where Kempty is the threshold number of pages at which the low memory killer will begin terminating processes. The following is one particular implementation of the above logic:","Elowmem=LowMemDistance of guest\u2212LowMemDistance of host, where:\n\nLowMemDistance=(FREE+FILE\u2212empty), if FILE\u2267empty; and\n\nLowMemDistance=max(0,FREE\u2212empty), if FILE<empty.\n","Ebg is calculated from the number of resident set size (RSS) pages belonging to hidden applications in the host (represented as RSS_H) and the number of RSS pages belonging to hidden applications in the guest (represented as RSS_G), based on the following equation:\n\n*(RSS\u2212RSS)\/(RSS+RSS)\n","The multiplier, S, provides the magnitude of the bias, and the adjacent fraction (which has a value from \u22121 to +1) provides the direction and proportion. The multiplier, S, is set to be less than max(RSS_G, RSS_H), since the low memory killer will begin to terminate non-hidden applications as well as hidden applications if confronted with too large a bias. Therefore, the size of the multiplier, S, is limited by the following equation:\n\n=min(Krmax,Krss*max(RSS,RSS)\n","Krmax represents a bound on the size of the bias and is used when there are a large number of hidden application pages. It should be large enough to ensure balloon adjustment will force necessary hidden application memory killing in the world (host or guest) with the higher number of hidden application pages, but not much larger, since it affects the maximum amount of memory available in the system for hidden application pages when an imbalance exists between hidden application pages in the guest and host. Krss is a fudge factor to account for the fact that the RSS measure does not accurately reflect the actual number of pages hidden applications use. It should be understood that RSS overestimates as it includes pages used by shared libraries. The fudge factor, Krss, is determined empirically by looking at how RSS tends to overestimate on some sample applications.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 4","b":["400","400","162","406","123","145","145","171","171","402","404","400"]},"At step , kernel  polls balloon controller thread  via an RPC for a balloon adjustment value. The polling includes the memory state of the guest, such as the number of memory pages in the guest's free memory pool and the guest's page cache, and the number of memory pages allocated to background processes running in the guest. Some time later, as denoted by the dashed arrow, kernel  receives the balloon adjustment value from balloon controller thread . If the balloon adjustment value is positive as determined at step , kernel  inflates the balloon at step  by allocating additional memory pages to balloon kernel module  in proportion to the size of the balloon adjustment value and pinning these newly allocated memory pages. After inflating the balloon, kernel  resets the timer at step . The timer value may be adjusted such that it is inversely proportional to the rate of change of the balloon adjustment value. If the balloon adjustment value is rapidly increasing or decreasing, the delay is set to a small value, e.g., 200 msec. On the other hand, if only a small net change in the balloon adjustment value has taken place recently, the delay is set to a large value, e.g., 1 second. If the balloon adjustment value is negative as determined at step , kernel  deflates the balloon at step  by unpinning a number of the memory pages allocated to balloon kernel module  in proportion to the size of the balloon adjustment value. After step , kernel executes step  where the timer is reset as described above. If the balloon adjustment value is zero, kernel  does nothing and proceeds directly to step .","It should be recognized that, in parallel with the memory ballooning technique described above, host kernel and guest kernel are separately managing memory allocations and deallocations in accordance with its own policies. For example, as described above, kernel  or kernel  frees up memory from its caches when it experiences memory pressure such as a slab shrink event. If there is insufficient memory in the kernel caches, one or more hidden applications may be terminated by the low memory killer.","In some embodiments, kernel  limits how often balloon controller module  may poll balloon controller thread  for updated balloon adjustment values by imposing a minimum delay between successive polls. If the host or the guest is under heavy memory pressure and issuing many slab shrink events, this minimum delay protects against overloading balloon controller thread , and ultimately the CPU, with balloon adjustment requests.",{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 5","b":["500","500","162","171","310","508","162","171","510","162","120","512","508","510","514","171","171","312"]},"Although one or more embodiments of the present invention have been described in some detail for clarity of understanding, it will be apparent that certain changes and modifications may be made within the scope of the claims. For example, while embodiments herein have referred to certain mobile operating systems such as Android, it should be recognized that any mobile operating systems may be utilized in alternative embodiments such as Apple's iOS, Research in Motion's Blackberry OS, Microsoft's Windows Phone, Hewlett Packard's webOS, Symbian, Java, and the like, and also non-mobile operating systems such as Mac OS X may be utilized in further embodiments. In addition, it should be recognized that the claims are applicable to embodiments employing a bare metal hypervisor as well as embodiments employing multiple guest virtual machines on a bare metal or hosted hypervisor. Accordingly, the described embodiments are to be considered as illustrative and not restrictive, and the scope of the claims is not to be limited to details given herein, but may be modified within the scope and equivalents of the claims. In the claims, elements and\/or steps do not imply any particular order of operation, unless explicitly stated in the claims.","The various embodiments described herein may employ various computer-implemented operations involving data stored in computer systems. For example, these operations may require physical manipulation of physical quantities\u2014usually, though not necessarily, these quantities may take the form of electrical or magnetic signals, where they or representations of them are capable of being stored, transferred, combined, compared, or otherwise manipulated. Further, such manipulations are often referred to in terms, such as producing, identifying, determining, or comparing. Any operations described herein that form part of one or more embodiments of the invention may be useful machine operations. In addition, one or more embodiments of the invention also relate to a device or an apparatus for performing these operations. The apparatus may be specially constructed for specific required purposes, or it may be a general purpose computer selectively activated or configured by a computer program stored in the computer. In particular, various general purpose machines may be used with computer programs written in accordance with the teachings herein, or it may be more convenient to construct a more specialized apparatus to perform the required operations.","The various embodiments described herein may be practiced with other computer system configurations including hand-held devices, microprocessor systems, microprocessor-based or programmable consumer electronics, minicomputers, mainframe computers, and the like.","One or more embodiments of the present invention may be implemented as one or more computer programs or as one or more computer program modules embodied in one or more computer readable media. The term computer readable medium refers to any data storage device that can store data which can thereafter be input to a computer system\u2014computer readable media may be based on any existing or subsequently developed technology for embodying computer programs in a manner that enables them to be read by a computer. Examples of a computer readable medium include a hard drive, network attached storage (NAS), read-only memory, random-access memory (e.g., a flash memory device), a CD (Compact Discs)\u2014CD-ROM, a CD-R, or a CD-RW, a DVD (Digital Versatile Disc), a magnetic tape, and other optical and non-optical data storage devices. The computer readable medium can also be distributed over a network coupled computer system so that the computer readable code is stored and executed in a distributed fashion.","Virtualization systems in accordance with the various embodiments, which may be hosted embodiments such as shown in , non-hosted embodiments such as shown in , or embodiments that tend to blur distinctions between the two, are all envisioned. Furthermore, various virtualization operations may be wholly or partially implemented in hardware. For example, a hardware implementation may employ a look-up table for modification of storage access requests to secure non-disk data.","Many variations, modifications, additions, and improvements are possible, regardless the degree of virtualization. The virtualization software can therefore include components of a host, console, or guest operating system that performs virtualization functions. Plural instances may be provided for components, operations or structures described herein as a single instance. Finally, boundaries between various components, operations and data stores are somewhat arbitrary, and particular operations are illustrated in the context of specific illustrative configurations. Other allocations of functionality are envisioned and may fall within the scope of the invention(s). In general, structures and functionality presented as separate components in exemplary configurations may be implemented as a combined structure or component. Similarly, structures and functionality presented as a single component may be implemented as separate components. These and other variations, modifications, additions, and improvements may fall within the scope of the appended claims(s)."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 2B","FIG. 1A"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 3","FIG. 2A"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
