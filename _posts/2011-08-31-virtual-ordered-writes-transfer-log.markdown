---
title: Virtual ordered writes transfer log
abstract: A primary storage device maintaining recovery data in connection with ordering data writes includes the primary storage device receiving a plurality of data writes, the primary storage device associating data writes begun after a first time and before a second time with a first chunk of data, and the primary storage device associating data writes begun after the second time with a second chunk of data different from the first chunk of data. After completion of all writes associated with the first chunk of data, the primary storage device initiates transfer of writes associated with the first chunk of data to a secondary storage device. The primary storage device maintains a transfer log of data from the first chunk that is successfully transferred to the secondary storage device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08924665&OS=08924665&RS=08924665
owner: EMC Corporation
number: 08924665
owner_city: Hopkinton
owner_country: US
publication_date: 20110831
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF VARIOUS EMBODIMENTS"],"p":["This application is a continuation of U.S. Pat. application Ser. No. 12\/214,749 filed on Jun. 19, 2008 (pending).","1. Technical Field","This application relates to computer storage devices, and more particularly to the field of transferring data between storage devices.","2. Description of Related Art","Host processor systems may store and retrieve data using a storage device containing a plurality of host interface units (host adapters), disk drives, and disk interface units (disk adapters). Such storage devices are provided, for example, by EMC Corporation of Hopkinton, Mass. and disclosed in U.S. Pat. No. 5,206,939 to Yanai et al., U.S. Pat. No. 5,778,394 to Galtzur et al., U.S. Pat. No. 5,845,147 to Vishlitzky et al., and U.S. Pat. No. 5,857,208 to Ofek. The host systems access the storage device through a plurality of channels provided therewith. Host systems provide data and access control information through the channels to the storage device and the storage device provides data to the host systems also through the channels. The host systems do not address the disk drives of the storage device directly, but rather, access what appears to the host systems as a plurality of logical disk units. The logical disk units may or may not correspond to the actual disk drives. Allowing multiple host systems to access the single storage device unit allows the host systems to share data stored therein.","In some instances, it may be desirable to copy data from one storage device to another. For example, if a host writes data to a first storage device, it may be desirable to copy that data to a second storage device provided in a different location so that if a disaster occurs that renders the first storage device inoperable, the host (or another host) may resume operation using the data of the second storage device. Such a capability is provided, for example, by the Remote Data Facility (RDF) product provided by EMC Corporation of Hopkinton, Mass. With RDF, a first storage device, denoted the \u201cprimary storage device\u201d (or \u201cR\u201d or \u201clocal storage device\u201d) is coupled to the host. One or more other storage devices, called \u201csecondary storage devices\u201d (or \u201cR\u201d or \u201cremote storage device\u201d) receive copies of the data that is written to the primary storage device by the host. The host interacts directly with the primary storage device, but any data changes made to the primary storage device are automatically provided to the one or more secondary storage devices using RDF. The primary and secondary storage devices may be connected by a data link, such as an ESCON link, a Fibre Channel link, and\/or a Gigabit Ethernet link. The RDF functionality may be facilitated with an RDF adapter (RA) provided at each of the storage devices.","RDF allows synchronous data transfer where, after data written from a host to a primary storage device is transferred from the primary storage device to a secondary storage device using RDF, receipt is acknowledged by the secondary storage device to the primary storage device which then provides a write acknowledge back to the host. Thus, in synchronous mode, the host does not receive a write acknowledge from the primary storage device until the RDF transfer to the secondary storage device has been completed and acknowledged by the secondary storage device.","A drawback to the synchronous RDF system is that the latency of each of the write operations is increased by waiting for the acknowledgement of the RDF transfer. This problem is worse when there is a long distance between the primary storage device and the secondary storage device; because of transmission delays, the time delay required for making the RDF transfer and then waiting for an acknowledgement back after the transfer is complete may be unacceptable.","It is also possible to have the host write data to the primary storage device and have the primary storage device copy data to the secondary storage device in an asynchronous background process. The background process cycles through each of the tracks of the primary storage device sequentially and, when it is determined that a particular block has been modified since the last time that block was copied, the block is transferred from the primary storage device to the secondary storage device. Although this mechanism may attenuate the latency problem associated with synchronous data transfer, a difficulty still exists because there can not be a guarantee of data consistency between the primary and secondary storage devices. If there are problems, such as a failure of the primary system, the secondary system may end up with out-of-order changes that make the data unusable.","A proposed solution to this problem is the Symmetrix Automated Replication (SAR) process, which is described in U.S. Pat. No. 7,117,386 titled \u201cSAR RESTART AND GOING HOME PROCEDURES\u201d to LeCrone, et al. and in U.S. Pat. No. 7,024,528 titled \u201cSTORAGE AUTOMATED REPLICATION PROCESSING\u201d to LeCrone, et al., both of which are incorporated by reference herein. The SAR uses devices (BCV's) that can mirror standard logical devices. A BCV device can also be split from its standard logical device after being mirrored and can be resynced (i.e., reestablished as a mirror) to the standard logical devices after being split. In addition, a BCV can be remotely mirrored using RDF, in which case the BCV may propagate data changes made thereto (while the BCV is acting as a mirror) to the BCV remote mirror when the BCV is split from the corresponding standard logical device.","However, using the SAR process requires the significant overhead of continuously splitting and resyncing the BCV's. The SAR process also uses host control and management, which relies on the controlling host being operational. In addition, the cycle time for a practical implementation of a SAR process is on the order of twenty to thirty minutes, and thus the amount of data that may be lost when an RDF link and\/or primary device fails could be twenty to thirty minutes worth of data.","Another solution is to use SRDF\/A data transfer (also sometimes referred to as \u201cvirtual ordered writes\u201d where data is accumulated in order-independent chunks at the primary storage device which are transferred, a chunk at a time, to the secondary storage device. Each chunk is provided with a sequence number that is associated with data as the data is transferred from the primary storage device to the secondary storage device. Data that is received by the secondary storage device is not committed (stored) by the secondary storage device unless and until data for the entire chunk has been received from the primary storage device, as indicated by a message provided by the primary storage device to the secondary storage device. The SRDF\/A mechanism is described, for example, in U.S. Pat. No. 7,054,883 titled \u201cVIRTUAL ORDERED WRITES FOR MULTIPLE STORAGE DEVICES\u201d to Meiri, et al., which is incorporated by reference herein.","A drawback to SRDF\/A is that, if communication between the primary storage device and the secondary storage device is broken, then data for any chunk that was partially sent needs to be discarded by the secondary storage device. After communication is reestablished, data for the entire chunk will need to be resent, including data from the partial chunk that had been previously sent. In some cases, the overhead associated with determining what needs to be sent is significant. Accordingly, it is desirable to provide an SRDF\/A system that simplifies the determination of what needs to be resent following a loss and subsequent reestablishment of communication between the primary and secondary storage devices.","According to the system described herein, a primary storage device maintaining recovery data in connection with ordering data writes includes the primary storage device receiving a plurality of data writes, the primary storage device associating data writes begun after a first time and before a second time with a first chunk of data, the primary storage device associating data writes begun after the second time with a second chunk of data different from the first chunk of data, and, after completion of all writes associated with the first chunk of data, the primary storage device initiating transfer of writes associated with the first chunk of data to a secondary storage device, where the primary storage device maintains a transfer log of data from the first chunk that is successfully transferred to the secondary storage device. A primary storage device maintaining recovery data in connection with ordering data writes may also include, in response to receiving a message from the primary storage device separate from the first and second chunks of data, the secondary storage device storing the data writes associated with the first chunk of data. A primary storage device maintaining recovery data in connection with ordering data writes may also include, after storing all of the data writes associated with the first chunk of data, the secondary storage device sending an acknowledge to the primary storage device, following sending a message to the secondary storage device, the primary storage device suspending transferring data to the secondary storage device, following suspending transferring data, the primary storage device associating data writes with a third chunk of data, different from the first and second chunks of data, to subsequent data writes, and, in response to the secondary storage device sending an acknowledge to the primary storage device, the primary storage device discarding transfer log data associated with the first chunk of data and resuming transferring data to the secondary storage device. A primary storage device maintaining recovery data in connection with ordering data writes may also include providing data writes to cache slots of the primary storage device. A primary storage device maintaining recovery data in connection with ordering data writes may also include, in response to a data write being associated with the second chunk of data corresponding to a cache slot already associated with the first chunk of data, copying the data to a new cache slot. A primary storage device maintaining recovery data in connection with ordering data writes may also include the primary storage device using a first list of pointers to the cache slots for data writes associated with the first chunk of data, the primary storage device using a second list of pointers to the cache slots for data writes associated with the second chunk of data, and providing a cache stamp field in a header portion of each of the slots, the cache stamp field including a sequence number associated with the slot, where the sequence number corresponds to a particular one of the chunks of data and where the cache stamp field includes a password field that is written when the slot is first used and in response to a slot no longer being used, the password field is cleared. A primary storage device maintaining recovery data in connection with ordering data writes may also include the primary storage device using a first cache only virtual device for the cache slots corresponding to data writes associated with the first chunk of data and the primary storage device using a second cache only virtual device for the cache slots corresponding to data writes associated with the second chunk of data. Receiving a plurality of data writes may also include receiving a plurality of data writes from a host.","According further to the system described herein, computer software, provided in a computer readable medium, maintains recovery data in connection with ordering data writes from a primary storage device to a secondary storage device. The software includes executable code that receives a plurality of data writes, executable code that associates data writes begun after a first time and before a second time with a first chunk of data, executable code that associates data writes begun after the second time with a second chunk of data different from the first chunk of data, and executable code that, after completion of all writes associated with the first chunk of data, initiates transfer of writes associated with the first chunk of data to the secondary storage device and maintains a transfer log of data from the first chunk that is successfully transferred to the secondary storage device. The software may also include executable code that suspends transferring data to the secondary storage device following sending a message to the secondary storage device, executable code that associates data writes with a third chunk of data, different from the first and second chunks of data, following suspending transferring data and executable code that discards the transfer log data associated with the first chunk of data and resumes transferring data to the secondary storage device in response to receipt of an acknowledge from the secondary storage device. The software may also include executable code that provides data writes to cache slots of the primary storage device. The software may also include executable code that copies data to a new cache slot in response to a data write being associated with the second chunk of data corresponding to a cache slot already associated with the first chunk of data. The software may also include executable code that uses a first list of pointers to the cache slots for data writes associated with the first chunk of data and a second list of pointers to the cache slots for data writes associated with the second chunk of data and executable code that provides a cache stamp field in a header portion of each of the slots, the cache stamp field including a sequence number associated with the slot, where the sequence number corresponds to a particular one of the chunks of data and where the cache stamp field includes a password field that is written when the slot is first used and in response to a slot no longer being used, the password field is cleared. The software may also include executable code that uses a first cache only virtual device for the cache slots corresponding to data writes associated with the first chunk of data and executable code that uses a second cache only virtual device for the cache slots corresponding to data writes associated with the second chunk of data. Executable code that receives a plurality of data writes may include receiving a plurality of data writes from a host.","According further to the system described herein, a data storage device includes at least one disk that contains data and at least one director, coupled to the at least one disk, that reads data from the disk and writes data to the disk, the director including at least one processor and including executable code that associates data writes to the storage device begun after a first time and before a second time with a first chunk of data and associates data writes begun after the second time with a second chunk of data different from the first chunk of data, the executable code also, after completion of all writes associated with the first chunk of data, initiates transfer of writes associated with the first chunk of data to another storage device and maintains a transfer log of data from the first chunk that is successfully transferred to the other storage device. The executable code may also provide data writes to cache slots of the storage device. The executable code may also copy data to a new cache slot in response to a data write being associated with the second chunk of data corresponding to a cache slot already associated with the first chunk of data. The executable code may also use a first list of pointers to the cache slots for data writes associated with the first chunk of data and a second list of pointers to the cache slots for data writes associated with the second chunk of data and the executable code also provides a cache stamp field in a header portion of each of the slots, the cache stamp field including a sequence number associated with the slot, wherein the sequence number corresponds to a particular one of the chunks of data and wherein the cache stamp field includes a password field that is written when the slot is first used and in response to a slot no longer being used, the password field is cleared. The executable code may also use a first cache only virtual device for the cache slots corresponding to data writes associated with the first chunk of data and uses a second cache only virtual device for the cache slots corresponding to data writes associated with the second chunk of data.","According further to the system described herein, a computer readable medium has computer executable instructions for performing any of the steps described herein.","According further to the system described herein, a system has at least one processor that performs any of the steps described herein.","Referring to , a diagram  shows a relationship between a host , a local storage device , and a remote storage device . The host  reads and writes data from and to the local storage device  via a host adapter (HA) , which facilitates the interface between the host  and the local storage device . Although the diagram  only shows one host  and one HA , it will be appreciated by one of ordinary skill in the art that multiple HA's may be used and that one or more HA's may have one or more hosts coupled thereto.","Data from the local storage device  is copied to the remote storage device  via an RDF link  to cause the data on the remote storage device  to be identical to the data on the local storage device . Although only one link is shown (the link ), it is possible to have additional links between the storage devices ,  and to have links between one or both of the storage devices ,  and other storage devices (not shown). In addition, the link  may be provided using a direct connection (wired, over-the-air, or some combination thereof), a network (such as the Internet), or any other appropriate means for conveying data. Note that there may be a time delay between the transfer of data from the local storage device  to the remote storage device , so that the remote storage device  may, at certain points in time, contain data that is not identical to the data on the local storage device . Communication using RDF is described, for example, in U.S. Pat. No. 5,742,792 titled \u201cREMOTE DATA MIRRORING\u201d to Yanai, et al., which is incorporated by reference herein.","The local storage device  includes a first plurality of RDF adapter units (RA's) , , and the remote storage device  includes a second plurality of RA's -. The RA's -, -are coupled to the RDF link  and are similar to the host adapter , but are used to transfer data between the storage devices , . The software used in connection with the RA's -, -is discussed in more detail hereinafter.","The storage devices ,  may include one or more disks, each containing a different portion of data stored on each of the storage devices , .  shows the storage device  including a plurality of disks , , and the storage device  including a plurality of disks , , . The RDF functionality described herein may be applied so that the data for at least a portion of the disks -of the local storage device  is copied, using RDF, to at least a portion of the disks -of the remote storage device . It is possible that other data of the storage devices ,  is not copied between the storage devices , , and thus is not identical.","Each of the disks -is coupled to a corresponding disk adapter unit (DA) , , that provides data to a corresponding one of the disks -and receives data from a corresponding one of the disks -. Similarly, a plurality of DA's , , of the remote storage device  are used to provide data to corresponding ones of the disks -and receive data from corresponding ones of the disks -. An internal data path exists between the DA's -, the HA  and the RA's -of the local storage device . Similarly, an internal data path exists between the DA's -and the RA's -of the remote storage device . Note that, in other embodiments, it is possible for more than one disk to be serviced by a DA and that it is possible for more than one DA to service a disk.","The local storage device  also includes a global memory  that may be used to facilitate data transferred between the DA's -, the HA  and the RA's -. The memory  may contain tasks that are to be performed by one or more of the DA's -, the HA  and the RA's -, and a cache for data fetched from one or more of the disks -. Similarly, the remote storage device  includes a global memory  that may contain tasks that are to be performed by one or more of the DA's -and the RA's -, and a cache for data fetched from one or more of the disks -. Use of the memories ,  is described in more detail hereinafter.","The storage space in the local storage device  that corresponds to the disks -may be subdivided into a plurality of volumes or logical devices. The logical devices may or may not correspond to the physical storage space of the disks -. Thus, for example, the disk may contain a plurality of logical devices or, alternatively, a single logical device could span both of the disks , . Similarly, the storage space for the remote storage device  that comprises the disks -may be subdivided into a plurality of volumes or logical devices, where each of the logical devices may or may not correspond to one or more of the disks -","Providing an RDF mapping between portions of the local storage device  and the remote storage device  involves setting up a logical device on the remote storage device  that is a remote mirror for a logical device on the local storage device . The host  reads and writes data from and to the logical device on the local storage device  and the RDF mapping causes modified data to be transferred from the local storage device  to the remote storage device  using the RA's, -, -and the RDF link . In steady state operation, the logical device on the remote storage device  contains data that is identical to the data of the logical device on the local storage device . The logical device on the local storage device  that is accessed by the host  is referred to as the \u201cR volume\u201d (or just \u201cR\u201d) while the logical device on the remote storage device  that contains a copy of the data on the R volume is called the \u201cR volume\u201d (or just \u201cR\u201d). Thus, the host reads and writes data from and to the R  volume and RDF handles automatic copying and updating of the data from the R volume to the R volume. The system described herein may be implemented using software, hardware, and\/or a combination of software and hardware where software may be stored in an appropriate storage medium and executed by one or more processors.","Referring to , a diagram  illustrates an embodiment of the storage device  where each of a plurality of directors -are coupled to the memory . Each of the directors -represents the HA  (and\/or other HA's), the RA's -, or DA's -. In an embodiment disclosed herein, there may be up to sixty four directors coupled to the memory . Of course, for other embodiments, there may be a higher or lower maximum number of directors that may be used.","The diagram  also shows an optional communication module (CM)  that provides an alternative communication path between the directors -. Each of the directors -may be coupled to the CM  so that any one of the directors -may send a message and\/or data to any other one of the directors -without needing to go through the memory . The CM  may be implemented using conventional MUX\/router technology where a sending one of the directors -provides an appropriate address to cause a message and\/or data to be received by an intended receiving one of the directors -. Some or all of the functionality of the CM  may be implemented using one or more of the directors -so that, for example, the directors -may be interconnected directly with the interconnection functionality being provided on each of the directors -. In addition, a sending one of the directors -may be able to broadcast a message to all of the other directors -at the same time.","In some embodiments, one or more of the directors -may have multiple processor systems thereon and thus may be able to perform functions for multiple directors. In some embodiments, at least one of the directors -having multiple processor systems thereon may simultaneously perform the functions of at least two different types of directors (e.g., an HA and a DA). Furthermore, in some embodiments, at least one of the directors -having multiple processor systems thereon may simultaneously perform the functions of at least one type of director and perform other processing with the other processing system. In addition, all or at least part of the global memory  may be provided on one or more of the directors -and shared with other ones of the directors -","Note that, although specific storage device configurations are disclosed in connection with  and , it should be understood that the system described herein may be implemented on any appropriate platform. Thus, the system described herein may be implemented using a platform like that described in connection with  and\/or  or may be implemented using a platform that is somewhat or even completely different from any particular platform described herein.","Referring to , a path of data is illustrated from the host  to the local storage device  and the remote storage device . Data written from the host  to the local storage device  is stored locally, as illustrated by the data element  of the local storage device . The data that is written by the host  to the local storage device  is also maintained by the local storage device  in connection with being sent by the local storage device  to the remote storage device  via the link .","In the system described herein, each data write by the host  (of, for example a record, a plurality of records, a track, etc.) is assigned a sequence number. The sequence number may be provided in an appropriate data field associated with the write. In , the writes by the host  are shown as being assigned sequence number N. All of the writes performed by the host  that are assigned sequence number N are collected in a single chunk of data . The chunk  represents a plurality of separate writes by the host  that occur at approximately the same time.","Generally, the local storage device  accumulates chunks of one sequence number while transmitting a previously accumulated chunk (having the previous sequence number) to the remote storage device . Thus, while the local storage device  is accumulating writes from the host  that are assigned sequence number N, the writes that occurred for the previous sequence number (N\u22121) are transmitted by the local storage device  to the remote storage device  via the link . A chunk  represents writes from the host  that were assigned the sequence number N\u22121 that have not been transmitted yet to the remote storage device .","The remote storage device  receives the data from the chunk  corresponding to writes assigned a sequence number N\u22121 and constructs a new chunk  of host writes having sequence number N\u22121. The data may be transmitted using appropriate RDF protocol that acknowledges data sent across the link . When the remote storage device  has received all of the data from the chunk , the local storage device  sends a commit message to the remote storage device  to commit all the data assigned the N\u22121 sequence number corresponding to the chunk . Generally, once a chunk corresponding to a particular sequence number is committed, that chunk may be written to the logical storage device. This is illustrated in  with a chunk  corresponding to writes assigned sequence number N\u22122 (i.e., two before the current sequence number being used in connection with writes by the host  to the local storage device ).","In , the chunk  is shown as being written to a data element  representing disk storage for the remote storage device . Thus, the remote storage device  is receiving and accumulating the chunk  corresponding to sequence number N\u22121 while the chunk  corresponding to the previous sequence number (N\u22122) is being written to disk storage of the remote storage device  illustrated by the data element . In some embodiments, the data for the chunk  is marked for write (but not necessarily written immediately), while the data for the chunk  is not.","Thus, in operation, the host  writes, to the local storage device , data that is stored locally in the data element  and accumulated in the chunk . Once all of the data for a particular sequence number has been accumulated (described elsewhere herein), the local storage device  increments the sequence number. Data from the chunk  corresponding to one less than the current sequence number is transferred from the local storage device  to the remote storage device  via the link . The chunk  corresponds to data for a sequence number that was committed by the local storage device  sending a message to the remote storage device . Data from the chunk  is written to disk storage of the remote storage device .","Note that the writes within a particular one of the chunks - are not necessarily ordered. However, as described in more detail elsewhere herein, every write for the chunk  corresponding to sequence number N\u22122 was begun prior to beginning any of the writes for the chunks ,  corresponding to sequence number N\u22121. In addition, every write for the chunks ,  corresponding to sequence number N\u22121 was begun prior to beginning any of the writes for the chunk  corresponding to sequence number N. Thus, in the event of a communication failure between the local storage device  and the remote storage device , the remote storage device  may simply finish writing the last committed chunk of data (the chunk  in the example of ) and can be assured that the state of the data at the remote storage device  is ordered in the sense that the data element  contains all of the writes that were begun prior to a certain point in time and contains no writes that were begun after that point in time. Thus, R always contains a point in time copy of R and it is possible to reestablish a consistent image from the R device.","Referring to , a diagram  illustrates items used to construct and maintain the chunks , . A standard logical device  contains data written by the host  and corresponds to the data element  of  and the disks -of .","Two linked lists of pointers ,  are used in connection with the standard logical device . The linked lists ,  correspond to data that may be stored, for example, in the memory  of the local storage device . The linked list  contains a plurality of pointers -, each of which points to a slot of a cache  used in connection with the local storage device . Similarly, the linked list  contains a plurality of pointers -, each of which points to a slot of the cache . In some embodiments, the cache  may be provided in the memory  of the local storage device . The cache  contains a plurality of cache slots - that may be used in connection to writes to the standard logical device  and, at the same time, used in connection with the linked lists , .","Each of the linked lists ,  may be used for one of the chunks of data ,  so that, for example, the linked list  may correspond to the chunk of data  for sequence number N while the linked list  may correspond to the chunk of data  for sequence number N\u22121. Thus, when data is written by the host  to the local storage device , the data is provided to the cache  and, in some cases (described elsewhere herein), an appropriate pointer of the linked list  is created. Note that the data will not be removed from the cache  until the data is destaged to the standard logical device  and the data is also no longer pointed to by one of the pointers - of the linked list , as described elsewhere herein.","In an embodiment herein, one of the linked lists ,  is deemed \u201cactive\u201d while the other is deemed \u201cinactive\u201d. Thus, for example, when the sequence number N is even, the linked list  may be active while the linked list  is inactive. The active one of the linked lists ,  handles writes from the host  while the inactive one of the linked lists ,  corresponds to the data that is being transmitted from the local storage device  to the remote storage device .","While the data that is written by the host  is accumulated using the active one of the linked lists ,  (for the sequence number N), the data corresponding to the inactive one of the linked lists ,  (for previous sequence number N\u22121) is transmitted from the local storage device  to the remote storage device . The RA's -use the linked lists ,  to determine the data to transmit from the local storage device  to the remote storage device .","Once data corresponding to a particular one of the pointers in one of the linked lists ,  has been transmitted to the remote storage device , the particular one of the pointers may be removed from the appropriate one of the linked lists , . In addition, the data may also be marked for removal from the cache  (i.e., the slot may be returned to a pool of slots for later, possibly unrelated, use) provided that the data in the slot is not otherwise needed for another purpose (e.g., to be destaged to the standard logical device ). A mechanism may be used to ensure that data is not removed from the cache  until all devices are no longer using the data. Such a mechanism is described, for example, in U.S. Pat. No. 5,537,568 titled \u201cSYSTEM FOR DYNAMICALLY CONTROLLING CACHE MANAGER MAINTAINING CACHE INDEX AND CONTROLLING SEQUENTIAL DATA ACCESS\u201d to Yanai, et al. and in U.S. Pat. No. 6,594,742 titled \u201cCACHE MANAGEMENT VIA STATISTICALLY ADJUSTED SLOT AGING\u201d to Josef Ezra, both of which are incorporated by reference herein.","Referring to , a slot , like one of the slots - of the cache , includes a header  and data . The header  corresponds to overhead information used by the system to manage the slot . The data  is the corresponding data from the disk that is being (temporarily) stored in the slot . Information in the header  includes pointers back to the disk, time stamp(s), etc.","The header  also includes a cache stamp  used in connection with the system described herein. In an embodiment herein, the cache stamp  is eight bytes. Two of the bytes are a \u201cpassword\u201d that indicates whether the slot  is being used by the system described herein. In other embodiments, the password may be one byte while the following byte is used for a pad. As described elsewhere herein, the two bytes of the password (or one byte, as the case may be) being equal to a particular value indicates that the slot  is pointed to by at least one entry of the linked lists , . The password not being equal to the particular value indicates that the slot  is not pointed to by an entry of the linked lists , . Use of the password is described elsewhere herein.","The cache stamp  also includes a two byte field indicating the sequence number (e.g., N, N\u22121, N\u22122, etc.) of the data  of the slot . As described elsewhere herein, the sequence number field of the cache stamp  may be used to facilitate processing. The remaining four bytes of the cache stamp  may be used for a pointer, as described elsewhere herein. Of course, the two bytes of the sequence number and the four bytes of the pointer are only valid when the password equals the particular value that indicates that the slot  is pointed to by at least one entry in one of the lists , .","Referring to , a flow chart  illustrates steps performed by the HA  in connection with a host  performing a write operation. Of course, when the host  performs a write, processing occurs for handling the write in a normal fashion irrespective of whether the data is part of an R\/R RDF group. For example, when the host  writes data for a portion of the disk, the write occurs to a cache slot which is eventually destaged to the disk. The cache slot may either be a new cache slot or may be an already existing cache slot created in connection with a previous read and\/or write operation to the same track.","Processing begins at a first step  where a slot corresponding to the write is locked. In an embodiment herein, each of the slots - of the cache  corresponds to a track of data on the standard logical device . Locking the slot at the step  prevents additional processes from operating on the relevant slot during the processing performed by the HA  corresponding to the steps of the flow chart .","Following step  is a step  where a value for N, the sequence number, is set. As discussed elsewhere herein, the value for the sequence number obtained at the step  is maintained during the entire write operation performed by the HA  while the slot is locked. As discussed elsewhere herein, the sequence number is assigned to each write to set the one of the chunks of data ,  to which the write belongs. Writes performed by the host  are assigned the current sequence number. It is useful that a single write operation maintain the same sequence number throughout.","Following the step  is a test step  which determines if the password field of the cache slot is valid. As discussed above, the system described herein sets the password field to a predetermined value to indicate that the cache slot is already in one of the linked lists of pointers , . If it is determined at the test step  that the password field is not valid (indicating that the slot is new and that no pointers from the lists ,  point to the slot), then control passes from the step  to a step , where the cache stamp of the new slot is set by setting the password to the predetermined value, setting the sequence number field to N, and setting the pointer field to Null. In other embodiments, the pointer field may be set to point to the slot itself.","Following the step  is a step  where a pointer to the new slot is added to the active one of the pointer lists , . In an embodiment herein, the lists ,  are circular doubly linked lists, and the new pointer is added to the circular doubly linked list in a conventional fashion. Of course, other appropriate data structures could be used to manage the lists , . Following the step  is a step  where flags are set. At the step , the RDF_WP flag (RDF write pending flag) is set to indicate that the slot needs to be transmitted to the remote storage device  using RDF. In addition, at the step , the IN_CACHE flag is set to indicate that the slot needs to be destaged to the standard logical device . Following the step  is a step  where the data being written by the host  and the HA  is written to the slot. Following the step  is a step  where the slot is unlocked. Following step , processing is complete.","If it is determined at the test step  that the password field of the slot is valid (indicating that the slot is already pointed to by at least one pointer of the lists , ), then control transfers from the step  to a test step , where it is determined whether the sequence number field of the slot is equal to the current sequence number, N. Note that there are two valid possibilities for the sequence number field of a slot with a valid password. It is possible for the sequence number field to be equal to N, the current sequence number. This occurs when the slot corresponds to a previous write with sequence number N. The other possibility is for the sequence number field to equal N\u22121. This occurs when the slot corresponds to a previous write with sequence number N\u22121. Any other value for the sequence number field is invalid. Thus, for some embodiments, it may be possible to include error\/validity checking in the step  or possibly make error\/validity checking a separate step. Such an error may be handled in any appropriate fashion, which may include providing a message to a user.","If it is determined at the step  that the value in the sequence number field of the slot equals the current sequence number N, then no special processing is required and control transfers from the step  to the step , discussed above, where the data is written to the slot. Otherwise, if the value of the sequence number field is N\u22121 (the only other valid value), then control transfers from the step  to a step  where a new slot is obtained. The new slot obtained at the step  may be used to store the data being written.","Following the step  is a step  where the data from the old slot is copied to the new slot that was obtained at the step . Note that the copied data includes the RDF_WP flag, which should have been set at the step  on a previous write when the slot was first created. Following the step  is a step  where the cache stamp for the new slot is set by setting the password field to the appropriate value, setting the sequence number field to the current sequence number, N, and setting the pointer field to point to the old slot. Following the step  is a step  where a pointer to the new slot is added to the active one of the linked lists , . Following the step  is the step , discussed above, where the data is written to the slot which, in this case, is the new slot.","Referring to , a flow chart  illustrates steps performed in connection with the RA's -scanning the inactive one of the lists ,  to transmit RDF data from the local storage device  to the remote storage device . As discussed above, the inactive one of the lists ,  points to slots corresponding to the N\u22121 cycle for the R device when the N cycle is being written to the R device by the host using the active one of the lists , .","Processing begins at a first step  where it is determined if there are any entries in the inactive one of the lists , . As data is transmitted, the corresponding entries are removed from the inactive one of the lists , . In addition, new writes are provided to the active one of the lists ,  and not generally to the inactive one of the lists , . Thus, it is possible (and desirable, as described elsewhere herein) for the inactive one of the lists ,  to contain no data at certain times. If it is determined at the step  that there is no data to be transmitted, then the inactive one of the lists ,  is continuously polled until data becomes available. Data for sending becomes available in connection with a cycle switch (discussed elsewhere herein) where the inactive one of the lists ,  becomes the active one of the lists , , and vice versa.","If it is determined at the step  that there is data available for sending, control transfers from the step  to a step , where the slot is verified as being correct. The processing performed at the step  is an optional check that may include verifying that the password field is correct and verifying that the sequence number field is correct. If there is incorrect (unexpected) data in the slot, error processing may be performed, which may include notifying a user of the error and possibly error recovery processing.","Following the step  is a step , where the data is sent via RDF in a conventional fashion. In an embodiment herein, the entire slot is not transmitted. Rather, only records within the slot that have the appropriate mirror bits set (indicating the records have changed) are transmitted to the remote storage device . However, in other embodiments, it may be possible to transmit the entire slot, provided that the remote storage device  only writes data corresponding to records having appropriate mirror bits set and ignores other data for the track, which may or may not be valid. Following the step  is a test step  where it is determined if the data that was transmitted has been acknowledged by the R device. If not, the data is resent, as indicated by the flow from the step  back to the step . In other embodiments, different and more involved processing may be used to send data and acknowledge receipt thereof. Such processing may include error reporting and alternative processing that is performed after a certain number of attempts to send the data have failed.","Once it is determined at the test step  that the data has been successfully sent, control passes from the step  to a step  where the data that has been sent is logged. In an embodiment herein, each track from an inactive cycle that is successfully transmitted from the R device to the R device is written to a transfer log that contains a list of all inactive tracks that are successfully sent. The transfer log may be used for data recovery, as discussed in more detail elsewhere herein. The transfer log may be no longer needed once the entire inactive cycle has been sent and the R device acknowledges receipt of all of the inactive cycle data (discussed in more detail elsewhere here). The transfer log may be provided using any appropriate mechanism. In an embodiment herein, the transfer log may be provided using one or more otherwise-unused cache slots (like the slots - of ), where multiple entries indicating logged tracks are provided in each slot using an appropriate mechanism, such as a table or a linked list. Thus, for example, each logged track and\/or modified portions thereof may be indentified using a two-byte (or four-byte, or six-byte, etc.) identifier within the slot. The one or more cache slots used for the transfer log may be pointed to by one or more entries in the lists ,  where, for example, the transfer log cache slots may be the first or the last entries on the lists , . Of course, the transfer log is different from the list of slots needing to be transferred.","Following the step , control passes to a step  to clear the RDF_WP flag (since the data has been successfully sent via RDF). Following the step  is a test step  where it is determined if the slot is a duplicate slot created in connection with a write to a slot already having an existing entry in the active one of the lists , . This possibility is discussed above in connection with the steps , , , , . If it is determined at the step  that the slot is a duplicate slot, then control passes from the step  to a step  where the slot is returned to the pool of available slots (to be reused). In addition, the slot may also be aged (or have some other appropriate mechanism applied thereto) to provide for immediate reuse ahead of other slots since the data provided in the slot is not valid for any other purpose. Following the step  or the step  if the slot is not a duplicate slot is a step  where the password field of the slot header is cleared so that when the slot is reused, the test at the step  of  properly classifies the slot as a new slot.","Following the step  is a step  where the entry in the inactive one of the lists ,  is removed. Following the step , control transfers back to the step , discussed above, where it is determined if there are additional entries on the inactive one of the lists ,  corresponding to data needing to be transferred. Note that  does not show steps for locking and unlocking slots to control access by other (unrelated) processes. However, it is understood that such steps may be performed, as appropriate, to provide data consistency. For example, a slot may be locked prior to being sent at the step , and may be unlocked some time after performing the step .","Referring to , a diagram  illustrates creation and manipulation of the chunks ,  used by the remote storage device . Data that is received by the remote storage device , via the link , is provided to a cache  of the remote storage device . The cache  may be provided, for example, in the memory  of the remote storage device . The cache  includes a plurality of cache slots -, each of which may be mapped to a track of a standard logical storage device . The cache  is similar to the cache  of  and may contain data that can be destaged to the standard logical storage device  of the remote storage device . The standard logical storage device  corresponds to the data element  shown in  and the disks -shown in .","The remote storage device  also contains a pair of cache only virtual devices (COVD) , . The cache only virtual devices ,  corresponded device tables that may be stored, for example, in the memory  of the remote storage device . Each track entry of the tables of each of the COVDs ,  point to either a track of the standard logical device  or point to a slot of the cache . Cache only virtual devices are described in U.S. Pat. No. 7,113,945 titled \u201cVIRTUAL STORAGE DEVICE THAT USES VOLATILE MEMORY\u201d to Moreshet, et al., which is incorporated by reference herein. Note, however, that the functionality described herein in connection with the COVDs may be implemented generally using tables having appropriate pointers that may point to cache slots as described herein.","The plurality of cache slots - may be used in connection to writes to the standard logical device  and, at the same time, used in connection with the cache only virtual devices , . In an embodiment herein, each of track table entries of the cache only virtual devices ,  contain a null to indicate that the data for that track is stored on a corresponding track of the standard logical device . Otherwise, an entry in the track table for each of the cache only virtual devices ,  contains a pointer to one of the slots - in the cache .","Each of the cache only virtual devices ,  corresponds to one of the data chunks , . Thus, for example, the cache only virtual device  may correspond to the data chunk  while the cache only virtual device  may correspond to the data chunk . In an embodiment herein, one of the cache only virtual devices ,  may be deemed \u201cactive\u201d while the other one of the cache only virtual devices ,  may be deemed \u201cinactive\u201d. The inactive one of the cache only virtual devices ,  may correspond to data being received from the local storage device  (i.e., the chunk ) while the active one of the cache only virtual device ,  corresponds to data being restored (written) to the standard logical device  (i.e., the chunk ).","Data from the local storage device  that is received via the link  may be placed in one of the slots - of the cache . A corresponding pointer of the inactive one of the cache only virtual devices ,  may be set to point to the received data. Subsequent data having the same sequence number may be processed in a similar manner. At some point, the local storage device  provides a message committing all of the data sent using the same sequence number. Once the data for a particular sequence number has been committed, the inactive one of the cache only virtual devices ,  becomes active and vice versa. At that point, data from the now active one of the cache only virtual devices ,  is copied to the standard logical device  while the inactive one of the cache only virtual devices ,  is used to receive new data (having a new sequence number) transmitted from the local storage device  to the remote storage device .","As data is removed from the active one of the cache only virtual devices ,  (discussed elsewhere herein), the corresponding entry in the active one of the cache only virtual devices ,  may be set to null. In addition, the data may also be removed from the cache  (i.e., the slot returned to the pool of free slots for later use) provided that the data in the slot is not otherwise needed for another purpose (e.g., to be destaged to the standard logical device ). A mechanism may be used to ensure that data is not removed from the cache  until all mirrors (including the cache only virtual devices , ) are no longer using the data. Such a mechanism is described, for example, in U.S. Pat. No. 5,537,568 titled \u201cSYSTEM FOR DYNAMICALLY CONTROLLING CACHE MANAGER MAINTAINING CACHE INDEX AND CONTROLLING SEQUENTIAL DATA ACCESS\u201d to Yanai, et al. and in U.S. Pat. No. 6,594,742 titled \u201cCACHE MANAGEMENT VIA STATISTICALLY ADJUSTED SLOT AGING\u201d to Josef Ezra, both of which are incorporated by reference herein.","In some embodiments discussed elsewhere herein, the remote storage device  may maintain linked lists ,  like the lists ,  used by the local storage device . The lists ,  may contain information that identifies the slots of the corresponding cache only virtual devices ,  that have been modified, where one of the lists ,  corresponds to one of the cache only virtual devices ,  and the other one of the lists ,  corresponds to the other one of the cache only virtual devices , . As discussed elsewhere herein, the lists ,  may be used to facilitate restoring data from the cache only virtual devices ,  to the standard logical device .","Referring to , a flow chart  illustrates steps performed by the remote storage device  in connection with processing data for a sequence number commit transmitted by the local storage device  to the remote storage device . As discussed elsewhere herein, the local storage device  periodically increments sequence numbers. When this occurs, the local storage device  finishes transmitting all of the data for the previous sequence number and then sends a commit message for the previous sequence number.","Processing begins at a first step  where the commit message is received. Following the step  is a test step  which determines if the active one of the cache only virtual devices ,  of the remote storage device  is empty. As discussed elsewhere herein, the inactive one of the cache only virtual devices ,  of the remote storage device  is used to accumulate data from the local storage device  sent using RDF while the active one of the cache only virtual devices ,  is restored to the standard logical device .","If it is determined at the test step  that the active one of the cache only virtual devices ,  is not empty, then control transfers from the test step  to a step  where the restore for the active one of the cache only virtual devices ,  is completed prior to further processing being performed. Restoring data from the active one of the cache only virtual devices ,  is described in more detail elsewhere herein. It is useful that the active one of the cache only virtual devices ,  is empty prior to handling the commit and beginning to restore data for the next sequence number.","Following the step  or following the step  if the active one of the cache only virtual devices ,  is determined to be empty, is a step  where the active one of the cache only virtual devices ,  is made inactive. Following the step  is a step  where the previously inactive one of the cache only virtual devices ,  (i.e., the one that was inactive prior to execution of the step ) is made active. Swapping the active and inactive cache only virtual devices ,  at the steps ,  prepares the now inactive (and empty) one of the cache only virtual devices ,  to begin to receive data from the local storage device  for the next sequence number.","Following the step  is a step  where the active one of the cache only virtual devices ,  is restored to the standard logical device  of the remote storage device . Restoring the active one of the cache only virtual devices ,  to the standard logical device  is described in more detail hereinafter. However, note that, in some embodiments, the restore process is begun, but not necessarily completed, at the step . Following the step  is a step  where the commit that was sent from the local storage device  to the remote storage device  is acknowledged back to the local storage device  so that the local storage device  is informed that the commit was successful. Following the step , processing is complete.","Referring to , a flow chart  illustrates in more detail the steps ,  of  where the remote storage device  restores the active one of the cache only virtual devices , . Processing begins at a first step  where a pointer is set to point to the first slot of the active one of the cache only virtual devices , . The pointer is used to iterate through each track table entry of the active one of the cache only virtual devices , , each of which is processed individually. Following the step  is a test step  where it is determined if the track of the active one of the cache only virtual devices ,  that is being processed points to the standard logical device . If so, then there is nothing to restore. Otherwise, control transfers from the step  to a step a  where the corresponding slot of the active one of the cache only virtual devices ,  is locked.","Following the step  is a test step  where it is determined if the corresponding slot of the standard logical device  is already in the cache of the remote storage device . If so, then control transfers from the test step  to a step  where the slot of the standard logical device is locked. Following step  is a step  where the data from the active one of the cache only virtual devices ,  is merged with the data in the cache for the standard logical device . Merging the data at the step  involves overwriting the data for the standard logical device with the new data of the active one of the cache only virtual devices , . Note that, in embodiments that provide for record level flags, it may be possible to simply OR the new records from the active one of the cache only virtual devices ,  to the records of the standard logical device  in the cache. That is, if the records are interleaved, then it is only necessary to use the records from the active one of the cache only virtual devices ,  that have changed and provide the records to the cache slot of the standard logical device . Following step  is a step  where the slot of the standard logical device  is unlocked. Following step  is a step  where the slot of the active one of the cache only virtual devices ,  that is being processed is also unlocked.","If it is determined at the test step  that the corresponding slot of the standard logical device  is not in cache, then control transfers from the test step  to a step  where the track entry for the slot of the standard logical device  is changed to indicate that the slot of the standard logical device  is in cache (e.g., an IN_CACHE flag may be set) and needs to be destaged. As discussed elsewhere herein, in some embodiments, only records of the track having appropriate mirror bits set may need to be destaged. Following the step  is a step  where a flag for the track may be set to indicate that the data for the track is in the cache.","Following the step  is a step  where the slot pointer for the standard logical device  is changed to point to the slot in the cache. Following the step  is a test step  which determines if the operations performed at the steps , ,  have been successful. In some instances, a single operation called a \u201ccompare and swap\u201d operation may be used to perform the steps , , . If these operations are not successful for any reason, then control transfers from the step  back to the step  to reexamine if the corresponding track of the standard logical device  is in the cache. Otherwise, if it is determined at the test step  that the previous operations have been successful, then control transfers from the test step  to the step , discussed above.","Following the step  is a test step  which determines if the cache slot of the active one of the cache only virtual devices ,  (which is being restored) is still being used. In some cases, it is possible that the slot for the active one of the cache only virtual devices ,  is still being used by another mirror. If it is determined at the test step  that the slot of the cache only virtual device is not being used by another mirror, then control transfers from the test step  to a step  where the slot is released for use by other processes (e.g., restored to pool of available slots, as discussed elsewhere herein). Following the step  is a step  to point to the next slot to process the next slot of the active one of the cache only virtual devices , . Note that the step  is also reached from the test step  if it is determined at the step  that the active one of the cache only virtual devices ,  is still being used by another mirror. Note also that the step  is reached from the test step  if it is determined at the step  that, for the slot being processed, the active one of the cache only virtual devices ,  points to the standard logical device . Following the step  is a test step  which determines if there are more slots of the active one of the cache only virtual devices ,  to be processed. If not, processing is complete. Otherwise, control transfers from the test step  back to the step .","In another embodiment, it is possible to construct lists of modified slots for the received chunk of data  corresponding to the N\u22121 cycle on the remote storage device , such as the lists ,  shown in . As the data is received, the remote storage device  constructs a linked list of modified slots. The lists that are constructed may be circular, linear (with a NULL termination), or any other appropriate design. The lists may then be used to restore the active one of the cache only virtual devices , .","The flow chart  of  shows two alternative paths ,  that illustrate operation of embodiments where a list of modified slots is used. At the step , a pointer (used for iterating through the list of modified slots) is made to point to the first element of the list. Following the step  is the step , which is reached by the alternative path . In embodiments that use lists of modified slots, the test step  is not needed since no slots on the list should point to the standard logical device .","Following the step , processing continues as discussed above with the previous embodiment, except that the step  refers to traversing the list of modified slots rather than pointing to the next slot in the COVD. Similarly, the test at the step  determines if the pointer is at the end of the list (or back to the beginning in the case of a circular linked list). Also, if it is determined at the step  that there are more slots to process, then control transfers from the step  to the step , as illustrated by the alternative path . As discussed above, for embodiments that use a list of modified slots, the step  may be eliminated.","Referring to , a flow chart  illustrates steps performed in connection with the local storage device  increasing the sequence number. Processing begins at a first step  where the local storage device  waits at least M seconds prior to increasing the sequence number. In an embodiment herein, M is thirty, but of course M could be any number. Larger values for M increase the amount of data that may be lost if communication between the storage devices ,  is disrupted. However, smaller values for M increase the total amount of overhead caused by incrementing the sequence number more frequently.","Following the step  is a test step  which determines if all of the HA's of the local storage device  have set a bit indicating that the HA's have completed all of the I\/O's for a previous sequence number. When the sequence number changes, each of the HA's notices the change and sets a bit indicating that all I\/O's of the previous sequence number are completed. For example, if the sequence number changes from N\u22121 to N, an HA will set the bit when the HA has completed all I\/O's for sequence number N\u22121. Note that, in some instances, a single I\/O for an HA may take a long time and may still be in progress even after the sequence number has changed. Note also that, for some systems, a different mechanism may be used to determine if all of the HA's have completed their N\u22121 I\/O's. The different mechanism may include examining device tables in the memory .","If it is determined at the test step  that I\/O's from the previous sequence number have been completed, then control transfers from the step  to a test step  which determines if the inactive one of the lists ,  is empty. Note that a sequence number switch may not be made unless and until all of the data corresponding to the inactive one of the lists ,  has been completely transmitted from the local storage device  to the remote storage device  using the RDF protocol. Once the inactive one of the lists ,  is determined to be empty, then control transfers from the step  to a step  where the commit for the previous sequence number is sent from the local storage device  to the remote storage device . As discussed above, the remote storage device  receiving a commit message for a particular sequence number will cause the remote storage device  to begin restoring the data corresponding to the sequence number.","Following the step  is a step  where the copying of data for the inactive one of the lists ,  is suspended. As discussed elsewhere herein, the inactive one of the lists is scanned to send corresponding data from the local storage device  to the remote storage device . It is useful to suspend copying data until the sequence number switch is completed. In an embodiment herein, the suspension is provided by sending a message to the RA's -. However, it will be appreciated by one of ordinary skill in the art that for embodiments that use other components to facilitate sending data using the system described herein, suspending copying may be provided by sending appropriate messages\/commands to the other components.","Following step  is a step  where the sequence number is incremented. Following step  is a step  where the bits for the HA's that are used in the test step  are all cleared so that the bits may be set again in connection with the increment of the sequence number. Following step  is a test step  which determines if the remote storage device  has acknowledged the commit message sent at the step . Acknowledging the commit message is discussed above in connection with .","Once it is determined that the remote storage device  has acknowledged the commit message sent at the step , control transfers from the step  to a step step to clear (discard, erase, etc.) the transfer log that indicates which of the tracks (and\/or portions thereof) of the previous inactive cycle have been transmitted to the R device. Following the step  is a step  where a new transfer log mechanism (i.e., a new slot) is initialized. Following step  is a step  where the suspension of copying, which was provided at the step , is cleared so that copying may resume. Following step , processing is complete. Note that it is also possible to go from the step  back to the step  to begin a new cycle to continuously increment the sequence number.","It is also possible to use COVD's on the R device to collect slots associated with active data and inactive chunks of data. In that case, just as with the R device, one COVD could be associated with the inactive sequence number and another COVD could be associated with the active sequence number. This is described below.","Referring to , a diagram  illustrates items used to construct and maintain the chunks , . A standard logical device  contains data written by the host  and corresponds to the data element  of  and the disks -of . The standard logical device  contains data written by the host  to the local storage device .","Two cache only virtual devices ,  are used in connection with the standard logical device . The cache only virtual devices ,  correspond to device tables that may be stored, for example, in the memory  of the local storage device . Each track entry of the tables of each of the cache only virtual devices ,  point to either a track of the standard logical device  or point to a slot of a cache  used in connection with the local storage device . In some embodiments, the cache  may be provided in the memory  of the local storage device .","The cache  contains a plurality of cache slots - that may be used in connection to writes to the standard logical device  and, at the same time, used in connection with the cache only virtual devices , . In an embodiment herein, each track table entry of the cache only virtual devices ,  may point to a corresponding track of the standard logical device  or may point to one of the slots - in the cache .","Each of the cache only virtual devices ,  may be used for one of the chunks of data ,  so that, for example, the cache only virtual device  may correspond to the chunk of data  for sequence number N while the cache only virtual device  may correspond to the chunk of data  for sequence number N\u22121. Thus, when data is written by the host  to the local storage device , the data is provided to the cache  and an appropriate pointer of the cache only virtual device  is adjusted. Note that the data will not be removed from the cache  until the data is destaged to the standard logical device  and the data is also released by the cache only virtual device , as described elsewhere herein.","In an embodiment herein, one of the cache only virtual devices ,  is deemed \u201cactive\u201d while the other is deemed \u201cinactive\u201d. Thus, for example, when the sequence number N is even, the cache only virtual device  may be active while the cache only virtual device  is inactive. The active one of the cache only virtual devices ,  handles writes from the host  while the inactive one of the cache only virtual devices ,  corresponds to the data that is being transmitted from the local storage device  to the remote storage device .","While the data that is written by the host  is accumulated using the active one of the cache only virtual devices ,  (for the sequence number N), the data corresponding to the inactive one of the cache only virtual devices ,  (for previous sequence number N\u22121) is transmitted from the local storage device  to the remote storage device . For this and related embodiments, the DA's -of the local storage device may handle scanning the inactive one of the cache only virtual devices ,  to send copy requests to one or more of the RA's -to transmit the data from the local storage device  to the remote storage device . Thus, the steps , , discussed above in connection with suspending and resuming copying, may include providing messages\/commands to the DA's -","Once the data has been transmitted to the remote storage device , the corresponding entry in the inactive one of the cache only virtual devices ,  may be set to null. In addition, the data may also be removed from the cache  (i.e., the slot returned to the pool of slots for later use) if the data in the slot is not otherwise needed for another purpose (e.g., to be destaged to the standard logical device ). A mechanism may be used to ensure that data is not removed from the cache  until all mirrors (including the cache only virtual devices , ) are no longer using the data. Such a mechanism is described, for example, in U.S. Pat. No. 5,537,568 titled \u201cSYSTEM FOR DYNAMICALLY CONTROLLING CACHE MANAGER MAINTAINING CACHE INDEX AND CONTROLLING SEQUENTIAL DATA ACCESS\u201d to Yanai, et al. and in U.S. Pat. No. 6,594,742 titled \u201cCACHE MANAGEMENT VIA STATISTICALLY ADJUSTED SLOT AGING\u201d to Josef Ezra, both of which are incorporated by reference herein.","Referring to , a flow chart  illustrates steps performed by the HA  in connection with a host  performing a write operation for embodiments where two COVD's are used by the R device to provide the system described herein. Processing begins at a first step  where a slot corresponding to the write is locked. In an embodiment herein, each of the slots - of the cache  corresponds to a track of data on the standard logical device . Locking the slot at the step  prevents additional processes from operating on the relevant slot during the processing performed by the HA  corresponding to the steps of the flow chart .","Following the step  is a step  where a value for N, the sequence number, is set. Just as with the embodiment that uses lists rather than COVD's on the R side, the value for the sequence number obtained at the step  is maintained during the entire write operation performed by the HA  while the slot is locked. As discussed elsewhere herein, the sequence number is assigned to each write to set the one of the chunks of data ,  to which the write belongs. Writes performed by the host  are assigned the current sequence number. It is useful that a single write operation maintain the same sequence number throughout.","Following the step  is a test step , which determines if the inactive one of the cache only virtual devices ,  already points to the slot that was locked at the step  (the slot being operated upon). This may occur if a write to the same slot was provided when the sequence number was one less than the current sequence number. The data corresponding to the write for the previous sequence number may not yet have been transmitted to the remote storage device .","If it is determined at the test step  that the inactive one of the cache only virtual devices ,  does not point to the slot, then control transfers from the test step  to another test step , where it is determined if the active one of the cache only virtual devices ,  points to the slot. It is possible for the active one of the cache only virtual devices ,  to point to the slot if there had been a previous write to the slot while the sequence number was the same as the current sequence number. If it is determined at the test step  that the active one of the cache only virtual devices ,  does not point to the slot, then control transfers from the test step  to a step  where a new slot is obtained for the data. Following the step  is a step  where the active one of the cache only virtual devices ,  is made to point to the slot.","Following the step , or following the step  if the active one of the cache only virtual devices ,  points to the slot, is a step  where flags are set. At the step , the RDF_WP flag (RDF write pending flag) is set to indicate that the slot needs to be transmitted to the remote storage device  using RDF. In addition, at the step , the IN_CACHE flag is set to indicate that the slot needs to be destaged to the standard logical device . Note that, in some instances, if the active one of the cache only virtual devices ,  already points to the slot (as determined at the step ) it is possible that the RDF_WP and IN_CACHE flags were already set prior to execution of the step . However, setting the flags at the step  ensures that the flags are set properly no matter what the previous state.","Following the step  is a step  where an indirect flag in the track table that points to the slot is cleared, indicating that the relevant data is provided in the slot and not in a different slot indirectly pointed to. Following the step  is a step  where the data being written by the host  and the HA  is written to the slot. Following the step  is a step  where the slot is unlocked. Following step , processing is complete.","If it is determined at the test step  that the inactive one of the cache only virtual devices ,  points to the slot, then control transfers from the step  to a step , where a new slot is obtained. The new slot obtained at the step  may be used for the inactive one of the cache only virtual devices ,  to effect the RDF transfer while the old slot may be associated with the active one of the cache only virtual devices , , as described below.","Following the step  is a step  where the data from the old slot is copied to the new slot that was obtained at the step . Following the step  is a step  where the indirect flag (discussed above) is set to indicate that the track table entry for the inactive one of the cache only virtual devices ,  points to the old slot but that the data is in the new slot which is pointed to by the old slot. Thus, setting indirect flag at the step  affects the track table of the inactive one of the cache only virtual devices ,  to cause the track table entry to indicate that the data is in the new slot.","Following the step  is a step  where the mirror bits for the records in the new slot are adjusted. Any local mirror bits that were copied when the data was copied from the old slot to the new slot at the step  are cleared since the purpose of the new slot is to simply effect the RDF transfer for the inactive one of the cache only virtual devices. The old slot will be used to handle any local mirrors. Following the step  is the step  where the data is written to the slot. Following step  is the step  where the slot is unlocked. Following the step , processing is complete.","Referring to , a flow chart  illustrates steps performed in connection with the local storage device  transmitting the chunk of data  to the remote storage device . The transmission essentially involves scanning the inactive one of the cache only virtual devices ,  for tracks that have been written thereto during a previous iteration when the inactive one of the cache only virtual devices ,  was active. In this embodiment, the DA's -of the local storage device  may scan the inactive one of the cache only virtual devices ,  to copy the data for transmission to the remote storage device  by one or more of the RA's -using the RDF protocol.","Processing begins at a first step  where the first track of the inactive one of the cache only virtual devices ,  is pointed to in order to begin the process of iterating through all of the tracks. Following the first step  is a test step  where it is determined if the RDF_WP flag is set. As discussed elsewhere herein, the RDF_WP flag is used to indicate that a slot (track) contains data that needs to be transmitted via the RDF link. The RDF_WP flag being set indicates that at least some data for the slot (track) is to be transmitted using RDF. In an embodiment herein, the entire slot is not transmitted. Rather, only records within the slot that have the appropriate mirror bits set (indicating the records have changed) are transmitted to the remote storage device . However, in other embodiments, it may be possible to transmit the entire slot, provided that the remote storage device  only writes data corresponding to records having appropriate mirror bits set and ignores other data for the track, which may or may not be valid.","If it is determined at the test step  that the cache slot being processed has the RDF_WP flag set, then control transfers from the step  to a test step , where it is determined if the slot contains the data or if the slot is an indirect slot that points to another slot that contains the relevant data. In some instances, a slot may not contain the data for the portion of the disk that corresponds to the slot. Instead, the slot may be an indirect slot that points to another slot that contains the data. If it is determined at the step  that the slot is an indirect slot, then control transfers from the step  to a step , where the data (from the slot pointed to by the indirect slot) is obtained. Thus, if the slot is a direct slot, the data for being sent by RDF is stored in the slot while if the slot is an indirect slot, the data for being sent by RDF is in another slot pointed to by the indirect slot.","Following the step  or the step  if the slot is a direct slot is a step  where data being sent (directly or indirectly from the slot) is copied by one of the DA's -to be sent from the local storage device  to the remote storage device  using the RDF protocol. Following the step  is a test step  where it is determined if the remote storage device  has acknowledged receipt of the data. If not, then control transfers from the step  back to the step  to resend the data. In other embodiments, different and more involved processing may be used to send data and acknowledge receipt thereof. Such processing may include error reporting and alternative processing that is performed after a certain number of attempts to send the data have failed.","Once it is determined at the test step  that the data has been successfully sent, control passes from the step  to a step  where the system logs an indicator of the slot\/track (and\/or portion thereof) that was sent at the step . Processing performed at the step  is like processing performed at the step  of , discussed above. Following the step  is a step  where the RDF_WP flag is cleared (since the data has been successfully sent via RDF). Following the step  is a step  where appropriate mirror flags are cleared to indicate that at least the RDF mirror (R) no longer needs the data. In an embodiment herein, each record that is part of a slot (track) has individual mirror flags indicating which mirrors use the particular record. The R device is one of the mirrors for each of the records and it is the flags corresponding to the R device that are cleared at the step .","Following the step  is a test step  which determines if any of the records of the track being processed have any other mirror flags set (for other mirror devices). If not, then control passes from the step  to a step  where the slot is released (i.e., no longer being used). In some embodiments, unused slots are maintained in a pool of slots available for use. Note that if additional flags are still set for some of the records of the slot, it may mean that the records need to be destaged to the standard logical device  or are being used by some other mirror (including another R device). Following the step , or following the step  if more mirror flags are present, is a step  where the pointer that is used to iterate through each track entry of the inactive one of the cache only virtual devices ,  is made to point to the next track. Following the step  is a test step  which determines if there are more tracks of the inactive one of the cache only virtual devices ,  to be processed. If not, then processing is complete. Otherwise, control transfers back to the test step , discussed above. Note that the step  is also reached from the test step  if it is determined that the RDF_WP flag is not set for the track being processed.","In another embodiment of the system described herein, it is possible to not use COVD's for the R device like those shown in the diagram  of . That is, it is possible to implement the R receipt of asynchronous data without using COVD's at the R device.","Referring to , a diagram  shows a cache  that is provided in the remote storage device  that receives data. The cache  includes a plurality of slots - in which asynchronous data that is received from the local storage device  is placed. Also shown is a first circularly linked list  and a second circularly linked list  which contain pointers to the slots - of the cache . Thus, for example, the circularly linked list  includes a plurality of pointers -, each of which points to one of the slots - in the cache . Similarly, the circularly linked list  includes a plurality of pointers -, each of which points to one of the slots - of the cache . A standard logical device  is also mapped to portions of the cache .","In an embodiment herein, one of the lists ,  corresponds to an inactive data chunk (e.g., like the chunk  shown in ), while the other one of the lists ,  corresponds to an active data chunk (e.g., like the chunk  of ). Received data is accumulated using an inactive one of the data chunks while the active one of the data chunks is used for storing data at the standard logical device  as described elsewhere herein in connection with the diagram  of  and the corresponding text. Thus, as new data arrives, it is placed in the cache  and a new pointer is added to which one of the circularly linked lists ,  corresponds to the inactive data chunk when the data is received.","In some instances, it may be useful to be able to determine whether a portion of the standard logical device  (or any other logical device) has a slot associated therewith in the cache  corresponding to received data. Of course, it is always possible to traverse both of the lists ,  to determine if there is a corresponding slot in the cache . However, it would be more useful if there were a way of using particular device, cylinder, and head values of a logical device to determine whether there is a corresponding one of the slots - in the cache  waiting to be destaged to the device.","Referring to , a diagram  shows a hash table  which contain a plurality of entries -. In an embodiment herein, each of the entries - either contains a null pointer or points to one of the cache slots - that correspond to data that has been received but not yet stored on the standard logical device  (or another standard logical device). The table  is indexed using a hash function that performs a mathematical operation using the particular values of the device, cylinder, and head to generate an index into the table  to find the corresponding entry. Thus, when data is received by the R device, the hash function is applied to the device, cylinder, and head to find its index value into the table  and then a pointer is written to the corresponding one of the entries - that points to the particular slot - in the cache . Once the received data is appropriately destaged to the standard logical device  (or another device), the corresponding one of the entries - is set to null. In this way, the hash table  allows quickly determining whether a particular portion of a standard logical device corresponds to received data that has not yet been destaged. For the system described herein, any appropriate hash function may be used to generate the index into the table .","In some instances, it may possible for a particular device, cylinder, and head values to generate an index into the table  that is the same as an index generated by different values for the device, cylinder, and head. This is called a \u201ccollision\u201d. In instances where collisions occur, a second entry into the table  corresponding to the same index as provided and the second entry is linked to the first entry so that a particular index would correspond to more than one entry. This is illustrated by an element  that is linked to the element  of the table . Thus, a first device, cylinder, and head are hashed to generate an index to the entry  while different device, cylinder, and head are input to the hash function to generate the same value for the index. In an embodiment herein, the entry  is used to point to the data in the cache  corresponding to the first device, cylinder, and head while the entry  is used to point to data in the cache  corresponding to the second device, cylinder and head. Of course, as data is destaged to an appropriate device, the corresponding one of the entries ,  may be eliminated from the table .","Note that any number of entries may correspond to a single index so that, for example, if collisions occur that cause three separate sets of values for device, cylinder, and head to generate the same index, then there would be three (or more) entries linked together at a particular index into the table . Note also that other appropriate techniques may be used to handle collisions, including providing additional tables (e.g., a second table, a third table, a fourth table, etc.).","Referring to , a diagram  shows an alternative embodiment of a hash table  which contain a plurality of entries -. The embodiment of  is like the embodiment of , with a few differences, as described herein. Each of the entries - either contains a null pointer or points to one of the cache slots , , , shown in the diagram , that correspond to data that has been received but not yet stored on the standard logical device  (or another standard logical device). The table  is indexed using a hash function that performs a mathematical operation using the particular values of the device, cylinder, and head to generate an index into the table  to find the corresponding entry. Thus, when data is received by the R device, the hash function is applied to the device, cylinder, and head to find its index value into the table  and then a pointer is written to the corresponding one of the entries - that points to the particular slot , , . Once the received data is appropriately destaged to the standard logical device  (or another device), the corresponding one of the entries - is adjusted appropriately. In this way, the hash table  allows quickly determining whether a particular portion of a standard logical device corresponds to received data that has not yet been destaged. For the system described herein, any appropriate hash function may be used to generate the index into the table .","For the embodiment shown in , in instances where collisions occur, the first slot pointed to by a table entry points to the second slot that caused the collision. Thus, for example, if the slot  and a slot  cause a collision at the table entry , the table entry  points to the slot  while the slot  points to the slot . Thus, a collision does not cause any change in the table  when the subsequent slot is added, since adding the subsequent slot simply involves changing the pointer value for a previous slot. Of course, any number of slots may correspond to a single table entry.","Note that any number of entries may correspond to a single index so that, for example, if collisions occur that cause three separate sets of values for device, cylinder, and head to generate the same index, then there would be three (or more) entries linked together at a particular index into the table . Note also that other appropriate techniques may be used to handle collisions, including providing additional tables (e.g., a second table, a third table, a fourth table, etc.).","Referring to , a diagram  illustrates a host  coupled to a plurality of local storage devices -. The diagram  also shows a plurality of remote storage devices -. Although only three local storage devices - and three remote storage devices - are shown in the diagram , the system described herein may be expanded to use any number of local and remote storage devices.","Each of the local storage devices - is coupled to a corresponding one of the remote storage devices - so that, for example, the local storage device  is coupled to the remote storage device , the local storage device  is coupled to the remote storage device  and the local storage device  is coupled to the remote storage device . The local storage device is - and remote storage device is - may be coupled using the ordered writes mechanism described herein so that, for example, the local storage device  may be coupled to the remote storage device  using the ordered writes mechanism. As discussed elsewhere herein, the ordered writes mechanism allows data recovery using the remote storage device in instances where the local storage device and\/or host stops working and\/or loses data.","In some instances, the host  may run a single application that simultaneously uses more than one of the local storage devices -. In such a case, the application may be configured to ensure that application data is consistent (recoverable) at the local storage devices - if the host  were to cease working at any time and\/or if one of the local storage devices - were to fail. However, since each of the ordered write connections between the local storage devices - and the remote storage devices - is asynchronous from the other connections, then there is no assurance that data for the application will be consistent (and thus recoverable) at the remote storage devices -. That is, for example, even though the data connection between the local storage device  and the remote storage device  (a first local\/remote pair) is consistent and the data connection between the local storage device  and the remote storage device  (a second local\/remote pair) is consistent, it is not necessarily the case that the data on the remote storage devices ,  is always consistent if there is no synchronization between the first and second local\/remote pairs.","For applications on the host  that simultaneously use a plurality of local storage devices -, it is desirable to have the data be consistent and recoverable at the remote storage devices -. This may be provided by a mechanism whereby the host  controls cycle switching at each of the local storage devices - so that the data from the application running on the host  is consistent and recoverable at the remote storage devices -. This functionality is provided by a special application that runs on the host  that switches a plurality of the local storage devices - into multi-box mode, as described in more detail below.","Referring to , a table  has a plurality of entries -. Each of the entries - correspond to a single local\/remote pair of storage devices so that, for example, the entry  may correspond to pair of the local storage device  and the remote storage device , the entry  may correspond to pair of the local storage device  and the remote storage device  and the entry  may correspond to the pair of local storage device  and the remote storage device . Each of the entries - has a plurality of fields where a first field -represents a serial number of the corresponding local storage device, a second field -represents a session number used by the multi-box group, a third field -represents the serial number of the corresponding remote storage device of the local\/remote pair, and a fourth field -represents the session number for the multi-box group. The table  is constructed and maintained by the host  in connection with operating in multi-box mode. In addition, the table  is propagated to each of the local storage devices and the remote storage devices that are part of the multi-box group. The table  may be used to facilitate recovery, as discussed in more detail below.","Different local\/remote pairs may enter and exit multi-box mode independently in any sequence and at any time. The host  manages entry and exit of local storage device\/remote storage device pairs into and out of multi-box mode. This is described in more detail below.","Referring to , a flowchart  illustrates steps performed by the host  in connection with entry or exit of a local\/remote pair in to or out of multi-box mode. Processing begins at a first step  where multi-box mode operation is temporarily suspended. Temporarily suspending multi-box operation at the step  is useful to facilitate the changes that are made in connection with entry or exit of a remote\/local pair in to or out of multi-box mode. Following the step , is a step  where a table like the table  of  is modified to either add or delete an entry, as appropriate. Following the step  is a step  where the modified table is propagated to the local storage devices and remote storage devices of the multi-box group. Propagating the table at the step  facilitates recovery, as discussed in more detail elsewhere herein.","Following the step  is a step  where a message is sent to the affected local storage device to provide the change. The local storage device may configure itself to run in multi-box mode or not, as described in more detail elsewhere herein. As discussed in more detail below, a local storage device handling ordered writes operates differently depending upon whether it is operating as part of a multi-box group or not. If the local storage device is being added to a multi-box group, the message sent at the step  indicates to the local storage device that it is being added to a multi-box group so that the local storage device should configure itself to run in multi-box mode. Alternatively, if a local storage device is being removed from a multi-box group, the message sent at the step  indicates to the local storage device that it is being removed from the multi-box group so that the local storage device should configure itself to not run in multi-box mode.","Following step  is a test step  where it is determined if a local\/remote pair is being added to the multi-box group (as opposed to being removed). If so, then control transfers from the test step  to a step  where tag values are sent to the local storage device that is being added. The tag values are provided with the data transmitted from the local storage device to the remote storage device in a manner similar to providing the sequence numbers with the data. The tag values are controlled by the host and set so that all of the local\/remote pairs send data having the same tag value during the same cycle. Use of the tag values is discussed in more detail below. Following the step , or following the step  if a new local\/remote pair is not being added, is a step  where multi-box operation is resumed. Following the step , processing is complete.","Referring to , a flow chart  illustrates steps performed in connection with the host managing cycle switching for multiple local\/remote pairs running as a group in multi-box mode. As discussed elsewhere herein, multi-box mode involves having the host synchronize cycle switches for more than one remote\/local pair to maintain data consistency among the remote storage devices. Cycle switching is coordinated by the host rather than being generated internally by the local storage devices. This is discussed in more detail below.","Processing for the flow chart  begins at a test step  which determines if M seconds have passed. Just as with non-multi-box operation, cycle switches occur no sooner than every M seconds where M is a number chosen to optimize various performance parameters. As the number M is increased, the amount of overhead associated with switching decreases. However, increasing M also causes the amount of data that may be potentially lost in connection with a failure to also increase. In an embodiment herein, M is chosen to be thirty seconds, although, obviously other values for M may be used.","If it is determined at the test step  that M seconds have not passed, then control transfers back to the step  to continue waiting until M seconds have passed. Once it is determined at the test step  that M seconds have passed, control transfers from the step  to a step  where the host queries all of the local storage devices in the multi-box group to determine if all of the local\/remote pairs are ready to switch. The local\/remote pairs being ready to switch is discussed in more detail hereinafter.","Following the step  is a test step  which determines if all of the local\/remote pairs are ready to switch. If not, control transfers back to the step  to resume the query. In an embodiment herein, it is only necessary to query local\/remote pairs that were previously not ready to switch since, once a local\/remote pair is ready to switch, the pair remains so until the switch occurs.","Once it is determined at the test step  that all of the local\/remote pairs in the multi-box group are ready to switch, control transfers from the step  to a step  where an index variable, N, is set equal to one. The index variable N is used to iterate through all the local\/remote pairs (i.e., all of the entries - of the table  of ). Following the step  is a test step  which determines if the index variable, N, is greater than the number of local\/remote pairs in the multi-box group. If not, then control transfers from the step  to a step  where an open window is performed for the Nth local storage device of the Nth pair by the host sending a command (e.g., an appropriate system command) to the Nth local storage device. Opening the window for the Nth local storage device at the step  causes the Nth local storage device to suspend writes so that any write by a host that is not begun prior to opening the window at the step  will not be completed until the window is closed (described below). Not completing a write operation prevents a second dependant write from occurring prior to completion of the cycle switch. Any writes in progress that were begun before opening the window may complete prior to the window being closed.","Following the step  is a step  where a cycle switch is performed for the Nth local storage device. Performing the cycle switch at the step  involves sending a command from the host  to the Nth local storage device. Processing the command from the host by the Nth local storage device is discussed in more detail below. Part of the processing performed at the step  may include having the host provide new values for the tags that are assigned to the data. The tags are discussed in more detail elsewhere herein. In an alternative embodiment, the operations performed at the steps ,  may be performed as a single integrated step , which is illustrated by the box drawn around the steps , .","Following the step  is a step  where the index variable, N, is incremented. Following step , control transfers back to the test step  to determine if the index variable, N, is greater than the number of local\/remote pairs.","If it is determined at the test step  that the index variable, N, is greater than the number of local\/remote pairs, then control transfers from the test step  to a step  where the index variable, N, is set equal to one. Following the step  is a test step  which determines if the index variable, N, is greater than the number of local\/remote pairs. If not, then control transfers from the step  to a step  where the window for the Nth local storage device is closed. Closing the window of the step  is performed by the host sending a command to the Nth local storage device to cause the Nth local storage device to resume write operations. Thus, any writes in process that were suspended by opening the window at the step  may now be completed after execution of the step . Following the step , control transfers to a step  where the index variable, N, is incremented. Following the step , control transfers back to the test step  to determine if the index variable, N, is greater than the number of local\/remote pairs. If so, then control transfers from the test step  back to the step  to begin processing for the next cycle switch.","Referring to , a flow chart  illustrates steps performed by a local storage device in connection with cycle switching. The flow chart  of  replaces the flow chart  of  in instances where the local storage device supports both multi-box mode and non-multi-box mode. That is, the flow chart  shows steps performed like those of the flow chart  of  to support non-multi-box mode and, in addition, includes steps for supporting multi-box mode.","Processing begins at a first test step  which determines if the local storage device is operating in multi-box mode. Note that the flow chart  of  shows the step  where the host sends a message to the local storage device. The message sent at the step  indicates to the local storage device whether the local storage device is in multi-box mode or not. Upon receipt of the message sent by the host at the step , the local storage device sets an internal variable to indicate whether the local storage device is operating in multi-box mode or not. The internal variable may be examined at the test step .","If it is determined at the test step  that the local storage device is not in multi-box mode, then control transfers from the test step  to a step  to wait M seconds for the cycle switch. If the local storage device is not operating in multi-box mode, then the local storage device controls its own cycle switching and thus executes the step  to wait M seconds before initiating the next cycle switch.","Following the step , or following the step  if the local storage device is in multi-box mode, is a test step  which determines if all of the HA's of the local storage device have set a bit indicating that the HA's have completed all of the I\/O's for a previous sequence number. When the sequence number changes, each of the HA's notices the change and sets a bit indicating that all I\/O's of the previous sequence number are completed. For example, if the sequence number changes from N\u22121 to N, an HA will set the bit when the HA has completed all I\/O's for sequence number N\u22121. Note that, in some instances, a single I\/O for an HA may take a long time and may still be in progress even after the sequence number has changed. Note also that, for some systems, a different mechanism may be used to determine if all HA's have completed their N\u22121 I\/O's. The different mechanism may include examining device tables.","Once it is determined at the test step  that all HA's have set the appropriate bit, control transfers from the test step  to a step  which determines if the inactive chunk for the local storage device is empty. Once it is determined at the test step  that the inactive chunk is empty, control transfers from the step  to a step , where copying of data from the local storage device to the remote storage device is suspended. It is useful to suspend copying data until the sequence number switch is complete.","Following the step  is a test step  to determine if the local storage device is in multi-box mode. If it is determined at the test step  that the local storage device is in multi-box mode, then control transfers from the test step  to a test step  to determine if the active chunk of the corresponding remote storage device is empty. As discussed in more detail below, the remote storage device sends a message to the local storage device once it has emptied its active chunk. In response to the message, the local storage device sets an internal variable that is examined at the test step .","Once it is determined at the test step  that the active chunk of the remote storage device is empty, control transfers from the test step  to a step  where an internal variable is set on a local storage device indicating that the local storage device is ready to switch cycles. As discussed above in connection with the flow chart  of , the host queries each of the local storage devices to determine if each of the local storage devices is ready to switch. In response to the query provided by the host, the local storage device examines the internal variable set at the step  and returns the result to the host.","Following step  is a test step  where the local storage device waits to receive the command from the host to perform the cycle switch. As discussed above in connection with the flow chart  of , the host provides a command to switch cycles to the local storage device when the local storage device is operating in multi-box mode. Thus, the local storage device waits for the command at the step , which is only reached when the local storage device is operating in multi-box mode.","Once the local storage device has received the switch command from the host, control transfers from the step  to a step  to send a commit message to the remote storage device. Note that the step  is also reached from the test step  if it is determined at the step test  that the local storage device is not in multi-box mode. At the step , the local storage device sends a commit message to the remote storage device. In response to receiving a commit message for a particular sequence number, the remote storage device will begin restoring the data corresponding to the sequence number, as discussed above.","Following the step  is a step  where the sequence number is incremented and a new value for the tag (from the host) is stored. The sequence number is as discussed above. The tag is the tag provided to the local storage device at the step  and at the step , as discussed above. The tag is used to facilitate data recovery, as discussed elsewhere herein.","Following the step  is a step  where completion of the cycle switch is confirmed from the local storage device to the host by sending a message from the local storage device to the host. In some embodiments, it is possible to condition performing the step  on whether the local storage device is in multi-box mode or not, since, if the local storage device is not in multi-box mode, the host is not necessarily interested in when cycle switches occur.","Following the step  is a step  where the bits for the HA's that are used in the test step  are all cleared so that the bits may be set again in connection with the increment of the sequence number. Following the step  is a test step  which determines if the remote storage device has acknowledged the commit message. Note that if the local\/remote pair is operating in multi-box mode and the remote storage device-active chunk was determined to be empty at the step , then the remote storage device should acknowledge the commit message nearly immediately since the remote storage device will be ready for the cycle switch immediately because the active chunk thereof is already empty.","Once it is determined at the test step  that the commit message has been acknowledged by the remote storage device, control transfers from the step  to a step  to clear (discard, erase, etc.) the transfer log that indicates which of the tracks (and\/or portions thereof) of the previous inactive cycle have been transmitted to the remote device. Following the step  is a step  where a new transfer log mechanism (i.e., a new slot) is initialized. Following step  is a step  where the suspension of copying, which was provided at the step , is cleared so that copying may resume. Following step , processing is complete. Note that it is also possible to go from the step  back to the step  to begin a new cycle to continuously increment the sequence number.","Referring to , a flow chart  illustrates steps performed in connection with RA's scanning the inactive buffers to transmit RDF data from the local storage device to the remote storage device. The flow chart  of  is similar to the flow chart  of  and similar steps are given the same reference number. However, the flow chart  includes two additional steps ,  which are not found in the flow chart  of . The additional steps ,  are used to facilitate multi-box processing. After data has been sent at the step , control transfers from the step  to a test step  which determines if the data being sent is the last data in the inactive chunk of the local storage device. If not, then control transfers from the step  to the step  and processing continues as discussed above in connection with the flow chart  of . Otherwise, if it is determined at the test step  that the data being sent is the last data of the chunk, then control transfers from the step  to the step  to send a special message from the local storage device to the remote storage device indicating that the last data has been sent. Following the step , control transfers to the step  and processing continues as discussed above in connection with the flow chart  of . In some embodiments, the steps ,  may be performed by a separate process (and\/or separate hardware device) that is different from the process and\/or hardware device that transfers the data.","Referring to , a flow chart  illustrates steps performed in connection with RA's scanning the inactive buffers to transmit RDF data from the local storage device to the remote storage device. The flow chart  of  is similar to the flow chart  of  and similar steps are given the same reference number. However, the flow chart  includes an additional step , which is not found in the flow chart  of . The additional steps  is used to facilitate multi-box processing and is like the additional step  of the flowchart  of . After it is determined at the test step  that no more slots remain to be sent from the local storage device to the remote storage device, control transfers from the step  to the step  to send a special message from the local storage device to the remote storage device indicating that the last data for the chunk has been sent. Following the step , processing is complete.","Referring to , a flow chart  illustrates steps performed at the remote storage device in connection with providing an indication that the active chunk of the remote storage device is empty. The flow chart  is like the flow chart  of  except that the flow chart  shows a new step  that is performed after the active chunk of the remote storage device has been restored. At the step , the remote storage device sends a message to the local storage device indicating that the active chunk of the remote storage device is empty. Upon receipt of the message sent at the step , the local storage device sets an internal variable indicating that the inactive buffer of the remote storage device is empty. The local variable is examined in connection with the test step  of the flow chart  of , discussed above.","Referring to , a diagram  illustrates the host , local storage devices - and remote storage devices -, that are shown in the diagram  of . The diagram  also includes a first alternative host  that is coupled to the host  and the local storage devices -. The diagram  also includes a second alternative host  that is coupled to the remote storage devices -. The alternative hosts ,  may be used for data recovery, as described in more detail below.","When recovery of data at the remote site is necessary, the recovery may be performed by the host  or, by the host  provided that the links between the local storage devices - and the remote storage devices - are still operational. If the links are not operational, then data recovery may be performed by the second alternative host  that is coupled to the remote storage devices -. The second alternative host  may be provided in the same location as one or more of the remote storage devices -. Alternatively, the second alternative host  may be remote from all of the remote storage devices -. The table  that is propagated throughout the system is accessed in connection with data recovery to determine the members of the multi-box group.","Referring to , a flow chart  illustrates steps performed by each of the remote storage devices - in connection with the data recovery operation. The steps of the flowchart  may be executed by each of the remote storage devices - upon receipt of a signal or a message indicating that data recovery is necessary. In some embodiments, it may be possible for a remote storage device to automatically sense that data recovery is necessary using, for example, conventional criteria such as length of time since last write.","Processing begins at a first step  where the remote storage device finishes restoring the active chunk in a manner discussed elsewhere herein. Following the step  is a test step  which determines if the inactive chunk of the remote storage device is complete (i.e., all of the data has been written thereto). Note that a remote storage device may determine if the inactive chunk is complete using the message sent by the local storage device at the steps , , discussed above. That is, if the local storage device has sent the message at the step  or the step , then the remote storage device may use receipt of that message to confirm that the inactive chunk is complete.","If it is determined at the test step  that the inactive chunk of the remote storage device is not complete, then control transfers from the test step  to a step  where the data from the inactive chunk is discarded. No data recovery is performed using incomplete inactive chunks since the data therein may be inconsistent with the corresponding active chunks. Accordingly, data recovery is performed using active chunks and, in some cases, inactive chunks that are complete. Following the step , processing is complete.","If it is determined at the test step  that the inactive chunk is complete, then control transfers from the step  to the step  where the remote storage device waits for intervention by the host. If an inactive chunk, one of the hosts , , , as appropriate, needs to examine the state of all of the remote storage devices in the multi-box group to determine how to perform the recovery. This is discussed in more detail below.","Following step  is a test step  where it is determined if the host has provided a command to all storage device to discard the inactive chunk. If so, then control transfers from the step  to the step  to discard the inactive chunk. Following the step , processing is complete.","If it is determined at the test step  that the host has provided a command to restore the complete inactive chunk, then control transfers from the step  to a step  where the inactive chunk is restored to the remote storage device. Restoring the inactive chunk in the remote storage device involves making the inactive chunk an active chunk and then writing the active chunk to the disk as described elsewhere herein. Following the step , processing is complete.","Referring to , a flow chart  illustrates steps performed in connection with one of the hosts , ,  determining whether to discard or restore each of the inactive chunks of each of the remote storage devices. The one of the hosts , ,  that is performing the restoration communicates with the remote storage devices - to provide commands thereto and to receive information therefrom using the tags that are assigned by the host as discussed elsewhere herein.","Processing begins at a first step  where it is determined if any of the remote storage devices have a complete inactive chunk. If not, then there is no further processing to be performed and, as discussed above, the remote storage devices will discard the incomplete chunks on their own without host intervention. Otherwise, control transfers from the test step  to a test step  where the host determines if all of the remote storage devices have complete inactive chunks. If so, then control transfers from the test step  to a test step  where it is determined if all of the complete inactive chunks of all of the remote storage devices have the same tag number. As discussed elsewhere herein, tags are assigned by the host and used by the system to identify data in a manner similar to the sequence number except that tags are controlled by the host to have the same value for the same cycle.","If it is determined at the test step  that all of the remote storage devices have the same tag for the inactive chunks, then control transfers from the step  to a step  where all of the inactive chunks are restored. Performing the step  ensures that all of the remote storage devices have data from the same cycle. Following the step , processing is complete.","If it is determined at the test step  that all of the inactive chunks are not complete, or if it is determined that at the step  that all of the complete inactive chunks do not have the same tag, then control transfers to a step  where the host provides a command to the remote storage devices to restore the complete inactive chunks having the lower tag number. For purposes of explanation, it is assumed that the tag numbers are incremented so that a lower tag number represents older data. By way of example, if a first remote storage device had a complete inactive chunk with a tag value of three and a second remote storage device had a complete inactive chunk with a tag value of four, the step  would cause the first remote storage device (but not the second) to restore its inactive chunk. Following the step  is a step  where the host provides commands to the remote storage devices to discard the complete inactive buffers having a higher tag number (e.g., the second remote storage device in the previous example). Following step , processing is complete.","Following execution of the step , each of the remote storage devices contains data associated with the same tag value as data for the other ones of the remote storage devices. Accordingly, the recovered data on the remote storage devices - should be consistent.","When data is being recovered following a link failure between the local storage device and the remote storage device, it is desirable to minimize the amount of overhead needed to resynchronize the storage devices. Of course, for intermittent and relatively short term link failures, the system may simply wait for the link to be restored and then resume operations. However, once the failure has caused the partial inactive cycle data to be discarded (as described above), then it is possible to use the transfer log data stored at the local storage device to provide efficient data recovery.","Referring to , a track change table  is part of device information that is provided with logical devices, such as the standard logical device  associated with the local storage device . The table  contains a plurality of entries -, each of which may correspond to a track (or some other increment) of the standard logical device. There are a plurality of fields -, -, -associated with the entries - that relate to the state of mirrors for the standard logical device to indicate whether the corresponding track has valid (up-to-date) data for the particular mirror represented by the field. At least one of the fields for each entry may correspond to the standard logical device itself. Thus, for example, the entry  may correspond to a particular logical track of the standard logical device and the field may indicate whether the particular track of the standard logical device contains valid data while the field may indicate whether a corresponding track of a local mirror standard logical device contains valid data and the field may indicate whether a corresponding track of a remote storage device (RDF R device) contains valid data.","Note that when data for a particular track of a standard logical device is modified locally, the corresponding track for any mirrors (local or remote) for the particular track become invalid and remain so unless and until the change is propagated to the mirrors. Thus, for example, when the host  of  writes data for a particular track to the standard logical device , an appropriate field of the track change table for the standard logical device  may indicate that a corresponding track for the standard logical device  is invalid. However, after the data has been successfully transmitted to the remote storage device , the field may be changed to indicate that the corresponding track of the standard logical device  is valid. Thus, for example, as data in the inactive cycle  is transmitted from the local storage device  to the remote storage device , the corresponding fields in the track change table are marked valid. Note that, once all fields for a track are valid, the corresponding slot in the cache table may be reused.","As discussed above, when failure is detected, the remote storage device may perform recovery operations that include discarding data received for any incomplete inactive cycle. In such a case, the remote storage device may indicate in its track change table that the corresponding tracks from the discarded cycle are locally invalid. Of course, this information may be combined with information from the track change table at the local storage device to reconstruct the discarded cycle. However, it may be desirable to avoid having to do this.","Referring to , a flow chart  illustrates steps performed at a local storage device using the transfer log data to modify the track change table in connection with a recovery. Processing begins at a first step  where an index variable, N, is set to one. Following the step  is a test step  where it is determined if the index variable, N, exceeds total the number of tracks for the standard logical device. If not, then control transfers from the step  to a test step  where it is determined if the transfer log data indicates that track N is invalid (transferred in an incomplete inactive cycle prior to the failure). If so, then control transfers from the step  to a step  where a corresponding field in the entry for track N is set to invalid to indicate that the data for track N at the remote storage location is not up-to-date.","Following the step  is a step  where the index variable, N, is incremented. Note that the step  is also reached from the step  if it is determined at the step  that the transfer log data does not indicate that track N is invalid. Following the step , control transfers back to the step  for another iteration. If it is determined at the step  that the value for the index variable, N, exceeds the number of tracks, then control transfers from the step  to a step  to clear (discard, erase, etc.) the transfer log, which is no longer needed. Following the step , processing is complete.","The system described herein may be implemented using the hardware described herein, variations thereof, or any other appropriate hardware capable of providing the functionality described herein. Thus, for example, one or more storage devices having components as described herein may, alone or in combination with other devices, provide an appropriate platform that executes any of the steps described herein. The system also includes computer software, in a computer readable medium, that executes any of the steps described herein.","While the invention has been disclosed in connection with various embodiments, modifications thereon will be readily apparent to those skilled in the art. Accordingly, the spirit and scope of the invention is set forth in the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF DRAWINGS","p":[{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 30"}]},"DETDESC":[{},{}]}
