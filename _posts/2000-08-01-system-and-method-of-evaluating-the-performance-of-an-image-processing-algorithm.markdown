---
title: System and method of evaluating the performance of an image processing algorithm
abstract: A system and method for creating an image processing algorithm and automatically evaluating the performance of the algorithm. A user may develop an image processing algorithm in an image prototyping environment. The image prototyping environment may provide image processing functions for analyzing, processing, or manipulating various types of images. Once the user has developed an image processing algorithm, the user may execute the algorithm. In response to executing the algorithm, the execution time requirements of the algorithm may be determined. This information may be used, for example, in order to determine whether the image processing algorithm is fast enough to evaluate images that are acquired at a particular rate in a real-time application. The information may also help the user identify portions of the algorithm that need to be modified, e.g., because they are bottlenecks in the algorithm. In the preferred embodiment, the image prototyping environment is operable to automatically generate a program implementing the image processing algorithm, once the user is satisfied with the performance of the algorithm.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06931633&OS=06931633&RS=06931633
owner: National Instruments Corporation
number: 06931633
owner_city: Austin
owner_country: US
publication_date: 20000801
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","DESCRIPTION OF THE RELATED ART","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["The present invention relates to the field of image processing, and in particular to an image processing prototyping environment operable to develop image processing algorithms in response to user input.","Traditionally, high level text-based programming languages have been used by programmers in writing application programs. Many different high level programming languages exist, including BASIC, C, JAVA, FORTRAN, Pascal, COBOL, ADA, APL, etc. Programs written in these high level languages are translated to the machine language level by translators known as compilers or interpreters. The high level programming languages in this level, as well as the assembly language level, are referred to herein as conventional programming environments.","Increasingly computers are required to be used and programmed by those who are not highly trained in computer programming techniques. When conventional programming environments are used, the user's programming skills and ability to interact with the computer system often become a limiting factor in the achievement of optimal utilization of the computer system.","There are numerous subtle complexities which a user must master before he can efficiently program a computer system in a conventional programming environment. The task of programming a computer system to model or implement a process often is further complicated by the fact that a sequence of mathematical formulas, mathematical steps or other procedures customarily used to conceptually model a process often does not closely correspond to the conventional programming techniques used to program a computer system to model such a process. In other words, the requirement that a user program in a conventional programming environment places a level of abstraction between the user's conceptualization of the solution and the implementation of a method that accomplishes this solution in a computer program. Thus, a user often must substantially master different skills in order to both conceptually model a system and then to program a computer to model that system. Since a user often is not fully proficient in techniques for programming a computer system in a conventional programming environment to implement his model, the efficiency with which the computer system can be utilized to perform such modeling often is reduced.","Examples of fields in which computer systems are employed to model and\/or control physical systems are the fields of instrumentation, process control, industrial automation, and simulation. Computer modeling or control of devices such as instruments or industrial automation hardware has become increasingly desirable in view of the increasing complexity and variety of instruments and devices available for use. However, due to the wide variety of possible testing\/control situations and environments, and also the wide array of instruments or devices available, it is often necessary for a user to develop a custom program to control a desired system. As discussed above, computer programs used to control such systems traditionally had to be written in conventional programming languages such as, for example, assembly language, C, FORTRAN, BASIC, or Pascal. Traditional users of these systems, however, often were not highly trained in programming techniques and, in addition, conventional programming languages were not sufficiently intuitive to allow users to use these languages without training. Therefore, implementation of such systems frequently required the involvement of a programmer to write software for control and analysis of instrumentation or industrial automation data. Thus, development and maintenance of the software elements in these systems often proved to be difficult.","Thus, various types of high-level prototyping environments have been developed that are targeted toward enabling users to easily create various types of specialized programs or algorithms. One example of such a specialized prototyping environment relates to the field of image processing. The term \u201cimage processing\u201d is used herein to refer to image processing, image analysis, and machine vision, among others. Image prototyping environments have been developed for rapidly developing image applications, e.g., for machine vision, pattern matching, shape matching, or other applications. Such an image prototyping environment may enable a user to easily and quickly experiment with an image, applying various image processing functions in order to manipulate, process, or analyze the image.","Algorithms developed in image prototyping environments are often intended for use in a real time environment, e.g., in order to inspect components as they are manufactured. Thus, evaluating the performance of an image processing algorithm may be very important, e.g., to determine whether the algorithm is capable of processing images at a required rate.","One embodiment of the present invention comprises a system and method for creating an image processing algorithm and automatically evaluating the performance of the algorithm. A user may develop an image processing algorithm in an image prototyping environment. The image prototyping environment may provide image processing functions for analyzing, processing, or manipulating various types of images, such as binary, grayscale, color, or complex images. The image prototyping environment may include a user interface enabling the user to easily apply the image processing functions to an image and immediately see the results, in order to develop the desired algorithm. In various embodiments, any of various types of image processing functions may be supported, including filtering functions, morphology functions, histogram functions, particle analysis functions, edge detection functions, etc. As the user applies each image processing function to an image, the function may be recorded as a step in a script, recipe, or computer program. The script essentially specifies an image processing algorithm; i.e., an image processing algorithm may be defined by the plurality of steps in a script.","Once the user has developed an image processing algorithm, the user may execute or run the algorithm. Executing or running the algorithm may comprise executing or running executable code associated with each of the individual image processing functions that define the algorithm. In response to executing the algorithm, the execution time requirements of the algorithm may be determined. The execution time requirements of each of the individual image processing functions may also be determined. The determined time requirements may be displayed to the user. A rate at which images can be processed by the algorithm may also be displayed. This information may be used, for example, in order to determine whether the image processing algorithm is fast enough to evaluate images that are acquired at a particular rate in a real-time application. The information may also help the user identify portions of the algorithm that need to be modified, e.g., because they are bottlenecks in the algorithm.","In one embodiment, the user may specify one or more images on which to run the algorithm, which may enable the determination of an average time requirement for processing various types of images. Also, in one embodiment the user may specify a desired number of times to run the algorithm, which may enable minor fluctuations in the running time of the algorithm to be taken into account.","In one embodiment, the image prototyping environment may automatically or programmatically generate suggested changes in parameters of steps (image processing functions) in the script, or changes in steps, to adjust the execution time, possibly in response to user input execution time criteria.","Information regarding various general image processing categories may also be displayed to the user. For example, the total time requirements for each function in the algorithm related to morphology operations may be summed and displayed as one category. Another category may relate to the total time requirements for steps involved with manipulating color information of the image. Other examples of possible categories include steps related to filtering functions, steps related to histogram functions, steps related to pattern matching functions, etc. In various embodiments, the categories may be separated into any level of granularity as desired and may be customized by the user.","In the preferred embodiment, the image prototyping environment is operable to automatically generate a program implementing the image processing algorithm, once the user is satisfied with the performance of the algorithm. Alternatively, the script created by the image prototyping environment may itself be a computer program. Thus, the execution time of the program in the image prototyping environment and the execution time of the program outside of the image prototyping environment should be the same.","In various embodiments, different types of programs, including text-based programs, e.g., C, BASIC, or JAVA programs, etc., and graphical programs, e.g., LABVIEW programs, may be created from a script. The program code implementing the image processing functions of the algorithm preferably has an execution time that is proportional or equivalent to the execution time of the executable code described above that is called when the algorithm runs under control of the image prototyping environment. For example, in one embodiment, the executable code called by the prototyping environment and the executable code used in the program may be the same, e.g., by calling a shared library or common component in both cases. In another embodiment, the generated program may utilize an image processing library that is associated with the image prototyping environment, e.g., a library that is provided by the vendor of the prototyping environment, so that the various image processing functions are implemented in the same way in both cases, and thus have equivalent running times.","While the invention is susceptible to various modifications and alternative forms specific embodiments are shown by way of example in the drawings and are herein described in detail. It should be understood however, that drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary the invention is to cover all modifications, equivalents and alternative following within the spirit and scope of the present invention as defined by the appended claims.","Incorporation by Reference","The following reference is hereby incorporated by reference in its entirety as though fully and completely set forth herein:","U.S. patent application Ser. No. 09\/587,682 titled \u201cSystem and Method for Automatically Generating a Graphical Program to Perform an Image Processing Algorithm,\u201d filed Jun. 5, 2000, whose inventors were Nicolas Vazquez, Jeffrey L. Kodosky, Ram Kudukoli, Kevin L. Schultz, Dinesh Nair, and Christophe Caltagirone.","FIGS. A and B\u2014Instrumentation and Industrial Automation Systems",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIGS. 1A and 1B","FIGS. 1A and 1B"]},"In one embodiment, the systems of  may perform an image processing algorithm in real-time, such as a machine-vision algorithm operable to inspect images acquired in real time. In other words, the performance of the image processing algorithm may be important, e.g., so that images may be processed at a required rate. As described below, the present invention comprises a system and method for evaluating the performance of an image processing algorithm, e.g., in order to determine the time requirements of the algorithm and possibly identify portions of the algorithm that need to be modified.",{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 1A","b":["100","100","102","102","102","150","102","132"]},"The one or more instruments may include a GPIB instrument  and associated GPIB interface card , a data acquisition board  and associated signal conditioning circuitry , a VXI instrument , a PXI instrument , a video device  and associated image acquisition card , a motion control device  and associated motion control interface card , and\/or one or more computer based instrument cards , among other types of devices.","The GPIB instrument  is coupled to the computer  via the GPIB interface card  provided by the computer . In a similar manner, the video device  is coupled to the computer  via the image acquisition card , and the motion control device  is coupled to the computer  through the motion control interface card . The data acquisition board  is coupled to the computer , and may interface through signal conditioning circuitry  to the UUT. The signal conditioning circuitry  preferably comprises an SCXI (Signal Conditioning eXtensions for Instrumentation) chassis comprising one or more SCXI modules .","The GPIB card , the image acquisition card , the motion control interface card , and the DAQ card  are typically plugged in to an I\/O slot in the computer , such as a PCI bus slot, a PC Card slot, or an ISA, EISA or MicroChannel bus slot provided by the computer . However, these cards , ,  and  are shown external to computer  for illustrative purposes.","The VXI chassis or instrument  is coupled to the computer  via a VXI bus, MXI bus, or other serial or parallel bus provided by the computer . The computer  preferably includes VXI interface logic, such as a VXI, MXI or GPIB interface card (not shown), which interfaces to the VXI chassis . The PXI chassis or instrument is preferably coupled to the computer  through the computer's PCI bus.","A serial instrument (not shown) may also be coupled to the computer  through a serial port, such as an RS-232 port, USB (Universal Serial bus) or IEEE 1394 or 1394.2 bus, provided by the computer . In typical instrumentation control systems an instrument will not be present of each interface type, and in fact many systems may only have one or more instruments of a single interface type, such as only GPIB instruments.","The instruments are coupled to the unit under test (UUT) or process , or are coupled to receive field signals, typically generated by transducers. The system  may be used in a data acquisition and control application, in a test and measurement application, a process control application, or a man-machine interface application.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 1B","FIG. 1A","FIG. 1A","FIG. 1B"],"b":["160","160","100","160","102","102","102","150","102","132"]},"The one or more devices may include a data acquisition board  and associated signal conditioning circuitry , a PXI instrument , a video device  and associated image acquisition card , a motion control device  and associated motion control interface card , a fieldbus device  and associated fieldbus interface card , a PLC (Programmable Logic Controller) , a serial instrument  and associated serial interface card , or a distributed data acquisition system, such as the Fieldpoint system  available from National Instruments, among other types of devices.","The DAQ card , the PXI chassis , the video device , and the image acquisition card  are preferably connected to the computer  as described above. The serial instrument  is coupled to the computer  through a serial interface card , or through a serial port, such as an RS-232 port, provided by the computer . The PLC  couples to the computer  through a serial port, Ethernet port, or a proprietary interface. The fieldbus interface card  is preferably comprised in the computer  and interfaces through a fieldbus network to one or more fieldbus devices. Each of the DAQ card , the serial card , the fieldbus card , the image acquisition card , and the motion control card  are typically plugged in to an I\/O slot in the computer  as described above. However, these cards , , , , and  are shown external to computer  for illustrative purposes. In typical industrial automation systems a device will not be present of each interface type, and in fact many systems may only have one or more devices of a single interface type, such as only PLCs. The devices are coupled to the device or process .","Referring again to , the computer system  preferably includes a memory medium on which one or more computer programs or software components according to the present invention are stored. The term \u201cmemory medium\u201d is intended to include an installation medium, e.g., a CD-ROM, floppy disks , or tape device, a computer system memory or random access memory such as DRAM, SRAM, EDO RAM, Rambus RAM, etc., or a non-volatile memory such as a magnetic media, e.g., a hard drive, or optical storage. The memory medium may comprise other types of memory as well, or combinations thereof.","In addition, the memory medium may be located in a first computer in which the programs are executed, or may be located in a second different computer which connects to the first computer over a network, such as the Internet. In the latter instance, the second computer provides the program instructions to the first computer for execution. Also, the computer system  may take various forms, including a personal computer system, mainframe computer system, workstation, network appliance, Internet appliance, personal digital assistant (PDA), television system or other device. In general, the term \u201ccomputer system\u201d can be broadly defined to encompass any device having at least one processor which executes instructions from a memory medium.","FIG. \u2014Computer System Block Diagram",{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 2","FIGS. 1A and 1B","FIG. 2","FIGS. 1A and 1B"]},"The computer  includes at least one central processing unit or CPU  which is coupled to a processor or host bus . The CPU  may be any of various types, including an x86 processor, e.g., a Pentium class, a PowerPC processor, a CPU from the SPARC family of RISC processors, as well as others. Main memory  is coupled to the host bus  by means of memory controller .","The main memory  stores computer programs according to the present invention. The main memory  also stores operating system software as well as the software for operation of the computer system, as well known to those skilled in the art. The computer programs of the present invention will be discussed in more detail below.","The host bus  is coupled to an expansion or input\/output bus  by means of a bus controller  or bus bridge logic. The expansion bus  is preferably the PCI (Peripheral Component Interconnect) expansion bus, although other bus types can be used. The expansion bus  includes slots for various devices such as the data acquisition board  (of ), a GPIB interface card  which provides a GPIB bus interface to the GPIB instrument  (of ), and a VXI or MXI bus card  coupled to the VXI chassis  for receiving VXI instruments. The computer  further comprises a video display subsystem  and hard drive  coupled to the expansion bus .","FIG. \u2014Creation and Performance Evaluation of an Image Processing Program",{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 3","b":"300"},"In step , one or more image processing functions are performed on an image, in response to user input accepted via the user interface displayed in step . Exemplary image processing functions are discussed below. The user interface may enable a user to select and apply these functions in any of various ways, e.g., by utilizing a menu, list, palette, etc. As the image processing functions are performed on the image, the user interface may update the image or display a separate resulting image.","As shown in step , the image processing functions performed in step  may be recorded as a script. This script may specify steps for an image processing algorithm that may be applied to various images. The script may be created automatically in response to the user's actions of applying the image processing functions to the image, or the user may provide input requesting each desired function to be added to the script. For example, the user may first apply a given image processing function to the image, in order to see the results before adding the function to the script. The user interface may enable the user to easily modify or analyze the script by adding or removing steps, performing undo operations, moving to a particular place in the script and displaying the image accordingly, etc.","It is noted that the image processing functions that are recorded in the script are not necessarily performed in step . In other words, a user may simply specify an image processing function to be added to the script without actually applying the function to an image.","In step , the script developed in steps  and  may be executed in response to user input. The user may specify one or more images on which to execute the script. Executing the script may comprise executing executable code associated with each of the recorded image processing functions. For example, when creating the script, the user may interactively specify each image processing function, and in response the image processing function may be performed, as described above. Performing each image processing function may comprise executing executable code associated with the function. In step , executable code associated with each of the image processing functions in the script may be executed, e.g., in response to a user command to execute the script.","In step , an amount of time required to execute the entire script, i.e., to perform the image processing algorithm specified by the script, may be determined. Amounts of time required to execute each individual image processing function in the script may also be determined. For example, step  may comprise timing the execution in step  of the executable code associated with each of the image processing functions.","As noted above, the user may specify one or more images on which to execute the script. Thus, the time requirements may be based on an average amount of time required for executing the image processing algorithm on various images. For example, different images may have different features which take more time to process. Also, in step , the user may specify a desired number of times to execute the script, and the time requirements may be based on an average of the times required for each repetition. For example, various hardware or software events may cause minor fluctuations in the time requirements determined for an individual repetition, and executing the script multiple times may account for these fluctuations.","In step , the time requirements determined in step  of the entire image processing algorithm and\/or of the individual image processing functions in the algorithm may be displayed. A rate at which images can be processed by the algorithm may also be displayed. For example, if the image processing algorithm takes 488 milliseconds to execute, a frame rate of 2.05 frames per second ((1000 ms\/sec)\/(488 ms\/frame)) may be displayed. This information may be required, for example, in order to determine whether the image processing algorithm is fast enough to evaluate images that are acquired at a particular rate in a real-time application. The information may also help the user identify portions of the algorithm that need to be modified, e.g., because they are bottlenecks in the algorithm. For example, the user may change parameters associated with various image processing functions in the algorithm, in order to reduce the execution time of the image processing functions.","It is noted that in one embodiment the image prototyping environment may automatically or programmatically generate and display suggested changes in the algorithm, e.g., in response to user input specifying desired execution time criteria. For example, the prototyping environment may suggest changes to parameters in various image processing functions or may suggest an alternative sequence of steps to replace existing steps. As an example, consider an algorithm including a step that computes a histogram of the image pixels. It may be possible to reduce the execution time of the histogram step by computing the histogram based on only a subset of pixels in the image instead of all the pixels. Thus parameters regarding the pixels to use in computing the histogram may be altered. In one embodiment, the prototyping environment may automatically make changes to the algorithm and inform the user of the changes, e.g., to enable the user to easily execute the changed algorithm to see the results. In this case, the user preferably can request the prototyping environment to automatically undo the changes made.","Various other types of information may also be displayed in step . For example, information indicating memory requirements for various functions may be displayed. (Collecting this memory information may affect the execution performance of the algorithm. Thus, the user may be able to disable this feature.) Also, if the image processing algorithm was executed multiple times, then statistical information regarding the execution iterations may be displayed, such as the number of iterations, the minimum, maximum, and average time requirements for the entire algorithm and\/or for the individual image processing functions in the algorithm, etc. For example, time information corresponding to each execution iteration may be shown in a tabular display that enables the user to view all or parts of the information, sort the information by different categories, etc.","Information regarding various general image processing categories may also be displayed. For example, the total time requirements for each function in the algorithm related to morphology operations may be summed and displayed as one category. Another category may relate to the total time requirements for steps involved with manipulating color information of the image. Other examples of possible categories include steps related to filtering functions, steps related to histogram functions, steps related to pattern matching functions, etc. In various embodiments, the categories may be separated into any level of granularity as desired and may be customized by the user.","In one embodiment, a program implementing the image processing algorithm specified by the script may then be automatically generated in response to a user request, as shown in step . For example, if the user decides that the image processing algorithm is sufficiently fast, the user may then request the image processing algorithm to be included in a standalone executable program. Otherwise, the user may repeat various of the steps above until the efficiency of the algorithm is improved.","In various embodiments, different types of programs, including text-based and graphical programs, may be created. As described below, the program associated with the displayed user interface may interact with another program, e.g., a graphical program development environment application, in order to create the program implementing the image processing algorithm. One embodiment of creating a graphical program in this way is described below.","It is noted that in another embodiment, the script created by the image prototyping environment may itself be an executable computer program operable to execute outside of the image prototyping environment. In this case, step  would not be necessary.","As noted above,  represents one embodiment of a method for automatically generating an image processing program, and various steps may be combined, omitted, added, reordered, or modified as desired.",{"@attributes":{"id":"h-0010","num":"0000"},"figref":"FIGS. 4\u201314"},{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 4"},"In various embodiments, the image prototyping environment may be operable to load and manipulate any of various types of images, including gray-level and color images. The prototyping environment may also support complex images in which pixel values have a real part and an imaginary part. The images may be obtained from any of various sources. The images may, for example, be obtained from an image file, such as a BMP, TIFF, AIPD, PNG, JPG, or GIF file, or a file formatted according to another image format. The images may also be obtained from a hardware device, such as a camera. For example, images may be obtained from a device such as the video device  illustrated in , or from any of various other types of devices, including digital cameras, framegrabbers, etc.","The prototyping environment may support any of various image processing functions or operations. As used herein, the term \u201cimage processing\u201d may include image processing, image analysis, and machine vision functions or operations, among others.","Image processing functions for processing an image may include functions such as:\n\n","The term \u201cimage processing\u201d may also include functions for performing various types of image analysis, including:\n\n","The term \u201cimage processing\u201d may also include functions useful in machine vision applications, including:\n\n","It is noted that the image processing functions listed above are exemplary only and that, in various embodiments of the image prototyping environment, other types of image processing functions or operations may be supported.","The user interface of the prototyping environment may enable the user to load or select an image and easily select image processing functions to apply to the image. One element illustrated in  is labeled as a \u201creference window\u201d.  also illustrates a \u201cprocessing window\u201d. As the user applies various image processing functions to the loaded image, the processing window may display the resulting image, while the reference window displays the original unmodified image. The user may select an image processing function to apply by choosing the desired function from a menu bar or by clicking on an icon, etc.","The user interface of  also illustrates a \u201cscript window\u201d. Each image processing function that the user applies to the image may be displayed in this script window. The image processing operations that a user applies to an image may result in a script of image processing operations specifying an algorithm that can be applied to analyze or manipulate other images. As an example,  illustrate a process of developing an image processing script useful for \u201cblob analysis\u201d.","A \u201cblob\u201d (Binary Large OBject) is a connected region or grouping of pixels in an image in which all pixels have the same intensity level. In a binary image, the background is zero, and every non-zero pixel is part of a binary object. Finding the size, number, or location of blob regions in an image may be useful for many applications, such as detecting flaws on silicon wafers, detecting soldering defects on electronic boards, locating objects in motion control applications, etc.",{"@attributes":{"id":"p-0078","num":"0090"},"figref":["FIG. 5","FIG. 5","FIGS. 5\u201311"],"i":"IMAQ Vision User Manual, "},"Based on the line profile grayscale values shown in , the user may then apply a filter to the image, e.g., to sharpen edges in the image and to create contrast between the particles and the background. The prototyping environment may provide various types of filters that may be applied, e.g., by selecting the desired filter from a menu bar.  illustrates the resulting image after the user has applied a \u201cConvolution-Highlight Details\u201d filter to the original image. Due to this filter operation, the  image appears to be sharper than the original image. Note that the filtering operation the user applied is recorded in the script window of . Note also that the grayscale values of a line drawn with the line profile tool have changed from the values shown in .","The next step the user may want to perform in the blob analysis is a thresholding operation to separate the particles from the background. A thresholding operation converts the grayscale image to a binary image, keeping the pixels of interest and removing the remaining pixels. The  processing window illustrates the results of applying a thresholding operation in which pixels with a value of 130 to 255 are kept and other pixels are removed. The thresholding operation applied to the image is recorded in the script window of .","It is noted that for each type of image processing function supported, the prototyping environment may be operable to display intermediate windows or screens that the user interacts with. These intermediate windows or screens may enable the user to specify various parameters or settings that apply to a particular image processing function. When the image processing function is added to the script, the specified parameters may be associated with the image processing function. The parameters may then be used in generating a program to implement the image processing algorithm, as described below. It is noted that various image processing functions may have output parameters as well as input parameters.","The process of developing an image processing algorithm may typically involve experimenting with various image processing functions and settings for the functions. However,  omit such intermediate states and simply illustrate the result of applying each step in the algorithm to the image. For example, when performing a threshold operation, an intermediate screen such as shown in  may appear.  illustrates a selection box enabling the user to select the particular type of threshold operation to apply and illustrates an interactive graph with minimum and maximum threshold values that the user may adjust in order to find the desired threshold pixel values to use. When the threshold operation step is added to the script, the specified minimum and maximum values may be associated with the step.","Continuing with the blob analysis example, after the thresholding operation is applied, the  binary image is obtained. The  particles are referred to as blobs. The user may then apply morphological functions to the image, where the morphological functions affect each blob on an individual basis. The  processing window illustrates the results of applying two successive morphological functions to the image: a \u201cFill Holes\u201d function to fill holes in the particles, and a \u201cRemove Border Objects\u201d function to remove objects that touch the border of the image. These morphological functions are also displayed in the  script window.","The user may next want to apply a particle filter function which isolates and keeps the circular blobs and removes the non-circular blobs from the image. The  processing window illustrates the results of applying such a particle filter. The particle filter operation is displayed in the  script window.","Once the user has developed the desired image processing algorithm in the prototyping environment, the user may test the algorithm on other images. As described above, a script describing each step of the algorithm may be recorded, and the prototyping environment may be operable to run this script on other images. For example,  illustrates an original image (Metal3.jpg) and the image that results from applying the script described above for . Notice that the resulting image is similar to the  result, in which circular blobs are isolated. Of course, the blob analysis algorithm discussed above is exemplary only, and image processing algorithms to perform any of various other types of image processing, manipulations, or analyses may be developed.","When running the script, the prototyping environment is preferably operable to determine the time requirements of the image processing algorithm and of the individual image processing functions defining the algorithm, as described above with reference to .  illustrate exemplary user interface windows related to the execution performance of the algorithm that the prototyping environment may display.  illustrates a status bar that may be displayed while the image processing algorithm is running in order to inform the user that the algorithm performance is being evaluated.  illustrates a window including an indicator that shows the performance of the algorithm as a whole, in terms of the number of frames or images per second that the algorithm can process. This window also shows the time in milliseconds required for the image processing algorithm to run. By clicking on the button labeled \u201cDetails,\u201d the user can also view the time requirements of the individual image processing functions, which are shown in .","In the example results shown in , the \u201cFilter Convolution\u201d step is the most expensive step, in terms of processing time. Thus, if desired, the user can attempt to improve this step of the algorithm, e.g., by editing parameters associated with this step to increase the efficiency. Also, as described above, in one embodiment, the image prototyping environment may be operable to automatically improve this portion of the algorithm, e.g., by changing parameters of the Filter Convolution step.",{"@attributes":{"id":"h-0011","num":"0000"},"figref":"FIGS. 15\u201320"},"In the preferred embodiment, once the user has developed and tested an image processing algorithm in the image prototyping environment, the prototyping environment is operable to automatically generate a program to perform the algorithm.  is a flowchart diagram illustrating one embodiment of a method for receiving information to be used in generating the program. In one embodiment, a code generation \u201cwizard\u201d, i.e., a series of related user interface dialogs, may be employed to receive the information described in .  illustrate an example of such a code generation wizard.","In step  of , input requesting automatic generation of a program is received, e.g., interactively or programmatically. For example, once the user has developed and measured the performance of a script as described above, the user may then issue a command to generate a program from the script.","As described above, in various embodiments, any of various types of programs, including text-based and graphical programs, may be generated to implement the image processing algorithm. In step , input specifying a type of program to create may be received. The input received in step  may specify a particular programming language to use in generating the program and\/or may specify a particular programming development environment where the generated program will be used. Many programming development environments support proprietary dialects of programming languages. If a particular programming development environment is specified in step , the generated program may utilize proprietary programming or development features, or may adhere to proprietary requirements.",{"@attributes":{"id":"p-0091","num":"0103"},"figref":"FIG. 16"},"As shown in , a user may also specify whether to generate additional files or other elements associated with the generated program. For example, many programming development environments utilize proprietary file types, such as project files that specify information or settings for an application. For an embodiment supporting such programming development environments, the user may specify whether to generate only the file(s) implementing the program or to also generate a project file or other relevant files associated with the program.","In step , input specifying a particular script to use in generating the program may be received. For example, a script developed as described above may be saved to a script file, which is then specified in step . Alternatively, a current script, i.e., a script that is currently open or in use, may be specified.  illustrates a user interface for receiving the information of step . In one embodiment, the current script is automatically used in generating the program.","In step , input specifying an image source or type of image source for the program may be received. In one embodiment, the generated program may perform different operations, depending on the type of image source. For example, if the image source is an image file, the program may include code for opening the file, extracting the image from the file, etc. If the image source is a hardware device, the program may include code for initializing the hardware device, acquiring the image from the device, etc.  illustrates an exemplary user interface for specifying an image source type. In this example, either an image file or a framegrabber hardware device may be specified. As shown in , if the image source is a hardware device, various parameters relating to the device, e.g., snap or triggered acquisition may also be specified in step .","In step , input specifying which image processing function parameters may be interactively specified or viewed may be received. As described above, each particular image processing function may have associated input and\/or output parameters or settings. When developing the script, the user may set the input parameter values for each step as desired, and the desired parameter values may be associated with the image processing function when the function is added to the script. The input parameter values may then be used to generate a program that operates as desired. In one embodiment, the parameter values are automatically hardcoded into the program and cannot be changed without modifying the program code. However, the user may desire the ability to interactively change one or more of the input parameter values during program operation and\/or view one or more output parameter values. Thus, in the preferred embodiment, the user can specify which input parameter values may be interactively specified or which output parameters may be viewed. The generated program is then operable to accept program input specifying new values for the chosen input parameters during program operation and is operable to provide program output displaying the chosen output parameters. For example, in one embodiment, a graphical user interface panel including various user interface controls and indicators allowing the user to set the input parameter values and view the output parameter values may automatically be displayed when the program executes.",{"@attributes":{"id":"p-0096","num":"0108"},"figref":["FIG. 19","FIG. 19","FIG. 10","FIG. 8","FIG. 23"],"b":"2"},"In step , the program is automatically generated, using the information received in steps \u2013. Step  may be performed in any of various ways as appropriate for a particular programming language or program development environment. For example, each step recorded in a script may correspond to a particular function or group of functions, and the prototyping environment may create a program that calls the appropriate functions. In various embodiments, additional elements may also be included in the created program. For example, as described above, the created program may include functions or nodes operable to load or acquire an image, display the image, etc.","The program code implementing the image processing function steps in the script preferably has an execution time that corresponds to the execution time of the code that is called in step  of , so that the time requirements determined in the method of  apply to the generated program. For example, in one embodiment, the executable code called in step  and the executable code used in the program may be the same, e.g., by calling a shared library or common component in both cases. In another embodiment, the generated program may utilize an image processing library that is associated with the image processing prototyping environment, e.g., a library that is provided by the vendor of the prototyping environment, so that the various image processing functions are implemented in the same way in both cases, and thus have equivalent running times.","One or more files including program code may be generated in step .  illustrates a user interface for receiving input specifying a file name for a program file. Also, as described above, step  may comprise generating other files, e.g., project files, in addition to the file(s) specifying the program code.","As noted above, the flowchart of  represents one embodiment of a method for receiving information to be used in generating a program, and various steps of  may be added, omitted, reordered, combined, etc. For example, the method may receive additional input in addition to that described above, to be used in generating the program. This additional input may pertain, for example, to a particular program development environment that is supported, and\/or may serve to enhance the functionality described above. As one example, additional input regarding the image source for a program may be received, e.g., to specify a particular default image file name.","Maintaining an Association Between a Script and a Generated Program","In one embodiment, an association between the script created in the prototyping environment and the program generated from the script may be maintained. This association may enable a user to run the automatically generated program and then return to the prototyping environment in order to view or edit the script used to create the program. The ability to return to the prototyping environment may be useful, for example, if while using the program to process images, it is discovered that the program has an error or needs to be modified for other reasons.","The association between the script and the generated program may be implemented in any of various ways. For example, in one embodiment, a program file may be enabled to store information related to the program; thus, the script information may be stored in the program file when the program is created. In another embodiment, the script information may be stored in another file associated with the program, such as a project or resource file. In another embodiment, the prototyping environment may be operable to store the script information. For example, when the program is created, the prototyping environment may determine or receive a key usable for uniquely identifying the program, and this key may later be used by the prototyping environment to retrieve the script information used to create the program. In another embodiment, information specifying the script used to create the program may not be maintained, but rather, the prototyping environment may be operable to read the program and automatically re-create the script used to create the program.","In various embodiments, a user may perform any of various actions in order to return to the prototyping environment to view or edit the script associated with a program. For example, the program may be a program associated with a development environment that is coupled with the prototyping environment, and the user may be able to automatically return to the prototyping environment by issuing a command to the development environment, e.g., by selecting a menu item. In another embodiment, the user may first view the user interface for the prototyping environment and then select the script corresponding to the program.","In one embodiment, a program created from a script may be \u201clocked\u201d. While the program is locked, the user may be prevented from modifying the program. The ability to lock the program may be useful, for example, in order to ensure that the state of the program corresponds to the state of the script used to create the program when the user returns to the prototyping environment. If the user desires to modify the program, the user may unlock the program, e.g., by selecting an option in a development environment associated with the program. The mechanisms of locking and unlocking a program may be implemented in any of various ways, according to methods supported by a particular system or programming environment.","FIG. \u2014Automatic Graphical Program Generation","As discussed above, any of various types of programs, including graphical programs, may be automatically generated from a script developed in the prototyping environment.  is a flowchart diagram illustrating one specific embodiment of automatically generating a program from a script, wherein the generated program is a graphical program. As described above, the script may include a number of steps, where each step represents a particular image processing function.  illustrates a method that may be performed for each step in the script, in order to generate graphical program code corresponding to the script step. It is noted that various steps of  may be combined, reordered, altered, omitted, etc.","Step  of  is to lookup information corresponding to the current step of the script, e.g., from a database. For example, each possible image processing function step that can appear in a script may have a corresponding key, such as the image processing function name, that may be used to lookup the information.","A graphical program diagram may comprise nodes which are connected together to model the program data flow or control flow, where various nodes represent different functional blocks. For each image processing function step of a script, the step may be implemented in a graphical program using one or more nodes that are connected to each other appropriately. For example,  illustrates a convolution filter function step in the prototyping environment script window. This convolution filter function may correspond to a single node available in a graphical programming system, wherein the node implements the convolution functionality. Alternatively, the convolution filter function may be implemented using a plurality of graphical program nodes. The graphical program nodes may be any of various types of nodes supported by a particular graphical programming system, including subprogram nodes, function nodes, etc. In the preferred embodiment, the graphical programming system provides a library of nodes related to image processing functions, which may be used in implementing steps of the script.","Thus, the information retrieved in step  may include a list of one or more nodes to add to the graphical program, in order to implement the current step of the script. The information may also include information specifying how the inputs and outputs of these nodes should be linked to each other, in order to accomplish the desired data or control flow. The link information may be specified in any of various ways, as appropriate for a particular graphical programming system. For example, in one embodiment, each graphical program node includes terminals corresponding to each node input or output. Thus, the link information may specify pairs of node terminals that should be connected to each other.","The information retrieved in step  also may include parameter information. As described above, various parameters or settings may be associated with each step in a script. These parameters may be represented in the graphical program as leaf nodes which provide input to or display output from the nodes which implement the current step of the script. Thus, the parameter information may include a list of leaf nodes to add to the graphical program, in order to provide or accept the parameter values to or from the other nodes. A type may be specified for each parameter. For example, if an input parameter is an integer value, a corresponding leaf node may be created as an integer constant node, i.e., a node which is operable to output an integer constant. A default value for the parameter may also be specified. For input parameters, information specifying which node input the output of the corresponding leaf node should connect to may also be specified. For output parameters, information specifying which node output the input of the corresponding leaf node should connect to may also be specified.","As discussed above, in one embodiment, the user may designate certain parameter values that he wishes to be able to change or display interactively. For these parameters, a leaf node constant representing the parameter value is preferably not connected to the node input\/output that receives\/generates the parameter value. Instead, a user interface control or indicator representing the parameter value may be created, and the node input or output that receives or generates the parameter value may be configured to receive or set the value of this user interface control or indicator. In one embodiment, when a user interface control or indicator is created, a corresponding node may be automatically created in the graphical program diagram. Thus, the output or input of the node corresponding to the user interface control\/indicator may simply be connected to the node input or output that receives or generates the parameter value. For other embodiments, the node input\/ouput may be connected to the user interface control\/indicator value in any of various other ways, as supported by the particular embodiment.","The parameter information obtained in step  may include information specifying the type of user interface control\/indicator to create and possibly other user interface information. For example, for a parameter that may be one of several strings, the parameter information may specify that a user interface control for selecting from a list of strings should be created and may specify the list of strings to configure the control with. Alternatively, the system may be operable to automatically create an appropriate user interface control or indicator by examining the type information of the node input or output that control or indicator connects to. This automatic creation of user interface controls\/indicators is discussed below.","In step , the nodes determined in step  are added to the graphical program. Elements may be added to the graphical program in any of various ways. For example, the application that generates the graphical program may comprise program logic for creating a graphical program file that is formatted appropriately. However, in the preferred embodiment, the application interfaces with a graphical programming system and requests the graphical programming system to create the desired program.","In step  the inputs and outputs of the nodes added in step  are linked to each other appropriately, using the information from step . Again, the application may perform step  directly or may request a graphical programming system to connect the node inputs and outputs.","In step , nodes representing parameters to the image processing functions for the current step of the script are added to the graphical program, using the information from step . For example, various leaf nodes may be added, as described above. In step , the outputs of the parameter nodes are connected to the appropriate inputs of the nodes added in step . Step  may also involve configuring the leaf nodes with an appropriate value. As noted above, when a step is added to a script, parameter values specified by the user (or default values) may be associated with the step. These parameter values may be used to configure the leaf nodes with an appropriate value. For example, in , a maximum threshold parameter value of  is illustrated. In this example, a leaf node representing the maximum threshold parameter may be created as an integer constant and may configured with a value of . Thus, this leaf node would provide the value  to the node input that the leaf node is connected to. For a parameter that is interactively changeable, steps  and  may involve creating a user interface control for the parameter and linking the control to the appropriate node input, as described above.","Steps \u2013 describe adding graphical program elements pertaining to a particular step of the script to the graphical program. For a given current step, it may be necessary to link various outputs of nodes added for previous steps to inputs of nodes added for the current step. For each step, information regarding outputs of nodes added for the step may be stored, e.g., in a table in memory. In step , this stored information may be used to connect the appropriate outputs of nodes previously added to inputs of nodes added for the current step. For example, in addition to specifying the desired links between nodes added for the current step of the script, the information obtained in step  may also specify when an input of a node added for the current step should be connected to an output of a node added for a previous step in the script. The stored information may then be searched to determine which previous node output should connect to the current node input. Any of various types of information enabling this determination may be stored, as appropriate for a particular embodiment, such as output terminal names, output data types, etc.","In step , output information relating to nodes added for the current step of the script is stored, so that this information will be available for subsequent steps.",{"@attributes":{"id":"h-0014","num":"0000"},"figref":"FIGS. 22\u201323"},{"@attributes":{"id":"p-0117","num":"0129"},"figref":["FIG. 22","FIGS. 5\u201314"]},"The graphical program of  corresponds to the code generation user interface screen shown in , in that the program is operable to accept interactive user input specifying the input parameters selected in  and is operable to display the output parameters selected in .  illustrates a user interface panel including user interface controls and indicators corresponding to the selected input and output parameters. This user interface panel may be generated along with the graphical program block diagram. Each user interface control or indicator on the user interface panel has a corresponding leaf node in the block diagram. For example, the block diagram leaf node labeled \u201cRange\u201d corresponds to the user interface control labeled \u201cRange\u201d, and the output of the \u201cRange\u201d leaf node is connected to the input of the \u201cIMAQ Threshold\u201d node, so that the \u201cIMAQ Threshold\u201d node receives the new range values as they are adjusted by a user.","Note that for the parameters which are not selected in , no corresponding user interface controls or indicators are created, and values for these parameters are instead hardcoded into the block diagram. For example, the \u201cKeep Particles\u201d item is unselected in , and a Boolean constant leaf node labeled \u201cKeep\/Remove Particles\u201d is connected to one of the nodes which implement step  of the script. The constant value may be set to True or False, e.g., depending on the settings the user specified when the script was created.","As noted above, in one embodiment, an appropriate user interface control or indicator for a selected parameter may be automatically created by examining the type information of the node input or output that the control or indicator connects to. For example, as discussed below, the prototyping environment may interface with a graphical programming system and may request the graphical programming system to create each graphical program object. The graphical programming system may be operable to automatically create a user interface control or indicator that matches the data expected by a node input or produced by a node output. For example, with respect to the block diagram node labeled \u201cIMAQ Threshold\u201d, the graphical programming system may examine the input terminal of the node and discover that the terminal expects two integer values. The graphical programming system may then create a user interface control appropriate for providing two integer values, such as the \u201cRange\u201d control illustrated in .","Interfacing with a Graphical Programming System","As described above, in one embodiment the prototyping environment may interface with a graphical programming system in order to automatically generate a graphical program implementing a script. The graphical programming system may support an application programming interface (API) that allows callers to create or edit graphical programs and add objects or nodes to graphical programs in order to achieve the desired functionality. For example, the prototyping environment may first call an API function to create a graphical program object, obtaining a reference to this object. The prototyping environment may then call an API function to add nodes representing the appropriate image processing functions to the graphical program object.","The graphical programming system may support any of various types of APIs for callers to use. For example, many applications are operable to call standard ActiveX\/COM components. Thus, in one embodiment, the graphical programming system may expose COM objects that the prototyping environment may call to create the graphical program. In another embodiment, the graphical programming system may provide a graphical API for creating graphical programs.","Although the system and method of the present invention has been described in connection with the preferred embodiment, it is not intended to be limited to the specific form set forth herein, but on the contrary, it is intended to cover such alternatives, modifications, and equivalents, as can be reasonably included within the spirit and scope of the invention as defined by the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["A better understanding of the present invention can be obtained when the following detailed description of the preferred embodiment is considered in conjunction with the following drawings, in which:",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIGS. 1A and 1B"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 2","FIGS. 1A and 1B"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIGS. 5\u201311"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIGS. 12\u201314"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 22","FIGS. 5\u201311"]},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 23","FIG. 22"]}]},"DETDESC":[{},{}]}
