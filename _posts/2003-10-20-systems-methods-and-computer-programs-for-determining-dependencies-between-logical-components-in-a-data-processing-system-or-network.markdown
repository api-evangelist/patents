---
title: Systems, methods and computer programs for determining dependencies between logical components in a data processing system or network
abstract: Described are methods, apparatus and computer programs for determining run-time dependencies between logical components of a data processing environment. Components of the data processing environment are monitored by monitoring agents accessing run-time activity data via APIs of the managed system. A dependency generator identifies correlations between the run-time activity of the monitored components. For synchronous monitored systems, the dependency generator calculates an activity period for monitored components and determines which component's activity periods contain the activity periods of other components. Containment is used as an indicator of a likely dependency relationship, and a weighting is computed for each dependency relationship based on the consistency of containment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07409676&OS=07409676&RS=07409676
owner: International Business Machines Corporation
number: 07409676
owner_city: Armonk
owner_country: US
publication_date: 20031020
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF INVENTION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION OF EMBODIMENTS"],"p":["The present invention relates to data processing methods, systems and networks. In particular, the invention relates to systems, methods and computer programs for determining run-time dependencies between logical components of distributed or stand-alone data processing systems.","The identification and tracking of dependencies between components of distributed systems is becoming increasingly important for integrated fault management (problem determination, impact analysis and repair for a set of cooperating components or processes). Distributed systems can be represented as interacting service components, classified into multiple layers, where each layer provides services to layers above. Many service components have dependencies on other service components\u2014such that failures occurring in one service component affect other services and ultimately customer applications. A dependency exists when a first component requires a service performed by another component in order for the first component to execute its functions.","Dependencies can exist between the components of different services on a single system and also between the client and server components of a service distributed across multiple systems and network domains. Typically, dependencies exist between various components of a distributed system, such as end-user services, system services, applications and their logical and physical components.","Relatively frequent failures is a characteristic of most complex operational systems. Recently, attempts have been made to reduce systems' mean time to recovery (MTTR) once failures are detected. In order to reduce MTTR, it is necessary to be able to quickly determine the root cause of a problem that is detected at a higher level, and then to resolve the problem. Many problem determination applications use a component dependency graph to pin-point the root cause.","For example, B. Gruschke, \u201cIntegrated Event Management: Event Correlation Using Dependency Graphs\u201d, Proceedings of 9IFIP\/IEEE International workshop on Distributed Systems: Operations and Management (DSOM), 1998, discloses the use of a dependency graph for problem determination, mapping incoming alarms and events to nodes of the graph to identify dependent nodes which are a likely root cause of problems.","However, the discovery and recording of dependency information in a distributed system is a time-consuming and difficult task, since service components generally do not expose dependency information in a standard way. The lack of explicit dependency information makes the tasks of problem determination, isolation and resolution particularly difficult.","It is not acceptable to rely solely on dependency information within configuration files or machine-readable files provided by a software vendor, because the vendor's knowledge of dependencies may be limited and because static information within configuration files cannot provide a picture of dynamic, run-time dependencies. Emerging Web-based architectures allow the composition of applications at runtime and an application running within a Web application server may be instantiated and then terminated within a few seconds.","Furthermore, known techniques for automatically determining dependency information rely on fairly invasive middleware instrumentation or internal instrumentation\u2014such as by embedding code which responds to Application Response Measurement (ARM) API calls (implementing The Open Group's Technical Standard C807) but this requires all components to implement the standard. In typical heterogeneous customer environments, which include a collection of hardware and software from different vendors, known approaches for intrumenting managed applications or objects to directly obtain dependency data are difficult and time consuming to implement, and therefore costly. Such instrumentation approaches may even be unusable in heterogeneous environments and in systems with security, licensing or other technical constraints.","One approach to instrumenting the components of a managed system is disclosed by P. Hasselmeyer in \u201cManaging Dynamic Service Dependencies\u201d, 12International Workshop on Distributed Systems: Operations and Management (DSOM), France, 2001. Dependencies are made accessible to management applications as properties attached to components. Dependency data is supplied directly by the component having the dependency. The components can be polled or dependency change notifications can be generated at run-time.","A technique for determining dependency information is described by S. Bagchi, G. Kar and J. Hellerstein in \u201cDependency Analysis in Distributed Systems using Fault Injection: Application to Problem Determination in an e-commerce Environment\u201d, 12International Workshop on Distributed Systems: Operations and Management (DSOM), France, 2001. The described technique involves injecting a fault into a system during a testing phase and collecting measurements of the external behaviour of the system. The measurements are then analyzed and statistical regression analysis is used to determine the extent to which a quality of service metric depends on specific components. However, fault insertion and other \u201cperturbation\u201d techniques are reliant on the ability to insert controlled perturbations which will be effective in discovering dependencies. Furthermore, typical fault insertion techniques are limited to a testing phase because the insertion of faults is generally unacceptable at run-time.","C. Ensel, \u201cAutomated generation of dependency models for service management\u201d, Workshop of the Open View University Association (OVUA), 1999, suggests that generation of service dependency models may be automated using a Neural Network and information collected at run-time. Information such as, for example, CPU usage of an application is taken from lower layers such as the operating system, middleware or transport system. According to Ensel, a time series of objects' activities may then be fed into a Neural Network to judge whether the objects appear to be related. Ensel states that a complex training process is required, but does not describe the training process or how the Neural Network would determine dependencies.","Aspects of the present invention provide methods, apparatus and computer programs for determining dependencies between logical components of a data processing environment by observing the run-time behaviour of the components comprising the environment.","A first embodiment of the invention provides a method, implemented in a data processing system, for determining run-time dependencies between logical components of a data processing environment, the method comprising the steps of:\n\n","The step of monitoring run-time activity of a component may include monitoring an activity period corresponding to the period between estimated start and end times for the processing of a request, or monitoring other run-time activity metrics for the monitored components such as the number of invocations within a monitoring period.","Most software vendors provide some integrated instrumentation for monitoring statistics, such as invocation and average execution time counters, for accounting and performance tuning purposes. Embodiments of the present invention can be implemented to use these existing monitoring features, avoiding the need for additional intrusive instrumentation of the components to be monitored.","In one embodiment, a set of monitoring agents cooperate with existing counters implemented within the monitored components. The monitoring agents generate an event on completion of processing of a request by the monitored resource, and the events are used to calculate an activity period which contains the period of execution of the component. A correlation identifier then compares the activity periods for different components to identify correlations, such as identifying components which have an activity period containing the activity period of other components. The correlation identifier may be implemented as a correlation-checking computer program.","In a particular embodiment, the correlation identifier determines whether a positive correlation between two components' run-time activity periods is identified consistently for a plurality of activity periods. The correlation identifier applies to each dependency relationship a \u2018probability\u2019 value (or \u2018weight\u2019) representing the proportion of compared activity periods for which a positive correlation is identified. The \u2018probability\u2019 value may be used to sort identified dependencies into an order for subsequent processing.","One embodiment determines whether an activity period of a first component contains the activity period of the second component to determine whether the first component has a synchronous dependency relationship with the second component. The first component's activity period contains the second component's activity period if two conditions are met: the start time of the second component is no earlier that the start time of the first component, and the end time of the first component is no later than the end time of the second component.","Vendors of \u2018middleware\u2019 computer programs, such as Web application servers, database servers and other application-enabling computer programs, typically provide interfaces for accessing essential management data (which can be in the form of logs) that pertains to the state of their programs and applications running on those programs. However, most vendors do not provide explicit information regarding dependencies between the components. A method according to an embodiment of the invention uses activity-related data which is accessible from a managed system, and computes probable dependencies between components of the managed system from the accessed activity data.","A method according to one embodiment of the invention includes data mining run-time monitoring data to construct a dynamic dependency graph between the components of a distributed application. The graph can be updated over time as more monitoring data becomes available. The graph may be used for problem analysis, impact analysis or other systems management applications.","One embodiment of the invention enables extracting of information for determining dependencies within systems (\u201cmicro-dependencies\u201d) and across systems (\u201cmacro-dependencies\u201d) of a distributed computing environment without the need to change either the applications installed on the managed systems or the existing application-enabling computer programs that provide run-time support to these applications.","One embodiment of the invention provides the ability to identify probable dependencies between logical components, such as between various cooperating server processes and application programs. The logical components of a data processing environment may include, for example, application programs, servlets and Enterprise Java Beans (EJBs) running within a Web application server, processes serving Uniform Resource Identifiers (URIs), processes executing Structured Query Language (SQL) requests and Web services components. The logical components may originate from a plurality of different vendors. In an enterprise system, a Web transaction (processing a URL request) is typically serviced by servlets which in turn may invoke EJBs or directly execute SQL queries. A Web application may issue SQL queries to a database server. Hereafter, references to the activity period or dependency of a URI should be interpreted as references to the process or transaction executing the URI, and references to the activity period or dependency of an SQL should be interpreted as references to the process or thread executing the SQL request (such as within a servlet or database server).","A second embodiment of the invention provides a data processing apparatus comprising:\n\n","One or more monitoring agents are preferably installed on the same data processing apparatus as the logical components to be monitored. The monitoring agents send monitoring data to the correlation identifier running on a different data processing apparatus.","A method, a correlation identifier and monitoring agents according to the invention may be implemented in computer program code, and made available as a computer program product comprising program code instructions for controlling the performance of operations within a data processing environment in which the program code runs. The computer program code may be recorded on a machine-readable recording medium or provided via any data transfer mechanism.","Described below are apparatus and methods for dependency determination in distributed data processing environments, by computation of probable dependencies based on monitored run-time activity metrics. Dependency graphs are generated and the resulting dependency graphs can be used for problem determination. The methods described below may be used to identify runtime dependencies between, for example, servlets, Web server processes serving Uniform Resource Locators (URLs), Enterprise JavaBeans\u2122 (EJBs), and Structured Query Language (SQL) server processes associated with a Web application.","Some portions of the following description are presented in terms of algorithms and symbolic representations of operations on data within a computer memory. Algorithmic descriptions and representations are used by persons skilled in the data processing arts to convey the substance of their work to others skilled in the art. An algorithm is a self-consistent sequence of steps leading to a desired result. The steps typically require physical manipulations of physical quantities\u2014such as electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. The signals are conveniently referred to as bits, values, elements, symbols, characters, terms, numbers, or the like. Such terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities.","Unless stated otherwise, discussions within this patent specification utilizing terms such as \u201cscanning\u201d, \u201ccalculating\u201d, \u201cdetermining\u201d, \u201creplacing\u201d, \u201cgenerating\u201d\u201cinitializing\u201d, \u201coutputting\u201d, or the like, refer to the action and processes of a computer system, or similar electronic device, that manipulates and transforms data represented as physical (electronic) quantities within the registers and memories of the computer system into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.","The present specification also discloses apparatus for performing the operations of the methods. Such apparatus may be specially constructed for the required purposes, or may comprise a general purpose computer or other device selectively activated or reconfigured by a computer program stored in the computer. The algorithms and displays presented herein are not inherently related to any particular computers or other apparatus. Various general purpose machines may be used with programs in accordance with the teachings herein. Alternatively, more specialized apparatus may be constructed to perform the required method steps.","The present patent specification also implicitly discloses a computer program, since it would be apparent to the person skilled in the art that the individual steps of the methods described herein can be put into effect by computer program code. The computer program is not intended to be limited to any particular programming language or implementation thereof. It will be appreciated that a variety of programming languages and coding thereof may be used to implement the teachings of the disclosure contained herein. Moreover, the computer program or programs are not intended to be limited to a single control flow. Other variants of the program can use different control flows and two or more steps of a described sequence may be performed in parallel rather than sequentially.","Such a computer program may be stored on any machine-readable medium. The readable medium may include storage devices such as magnetic or optical disks, memory chips, or other storage devices suitable for interfacing with a computer or similar device. The machine-readable medium may include a hard-wired medium such as exemplified in the Internet system, or wireless medium such as exemplified in the GSM mobile telephone system. The computer program or programs when loaded and executed on a computer system effectively results in an apparatus that implements the steps of the preferred method.","Where reference is made in any one or more of the accompanying drawings to steps or features which have the same reference numerals, those steps or features have substantially the same functions or operations for the purposes of this description.","The principles of the preferred method described herein have general applicability to the run-time determination of dependencies between logical components or processes in a computing system or network.","Architectural Overview",{"@attributes":{"id":"p-0044","num":"0050"},"figref":"FIG. 1","b":["10","12","14","16","18","20","20","10"]},"In the present embodiment, the agents  poll the system components to obtain activity-related metrics such as performance data, the number of requests sent to a component within a monitoring period or the average response time of a component. In particular, an agent  accesses static information within configuration files of the managed system or subsystem that it monitors, and accesses activity-related data within logs created by the managed system. An agent can run in the same host, or even the same process, as the managed system or subsystem or the agent can run on an entirely separate computer system.","The data gathered by an agent  from the managed system  is then forwarded to a Dependency Generator , the responsibility of which is to use this data to identify and record dependencies between system components and variables belonging to the managed system. Dependencies are estimated based on correlations between the run-time activity of components of the system. If the number of requests to a first component is related to the number of requests to a second component within a specific time period, or if the execution times of the two components show a positive correlation, the Dependency Generator  determines that a dependency relationship is likely based on the correlation. The operation of the Dependency Generator is described in more detail below.","The identified dependencies are then aggregated and persisted to a database or file system  by a Dependency Aggregator . A management client application  can access the stored dependency data via the Dependency Aggregator, and process the data in various ways such as to perform root-cause analysis, impact analysis, or to repair faults.","Example System and Method","Specific examples of a system implementing the above-described architecture and a method performing automated generation of dependencies are described below with reference to . The system comprises three tiers ,,. The bottom tier  includes the managed system , which in the example described here comprises a Web application server  (such as IBM Corporation's WebSphere(\u2122) Application Server software) and a database server  such as IBM Corporation's DB2(\u2122) database software). A Web-accessible application program  is installed to run on the Web application server . Both the Web application server (WAS)  and the database server  have a monitoring API  through which local agents  and  can access runtime statistics, such as via standard performance-monitoring counters.","The Web application server  populates an access log with URIs identifying accessed Web resources, and maintains log records including start and end times for processes running in the managed system . The Web application  includes a configuration file which identifies the dependence of URIs on the particular servlet which serves requests for the respective URI. The Web application server also includes counters and provides access to a system clock enabling monitoring of access counts and average response times of servlets and EJBs. In the example of IBM Corporation's WebSphere Application Server, counters are implemented within a Performance Monitoring Infrastructure (PMI) component .","Referring to , run-time activity data is monitored  by the local agents  and  extracting activity-related data from the access log, counters and configuration files, using the monitoring APIs referred to above. The agents may manipulate the raw monitored data to generate more useful activity-related metrics for subsequent processing (for example, aggregating or computing averages). Such manipulation by the agents enables reduction of subsequent network communications. However, alternative embodiments of the invention implement such manipulation at the next layer  of the system, to avoid adding complexity to the agents and in particular to avoid imposing a processing overhead on the managed system . In the specific implementation shown in , the application server and the database server run on the same computer, and hence both agents  and  send data that is time-stamped using the same clock. Alternative implementations may include a distributed system, requiring handling of clock synchronization between computers. Such synchronization may be implemented using conventional methods.","The agents  and  then send the monitored data to a Dependency Generator  in the central management layer . The Dependency Generator  includes a correlation identifier for identifying  correlations. The correlation identifier determines an activity period for each process or component, using events indicating completion of request processing to compute theoretical start and end times. The correlation identifier then compares components' activity periods to identify correlations, as described below. A data mining method implemented in the Dependency Generator processes the identified correlations output by the correlation identifier to generate  identifications of probable dependencies between the monitored components.","The dependency information is persistently stored  in a repository under the control of a Dependency Aggregator \u2014implemented as a Common Information Model (CIM) Object Manager. The CIM Object Manager  has the following functions:\n\n","The CIM Object Manager stores dependency information in a standard CIM format so that the information can be understood by management applications from multiple vendors.","The top-most layer  of the system comprises management applications  that pull  dependency data from the repository through the CIM Object Manager , for various uses including, for example, visualization, root cause analysis, and impact analysis applications.","The system described herein reuses existing monitoring data and logs from the managed system to obtain dependency information between URLs, servlets, EJBs and SQLs. URL-to-servlet mappings are obtained by parsing the access log of the Web application server  and other activity log records, using the static information present in configuration files of the installed Web application  which interfaces to the Web application server. Servlet-to-EJB, servlet-to-SQL, and EJB-to-SQL dependencies can be obtained from events generated through conventional database monitoring functions and the conventional activity monitoring functions of the Web application server . An API  of the monitoring infrastructure  provides access to performance-related activity data relating to processes running in the Web application server.","An example of an existing monitoring infrastructure which is suitable for use within the present embodiment is the Performance Monitoring Infrastucture (PMI) of IBM Corporation's WebSphere Application Server.","Monitoring and Generated Events","The monitoring infrastructure  and API  provide a framework to extract monitoring data from the Web application server (WAS)  and local application components  at runtime. The client side of this framework is externalized and published as a lightweight Java\u2122 API  that allows monitoring data to be gathered from instrumented components. Within the Web application server , the monitoring infrastructure  on the server-side of the monitoring infrastructure API  keeps the performance data as raw counter values, whereas the agents , on the client side of the API  retrieve and manipulate the raw counters to provide more meaningful statistics such as average, time-weighted average, percentage change, rate, etc. This imposes less overhead on the Web application server  than if the Web application server was required to generate statistics from the raw data, and allows the server data to be shared across multiple clients.","A subset of the objects and resources pertaining to the Web application , Web application server  and the database server  are monitored. The monitored objects and resources are referred to hereafter as logical components and may include processes serving URLs, servlets, EJBs, SQL database server processes and database tables. However, since the monitoring methods implemented in the embodiment described here are not limited to monitoring specific types of logical components, the methods may be generalized to other types of logical components. In the present embodiment, the agent  obtains activity metrics including access counts and average response times of servlets and EJBs, and obtains accessed URLs from an HTTP access log. The dependence of a URL on the servlet which serves that URL is obtained from a Web application's configuration files. The agent  provides to the correlation identifier events for URLs, servlets, and EJBs; whereas agent  provides events for SQL request executions.","Each of the URLs, servlets, and EJBs can be modelled using the Common Information Model schema of the J2EE Management Specification (which is described, at the time of writing this specification). For example, we use the following CIM class for the servlet:",{"@attributes":{"id":"p-0060","num":"0068"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class J2EE_Servlet:CIM_Service"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"string UrlPattern;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"[Key, Override (\u201cName\u201d) ]"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"string Name;"]},{"entry":[{},"string ShortName;"]},{"entry":[{},"real64 AvgResponseTime;"]},{"entry":[{},"uint64 TotalRequests;"]},{"entry":[{},"real64 ResponseTimeOfLastRequest;"]},{"entry":[{},"uint64 StartTimeOfLastRequest;"]},{"entry":[{},"uint64 EndTimeOfLastRequest;"]},{"entry":[{},"uint64 RequestsBeingServed;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The class CIM_Service is a CIM class that is a super class of class J2EE_Servlet. That is, J2EE_Servlet derives from CIM_Service which is present in the CORE CIM Schema. The field or property \u201cName\u201d in the class is the key. Monitoring data obtained from the monitoring infrastructure interface  can be used to create an object of the above CIM class. Creating an object of the above J2EE_Servlet class amounts to using the functionality of the CIM Object Manager  to obtain an instance of J2EE_Servlet and to populate at least some of the fields in the instance, and then writing the object to the repository . The new instance is created with a different key set from other instances of class J2EE_Servlet already present in the repository . Similarly, CIM classes J2EE_EJB and J2EE_URLResource are used for Enterprise JavaBeans and Web-based resources identified by URLs.","The SQL events are modelled using the CIM_UnitOfWorkDefinition class of the CIM Metrics Model (described, at the time of writing. The specific CIM class eBIM_SQL used for modelling SQL events, which derives from class CIM_UnitOfWorkDefinition, is defined as follows:",{"@attributes":{"id":"p-0063","num":"0071"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class eBIM_SQL:CIM_UnitOfWorkDefinition"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"[Key, Override(\u201cId\u201d) ]"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"string Id;"]},{"entry":[{},"uint64 TotalExecutions;"]},{"entry":[{},"real64 AvgResponseTime;"]},{"entry":[{},"real64 ResponseTimeOfLastExecution;"]},{"entry":[{},"uint64 StartTimeOfLastExecution;"]},{"entry":[{},"uint64 EndTimeOfLastExecution;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"In the above class eBIM_SQL, \u201cId\u201d is the key. Since this property is present in CIM_UnitOfWorkDefinition, we override the super class definition (as shown above). The agent that monitors the SQL information provides events to create new instances of the class eBIM_SQL. The method for creating a new instance for eBIM_SQL is the same as that described for J2EE_Servlet, including providing a unique key set for the new instance compared with instances already present in the repository .","In order to capture the dependency information between the above-described objects, such as for example the dependency between a servlet and an EJB, additional association classes have been defined as subclasses of the CIM_dependency class (see below). When the instances of the CIM classes pertaining to the URLs, servlets, EJBs, SQLs, and their dependencies are discovered, the CIM repository  in the middle layer  in  is populated with the dependencies discovered by the dependency generator. The CIM class instances are held in the CIM repository  in association with identifiers of the respective monitored components. The newly defined dependency classes are:",{"@attributes":{"id":"p-0066","num":"0074"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"class eBIM_ServletExecutesSQL:CIM_Dependency"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"{"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"[Key, Override (\u201cAntecedent\u201d) ]"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"eBIM_SQL REF Antecedent;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"[Key, Override (\u201cDependent\u201d) ]"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"J2EE_Servlet REF Dependent;"]},{"entry":[{},"real32 DependencyStrength;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The above new class eBIM_ServletExecutesSQL:CIM_Dependency associates an instance of J2EE_Servlet to an instance of eBIM_SQL (i.e. t the SQL request execution resulting from processing of the servlet). The new class derives from the class \u201cCIM_Dependency\u201d which is present in the CORE CIM Schema. The new class has two keys: \u201cAntecedent\u201d and \u201cDependent\u201d, which are references to the corresponding antecedent SQL instance and dependent servlet instance, respectively. The property\/attribute \u201cDependencyStrength\u201d corresponds to a measure of the consistency of identification of a dependency between the two instances, as computed by the dependency generator.","An additional subclass of CIM_dependency is the eBIM_Servlet2EJB association class whose parent superclass is J2EE_ServiceDependency. The new class eBIM_Servlet2EJB associates a servlet with an EJB. The dependent is an instance of J2EE_Servlet and the antecedent is the instance of J2EE_EJB (the JSR-77 IDE toolkit referenced above provides a definition of CIM classes with prefix \u201cJ2EE\u201d).",{"@attributes":{"id":"p-0069","num":"0077"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class eBIM_Servlet2EJB:J2EE_ServiceDependency"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"[Key, Override (\u201cDependent\u201d) ]"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"J2EE_Servlet REF Dependent;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"[Key, Override (\u201cAntecedent\u201d) ]"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"J2EE_EJB REF Antecedent;"]},{"entry":[{},"real32 DependencyStrength;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"Similarly, additional relationships can exist between pairs of subcomponent types. The correlation engine uses the events that are sent by the agents  to compute the dependencies. The events are wrappers (java class objects) around the monitored data accessed by the agents.","It is well known to use a CIM framework for keeping and storing management information. The known CIM framework separates the management interface from the business interface, such that a vendor of a higher-level management application does not have to be concerned with the specific mechanism by which the management data of a product is provided to the CIM Object Manager. Such mechanisms are typically vendor-specific, and may change from one version of a product to another.","A client agent  polls the Web application server for performance data. Each time the client agent polls, it gets the latest values of the polled counters. If the number of requests made to a particular servlet is a required metric, each monitoring infrastructure client request returns the total number of requests made to the servlet (i.e. the number of requests within a defined time period, or from the time the client agent  started monitoring the Web application server ). The client agent  runs on the same computer as the Web Application Server  and polls the Web Application Server at a regular interval of PI milliseconds. Each time the Web Application Server is polled, servlet and EJB events are generated corresponding to new requests completed for servlets and EJBs since the last poll. The generated events are sent to the Correlation Identifier of the Dependency Generator  within the management server . If the correlation identifier identifies a correlation between components, the Dependency Generator generates a new instance of the relevant subclass of the CIM_dependency class and the new dependency information is sent to the CIM repository .","For example, a servlet event contains:\n\n","Each servlet and EJB event also contains a time stamp that corresponds to the time of completion of the polling request (made to the Web Application Server by agent  in ) that resulted in the creation of this event. If the polling frequency, 1\/PI, is higher than the rate at which requests to a given servlet complete in the Web Application Server, then each servlet event that is sent would correspond to a completion of a single request to that servlet. Otherwise, servlet events are generated for multiple servlet request completions. The methods and algorithms described below for generating dependencies can handle both these eventualities. For simplicity and without loss of generality, the following description assumes that each generated event (whether for a servlet or an EJB) corresponds to a single request or method call completion.","An SQL event is sent to the management server  for each SQL request execution captured from a monitoring interface of the database server . Each event comprises an SQL query string, a time stamp that is defined to be the end time of the SQL request, and the start time of the query.","Computing Activity Periods from Events","On receiving an event, the Correlation Identifier of the Dependency Generator  (in ) computes the time interval during which the request, represented by the event, is active. This interval is referred to hereafter as the \u201cactivity period\u201d of an event. Ideally, the activity period for an event is the time interval beginning with the start time and ending with the completion time, respectively, of the request to the component represented by the event. However, when using polling-based interfaces to obtain monitoring data, the computation of the activity period is more complicated than this ideal case\u2014as explained in the next paragraph.","Since the agents  poll the Web Application Server  via the monitoring infrastructure  at regular intervals of length PI, a request for the services of an EJB or servlet which request completes at some time t will only be detected at PE, the next monitoring infrastructure polling time that happens after time t. The event corresponding to the completion of the request, which event is generated at PE, does not include the information that the request was completed at time t but rather a time stamp PE, is assigned to the event. Thus, the estimate of the completion time could be in error by as much as PI. For this reason the correlation identifier calculates an interval, for use as the activity period, which interval can be relied on to cover the actual activity period of the event. To compute the activity period of an event, the time stamp of the event and the execution time of the component request represented by the event are used. Since the time stamp is already an attribute of the event, the Correlation Identifier can compute the execution time of a request from the corresponding event.","If the current event corresponds to the N+1request to the servlet, then X(the execution time of the request) can be calculated by subtracting the product of the average response time Tand the total number of requests N (values of the event prior to the current one) from the product of the average response time Tand the total number of requests N+1 (values of the current event). That is:\n\n=(+1)\n","For the event corresponding to the first request to the servlet, the average response time value Tis actually the execution time of the servlet request Xcorresponding to that event. Similarly, the execution time of a method execution corresponding to an EJB event can also be obtained.","The \u2018activity period\u2019 of an event is then obtained as follows. Let the \u2018activity period\u2019 of the N+1request be denoted as [L, R]. As mentioned earlier, the time stamp carried by a servlet-related or EJB-related event is actually the time at which the monitoring infrastructure poll request completed (i.e. the completion of the request that resulted in the creation of this event). Let the time stamp carried by the event corresponding to the N+1request be denoted as TS. Define R=TS. The end time of the servlet request could lie anywhere in the interval [TS\u2212PI, TS] implying that the earliest time that the request could have started is TS\u2212PI\u2212X. We define Lto be this earliest possible start time, i.e.:\n\n.\n","A small difference exists in the case of investigating dependencies of servlets on EJBs. For computing a servlet's activity period, we let:\n\n\n","The reason for this difference is that it facilitates the containment of the activity period of an EJB, which is invoked by a servlet, into the activity period of the servlet. Such \u201ccontainment\u201d is defined below.","For some monitoring infrastructures, an assumption can validly be made that the EJB events pertaining to the EJB method calls made during a servlet request are generated no later than the servlet event pertaining to the completion of the servlet request.",{"@attributes":{"id":"p-0084","num":"0095"},"figref":["FIG. 3","FIG. 3"],"b":["0","130","1","0","1","3","2","6"],"sub":"N"},"Let us assume that the polling rate is sufficiently high that, between two successive polls, at most one request to servlet A can complete. The counter N corresponds to the total number of requests to servlet A that have completed since the polling began (i.e., since time ). The counter Trecords for servlet A the average execution time of a request to the servlet. After each new request to servlet A, the value of the counter N and Tare updated by the Web Application Server. The retrieved values of the counters N and Tat the end of each of the polling times (PE, PE, PE, PE, and PE) are catalogued in the table shown below the timeline in . The determination of the execution time Xof each request from N and TN values is described above. The third request to the servlet finishes only after the poll PE is complete. Thus PE returns the values of counters that existed at the end of PE.","At the end of each poll the PMI client agent generates events for servlet A. These events are sent to the management clients  (see ). No event is sent after the completion of poll PE because no servlet request has completed during the interval [6, 9] between PE and PE, and hence there has been no change in the counter values. Thus, only when the corresponding counter values change are any servlet or EJB events generated. For example, just after time PE a servlet event will be generated that will carry the following fields: (1) an identifier for the servlet, which in this case is \u2018A\u2019, (2) time stamp TS, which in this case is \u20183\u2019, (3) the retrieved value of counter N, which in this case is \u20181\u2019, and (4) the retrieved value of the counter TN, which in this case is \u20180.5\u2019. Likewise, a servlet event is generated just after each of the remaining times PE, PE, and PE. The third event, generated just after time PE and having time stamp TS=12, corresponds to the third servlet request having execution time X=2.0. It is desired to calculate the \u2018activity period\u2019 corresponding to this request. The request ends at time 9.5, but this time is not known. Instead, the timestamp TS of the event is known, and from this it is possible to determine the time interval in which the request has completed which is [TS\u2212PI, TS] or [9, 12]. The covering interval or \u2018activity period\u2019 of the request is then [TS\u2212PI\u2212X, TS] or [7, 12]. Table 1 below shows the request counter value N, average response times T, execution times Xand event time stamps TSfor a number of polling times as shown in .",{"@attributes":{"id":"p-0087","num":"0098"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"42pt","align":"center"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"5","align":"center","rowsep":"1"}}]},{"entry":[{},"PE1(=3)","PE2(=6)","PE3(=9)","PE4(=12)","PE5(=15)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"5","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"42pt","align":"char","char":"."}},{"@attributes":{"colname":"6","colwidth":"42pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["N","1","2","2","3","4"]},{"entry":["T","0.5","1.0","1.0","4\/3","6\/4"]},{"entry":["X","0.5","1.5","\u2014","2.0","2.0"]},{"entry":["TS","3","6","\u2014","12","15"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}]}}},"In the case of SQL events, as opposed to the servlet and EJB events, the start and end time of every SQL request is known. Therefore, it is possible to determine the \u2018activity period\u2019 of each SQL request precisely, as:\n\n","An existing database monitoring interface can be used instead of Java Database Connectivity (JDBC) instrumentation, and yet it remains possible to obtain SQL information to construct such exact activity periods for SQL requests.","Whether a servlet, EJB, or an SQL event, references herein to the end time or start time of an event mean the end time or start time, respectively, of the activity period represented by the event. Every event carries a time stamp that equals the end time of the activity period that the event represents.","Dependency Extraction","A method and algorithn for extracting dependency relationships from monitoring data is now described. Also described is a problem-determination application's solution to falsely-identified dependencies.","In the description below, services and components that depend on other services or components are referred to as \u2018dependents\u2019. Services and components on which other services or components depend are termed \u2018antecedents\u2019. In the dependency graph model of the distributed system, each resource or component is represented as a node and a dependency between nodes is represented as a directed edge or link. Attributes are maintained for each node to capture its runtime status. Weightings are calculated at run-time for the identified dependency relationships represented by edges.","Dependency Definitions","Consider any two components, such as a servlet A and an EJB B for example. In the general case, A is said to be dependent on B if B's services are required for A to complete its own service. A weight may also be attached to the directed edge from A to B. Weightings may be interpreted in various ways, but in this specific implementation weightings are a quantitative measure of the extent to which A depends on B (i.e. a measure of the extent to which A may be affected by unavailability or poor performance of B). Any true dependency between A and B arises from an invocation of B from A, which may be synchronous or asynchronous. The example method described below handles synchronous invocations only but alternative embodiments, such as those identifying correlations between the numbers of component invocations instead of contained activity periods, may handle asynchronous invocations.","An activity period [b, b] of the component B is said to be contained in an activity period [a, a] of the component A if a\u2266b and b\u2266a. As mentioned above, the activity periods of a component are assumed to have a one-to-one correspondence to the service request start and completions for that component, for simplicity. Therefore, for each service request completion for a component, the component's activity period can be computed from the corresponding event received at the Correlation Identifier (in ). If there is determined to be a \u2018probability\u2019 p that a given activity period of A contains an activity period of B, the definition of dependency between the two components A and B is as follows:\n\nA depends on B with probability p (or A\u2192B)\n","The above definition of containment of an activity period into another period captures the following dependency type:\n\n","A dependency of the above type is called a true dependency. Any other type of dependency that is captured by our dependency definition is called a false dependency. A motivation for the definition for p given above is that the number p comes very close to the probability that a given execution of A invokes, directly or indirectly and at least once, the component B, and finishes only after the invocation to B returns.","If A calls B's methods on each request to A then, according to the above definition, p is 1.0. If only 20% of the requests to A result in calls to B then p is 0.2. Multiple calls or containment of activity periods of B per request to A are counted as a single call to B.",{"@attributes":{"id":"p-0098","num":"0111"},"figref":["FIG. 4","FIG. 4","FIG. 4"],"b":["1","1","1","1","2","2","2","1","1","2","2","1","1","1","1","1","1","1","1","1","1","2","1","1","2"]},"Similarly, the dependencies of Servlet S are S\u2192SQ and S\u2192SQ, both of which are true dependencies. The dependency definition presented above assumes, for simplicity, a synchronous invocation model where A does not finish executing until all its invocations of B return.","A method (and an algorithmic representation of the method) is presented below for computing the dependencies for any given component, based on the definition above. The true dependencies for the given component include all the components that are directly and indirectly invoked by the given component. The method can also be expected to compute \u2018false\u2019 dependencies.","Referring to , a two-level dependency graph may be generated using the above definition of a dependency, which graph has a node at level one with all its true and false dependencies situated at the second level.  shows a two-level dependency graph for Servlet S of . Looking at only the two-level graph of a component suffices because all the components on which the current monitored component is dependent (i.e. the antecedent nodes) are captured at the second level of the graph, and there is no need to traverse the two-level graphs of any of the antecedent nodes. Furthermore, the transitive property of dependencies may not hold in general, and so a two-level graph helps to consider only the true dependencies of a component.","Referring to  and 5 and the dependency relationships of servlet S, S invokes EJB E each time the servlet S is active, and EJB E in turn executes SQL SQ twice. A directed edge from S to E, for example, states that S depends on E; and the edge label is an empirical value representing the \u2018likelihood\u2019 that a dependency relationship exists (the value of p for this dependency). In , the true dependencies of servlet S include the antecedents EJB E and the SQL SQ. The edge label for the dependency S\u2192E is 1.0 because the proportion of the activity periods of S that contain at least one activity period of E is 1.0 (for the current monitoring period). In , the servlet S does not execute SQL SQ, but SQ occurs in the set of dependencies for S due to false containment.","The calculated \u2018probability\u2019 value, p, in A\u2192B (referred to hereafter as the \u2018p-value\u2019) depends on the business logic in A and the workload applied to the enterprise environment containing the component A. If the logic and the workload change, the p-value may also change. Assuming that the logic and the workload do not vary with time, the Correlation Identifier  (see ) estimates the p-value from event traces. From the definition of the p-value given above and the event traces received for both A and B, the p-value is determined by calculating the proportion of the activity periods of A that contain at least one activity period of B. That is, let #A denote the total number of activity periods of A seen so far, and #(B, A) denote the total number of activity periods out of #A that contain at least one activity period of B. Then the number #(B, A)\/#A is an estimate of the p-value. As new events are received at the CIM repository  (see ) the method generates and updates the dependency graph automatically.","Dependency Extraction Method and Algorithm","A dependency extraction method and algorithm are presented herein informally, referring to servlet and SQL events by way of example only (without any intended limitation). Let \u03a3denote the set of all SQLs and \u03a3denote the set of all servlets in a given Web application. Let A \u03b5 \u03a3. The method sets out to discover and update all dependencies A\u2192B, where B\u03b5\u03a3.","A property that the method uses (which property can be assumed to be satisfied by the system of ) is that the events from a given component (say servlet A) are received at the Correlation Identifier in the increasing order of their time stamps. As noted previously, the time stamp of an event is defined as the end time of the activity period represented by the event. This also implies that SQL events received at the Correlation Identifier are in the increasing order of their time stamps.","Some definitions are presented here, to enable interpretation of the algorithmic representation of the method.\n\n","The following event lists are maintained in the CIM repository:\n\n","The dependencyList variable keeps the list of all those SQLs in \u03a3for which dependencies have been detected so far.\n\n","The dependency extraction algorithm is presented below in a pseudo-code form. Based on the type (servlet or SQL) of the next event E receives, the following tasks are performed:","Main Algorithm",{"@attributes":{"id":"p-0110","num":"0133"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"1. E of type servlet event:"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"a. Add E to the end of dependentList"]},{"entry":[{},"b. if LPP is null then"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"i. \u2009set LPP to E"]},{"entry":[{},"ii. increment #A by 1."]},{"entry":[{},"iii.computeHSQ( ), return,"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"c. else \/* LPP is not null *\/"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"i. \u2009if HSQ is null then return"]},{"entry":[{},"ii. if HSQ.next or LPP.next is null then return,"]},{"entry":[{},"\u2003\u2002else set LPP to LPP.next, increment #A by 1,"]},{"entry":[{},"\u2003\u2002updateDependencies( ), computeHSQ( ), goto 1.c.ii"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"2. E of type SQL event:"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"a. Add E to the end of antecedentList"]},{"entry":[{},"b. if LPP is null then return"]},{"entry":[{},"c. computeHSQ( )"]},{"entry":[{},"d. if HSQ.next or LPP.next is null then return,"]},{"entry":[{},"\u2003\u2002else set LPP to LPP.next, increment #A by 1,"]},{"entry":[{},"\u2003\u2002updateDependencies( ), goto 2.c"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The main algorithm above includes the following subroutines:",{"@attributes":{"id":"p-0112","num":"0135"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"computeHSQ( )"]},{"entry":[{},"1. if antecedentList is empty then return,"]},{"entry":[{},"\u2003\u2002else set tempList to antecedentList if HSQ is null or to the"]},{"entry":[{},"\u2003\u2002portion of the event list after HSQ (i.e., those SQL events"]},{"entry":[{},"\u2003\u2002that have time stamps greater than or equal to the"]},{"entry":[{},"\u2003\u2002HSQ.timestamp)"]},{"entry":[{},"2. while there is a next event to process in tempList"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"a. set temp to the next event in tempList"]},{"entry":[{},"b. if temp.timestamp > LPP.timestamp then return"]},{"entry":[{},"c. checkContainment(LPP, temp), HSQ = temp"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"3. return"]},{"entry":[{},"updateDependencies( )"]},{"entry":[{},"1. tempHSQ = HSQ"]},{"entry":[{},"2. if tempHSQ.timestamp < LPP.starttime then return"]},{"entry":[{},"3. checkContainment(LPP, tempHSQ), goto 2"]},{"entry":[{},"checkContainment(depEvent, antEvent)"]},{"entry":[{},"1. if depEvent.timestamp \u2267 antEvent.timestamp and"]},{"entry":[{},"\u2003\u2002depEvent.starttime \u2266 antEvent.starttime then add antEvent.id"]},{"entry":[{},"\u2003\u2002to dependencyList if not already done, increment by 1 the"]},{"entry":[{},"\u2003\u2002counter #(antEvent.id, A), corresponding to dependency"]},{"entry":[{},"\u2003\u2002A\u2192antEvent.id,"]},{"entry":[{},"2. return"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The main algorithm shown above preserves the following properties:\n\n","In the non-boundary case (i.e. when both LPP and HSQ are not null), on an arrival of an SQL event with time stamp less than LPP.timestamp, HSQ is set to this event; otherwise LPP is set to LPP.next (i.e. to the next servlet event, whenever it becomes available) and the count #A is incremented by one. In the latter case, the method continues to scan the SQL events earlier than the event pointed to by HSQ until an SQL event is reached which has an end time earlier than the start time of the new servlet event pointed to by LPP; thereafter the method scans the later SQL events to compute the new value for HSQ. Each time an SQL event is compared with the servlet event pointed to by the LPP, the method also checks for containment of the activity period of the SQL event within the servlet event, updating the dependencyList and corresponding frequency counts if required. This process is repeated with the new LPP and HSQ. The method outputs estimates of p-values by computing for each SQL B in the dependencyList the number #(B, A)\/#A.","The above dependency extraction method has a desirable property that the number of event comparisons needed in order to ascertain all the probable dependencies is relatively low. If n is the number of activity periods contained in a given activity period, the number of event comparisons required to determine the set of probable dependencies is a linear function of n, represented as O(n).","Problem Determination using Probabilistic Graph","As discussed above, a dependency graph may be used to identify the root cause of a problem, which is visible at a high level, such as an end-user response time violation of a client transaction. It is assumed that the node state can be examined and a determination made at run-time of whether the node has a problem, and the assumption is valid for response-time related problems. A problem at a node will manifest itself in its parent nodes and thus appears as a end-user problem or Service Level Agreement (SLA) violation. A systematic top-down traversal of a graph is performed to visit the nodes in some order until a node is reached which shows a problem by its state, but whose children do not have a problem. For example, if it is observed that a particular URL's response time is higher than usual (a possible SLA violation), then a component dependency graph may be used to identify whether the problem lies in the servlet code (that services the URL) or in any of the EJBs or SQLs called by the servlet.","Root cause analysis using dependency graphs is described in a number of references including the paper by B. Grushke \u201cIntegrated Event Management: Event Correlation Using Dependency Graphs\u201d (DSOM '98, referenced above). In a simple root cause analysis, a depth-first or breadth-first traversal of the graph can be performed to identify such nodes. The edge weights may or may not be used in deciding the traversal order. The following paragraph describes how dependency edge weights may be used to decide the traversal order of edges in the two-level graph of a component.","The presence of false dependency edges in a two-level graph complicates the traversal problem. The edge weights represent the computed \u201clikelihood\u201d of A depending on B. False dependencies may be identified from containment of activity periods due to concurrency of transactions flowing through the components of the server. Additionally, there may be certain components that tend to be active at the same time without a true dependency relationship. For example, a significant percentage of users may choose to invoke \u201csearch\u201d immediately after going to the \u201cmain page\u201d of a site. Therefore, it is likely that the activity periods of some of the components invoked by the servlet servicing the main page request will overlap with some invocations of the servlet servicing the search request, and vice versa. This may result in detection of false dependencies (based on the above definition) for both servlets.","Clearly, traversal of false dependencies reduces the performance of a Problem Determination algorithm and increases the Mean Time To Recovery.","In order to optimize the search from any node A to its root causes, the dependencies of A in its two-level graph are sorted into a decreasing order of the p-value. This decreases the likelihood of having to investigate an antecedent node that is actually a false dependency, based on the premise that most of the true dependencies will precede the false ones in the traversal order. If A's problem is due to a component on which it depends, then as the dependencies of A are investigated (in the descending order of the p-value), the Problem Determination application stops when it encounters a problem component. This should avoid the Problem Determination application continuing to process all identified dependencies including false ones.","However, the specific workload of the monitored system may be such that the empirical probability of a false dependency can be higher than that of a true dependency. For instance, A may have a true dependency on B, but if A invokes B only 5% of the times that A is active, then p is 0.05 and a false dependency could have a higher p-value. In order to further decrease the likelihood of having to look at false dependencies during problem determination, another statistic can be used as described below.","Improved Traversal Order for Problem Determination Applications","Additional statistics and heuristic transformations of the basic \u2018probability\u2019 values may be used by a Problem Determination application to avoid investigating false dependencies during root cause analysis. In particular, a \u201creverse probability\u201d of a dependency A\u2192B, called the r-value, may be used. Both the p-value and the r-value are used together to sort the dependencies in the two-level graph of a node so that the likelihood of a true dependency being higher in the sorted list is more than simply sorting based on only the p-value.","Conceptually speaking, the r-value is similar to the definition of p-value. We define the r-value as the probability that a given activity period of the component B is contained in an activity period of the component A, where the definition of containment is as described earlier. We estimate the r-value as follows. Let, (\u03c6(A, B) denote the number of activity periods of B, seen so far, which were found to be contained in at least one activity period of A. Finally, let #B be the total number of activity periods of B seen so far. We take the number p(A, B)\/#B as an estimate of r-value. To see the difference between p-value and r-value, consider the earlier example in which A invokes B only 5% of the time A is active. Suppose A is the only component that invokes B in the application, then the p-value will be close to 0.05 whereas the r-value will be close to 1.0. Another illustration of the difference between p and r-values is given in Table 1. The algorithm for computing p-values given above can be tailored to compute the r-values as well.","We then sort the dependencies at node A in the non-increasing order of:\n\nmax()+\n","This heuristic uses the two statistics to effectively transform the weights (or computed probabilities) of all dependencies of a node. The dependencies of a node are then sorted in non-increasing order of these new weights. The rationale for choosing the heuristic is the following. The first term coarsely sorts the dependencies of a node so that edges with high p- or high r-values are catapulted up in the order. A dependency is more likely to be true if at least one of these is high. The product term, pr, performs finer grain sorting among equals. A dependency is more likely to be true if both p- and r-values are high compared to the case when only one of the values is high.","However, the heuristic \u2018max(p, r)+pr\u2019 penalizes the true dependencies which have low p- and r-values. For example, if a servlet X executes an SQL Y rarely, but the SQL Y is frequently executed by some other servlets in an application, then the dependency Y of X will appear lower down in the sorted list of dependencies of X, because both p and r values will be small. However, there is an increased likelihood that if the problem in X is due to Y, then other servlets that more frequently call Y also have the same problem and we are able to identify Y through one these servlets.","Other such heuristics may be used to transform the basic weight values in a system-specific Problem Determination application. The presence of false dependencies can be coped with at the management application level.","Table 2 below shows the p- and r-values of some of the dependencies of Servlets S and S, in the example in , at two polling times T and T. Note that by time T only two requests\u2014one from S and one from S\u2014have completed; and by time T, two requests from S and one request from S have completed.",{"@attributes":{"id":"p-0129","num":"0154"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"center"}}],"thead":{"row":{"entry":[{},"TABLE 2"]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]},{"entry":[{},"Dependencies with their p- and r-values"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"42pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["Polling","S1 \u2212> SQ1","S1 \u2212> SQ2","S2 \u2212> SQ1","S2 \u2212> SQ2"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"9"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"8","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"9","colwidth":"21pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["times","p","r","p","R","p","r","p","r"]},{"entry":{"@attributes":{"namest":"1","nameend":"9","align":"center","rowsep":"1"}}},{"entry":["T1","1.0","\u2154","1.0","1.0","1.0","\u2153","1.0","1.0"]},{"entry":["T2","\u2158","\u00bd","1.0","1.0","1.0","\u2155","1.0","1.0"]},{"entry":{"@attributes":{"namest":"1","nameend":"9","align":"center","rowsep":"1"}}}]}}]}}},"Described below is an experimental evaluation which shows positive results for the above-described heuristic, max(p,r)+pr, for a benchmark application. The pathological case described above occurs only infrequently.","Experimental Evaluation","The dependency algorithm described above has been evaluated experimentally. The test system setup is described below, followed by measurements for accuracy, precision, and overhead of the algorithm.","The test system comprises three machines, such as represented in . IBM Corporation's WebSphere Application Server v4.0 software (Web application server ) and DB2 v7.1 software (database server ) are installed on a first computer (2 GHz processor, 1 GB memory) at layer  of . A second computer (600 MHz processor, 512 MB memory\u2014also at layer ) is used to run a browser emulator or TPC-W request generator  (see below) and send URL requests to the first computer. The first computer also runs an HTTP server. A third computer (2 GHz, 1 GB) at layer 80 in  runs a CIM Object Manager  and the dependency generator  which includes the correlation identifier. The computers are connected over a 100 Mbps Ethernet connection.","The test system uses the known TPC-W bookstore application from University of Wisconsin as a benchmark application for evaluating the algorithm. (TPC-W is selected because the application has a sufficient number of dependencies for preliminary investigation purposes, without having a complicated program structure. Furthermore, TPC-W is easy to instrument and enables easy comparison between results achieved using the above-described algorithm and ideal results. The simplicity in structure and presence of only servlet-to-SQL dependencies facilitates analysis and debugging the mining-based approach. Although the above-described algorithm can tackle dependencies involving EJBs, there are no EJBs in the TPC-W application.) The University of Wisconsin's TPC-W application implementation is written in the Java(\u2122) programming language and comprises  servlets,  SQL servlets and a database of 10,000 books. At the time of writing.","TPC-W provides three types of Web communication traffic mixes, as follows:\n\n","Unless otherwise specified, MIX is used in the experiments described below, for larger graph coverage within a given time period. The experiments involve applying the methods described above to discover the dependencies between servlets and SQLs. In the test system, there are 54 true servlet-to-SQL dependencies out of potential set of 644 dependencies.\n\n","The contribution of weight coming from false dependencies, from the total w, is defined as:",{"@attributes":{"id":"p-0137","num":"0167"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["w","f"]},"mo":":=","mrow":{"munder":{"mo":"\u2211","mrow":{"mrow":[{"mi":["i","m"],"mo":"<"},{"mi":["i","is","a","false","Dependency"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]}],"mo":","}},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mi":["m","i"],"mo":"-"}}}}}},"ul":{"@attributes":{"id":"ul0024","list-style":"none"},"li":{"@attributes":{"id":"ul0024-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0025","list-style":"none"},"li":"Percentage node-precision is defined as: 100 (1-(w\/w))"}}}},"The above definition of the Percentage node-precision penalizes a false dependency more if the false dependency occurs higher in the list. The precision value reported in the following experiments is the mean percentage node-precision over the 14 servlets.","Accuracy and precision are measured on the test system as follows. The TPC-W application is instrumented with a transaction correlation program to find the actual set of the dependencies that should be discovered at each point in time as user transactions flow through the system. Thus accuracy and precision can be computed at each time point by comparing the dependency information generated by the above-described dependency algorithm with information generated in the same experiment by the instrumented transaction correlation program.",{"@attributes":{"id":"p-0140","num":"0171"},"figref":["FIGS. 7A-B","FIGS. 7A-B","FIGS. 7A-B","FIG. 7A"]},"Accuracy and Precision for TPC-W Bookstore Application","A factor which may significantly impact the performance of the dependency algorithm is the degree of concurrency in the system. If multiple transactions proceed simultaneously, difficulties arise when trying to separate true dependencies from false dependencies using containment relationships.","The degree of concurrency of transactions on a Web Application Server may be increased by increasing the number of simultaneous customers or Web Browser emulators, thus keeping more threads in the available thread pool simultaneously active. The Web Application Server is configured to fork threads on demand with a minimum of 25 pre-forked threads. As customer load is increased, the number of simultaneously active threads grows, and the thread pool size is also automatically increased by the system beyond 25 if needed.","Table 3 shows the variation of accuracy and precision values with increasing customer load and concurrency (for traffic MIX). The number of customers is increased until a significant percentage of URL requests timed out due to high workload. The Web Application Server machine used in the experiment was able to support up to 200 customers and so the experiments have been run up to 200 customers as a high load case. At 200 customers load-level, the client emulator which sends requests to the application program via the Web application server generates around 450-500 requests per minute. Each experiment was run for one-hour duration. It is likely that precision values could be increased by running experiments for longer periods.",{"@attributes":{"id":"p-0144","num":"0175"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 3"},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["Load:","#Avg active threads","Mean Precision %","Accuracy"]},{"entry":["# Customers","(Avg thread pool size)","(std dev \u03c3)","%"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["5","2.2","(25.0)","100","(0)","100"]},{"entry":["25","3.5","(25.0)","99.94","(0.22)","100"]},{"entry":["50","4.6","(25.0)","98.33","(3.12)","100"]},{"entry":["100","10.6","(25.0)","81.86","(21.00)","100"]},{"entry":["150","17.1","(26.4)","71.52","(32.43)","100"]},{"entry":["200","20.0","(31.9)","62.62","(26.82)","100"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}]}}},"Table 4 shows the effect of the Performance Monitoring Infrastructure polling rate on precision and accuracy with a fixed load of 100 customers. The results in Table 4 show precision to be more sensitive to polling rate than accuracy. At lower polling rates, even though accuracy is 100% and the management overhead reduces, the precision also reduces. At higher load, a high polling rate is required to maintain high precision, but the overhead is also increased and such increases are undesirable at high load.",{"@attributes":{"id":"p-0146","num":"0177"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"91pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"77pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 4"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Polling interval","Mean Precision","Accuracy"]},{"entry":["(milliseconds)","% (std dev \u03c3)","%"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"91pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"77pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["50","88.71 (18.75)","100"]},{"entry":["100","81.86 (21.00)","100"]},{"entry":["500","71.03 (29.82)","100"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"The algorithm results showed 100% accuracy under all loads. Precision values decrease with increasing load. The standard deviation (v) for precision is low at low loads but rises at higher loads. Dependency extraction can be performed at low to medium loads and stopped, if the precision level of the graph is to be maintained. The operating load range of the algorithm may be determined by the acceptable level of precision, which may be objectively decided by the acceptable latency in computing the root cause of a problem. A lower precision typically leads to a higher latency in root cause computation.","Table 4 shows the variation of accuracy and precision at a fixed load of 100 customers by varying the Performance Monitoring Infrastructure (PMI) polling rate. A higher polling rate leads to increased management overheads. Table 5 shows preliminary overhead measurements, in terms of percentage increases in transaction response time and throughput, when dependency extraction is active, by varying the customer load and PMI polling interval. Each reading corresponds to an experiment run for 3 hours.",{"@attributes":{"id":"p-0149","num":"0180"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"center"}}],"thead":{"row":{"entry":[{},"TABLE 5"]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]},{"entry":[{},"Polling Interval (milliseconds)"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"84pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"100","500"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Simultaneous","Throughput","Response","Throughput","Response"]},{"entry":["Customers","(%)","Time (%)","(%)","Time (%)"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["10","2","10","0","3"]},{"entry":["200","9","33","8","25"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"The embodiments of the invention described in detail above enable discovery of dependencies between system components using non-intrusive techniques. A system and method according to one embodiment of the invention can discover dependencies between any two monitored components in a managed system without any changes or modifications to the existing source code or executables comprising the managed system. The dependencies are constructed using only the data accessible from the managed system, such as logs and performance metrics, and this data is retrieved from the managed system by agents that poll the managed system for changes in state, or subscribe to events from the system.","The amount of manipulation of monitoring data performed by a monitoring agent depends on the specific implementation of the invention. If an agent is running on the same CPU as the monitored system, any computation by the agent imposes a processing overhead on the CPU. However, if the agent runs on a different CPU from the correlation identifier, network communication overhead is imposed by the sending of events from the agent to the management server running the correlation identifier. One embodiment balances these factors by the agent performing aggregation, such as averaging, and batching events to reduce network overhead. Alternative trade-offs between the processing overhead of the CPU of the monitored system and network communication overheads may be implemented by varying the amount of processing performed by the agents, the correlation identifier and the dependency aggregator.","According to the embodiment, a dependency generator identifies correlations between the run-time activity of logical components and uses the correlation results to generate estimates of the dependencies between the monitored components. The run-time activity data may include the number of requests made to a monitored component, the average response time of a monitored component so far, or other activity metrics. One dependency generation method requires an estimate of only the activity periods of the two components under consideration\u2014which activity periods are estimated from the monitored run-time activity data. A \u2018probability\u2019 of a dependency is estimated from the consistency with which the monitoring data shows a positive correlation between components and, in some cases, also by reference to the attributes of the components. This estimate is updated as and when new data becomes available. The dependency extraction method does not rely on any specific measure of the probability of a dependency between components.","The computed \u2018probability\u2019 value, representing the consistency of identification of a positive correlation between a first component and a second component, can be updated from a Current Estimate value to a New Estimate value according to the result of comparing the run-time activity data of the first and second component for each execution of the components. In one embodiment, this update is in accordance with the rule:\n\nNewEstimate=CurrentEstimate+StepSize[Target\u2212CurrentEstimate]\n\nwhere StepSize is the inverse of the total number of executions of the second component and Target is 1 if the comparison of the run-time activity data of the first and second component for the current execution results in a positive identification of a dependency relationship, and 0 otherwise.\n","One example statistic for estimating a \u2018probability\u2019 of dependency is the p-value (described above). Alternatively, a function of the two statistics r-value and p-value together can be used as a measure of the \u2018probability\u2019 of the dependency.","The update procedure for the p-value for a dependency is of the form:\n\nNewEstimate=CurrentEstimate+StepSize[Target\u2212CurrentEstimate],\n\nwhere StepSize is the inverse of the total number of activity periods of the antecedent component and Target is a function of the activity periods of the antecedent and the dependent in the preferred embodiment. Target is I if the antecedent's activity period is contained in the activity period of the dependent in the preferred embodiment, otherwise the Target is 0. A similar update procedure can be applied to the r-value, except that the StepSize is then the inverse of the total number of activity periods of the dependent component.\n","The dependency results may be used by a number of different systems management applications such as visualization, root cause analysis for problem determination or impact analysis such as for determining the effects of taking system components off-line (for maintenance or upgrades). Containment of computed activity periods for logical components has been found to provide a good basis for discovering dependencies between synchronous components of a distributed system, but the method may also discover false dependencies. To reduce the likelihood of a problem determination application investigating false dependencies, a sorting heuristic may be used to increase the probability of true dependencies appearing high in a sorted list. Such sorting methods may use attributes such as the frequency of invocation of a component, or attach higher significance to apparent dependencies discovered when the monitored system is under light load conditions. In particular, a higher weightings can be applied to dependency results discovered when a small number of processes are running concurrently in the monitored system, or results discovered during high load conditions may be filtered out.","Alternative embodiments of the invention discover correlations between run-time activity metrics other than activity period containment to determine probable dependencies\u2014such as discovering correlations between the frequency of execution of the components or the average execution period of the components. If there is a correlation between increases or decreases of average execution period for two components, and those increases or decreases are not explained by increasing or decreasing load, then it is likely that the two components are dependent on each other or share a dependency relationship with another component or resource.","Methods according to the invention may include a consideration of which of the identified dependency relationships are sufficiently consistently identified to be reported as dependencies. Weightings may be determined by combining the results of correlation comparisons for a plurality of different run-time activity characteristics and used to sort the dependencies in order, or computed \u2018probability\u2019 values may be compared with a minimum threshold value.","As will be understood by persons skilled in the art, additional modifications or additions may be made to the specific methods, apparatus and computer programs described in detail above without departing from the scope of the invention as set out in the claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF DRAWINGS","p":["Embodiments of the invention are described below in detail, by way of example, with reference to the accompanying drawings in which:",{"@attributes":{"id":"p-0028","num":"0034"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0029","num":"0035"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0030","num":"0036"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0031","num":"0037"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0032","num":"0038"},"figref":["FIG. 5","FIG. 4","FIG. 5A","FIG. 5B"],"b":"1"},{"@attributes":{"id":"p-0033","num":"0039"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0034","num":"0040"},"figref":"FIG. 7A"},{"@attributes":{"id":"p-0035","num":"0041"},"figref":"FIG. 7B"}]},"DETDESC":[{},{}]}
