---
title: System, method, and computer program product for optimizing the management of thread stack memory
abstract: A system, method, and computer program product for optimizing thread stack memory allocation is disclosed. The method includes the steps of receiving source code for a program, translating the source code into an intermediate representation, analyzing the intermediate representation to identify at least two objects that could use a first allocated memory space in a thread stack memory, and modifying the intermediate representation by replacing references to a first object of the at least two objects with a reference to a second object of the at least two objects.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09411715&OS=09411715&RS=09411715
owner: NVIDIA Corporation
number: 09411715
owner_city: Santa Clara
owner_country: US
publication_date: 20121212
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The present invention relates to compilers, and more particularly to optimizations in memory allocation.","Local memory available for execution of a program is an important resource in a system architecture. Proper management of that resource is crucial to efficient execution of the program. Ideally, during execution of the program, only memory that includes data for current instructions and future instructions is allocated, while any memory containing data used in previously executed instructions is deallocated and returned to a free memory pool. Certain memory may be managed by a programmer, such as by using the malloc and free instructions in a program written in C++, in order to allocate and free blocks of memory explicitly.","However, in the case of a thread stack memory (i.e., a portion of memory allocated to a program thread that acts as a last-in, first-out (LIFO) queue), the programmer typically does not manage the thread stack memory. Instead, the thread stack memory is allocated dynamically as the program executes. Current compilers do not often address optimizations for efficient management of the thread stack memory. Thus, there is a need for addressing this issue and\/or other issues associated with the prior art.","A system, method, and computer program product for optimizing thread stack memory allocation is disclosed. The method includes the steps of receiving source code for a program, translating the source code into an intermediate representation, analyzing the intermediate representation to identify at least two objects that could use a first allocated memory space in a thread stack memory, and modifying the intermediate representation by replacing references to a first object of the at least two objects with a reference to a second object of the at least two objects.","Some conventional compilers optimize allocation of registers by performing data-flow analyses and ordering program instructions in a manner such that certain registers can be reused to store different values at different times in the program execution. A compiler typically translates the source code (e.g., a program written in a high-level language such as C++) into an intermediate representation (IR), which is a data structure that represents the meaning (including the execution order) of the program. The IR may be an intermediate language for an abstract machine. The IR enables the compiler to perform data-flow analysis and rearrange the order of the program before generating the machine-code to be executed by a processor.","The optimizations described above in connection with register allocation cannot be applied in the same way to larger memory structures in the thread stack. The objects allocated in the thread stack may be variable in size. In contrast, registers have a well-defined size, such as 32 bits. When a value is stored in a register by an instruction included in a program, the value necessarily overwrites all data previously allocated to that register. Objects in the thread stack memory behave differently. When a value is stored in an element of an object, such as one entry of an array, the value overwrites the data that was previously stored in that entry. However, the other entries of the object may still be valid and allocated to the data that was previously stored in the object. A data-flow analysis that attempted to track every entry in the thread stack would become very complex and the optimizations that would be able to be achieved may not be effective.","The algorithm described below performs a different type of data-flow analysis that tracks whether objects allocated to the thread stack memory (i.e., stack allocated objects) are \u201clive\u201d in different parts of the program. The following definitions are used throughout the present disclosure. In the context of the present description, an object is live at a certain point (i.e., instruction) in the program if the data that is stored in the object is potentially needed by the current instruction or a future instruction. An object's def is an instruction that stores data in the object. Examples of an object's def include a store instruction, an instruction having a variable on the left hand side (LHS) of the instruction that points to the object, etc. The instruction does not need to overwrite the entire memory allocated to the object, but merely needs to write data into a portion of the object. The allocation of memory for an object is not an object's def (because the data in the object is not initialized). An object's use is an instruction that uses a variable that has access to the stack allocated object. Examples of an object's use include a load instruction, a binary operation involving a pointer to the object, etc.",{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1","b":["100","102","104","106"]},"At step , the compiler modifies the IR by replacing references to a first object of the at least two objects with a reference to a second object of the at least two objects. In one embodiment, when two stack allocated objects may be allocated to the same memory space, the compiler will replace instructions that point to the smaller object (i.e., in terms of memory size allocated to the object) with new instructions that point to the larger object. It should be noted that, while various optional features are set forth herein in connection with optimizing allocation of a thread stack memory, such features are set forth for illustrative purposes only and should not be construed as limiting in any manner.",{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 2","FIG. 2"],"b":["200","200","210","201","202","203","201","202","203","210","210","201","201","202","210","201"]},"In one embodiment, the program  is a text file (e.g., ASCII text) that includes a plurality of instructions in a human-readable format. The program  may be written in a high-level programming language such as C++. The IR  includes representations of the plurality of instructions from the program  abstracted out into a plurality of instructions in the intermediate language. For example, the intermediate language may be TAC and each instruction of the IR  represents one fundamental operation of the target processor (e.g., binary operations, logical operations, load\/store operations, etc.). An instruction in program  may not be able to be executed in a single clock cycle. For example, a binary operation such a \u201cD=A+B+C\u201d may not be able to be executed by the processor in a single clock cycle. Therefore, in the intermediate language, the instruction set forth above may be broken down into two instructions in the intermediate language (e.g., a first instruction \u201cT1=A+B\u201d and a second instruction \u201cD=T1+C\u201d).","Once the compiler  has generated the IR , the compiler performs a data-flow analysis on the IR . For example, the compiler  may rearrange the order of instructions in the IR . By changing the order of instructions, the compiler may be able to allocate memory in the thread stack in a more efficient way, reusing the same memory locations for different variables in the program . The compiler may analyze the rearranged instructions to find variables that can be assigned to the same memory object, and modify the instructions in the IR  such that different variables in the program  can reuse the same memory object in the thread stack. Once the compiler  has modified the IR  and made certain optimizations to the code, the compiler  compiles the IR  to generate the machine code  for execution by the processor.",{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 3A","FIG. 3A"],"b":["201","201","201","201","201","201","201","201","201"]},"The main body of the function g comprises an If . . . Else statement. A first block (i.e., lines 10-15 of the program ) of the If . . . Else statement is executed when parameter n is less than parameter m. A second block (i.e., lines 17-25 of the program ) is executed when parameter n is greater than or equal to parameter m. Then, the value of the variable result is returned by the function. Examining the If . . . Else statement in more detail, one of skill in the art will notice that the array A is initialized in the first block within a first for loop (i.e., lines 10-12 of the program ) and then a plurality of values of A are added to the variable result within a second for loop (i.e., lines 13-15 of the program ). The array B is initialized in a third for loop (i.e., lines 17-19 of the program ), the array C is initialized in a fourth for loop (i.e., lines 20-22 of the program ), and then every kvalue of B is multiplied by every kvalue of C and added to the variable result within a fifth for loop (i.e., lines 23-25 of the program ).","It will be appreciated that, each time function g is called by a thread, the function will execute either the first block or the second block of the If . . . Else statement, but not the first block and the second block. In other words, during execution, either the array A will be defined and used in one or more instructions, or the arrays B and C will be defined and used in one or more instructions, based on the conditional statement (\u201cn<m\u201d). Advantageously, the compiler may optimize the IR  for program  such that array A and either array B or array C may be allocated to the same object in the thread stack memory. In contrast, because array B and array C may be live at the same point in the program (e.g., in the fifth for loop values from both array B and C may be used as operands in the same instruction), the arrays must point to different objects in the thread stack memory. More generally, if two objects are not live at the same point in the program, then the two objects may be allocated to the same memory space having a size at least as large as the size of the larger of the two objects. In other words, a portion of the thread stack memory is allocated once and used by both objects. Since scalar values are typically allocated to registers by the compiler, objects allocated to the thread stack memory are typically arrays or aggregate values that are larger than the width of a single register.",{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 3B","FIG. 3A","FIG. 3B"],"b":["202","201","210","201","202","202","202","202","201","202","201","201","202","201","201","201","201","201"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 3C","FIG. 3B","FIG. 3C","FIG. 3B","FIG. 3B","FIG. 3B"],"b":["202","1","202","202","202","202","1","202","210","202","1","202","1","202","202","1","202","202","1","202","1","202","202","1","202","1","202"]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 4","b":["400","202","402","210","202","210","202","202"]},"At step , for each stack allocated object, the compiler  analyzes the IR  to identify all variables that have access to the stack allocated object. In other words, as a result of an instruction, a variable that represents the left hand side (LHS) of an instruction \u201cpoints to\u201d the object if one or more variables on the right hand side (RHS) of the instruction point to the object. For example, if a handle a is copied to b, b is considered to point to the object allocated to a and, thus, should be tracked in order to determine when the memory space for a is being used. The specific instructions for which the result may point to a stack allocated object are different depending on the intermediate language utilized by the IR . Types of instructions that point to a stack allocated object include, but are not limited to, copy instructions, binary operations, conversions (e.g., a type cast), PHI nodes (i.e., a special instruction used to select a value depending on the predecessor of the current block), store instructions, and function calls. In one embodiment, if a variable points to any location in the memory space allocated to the object, the variable is considered to point to the entire object (i.e., not just a particular element of the object). Table 1 illustrates an example pseudocode for identifying all variables that have access to a stack allocated object:",{"@attributes":{"id":"p-0030","num":"0029"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"pointsTo (variable v, instruction inst) {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if (RHS of inst includes v) {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"return LHS of inst;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"else {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"return NULL;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"}"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"set accessVariables = {a}"]},{"entry":[{},"set worklist = {a}"]},{"entry":[{},"set alreadyChecked = null;"]},{"entry":[{},"while worklist != null do"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"v = worklist.pop( )"]},{"entry":[{},"for instr \u2208 instructions(function) do"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if v == operand of instr then"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if altV = pointsTo (v, inst) then"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"accessVariables = accessVariables \u222a {altV}"]},{"entry":[{},"if altV ! \u2208 alreadyChecked then"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"worklist = worklist \u222a {altV}"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end if"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end if"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end if"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end for"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end while"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"At step , the compiler  generates a liveness web for each stack allocated object. A liveness web for a stack allocated object is a collection of defs (i.e., instructions assigning a value to the object) and uses (i.e., instructions using a value stored by the object as an operand) for the stack allocated object that represent when the stack allocated object is \u201clive\u201d in the program flow. It will be appreciated that the allocation of memory for an object is not a def for that object. An object is \u201clive\u201d at a certain point in the program if the data that the object contains is potentially needed by the current instruction or by a future instruction. In one embodiment, for each stack allocated object, the compiler  iterates through the instructions in IR  and determines if the instruction is either a def or a use (or both) of the object. If the instruction is either a def or a use, then the instruction is added to the liveness web for the object. Table 2 illustrates an example pseudocode for generating the liveness web for a stack allocated object:",{"@attributes":{"id":"p-0032","num":"0031"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 2"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"struct LivenessWeb {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"set defs;"]},{"entry":[{},"set uses;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"} livenessWeb"]},{"entry":[{},"set accessVariables; \/\/obtained from step 404"]},{"entry":[{},"for instr \u2208 instructions(function) do"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"for v \u2208 accessVariables do"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if instr == def(v) then"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"livenessWeb.addDef(v);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end if"]},{"entry":[{},"if instr = use(v) then"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"livenessWeb.addUse(v);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end if"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end for"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end for"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"At step , the compiler  tracks whether each stack allocated object is initialized or uninitialized at the beginning and end of each basic block. In one embodiment, the compiler  iterates through each basic block in the IR  and records when defs are encountered for each stack allocated object. A basic block is a portion of code within a program that has one entry point and one exit point (i.e., whenever the first instruction in a basic block is executed, the rest of the instructions in the basic block are executed exactly once in order). For example, in IR  of , a first basic block extends from line 1 (i.e., \u201cA:=alloc(in, 2000)\u201d) to line 6 (i.e., \u201cif n>=m goto L5\u201d), a second basic block extends from line 7 (i.e., \u201ci:=0\u201d) to line 8 (i.e., if i>=2000 goto L2\u201d), a third basic block extends from line 9 (i.e., \u201ct0:=i*3\u201d) to line 14 (i.e., \u201cgoto L1\u201d), and so forth. The compiler  may use the liveness web for each object, which records each of the defs and uses for an object, to determine whether each basic block includes a def for the object. If an object has been initialized on any path leading to the current block, then the object is considered initialized in the current block. Table 3 illustrates an example pseudocode for tracking whether each stack allocated object is initialized or uninitialized at each basic block:",{"@attributes":{"id":"p-0034","num":"0033"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":"TABLE 3"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"set allocatedObjects; \/\/ contains all stack allocated objects"},{"entry":"map bbToInitializedBefore; \/\/ sets of objects initialized before each block"},{"entry":"map bbToInitializedAfter; \/\/ sets of objects initialized after each block"},{"entry":"bool change = true"},{"entry":"while change do"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"change = false;"]},{"entry":[{},"for bb \u2208 basicBlocks(function) do"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"workset = null;"]},{"entry":[{},"for predBB \u2208 predecessors(bb) do"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"workset = workset \u222a bbToInitializedAfter(predBB);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end for"]},{"entry":[{},"if workset != bbToInitializedBefore.find(bb) then"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"change = true;"]},{"entry":[{},"bbToInitializedBefore = bbToInitializedBefore \u222a {(bb,"]},{"entry":[{},"workset)};"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end if"]},{"entry":[{},"for instr \u2208 instructions(bb) do"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"for allocatedObject \u2208 allocatedObjects do"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if instr \u2208 defs then"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"workset = workset \u222a {allocatedObject};"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end if"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end for"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end for"]},{"entry":[{},"if workset != bbToInitializedAfter.find(bb) then"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"change = true;"]},{"entry":[{},"bbToInitializedAfter = bbToInitializedAfter \u222a {(bb,"]},{"entry":[{},"workset)};"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end if"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end for"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"end while"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"At step , the compiler  determines which stack allocated objects are live at the same points in the IR . After obtaining the liveness webs in step  and tracking which objects are initialized and uninitialized at the beginning and end of each basic block in step , the compiler  maintains a set of stack allocated objects that are live at the beginning and end of each basic block. It will be appreciated that step  only determines when an object has been initialized (i.e., represented by the defs of the object), but, in step , the compiler determines when the object is no longer needed based on the object's uses. The compiler  updates the set of stack allocated objects that are live by iterating through the blocks and the instructions in the function in reverse order, taking into account the defs and uses for the object. If, at any point in the IR , two stack allocated objects are live simultaneously, the pair of objects may be marked as a conflict. Each stack allocated object may be associated with a list of the other stack allocated objects that conflict with that stack allocated object. Table 4 illustrates an example pseudocode for determining which stack allocated objects are live at the same time:",{"@attributes":{"id":"p-0036","num":"0035"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":"TABLE 4"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"set allocatedObjects; \/\/ contains all stack allocated objects"},{"entry":"map bbToBeforeSet; \/\/ sets of objects live before each block state"},{"entry":"map bbToInitializedBefore; \/\/ sets of objects initialized before each block"},{"entry":"map bbToInitializedAfter; \/\/ sets of objects initialized after each block"},{"entry":"bool change = true"},{"entry":"while change do"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"change = false;"]},{"entry":[{},"for bb \u2208 basicBlocks(function) do"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"workset = null;"]},{"entry":[{},"for succBB \u2208 successors(bb) do"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"workset = workset \u222a bbToBeforeSet(succBB);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end for"]},{"entry":[{},"workset = workset \u2229 bbToInitializedAfter(bb);"]},{"entry":[{},"for allocatedObject \u2208 allocatedObjects do"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"bool initialized = (allocatedObject \u2208"]},{"entry":[{},"bbToInitializedAfter(bb));"]},{"entry":[{},"if initialized & allocatedObject ! \u2208"]},{"entry":[{},"bbToInitializedAfter(bb) then"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"initDef = first def in bb;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end if"]},{"entry":[{},"for instr \u2208 instructions(bb) do \/\/ in reverse order"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if (instr \u2208 defs) & (initDef == instr) then"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"workset = workset \u2212{allocatedObject};"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end if"]},{"entry":[{},"if (instr \u2208 uses) & initialized then"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"workset = workset \u222a {allocatedObject};"]},{"entry":[{},"for otherObject \u2208 workset do"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if otherObject == allocatedObject then"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"continue;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end if"]},{"entry":[{},"allocatedObject.addConflicts(otherObject);"]},{"entry":[{},"otherObject.addConflicts(allocatedObject);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end for"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end if"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end for"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end for"]},{"entry":[{},"if workset != bbToBeforeSet.find(bb) then"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"change = true;"]},{"entry":[{},"bbToBeforeSet = bbToBeforeSet \u222a {(bb, workset)};"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end if"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end for"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"end while"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"At step , the compiler  determines which objects can be allocated to the same memory space. If two objects do not conflict, then the two objects can be allocated to the same memory space. At step , the compiler  determines how many allocations are actually needed, the size of each allocation, and which objects will use each allocated space. In one embodiment, only objects of the same type and alignment are allocated to the same memory space. For example, if there are two allocated arrays of integers with an alignment 4, one array having a size of 2000 integers and the other array having a size of 3000 integers, and the two allocated arrays do not conflict, then both objects can use a single allocated space of 3000 integers. However, if the arrays are of different types, such as an array of integers and an array of doubles, or of different alignment, then the objects are not allocated to the same memory space. In another embodiment, objects of different types and alignment can be allocated to the same memory space.","In one embodiment, the larger allocations are kept and smaller allocations of the same type use the memory space allocated to the larger object. For each type of object in the IR , the compiler  sorts the stack allocated objects of that type by size, in decreasing order. A set of objects that will remain in the code is maintained. Each object maintains a pointer to the stack allocated object that is going to replace the object (if the object is replaced) and a set of stack allocated objects that will use the object's allocated memory space (if the object remains in the IR ). The larger objects will be allocated to the thread stack memory and the rest of the objects are checked to see if they conflict with the first object or with other objects that use that memory space. If the objects do not conflict, the objects are assigned to use the same memory space, or are put in a worklist. The largest object in the worklist is then allocated to the thread stack memory and the rest of the objects in the worklist are checked to see if they conflict with the first object or with other objects that use that memory space. If the objects do not conflict, the objects are assigned to use the same memory space, or are put in a new worklist, which is again checked like the previous worklist and so forth until all of the objects are allocated to the thread stack memory space or are assigned to use the same memory space as a stack allocated object. Tables 5 and 6 illustrate example pseudocode for determining which objects can be allocated to the same memory space:",{"@attributes":{"id":"p-0039","num":"0038"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":"TABLE 5"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"struct allocatedObjectStruct{"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"set < allocatedObjectStruct > residents; \/\/ objects using this memory"]},{"entry":[{},"space"]},{"entry":[{},"allocatedObjectStruct *home; \/\/ the object whose allocation this"]},{"entry":[{},"object uses"]},{"entry":[{},"bool decided; \/\/ marks whether this object has been decided yet"]},{"entry":[{},"bool isArray; \/\/ marks whether this object is an array"]},{"entry":[{},"unsigned size; \/\/ the size if the object is an array"]},{"entry":[{},"unsigned alignment; \/\/ the alignment of the object"]},{"entry":[{},"Type type; \/\/ the objects type"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":"set < allocatedObjectStruct > allocatedObjects;"},{"entry":"set < allocatedObjectStruct > toAllocated = null;"},{"entry":"for allocatedObject \u2208 allocatedObjects do"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if allocatedObject.decided then"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"continue;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end if"]},{"entry":[{},"choose(allocatedObject.type, allocatedObject.alignment);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"end for"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0040","num":"0039"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":"TABLE 6"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"void choose(Type type, unsigned alignment) {"},{"entry":"\u2003vector < allocatedObjectStruct > rightType;"},{"entry":"\u2003for allocatedObject \u03b5 allocatedObjects do"},{"entry":"\u2003\u2003if (allocatedObject.type == type) & (allocatedObject.alignment =="},{"entry":"\u2003\u2003\u2003\u2003alignment) then"},{"entry":"\u2003\u2003\u2003rightType.insert(allocatedObject);"},{"entry":"\u2003\u2003end if"},{"entry":"\u2003end for"},{"entry":"\u2003if ! rightType.empty( ) then"},{"entry":"\u2003\u2003sort(rightType);"},{"entry":"\u2003end if"},{"entry":"\u2003set < allocatedObjectStruct > worklist;"},{"entry":"\u2003allocatedObjectStruct *current = null;"},{"entry":"\u2003repeat"},{"entry":"\u2003\u2003if current != null then"},{"entry":"\u2003\u2003\u2003repeat"},{"entry":"\u2003\u2003\u2003\u2003current = worklist.pop( );"},{"entry":"\u2003\u2003\u2003until !current.decided"},{"entry":"\u2003\u2003\u2003toAllocate = toAllocate \u222a {current};"},{"entry":"\u2003\u2003\u2003current.decided = true;"},{"entry":"\u2003\u2003end if"},{"entry":"\u2003\u2003for rightTypeObject \u03b5 rightType do"},{"entry":"\u2003\u2003\u2003if rightTypeObject.decided then"},{"entry":"\u2003\u2003\u2003\u2003continue;"},{"entry":"\u2003\u2003\u2003end if"},{"entry":"\u2003\u2003\u2003if current == null then"},{"entry":"\u2003\u2003\u2003\u2003current = rightTypeObject;"},{"entry":"\u2003\u2003\u2003\u2003toAllocate = toAllocate \u222a {current};"},{"entry":"\u2003\u2003\u2003\u2003current.decided = true;"},{"entry":"\u2003\u2003\u2003\u2003continue;"},{"entry":"\u2003\u2003\u2003end if"},{"entry":"\u2003\u2003\u2003if !current.isConfiict(rightTypeObject) then"},{"entry":"\u2003\u2003\u2003\u2003current.addResident(rightTypeObject);"},{"entry":"\u2003\u2003\u2003\u2003rightTypeObject.addHome(current);"},{"entry":"\u2003\u2003\u2003\u2003rightTypeObject.decided = true;"},{"entry":"\u2003\u2003\u2003else"},{"entry":"\u2003\u2003\u2003\u2003worklist.push(rightTypeObject);"},{"entry":"\u2003\u2003\u2003end if"},{"entry":"\u2003\u2003end for"},{"entry":"\u2003until worklist.empty ( )"},{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"It will be appreciated that the framework set forth above may be implemented for a variety of different compilers. In one embodiment, the framework may be implemented in a compiler of a parallel processing unit (PPU) that generates machine code in response to a program  generated by an application executing on a central processing unit (CPU). The following description illustrates one such architecture that could be used to implement at least a portion of the framework set forth above.",{"@attributes":{"id":"p-0042","num":"0041"},"figref":["FIG. 5","FIG. 6"],"b":["500","500","500","550","550","550"]},"In one embodiment, the PPU  includes an input\/output (I\/O) unit  configured to transmit and receive communications (i.e., commands, data, etc.) from a central processing unit (CPU) (not shown) over the system bus . The I\/O unit  may implement a Peripheral Component Interconnect Express (PCIe) interface for communications over a PCIe bus. In alternative embodiments, the I\/O unit  may implement other types of well-known bus interfaces.","The PPU  also includes a host interface unit  that decodes the commands and transmits the commands to the grid management unit  or other units of the PPU  (e.g., memory interface ) as the commands may specify. The host interface unit  is configured to route communications between and among the various logical units of the PPU .","In one embodiment, a program encoded as a command stream is written to a buffer by the CPU. The buffer is a region in memory, e.g., memory  or system memory, that is accessible (i.e., read\/write) by both the CPU and the PPU . The CPU writes the command stream to the buffer and then transmits a pointer to the start of the command stream to the PPU . The host interface unit  provides the grid management unit (GMU)  with pointers to one or more streams. The GMU  selects one or more streams and is configured to organize the selected streams as a pool of pending grids. The pool of pending grids may include new grids that have not yet been selected for execution and grids that have been partially executed and have been suspended.","A work distribution unit  that is coupled between the GMU  and the SMs  manages a pool of active grids, selecting and dispatching active grids for execution by the SMs . Pending grids are transferred to the active grid pool by the GMU  when a pending grid is eligible to execute, i.e., has no unresolved data dependencies. An active grid is transferred to the pending pool when execution of the active grid is blocked by a dependency. When execution of a grid is completed, the grid is removed from the active grid pool by the work distribution unit . In addition to receiving grids from the host interface unit  and the work distribution unit , the GMU  also receives grids that are dynamically generated by the SMs  during execution of a grid. These dynamically generated grids join the other pending grids in the pending grid pool.","In one embodiment, the CPU executes a driver kernel that implements an application programming interface (API) that enables one or more applications executing on the CPU to schedule operations for execution on the PPU . An application may include instructions (i.e., API calls) that cause the driver kernel to generate one or more grids for execution. In one embodiment, the PPU  implements a SIMD (Single-Instruction, Multiple-Data) architecture where each thread block (i.e., warp) in a grid is concurrently executed on a different data set by different threads in the thread block. The driver kernel defines thread blocks that are comprised of k related threads, such that threads in the same thread block may exchange data through shared memory. In one embodiment, a thread block comprises 32 related threads and a grid is an array of one or more thread blocks that execute the same stream and the different thread blocks may exchange data through global memory. In one embodiment, the driver kernel implements a compiler that performs optimizations for thread stack memory allocation when generating threads for execution on PPU .","In one embodiment, the PPU  comprises X SMs (X). For example, the PPU  may include 15 distinct SMs . Each SM  is multi-threaded and configured to execute a plurality of threads (e.g., 32 threads) from a particular thread block concurrently. Each of the SMs  is connected to a level-two (L2) cache  via a crossbar  (or other type of interconnect network). The L2 cache  is connected to one or more memory interfaces . Memory interfaces  implement 16, 32, 64, 128-bit data buses, or the like, for high-speed data transfer. In one embodiment, the PPU  comprises U memory interfaces (U), where each memory interface (U) is connected to a corresponding memory device (U). For example, PPU  may be connected to up to 6 memory devices , such as graphics double-data-rate, version 5, synchronous dynamic random access memory (GDDR5 SDRAM).","In one embodiment, the PPU  implements a multi-level memory hierarchy. The memory  is located off-chip in SDRAM coupled to the PPU . Data from the memory  may be fetched and stored in the L2 cache , which is located on-chip and is shared between the various SMs . In one embodiment, each of the SMs  also implements an L1 cache. The L1 cache is private memory that is dedicated to a particular SM . Each of the L1 caches is coupled to the shared L2 cache . Data from the L2 cache  may be fetched and stored in each of the L1 caches for processing in the functional units of the SMs .","In one embodiment, the PPU  comprises a graphics processing unit (GPU), such as the GPU . The PPU  is configured to receive commands that specify shader programs for processing graphics data. Graphics data may be defined as a set of primitives such as points, lines, triangles, quads, triangle strips, and the like. Typically, a primitive includes data that specifies a number of vertices for the primitive (e.g., in a model-space coordinate system) as well as attributes associated with each vertex of the primitive. The PPU  can be configured to process the graphics primitives to generate a frame buffer (i.e., pixel data for each of the pixels of the display). The driver kernel implements a graphics processing pipeline, such as the graphics processing pipeline defined by the OpenGL API.","An application writes model data for a scene (i.e., a collection of vertices and attributes) to memory. The model data defines each of the objects that may be visible on a display. The application then makes an API call to the driver kernel that requests the model data to be rendered and displayed. The driver kernel reads the model data and writes commands to the buffer to perform one or more operations to process the model data. The commands may encode different shader programs including one or more of a vertex shader, hull shader, geometry shader, pixel shader, etc. For example, the GMU  may configure one or more SMs  to execute a vertex shader program that processes a number of vertices defined by the model data. In one embodiment, the GMU  may configure different SMs  to execute different shader programs concurrently. For example, a first subset of SMs  may be configured to execute a vertex shader program while a second subset of SMs  may be configured to execute a pixel shader program. The first subset of SMs  processes vertex data to produce processed vertex data and writes the processed vertex data to the L2 cache  and\/or the memory . After the processed vertex data is rasterized (i.e., transformed from three-dimensional data into two-dimensional data in screen space) to produce fragment data, the second subset of SMs  executes a pixel shader to produce processed fragment data, which is then blended with other processed fragment data and written to the frame buffer in memory . The vertex shader program and pixel shader program may execute concurrently, processing different data from the same scene in a pipelined fashion until all of the model data for the scene has been rendered to the frame buffer. Then, the contents of the frame buffer are transmitted to a display controller for display on a display device.","The PPU  may be included in a desktop computer, a laptop computer, a tablet computer, a smart-phone (e.g., a wireless, hand-held device), personal digital assistant (PDA), a digital camera, a hand-held electronic device, and the like. In one embodiment, the PPU  is embodied on a single semiconductor substrate. In another embodiment, the PPU  is included in a system-on-a-chip (SoC) along with one or more other logic units such as a reduced instruction set computer (RISC) CPU, a memory management unit (MMU), a digital-to-analog converter (DAC), and the like.","In one embodiment, the PPU  may be included on a graphics card that includes one or more memory devices  such as GDDR5 SDRAM. The graphics card may be configured to interface with a PCIe slot on a motherboard of a desktop computer that includes, e.g., a northbridge chipset and a southbridge chipset. In yet another embodiment, the PPU  may be an integrated graphics processing unit (iGPU) included in the chipset (i.e., Northbridge) of the motherboard.","It will be appreciated that a master thread may be configured to execute on a first SM () of PPU . In addition, two or more child threads may be configured to execute on two or more additional SMs (e.g., (), (), etc.). The master thread and child threads may access motion vector data stored in a memory by a hardware video encoder .",{"@attributes":{"id":"p-0055","num":"0054"},"figref":["FIG. 6","FIG. 5","FIG. 6"],"b":["550","550","605","610","620","650","651","652","653","680","670","690"]},"As described above, the work distribution unit  dispatches active grids for execution on one or more SMs  of the PPU . The scheduler unit  receives the grids from the work distribution unit  and manages instruction scheduling for one or more thread blocks of each active grid. The scheduler unit  schedules threads for execution in groups of parallel threads, where each group is called a warp. In one embodiment, each warp includes 32 threads. The scheduler unit  may manage a plurality of different thread blocks, allocating the thread blocks to warps for execution and then scheduling instructions from the plurality of different warps on the various functional units (i.e., cores , DPUs , SFUs , and LSUs ) during each clock cycle.","In one embodiment, each scheduler unit  includes one or more instruction dispatch units . Each dispatch unit  is configured to transmit instructions to one or more of the functional units. In the embodiment shown in , the scheduler unit  includes two dispatch units  that enable two different instructions from the same warp to be dispatched during each clock cycle. In alternative embodiments, each scheduler unit  may include a single dispatch unit  or additional dispatch units .","Each SM  includes a register file  that provides a set of registers for the functional units of the SM . In one embodiment, the register file  is divided between each of the functional units such that each functional unit is allocated a dedicated portion of the register file . In another embodiment, the register file  is divided between the different warps being executed by the SM . The register file  provides temporary storage for operands connected to the data paths of the functional units.","Each SM  comprises L processing cores . In one embodiment, the SM  includes a large number (e.g., 192, etc.) of distinct processing cores . Each core  is a fully-pipelined, single-precision processing unit that includes a floating point arithmetic logic unit and an integer arithmetic logic unit. In one embodiment, the floating point arithmetic logic units implement the IEEE 754-2008 standard for floating point arithmetic. Each SM  also comprises M DPUs  that implement double-precision floating point arithmetic, N SFUs  that perform special functions (e.g., copy rectangle, pixel blending operations, and the like), and P LSUs  that implement load and store operations between the shared memory\/L1 cache  and the register file . In one embodiment, the SM  includes 64 DPUs , 32 SFUs , and 32 LSUs .","Each SM  includes an interconnect network  that connects each of the functional units to the register file  and the shared memory\/L1 cache . In one embodiment, the interconnect network  is a crossbar that can be configured to connect any of the functional units to any of the registers in the register file  or the memory locations in shared memory\/L1 cache .","In one embodiment, the SM  is implemented within a GPU. In such an embodiment, the SM  comprises J texture units . The texture units  are configured to load texture maps (i.e., a 2D array of texels) from the memory  and sample the texture maps to produce sampled texture values for use in shader programs. The texture units  implement texture operations such as anti-aliasing operations using mip-maps (i.e., texture maps of varying levels of detail). In one embodiment, the SM  includes 16 texture units .","The PPU  described above may be configured to perform highly parallel computations much faster than conventional CPUs. Parallel computing has advantages in graphics processing, data compression, biometrics, stream processing algorithms, and the like.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 7","b":["700","700","701","702","702","700","704","704"]},"The system  also includes input devices , a graphics processor , and a display , i.e. a conventional CRT (cathode ray tube), LCD (liquid crystal display), LED (light emitting diode), plasma display or the like. User input may be received from the input devices , e.g., keyboard, mouse, touchpad, microphone, and the like. In one embodiment, the graphics processor  may include a plurality of shader modules, a rasterization module, etc. Each of the foregoing modules may even be situated on a single semiconductor platform to form a graphics processing unit (GPU).","In the present description, a single semiconductor platform may refer to a sole unitary semiconductor-based integrated circuit or chip. It should be noted that the term single semiconductor platform may also refer to multi-chip modules with increased connectivity which simulate on-chip operation, and make substantial improvements over utilizing a conventional central processing unit (CPU) and bus implementation. Of course, the various modules may also be situated separately or in various combinations of semiconductor platforms per the desires of the user.","The system  may also include a secondary storage . The secondary storage  includes, for example, a hard disk drive and\/or a removable storage drive, representing a floppy disk drive, a magnetic tape drive, a compact disk drive, digital versatile disk (DVD) drive, recording device, universal serial bus (USB) flash memory. The removable storage drive reads from and\/or writes to a removable storage unit in a well-known manner.","Computer programs, or computer control logic algorithms, may be stored in the main memory  and\/or the secondary storage . Such computer programs, when executed, enable the system  to perform various functions. The memory , the storage , and\/or any other storage are possible examples of computer-readable media. Program , IR , IR -, machine code , and compiler  may be stored in the main memory  and\/or the secondary storage . The compiler  is then executed by processor  to generate the optimized machine code .","In one embodiment, the architecture and\/or functionality of the various previous figures may be implemented in the context of the central processor , the graphics processor , an integrated circuit (not shown) that is capable of at least a portion of the capabilities of both the central processor  and the graphics processor , a chipset (i.e., a group of integrated circuits designed to work and sold as a unit for performing related functions, etc.), and\/or any other integrated circuit for that matter.","Still yet, the architecture and\/or functionality of the various previous figures may be implemented in the context of a general computer system, a circuit board system, a game console system dedicated for entertainment purposes, an application-specific system, and\/or any other desired system. For example, the system  may take the form of a desktop computer, laptop computer, server, workstation, game consoles, embedded system, and\/or any other type of logic. Still yet, the system  may take the form of various other devices including, but not limited to a personal digital assistant (PDA) device, a mobile phone device, a television, etc.","Further, while not shown, the system  may be coupled to a network (e.g., a telecommunications network, local area network (LAN), wireless network, wide area network (WAN) such as the Internet, peer-to-peer network, cable network, or the like) for communication purposes.","While various embodiments have been described above, it should be understood that they have been presented by way of example only, and not limitation. Thus, the breadth and scope of a preferred embodiment should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":["FIG. 3B","FIG. 3A"]},{"@attributes":{"id":"p-0010","num":"0009"},"figref":["FIG. 3C","FIG. 3B"]},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 6","FIG. 5"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
