---
title: Interactive scheduling of an application on a multi-core target processor from a co-simulation design environment
abstract: In an embodiment, a method for interactively varying scheduling of a multi-threaded application executing on a symmetric multi-core processor provides an interface in a co-simulation design environment. The interface is associated with a multi-threaded application executing on a target processor that includes symmetric processor cores. The method also sets a scheduling attribute of the multi-threaded application using the interface. The setting occurs when the multi-threaded application is executing. The method further receives data associated with the executing of the multi-threaded application in the co-simulation design environment when the multi-threaded application is executing subsequent to the setting of the scheduling attribute.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09317331&OS=09317331&RS=09317331
owner: The MathWorks, Inc.
number: 09317331
owner_city: Natick
owner_country: US
publication_date: 20121031
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND INFORMATION","DETAILED DESCRIPTION"],"p":["Co-simulation is a technique used by developers to design, test, and optimize an application that is to be implemented on particular target hardware. With co-simulation, one or more components of an application in development executes on the target hardware. The target hardware may be a symmetric multi-core processor (SMP) where the resources associated with the cores are identical. That is, the execution characteristics of an application component running on one core of an SMP are identical to the execution characteristics of the same component running on any other core of the SMP.","During co-simulation, execution of the application under development may include one or more application components that are simulated in the host simulation environment and one or more application components that are executing on SMP. The one or more application components executing on the SMP may have been generated from the host environment via automatic code generation.","According to various embodiments, an application is designed in a co-simulation design environment. The application may be designed by a user. A user may be a person, an algorithm, a program that is part of an application running in simulation, or any combination thereof. Accordingly, the term \u201cinteraction\u201d may refer to an interaction with a person, an algorithm, a program or any combination thereof.","Exemplary co-simulation design environments may include graphical programming environments, e.g., block diagram environments (BDEs), and\/or textual programming environments (TPEs). An application designed in a BDE may be a BDE model and an application designed in a TPE may be a TPE model. According to various embodiments, a TPE model can include one or more of a textual program, a script, a function, another TPE model, etc. A BDE model can include one or more of a block, a subsystem, another BDE model, etc.","The application designed in the co-simulation design environment may include one or more application components. As discussed in further detail below in connection with , an application component may be formed by grouping together one or more elements of the application. An application component may be a subset of the application that is able to run independently from the rest of the application and that has defined boundaries along with a defined input and output.","In a TPE, the application components may be formed by grouping elements of the application by function, object, method, model, textual program, other demarcated boundary (e.g., a conditional statement), etc.","In a BDE, the components may be formed by grouping elements of the application by block, subsystem, rate, sub-model (e.g., Referenced Model), other demarcated boundary, etc. An application component may be composed of one or more execution threads that may be mapped to processing cores of a symmetric multi-core processor (SMP). An application component may be designated to execute on a SMP.","A scheduler may distribute, or map, execution threads of one or more application components to available processing cores at compile-time. Conventionally, the schedulers are implemented in the target processing device such as a SMP. Conventional schedulers may include conventional static schedulers and conventional dynamic schedulers.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIGS. 1A-1C","b":["100","102","100","102"]},"For example, conventional static scheduler  illustrated in  has the following fixed mapping: execution threads of application components  and  are mapped to processing core  of the SMP, execution threads of application component  are mapped to processing core  of the SMP, execution threads of application component  are mapped to processing core  of the SMP, and execution threads of application components  and  are mapped to processing core  of the SMP. The mapping between the execution threads of application components - and processing cores - implemented by conventional static scheduler  remains unchanged during the execution of the application components - on the SMP with processing cores -.","Conventional static scheduler  illustrated in  implements a different fixed mapping. As shown in , conventional static scheduler  maps execution threads of application components  and  to processing core  of the SMP, execution threads of application components  and  to processing core  of the SMP, execution threads of application component  to processing core  of the SMP, and execution threads of application component  to processing core  of the SMP. The mapping between the execution threads of application components - and processing cores - implemented by conventional static scheduler  remains unchanged during the execution of the application components - on the SMP with processing cores -.","Conventional static scheduler  illustrated in  implements a different fixed mapping. As shown in , conventional static scheduler  maps execution threads of application components  and  to processing core  of the SMP, execution threads of application component  to processing core  of the SMP, execution threads of application components  and  to processing core  of the SMP, and execution threads of application component  to processing core  of the SMP. The mapping between the execution threads of application components - and processing cores - implemented by conventional static scheduler  remains unchanged during the execution of the application components - on the SMP with processing cores -.",{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIGS. 2A-2B","b":["200","212"]},"Other exemplary conventional dynamic scheduling rule sets may include, for example, a shortest execution time scheme where the application component with the shortest predicted execution time is assigned to the least busy core and the application component with the second predicted execution time is assigned to the second least busy core, etc. One of ordinary skill in the art will appreciate that load-balancing and shortest execution time allocation execution rules are used for illustrative purposes only and that the execution criteria may include other execution rules and\/or rule sets.","For example, conventional dynamic scheduler  illustrated in  may change the mapping of execution threads of application components - to processing cores - when application components are executing on the SMP. At time t=0, conventional dynamic scheduler  implements a first mapping where conventional dynamic scheduler  maps execution threads of the application components  and  to processing core  of the SMP, execution threads of the application component  to processing core  of the SMP, execution threads of the application component  to processing core  of the SMP, and execution threads of the application components  and  to processing core  of the SMP.","At time t=1, conventional dynamic scheduler  may change the mapping and implement a second mapping where: execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application component  are mapped to processing core  of the SMP, and execution threads of the application component  are mapped to processing core  of the SMP. While the execution of threads of the application components continues on the cores of the SMP, conventional dynamic scheduler  implements a third mapping at time t=3. As illustrated in , at time t=2, execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application component  are mapped to processing core  of the SMP, execution threads of the application components  and  are mapped to processing core  of the SMP, and execution threads of the application component  are mapped to processing core  of the SMP.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIG. 2B","FIG. 2B"],"b":["212","212","1","6","1","4","212","1","1","2","3","6","2","4","3","5","4"]},"At time t=1, conventional dynamic scheduler  may change the mapping and implements a second mapping: execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application components  and  are mapped to processing core  of the SMP, no execution thread is mapped to processing core  of the SMP, and execution threads of the application components  and  are mapped to processing core  of the SMP. Thus, conventional dynamic scheduler  does not have to assign execution thread of the application components to each processing core of the SMP.","Conventional dynamic scheduler  may choose to assign no execution thread or all execution threads to a given processing core of the SMP. While the execution of the components continues on the processing cores of the SMP, conventional dynamic scheduler  may implement a third mapping at time t=2. As illustrated in , at time t=3, execution threads of the application components ,  and  are mapped to processing core  of the SMP, execution threads of the application component  are mapped to processing core  of the SMP, execution threads of the application component  are mapped to processing core  of the SMP, and execution threads of the application component  are mapped to processing core  of the SMP. As shown in  a conventional dynamic scheduler may change the mapping of an execution thread of an application component to a specific processing core multiple times during the execution of the application.","According to various embodiments, conventional schedulers may be implemented in the co-simulation design environment. Such schedulers are referred as co-simulation schedulers. For example, if a conventional static scheduler is implemented in the co-simulation design environment, such scheduler is referred as a co-simulation static scheduler. Accordingly, the co-simulation static scheduler is a scheduler implemented in the co-simulation environment with a fixed mapping of execution threads to processing cores. The mapping implemented by a co-simulation static scheduler is similar to the mapping illustrated in . However, contrary to a conventional static scheduler which is implemented on the target processor such as the SMP, the co-simulation static scheduler is implemented in the co-simulation design environment.","If a conventional dynamic scheduler is implemented in the co-simulation design environment, such scheduler is referred as a co-simulation dynamic scheduler. Accordingly, the co-simulation dynamic scheduler is a scheduler implemented in the co-simulation environment with a dynamic mapping of execution threads to processing cores. The mapping implemented by a co-simulation dynamic scheduler is similar to the mapping illustrated in . However, contrary to a conventional dynamic scheduler which is implemented on the target processor such as the SMP, the co-simulation dynamic scheduler is implemented in the co-simulation design environment.","According to various embodiments, interactive schedulers may be constructed from co-simulation schedulers. For example, an interactive static scheduler may be constructed from a co-simulation static scheduler. The interactive static scheduler is a scheduler implemented in the co-simulation environment that may interactively change from one co-simulation static scheduler to another co-simulation static scheduler during co-simulation, without re-generating, re-compiling or re-running code for the one or more application components.","The interactive static scheduler remaps execution threads of application components to processing cores during co-simulation, i.e. at runtime, from the co-simulation environment. This form of operation by an interactive static scheduler is referred to as \u201cchanging of co-simulation static schedulers.\u201d The varying of one co-simulation static scheduler to another co-simulation static scheduler is prompted by the user. As provided above, the user may be a person, an algorithm, a program that is part of an application running in simulation, or any combination thereof. Varying one co-simulation static scheduler to another co-simulation static scheduler has the effect of changing the mapping of execution threads of application components to processing cores without re-generating, re-compiling or re-running code for the one or more application components.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 3","FIG. 3"],"b":["300","300","302","304","306"]},"At time t=0, interactive static scheduler  implements a first co-simulation static scheduler  where execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application component  are mapped to processing core  of the SMP, execution threads of the application component  are mapped to processing core  of the SMP, and execution threads of the application components  and  are mapped to processing core  of the SMP.","At time t=1, interactive static scheduler  may change to co-simulation static scheduler  without re-generating, re-compiling or re-running code for the one or more application components. As illustrated in , at time t=1, execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application component  are mapped to processing core  of the SMP, and execution threads of the application component  are mapped to processing core  of the SMP.","At time t=2, interactive static scheduler  may change to co-simulation static scheduler  without re-generating, re-compiling or re-running code for the one or more application components. As illustrated in , at time t=2, execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application component  are mapped to processing core  of the SMP, execution threads of the application components  and  are mapped to processing core  of the SMP, and execution threads of the application component  are mapped to processing core  of the SMP.","The technique of changing the mapping of execution threads to processing cores at runtime, such as changing from co-simulation static scheduler  to co-simulation static scheduler , may be thought of as \u201cchanging of co-simulation static schedulers\u201d during co-simulation (i.e., run-time), without re-generating, re-compiling or re-running code for the one or more application components. In certain embodiments, a desired co-simulation static scheduler may be chosen during co-simulation. Based on the selected co-simulation static scheduler, a desired conventional static scheduler that will implement a static mapping of threads to cores at compile time of the application may be automatically generated. This generated conventional static scheduler may be reused for subsequent executions of the application on target SMP.","According to various embodiments, interactive dynamic schedulers may be constructed from co-simulation schedulers. For example, an interactive dynamic scheduler may be constructed from a co-simulation dynamic scheduler. The interactive dynamic scheduler is a scheduler implemented in the co-simulation environment that may interactively change from one co-simulation dynamic scheduler to another co-simulation dynamic scheduler during co-simulation, without re-generating, re-compiling or re-running code for the one or more application components.","The interactive dynamic scheduler remaps execution threads of application components to processing cores during co-simulation, i.e. at runtime, from the co-simulation environment. Accordingly, the interactive dynamic scheduler is a scheduler implemented in the co-simulation environment that may vary from one co-simulation dynamic scheduler to another co-simulation dynamic scheduler at runtime during co-simulation, without re-generating, re-compiling or re-running code for the one or more application components. This form of operation by an interactive dynamic scheduler is referred to as \u201cchanging of co-simulation dynamic schedulers.\u201d The varying of one co-simulation dynamic scheduler to another co-simulation dynamic scheduler may be prompted by the user. As provided above, the user may be a person, an algorithm, a program that is part of an application running in simulation, or any combination thereof.","A co-simulation dynamic scheduler remaps execution threads of application components to processing cores based on, for example, conditions and\/or rule sets of the runtime environment during co-simulation without re-generating, re-compiling or re-running code for the one or more application components. For example, an interactive dynamic scheduler may change a co-simulation dynamic scheduler based on load-balancing, where the execution thread of an application component is mapped to a least busy processing core at that instance of time, to another co-simulation dynamic scheduler where the execution threads of the application component are mapped to the processing core that has been running the longest. One of ordinary skill in the art will appreciate that other conditions and\/or rule sets, such as dependency among threads (e.g., requiring two or more execution threads to run on the same processing core, etc.), can be used to determining how co-simulation dynamic schedulers may map execution threads to processing cores. In certain embodiments, a desired co-simulation dynamic scheduler may be chosen during co-simulation. Based on the chosen co-simulation dynamic scheduler, a desired conventional dynamic scheduler may be automatically generated using an embodiment of the invention. The generated conventional dynamic scheduler may be reused for subsequent executions of the application on target SMP.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 4","FIG. 4"],"b":["400","400","402","404"]},"At time t=0, interactive dynamic scheduler  implements the first mapping of co-simulation dynamic scheduler  where execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application component  are mapped to processing core  of the SMP, execution threads of the application component  are mapped to processing core  of the SMP, and execution threads of the application components  and  are mapped to processing core  of the SMP.","At time t=1, interactive dynamic scheduler  may change to co-simulation dynamic scheduler  without re-generating, re-compiling or re-running code for the one or more application components. Interactive dynamic scheduler  may implement the second mapping of co-simulation dynamic scheduler  where: execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application components  and  are mapped to processing core  of the SMP.","At time t=2, interactive dynamic scheduler  may change back to co-simulation dynamic scheduler  without re-generating, re-compiling or re-running code for the one or more application components. Interactive dynamic scheduler  may implement the third mapping of co-simulation dynamic scheduler  where: execution threads of the application components  and  are mapped to processing core  of the SMP, execution threads of the application component  are mapped to processing core  of the SMP, execution threads of the application components  and  are mapped to processing core  of the SMP and execution threads of the application component  are mapped to processing core  of the SMP.","Changes to a mapping of execution threads to processing cores at runtime, such as changing from co-simulation dynamic scheduler  to co-simulation dynamic scheduler , is a technique of \u201cchanging co-simulation dynamic schedulers\u201d during co-simulation (i.e., run-time) without re-generating, re-compiling or re-running code for the one or more application components. In certain embodiments, a desired co-simulation dynamic scheduler may be chosen during co-simulation. Based on the selected co-simulation dynamic scheduler, a desired conventional dynamic scheduler that will implement a dynamic mapping of threads to cores at compile time of the application may be automatically generated. This generated conventional dynamic scheduler may be reused for subsequent executions of the application on target SMP.","A co-simulation dynamic scheduler remaps execution threads of application components to processing cores during co-simulation, i.e. at runtime, from the co-simulation environment. The varying of one mapping of execution threads of application components to processing cores to another mapping of execution threads of application components to processing cores is performed by the co-simulation dynamic scheduler. A co-simulation dynamic scheduler changes the mapping of execution threads of application components to processing cores without re-generating, re-compiling or re-running code for the one or more application components","A co-simulation dynamic scheduler may operate in a similar manner as an interactive static scheduler. As example, the co-simulation dynamic scheduler  of  may operate in a similar manner as the interactive static scheduler  of . According to various embodiments, an interactive static scheduler may help to generate an optimal conventional static scheduler. For example, the interactive static scheduler  of  may be used to generate an optimal conventional static scheduler, such as the conventional static scheduler ,  or  illustrated in , respectively. In some embodiments, a co-simulation dynamic scheduler may help to generate a conventional dynamic scheduler. For example, the co-simulation dynamic scheduler  or  of  may be used to generate a conventional dynamic scheduler, such as the conventional dynamic scheduler  or  illustrated in , respectively. In some embodiments, a co-simulation dynamic scheduler may be used to construct an interactive dynamic scheduler, which may be used to generate an optimal conventional dynamic scheduler. For example, the co-simulation dynamic scheduler  and\/or  of  may be used to construct an interactive dynamic scheduler, such as the interactive dynamic scheduler  illustrated in . The interactive dynamic scheduler  may be used to generate an optimal conventional dynamic scheduler, such as the conventional dynamic scheduler  or  illustrated in , respectively.","The interactive static and dynamic schedulers discussed above may allow interactive re-scheduling of execution threads of the application components to different processing cores of the target SMP during execution of the one or more application components, (i.e., without stopping execution of the one or more application components). The re-scheduling during co-simulation does not alter the design of the one or more application components and does not require re-generating, re-compiling or re-running code for the one or more application components. Accordingly, the re-scheduling discussed herein represents improved efficiency and time savings compared to conventional approaches that require re-generating, re-compiling, and re-running of code for the components in order to find a suitable conventional static and\/or dynamic scheduler.","The ability to assess various scheduling schemes by interactively altering co-simulation static or dynamic schedulers may help to determine an optimal co-simulation scheduling scheme without re-generating, re-compiling or re-running code for the application. Conventional scheduling schemes assess a single candidate conventional scheduler. If a different scheduling scheme is to be employed, the conventional schemes need to stop the target SMP, re-generate, re-compile, and re-run code for the application using the different scheduling scheme. According to various embodiments discussed herein, a desired co-simulation static or dynamic scheduler may be identified during co-simulation using interactive scheduling. The desired conventional static or dynamic scheduler (that corresponds to the identified co-simulation static or dynamic scheduler) may then be generated for standalone deployment of the application on the target SMP. Contrary to the conventional scheduling schemes, embodiments allow interactively altering co-simulation static or dynamic schedulers to generate the desired conventional static or dynamic scheduler without re-generating, re-compiling or re-running code for the application.","Embodiments allow profiling results, i.e. runtime statistics, of various static and dynamic scheduling schemes that map the execution threads of application components to specific processing cores on the target SMP to be considered and acted upon. For example, relevant runtime statistics, such as CPU load and memory usage, may be streamed back to the co-simulation design environment from the target SMP in real time, i.e. while the code for the application components is being executed on the target SMP. According to various embodiments, the target SMP may send continuous runtime statistics updates to the co-simulation design environment. A portion of the runtime statistics may be provided to the user in various graphical and\/or textual formats, if desired. Based on the profiling results, the user may change the co-simulation static or dynamic scheduling scheme to improve execution efficiency of the code including but not limited to increasing execution speed, minimizing memory usage, improving load distribution across cores, minimizing power consumption, minimizing communication among the cores, etc. For example, the user may change the mapping for faster execution or to better meet application design constraints.","According to exemplary embodiments, runtime scheduling experiments may be conducted in the co-simulation design environment to determine and subsequently generate schedulers that satisfy (e.g., meet or exceed) a design requirement for an application. A generated scheduler may identify a scheduling scheme for executing the application being designed in the co-simulation design environment on the SMP. The generated scheduler may be reused in subsequent executions of the application on the SMP.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 5","b":["500","500","500","500","501","501","500","502","504","501","501","500"]},"Optionally, computing device  may include multiple CPUs for executing software loaded in memory , and other programs for controlling system hardware. Each of the CPUs can be a single or a multiple core processor. The code loaded in memory  may run in a virtualized environment, such as in a Virtual Machine (VM). Multiple VMs may be resident on a single processor. Also, part of the code may be run in hardware, for example, by configuring a field programmable gate array (FPGA), using an application specific instruction set processor (ASIP) or creating an application specific integrated circuit (ASIC). Further, part of the applications may be run on analog electronic devices or other resources, may be used to run part of the application, such as graphics processing units (GPUs), or may be dedicated hardware such as Fast Fourier Transform (FFT) processing blocks.","Storage  may contain software tools for applications. Storage can include code for the operating system (OS) of the computing device , code for at least one application executed by the OS including the applications for the co-simulation design environment . Storage may also hold data generated from the co-simulation design environment . Those of ordinary skill in the art will appreciate that parts of applications can be stored in the CPU cache or memory as well, or they can be stored on a network.","Input device  coupled to computing device  may include a keyboard, mouse, microphone, camera, such as a web camera, or other input device such as a 3D mouse, space mouse, multipoint touchpad, accelerometer-based device, gyroscope-based device, etc. Computing device  may receive, through input device , input data, such as the input data for developing a model. Computing device  may display on output device  one or more interfaces for displaying the data generated from co-simulation design environment .","As discussed above, computing device  may host co-simulation design environment . For example, computing device  may host a BDE or TPE. The co-simulation design environment  may be used to create and test application . Application  may include one or more of a block diagram, a state-based diagram, a textual program, a technical computing program that performs technical calculations when executed, etc.","For example, co-simulation design environment  may be used to develop a block diagram application or a textual application. Application  may have one or more application components, such as application components ,  and . Furthermore, co-simulation design environment  may include code generator . Code generator  may be used to generate code that executes on an SMP . For example, code generator  may generate code for application components ,  and  where the generated code is capable of executing on SMP . Code generator  may be implemented in hardware or a combination of hardware and software.","A scheduler  for application  may be developed in co-simulation design environment . Scheduler  may be an interactive static scheduler or an interactive dynamic scheduler. Scheduler  may implement a mapping of application components ,  and  to individual processing cores on SMP . SMP  may include identical processing cores: core , core , core  and core . The term \u201cidentical\u201d is used herein to indicate that resources associated with the cores are identical. That is, when the input to cores , , ,  is the same, execution results of a given core of SMP  are identical to the execution results of any other core of SMP . It will be appreciated that the number of cores depicted in SMP  is exemplary and the actual number of identical cores in SMPs utilized by embodiments may be less or greater. In one embodiment, SMP  may be the processor for computing device .","Based on the mapping, code for application components ,  and  may be executed on the assigned cores , ,  and  during a co-simulation of application . For example, application component  may be mapped to execute on core . Application component  may be mapped to execute on core . Application component  may be mapped to execute on core . The mapping may maintain data synchronization within application , and across application components ,  and . That is, if application  includes multiple copies of a dataset, application  may be mapped to execute such that the multiple copies are kept in coherence with one and other, and therefore data integrity is maintained. Thread synchronization primitives may be implemented to maintain data synchronization.","It will be appreciated that application  can contain at least one application component that is simulated in co-simulation design environment  while other application components from application  are executed on SMP .","During a co-simulation of application , profiling results may be generated during execution of application  and provided to co-simulation design environment  from the SMP  in real-time, i.e., while application  is executing. Profiling results may include performance statistics associated with the cores of the target SMP. For example, profiling results may include, but are not limited to, metrics and\/or runtime statistics associated with the execution of application  on SMP . Exemplary profiling results may include processor load (a metric associated with the execution utilization of a core), memory usage, stack usage, cache utilization (e.g., hit\/miss statistics), etc. Profiling results may also include metrics relating to a buffer allocation, algorithm data synchronization, an inter-thread wait time, resource utilization by other applications and the execution priorities of those applications. Profiling results are discussed below in greater detail in connection with .","A user of co-simulation design environment  (e.g. a person, another software program or an algorithm that is part of the application running in simulation, etc.) may view profiling results via interface . According to various embodiments, interface  may include a graphical user interface (GUI) or an application programming interface (API). In an embodiment, interface  may be provided via output device  in communication with computing device . The user may review the information from profiling results. Based on the review, the user may interactively vary the scheduling scheme of scheduler  during the execution of application  via interface . According to various embodiments, the user may use input device  to interact with interface . The scheduling scheme may be interactively varied without halting execution of application . In addition, the scheduling scheme can be modified without re-generating, re-compiling or re-running code for application .","According to various embodiments, the application components may be formed by grouping, i.e. factoring together, various components of application .  depict an exemplary technique for factoring an application into application components within a BDE.",{"@attributes":{"id":"p-0084","num":"0083"},"figref":"FIG. 6A","b":["600","600","602","604","616","602","604","606","602","604","606","607","607","610","608","608","607","610","613","607","616","618","618","607","616","619"]},"Output signal  is fed into if-block . If output signal  satisfies the condition specified in the if-block , output signal  is added with output signal  at adder block . The output  of adder block  is fed into block  which may contain a Boolean expression such as \u2018AND\u2019. Output signal  is also fed into block . The output of block  may be generated as the final output  of the block diagram model  illustrated in . Block diagram model  may be an executable block diagram model that represents a dynamic system that can be simulated on target hardware. Additionally, block diagram  may be factored according to an instruction received from a user or programmatically, e.g., from a remote application. The factorization of block diagram  is illustrated in .","As illustrated in , blocks , , , , , and  may be grouped together to form a first factored region, e.g. demarcation boundary , of diagram  according to an instruction received from a user or programmatically, e.g., from a remote application. Demarcation boundary  indicates that blocks , , , ,  and  represent a group. Blocks , , ,  and  of block diagram  remain outside demarcation boundary  and thus are not part of the group. Grouping of the elements illustrated in  is for illustrative purposes and should not be construed as limiting.","In , the blocks within demarcation boundary  are designated as application component  in block diagram . Use of application component  to represent blocks , , , , , and  does not alter the design of block diagram . As illustrated in , three outputs ,  and  leave the demarcated boundary of application component . These three outputs , ,  are illustrated as output signals of application component  in .  further illustrates an additional grouping of blocks ,  and  using demarcation boundary . Similarly, block  is encompassed by demarcation boundary .","According to various embodiments, factorization may attempt to break components of an application into groups according to a criteria. For example, an application may be factored into groups using as few groups as possible.  illustrates an exemplary factorization result for block diagram . Blocks ,  and  are designated as application component . Block  is designated as application component . As shown in , exemplary factorization illustrated in  resulted in grouping blocks of diagram  into three application components ,  and .","Application components ,  and  of application  may be executed on an SMP using an interactive static scheduler or an interactive dynamic scheduler.",{"@attributes":{"id":"p-0090","num":"0089"},"figref":["FIGS. 7A-7C","FIG. 7A","FIG. 7A"],"b":["750","700","702","704","752","754","756","702","704","706","708","710","712","720","754","706","756","708","752","712"]},"During co-simulation, a user or a program can modify the mapping between the application components and cores of the SMP by re-allocating application components to different cores for execution. For example, via input device , a user may activate interface  displayed on output device . Interface  may be associated with application components ,  and . According to various embodiments, interface  may be a graphical user interface (GUI) or an application programming interface (API).  illustrates an exemplary GUI as interface . Interface  allows a user to switch the execution of application component  from the currently selected core  to another core via graphical affordance . Graphical affordance  may include, for example, a button, a dropdown menu, a list, etc. The switch can be made from co-simulation design environment . For example, selecting a core on graphical affordance  of interface  may transfer execution of application component  from core  to core  when application component  is next invoked (i.e., the next time application component  runs). It should be noted that co-simulation may not need to be stopped during the core selection and execution transfer processes. That is, the execution of application component  is transferred from core  to another core without re-generating, re-compiling or re-running code for application component  or application components  and .",{"@attributes":{"id":"p-0092","num":"0091"},"figref":["FIG. 7C","FIG. 7A","FIG. 7C"],"b":["760","720","760","752","710","754","756","708","706","712","760","752","754","756","706","708","710","712","760","752","754","756","752","754","756","720","760","752","754","756"]},"As provided above, an interactive static scheduler or a co-simulation dynamic scheduler may be used to modify the scheme assigning the execution threads associated with application components to processing cores on the SMP. That is, an interactive static scheduler or a co-simulation dynamic scheduler may be used to remap the execution threads associated with application components to different processing cores on the SMP during co-simulation. According to various embodiments, the scheduling scheme, i.e. the mapping between the execution threads and processing cores, may be modified by a user, such an algorithm or an application. The \u2018main.c\u2019 code illustrated below represents the main execution entry point of the application components to be executed on the target SMP. The \u2018main.c\u2019 code also refers to the main thread of the application components running on the SMP that receives instructions from the co-simulation environment and allocates the other application threads to processing cores. In this example, there is one thread representing one application component. The thread representing the application component is illustrated using a variable called \u2018baseRateThread\u2019 in the code. Additionally, the desired processor core number to which the application component is to be mapped is received from the host simulation environment and stored in a variable called \u2018cpuset\u2019 during co-simulation. With the statement, s=pthread_setaffinity_np(baseRateThread, sizeof(cpu_set_t), &cpuset); the thread, \u2018baseRateThread\u2019, is set to be executed on the processor core pointed to by \u2018cpuset\u2019 Since the processor core identification is parameterized, the core processors to execute the application components may be set and changed during co-simulation. Therefore, modifying the scheduling scheme does not require re-generating, re-compiling, and re-running the code for the application comprising the application components. Provided below is an exemplary C-code program that executes on the SMP for modifying the scheduling scheme without re-generating, re-compiling, and re-running code for the application components.","Generated Examplary C-code","#include <stdio.h>","#include <sys\/types.h>","#include <sys\/socket.h>","#include <netinet\/in.h>","void baseRateTask(void *arg)","{","while (1) {\n\n","}","int main(argc, char *argv[ ])","{","pthread_t baseRateThread;\n\n","struct sockaddr_in serv_addr, cli_addr;","int n;\n\n","sp.sched_priority=sched_get_priority_max(SCHED_FIFO);","ret=sched_setscheduler(0, SCHED_FIFO, &sp);","\/* Set thread attributes *\/","pthread_attr_init(&attr);","ret=pthread_attr_setinheritsched(&attr, PTHREAD_EXPLICIT_SCHED);","CHECK_STATUS(ret, \u201cpthread_attr_setinheritsched\u201d);","ret=pthread_attr_setschedpolicy(&attr, SCHED_FIFO);","CHECK_STATUS(ret, \u201cpthread_attr_setschedpolicy\u201d);","ret=pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED);","CHECK_STATUS(ret, \u201cpthread_attr_setdetachstate\u201d);","stackSize=131072+PTHREAD_STACK_MIN;","ret=pthread_attr_setstacksize(&attr, stackSize);","CHECK_STATUS(ret, \u201cpthread_attr_setstacksize\u201d);\n\n","ret=pthread_attr_setschedparam(&attr, &sp);\n\n","ret=pthread_create(&baseRateThread, &attr, (void *) baseRateTask, (void *)0);\n\n","sockfd=socket(AF_INET, SOCK_STREAM, 0);\n\n","bzero((char *) &serv_addr, sizeof(serv_addr));","portno=atoi(argv[1]);","serv_addr.sin_family=AF_INET;","serv_addr.sin_addr.s_addr=INADDR_ANY;","serv_addr.sin_port=htons(\u201810000\u2019);\n\n","listen(sockfd, 5);","clilen=sizeof(cli_addr);","newsockfd=accept(sockfd, (struct sockaddr *) &cli_addr, &clilen);\n\n","\/* begin receiving messages from host *\/","CPU_ZERO(&cpuset);\n\n","The ability to modify the scheduling scheme of application components as illustrated in  gives a user the ability to determine an allocation of application components to cores to provide things, such as but not limited to, improved load balancing on the SMP, faster execution of the application, improved processing efficiency and optimal memory usage. In an embodiment, a user can determine a best or optimum allocation of application components to cores. The user may use real-time information, such as statistics about the cores processing the application components, to better determine which modifications may improve processing efficiency among the cores. For example, relevant runtime statistics, such as CPU load and memory usage, may be streamed back to the co-simulation design environment from the target SMP in real time, i.e. while the code for the application components is being executed on the target SMP. Accordingly, it may be beneficial to provide relevant runtime statistics to the co-simulation design environment where the user can access the runtime statistics.","According to various embodiments, the target SMP may send continuous runtime statistics updates to the co-simulation design environment. As illustrated in , profiling results  may be generated during execution of application  including application components , ,  and  and provided to co-simulation design environment  from SMP  in real-time, i.e., while application  is executing. Profiling results may include performance statistics associated with cores , , ,  of SMP . For example, profiling results  may include, but are not limited to, metrics and\/or runtime statistics associated with the execution of application  on SMP . Exemplary profiling results  may include processor load (a metric associated with the execution utilization of a core), memory usage, stack usage, cache utilization (e.g., hit\/miss statistics), etc. Profiling results  may also include metrics relating to a buffer allocation, algorithm data synchronization, an inter-thread wait time, resource utilization by other applications and the execution priorities of those applications.","A portion of the profiling results may be provided to the user in various graphical and\/or textual formats, if desired. For example, profiling results  may be provided on output device . Based on the profiling results, the user may change the interactive static or dynamic scheduling scheme to improve execution efficiency of the code including but not limited to increasing execution speed, minimizing memory usage, improving load distribution across cores, minimizing power consumption, minimizing communication among the cores, etc. For example, the user may change the mapping of application components , , ,  to cores , , ,  using interface  via input device  for faster execution or to better meet application design constraints.","According to various embodiments, relevant runtime statistics may be provided in the co-simulation design environment and back-annotated to corresponding application components. For example, runtime statistics associated with each application component may be displayed in the co-simulation design environment along with the corresponding application component.",{"@attributes":{"id":"p-0130","num":"0160"},"figref":"FIGS. 8B-8C"},{"@attributes":{"id":"p-0131","num":"0161"},"figref":"FIG. 8B","b":["880","862","864","866","868","870","872","874","876","878"]},"Exemplary C-code that implements the flowchart illustrated in  is provided below.","include <stdio.h>","#include <sys\/types.h>","#include <sys\/socket.h>","#include <netinet\/in.h>","#define FIFO_SIZE (8192)","#define REQUEST_PROFILING_DATA (0x1)","#define FLUSH_PROFILING_DATA (0x2)","unsigned long long profilingFIFO[FIFO_SIZE];","int head=0;","int tail=0;","\/* This is the OS thread that runs the algorithm and collects the profiling results *\/","void algorithmTask (void *arg)","{","struct timespec tic, toc;","unsigned long long runTime;","while (1) {\n\n","}","}","\/* Target application program entry point *\/","int main(argc, char *argv[ ])","{","pthread_t algorithmThread, profilingThread;\n\n","struct sockaddr_in serv_addr, cli_addr;","char recvBuf[10];\n\n","pthread_attr_init(&attr);","ret=pthread_create(&algorithmThread, &attr, (void *) algorithmTask, (void *)0);","if (ret<0) {\n\n","}","\/* Open a TCP\/IP socket to upload profiling results to remote host *\/","sockfd=socket(AF_INET, SOCK_STREAM, 0);","if (sockfd<0) {\n\n","}","bzero((char *) &serv_addr, sizeof(serv_addr));","serv_addr.sin_family=AF_INET;","serv_addr.sin_addr.s_addr=INADDR_ANY;","serv_addr.sin_port=htons(\u201810000\u2019);","if (bind(sockfd, (struct sockaddr *) &serv_addr, sizeof(serv_addr))<0)","{\n\n","}","listen(sockfd, 2);","clilen=sizeof(cli_addr);","newsockfd=accept(sockfd, (struct sockaddr *) &cli_addr, &clilen);","if (newsockfd<0) {\n\n","}","\/* Begin receiving messages from remote host *\/","while (1) {\n\n","}","return 0;","}","As provided above, one or more application components of the application provided in the co-simulation design environment may execute on the SMP while other application component(s) may execute on the co-simulation design environment.  illustrates an exemplary flowchart  where an application component of the application is running on the co-simulation design environment during co-simulation. The execution of algorithm component is started on the co-simulation design environment (block ). As the application executes in co-simulation, one or more application components of the application execute on the SMP. The profiler results for those application components running on the SMP may be sent from SMP to the co-simulation design environment using a TCP\/IP server. TCP\/IP server is started for sending the profiling results to the co-simulation design environment (block ). The co-simulation design environment connects to the TCP\/IP server for receiving the profiling results for those application components running on the SMP from the target SMP (block ). The receiver, i.e. the co-simulation design environment, may request the profiling results of the application components running on the SMP from the SMP (block ). The system then determines if the profiling results for current time step has been received (block ). If the profiling results for current time step has been received, the profiling results is displayed for the current time step (block ).","An exemplary C-code that implements the flowchart illustrated in  is provided below.","#define REQUEST_PROFILING_DATA (0x1)","#define FLUSH_PROFILING_DATA (0x2)","void simulationLoop(char *targetIP, unsigned short serverPort)","{","int sock; \/* Socket descriptor *\/\n\n","char buff[BUFSIZE];","int bytesRcvd;\n\n","if ((sock=socket(AF_INET, SOCK_STREAM, IPPROTO_TCP))<0) {\n\n","}","\/* Construct the server address structure *\/","memset(&serv_addr, 0, sizeof(serv_addr));","serv_addr.sin_family=AF_INET;","serv_addr.sin_addr.s_addr=inet_addr(targetIP);","serv_addr.sin_port=htons(serverPort);","\/* Establish the connection to the echo server *\/","if (connect(sock, (struct sockaddr *)&serv_addr, sizeof(serv_addr))<0)\n\n","}","while (simulationMode==SIMULATION_RUNNING) {\n\n","}","}","According to various embodiments, flowchart  illustrated in  and flowchart  illustrated in  may be active simultaneously during co-simulation to illustrate that the profiler results may be received on the co-simulation design environment during co-simulation. Flowchart  illustrated in  describes the application running on the SMP and flowchart  illustrated in  describes the application running on the co-simulation design environment. Accordingly, there may be communication and\/or synchronization between flowchart  and flowchart .",{"@attributes":{"id":"p-0182","num":"0270"},"figref":"FIGS. 9A-12B"},{"@attributes":{"id":"p-0183","num":"0271"},"figref":["FIG. 9A","FIG. 9A"],"b":["900","902","904","906","902","904","906","912","902","902","0","0","914","904","904","0","0"]},"Back-annotated runtime statistics  for application component  indicate that application component  is executed on core  with execution priority of 4 and uses up 78% of the processing resources of core  when executing. The utilization percentage illustrated in back-annotated runtime statistics , , and  refers to the percentage of execution capacity of the specified processing core that the associated component uses. The runtime statistics for application components ,  and  illustrated in  indicate that all components have been mapped to execute on core  on the target SMP. A user may wish to modify the mapping so that more than one core are used to execute application components ,  and .","During co-simulation, a user presented with profiling results may interactively modify the scheduling scheme for an application by re-allocating components to different cores for execution.  depicts model  during co-simulation in which the profiling statistics for the components have been updated following an interactive static or dynamic varying of the scheduling scheme to reassign application component  and application component  to execute on cores  and core , respectively. Following the static or dynamic re-scheduling of the application components to execute on different cores, the back-annotation of profiling results  for application component  indicate that application component  still executes on core , now with execution priority set to 12 and using up 23% of the processing resources of core  when executing.","Back-annotation of profiling results  for application component  indicates that application component  now executes on core  with execution priority set to 7 and using up 57% of the processing resources of core  when executing. Back-annotation of profiling results  for application component  indicates that application component  now executes on core  with execution priority set to 4 and using up 80% of the processing resources of core  when executing.","Comparing the execution profiling results of the modified scheduling scheme illustrated in  with the profiling results of the scheduling scheme illustrated in , it can be determined that the utilization of each component has increased. The increased utilization may be, for example, due to additional communications overhead associated with transferring data between different cores. In the modified scheduling scheme, only application component  executes on core , thereby reducing the load on core . Accordingly, the overall load has been more effectively balanced across the multiple cores.","Profiling results of the modified scheduling scheme illustrated in  can be visually provided on an output device. For example, CPU load  for each core can be processed and may be graphically represented, e.g., using a scope block  and a plot.  depicts exemplary plots , ,  of profiling results for each target processor core respectively, during co-simulation of application components , ,  as depicted in . In plots , , , the utilization percentage over time for core , core  and core , respectively, is displayed and tracks the profiling results displayed in .","Based on utilization graph  of core  illustrated in , the user may determine that resources of core  are being used close to the maximum level. Accordingly, the user may choose to avoid mapping another application component to core  in order to prevent core  from overloading or generating errors. On the other hand, utilization graph  of core  illustrated in  indicates that resources of core  are being used at a minimum level. Accordingly, the user may choose to map other application components to core  in order to better distribute the load between cores  and .","According to various embodiments, the design of an application may be re-factored during co-simulation. As provided above,  illustrate exemplary BDE model  being factored into three application components ,  and . Embodiments allow re-factorization of model .","For example, application components  and  of model  can be combined into a single component.  illustrates exemplary re-factored BDE model  where application component  of BDE model  remains intact. However, in re-factored BDE model , application components  and  of BDE model  are combined together and represented by a new application component . Following re-factorization, the profiling results of application components  and  may be annotated back to BDE model . As illustrated in profiling results  of application component , application component  may be assigned to core  for processing. Application component  uses up to 76% of resources of core . The utilization rate for new application component  is equal to the sum of the utilization rates for two application components  and  together. Profiling results  associated with application component  illustrate that application component is assigned to core  for processing, where application component  uses up to 78% of resources of core .",{"@attributes":{"id":"p-0192","num":"0280"},"figref":"FIG. 10B","b":["1010","632","634","600","1010","630","600","1022","1024","630","600","0","1022","1024","1010","0"]},{"@attributes":{"id":"p-0193","num":"0281"},"figref":["FIG. 11A","FIG. 11A","FIG. 11A"],"b":["1100","1100","1102","1104","1106","1108","1102","1104","1106","1108"]},"The CPU load, i.e. utilization percentage, of a specific core is the sum of all application component utilizations for that core.  illustrates that application component  and application component  are both executed on core , for example core  of SMP  illustrated in . The utilization rate for application component  is 29% and the utilization rate for application component  is 15%. Accordingly, the utilization rate of core  is the sum of the utilization rates for application component  and application component , which is equal to 44%. The utilization percentage of the cores may be displayed in a graphical plot such as plots , ,  and  shown in . Plots , ,  and  graphically depict core utilization on the target SMP, e.g. SMP , over time for model  that is being co-simulated according to the scheduling scheme illustrated in .","Based on the profiling results illustrated in , no application component was assigned to core , for example core  of SMP  illustrated in . Accordingly, graph  for core  indicates an utilization rate of about 0%. As provided above, the utilization rate of core  is the sum of the utilization rates for application component  and application component , which is equal to 44%. Graph  for core  indicates a utilization rate of about 44%. The runtime statistics provided on  show that the utilization rate of core , for example core  of SMP  illustrated in , is 17% and the utilization rate for core , for example core  of SMP  illustrated in , is 65%. Accordingly, graph  for core  indicates a utilization rate of about 17% and graph  for core  indicates an utilization rate of about 65%. The graph provides visual representation to the user illustrating the utilization rates of all cores on SMP . Accordingly, the user can determine if the application components should be re-mapped among the cores using a different scheduling scheme.",{"@attributes":{"id":"p-0196","num":"0284"},"figref":["FIG. 12A","FIG. 12A"],"b":["1200","1202","1204","1206","1208","1210","1200","1202","1204","1206","1204","1208","1206"]},"Accordingly, in , an interactive dynamic scheduler may be better suited for BDE model  as compared to an interactive static scheduler. Profiling results can be back-annotated to model  and shown on BDE representations of components , ,  and . The profiling results may be displayed in streaming fashion. Interactive dynamic scheduler  may switch between a plurality of co-simulation dynamic schedulers during execution of BDE model . Interactive dynamic scheduler  may generate one conventional dynamic scheduler using the plurality of co-simulation dynamic schedulers based on execution, i.e. simulation, results of BDE . According to various embodiments, a conventional dynamic scheduler may be generated using a single co-simulation dynamic scheduler. An interactive dynamic scheduler adds the ability to consider multiple co-simulation dynamic schedulers and generate an optimal, i.e. desired, conventional dynamic scheduler. Interactive dynamic scheduler  is illustrated in greater detail in .","For example, interactive dynamic scheduler  may switch between a first co-simulation dynamic scheduler  or a second co-simulation dynamic scheduler . According to various embodiments, co-simulation dynamic scheduler  may implement a dynamic scheduling algorithm where application components , ,  and  of BDE model  are assigned to SMP cores based on shortest predicted execution time mapped to least busy core. Co-simulation dynamic scheduler  may implement a dynamic scheduling algorithm based on executing the longest waiting component first on the least busy core. Co-simulation dynamic schedulers  and  execute during simulation and control the mapping of the components in model  to the cores of the target SMP. After co-simulation, a conventional dynamic scheduler may be generated using one of the co-simulation dynamic schedulers  and . For example, the optimal conventional dynamic scheduler may be generated that corresponds to the co-simulation dynamic scheduler that had the best runtime statistics during execution of BDE model .",{"@attributes":{"id":"p-0199","num":"0287"},"figref":["FIG. 12C","FIG. 12C","FIG. 12A","FIG. 12A"],"b":["1200","1200","1202","0","1204","2","1206","3","1208","1","0","1","2","3","1224","0","1226","1","1228","2","1222","3","1222","1224","1226","1228"]},"In addition to improving the execution efficiency, it may be necessary to re-map the components to different cores to satisfy system requirements and\/or design constraints. An embodiment may be used to identify schedulers that satisfy certain system requirements and\/or design constraints. For example, with regard to the model  depicted in , an adequate, or possibly optimal, interactive dynamic scheduler might have to take the following into account to satisfy design constraints:\n\n","According to various embodiments, a co-simulation dynamic scheduler may be represented using a state chart BDE such as that depicted as chart  in .  shows a co-simulation dynamic implemented as a state chart. Blocks , , , ,  and  in state chart  represent states. The directed arrows , , , , , , , , ,  connecting one state to another are state transitions. Some state transitions, such as directed arrows , , , , , have conditions attached to them signifying that state transitions occur when the specified conditions are satisfied. The co-simulation dynamic starts by transitioning to state  that contains the initial conditions of the scheduling algorithm.","As illustrated in connection with state , application components  through  start running on core . The co-simulation dynamic starts simulating in the co-simulation environment and continuously monitors the CPU load of core . Based on the condition associated with state transition , if the CPU load of core  exceeds 80%, a state transition occurs. State chart  tests a series of conditions to determine the next state of the algorithm. For example, the condition associated with transition  tests if application component  is running, i.e., active. If it is determined that Component  is active, state transition  to state  occurs. As a result of state transition , the co-simulation dynamic starts executing application component  on core  of the SMP, as indicated by state . There is an unconditional state transition  associated with state , which brings the state back to .","While the co-simulation dynamic is running, the co-simulation dynamic continuously receives runtime statistics from the SMP, e.g., CPU load. The co-simulation dynamic determines the mapping of application components to SMP cores based on the runtime statistics. The user may interactively vary the scheduling scheme by, for example selecting one co-simulation dynamic scheduler among a plurality of co-simulation dynamic schedulers during co-simulation, i.e. only one co-simulation dynamic scheduler is executing at any given time.","According to embodiments, the user or a program may also interactively vary the scheduling scheme by, for example, interactively varying a parameter or a condition of a state transition of a given co-simulation dynamic scheduler. Interactively varying the parameter or the condition of the state transition in turn may alter the decision making process of the co-simulation dynamic scheduler resulting in changing the behavior of the co-simulation dynamic scheduler. For example, the user may decide to change the threshold for state transition  to 70% from the initial 80%. Such interactive actions do not require re-generating, re-compiling or re-running code for the application running on the SMP. Accordingly, co-simulation dynamic schedulers may be interactively modified without re-generating, re-compiling or re-running code for the application running on the SMP.","Once a satisfactory co-simulation dynamic scheduler is identified by interactive dynamic scheduling, code controlling the scheduling of the application, may be generated in the co-simulation design environment for standalone execution on the SMP. That is, a conventional dynamic scheduler is generated as a result of the by interactive static scheduling illustrated in .",{"@attributes":{"id":"p-0206","num":"0298"},"figref":"FIG. 14"},"In , processing may begin by factoring the design of an application, such as a model in either a BDE or TPE, into two or more application components (block ). As provided above, the factored application components can be defined in a BDE by block, by subsystem, by rate, by model, or by demarcated boundary. Similarly, application components in a TPE may be defined by function, by object\/method, by # pragma instrumentation, by model or by demarcated boundary. For example, in an exemplary TPE (e.g., MATLAB\u00ae), code may be factored as follows:","Original:","function comm_dmt(noisePower)","x=1:0.1:1024+noisePower*randn(1024);","y=fft(x, 1024);","z=abs(fftshift(y));","avg=0.0;","for i=1:numel(z)","avg=avg+z(i)^(2\/3);","end","Factor out \u201ccomponent \u201d:","function comm_dmt1(noisePower)","x=1:0.1:1024+noisePower*randn(1024);","z=component(x);","avg=0.0;","for i=1:numel(z)","avg=avg+z(i)^(2\/3);","end","% Sub-component that executes a portion of the original algorithm","function z=component(x)","y=fft(x, 1024);","z=abs(fftshift(y));","The MATLAB code above provides an example depicting how MATLAB functions can be used to factor the design into application components. The MATLAB code shows the results of factoring an application component from the original function comm_dmt, resulting in a new function comm._dmt1 with a factored application component, i.e., the function component.","Processing may initially map application components to one or more cores of the target SMP (block ). Code for the application may be generated based on the initial mapping (block ). For example, in one embodiment, default settings may initially map all application components to one core, and then generate code to be executed on that one core. Mapping all application components to execute on a single core may predict the processing time (CPU load) of each application component. However, such mapping does not predict the potential I\/O wait times if dependent data were to come from a different core (i.e., wait times caused by inter-thread communications and synchronization). Also, the profiling results of the single core execution may not account for cache effects associated with multi-core parallel execution. That is, runtime statistics such as CPU load may not be an exact predictor for CPU load when the application components are distributed across multiple cores in parallel. As a result, in other embodiments, an initial mapping of application components may be distributed across multiple cores rather than all of the components being assigned to execute on the same core.","Once mapped, the application may be co-simulated by executing some application components in the co-simulation design environment and executing other application components for which code has been generated on the SMP using the assigned core(s) (block ).","Profiling may be performed on different components running on the SMP cores during co-simulation. Runtime statistics for the application components can be captured and stored or displayed (block ). The runtime statistics may be displayed in the co-simulation design environment in various graphical and textual formats during co-simulation. For example, runtime statistics may be displayed by back-annotation to the corresponding application components in the co-simulation design environment. For example, a textual display of runtime statistics may include CPU load, memory usage, cache utilization, cache hit\/miss statistics, system throughput, input wait times, buffer use\/re-use, thread dependencies graph\/timelines, etc.","Processing allows for interactively varying the scheduling scheme by reallocating one or more application components to available cores during co-simulation (block ). Reallocation of the application components to available cores results in a modified mapping, i.e., modified scheduling scheme. The interactive varying of scheduling scheme occurs without a user or program first having to re-generate, re-write, re-compile, re-link, re-download and\/or re-run the application code. Embodiments allow implementing application components deployed as threads of execution in a multi-threaded process to allow for varying the scheduling scheme.","A thread may be mapped to any core of an SMP based on, for example, inter-thread communication primitives. The inter-thread communication primitives may include an OS-supplied interface and synchronization abstractions like pipes, messages queues, etc., to carry signal buffers back and forth across the components. Instrumenting and parameterizing the generated code using application programming interfaces (APIs) may allow the co-simulation design environment to tune the processor core affinity while the application components are running on the SMP. Notwithstanding the above, it should be appreciated that threading is one way to dynamically map application components to cores at runtime and embodiments are not limited to deploying application components as separate threads of execution in a multi-threaded process.","Runtime statistics may be updated for the new, modified scheduling scheme. The updated runtime statistics may be analyzed programmatically and\/or by a user (block ). For example, the runtime statistics may be sent back to the co-simulation design environment and back-annotated to the corresponding application components. A user may determine whether the modified scheduling scheme meets requirements. Alternatively, a program may determine whether the modified scheduling scheme meets requirements based on comparing the runtime statistics to pre-determined criteria. If the updated runtime statistics indicate that the modified scheduling scheme meets design requirements (\u201cyes\u201d for block ), a conventional static or dynamic scheduler implementing the modified scheduling scheme is generated for the application (block ). The process ends with generating the conventional static or dynamic scheduler.","If the scheduling scheme does not meet requirements (\u201cno\u201d for block ) a further decision is made as to whether or not there are additional scheduling schemes to attempt (block ).","If there are more scheduling schemes to try in the search for a scheduling scheme that best meets design requirements (\u201cyes\u201d for block ), the sequence repeats and allows the interactive scheduler to reallocate application components to different cores (block ).","If there are no more scheduling schemes to try (\u201cno\u201d for block ) a further determination may be reached as to whether or not there are any more application component combinations to try in which the various elements in the model may be factored into different combinations (block ). The decision as to whether or not there are more application component combinations to try may be made by a user or may be programmatically determined based on pre-determined criteria. If there are more application component combinations to try (\u201cyes\u201d for block ), the process iterates and the application design is factored into two or more different application components (block ). If there are no more application component combinations to try (\u201cno\u201d for block ), then processing may optionally generate the next best conventional static or dynamic scheduler (block ). According to various embodiments, the processing may end without generating a conventional static or dynamic scheduler.","The processing described above in reference to  illustrates an exemplary sequence in which a scheduler that is good enough to meet a design requirement is produced. Processing depicted in  stops once any conventional static or dynamic scheduler that meets design requirements is found. In another exemplary embodiment, the processing of  can be adjusted so as to attempt to generate an optimal conventional static or dynamic scheduler. The processing can include determining whether the current conventional static or dynamic scheduler is the best so far in the co-simulation. The determination may be by a user or programmatically determined without user input based on pre-determined criteria. For example, design requirements for the application may be automatically compared to the profiling results of the modified scheduling scheme to see if the profiling result passes a pre-determined threshold. One or more modified scheduling schemes may be compared and the best scheme may be determined for example as the best-so-far scheduling scheme. The resulting scheduler may be the best-so-far conventional static or dynamic scheduler implementing the best-so-far scheduling scheme.","The potential re-factoring of the application design by assembling new application component combinations provides greater flexibility in identifying an optimal conventional static or dynamic scheduler that meets application design requirements than does the varying of mappings alone. Thus, using the exemplary techniques described above, a generated conventional static or dynamic scheduler that meets design requirements can continually be refined and improved in an attempt to identify an optimal conventional static or dynamic scheduler for an application under development in the co-simulation design environment.","If the co-simulation techniques described above are unable to identify a satisfactory conventional static or dynamic scheduler, a user may need to change some of the variables affecting the co-simulation of the application design. For example, the user (or program) may choose a different SMP platform (with different characteristics), reduce complexity of the application design, lower scheduling requirements, or make other changes and then perform the above-described techniques again to attempt to identify a satisfactory conventional static or dynamic scheduler.",{"@attributes":{"id":"p-0223","num":"0315"},"figref":["FIG. 15","FIG. 15"],"b":["1500","1520","1510","1510","1510"]},"In the network environment, computing devices  and  may provide clients with software components or products under a particular condition, such as a license agreement. The software components or products may include those for providing co-simulation design environment  and\/or implementations of code for select elements. In one example, computing device  may perform program development in the co-simulation design environment  while computing device  hosts a target hardware used in the co-simulation.","In an embodiment a non-transitory computer-readable media is provided. The media comprises one or more instructions that, when executed, cause at least one computing device to interact with a co-simulation design environment using an interface to communicate with a multi-threaded application executing on a target processor. The target processor includes a plurality of symmetric processor cores. The media further comprises one or more instructions that, when executed, cause at least one computing device to allocate execution of the multi-threaded application to one or more symmetric processor cores of the target processor using the interface. The media also comprises one or more instructions that, when executed, cause at least one computing device to receive an interactive instruction via the co-simulation design environment, the interactive instruction to alter allocation of at least a portion of the execution of the multi-threaded application. The media further comprises one or more instructions that, when executed, cause at least one computing device to alter, via the interface, allocation of the at least a portion of the execution of the multi-threaded application.","In another embodiment a method for interactively varying scheduling of a multi-threaded application executing on a symmetric multi-core processor is provided. The method interacts with a co-simulation design environment using an interface to communicate with a multi-threaded application executing on a target processor. The target processor includes a plurality of symmetric processor cores. The method further allocates execution of the multi-threaded application to one or more symmetric processor cores of the target processor using the interface. The method receives an interactive instruction via the co-simulation design environment. The interactive instruction is to alter allocation of at least a portion of the execution of the multi-threaded application. The method alters, via the interface, allocation of the at least a portion of the execution of the multi-threaded application.","In an embodiment, a system for interactively varying scheduling of a multi-threaded application executing on a symmetric multi-core processor is provided. The system includes a memory and a processor. The memory stores allocation information. The processor interacts with the memory and uses the allocation information to interact with an interface in a co-simulation design environment to communicate with a multi-threaded application executing on a target processor. The target processor includes a plurality of symmetric processor cores. The processor further uses the allocation information to allocate execution of the multi-threaded application to one or more symmetric processor cores of the target processor using the interface. The allocating occurs when the multi-threaded application is executing, without re-generating, re-compiling or re-running code for the multi-threaded application. The processor further uses the allocation information to receive an interactive instruction via the co-simulation design environment. The interactive instruction is to alter allocation of at least a portion of the execution of the multi-threaded application while the multi-threaded application is executing. The processor further uses the allocation information to receive execution data from the multi-threaded application executing on the one or more symmetric processor cores of the target processor. The receiving occurs in the co-simulation design environment via the interface, and when the multi-threaded application is executing. The processor further uses the allocation information to alter, via the interface, allocation of the at least a portion of the execution of the multi-threaded application based on the received data, while the multi-threaded application is executing on the symmetric processor cores of the target processor, without re-generating, re-compiling or re-running code for the multi-threaded application.","Although the embodiments described above take place within a co-simulation design environment, other embodiments are also possible within the scope of the present invention. For example, in another embodiment, the search to identify static and dynamic schedulers as described above may take place completely within a simulation environment. In such an embodiment, instead of generating code for a target hardware that will be executed on an actual SMP during co-simulation, the performance of the SMP cores in executing the application being designed may be completely simulated within a simulation design environment. During the simulation, a user or program may be presented with simulated performance data representing the performance of the virtual cores of the SMP and may adjust scheduling attributes based on the data. While such an embodiment may suffer some accuracy loss due to not running the application code on the actual target hardware, it may provide a lower cost alternative and be more readily-available than the co-simulation techniques described above as the target hardware does not need to be available during application design.","One type of application that can be co-simulated may include a block diagram model representing a real-world system. It should be noted that the term block diagram may also refer to and can include other graphical modeling formalisms. For instance, flow-charts are block diagrams of entities that are connected by relations. Flow-charts may be used to capture process flow and may not generally be suitable for describing dynamic system behavior. Data flow block diagrams are diagrams of entities with relations between them that describe a graphical programming paradigm where the availability of data is used to initiate execution of blocks in the diagram. In data flow diagrams, a block may represent an operation and a line may represent execution dependency describing the direction of data flowing between blocks. It will be appreciated that a block diagram model provided in one modeling formalism may include entities from other modeling formalisms.","Embodiments described herein may be provided as one or more computer-readable programs embodied on or in one or more physical and non-transitory computer-readable storage media. The media may be a floppy disk, a hard disk, a compact disc, a digital versatile disc, a flash memory card, a PROM, an MRAM, a RAM, a ROM, a magnetic tape, etc. In general, the computer-readable programs may be implemented in any programming language. Some examples of languages that can be used include MATLAB\u00ae programming language, FORTRAN, C, C++, C#, Python, FLASH, JavaScript, or JAVA\u00ae. A programming language may be an array-based language. An array-based language is a language where an array is a basic unit of data storage. An array may have zero or more dimensions. An example of an array based language may be a language at least a subset of which is executable in the MATLAB\u00ae programming environment. The software programs may be stored on, or in, one or more mediums as object code. Hardware acceleration may be used and all or a portion of the code may run on a FPGA, an Application Specific Integrated Processor (ASIP), or an Application Specific Integrated Circuit (ASIC). The code may run in a virtualized environment such as in a virtual machine. Multiple virtual machines running the code may be resident on a single processor.","Since certain changes may be made without departing from the scope of the present invention, it is intended that all matter contained in the above description or shown in the accompanying drawings be interpreted as illustrative and not in a literal sense. Practitioners of the art will realize that the sequence of steps and architectures depicted in the figures may be altered without departing from the scope of the present invention and that the illustrations contained herein are singular examples of a multitude of possible depictions of the present invention.","The foregoing description of example embodiments of the invention provides illustration and description, but is not intended to be exhaustive or to limit the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practice of the invention. For example, while a series of acts has been described herein, the order of the acts may be modified in other implementations consistent with the principles of the invention. Further, non-dependent acts may be performed in parallel.","In addition, implementations consistent with principles of the invention can be implemented using devices and configurations other than those illustrated in the figures and described in the specification without departing from the spirit of the invention. Devices and\/or components may be added and\/or removed from the implementations described herein depending on specific deployments and\/or applications. Further, disclosed implementations may not be limited to any specific combination of hardware.","Further, certain portions of the invention may be implemented as logic that performs one or more functions. This logic may include hardware, such as hardwired logic, an application-specific integrated circuit, a field programmable gate array, a microprocessor, software, wetware, or a combination of hardware and software.","No element, act, or instruction used in the description of the invention should be construed as critical or essential to the invention unless explicitly described as such. Also, as used herein, the article \u201ca\u201d is intended to include one or more items. Where only one item is intended, the term \u201cone\u201d or similar language is used. Further, the phrase \u201cbased on,\u201d as used herein is intended to mean \u201cbased, at least in part, on\u201d unless explicitly stated otherwise.","The scope of the invention is defined by the claims and their equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate one or more embodiments of the invention and, together with the description, explain the invention. In the drawings:",{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIGS. 1A-1C"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIGS. 2A-2B"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":["FIGS. 6B-6C","FIG. 6A"]},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 6D","FIG. 6A","FIGS. 6B-6C"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 7A"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 7B","FIG. 7A"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 7C","FIG. 7A"]},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 8B"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 8C"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 9A"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 9B"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 9C","FIG. 9B"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 10A","FIG. 6"]},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 10B","FIG. 6"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 11A"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 11B","FIG. 11A"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 12A","FIG. 12B"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 12B","FIG. 11A"]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 12C","FIG. 12A"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 15"}]},"DETDESC":[{},{}]}
