---
title: Immersive scaling interactive television
abstract: A video media viewport/window may be progressively scaled and/or repositioned based on sequential navigational commands received via an input device. A process may include presenting video media within a viewing window that substantially spans an area of the display, and receiving, during playback of the video media, a plurality of sequential user input commands via an input device that indicate a navigational command in a first direction. In response to receiving the sequential user input commands, the system may progressively scale the viewing window to increasingly smaller size viewing windows, position the smaller size viewing windows a distance from a center of the display relative to the direction of the received navigational commands, and present one or more interactive elements outside of the smaller size viewing windows.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09380345&OS=09380345&RS=09380345
owner: Microsoft Technology Licensing, LLC
number: 09380345
owner_city: Redmond
owner_country: US
publication_date: 20141201
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Example One","Example Two","Example Three","Example Four","Example Five","Example Six","Example Seven","Example Eight","Example Nine","Example Ten","Example Eleven","Example Twelve","Example Thirteen","Example Fourteen","Example Fifteen","Example Sixteen","Example Seventeen","Example Eighteen","Example Nineteen","Example Twenty","Example Twenty-One","Example Twenty-Two","CONCLUSION"],"p":["Display interfaces for conventional video media (e.g., broadcast television) predominantly rely on \u201cpanel-based\u201d overlay technology or picture-in-picture (PiP) technology to allow a viewer of the video media to interact with elements on the display screen. For example, a viewer may press a button on a remote control that causes an overlay panel to be presented on the display screen while the video media continues to play in the background. In this scenario, the overlay panel may present an electronic programming guide (EPG), television settings, or other similar information to the viewer. PiP-based interfaces place the video media in a small viewport that is typically positioned near a periphery of the display, and is overlaid or composited on top of another video feed or on another type of user interface. In either scenario, the user interface is modal, meaning that the viewer can choose to be in either a video media viewing mode (with the video media presented in full screen), or a non-viewing mode (with the video media presented in the background or in a PiP viewport).","Described herein are techniques and systems for progressively scaling and repositioning a video media viewport\/window based on sequential navigational commands received via an input device. The size to which the viewport is scaled and\/or the position on the display where the viewport is placed may be in context of directional navigation from an origin point that corresponds to full screen viewing of the video media. In other words, the degree of movement from the origin (full screen viewing) that is indicated by the sequentially received navigational commands may dictate the amount of scaling and the particular position of the scaled viewport on the display screen. For instance, as a viewing user navigates (via an input device) further and further in a direction from the origin (full screen viewing), the viewing window or viewport within which the video media is presented may be progressively scaled to increasingly smaller size viewing windows, and repositioned at respective distances from a center of the display. In addition, upon scaling and repositioning the video media viewport, interactive elements may be presented on the display in areas outside and around the scaled video media viewport. The interactive elements may reflow around the viewport as the viewport is progressively scaled and repositioned.","By providing a display interface that progressively scales and repositions the video media viewport in context of received navigational commands, a continuum of experience may be provided to a user of the display interface that allows her to intuitively navigate in different directions along the continuum and to customize her viewing experience. A hierarchy of contextual content types may be accessible through the interactive elements that are presented on the display interface in a manner that reduces occlusion of rendered content presented by the interactive elements. Therefore, the arrangement of displayed elements is optimized on the screen, while leaving the viewport unobstructed. In addition, the manner in which the scaled video media viewport is positioned on the display screen gives the user a sense of direction so that she may intuitively navigate to a particular viewing experience. Thus, the user can choose how to immerse herself in contextual content at various hierarchically organized levels while keeping the video media \u201cin-frame\u201d (i.e., the video media remains within the frame or area of the display) via a scaled viewing window. Moreover, the display interface respects the user's desired viewing experience by providing a larger video media viewport in instances when it can be inferred that the user is predominantly interested in watching the video media, and providing a smaller video media viewport in instances when it can be inferred that the user is predominantly interested in browsing contextual content.","Furthermore, the techniques and systems described herein provide optimal user interaction performance and system efficiency. User interaction performance may be optimized through the above-described intuitive navigational interfaces that give the user a sense of direction along the continuum of viewing experiences. This intuitive navigational interface works to decrease user selection\/navigation error rates, among other things, making the user interaction performance more efficient for the user. For example, by providing a notion of an origin location (full screen viewing) as well as navigational directions that a user can traverse to receive different, predetermined viewing experiences, a user is less likely to navigate to an undesired experience by error, thereby reducing the need for providing additional inputs to the system. In this manner, the display interfaces can be specifically tailored and optimized to provide optimal user interaction performance. Additionally, through the implementation of predetermined hierarchical levels along the continuum of viewing experiences, the systems and techniques disclosed herein may leverage system hardware and software to improve system efficiency. For example, display interface modifications may be embodied in system hardware to allow fast computational performance, in some instances. Additionally, or alternatively, high-efficiency programming languages (e.g., register-based operations, look-up tables, etc.) may be leveraged for certain modifications of the display interfaces where predetermined configurations can be predicted in advance.","This Summary is provided to introduce a selection of concepts in a simplified form that is further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.","Embodiments of the present disclosure are directed to, among other things, techniques and systems for progressively scaling and repositioning a video media viewport\/window based on sequential navigational commands received via an input device. For illustrative purposes, video media is often described as broadcast television herein. However, it is to be appreciated that the techniques and systems disclosed herein may utilize video media of any suitable type. A non-exhaustive list of video media contemplated herein includes streaming video, downloaded video, digital versatile disc (DVD) video, Blu-ray video, recorded video (e.g., digital video recorder (DVR) video), and so on. Thus, the techniques and systems described herein are not limited to viewing broadcast television. Additionally, the video media may provide any type of content, such as movies, television programs, games, software programs, etc.","Example Architecture",{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 1","FIG. 1"],"b":["100","102","102","102","102","104","106","106","108","1","108","2","108","108","106","100","100"]},"The computing device  may be implemented as any type of computing device  including, but not limited to, a game console, a set-top box (STB), a smart television (TV), a personal computer, a laptop computer, a tablet computer, a portable digital assistant (PDA), a mobile phone (e.g., a smart phone), an electronic book (e-book) reader, a portable game player, a portable media player, and so forth.  shows a representative computing device  in the form of a game console (), such as the X-box One\u00ae game console, commercially available from Microsoft\u00ae Corporation of Redmond, Wash. Another suitable example of computing devices  may include the Apple\u00ae TV console, commercially available from Apple\u00ae Inc. of Cupertino, Calif.","The computing device  may be configured to present video media on a display  of the computing device . The presented video media may be retrieved from any suitable location or video content source. For example, remote sources, which are represented by the other computing devices , may provide the video media. The other computing devices  may include, without limitation, service providers of broadcast television (e.g., cable operators, satellite operators, etc.), service providers of streaming or downloadable video content (e.g., Netflix\u00ae, Youtube\u00ae, Hulu\u00ae, etc.), and so on. Alternatively, the video media may be retrieved from local sources, such as a local data store  (e.g., a hard drive of the computing device ), or from removable storage  (e.g., digital versatile discs (DVDs), Blu-Ray discs, thumb drives, etc.).","The computing device  is shown as including one or more processors  and one or more forms of computer-readable memory . The processor(s)  may be configured to execute instructions, applications, or programs stored in the memory . In some embodiments, the processor(s)  may include hardware processors that include, without limitation, a hardware central processing unit (CPU), a field programmable gate array (FPGA), a complex programmable logic device (CPLD), an application specific integrated circuit (ASIC), a system-on-chip (SoC), or a combination thereof.","The computing device  may also include additional data storage devices, such as the removable storage , introduced above, and\/or non-removable storage  (e.g., one or more hard disk drives (HDDs)). Computer-readable media may include two types of computer-readable media, namely computer storage media and communication media. The memory , the removable storage , and the non-removable storage  are all examples of computer storage media. Computer storage media may include volatile and non-volatile, removable, and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, or other data. Computer storage media includes, but is not limited to, random access memory (RAM), read-only memory (ROM), erasable programmable read-only memory (EEPROM), flash memory or other memory technology, compact disc read-only memory (CD-ROM), DVD, or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other non-transmission medium that may be used to store the desired information and which may be accessed by the computing device . Any such computer storage media may be part of the computing device . In general, computer storage media may include computer-executable instructions that, when executed by the processor(s) , perform various functions and\/or operations described herein.","In contrast, communication media embody computer-readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave, or other transmission mechanism. As defined herein, computer storage media does not include communication media.","The memory  may include an operating system (OS) , which may include one or more subcomponents, such as a user interface (UI) module , and an OS agent . The UI module  may be configured to output the display interface  on the display  of the computing device . The OS agent  may be configured to assist a user of the computing device , such as by providing searching functionality, facilitating companion viewing functionality, and other \u201cvirtual assistant\u201d functions, as will be described in more detail below.","The memory  may further include a content retrieval module  that is configured to obtain content from various sources. For example, the content retrieval module  may retrieve contextual content or information from the other computing devices , the retrieved content being ultimately presented via the display interface  as the interactive element(s) . As another example, the content retrieval module  may retrieve video content from the various aforementioned content sources, such as the other computing devices , the local data store , the removable storage , and\/or the non-removable storage .","The local data store  may store various types of data such as video content (e.g., recorded videos, downloaded or imported videos, and so on), user profile data of the users who operate the computing device , and the like. Accordingly, users may be able to log\/sign into respective user profiles (e.g., via credentials, biometric data (e.g., fingerprint scan, facial recognition, etc.), and so on) so that the identity of each user may be determined by the computing device  to customize a video media viewing experience for the specific user. In this scenario, user profiles that are stored in the local data store  may represent individuals and\/or groups of users. For example, a shared, family computing device  may store a \u201cfamily\u201d profile for a group of users.","The computing device  may include, or may be connectable to, one or more input devices  for interfacing with the computing device . The input device(s)  may include, without limitation, a pointing device (e.g., a mouse, joystick, etc.), physical buttons, a remote control, a camera(s), a microphone(s) (e.g., for receiving voice commands), a touch screen display, and\/or any other suitable input device . The input device(s)  may be a wired or wireless input device(s) .  shows a representative example input device  in the form of a remote control () (e.g., a game controller). In some embodiments, the remote control () may include various buttons and\/or manual actuators, including, without limitation, one or more thumbsticks , a directional pad , bumper buttons , and the like, that allow a user to provide various types of user input commands to the computing device .","One type of input command that may be input via the input device(s)  comprises a navigational command. A navigation command indicates a direction, and the navigational command may be provided via one or more of the thumbsticks , the directional pad , and\/or the bumper buttons  to provide directional input (e.g., right, left, up, down, or any intermediate direction thereof) to the computing device . In some embodiments, tilting gestures may be enabled by an inertial measurement unit (IMU) of either the input device(s)  or the computing device  when the computing device  is a mobile or hand-held device. For example, gyroscopes, accelerometers, magnetometers, or any combination thereof, may allow for sensing orientation of the input device(s)  or the computing device  itself that may be analyzed and interpreted as navigational commands. That is, a user may tilt or move the computing device  to her right to indicate a rightward navigational command.","In some embodiments, the input device(s)  may include a three-dimensional (3D) camera or depth camera that is configured to continuously detect image data (i.e., capture video) of a user with depth information so that movements of the user may be interpreted by onboard processing units of the computing device  as user input commands (e.g., navigational commands). For example, a user may extend or swipe her hand to her right to indicate a rightwards navigational command. The camera-based input device(s)  may use any suitable technique to capture image data with depth information (e.g., time-of-flight (ToF), structured light imaging, stereo imaging, etc.) to facilitate the techniques described herein. In some embodiments, infrared (IR) sensors may be used to emit and\/or detect IR light as a means of ToF imaging. One suitable example camera-based input device  that may be used for detecting user input (e.g., navigational commands) is the Kinect\u00ae sensor used with the Xbox\u00ae console system from Microsoft\u00ae Corporation of Redmond, Wash.","The computing device  may further include one or more output devices  for providing output to a user of the computing device . The output device(s)  may include, without limitation, the display , speakers, tactile feedback mechanisms, a printer, and so on. For example, the display  may provide visual output to a user of the computing device , such as when outputting the display interface  on the display . The display  may be of any size, as represented by the width, w, and height, h, dimensions of the display interface , which may span substantially the entire area (w\u00d7h) of the display .","The computing device  may further include one or more communication connections  that allow the computing device  to communicate with the other computing devices  such as via a network (e.g., the Internet). Additionally, the communications connection(s)  may enable WiFi-based communication such as via frequencies defined by the IEEE 802.11 standards, short range wireless frequencies such as Bluetooth\u00ae, or any suitable wired or wireless communications protocol that enables the computing device  to interface with the other computing devices .",{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIG. 2","FIG. 1"],"b":["200","102","202","102","102","102","1","102","2","102","3","102","202"]},"The computing device  may be configured to receive, via the network , video media from one or more cable operators  that maintain equipment (), (), . . . , (P) (collectively ) for transmitting video media over the network . For example, the cable operator  may broadcast television over the network  to a plurality of computing devices, such as the computing device . Additionally, or alternatively, the equipment  may allow for streaming or downloadable video media that is accessible to the computing device  on-demand.","The computing device  may be configured to retrieve, via the network , content from one or more content providers  that maintain one or more servers (), (), . . . , (Q) (collectively ) for transmitting content in response to requests from the computing device . The content provider(s)  may represent various types of content providers, including, without limitation, social networking sites (e.g., Facebook\u00ae, Twitter\u00ae, etc.), video content sites (e.g., Netflix\u00ae, Youtube\u00ae, Hulu\u00ae, etc.), encyclopedia information sites (e.g., Wikipedia\u00ae, IMDB\u00ae, etc.), news sites, electronic commerce (e-commerce) sites, media file hosting sites (e.g., OneDrive\u2122, commercially available from Microsoft\u00ae Corporation of Redmond, Wash., Google Drive\u2122, commercially available from Google\u00ae Inc. of Menlo Park, Calif.), and so on. In some embodiments, the computing device  may be configured to utilize one or more search engines (e.g., Bing\u00ae, Google Search\u00ae, etc.) to search for content available from the content provider(s) . For instance, content that is available from the content provider(s)  may be indexed by a search engine accessible to the computing device  so that the computing device  may efficiently retrieve content (e.g., contextual content) from the content provider(s)  based on search queries. In some embodiments, the computing device  may utilize an application programming interface (API) to programmatically issue such queries to the search engine.","In some embodiments, the computing device  may be a thin-client configured to display a graphical user interface (GUI) provided by one or more remote computing resources . The one or more remote computing resources  may be provided on one or more servers (), (), . . . , (R) (collectively ) for carrying out some or all of the functionality of the techniques and systems described herein. As such, server(s)  may include some or all of the components of the computing device  described with reference to . In this scenario, the thin-client computing device  may include at least a display  and a communication connection(s)  to receive data over the network .","Example Display Interface Functionality",{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 3","FIG. 1"],"b":["104","102","104","132","104","300"]},"In the example illustrated by , a user may have powered on the computing device  and caused the computing device  to present video media on the display  in the \u201cfull screen\u201d viewing state . In the full screen viewing state , video media (e.g., broadcast television) may be presented within a viewing window  that is sized to substantially span the entire area (w\u00d7h) of the display . For example, live television may be presented within the viewing window  in the full screen viewing state . The full screen viewing state  may correspond to a \u201clowest engagement\u201d viewing experience referred to as the \u201cnow playing\u201d viewing experience . The \u201cnow playing\u201d viewing experience  may define the origin of the continuum  of viewing experiences that the user may navigate between.","In some embodiments, the computing device  may default to the \u201cnow playing\u201d viewing experience  upon power-up of the computing device . In other embodiments, the user may first invoke an application to view video media on the display  where a viewing experience, such as the \u201cnow playing\u201d viewing experience , may be launched by default. Such an application may be a native application that is integrated into the OS , or it may be a standalone, aftermarket application downloaded to the computing device , or it may be a web-based application rendered within a browser, or the like.","In response to receipt of sequential user input commands via the input device(s)  that each indicate a first navigational direction, different display interfaces, such as the display interfaces , , , and , may be output on the display . These display interfaces -, progressively scale and reposition the viewing window  in context of the received navigational commands. For example, if a user presses the rightmost portion of the directional pad  of the remote control (), the display interface  may be output on the display . Upon a subsequently received user input command in the same navigational direction as the first input command (i.e., rightward or positive X direction), the display interface  may be output on the display . Thus, as the user continues to navigate further and further to the right, the display interfaces  and  may be output in order to progressively scale down and reposition the viewing window  such that the center of the scaled down viewing window  is positioned at a distance from the center of the display . The scaling and repositioning of the viewing window  may include interpolated data points between two discrete positions to make the scaling and repositioning appear smooth and continuous to the viewer. In some embodiments, the scaling and repositioning between two relative positions may be presented as more discrete steps. In some instances, a component of the direction from the center of the display  to the center of the scaled down viewing window  is opposite the direction of the navigational command. For example, when a rightward navigational command is received, the center of the scaled viewing window  may be positioned in a direction from the center of the display  that has at least a component direction in the leftward direction. In other words, the direction from the center of the display  to the center of the scaled viewing window  may be in a diagonal direction (e.g., upward and leftward direction), and therefore, the diagonal direction may be represented with two components (e.g., an upward component and a leftward component) of the diagonal direction, at least one of them being different than the direction of the navigational command.","In addition, one or more interactive elements  may be presented outside of the viewing window  in each of the display interfaces  and . These interactive elements  may provide content in context of the navigational commands that corresponds to hierarchically arranged types of content, as shown by the continuum .","In the illustrative example shown in , the content to be displayed via the interactive elements  may correspond to different viewing experiences along the continuum  of viewing experience. In the rightward direction along the continuum , viewing experiences may include, without limitation, a \u201csocial\u201d viewing experience , an \u201cagent\u201d viewing experience , and a \u201cpartners\u201d viewing experience , each of which will be described in more detail below with reference to the following figures. In other words, as the user navigates farther and farther in the rightward (i.e., positive X-direction), she can be immersed in different, hierarchically organized viewing experiences (e.g., viewing experiences -) that are output on the display  via the dynamically changing display interfaces  and , for example.","Similarly, if sequential user input commands are received via the input device(s)  indicating a leftward (i.e., a negative X) direction, the display interfaces  and  may be output on the display  in response to the received sequential input. The display interfaces  and , like the display interfaces  and , progressively scale and reposition the viewing window  in context of the received navigational commands, only this time, the viewing window  may be repositioned by moving it in the opposite direction from the center of the display . Thus, as the user continues to navigate further and further to the left, the display interfaces  and  may be sequentially output on the display  in order to progressively scale down and reposition the viewing window , and to present one or more interactive elements  outside of the viewing window . These interactive elements  may provide content in context of the navigational commands that corresponds to the viewing experiences in the leftward direction along the continuum .  illustrates how the interactive elements  can be reflowed around the scaled-down viewing window , allowing the viewing window to remain visible without occluding the presentation of the interactive elements  and the associated content therein.","In the illustrative example shown in , the hierarchically arranged viewing experiences in the leftward direction may include, without limitation, a favorites viewing experience , a \u201cmy shows\u201d viewing experience , and a \u201cfriends\u201d viewing experience , each of which will be described in more detail below with reference to the following figures. In other words, as the user navigates farther and farther in the leftward (i.e., negative X-direction), she can be immersed in different, hierarchically organized viewing experiences (e.g., the viewing experiences -) that are output via the dynamically changing display interfaces  and , for example. The hierarchical organization of predetermined viewing experiences can be leveraged by the system to utilized high-efficiency algorithms, and\/or combinations of hardware and software that improve computational performance and system efficiency. For example, having predetermined layouts for the display interface  along the continuum  may allow for modifications of the display interface  between points on the continuum  to be implements via hardware algorithms or more efficient programming algorithms (e.g., lookup tables).","The example shown in  illustrates how the display interfaces - give the user a sense of directional navigation when navigating through the continuum . This intuited sense of directional navigation through the continuum  provides a significant benefit in user interaction performance by clearly indicating to the user how to navigate the continuum , thereby reducing or altogether eliminating selection\/navigation error rates, which cause unnecessary processing of input commands by the system. In other words, as the user navigates farther and farther in a particular direction, the manner in which the viewing window  is positioned relative to the center of the display  acts as a visual cue to the user that tells her \u201cif you would like to go back to the full screen viewing state , you can move toward the viewing window .\u201d For example, when the user navigates farther and farther to the right, she knows intuitively to move toward the viewing window  (i.e., in the leftward or negative X direction), which can be realized through sequential user input commands using the input device(s) .","It is to be appreciated that the display interfaces - may comprise modeless interfaces (e.g., modeless GUIs) that are implemented as an application configured to simultaneously present the scaled viewing window  and the interactive element(s)  while allowing user interaction therewith. In this sense, the display interfaces - are embodied via a single interactive application. For example, the viewing window  can be temporarily ignored by the user while the user interacts with the interactive element(s)  of the same application, and vice versa. In other words, user input is interpreted the same for all presented user interface elements at all times.","The example viewing experiences in the continuum  are merely example viewing experiences. Furthermore, the example left and right directions shown in  are merely example directions that may be utilized with an implementation of the system. For example, navigational commands in the upwards (i.e., positive Y direction), downwards (i.e., negative Y direction), and\/or intermediate directions may cause the dynamically changing display interfaces to be output on the display  in a similar fashion.",{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIGS. 4-6","FIG. 3","FIGS. 4-6","FIG. 4"],"b":["302","302","304","300","302","110","110","302"]},"If the user provides user input via the input device(s) , such as pressing a button (e.g., a portion of the directional pad ) on the remote control (), the display output shown in  may be rendered on the display . Specifically, a panel  (sometimes called the \u201cnow playing panel \u201d) may be overlaid on top of the video media presentation. Even though the panel  takes up a portion of the display area (e.g., a portion of the bottom of the display screen), the display output of  may still be considered as the full screen viewing state  because the video media continues to span substantially the entire area of the display  (i.e., the panel  merely obscures a small portion of the bottom of the video media). It is to be appreciated that other relatively minor display elements may be overlaid upon, or presented around, the video media in the full screen viewing state , such that the video media does not have to span the entire area of the display  in the full screen viewing state .","In some embodiments, the panel  may include a navigation bar  that provides a visual indicator  of the current viewing experience along the continuum .  shows the navigation bar  at the bottom of the panel , but it may be placed anywhere within the panel , and oriented in any suitable manner (e.g., vertically oriented) without changing the basic characteristics of the system. In some embodiments, the visual indicator  may comprise a slider element that is movable along the navigation bar  in response to navigational commands received from the input device(s) .",{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 5","b":["504","502","304","502","504","300","304","506","500","506","500","302"]},{"@attributes":{"id":"p-0056","num":"0055"},"figref":["FIG. 5","FIG. 5"],"b":["508","132","508","508","506","500","510","500","512","514","516"]},"If the user moves the focus element  to a different channel, such as \u201cNetwork \u03b2\u201d that is currently broadcasting a Major League Soccer program, and the user selects that channel, the video media may present a live broadcast of the program on that channel, as is shown by the display output of . The display output shown in  is still considered as the full screen viewing state , which, in this case, may still present the panel  for at least a period of time. That is, the panel  may disappear after a period of time has lapsed without any received input from the input device(s) .","The \u201cnow playing\u201d viewing experience  that is represented by  may be considered a lowest engagement viewing experience that respects the fact that the user is watching the video media. The \u201cnow playing\u201d panel  honors the fact that the user is watching the video media by being rendered on the display  as a minimally intrusive panel  that allows the user to find out what shows are on, when they end, and other functionality to aid the user's \u201cnow playing\u201d viewing experience .","From the full screen viewing state  corresponding to the \u201cnow playing\u201d viewing experience , the user may navigate in any direction along the continuum  to immerse themselves in different viewing experiences.  illustrates an example where the user has provides input via the input device(s)  that indicates a rightwards (i.e., positive X) navigational command along the navigation bar . The display output of  represents the \u201csocial\u201d viewing experience  that was introduced with reference to . To provide the \u201csocial\u201d viewing experience , a display interface such as the display interface  of  may be output on the display , as shown in . The display interface  presents a scaled down video media viewport  in the upper left corner of the display . In the example of , the viewing window  is shown as comprising about \u2154 to about \u00be of the display area. This particular size range of the viewing window  respects the fact that the user may still desire to watch the video media while concurrently browsing the interactive elements ()-() that are presented outside of the viewing window . In fact, the notion that the display output of  represents a \u201cviewing experience\u201d exemplifies the fact that the user may prefer to watch the video media in the \u201csocial\u201d viewing experience  on a more permanent basis. In contrast to typical PiP viewports which are too small to continually watch video media in, the size of the viewing window  allows for more permanent viewing of video media while interacting with the content of the interactive elements . The continuum  allows the user to choose what viewing experience to immerse herself in. In some embodiments, the computing device  may be configured to remember a particular viewing experience as a \u201cfavorite\u201d viewing experience of a particular user so that the display output can default to the user's favorite viewing experience upon powering on the computing device . In some embodiments, the computing device  may remember a \u201cmost recent\u201d viewing experience that the user was in before the user exited to the full screen, \u201cnow playing\u201d viewing experience . For example, the user may have viewed the \u201cpartners\u201d viewing experience , then selected a \u201cback\u201d button (\u201cB\u201d button) on the input device  to return to full screen, and then provided a directional input (e.g., selection of the directional pad ). In response to the directional input, the display interface  may return to the most recent viewing experience; in this case, the \u201cpartners\u201d viewing experience , instead of traversing through the intermediate viewing experiences between the \u201cnow playing\u201d viewing experience  and the \u201cpartners\u201d viewing experience .",{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 7","b":["504","502","314","504","502","300"]},{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 7","FIG. 7"],"b":["106","110","110","106","106","110","106","110","106","110","106","110","106","110","106","106","106","108"]},"The \u201csocial\u201d viewing experience  may include interactive elements ()-() that provide \u201csocial\u201d content so that the user can discover activity in a community of users that is related to the program being played back within the viewing window . The content retrieval module  may retrieve such content over the network  from the content provider(s) . For example, the content retrieval module  may retrieve contextual content from social networking sites, such as Twitter\u00ae, Facebook\u00ae, Instagram\u00ae, and so on. The content retrieval module  may search social networking sites for relevant content based on keywords, image analysis, or any other suitable search technology. In some embodiments, a search engine may be utilized to search the content available from social networking sites. Because of the limited \u201creal-estate\u201d on the display  outside of the area allocated for the video media viewport , the content retrieval module  may filter or otherwise curate the retrieved content to a \u201cbest\u201d content subset that is to be presented via the interactive elements ()-(). The selection of the \u201cbest\u201d content may be based on a number of factors, such as quality of media files (e.g., images or videos) of the retrieved content, diversity indicators that analyze posts (e.g., text, images, videos, etc.) that are not too similar, age of the posts (e.g., newer posts may be selected over older ones), and\/or user interaction characteristics (e.g., the number of \u201clikes\u201d, re-shares, comments, top trending posts, etc.). Furthermore, a current state of relationship between the user of the computing device  and other users in the social community may factor into the filtering\/curating of content (e.g., close friends and family activity may be selected over more distant social connections, when applicable).","Because the user is watching a soccer game in the viewing window , the content retrieval module  may search for posts, status updates, and media files (e.g., images, videos, etc.) that are related to soccer in general, and\/or to the specific soccer game being broadcast in the viewing window . For example, the interactive elements () and () may present a social media post from a user of a social networking (SNW) service regarding an interview of one of the star players in the game that is being broadcast. The interactive element () may present buttons that allow the user to save the posted video to the local data store  of the computing device , to re-share the posted video via the social networking service or via another social networking service, and\/or to send the video, or a link to the video, via electronic mail (e-mail), short message service (SMS) text, and the like. The interactive element () may present a picture that a user posted to a social networking site (e.g., a user who is at the soccer game being shown in the viewing window ). The interactive elements () and () may present status updates or posts (e.g., microblogs) from users of various social networking sites that are related to the currently playing video media in the viewing window . The content presented via the interactive elements ()-() may be contextual by relating to the currently broadcast program and may provide a more social viewing experience for the user.","From the \u201csocial\u201d viewing experience , the user may provide another rightward navigational command (e.g., by pressing the rightmost portion of the directional pad  on the remote control ()) to navigate to the \u201cagent\u201d viewing experience  illustrated by . It is noted that the size and\/or position of the video media viewport  between the \u201csocial\u201d viewing experience  and the \u201cagent\u201d viewing experience  may not change. In other words, individual ones of sequentially received navigational commands may not cause any scaling or repositioning of the video media viewport , but may cause the type of content of the interactive elements  outside of the viewing window  to change. The transition from  to  illustrates this scenario. In this case, the additional rightward navigational command caused the interactive elements  to be updated with different content that is related to the \u201cagent\u201d viewing experience . The visual indicator  may also move farther to the right in response to the received navigational command in the rightward direction to indicate to the user that she is in the \u201cagent\u201d viewing experience .","The \u201cagent\u201d viewing experience  may cause the display interface to present an interactive element () that indicates to the user that the OS agent  is currently \u201cviewing\u201d the video media together with the user. One suitable example of an OS agent  for use with the \u201cagent\u201d viewing experience  is Cortana\u2122, commercially available from Microsoft\u00ae Corporation of Redmond, Wash. The OS agent  may \u201cview\u201d the video media with the user by analyze metadata (e.g., closed captioning) associated with the video media, performing visual and\/or audio analysis (e.g., voice recognition, song recognition, etc.) of the video stream, and the like. As the OS agent  performs real-time analysis of the video media that is playing in the viewing window , the OS agent  may create a series of time entries, shown as interactive elements (), (), and (). For example, at time 13:45, the OS agent  may have analyzed metadata of the video media or the video stream itself to determine that the soccer match is being played at the soccer stadium in Seattle, Wash., and created time entry (). At a later time (14:21), the OS agent  recognized that the teams in the soccer match are Seattle vs. Los Angeles, and created time entry (). At an even later time (15:02), the OS agent  may have recognized (via audio recognition) that the announcer said the goalie's name \u201cJohn Goalie,\u201d and created time entry (). As new time entries are added, the previous time entries may be pushed down until they disappear from the display screen. The user may still scroll back through previous time entries to recall content related to those time entries.","As each time entry is presented, and\/or in response to the focus element  being moved over a particular time entry (e.g., time entry ()), interactive elements ()-() may be updated with content that is relevant to that time entry (). For example, the content retrieval module  may access a sports site that tracks statistics of the soccer match for each player and for the teams to present, for example, percentage of shots that were saved by \u201cJohn Goalie,\u201d shown by interactive element (). The content retrieval module  may also retrieve videos that are relevant to the time entry (), such as a highlight video (). Links to informational, encyclopedia, and\/or news sites may be presented, such as the link shown in interactive element (). Player statistics may be retrieved from any suitable content source and presented via interactive element ().","From the \u201cagent\u201d viewing experience , the user may provide another rightward navigational command (e.g., by pressing the rightmost portion of the directional pad  on the remote control ()) to navigate to the \u201cpartners\u201d viewing experience  illustrated by . The visual indicator  may be presented in a rightmost position in response to the received navigational command in the rightward direction to indicate to the user that she is in the \u201cpartners\u201d viewing experience . Furthermore, the viewing window  may be further scaled down in size to a smaller size viewing window  (e.g., about \u00bc of the display area or less) and repositioned further to the left and further above the center of the display . The size of the scaled viewing window  may be based on the notion that it can be inferred that the user is no longer predominantly interested in watching the video media program, but is perhaps more interested in immersing themselves deeper into the contextual content provided via the interactive elements . The associated display interface (e.g., the display interface ) may be a \u201chighest engagement\u201d form of the display interface to engage the user with contextual content via the interactive elements  as much as possible. Thus, the viewing window  may be scaled to various sizes (the viewing window  is not limited to scaling to only one size) depending on the particular viewing experience that the user navigates to along the continuum .","In , the viewing window  is still positioned in the corner of the display , but it is not limited to a corner position. The direction of movement of the viewing window  is generally different from the direction of the received navigational commend, which, in this case, is in the rightward (i.e., positive X) direction. Accordingly, the \u201cpartners\u201d viewing experience  may be enabled by outputting the display interface  of .","The content presented via the interactive elements ()-() in the \u201cpartners\u201d viewing experience  may comprise news articles, blogs, exclusive content from the studio that provides the video media program, or any similar type of content that is related to the video media program playing in the viewing window . Again, because of the limited \u201creal-estate\u201d of the display , a curated set of the \u201cbest\u201d content related to the video media program may be presented on the display screen, yet the user may be able to scroll (vertically and\/or horizontally) or otherwise page through additional \u201coff-screen\u201d interactive elements  that provide additional content for the \u201cpartners\u201d viewing experience .  shows the interactive element () as providing an article from a website that is related to the soccer program being played in the viewing window . The content retrieval module  may have leveraged a search engine to retrieve the article presented via interactive element (). Interactive element () may present a highlights video for one of the teams playing in the soccer program, while interactive element () may present another highlight clip of a player for one of the two soccer teams, named \u201cJim Q. Player.\u201d Interactive element () may, upon selection, allow the user to browse soccer-related video games. In some embodiments, the user may be able to launch a video game that is related to the video media program being played in the viewing window  so that the user can play the related game in parallel to watching the program. For example, the user may be watching Jeopardy\u00ae and may decide that they want to play the video game while watching the program.","In some embodiments, if the user were to move the focus element  over the interactive element (), as shown in , to begin playing the highlights video, the computing device  may temporarily pause the playback of the video media in the viewing window  while the highlights video is played back in another window outside of the viewing window . To provide this functionality, the computing device  may include a DVR or other recording component to at least buffer the video media as it is played back so that it may be paused, and\/or so that the user may seek backward\/forward in the video media stream. In some embodiments, the highlights video, upon selection, may relocate to the larger interactive element () while it is played back. In some embodiments, the highlights video may take over a full screen viewing state , at least temporarily while the highlights video is played back, and upon termination, the display output may revert to the display interface , as depicted in .","The hierarchical organization of the viewing experiences in the continuum  of  may be organized such that the viewing experiences - in the rightward (positive X) direction allow a user to immerse herself further and further into contextual content that is related to the video media program being played back in the viewing window , while the viewing experiences - in the leftward (negative X) direction allow the user to immerse herself further and further into content that is not related to the show, but is in context of the received navigational commands. Thus,  illustrate viewing experiences in the rightward (positive X) direction that provide contextual content that is related to the video media program in the viewing window , and the following figures will illustrate the types of content that may be provided in the viewing experiences that are in the leftward (negative X) direction. It is to be appreciated that the directions and content types can be hierarchically organized in other ways, and that the leftward\/rightward organization illustrated herein are merely one example implementation.","Referring now to , an example display output with a navigation interface  is shown. The navigation interface  may be invoked in response to receipt of user input via the input device , such as in response to the user pressing the bumper buttons  on the remote control (). The navigation interface  may replicate the continuum  of viewing experiences introduced with reference to , and may allow a user to skip to a particular viewing experience along the continuum . For example, the user may provide user input via the input device(s)  in order to move the focus element  to any particular viewing experience in order to navigate directly to that viewing experience. This may be desirable if the user wants to navigate from the \u201cpartners\u201d viewing experience  to the \u201cfriends\u201d viewing experience , for example, rather than traversing back through each intermediate viewing experience in the continuum . Additionally, or alternatively, the user may press a back button on the remote control () to return to the \u201cnow playing\u201d viewing experience  in the full screen viewing state . The above-described features work to improve the efficiency of user interaction performance. For example, the system can change from one viewing experience to another, non-adjacent viewing experience without having to process and render the display interfaces associated with intermediate viewing experiences on the continuum . This greatly improves user interaction efficiency as the user navigates the continuum.","Imagine, for example, that the user navigates to the \u201cfavorites\u201d viewing experience  by, for example, moving the focus element  over the \u201cfavorites\u201d viewing experience  within the navigation interface  of . The resulting display output may be that which is shown in . In the \u201cfavorites\u201d viewing experience , the visual indicator  may be positioned on a portion of the navigation bar  that indicates to the user that she is in the \u201cfavorites\u201d viewing experience , which, in this case, is slightly left of center on the navigation bar . The viewing window  may also be scaled and positioned in a direction from the center of the display  that is opposite the direction of navigation from the origin (i.e., \u201cnow playing\u201d viewing experience ) to the \u201cfavorites\u201d viewing experience . For example, because the \u201cfavorites\u201d viewing experience  is oriented to the left of the continuum origin, the center of the viewing window  may be positioned right of the center of the display  and\/or above or below the center of the display . In the example of , the viewing window  is positioned in the top right corner of the display  and is scaled to a size that is about \u2154 to about \u00be of the display area to honor the fact that the user may be predominantly interested in viewing the video media program while browsing the additional content within the \u201cfavorites\u201d viewing experience .","The \u201cfavorites\u201d viewing experience  may provide, via interactive elements () and () presented outside of the viewing window , recently viewed channels and\/or favorite channels of the user. The interactive element () may comprise a guide that is scrollable and\/or pageable by providing input via the input device(s) .  shows that the user has moved the focus element  over \u201cNetwork \u201d and has provided user input via the input device(s)  to select the program \u201cCar show\u201d on that network\/channel for viewing in the video media viewport . Interactive element () may provide a brief synopsis of the program being broadcast on the highlighted channel, as well as one or more interactive display elements, such as a \u201cRecord\u201d element, an \u201cAdd to Favorites\u201d element, and\/or a \u201cFull Detail\u201d element similar to those described with reference to the display output of . Within the \u201cfavorites\u201d viewing experience , the user may continue to watch the video media program in the viewing window  while browsing through their recently watched and\/or favorite channels.","From the \u201cfavorites\u201d viewing experience , the user may provide a leftward navigational command (e.g., by pressing the leftmost portion of the directional pad  on the remote control ()) to navigate to the \u201cmy shows\u201d viewing experience  illustrated by . The visual indicator  may be moved to the left along the navigation bar  in response to the received navigational command in the leftward direction to indicate to the user that she is in the \u201cmy shows\u201d viewing experience . Again, it is noted that the size and\/or position of the video media viewport  between the \u201cfavorites\u201d viewing experience  and the \u201cmy shows\u201d viewing experience  may not change in the transition from  to , yet the type of content of the interactive elements  outside of the viewing window  may update in context of the navigational command. In this case, the additional leftward navigational command from the \u201cfavorites\u201d viewing experience  caused the interactive elements  to be updated with different content that is related to the \u201cmy shows\u201d viewing experience .","The content presented via the interactive elements ()-() of  may include programs that the user has recorded using the DVR functionality of the computing device , programs are being recorded or marked\/scheduled for recording, programs that the user has marked as favorites, programs that the user has recently watched, and\/or system recommendations for programs that are likely to be of interest to the user based on the user's viewing history.  shows interactive element () as a video that the user has recently recorded or saved to the local memory of the computing device . Interactive element () may present a program that the user has marked as a favorite, and may further indicate a number of shows that are new (at least in terms of whether the user has watched the programs or not). Interactive element () may present a program that the user has recently watched, which may be more of a system-inferred favorite program. The column of interactive elements ()-() in  may be scrollable and\/or pageable so that the user can browse additional content in the \u201cmy shows\u201d viewing experience . Interactive element () may present a system recommendation of a program that the user may be interested in based on the user's viewing history.","From the \u201cmy shows\u201d viewing experience , the user may provide another leftward navigational command (e.g., by pressing the leftmost portion of the directional pad  on the remote control ()) to navigate to the \u201cfriends\u201d viewing experience  illustrated by . The visual indicator  may be positioned at a leftmost portion of the navigation bar  in response to the received navigational command in the leftward direction to indicate to the user that she is in the \u201cfriends\u201d viewing experience . In addition, the viewing window  may be scaled and repositioned in a direction from the center of the display  that is different from the direction of the received navigational command. In this case, in response to the leftward (i.e., negative X direction) navigational command, the position of the viewing window  is moved to the right of the center of the display  and\/or above or below the center of the display . In , the viewing window  is shown as being placed in the upper right corner of the display . The smaller size of the scaled viewing window  appreciates the fact that the user may be less interested in watching the video media program, and relatively more interested in browsing the additional content provided via the interactive elements  outside of the viewing window . The associated display interface (e.g., the display interface ) may be a \u201chighest engagement\u201d form of the display interface to engage the user with additional content via the interactive elements  as much as possible.",{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 13","b":["108","1","1300","108","1","108","2","5","324","324","106"]},"Example Process",{"@attributes":{"id":"p-0079","num":"0078"},"figref":"FIG. 14","b":["1400","106","132"]},"The process  is described with reference to the architectures  and  of . Particular reference may be made to the UI module , the input device , and the display , among other elements shown in .","At , video media (e.g., broadcast television) may be presented on a display  within a viewing window on the display . In some embodiments, the viewing window may substantially span an entire area of the display . In other words, a full screen viewing state  may be invoked to present the video media full screen. This may be a default viewing state, such as when a user powers on the computing device  associated with the display .","At , the computing device  may receive, during playback of the video media, a first user input via an input device  that indicates a navigational command in a first direction within a plane that is parallel to a front surface of the display . The diagram to the right of  shows an example where user input may be provided via the directional pad  of the remote control (). In this case, the user may press the rightmost portion of the directional pad  to indicate a rightward (i.e., positive X direction) navigational command within the plane that is parallel to the front surface of the display .","At , in response to the first user input received at , the UI module  scale down and positioned the center of video media viewport  on a portion of the display  that is a distance from the center of the display . In some embodiments, a component direction from the center of the display  to the position of the center of the scaled viewing window  may be different than (e.g., opposite) the first direction of the navigational command. For example, when the navigational command is in a rightward (i.e., positive X) direction in the plane of the display screen, the movement of the viewing window  may be in the leftward, upward, downward, and\/or intermediate direction in the plane of the display screen. Furthermore, one or more interactive elements  may be presented outside of the scaled viewing window  at . In some embodiments, the interactive element(s)  may surround the viewing window  on at least two sides of the viewing window . The interactive elements  may present contextual content that, in some instances, may relate to the video media program being played back in the viewing window .","At , the computing device  may receive a second, sequential user input via an input device  that indicates a navigational command in the first direction (i.e., the same direction as the navigational command at . The second user input at  is received after the first user input such that the first and second user inputs make up a series of user inputs or a plurality of sequential user inputs that indicate navigational commands in the same direction.","At , in response to the second user input received at , the viewing window  that presents the video media may be scaled down even further and re-positioned on a portion of the display  that is in a direction from the center of the display  that is different than the first direction of the navigational command. Again, if the navigational command is in the rightward direction, the movement\/repositioning of the viewing window  may be in the leftward, upward, downward, and\/or intermediate direction in the plane of the display screen. Furthermore, one or more interactive elements  may be presented outside of the scaled viewing window  at . In some embodiments, the interactive elements  may present content that corresponds to a different viewing experience than the viewing experience at . That is, the interactive element(s)  presented on the display  at  may include a different type of content (e.g., social-based content) than the content of the interactive element(s)  that are presented on the display  at  (e.g., agent-based content).","The process  allows the user of the computing device to navigate through a continuum  of viewing experiences so that she may immerse herself in a viewing experience of her choice. The dynamically changing display interfaces (e.g., display interfaces  and ) progressively scale and reposition the video media viewport  in a manner that gives the user a sense of direction for intuitive navigation throughout the continuum .","The environment and individual elements described herein may of course include many other logical, programmatic, and physical components, of which those shown in the accompanying figures are merely examples that are related to the discussion herein.","The various techniques described herein are assumed in the given examples to be implemented in the general context of computer-executable instructions or software, such as program modules, that are stored in computer-readable storage and executed by the processor(s) of one or more computers or other devices such as those illustrated in the figures. Generally, program modules include routines, programs, objects, components, data structures, etc., and define operating logic for performing particular tasks or implement particular abstract data types.","Other architectures may be used to implement the described functionality, and are intended to be within the scope of this disclosure. Furthermore, although specific distributions of responsibilities are defined above for purposes of discussion, the various functions and responsibilities might be distributed and divided in different ways, depending on circumstances.","Similarly, software may be stored and distributed in various ways and using different means, and the particular software storage and execution configurations described above may be varied in many different ways. Thus, software implementing the techniques described above may be distributed on various types of computer-readable media, not limited to the forms of memory that are specifically described.","A computer-implemented method comprising: causing presentation of video media within a viewing window that substantially spans an area of a display; receiving a plurality of sequential user inputs (e.g., push button, touch screen, voice command, gestural (camera-based), etc.) that indicate a navigational command in a first direction (e.g., horizontal, vertical, or intermediate direction) within a plane that is substantially parallel to a front surface of the display; and in response to receiving the plurality of sequential user inputs: progressively scaling the viewing window to increasingly smaller size viewing windows based at least in part on individual ones of the sequential user inputs; positioning respective centers of the smaller size viewing windows at respective distances from a center of the display; and causing presentation, on the display, of one or more interactive elements outside of the smaller size viewing windows.","The computer-implemented method of Example One, wherein the respective centers of the smaller size viewing windows are positioned in a direction from the center of the display having at least a component of the direction that is in a different (e.g., perpendicular\/orthogonal, opposite, etc.) direction than the first direction of the navigational command.","The computer-implemented method of the previous examples, alone or in combination, wherein the different direction is opposite the first direction.","The computer-implemented method of the previous examples, alone or in combination, wherein the one or more interactive elements: are reflowed around the smaller size viewing windows, and present, or link (e.g., hyperlink) to, content that is related to the video media.","The computer-implemented method of the previous examples, alone or in combination, further comprising: receiving a non-navigational user input (e.g., press of a \u201cback button\u201d); and in response to the receiving the non-navigational user input, reverting to causing presentation of the video media within the viewing window that substantially spans the area of the display.","The computer-implemented method of the previous examples, alone or in combination, wherein the positioning comprises progressively positioning the smaller size viewing windows at increasingly greater distances from the center of the display.","The computer-implemented method of the previous examples, alone or in combination, further comprising: analyzing the video media during playback of the video media; and deriving content to be presented by the one or more interactive elements from the analyzing.","The computer-implemented method of the previous examples, alone or in combination, wherein the smaller size viewing windows and the one or more interactive elements displayed after each sequential user input are included within a modeless graphical user interface that is implemented as an application that presents, while allowing user interaction with, one of the smaller size viewing windows and the one or more interactive elements.","A system comprising: a display having a front surface, a center, and an area; an input device (e.g., a microphone, camera, remote control, etc.); one or more processors; and memory storing computer-executable instructions that, when executed by the one or more processors, cause the one or more processors to perform acts comprising: causing presentation of video media within a viewing window on the display; receiving a plurality of sequential user inputs (e.g., push button, touch screen, voice command, gestural (camera-based), etc.) via the input device that indicate a navigational command in a first direction (e.g., horizontal, vertical, or intermediate direction) within a plane that is substantially parallel to the front surface of the display; and in response to receiving the plurality of sequential user inputs: progressively scaling the viewing window to increasingly smaller size viewing windows based at least in part on individual ones of the sequential user inputs; positioning respective centers of the smaller size viewing windows at respective distances from the center of the display; and causing presentation, on the display, of one or more interactive elements outside of the smaller size viewing windows.","The system of Example Nine, wherein the respective centers of the smaller size viewing windows are positioned in a direction from the center of the display having at least a component of the direction that is in a different (e.g., perpendicular\/orthogonal, opposite, etc.) direction than the first direction of the navigational command.","The system of the previous examples, alone or in combination, wherein the different direction is opposite the first direction, and wherein the positioning comprises positioning the smaller size viewing windows in a corner of the display.","The system of the previous examples, alone or in combination, further comprising an operating system agent stored in the memory and executable by the one or more processors to: analyze the video media during playback of the video media; and derive content to be presented by the one or more interactive elements based at least in part on analyzing the video media.","The system of the previous examples, alone or in combination, wherein the smaller size viewing windows and the one or more interactive elements are included within a modeless graphical user interface that is implemented as an application that presents, while allowing user interaction with, one of the smaller size viewing windows and the one or more interactive elements.","The system of the previous examples, alone or in combination, wherein the input device comprises a remote control having a directional pad, and the user inputs are received via the directional pad.","The system of the previous examples, alone or in combination, wherein the one or more interactive elements present, or link to, content that is related to the video media.","A computer-implemented method comprising: causing presentation of video media within a viewing window on a display; receiving a first user input (e.g., push button, touch screen, voice command, gestural (camera-based), etc.) that indicates a navigational command in a first direction (e.g., horizontal, vertical, or intermediate direction) within a plane that is substantially parallel to a front surface of the display; in response to receiving the first user input: scaling down the viewing window to a first reduced-size viewing window; positioning a center of the first reduced-size viewing window a first distance from a center of the display; and causing presentation, on the display, of one or more first interactive elements outside of the first reduced-size viewing window; receiving a second user input (e.g., push button, touch screen, voice command, gestural (camera-based), etc.) that indicates the navigational command in the first direction; and in response to receiving the second user input command: scaling down the first reduced-size viewing window to a second reduced-size viewing window; positioning a center of the second reduced-size viewing window a second distance from the center of the display; and causing presentation, on the display, of one or more second interactive elements outside of the second reduced-size viewing window.","The computer-implemented method of Example Sixteen, wherein the center of the first reduced-size viewing window is positioned in a direction from the center of the display that is different (e.g., perpendicular\/orthogonal, opposite, etc.) than the first direction of the navigational command.","The computer-implemented method of the previous examples, alone or in combination, wherein the one or more first interactive elements present, or link (e.g., hyperlink) to, a first type of content, and the one or more second interactive elements present, or link to, a second type of content.","The computer-implemented method of the previous examples, alone or in combination, further comprising analyzing the video media during playback of the video media to derive content presented by the one or more first interactive elements or the one or more second interactive elements.","The computer-implemented method of the previous examples, alone or in combination, wherein the first reduced-size viewing window and the one or more first interactive elements are included within a modeless graphical user interface that is implemented as an application that presents, while allowing user interaction with, the first reduced-size viewing window and the one or more first interactive elements.","A system comprising: means for displaying video media, the means for displaying having a front surface, a center, and an area; means for receiving user input; means for executing computer-executable instructions (e.g., processors, including, for example, hardware processors such as central processing units (CPUs), system on chip (SoC), etc.); and means for storing computer-executable instructions (e.g., memory, computer readable storage media such as RAM, ROM, EEPROM, flash memory, etc.) that, when executed by the means for executing computer-executable instructions, cause performance of acts comprising: causing presentation of video media within a viewing window on the means for displaying; receiving a plurality of sequential user inputs (e.g., push button, touch screen, voice command, gestural (camera-based), etc.) via the means for receiving user input that indicate a navigational command in a first direction (e.g., horizontal, vertical, or intermediate direction) within a plane that is substantially parallel to the front surface of the means for displaying; and in response to receiving the plurality of sequential user inputs: progressively scaling the viewing window to increasingly smaller size viewing windows based at least in part on individual ones of the sequential user inputs; positioning respective centers of the smaller size viewing windows at respective distances from the center of the means for displaying; and causing presentation, on the means for displaying, of one or more interactive elements outside of the smaller size viewing windows.","The system of Example Twenty-One, further comprising means for analyzing the video media, the means for analyzing stored in the memory and executable by the means for executing computer-executable instructions to: analyze the video media during playback of the video media; and derive content to be presented by the one or more interactive elements based at least in part on analyzing the video media.","In closing, although the various embodiments have been described in language specific to structural features and\/or methodological acts, it is to be understood that the subject matter defined in the appended representations is not necessarily limited to the specific features or acts described. Rather, the specific features and acts are disclosed as example forms of implementing the claimed subject matter."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The detailed description is described with reference to the accompanying figures. In the figures, the left-most digit(s) of a reference number identifies the figure in which the reference number first appears. The same reference numbers in different figures indicates similar or identical items.",{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 14"}]},"DETDESC":[{},{}]}
