---
title: Sparse sampling and reconstruction for electron and scanning probe microscope imaging
abstract: Systems and methods for conducting electron or scanning probe microscopy are provided herein. In a general embodiment, the systems and methods for conducting electron or scanning probe microscopy with an undersampled data set include: driving an electron beam or probe to scan across a sample and visit a subset of pixel locations of the sample that are randomly or pseudo-randomly designated; determining actual pixel locations on the sample that are visited by the electron beam or probe; and processing data collected by detectors from the visits of the electron beam or probe at the actual pixel locations and recovering a reconstructed image of the sample.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09093249&OS=09093249&RS=09093249
owner: Sandia Corporation
number: 09093249
owner_city: Albuquerque
owner_country: US
publication_date: 20140910
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATION","STATEMENT OF GOVERNMENTAL INTEREST","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","EXAMPLES","Example 1","Example 2","Example 3","Example 4","Example 5","Example 6"],"p":["This application claims priority to United States Provisional Patent Application No. 61\/877,109, filed on Sep. 12, 2013, and entitled \u201cSPARSE SAMPLING AND RECONSTRUCTION FOR SCANNING ELECTRON MICROSCOPE IMAGING\u201d, the entirety of which is incorporated herein by reference.","This invention was made with Government support under Contract No. DE-AC04-94AL85000 between Sandia Corporation and the U.S. Department of Energy. The Government has certain rights in the invention.","Electron microscopes are used in neuroscience, microbiology and materials science for high-resolution imaging and subsequent structural or compositional analysis. In particular, many applications that utilize a scanning electron microscope (SEM) require imaging millimeters or even centimeters of material at nanometer resolutions, leading to semi-autonomous operation of the SEM, weeks of around-the-clock collection time, and vast quantities of data. Scanning probe microscopes are similarly limited.","A traditional SEM operates in raster mode, visiting every \u201cpixel\u201d location in sequence. Many engineering advances have been proposed to increase the speed of raster mode through faster scanning coils, or efficiency gains through image acquisition buffers and communications protocols. Nevertheless, there is a need to provide faster scan times. Advancements that provide speedup in series with any of the aforementioned engineering advances would be particularly beneficial.","Interpolation methods of sampling and imaging, such as bilinear interpolation, are known, but are difficult to apply in high noise environments. A structured sampling methodology, such as interpolation, may also miss details that are regularly structured in a way that avoids recognition of the structure of the sample.","Systems and methods for electron and scanning probe microscope imaging are provided herein. In a general embodiment, the present disclosure provides a method for conducting electron or scanning probe microscopy. The method comprises driving an electron beam or probe to scan across a sample and visit a subset of pixel locations of the sample that are randomly or pseudo-randomly designated; determining actual pixel locations on the sample that are visited by the electron beam or probe; and processing data collected by detectors from the visits of the electron beam or probe at the actual pixel locations and recovering a reconstructed image of the sample.","In another embodiment, the present disclosure provides a retrofit to existing scanning probe or electron microscopes to speed up image acquisition by about two times or greater while providing \u201csmooth\u201d images in which the electron probe measures one-at-a-time a randomly-selected subset of the pixel locations. Smooth images have features that are relatively few and large compared to the pixel spacing. Smooth images are highly compressible. This solution may be particularly desirable in very long collections, such as those needed in biology, neuroscience and materials science.","In an embodiment, image reconstruction is performed using a compressive sensing inversion method\/split Bergman method that utilizes a total variation prior. Significantly, this has been demonstrated in an operational SEM. Speedups of 4\u00d7 and more have been accomplished.","Further details of embodiments of the systems and methods described herein are provided in the publication Hyrum S. Anderson, et al, \u201cSparse imaging for fast electron microscopy,\u201d Proceedings of the SPIE, Vol. 8657, id. 86570C 12 pp. (2013), which is incorporated herein by reference for all purposes.","Additional features and advantages are described herein, and will be apparent from the following Detailed Description and the figures.","Systems and methods for electron and scanning probe microscope imaging are provided herein. Because SEMs are innately single-detector scanning systems, the time to acquire thousands of images of tissue or material for analysis can be extremely prohibitive for many applications. In a general embodiment, the present disclosure provides a system and method (demonstrated on an operational SEM) for a sparse sampling scheme that leverages image smoothness for compressed sensing inversion. Accurate knowledge of the probe location is utilized, and is accounted for through a linear dynamical model.","A scanning electron microscope (SEM) is an example of an electron microscope.  shows a simplified schematic view of an SEM. The SEM includes a column  that houses several components. An electron gun  that emits an electron beam  is disposed at an end of the column . One or more scan coils  are disposed along the interior of the column , and these function to deflect the electron beam  onto a sample area , thereby controlling where the beam contacts the sample area . During data gathering operations, the sample area  includes a sample  disposed thereon for analysis. At least a portion of the sample area  and sample  are divided into pixel locations that may be described and x and y coordinates on a two-dimensional grid.","Components of the column  including the electron gun  and the coil  are coupled to a computing device . The computing device  is further described below in reference to .","It is to be understood that this is a simplified description of an SEM that is provided for explanatory purposes of the components and methodologies described herein in greater detail. Other common components are not shown, such as detectors, a power source, condenser lenses and apertures, and an air lock and pump for the sample chamber, but their locations and function are to be understood.","In a scanning probe microscope embodiment, a physical probe (such as a needle), rather than an electron beam, scans across the sample area surface. There are other differences between electron and scanning probe microscopes, which will be readily appreciated.","Other examples of electron microscopes include transition electron microscopes (TEM), reflection electron microscopes (REM), scanning optical microscope (SOM), and scanning transmission electron microscopes (STEM). In another embodiment, the method is applicable to other domains of nanometer microscopy in which speed is a limiting factor, including scanning probe microscopy, such as atomic force microscopes (AFM) and scanning tunneling microscopes (STM).",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIGS. 2 and 2A"},"Moreover, the acts described herein may be computer-executable instructions that can be implemented by one or more processors and\/or stored on a computer-readable medium or media. The computer-executable instructions may, for example, include a routine, a sub-routine, programs, and\/or a thread of execution. Still further, results of acts of the methodologies may, for example, be stored in a computer-readable medium and\/or displayed on a display device.","Referring now to , a methodology  that facilitates electron or scanning probe microscopy is illustrated. The methodology  begins at , and at  an electron beam or probe is driven to scan across a sample and visit a subset of pixel locations of the sample that are randomly or pseudo-randomly designated. The random sampling may, for example, be computed by a processor in real-time and stored or the sampling may be directed by pre-computed random values. In an embodiment, the full set of pixel locations comprises the sample area that is occupied by the sample itself. The number of pixel locations for a given sample area may be preset or determined by an operator, within the resolution limits of the particular microscope. Typically, the probe interaction area on a sample is much smaller than the distance between pixel locations.","In an embodiment, the dwell time is variable at each location and is a function of the random selection of pixels. Alternatively, the dwell times can be set to a given value required for achieving a desired signal-to-noise ratio (SNR). In general, the methodology  does not require increased dwell times to substantially maintain SNR, nor does it require decreased dwell times to provide the speed up in analysis.","In an embodiment, the dwell time is set, for example, 0.1 to 100 microseconds, such as 1 microsecond to 10 microseconds or 3 microseconds to 8 microseconds at each pixel location. Depending on the instrument used and other settings, the selected dwell time may equate to 1 to 100 samples at each random selected pixel location, such as 5 to 50 samples, or 10 to 25 samples. In an embodiment, the beam or probe continuously samples as it is in transit to the next pixel location. The result is that the dwell time for a selected pixel or the number of samples per pixel are actually distributed across multiple pixel locations as the electron beam or probe is in transit to the next pixel location of the randomly selected subset. It is a challenge, however, to know the actual location of the probe in transit while the sampling is performed. This may be determined however as explained below.","The random or pseudo random sampling of step  is in contrast to traditional electron microscope methodologies, where imaging rates are physically constrained because the probe (probe meaning an electron beam or physical probe structure) visits each pixel location in raster-scan order. As the probe or electrons in the incident beam interact with the sample, various signals are produced providing information about the composition or topography of the sample surface. These signals are detected and digitally assigned to the image pixel value at the corresponding sample location. The electron probe is then repositioned, for example, via electromagnetic or electrostatic deflection to a subsequent pixel location.","In an embodiment, the scanning speed of the beam or probe, that is the speed at which the beam moves from one pixel to the next, is increased by at least 1.5 times faster than the typical microscope setting, for example, 2 times faster to 12 times faster, or 3 times faster to 5 times faster. For example, the beam or probe may have a scan speed of from 0.05 pixels\/microsecond to 100 pixels\/microsecond, such as 10 nm\/microsecond to 50 nm\/microsecond, or 60 nm\/microsecond to 90 nm\/microsecond.","In an embodiment, rather than scanning each pixel location of the sample, the electron probe is commanded to visit a smaller subset of pixel locations, for example, 10% to 50%, 30% to 50%, or 15% to 40% of the sample locations. A speed up in total analysis time will be realized proportionately to the sample locations. For example, a 2\u00d7 speed-up corresponds to an analysis of a 50% subset of pixels and a 10\u00d7 speed-up corresponds to analysis of 10% of the pixel locations. If a sample has high contrast and\/or large areas that are the same, it is more compressible. Accordingly, in such samples a lower subset of pixels can be analyzed and a higher speed up can be obtained.","In an embodiment, the electron beam or probe may be commanded to visit or sample one half or fewer of the total number of pixel locations of a sample area, for example, one-third to one-tenth or one fourth to one-sixth of the total number of pixel locations.","The locations visited, although random or pseudo-randomly selected, may, for example, be visited in an order that follows the typical movement of the microscope beam or probe, such as vertical or horizontal raster order.","In an embodiment, the electron beam or probe is moved around the sample by providing a set of voltage signals to the scan coils. These voltage signals differ from the traditional signals that command the beam or probe to move around the sample in raster order. Rather, the voltage signals are varied to direct the beam or probe to provide the random or pseudo-random pattern of visitation and analysis.","In an embodiment, a hardware or software component acts as a randomizer to modify the driving of the probe or beam. For example, the component could be a computer or a custom ASIC or FPGA that sends a signal to the microscope. In an embodiment, a control algorithm drives hardware to create voltage patterns and those voltage patterns are transmitted to the scan coils of the microscope. In a small integrated system embodiment, random voltage pattern codes could be pre-stored and built into the hardware system.","In an embodiment, the driving of the beam or probe can be combined with a mechanical mechanism to move the sample itself in relation to the beam or probe. In an embodiment, the electrical and mechanical movement can be integrated with the beam or probe movement to examine a large sample. For example, once the full scope of the subset of pixels of the normal sample area is randomly analyzed by the beam or probe, a stage on which the sample is set may be mechanically moved to put an adjacent section of the sample in the scope of the beam or probe for further random sampling.","Turning again to , the methodology  continues at step , which comprises determining actual pixel locations on the sample that are visited by the electron beam or probe.","Part of the challenge encountered with only randomly sampling as opposed to sampling every location in raster-scan order is that it may be difficult to know where the exact actual sampling locations are, and this uncertainty makes it difficult to accurately reconstruct the image. This is particularly true where the sampling is distributed over several locations while the beam or probe is scanning. This is not a problem with conventional full pixel set raster scanning where there is continued motion in one direction at a constant speed. In raster-scanning this is accounted for by starting the beam moving in one direction and when it reaches a constant speed, only then does data collection begin. Thus, the beginning of each row of the sample area is not collected or analyzed. By going at a constant speed and spending a set dwell time at every consecutive pixel there is no need for a detailed model of how the beam dynamics work.","However, in the sparse imaging methodology  utilized with electromagnetically driven beams or probes, the interval between randomly-selected pixel locations within a scan line is highly variable, so that the effect of the dynamics is pronounced, and the measured location may differ greatly from the desired location. Any time there is a change in the motion, there is a nonlinear response by the beam. In an SEM embodiment, the beam is deflected with two or more sets of electromagnetic coils, at least one for each scan direction. The current driven through these coils creates a magnetic field that deflects the moving electrons as they travel down the column. In addition to the inductance in the coils, stray capacitance and wire resistance creates a dynamic system which cannot respond instantaneously to changes in current. Additionally, the amplifiers used to drive the coils exhibit a non-negligible dynamic response. The combination of these systems creates a non-trivial dynamic system that can affect signals with frequency content as low as tens or hundreds of kHz. As a result, the actual location of the beam is often not the same as the commanded location, which creates image distortion unless some compensation is done.","Certain systems, such as electrostatic coil SEMs, do not typically suffer from the nonlinear response issues of electromagnetically driven systems. Accordingly the determining step may be straightforward in such systems, that is, the expected location will equate to the actual location, and the determining step may be skipped.","In an embodiment, in order to determine actual pixel locations on the sample that are visited by the electron beam or probe, a calibration step is performed for calibrating the microscope to account for beam dynamics. The calibration is performed to predict where the beam actually is at a given point in time during transit of the beam. In general, the information on where the beam is commanded to be is recorded, the actual measurement of a known sample at that point is detected and recorded, and then using that information, an index is created to determine the actual pixel location that is being visited and analyzed by the detector as a function of time. In an embodiment, the calibration may be performed at a variety of magnifications and speeds.","The index created is employed in the determining step  to modify the commanded location of the beam to correspond to the actual pixel location of the beam when a given measurement is taken. The determining may be done in real time, during the sample analysis, or after the sample analysis is complete.","In an embodiment, determining of the actual location is based on at least a 5th-order dynamical model shown in Equation (1).",{"@attributes":{"id":"p-0050","num":"0049"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"5"},"mo":"\u2062","mrow":{"mi":"x","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}},{"mo":"\u2146","msup":{"mi":"t","mn":"5"}}]},"mo":"=","mrow":{"mrow":[{"msub":{"mi":"\u03b1","mn":"0"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mover":{"mi":"x","mo":"^"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mi":"x","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}],"mo":"-"}}},{"msub":{"mi":"\u03b1","mn":"1"},"mo":"\u2062","mfrac":{"mrow":[{"mo":"\u2146","mrow":{"mi":"x","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}},{"mo":"\u2146","mi":"t"}]}},{"msub":{"mi":"\u03b1","mn":"2"},"mo":"\u2062","mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"2"},"mo":"\u2062","mrow":{"mi":"x","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}},{"mo":"\u2146","msup":{"mi":"t","mn":"2"}}]}},{"msub":{"mi":"\u03b1","mn":"3"},"mo":"\u2062","mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"3"},"mo":"\u2062","mrow":{"mi":"x","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}},{"mo":"\u2146","msup":{"mi":"t","mn":"3"}}]}},{"msub":{"mi":"\u03b1","mn":"4"},"mo":"\u2062","mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"4"},"mo":"\u2062","mrow":{"mi":"x","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}},{"mo":"\u2146","msup":{"mi":"t","mn":"4"}}]}}],"mo":["-","-","-","-"]}}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}},"br":{},"sub":["0","4"]},"At step  of the methodology  shown in , processing of the data collected by the microscope detectors from the visits of the electron beam or probe at the actual pixel locations is performed, and through this, the reconstructed image of the sample is recovered.","In an embodiment, the image is reconstructed from the sparse pixel data through interpolation plus denoising using block-DCT with total variation regularizer. These calculations are described in detail below. The degrees of freedom of typical electron microscope images are many fewer than the number of image pixels. Foundational contributions in compressed sensing guarantee that an N-pixel image x, which can be described by K coefficients in some compression basis \u03a8, can be exactly recovered in only M=O(K log N\/K) linear measurements of the form y=\u03a6x. The tightest guarantee to date holds when A=\u03a6\u03a8 satisfies the restricted isometry property, which guarantees recovery using basis pursuit:",{"@attributes":{"id":"p-0053","num":"0052"},"maths":[{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"munder":{"mi":["min","x"]},"mo":"\u2062","mrow":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"msup":{"mi":["\u03a8","T"]},"mo":"\u2062","mi":"x"}},"mo":"\u2062","mn":"1"}},"mo":"+","msub":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":["\u25bd","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mn":"1"}}}},{"@attributes":{"id":"MATH-US-00002-2","num":"00002.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":["s","t"],"mo":[".","."],"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":"y","mo":"-","mrow":{"mi":["\u03a6","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},"mo":"\u2264","msup":{"mi":"\u03c3","mn":"2"}}}}]},"It should be noted that for arbitrary A, certifying that the restricted isometry property holds is combinatoric in M. Although mutual coherence \u03bc(\u03a6\u03a8) provides a looser guarantee on reconstruction from M=0 (\u03bcKlogN)) measurements, it is trivial to compute.","In view of this, in an embodiment, noise and compression of the sparse sample data may be dealt with by the following approach. After M<N measurements are collected (M=O(\u03bcKlogN) and N is the number of image pixels), regularized basis pursuit denoising is performed to recover the image from the compressed random sampling data. It is assumed that each measurement is corrupted by white noise with noise power \u03c32. It is assumed that each measurement is corrupted by white noise with noise power \u03c3. A measurement model, based on sparsely sampled elements y=\u03a6x+n, may be used, where n is the additive noise with E[nn]=\u03c3I, \u03a6 represents a randomly selected subset of pixels (subset of rows of identity), and I is the identity matrix.","From the M<N measurements, the image can be reconstructed via",{"@attributes":{"id":"p-0057","num":"0056"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":{"munder":{"mi":["min","x"]},"mo":"\u2062","mrow":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"msup":{"mi":["\u03a8","T"]},"mo":"\u2062","mi":"x"}},"mo":"\u2062","mn":"1"}},"mo":"+","msub":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":["\u25bd","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mn":"1"}},{"mrow":{"mi":["s","t"],"mo":[".","."],"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":"y","mo":"-","mrow":{"mi":["\u03a6","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},"mo":"\u2264","msup":{"mi":"\u03c3","mn":"2"}}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}},"br":[{},{},{}],"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00001","he":"3.56mm","wi":"1.78mm","file":"US09093249-20150728-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00002","he":"3.56mm","wi":"1.78mm","file":"US09093249-20150728-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}],"in-line-formulae":[{},{}],"sub":["i","h","i","u","i","h","i","u","i"],"sup":["2","2","2","2"]},"Equation (2) can be solved by applying a basis pursuit recovery algorithm utilizing compressibility of the acquired image data for recovering the reconstructed image. For example, this may be accomplished through the split Bregman method by T. Goldstein and S. Osher, described in \u201cThe Split Bregman Method for L1-regularized Problems,\u201d SIAM Journal on Imaging Sciences 2(2), 323-343 (2009) (Goldstein and Osher), which is incorporated herein by reference. By using the Bregman iteration, the solution of the unconstrained problem will converge to the solution of the constrained problem in (2) by iteratively solving for an intermediate solution to the problem, then updating the so-called Bregman parameters, which add the error back in. The equations and method below are exemplary.",{"@attributes":{"id":"p-0059","num":"0058"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"munder":{"mi":["min","x"]},"mo":"\u2062","mrow":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"msup":{"mi":["\u03a8","T"]},"mo":"\u2062","mi":"x"}},"mo":"\u2062","mn":"1"}},{"mfrac":{"mi":"\u03bc","mn":"2"},"mo":["\u2062","\u2062","\u2062"],"msubsup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":"y","mo":"-","mrow":{"mi":["\u03a6","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},"mn":["2","2"]},"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mi":["unconstrained","problem"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}}}],"mo":["+","+"],"msub":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":["\u25bd","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mn":"1"}}}}},"The compressed sensing MRI derivation in Goldstein and Osher can be followed, noting that the present problem structure differs since image-domain samples are collected rather than Fourier-domain samples. The split Bregman formulation is applied so that the problem can be solved iteratively to arbitrary precision. In particular, at the kth iteration, the following equation may be solved:",{"@attributes":{"id":"p-0061","num":"0060"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"munder":{"mi":"min","mrow":{"mi":["x","u","v","w"],"mo":[",",",",","]}},"mo":"\u2062","msub":{"mrow":{"mo":["\uf605","\uf606"],"mi":"w"},"mn":"1"}},{"mfrac":{"mi":"\u03bc","mn":"2"},"mo":"\u2062","msubsup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mrow":{"mi":["\u03a6","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"-","mi":"y"}},"mn":["2","2"]}},{"mfrac":{"mi":"\u03bb","mn":"2"},"mo":"\u2062","msubsup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":"u","mo":["-","-"],"mrow":{"msub":{"mi":["\u25bd","u"]},"mo":"\u2062","mi":"x"},"msubsup":{"mi":["b","u","k"]}}},"mn":["2","2"]}},{"mfrac":{"mi":"\u03bb","mn":"2"},"mo":"\u2062","msubsup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":"v","mo":["-","-"],"mrow":{"msub":{"mi":["\u25bd","v"]},"mo":"\u2062","mi":"x"},"msubsup":{"mi":["b","v","k"]}}},"mn":["2","2"]}},{"mfrac":{"mi":"\u03b3","mn":"2"},"mo":"\u2062","msubsup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mi":"w","mo":["-","-"],"mrow":{"msup":{"mi":["\u03a8","T"]},"mo":"\u2062","mi":"x"},"msubsup":{"mi":["b","w","k"]}}},"mn":["2","2"]}}],"mo":["+","+","+","+","+"],"msub":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mo":["(",")"],"mrow":{"mi":["u","v"],"mo":","}}},"mn":"2"}},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"4"}}]}}}},"br":[{},{},{},{},{},{},{}],"sup":["T","2","2","k+1","k","k+1","k+1","k+1","k","k+1","k+1","k+1","k","k+1","k+1"],"sub":["u","v","2","i","i","i","u","u","u","v","u","v","w","w","1 ","2 "],"in-line-formulae":[{},{},{},{},{},{},{},{}],"i":["u,v","u","+|v","b","=b","x","\u2212u","b","=b","x","\u2212v","b","=b","x","\u2212u"]},{"@attributes":{"id":"p-0062","num":"0061"},"maths":[{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msubsup":{"mi":["u","i"],"mrow":{"mi":"k","mo":"+","mn":"1"}},"mo":"=","mrow":{"mfrac":{"mrow":{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msubsup":{"mi":["s","i","k"]},"mo":"-","mfrac":{"mn":"1","mi":"\u03bb"}},"mo":",","mn":"0"}}},"msubsup":{"mi":["s","i","k"]}},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"msub":{"mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u25bd","u"]},"mo":"\u2062","msup":{"mi":["x","k"]}}},"mi":"i"},"mo":"+","msubsup":{"mi":["b","k"],"mrow":{"mi":["u","i"],"mo":","}}}}}}}},{"@attributes":{"id":"MATH-US-00006-2","num":"00006.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msubsup":{"mi":["v","i"],"mrow":{"mi":"k","mo":"+","mn":"1"}},"mo":"=","mrow":{"mfrac":{"mrow":{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msubsup":{"mi":["s","i","k"]},"mo":"-","mfrac":{"mn":"1","mi":"\u03bb"}},"mo":",","mn":"0"}}},"msubsup":{"mi":["s","i","k"]}},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"msub":{"mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u25bd","v"]},"mo":"\u2062","msup":{"mi":["x","k"]}}},"mi":"i"},"mo":"+","msubsup":{"mi":["b","k"],"mrow":{"mi":["v","i"],"mo":","}}}}}}}},{"@attributes":{"id":"MATH-US-00006-3","num":"00006.3"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msubsup":{"mi":["w","i"],"mrow":{"mi":"k","mo":"+","mn":"1"}},"mo":"=","mrow":{"mrow":{"mi":"shrink","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":{"mrow":{"mo":["(",")"],"mrow":{"msup":[{"mi":["\u03a8","T"]},{"mi":"x","mrow":{"mi":"k","mo":"+","mn":"1"}}],"mo":"\u2062"}},"mi":"i"},"mo":"+","msubsup":{"mi":["b","k"],"mrow":{"mi":["w","i"],"mo":","}}},"mo":",","mfrac":{"mn":"1","mi":"\u03b3"}}}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mi":"where"}}}},{"@attributes":{"id":"MATH-US-00006-4","num":"00006.4"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msubsup":{"mi":["s","i","k"]},"mo":"=","mrow":{"msqrt":{"mrow":{"msup":[{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u25bd","u"]},"mo":"\u2062","msup":{"mi":["x","k"]}}},"mi":"i"},"mo":"+","msubsup":{"mi":["u","i","k"]}}},"mn":"2"},{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u25bd","v"]},"mo":"\u2062","msup":{"mi":["x","h"]}}},"mi":"i"},"mo":"+","msubsup":{"mi":["v","i","k"]}}},"mn":"2"}],"mo":"+"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mi":"and"}}}},{"@attributes":{"id":"MATH-US-00006-5","num":"00006.5"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"shrink","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","\u03c1"],"mo":","}}},{"mrow":[{"mi":"sgn","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mrow":{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mrow":{"mo":["\uf603","\uf604"],"mi":"x"},"mo":"-","mi":"\u03c1"},"mo":",","mn":"0"}}},"mo":"."}],"mo":"\u2062"}],"mo":"="}}}],"br":[{},{},{}],"in-line-formulae":[{},{}],"sup":["T","k+1","T","T","k","T","k","k","k ","T"],"i":["\u03a6\u2212\u03bb\u0394+\u03b3I","x","y+\u03bb\u2207","u","\u2212b","v","\u2212b","w","\u2212b"],"sub":["u","u","u","v","w"],"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00003","he":"3.56mm","wi":"1.78mm","file":"US09093249-20150728-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00004","he":"3.56mm","wi":"1.78mm","file":"US09093249-20150728-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00005","he":"3.56mm","wi":"1.78mm","file":"US09093249-20150728-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00006","he":"3.56mm","wi":"1.78mm","file":"US09093249-20150728-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}]},"An alternative method of solving includes the conjugate gradient method. However, by approximating the system as circulant, and solving for x using Fourier diagonalization, the overall algorithm converges, even though this step only provides an approximate solution. The basis pursuit denoising implementation is essentially jointly interpolating and denoising from the undersampled image data.","In summary, the above application of the split Bregman formulation for basis pursuit interpolation includes an inner loop that solves (2) via (6)-(8) and a circulant approximation to (5), and an outer loop that updates the Bregman parameters via (3)-(5). For typical images on the interval[0, 1], it was found that \u03bc=\u03bb=1 and \u03b3=10\u22122 are reasonable values for reconstruction. In the implementation herein, two iterations of the inner loop, and 150 iterations of the outer loop for noiseless data were used, though 20-50 iterations are typically sufficient to produce high-quality reconstructions.","Once the processing and recovering step  is completed or at least partially completed, the processed and recovered image or partial image is displayed in a displaying step . For example, the image may be displayed through an output device, such as a monitor or printer. The methodology  completes at .","With reference to , an exemplary methodology  for performing the above-referenced calibration is illustrated. The methodology  begins at , and at , in order to model the dynamics of the system, including the effects of the amplifiers and scan coils of the system, a stepwise jump in position from one extreme of the beam's scanning range to the other over a calibration sample is commanded. For example, the two extremes may be at opposite extremes in a horizontal row across the calibration sample. At , while the electron beam is in transit across the sample, the output of the secondary electron detector is recorded. At , this step-scanning routine produces a \u201csmeared\u201d scan of the sample. At , a standard slow raster scan of the same sample is performed across the same extremes of the sample. The beam in the two scans is run in the same direction, for example, horizontally left-to-right. At , a comparison of the \u201csmeared\u201d scan and the slow raster scan is performed. At , using the comparison data, the transit of the beam is plotted as a function of time to create an index that reflects the beam dynamics. (See also Example 5 below).",{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 3"},"The sparse imaging methodology  is capable of achieving efficient data collection at the expense of greater off-line computation. Moreover, the methodology  may still require an order of magnitude more time to reconstruct the image than was required to collect the data. The greater computation times may be acceptable, since, in contrast to data collection, image recovery may be distributed across many CPUs.","Referring now to , in an embodiment, the computing device  includes or is coupled to a processor  and a computer-readable memory  (which may be memory or a data store) that comprises a plurality of components that are executed by the processor . The computing device  can be configured to execute the methodology  described herein.","A command component  is configured to command an electron beam or probe to scan across a sample area and visit a subset of desired pixel locations of the sample area. The subset of desired pixel locations may be designated in a random or pseudo-random manner. A determiner component  is configured to determine actual pixel locations on the sample area that are visited by the electron beam, and a reconstruction component  is configured to process data collected by detectors from the visits of the electron beam at the actual pixel locations and recover a reconstructed image from the processed data.","In an embodiment, the computing device  is part of a system that includes input and output devices, and in an embodiment, the functionalities of one or more of the components, particularly the reconstruction component , are executed across a distributed series of multiple processors.","In an embodiment, the computing device  comprises a small electronics hardware package that includes components to do analog to digital conversion and digital to analog conversion, and a processing unit to control the values. Software to execute the sparse sampling methodology , may be either implemented on the hardware package or on a remote computer that is connected to the hardware package. The remote computer, for example, may perform the data processing or just the computational intensive tasks associated with the iterative reconstruction process. In an embodiment, the computing device comprises electronics hardware for generating random or pseudo-random sampling patterns.","In an embodiment, the methodology  may be implemented as software on a computing device that is coupled to an electron or scanning probe microscope and also executes instructions for operating the microscope.","Referring now to , a high-level illustration of an exemplary computing device  that can be used in accordance with the systems and methodologies disclosed herein is illustrated. The computing device  includes at least one processor  that executes instructions that are stored in a memory . The instructions may be, for instance, instructions for implementing functionality described as being carried out by one or more components discussed above or instructions for implementing one or more of the methods described above. The processor  may access the memory  by way of a system bus . In addition to storing executable instructions, the memory  may also, for example, store random or pseudo randomly selected pixel locations or voltages for driving a beam to such pixel locations, data received from the detectors of the electron or scanning probe microscope, and algorithms used in executing the determining and processing steps mentioned above.","The computing device  additionally includes a data store  that is accessible by the processor  by way of the system bus . The data store  may include, for example, executable instructions, random or pseudo randomly selected pixel locations or voltages for driving a beam to such pixel locations, data received from the detectors of the electron or scanning probe microscope, and algorithms used in executing the determining and processing steps mentioned above. The computing device  also includes an input interface  that allows external devices to communicate with the computing device . For instance, the input interface  may be used to receive instructions from an external computer device, from a user, etc. The computing device  also includes an output interface  that interfaces the computing device  with one or more external devices. For example, the computing device  may display text, images, etc. by way of the output interface .","It is contemplated that the external devices that communicate with the computing device  via the input interface  and the output interface  can be included in an environment that provides substantially any type of user interface with which a user can interact. Examples of user interface types include graphical user interfaces, natural user interfaces, and so forth. For instance, a graphical user interface may accept input from a user employing input device(s) such as a keyboard, mouse, remote control, or the like and provide output on an output device such as a display. Further, a natural user interface may enable a user to interact with the computing device  in a manner free from constraints imposed by input device such as keyboards, mice, remote controls, and the like. Rather, a natural user interface can rely on speech recognition, touch and stylus recognition, gesture recognition both on screen and adjacent to the screen, air gestures, head and eye tracking, voice and speech, vision, touch, gestures, machine intelligence, and so forth.","Additionally, while illustrated as a single system, it is to be understood that the computing device  may be a distributed system. Thus, for instance, several devices may be in communication by way of a network connection and may collectively perform tasks described as being performed by the computing device .","Various functions described herein can be implemented in hardware, software, or any combination thereof. If implemented in software, the functions can be stored on or transmitted over as one or more instructions or code on a computer-readable medium. Computer-readable media includes computer-readable storage media. A computer-readable storage media can be any available storage media that can be accessed by a computer. By way of example, and not limitation, such computer-readable storage media can comprise RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Disk and disc, as used herein, include compact disc (CD), laser disc, optical disc, digital versatile disc (DVD), floppy disk, and Blu-ray disc (BD), where disks usually reproduce data magnetically and discs usually reproduce data optically with lasers. Further, a propagated signal is not included within the scope of computer-readable storage media. Computer-readable media also includes communication media including any medium that facilitates transfer of a computer program from one place to another. A connection, for instance, can be a communication medium. For example, if the software is transmitted from a website, server, or other remote source using a coaxial cable, fiber optic cable, twisted pair, digital subscriber line (DSL), or wireless technologies such as infrared, radio, and microwave, then the coaxial cable, fiber optic cable, twisted pair, DSL, or wireless technologies such as infrared, radio and microwave are included in the definition of communication medium. Combinations of the above should also be included within the scope of computer-readable media.","Alternatively, or in addition, the functionally described herein can be performed, at least in part, by one or more hardware logic components. For example, and without limitation, illustrative types of hardware logic components that can be used include Field-programmable Gate Arrays (FPGAs), Program-specific Integrated Circuits (ASICs), Program-specific Standard Products (ASSPs), System-on-a-chip systems (SOCs), Complex Programmable Logic Devices (CPLDs), etc.","By way of example and not limitation, the following examples are illustrative of various embodiments of the present disclosure.","The sparse sampling method was demonstrated with public domain SEM images and on an operational SEM. As shown in the Examples below, acceptable image quality was achieved at 3\u00d7 speedup. This was accomplished by commanding the electron probe to visit a randomly-selected subset of pixel locations, predicting the actual locations via a 5th-order dynamical model, then recovering the image using a split-Bregman formulation of regularized basis pursuit that leveraged block-DCT as a compression basis.","To assess image sparsity of typical electron microscopy images, 1,022 electron microscopy images (SEM, TEM and E-SEM) were obtained from the Dartmouth public domain gallery. The images are of a variety of different specimens in biology, geology, and materials, and include a wide range of magnifications and image sizes. To standardize analysis, the center 512\u00d7512 of each image was excised to remove banners and rescaled images to [0; 1] grayscale values. For each 512\u00d7512 image, the sparsity K was computed by counting the number of large coefficients in the block-DCT domain (32\u00d732 blocks) that accounted for at least 99.75% of the total coefficient energy.",{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIG. 6"},"This suggests that by applying compressed sensing, most SEM images could be acquired with compressed measurements with about 20-40% reduction in the number of samples, with little or no information loss.","Using the proposed recovery method in equation (1) (see above), reconstruction of the public domain Dartmouth images analyzed in Example 1 was simulated from sparse samples. For each 512\u00d7512 excised and standardized image x, sparse sampling was simulated by choosing M pixels at random from the image, where M\/N is swept from 10% to 100%. Then, the images were reconstructed using both the basis pursuit approach and bilinear interpolation approach described above for comparison purposes.",{"@attributes":{"id":"p-0086","num":"0085"},"figref":"FIG. 7"},"The shading at each x\/y location on the plot indicates how frequently an image with a given sparsity K\/N was \u201csuccessfully\u201d reconstructed (accounted for at least 99.75% of the image energy) at a given undersampling rate M\/N; the shading ranges from 0% (black) to 100% (white). The reconstructed image x^ was deemed a \u201csuccess\u201d if the following inequality were true:\n\n\u2225\u22660.25%\n","In other words, if the reconstruction accounts for at least 99.75% of the image energy, the image was \u201csuccessfully\u201d recovered.","It can be seen from the plots on the top panels, for noiseless reconstruction, basis pursuit and bilinear interpolation are approximately the same, with the phase transition between success and failure on the bilinear interpolation curve accounting for about 5% less area under the curve. However, when a very small amount of noise is added (multiplicative noise, in the case with variance 1\/100 of the pixel intensity), bilinear interpolation breaks down quickly, with 50% less area under the curve compared to the basis pursuit denoising method.","Simple linear interpolation of the sparse sampled compressed images is both simple and very efficient. For example, the reconstruction in  (pollen sample), the basis pursuit approach took 18 seconds for 50 iterations using non-optimized MATLAB code with a 2.66 GHz Intel Xeon processor, whereas a similar reconstruction using MATLAB's griddata for linear interpolation took only 2 seconds. Thus, linear interpolation may be attractive as a \u201cquick-look\u201d option, but the proposed basis pursuit denoising method is preferred for high-quality reconstruction.","Example 3 demonstrates on an operational SEM, the sparse sampling and recovery method for fast electron microscopy. The experiments were conducted using a commercially available SEM column with custom electronics to drive the beam location and sample the detector. A Zeiss GmbH (Oberkocken, Germany) column was used with a Schottky thermal field emission source and Gemini\u2122 optics. A nominal beam energy of 10 keV was used with a 10 \u03bcm aperture, resulting in a beam current of approximately 200 pA.","The incident beam was deflected onto the sample using the standard scanning coils and current amplifiers in the column. However, custom electronics were used to set the desired beam location using an external scan mode. The magnification (and consequently the field of view) was set using the standard column controls. Once this was determined, pixels in the field of view were visited by driving a voltage of \u221210 V to +10 V, which is converted to a current in the coil amplifiers. For example, in the horizontal direction, driving \u221210 V would place the beam at the far left of the field of view and +10 V would place the beam at the far right. The same is true in the vertical direction.","A digital to analog converter (DAC) was used to drive the desired voltages by converting an digital signal from the computer to an analog signal that controls the scan coils. The detector was sampled using an analog to digital converter (A\/D) that was synchronized to the DAC. The A\/D and DAC were implemented using a National Instruments (Austin, Tex.) PCI-6110 multi-function data acquisition system. This system has a maximum frequency of 2.5 MHz with two analog outputs, an output resolution of 16 bits per sample and an input resolution of 12 bits per sample. DACs generally have a maximum \u201csample rate\u201d at which they can update their command signals. This maximum rate can be considered one \u201csample.\u201d The amount of dwell time at any pixel must be an integer multiple of this sample time. Thus, if the beam was desired to dwell longer than the minimum sample time at one point, the DAC is commanded to hold a voltage for multiple samples. The effective dwell time (more dwell time means better SNR for that pixel) was then controlled by how many multiples of the basic sample time that the DAC was commanded to hold at each point. In this Example, variable dwell time was achieved by digitally averaging multiple samples at the same pixel location. A basic dwell time of 400 ns using one sample per pixel resulted in low-signal to noise ratio (SNR) images, while a high-SNR dwell time of 6.4 \u03bcs was achieved by averaging 16 samples per pixel.","A high-SNR image of the surface of a Gibeon meteorite collected in the manner just described is shown in , along with simulated sparse sampling and subsequent image recovery.","A digital command is created in a computer and this gets converted by a DAC to an analog signal that controls the scan coils. DACs generally have a maximum \u201csample rate\u201d at which they can update their command signals. This maximum rate can be considered one \u201csample\u201d. The amount of dwell time at any pixel must be an integer multiple of this sample time. If we want the beam to dwell longer than the minimum sample time at one point, we command the DAC to hold a voltage for multiple samples. The effective dwell time (more dwell time means better SNR for that pixel because we average all the samples) is then controlled by how many multiples of the basic sample time we command the DAC to hold at each point.",{"@attributes":{"id":"p-0096","num":"0095"},"figref":"FIG. 8"},"It should be noted that on an operational SEM, nontrivial dynamics of the electron probe scanning system create a mismatch between the desired and actual measurement locations on the sample. The effect is less pronounced when visiting every pixel in typical raster-scan mode in which the electron probe follows the same trajectory during each scan line, and leads only to a nonlinear stretch of the image. However, as explained above, in the sparse imaging embodiment, the interval between randomly-selected pixel locations within a scan line is highly variable, so that the effect of the dynamics is pronounced, and the measured location differs greatly from the desired location.","In Example 4, the sparse sampling method was utilized in an operational SEM. Mirroring Example 3, the electron probe was commanded to visit 10%, 30% and 50% of the sample locations chosen at random in vertical-raster order, and to dwell for 6.4 \u03bcs (16 samples per pixel) at each randomly selected pixel location. The result is that the 16 samples per randomly selected pixel are actually distributed across multiple pixel locations as the electron probe is in transit. To predict the actual location of the electron probe, a \u2158 Runge-Kutta method to solve Equation (1).","A portion of the Gibeon meteorite sample was imaged at 800\u00d7 magnification at a working distance of 4.7 mm. Due to the close working distance, samples were collected with an in-lens secondary electron (SE) detector. Brightness and contrast for each sparse sampling collection was fixed at 76% and 41%, respectively.","Results for the sparse sampling collection and reconstruction are shown in , which shows: (top row) a standard SEM image of the Gibeon sample; (2nd row) a 10% sparse (M\/N=10%), modeled sample locations (left) and reconstruction (right); (3rd row) a 30% sparse, modeled sample locations (left) and reconstruction (right); (4th row) a 50% sparse, modeled sample locations (left) and reconstruction (right). The intensity of the gray-scale in the left column represents the number of times the probe visited the given pixel. The electron probe scanned vertically. In addition to sample quality, a difference in sample charging is also evident, which indicates that the sparse sampling method may be additionally useful for samples that are sensitive to overdosing.","For M\/N=10%, the reconstruction exhibits some smearing along the vertical path of the electron probe, which can be attributed to large electron probe velocities and small errors in the 5th order model actual location prediction. Acceptable image reconstruction is achieved for M\/N=30%, corresponding to a greater than 3\u00d7 increase in image collection speed. Notice also that for smaller M\/N, the lower average electron dose rates contribute to less charging on the sample (manifest by the slight glow on the left-hand side of the original image).","A calibration routine was performed to characterize the dynamics of the amplifiers and scan coils. This was done by commanding a stepwise jump in position from one extreme of the beam's scanning range to the other over a calibration sample. While the electron beam was in transit, the output of the secondary electron detector was recorded. This step-scanning method produced a smeared scan of the sample.","Comparing this with a very slow raster scan of the same sample allowed plotting a beam location corresponding to the recorded output of the detector as a function of time.",{"@attributes":{"id":"p-0104","num":"0103"},"figref":"FIG. 10"},"The data showed the dynamics of the beam are slow compared to the sampling period (400 ns). The 90% rise time was approximately 12 \u03bcs, the 99% rise time about 32 \u03bcs, and the 99.9% rise time approximately \u00bc ms. Note that the 99.9% rise time is relevant; when making scans of several thousand pixels per line, an error of 0.1% corresponds to several pixels.","The lowest order linear model to fit the data points well was fifth-order of the form of equation (1) where x(t) is the true one-dimensional probe position (in pixels) at time t, {circumflex over (x)}(t) is the desired position, and the best-fit parameters {a, . . . , a} are listed in Table 1. The same dynamical model was used for both horizontal and vertical beam deflection.",{"@attributes":{"id":"p-0107","num":"0106"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"center"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"parameter","value"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u03b1","4.42 \u00d7 10"]},{"entry":[{},"\u03b1","8.20 \u00d7 10"]},{"entry":[{},"\u03b1","5.49 \u00d7 10"]},{"entry":[{},"\u03b1","2.46 \u00d7 10"]},{"entry":[{},"\u03b1","4.60 \u00d7 10"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"The measured image acquisition time for collecting every pixel of a 1000\u00d71000 image with 16 samples per pixel was determined to be 6.9 s. An image acquisition time of 6.4 s was expected at 2.5 MHz. Using sparse sampling factors of 10%, 30% and 50%, image collection times of 0.7 s (9.9\u00d7 speedup), 2.1 s (3.3\u00d7 speedup), and 3.5 s (2.0\u00d7 speedup), respectively, for 1000\u00d71000 images. These collection times were only slightly more than what would be predicted at 2.5 MHz, and this can be ascribed to software overhead. Nevertheless, the collection time indeed grows linearly with the number of samples M, as shown in .","As used herein, the terms \u201ccomponent\u201d and \u201csystem\u201d are intended to encompass computer-readable data storage that is configured with computer-executable instructions that cause certain functionality to be performed when executed by a processor. The computer-executable instructions may include a routine, a function, or the like. It is also to be understood that a component or system may be localized on a single device or distributed across several devices. Additionally, as used herein, the term \u201cexemplary\u201d is intended to mean serving as an illustration or example of something, and is not intended to indicate a preference. The term \u201crandom\u201d when used by itself herein may include both random and pseudo-random as those terms are technically defined in the art.","All patents, patent applications, publications, technical and\/or scholarly articles, and other references cited or referred to herein are in their entirety incorporated herein by reference to the extent allowed by law. The discussion of those references is intended merely to summarize the assertions made therein. No admission is made that any such patents, patent applications, publications or references, or any portion thereof, are relevant, material, or prior art. The right to challenge the accuracy and pertinence of any assertion of such patents, patent applications, publications, and other references as relevant, material, or prior art is specifically reserved.","In the description above, for the purposes of explanation, numerous specific details have been set forth in order to provide a thorough understanding of the embodiments. It will be apparent however, to one skilled in the art, that one or more other embodiments may be practiced without some of these specific details. The particular embodiments described are not provided to limit the invention but to illustrate it. The scope of the invention is not to be determined by the specific examples provided above but only by the claims below. In other instances, well-known structures, devices, and operations have been shown in block diagram form or without detail in order to avoid obscuring the understanding of the description. Where considered appropriate, reference numerals or terminal portions of reference numerals have been repeated among the figures to indicate corresponding or analogous elements, which may optionally have similar characteristics.","It should also be appreciated that reference throughout this specification to \u201cone embodiment\u201d, \u201can embodiment\u201d, \u201cone or more embodiments\u201d, or \u201cdifferent embodiments\u201d, for example, means that a particular feature may be included in the practice of the invention. Similarly, it should be appreciated that in the description various features are sometimes grouped together in a single embodiment, figure, or description thereof for the purpose of streamlining the disclosure and aiding in the understanding of various inventive aspects. This method of disclosure, however, is not to be interpreted as reflecting an intention that the invention requires more features than are expressly recited in each claim. Rather, as the following claims reflect, inventive aspects may lie in less than all features of a single disclosed embodiment. Thus, the claims following the Detailed Description are hereby expressly incorporated into this Detailed Description, with each claim standing on its own as a separate embodiment of the invention."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
