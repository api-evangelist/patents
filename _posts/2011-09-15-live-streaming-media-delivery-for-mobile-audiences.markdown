---
title: Live streaming media delivery for mobile audiences
abstract: A live streaming system/method provides cross platform live streaming capabilities to mobile devices. The live streaming system includes a live streaming recorder operative to (1) capture a live media stream generated by a live media source and save the captured live media stream as a recorded stream in a recorded media file, and (2) transcode the recorded stream into a plurality of transcoded media files of respective different media encoding formats. The system further includes a stream distribution subsystem operative to generate a plurality of distributed media streams each generated from one or more of the transcoded media files, each distributed media stream being delivered to a corresponding set of the mobile endpoint devices.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08874778&OS=08874778&RS=08874778
owner: Telefonkatiebolaget LM Ericsson (Publ)
number: 08874778
owner_city: Stockholm
owner_country: SE
publication_date: 20110915
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Overview","DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS"],"p":["The invention relates generally to the field of streaming media, and more particularly to the streaming of live media in a scalable and flexible manner.","Available bandwidth in the internet can vary widely. For mobile networks, the limited bandwidth and limited coverage, as well as wireless interference can cause large fluctuations in available bandwidth which exacerbate the naturally bursty nature of the internet. When congestion occurs, bandwidth can degrade quickly. For streaming media, which require long lived connections, being able to adapt to the changing bandwidth can be advantageous. This is especially so for streaming which requires large amounts of consistent bandwidth.","In general, interruptions in network availability where the usable bandwidth falls below a certain level for any extended period of time can result in very noticeable display artifacts or playback stoppages. Adapting to network conditions is especially important in these cases. The issue with video is that video is typically compressed using predictive differential encoding, where interdependencies between frames complicate bit rate changes. Video file formats also typically contain header information which describe frame encodings and indices; dynamically changing bit rates may cause conflicts with the existing header information. This is further complicated in live streams where the complete video is not available to generate headers from.","Frame-based solutions like RTSP\/RTP solve the header problem by only sending one frame at a time. In this case, there is no need for header information to describe the surrounding frames. However RTSP\/RTP solutions can result in poorer quality due to UDP frame loss and require network support for UDP firewall fixups, which may be viewed as network security risks. More recently segment-based solutions like HTTP Live Streaming allow for the use of the ubiquitous HTTP protocol which does not have the frame loss or firewall issues of RTSP\/RTP, but does require that the client media player support the specified m3u8 playlist polling. For many legacy mobile devices that support RTSP, and not m3u8 playlists, a different solution is required.","A method and apparatus are disclosed for delivering live content (live video and\/or audio) as streaming media over the Internet to mobile devices in a device- and operator-agnostic manner. Currently, mobile video broadcasting either uses a built-in capability which is specific to a particular cell network operator or requires a device-specific application download. The disclosed technique may be used with a standard web-browser and delivered via the Internet to any mobile device in a manner that is independent of any particular cell network operator. The technique can efficiently scale horizontally to a large number of endpoints (mobile devices). In addition, a capability for automatically saving and viewing earlier segments of the stream is also provided. Overall, the disclosed method and apparatus provide the ability to deliver, in a scalable and cost-effective manner, live and time-shifted streaming of content over the Internet to mobile endpoints.","A disclosed system includes functions of recording, transcoding, and distributing live content or media. A recording system captures the live stream and transcodes it to various mobile device formats such as 3gpp, WMV, MOV, etc. The transcoded data is stored in a file system. A distribution subsystem provides distribution to a large number of endpoints in a highly scalable manner.","A scalable live streaming system is used to deliver live event to large mobile audiences. The system generally provides mobile users with interactive and \u201csnackable\u201d access to the content, i.e., the ability to view selected portions of the content, along with metadata associated within a live event. The system supports the following major live streaming features:","Live Streaming","Live streaming provides real time live streaming functionality. In one embodiment, the system receives the live feed as a live stream from a content delivery network (CDN). In another embodiment, the system receives the live feed as a direct stream from an attached recording device (e.g. a web-cam). The stream is recorded into a media file and re-streamed out with different encoding formats to support different mobile audiences.","Interactive Near-Live Streaming","In one embodiment, the system provides near-live interactive streaming functionality for a live feed. A mobile user can navigate the live event and play interesting video chunks in near real time while the live event is ongoing. In one embodiment, the system supports redirecting from a near live chunk to the live streaming to allow a mobile user to \u201ctune\u201d in the live event directly.","Server-Side Simulated Broadcast Live Streaming","This feature allows an end-user to tune in the live streaming event anywhere from the beginning of live event to near the present time.","Video on Demand","In one embodiment, the live event is recorded by the system. The recorded file can be further transcoded into multiple media formats to provide Video on Demand (VoD) replay functionality after the live event is over.","As used herein, \u201cnear-live\u201d refers to the presence of certain latencies in the system, such as recording the live stream(s), transcoding the live media, relaying an intermediate stream, chopping into video chunks, extracting image \u201ctiles\u201d, and transferring the video chunks to a content delivery network. The particular constituents and amounts of these delays will necessarily vary among different embodiments.","The system may also provide a desktop graphical user interface (GUI) to control operation such as starting and stopping a stream.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 1","b":["2","10"]},"The live streaming system provides the following functionality:\n\n","The live streaming system is designed to be flexible and easily expandable to support large mobile audiences.",{"@attributes":{"id":"p-0033","num":"0043"},"figref":"FIG. 2","b":["10","11","12","13","14","15"]},"Live Streaming Monitor and Control","The live streaming monitor  consists of scripts running in the background to monitor incoming stream properties, the status of an RTMP connection, and the status of the Root Streamer  and Branch Streamers . Additionally, a Web-based interface is provided in the system to be used by a customer to send stream properties before the live event starts or end of the live event. In one embodiment, the Web-based interface is implemented as a CGI script. In another embodiment, the Web-based interface is implemented as a RESTful Web Service. A desktop GUI may be provided to control the live streaming server by calling the Web-based interface. An example CGI interface may be the following:","http:\/\/<hostname>\/cgi-bin\/ags.cgi?event=<name>&id=<event id>&status=<on|off>","where a customer provides the following parameters:",{"@attributes":{"id":"p-0037","num":"0000"},"ul":{"@attributes":{"id":"ul0003","list-style":"none"},"li":{"@attributes":{"id":"ul0003-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0004","list-style":"none"},"li":["event: stream name","id: event ID","status: event status (ON or OFF)"]}}}},"These scripts control the whole live streaming system to start, stop, and terminate automatically based on stream properties and network connection status. A system administrator can also control the system through GUI.","Live Streaming Recorder","In one embodiment, the Live Stream Recorder  is used to capture a live stream via the RTMP protocol and save the stream into a local file. In another embodiment, the Live Stream Recorder  is used to capture a live stream via the MMS protocol and save the stream to a local file. In another embodiment, the Live Stream Recorder  is used to capture a live stream via the RTP protocol and save the stream to a local file. The local file can be one of a number of valid container formats (e.g. FLV, MP4, 3GP, MOV, WMV, etc.) which should be known to those skilled in the art. The local file is then transcoded and streamed out through the Streaming Tree (described below). The Live Stream Recorder  is also responsible for notifying the Live Stream Monitor of streaming protocol specific events which affect the state of the stream (e.g. stream start, stream stop, and stream errors).","Video on Demand","The live event is recorded by the Live Streaming Recorder  into a recorded media file. This media file can be further transcoded into multiple transcoded media files in different formats. These transcoded media files can be used by the system to provide Video on Demand (VoD) functionality after the live event is over.","Live Event Metadata and Database (Shown as \u201cDB\u201d in )","While a live event is ongoing, multiple metadata associated with the live event are created and stored in the central database . These metadata can be used to describe the properties of each specific live event. By using these metadata entries in the database, each live event is searchable.","Streaming Tree","A Streaming Tree contains at least one Root Streamer  and multiple Streaming Servers . One or more intermediate Branch Streamers  are generally also employed, although for sufficiently small audiences it may be possible for the Root Streamer  to provide its streams directly to Streaming Servers . Each Streaming Tree is used to deliver one live event. The Branch Streamers  and Streaming Server  receive streams from their parents and replicate the stream to multiple children. Within one Streaming Tree, more Branch Streamers  and Streaming Servers  can be added into the Streaming Tree to accommodate the mobile audience scale. A Streaming Tree is one specific type of stream distribution subsystem. For VoD or chunk content, the Streaming Tree may function more as a hierarchical caching infrastructure with push-based distribution of live recorded files. In one embodiment, Streaming Tree distribution is performed by unicast connections between parents and children. In another embodiment, Streaming Tree distribution is performed via IP multicast.","Multiple Live Events","The system can be easily expanded to support concurrent live events. The system can be configured to have multiple Streaming Trees each delivering a different live event. Multiple Streaming Trees may also be used to provide different encodings of a single live event. For VoD or chunk content, a single distribution tree may be used to support multiple encoding or live events.","Encoding Parameters Configuration","When a live event is starting, a set of encoding parameters, such as, video format, video bit rate, audio format, audio bit rate, frame rate, etc., can be configured to deliver specific streams to mobile audiences based on targeted mobile phones and wireless network bandwidth. These encoding parameters have been configured to support various mobile phones and wireless carrier networks.","Load Balancing","The system can provide load balancing functionality to deliver the live stream to mobile users. The plurality of Streaming Servers  may be distributed across multiple data centers, in which case DNS load balancing may be used to map the closest data center. Within a single data center, the plurality of Streaming Servers  may also be load balanced by a server load balancer to distribute load.","Live Streaming Navigation","The system may enable a user to watch a live event in two different ways. One is to watch the real time live event in the normal linear fashion (beginning to end). Another way is to allow the user to navigate into the live event to find interesting points and watch \u201csnackable\u201d portions or clips. These snackable clips are produced by the Live Streaming Chopper (see below) dynamically while the live event is ongoing.","Root Streamer","The Root Streamer  is the streaming source of the live streaming system. It transcodes the recorded  file and streams out multiple streams to either the intermediate Branch Streamers  or the Streaming Servers  directly. In one embodiment, the Root Streamer  uses RTP streams to distribute live content. The Root Streamer  also streams the live content to the chopper . The Root Streamer  also sets the event metadata to database so that the GUI can display the event status to mobile audiences.","There may be multiple Root Streamers  in the system in case of supporting multiple live streaming channels or multiple live stream encodings for one customer or many customers. By supporting multiple Root Streamers  and intermediate Branch Streamers , the system can support multiple customers and expand to support large audiences.","Branch Streamer","The Branch Streamer  is the intermediate streamer in the system. It takes the incoming RTP stream and relays the stream to a next level of the Branch Streamers  or to the Streaming Servers . The Branch Streamers  are used to expand the system to support large mobile audiences.","Streaming Server","The Streaming Servers  are the front end of the live streaming system to deliver the stream(s) to mobile audiences. They receive the streams from the Root Streamer  or Branch Streamers  and relay the streams to mobile audiences to watch the live event. The system may support a variety of streaming protocols, including but not limited to HTTP Live Streaming, RTSP and MMS. The number of Streaming Servers  used will generally depend on how many concurrent clients are supported by the live streaming system. Additional Streaming Servers  may also be used to provide physical distribution over a wider geographical area. Increasing distribution allows for lower latency when streaming to mobile clients in a specific region. The streams delivered to the client devices by the Streaming Servers are referred to as \u201cdistributed streams\u201d.","Live Streaming Chopper","The Live Streaming Chopper  is used for the interactive Near-Live Streaming. It receives the stream from Root Streamer , transcodes and saves the stream to many N-minute video chunks, chops the N-minute video chunks into smaller video chunks based on a default definition file and extracts image tiles. In one embodiment, the Chopper  uploads chunks and tiles to a CDN for distribution to clients. In another embodiment, the Chopper  uses the Streaming Tree as a distribution path for video chunks. In one embodiment the chunks are distributed using reliable multicast to the Branch Streamers (or proxy caches in this case) , through to the Streaming Servers . In one embodiment, the user can play the snackable chunks through an interactive GUI such as described in PCT patent application PCT\/US09\/32565 entitled \u201cMedia Navigation System\u201d, published Aug. 6, 2009 as WO\/2009\/097492. In another embodiment, the user can play the chunks using an HTTP Live Streaming compatible media player. In another embodiment, the user can play the chunks using a method in accordance with various provisions of this invention.",{"@attributes":{"id":"p-0052","num":"0064"},"figref":"FIG. 3","b":["100","108","102","102","108"]},"The client  connects to a standard HTTP server  to retrieve segments. The segments are stored on a storage device . The storage may be local or remote and may use any of a number of storage technologies, as should be known to those skilled in the art. The segments are generated by the R\/S server . The R\/S server  is responsible for recording the live stream and transcoding it into a plurality of encodings, where each encoding uses a different bit rate. In one embodiment, default encoding parameters are provided in a configuration file. In another embodiment, default encoding parameters are provided at invocation. In one embodiment, individual source files may override default encoding parameters via an accompanying configuration file. In another embodiment, individual source files may override default encoding parameters using parameters provided at invocation. The R\/S server  writes the transcoded data into segments then uploads the segments to the storage device . In one embodiment the recoding and segmentation may be invoked manually. In another embodiment, the recording and segmentation may be asynchronously invoked programmatically, based on pre-scheduled live events. The R\/S server  is also responsible for segment encryption. In one embodiment, segments are encrypted before being uploaded to the storage device .",{"@attributes":{"id":"p-0054","num":"0066"},"figref":"FIG. 4","b":["200","102","212","202","202","212","202"]},"The stream recorder  passes recorded data to a stream transcoder  as it is received. The stream transcoder  is responsible for decoding the input stream and re-encoding the output video frames in the proper output codecs. The stream transcoder  passes the re-encoded frames to the output framer . The output framer  is responsible for packing the encoded frames into the proper container format. In one embodiment, the stream transcoder  and output framer  support the H.264, H263, MPEG2, MPEG4, and WVM, video codecs and the MP3, AAC, AMR, and WMA audio codecs, along with the FLV, MOV, 3GP, MPEG2-TS and ASF container formats. In another embodiment, the stream transcoder  and output framer  may support other standard or proprietary codecs and container formats. There are numerous video and audio codecs and container formats, as should be known to those skilled in the art, of which any would be suitable for the stream transcoder  and output framer . In one embodiment, the output framer  also supports the proprietary container format shown in  and discussed below.","The output framer  writes the formatted data into segment files in the media storage . The output framer  is responsible for enforcing segment boundaries and durations. When the segments are complete, the output framer  notifies the segment encryptor . If segment encryption is required, the segment encryptor  reads the segment from the media storage , encrypts the segment, writes the encrypted segment back out to the media storage , and notifies the segment uploader  that the segment is ready for upload to the storage device . If no encryption is required, the segment encryptor  just notifies the segment uploader  that the segment is ready for upload to the storage device .","The segment uploader  uploads the finished segments to the storage device  (). In one embodiment, the segment uploader  uses HTTP to upload segments. In another embodiment, segment uploader  uses FTP to upload segments. In another embodiment, segment uploader  uses SCP to upload segments. In another embodiment, segment uploader  uses simple file copy to upload segments. There are numerous methods, with varying levels of security, which may be used to upload the files, as should be known to those skilled in the art, of which any would be suitable for the segment uploader .",{"@attributes":{"id":"p-0058","num":"0070"},"figref":"FIG. 5","b":["300","302","304","304","306","308","306","310","312","310","312","308","312","306","308"]},"The frame payload  contains further video frame encapsulation. In one embodiment, the encapsulation may be the further frame encapsulation may be for the RTP protocol. In another embodiment, the further frame encapsulation may be for the RTMP protocol. There are numerous video delivery protocols with different frame encapsulation formats, as should be known to those skilled in the art, which would be suitable for inclusion in the frame payload . In diagram , the further frame encapsulation shown is for the RTP protocol. The video frame is further encapsulated by the RTP packet header . The RTP payload  contains the actual video frame plus RTP padding . In one embodiment, RTP protocol padding  is used to pad the RTP payload  out to a 4 or 8 byte boundary, to ensure that the frame header  is 4 or 8 byte aligned, respectively. In another embodiment, custom padding may be added, outside of the protocol-specific frame encapsulation.",{"@attributes":{"id":"p-0060","num":"0072"},"figref":"FIG. 6","b":["400","410"]},"In one embodiment, the client contains a downloader . The downloader  is responsible for interacting with the HTTP server  () to retrieve segments from the network storage device . The segments retrieved are written into the media buffer  and the downloader  notifies the segment decryptor . If the segment does not require decryption, the segment decryptor  notifies the segment parser  that the segment is ready. If the segment does require decryption, the segment decryptor  reads the segment from the media buffer , decrypts the segment, writes the decrypted segment back out to the media buffer , and notifies the segment parser  that the segment is ready.","RTSP requires separate frame based delivery for audio and video tracks. The RTP segments retrieved use the format  detailed in . The segments are parsed by the segment parser  to extract the individual audio and video RTP frames . The RTP frames  are already encapsulated for RTP simplifying the RTSP server . Once all the RTP frames  have been extracted and handed off to the RTSP server , the segment is no longer required. In one embodiment, the segment parser  removes the segment from the media buffer  once it has been completely parsed. In another embodiment, the segment parser  does not purge segments until the media buffer  is full. The RTSP server  handles requests from the media player  on the RTSP control channel , and manages setting up the audio and video RTP channels  and , and the audio and video RTCP channels  and . The audio and video RTP frames  are sent in a paced manner, by the RTSP server  on their respective RTP channels  and .",{"@attributes":{"id":"p-0063","num":"0075"},"figref":"FIG. 7","b":["500","510"]},"In one embodiment, the client contains a downloader . The downloader  is responsible for interacting with the HTTP server  () to retrieve segments. The segments retrieved are written into the media buffer  and the downloader  notifies the segment decryptor . If the segment does not require decryption, the segment decryptor  notifies the playlist generator  that the segment is ready. If the segment does require decryption, the segment decryptor  reads the segment from the media buffer , decrypts the segment, writes the decrypted segment back out to the media buffer , and notifies the playlist generator  that the segment is ready.","In the case of the HTTP Live Streaming client, MPEG2-TS format segments are retrieved. HTTP Live Streaming supports direct download of segments, as pointed to by an m3u8 playlist file. The playlist generator  is passed the file location, in the media buffer, by the segment decryptor . The playlist generator  updates the existing playlist adding the new segment and removing the oldest segment and passes the updated playlist to the HTTP server . The playlist generator  is also responsible for purging old segments from the media buffer . In one embodiment, segments are purged from the media buffer  as segments are removed from the playlist. In another embodiment, segments are only purged once the media buffer  is full, to support the largest possible rewind buffer.","The HTTP server  responds to playlist polling requests from the media player  with the current playlist provided by the playlist generator . The HTTP server  responds to segment requests from the media player  by retrieving the segment from the media buffer  and delivering it to the media player . The media player  connects to the HTTP server  though a local host HTTP connection .","For the clients in both  and , the downloader  is also responsible for calculating average available bandwidth. In one embodiment, the downloader  calculates the available bandwidth based on download time and size of each segment retrieved. In one embodiment, bit rate switching is initiated when the average available bandwidth falls below the current encoding's bit rate:",{"@attributes":{"id":"p-0068","num":"0080"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"133pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003","int bandwidth_avg","\/\/ average available network bandwidth"]},{"entry":[{},"int video_bit_rate","\/\/ current video encoding bit rate"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"if bandwidth_avg < video_bit_rate"]},{"entry":[{},"\u2003for each encoding sorted by bit rate in descending order"]},{"entry":[{},"\u2003\u2003if encoding.bit_rate < bandwidth_avg && encoding.bit_rate != "]},{"entry":[{},"\u2003\u2003video_bit_rate"]},{"entry":[{},"\u2003\u2003\u2003change encoding"]},{"entry":[{},"\u2003\u2003\u2003break"]},{"entry":[{},"\u2003\u2003end"]},{"entry":[{},"\u2003end"]},{"entry":[{},"end"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"The above can also be stated as, a bit rate switch is initiated when the download time required for a segment exceeds the duration of the segment. In one embodiment, a multiplier, less than one, is applied to detect network underruns before they occur:",{"@attributes":{"id":"p-0070","num":"0082"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"119pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003","int bandwidth_avg","\/\/ average available network bandwidth"]},{"entry":[{},"int video_bit_rate","\/\/ current video encoding bit rate"]},{"entry":[{},"int segment_download_time","\u2003\/\/ time to download most recent segment"]},{"entry":[{},"int segment_duration","\u2003\/\/ duration of most recent segment"]},{"entry":[{},"int multiplier","\u2003\/\/ multiplier less than 1"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"7pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"210pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"if segment_download_time > segment_duration * multiplier"]},{"entry":[{},"\u2003for each encoding sorted by bit rate in descending order"]},{"entry":[{},"\u2003\u2003if encoding.bit_rate < bandwidth_avg && encoding.bit_rate != "]},{"entry":[{},"\u2003\u2003video_bit_rate"]},{"entry":[{},"\u2003\u2003\u2003change encoding"]},{"entry":[{},"\u2003\u2003\u2003break"]},{"entry":[{},"\u2003\u2003end"]},{"entry":[{},"\u2003end"]},{"entry":[{},"end"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"In this scheme, the average network bandwidth is unable to sustain the video playout rate and a playback stoppage is imminent once the buffer runs out. This scheme requires relatively few calculations to determine when to switch encodings. However, it also has relatively low capability for predicting when a stoppage will occur. The encoding to switch to is the next lowest bit rate encoding whose bit rate is less than the average network bandwidth. Switching encodings to one of higher bit rate is initiated when the buffer occupancy of the media buffer  has reached its capacity and the average bandwidth exceeds the encoding bit rate of another encoding:",{"@attributes":{"id":"p-0072","num":"0084"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["int bandwidth_avg","\/\/ average available network bandwidth"]},{"entry":["int video_bit_rate","\/\/ current video encoding bit rate"]},{"entry":["int buffer_occupancy","\/\/ seconds of video currently in the buffer"]},{"entry":["int buffer_capacity","\/\/ seconds of video the buffer can hold"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"if bandwidth_avg > video_bit_rate && buffer_occupancy >= buffer_capacity"},{"entry":"\u2003for each encoding sorted by bit rate in descending order"},{"entry":"\u2003\u2003if encoding.bit_rate < bandwidth_avg && encoding.bit rate != "},{"entry":"\u2003\u2003video_bit_rate"},{"entry":"\u2003\u2003\u2003change encoding"},{"entry":"\u2003\u2003\u2003break"},{"entry":"\u2003\u2003end"},{"entry":"\u2003end"},{"entry":"end"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"The encoding to switch to is the highest bit rate encoding whose bit rate is less than the average network bandwidth. This is an optimistic approach which assumes no further degradation in bit rate and works well when connected to a reliable, high bandwidth network. In another embodiment predictive bandwidth schemes may also be used to optimize rate adaptation for other environments.",{"@attributes":{"id":"p-0074","num":"0086"},"figref":["FIGS. 8-10","FIGS. 3-7"]},{"@attributes":{"id":"p-0075","num":"0087"},"figref":"FIG. 8","b":["600","602","202","202","204","604","202","602","604"]},"The stream transcoder  processing begins in step , once data has been queued by the stream recorder . In step , the stream transcoder  starts by decoding individual frames from the recorded data. In step , the stream transcoder  re-encodes each frame based on the output configuration. In step , the stream transcoder  passes the encoded frame to the output framer . In step , the stream transcoder  determines if additional encodings of the current frame are needed. If another encoding is required, processing proceeds back to step  where the current frame is encoded into another encoding. If no additional encodings are required, processing proceeds back to step , where the next frame is decoded. In one embodiment, the stream transcoder supports generating a plurality of different bit rate encodings, as well as using a plurality of different codecs. The stream transcoder  encodes frames into a full permutation of bitrates and codecs. Steps , , and  are repeated for each encoding, on a given frame.","The output framer  processing begins in step  when frames are enqueued by the stream transcoder . The stream transcoder  produces multiple output frames for each input frame. In step , the output framer  maps each output frame to a specific output segment file, creating a new segment file in the media storage  if necessary. The output framer  synchronizes encoding configurations with unique segment files. In one embodiment, the output framer  also packs each frame into a plurality of segment file formats. In one embodiment, the frame formats include MPEG-TS and the custom frame format . In another embodiment, the frame format may include FLV or any other suitable container format, as should be known to those skilled in the art.","In step , the output framer  checks to see if the custom frame format for the RTP protocol  is required. If the custom frame format for the RTP protocol  is not required, then processing continues to step . If the custom frame format for the RTP protocol  is required, then processing proceeds to step  where the RTP packet headers , RTP padding , and the segment frame header  are added to the frame. The frame is then appended to the appropriate segment file, stored in the media storage , and processing continues to step . In one embodiment, only the custom format for the RTP protocol is required. In another embodiment, additional custom formats for RTMP or other protocols may be required. Steps  and  should be repeated for each additional custom frame format required.","In step , the output framer  checks to see if the MPEG-TS format is required. If the MPEG-TS format is not required, then processing continues to step . If the MPEG-TS format is required, then processing proceeds to step  where the frame and MPEG metadata headers are added to the appropriate segment file, stored in the media storage , and processing continues to step . In step , the output framer  checks to see if the segments are complete. In one embodiment, the segments are of a fixed duration, measured in seconds S. Given the constant frame rate R of the stream transcoder  output, the segments each contain a fixed number of frames F, where F=S*R. If the segment is not yet complete, processing proceeds back to step . If the segment(s) are complete, processing proceeds to step .","In step , the output framer performs any file post-processing. In one embodiment, file header reordering may be used to optimize the segment for client parsing. In another embodiment, additional hint tracks may be added to aid in client parsing. In another embodiment, additional compression may be applied to optimize segment delivery. Once the post-processing is complete, the output framer  notifies the segment encryptor  that the new segment(s) is available. The output framer  proceeds back to step , while the segment encryptor  proceeds to step .","In step , the segment encryptor  checks to see if encryption is required. If encryption is not required, processing continues to step . If encryption is required, processing continue to step  where the segment encryptor  reads the segment(s) from the media storage , encrypts the segment(s), and writes the segment(s) back out to the media storage , before continuing on to step . In step , the segment encryptor  notifies the segment uploader  that the new segment(s) is available. The segment encryptor  proceeds back to step  to wait for the next segment. The segment upload proceeds to step  where the segment is uploaded to the network storage .",{"@attributes":{"id":"p-0082","num":"0094"},"figref":"FIG. 9","b":["700","108","702","402","106","410","408","704","704","402","420","404","402","706","404","714"]},"In step , the downloader  checks to see if a bit rate change is required. Given the fixed segment duration of S seconds, download of live segments must take less than S seconds. If the download time for the previous segment exceeded some threshold T, where T<S, then a transition to a lower bit rate is required. If the download time for the previous segment was below a alternate threshold T\u2032, where T\u2032<<S, then a transition to a higher bit rate may be required. In one embodiment, given three bit rate encodings, encoded at bitrates: B, B\u2032, B\u2033, where B<B\u2032<B\u2033, the threshold T, for switching from B\u2032 to B, would be: T=C*S, where C is a constant multiplier and C<1.0 (e.g. C=0.8). In one embodiment, given three bit rate encodings, encoded at bitrates: B, B\u2032, B\u2033, where B<B\u2032<B\u2033, the threshold T\u2032, for switching from B\u2032 to B\u2033 would be: T\u2032=(C*S)*(B\u2032\/B\u2033), where C is a constant multiplier and C<1.0 (e.g. C=0.8) and B\u2032\/B\u2033 represents the ratio of additional bandwidth required to support the new bit rate. In another embodiment, different thresholds may be used to favor upward or downward transitions. In deployments where high bandwidth and high network availability is expected, upward transitions may be favored. In deployments where network interruption is likely, downward transitions may be favored. In one embodiment, historical average segment download times are used to account for hysteresis. If the download time for the previous segment was between T\u2032 and T, then no action is needed, and processing continues to step . If a bit rate change is required, processing continues to step , where the new bit rate is chosen, then proceeds to step .","In step , the downloader  determines file name of the next segment. In one embodiment, the file names follow a well known naming convention such that bit rate and sequence number are embedded in the file name. In another embodiment, the file names may be retrieved from a Web service interface. The downloader  then begins polling for the next segment. In one embodiment, the downloader  calculates the time when the next segment will be available and waits until then to poll. In another embodiment, the downloader  may discount the segment availability time by the round trip delay for requesting the segment. In another embodiment, the downloader  begins polling immediately but uses an exponential decay algorithm to poll faster as the next segment availability time gets nearer. Once a new segment is retrieved, the downloader  returns to step .","In step , the segment decryptor  checks to see if the segment is encrypted. If the segment is not encrypted, then processing continues to step . If the segment is encrypted, processing continues to step , where the segment decryptor  reads in the segment from the media buffer , decrypts the segment, and writes the segment back out to the media buffer , then continues to step . In step , the segment decryptor  notifies the segment parser  that the new segment is available. The segment decryptor  returns to step , while the segment parser  proceeds to step .","In step , the segment parser  begins processing the custom segments  by extracting the next RTP packet . The custom segments  are parsed sequentially, using the payload lengths  to determine frame  boundaries. Each RTP packet  processed individually. The segment parser  queues the packet to the RTSP server , in step . In step , the segment parser  checks to see if the current frame is the last frame in the segment. If the current frame is not the last frame, the segment parser  proceeds back to step  to process the next frame. If the current frame is the last frame, the segment parser  proceeds to step  where it purges the segment, then continues back to step  to wait for the next segment. In one embodiment, segments are immediately purged by the segment parser . In another embodiment, the segment parser  waits until the media buffer  is full, before purging segments. If the mobile client  has limited memory immediate purging may be required, to make room for new segments in the media buffer . If the network is expected to have high error rates, immediate purging also frees up cache space in the media buffer , allowing more segments to be prefetched, which helps protect against future network errors. If the client application wishes to support rewind capabilities, delayed purging allows the media buffer  to cache previous segments for immediate access, when requested by the media player , rather than having to delay while the segment is re-downloaded.","The RTSP server  processes requests from the media player  asynchronously from the segment retrieval. Once the media player  negotiates the RTP connections  and  for the streaming session, the RTSP server  sends RTP packets  in a paced fashion, as dictated by timestamps in the RTP headers , as should be known to those skilled in the art. Step  shows the RTSP server  sending RTP packets to the media player . The RTSP server  maintains separate queues and separate timers for audio and video RTP packets to simplify parsing and delivery.",{"@attributes":{"id":"p-0088","num":"0100"},"figref":"FIG. 10","b":["800","108","802","402","106","510","508","402","510","804","804","402","420","404","402","806","404","814"]},"In step , the downloader  checks to see if a bit rate change is required. Given the fixed segment duration of S seconds, download of live segments must take less than S seconds. If the download time for the previous segment exceeded some threshold T, where T<S, then a transition to a lower bit rate is required. If the download time for the previous segment was below a alternate threshold T\u2032, where T\u2032<<S, then a transition to a higher bit rate may be required. In one embodiment, given three bit rate encodings, encoded at bitrates: B, B\u2032, B\u2033, where B<B\u2032<B\u2033, the threshold T, for switching from B\u2032 to B, would be: T=C*S, where C is a constant multiplier and C<1.0 (e.g. C=0.8). In one embodiment, given three bit rate encodings, encoded at bitrates: B, B\u2032, B\u2033, where B<B\u2032<B\u2033, the threshold T\u2032, for switching from B\u2032 to B\u2033 would be: T\u2032=(C*S)*(B\u2032\/B\u2033), where C is a constant multiplier and C<1.0 (e.g. C=0.8) and B\u2032\/B\u2033 represents the ratio of additional bandwidth required to support the new bit rate. In another embodiment, different thresholds may be used to favor upward or downward transitions. In deployments where high bandwidth and high network availability is expected, upward transitions may be favored. In deployments where network interruption is likely, downward transitions may be favored. In one embodiment, historical average segment download times are used to account for hysteresis. If the download time for the previous segment was between T\u2032 and T, then no action is needed, and processing continues to step . If a bit rate change is required, processing continues to step , where the new bit rate is chosen, then proceeds to step .","In step , the downloader  determines file name of the next segment. In one embodiment, the file names follow a well known naming convention such that bit rate and sequence number are embedded in the file name. In another embodiment, the file names may be retrieved from a Web service interface. The downloader  then begins polling for the next segment. In one embodiment, the downloader  calculates the time when the next segment will be available and waits until then to poll. In another embodiment, the downloader  may discount the segment availability time by the round trip delay for requesting the segment. In another embodiment, the downloader  begins polling immediately but uses an exponential decay algorithm to poll faster as the next segment availability time gets nearer. Once a new segment is retrieved, the downloader  returns to step .","In step , the segment decryptor  checks to see if the segment is encrypted. If the segment is not encrypted, then processing continues to step . If the segment is encrypted, processing continues to step , where the segment decryptor  reads in the segment from the media buffer , decrypts the segment, and writes the segment back out to the media buffer , then continues to step . In step , the segment decryptor  notifies the playlist generator  that the new segment is available. The segment decryptor  returns to step , while the playlist generator  proceeds to step .","In step , the playlist generator  updates the current playlist adding the new segment and removing the oldest segment. Once segments have been removed from the playlist, the segments are no longer required in the media buffer . In one embodiment, segments are immediately purged by the playlist generator . In another embodiment, the playlist generator  waits until the media buffer  is full, before purging segments. If the mobile client  has limited memory immediate purging may be required, to make room for new segments in the media buffer . If the network is expected to have high error rates, immediate purging also frees up cache space in the media buffer , allowing more segments to be prefetched, which helps protect against future network errors. If the client application wishes to support rewind capabilities, delayed purging allows the media buffer  to cache previous segments for immediate access, when requested by the media player , rather than having to delay while the segment is re-downloaded.","The playlist generator  then notifies the HTTP Server  of the playlist update. Step  shows the HTTP server  getting the notification from the playlist generator , however, the HTTP server  processes requests from the media player  asynchronously from the segment retrieval. When the media player  requests playlists, the HTTP server  provides the most recent playlist made available by the playlist generator . When the media player  requests segments, the HTTP server  retrieves the segments from the media buffer  and returns them to the media player . The media player  should only request segments that are in the playlist. The playlist generator  ensures that segments in the playlist exist in the media buffer .","In the description herein for embodiments of the present invention, numerous specific details are provided, such as examples of components and\/or methods, to provide a thorough understanding of embodiments of the present invention. One skilled in the relevant art will recognize, however, that an embodiment of the invention can be practiced without one or more of the specific details, or with other apparatus, systems, assemblies, methods, components, materials, parts, and\/or the like. In other instances, well-known structures, materials, or operations are not specifically shown or described in detail to avoid obscuring aspects of embodiments of the present invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing and other objects, features and advantages will be apparent from the following description of particular embodiments of the invention, as illustrated in the accompanying drawings in which like reference characters refer to the same parts throughout the different views. The drawings are not necessarily to scale, emphasis instead being placed upon illustrating the principles of various embodiments of the invention.",{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
