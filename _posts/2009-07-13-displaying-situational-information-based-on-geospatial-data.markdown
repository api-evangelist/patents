---
title: Displaying situational information based on geospatial data
abstract: In accordance with a particular embodiment of the invention, a request for a geotag comprising situational information and geographic coordinates may be received from a requestor. The request may include geospatial data, such as position data and viewing angle data, that identifies a location of the requester. The position data may be latitude data, longitude data, and/or elevation data, and the viewing angle data may be azimuth data, compass direction data, and/or orientation data. The geographic coordinates of a candidate geotag may be compared to the location received in the request. If the candidate geotag is near the location received in the request, it may be sent to the requestor.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08558847&OS=08558847&RS=08558847
owner: Raytheon Company
number: 08558847
owner_city: Waltham
owner_country: US
publication_date: 20090713
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND","SUMMARY OF EXAMPLE EMBODIMENTS","DETAILED DESCRIPTION"],"p":["This application is related to U.S. patent application Ser. No. 12\/501,905, entitled \u201cEXTRACTION OF REAL WORLD POSITIONAL INFORMATION FROM VIDEO,\u201d; to U.S. patent application Ser. No. 12\/501,969, entitled \u201cOVERLAY INFORMATION OVER VIDEO,\u201d; and to U.S. patent application Ser. No. 12\/501,785, entitled \u201cSYNCHRONIZING VIDEO IMAGES AND THREE DIMENSIONAL VISUALIZATION IMAGES,\u201d, all filed concurrently with the present application.","The present disclosure relates generally to image displays, and more particularly to displaying situational information based on geospatial data.","A decision-maker may have difficulty making a decision in the absence of information. For example, a decision-maker in an unfamiliar situation may lack access to situational information that may affect the decision.","In accordance with a particular embodiment of the invention, a request for a geotag comprising situational information and geographic coordinates may be received from a requester. The request may include geospatial data, such as position data and viewing angle data, that identifies a location of the requester. The position data may be latitude data, longitude data, and\/or elevation data, and the viewing angle data may be azimuth data, compass direction data, and\/or orientation data. The geographic coordinates of a candidate geotag may be compared to the location received in the request. If the candidate geotag is near the location received in the request, it may be sent to the requestor.","Certain embodiments of the present invention may provide various technical advantages. A technical advantage of one embodiment may allow users of a situational awareness tool to share communications and observations. For example, a user may view a display comprising the communications and observations of other users to learn information about a situation. In some embodiments, the communications and observations may be displayed on a background image that depicts the user's surroundings. The background image may be selected according to the perspective of a device used to generate the display. For example, the background image may be selected according to the position and viewing angle of the device.","Although specific advantages have been enumerated above, various embodiments may include all, some, or none of the enumerated advantages. Additionally, other technical advantages may become readily apparent to one of ordinary skill in the art after review of the following figures and description.","It should be understood at the outset that, although example implementations of embodiments of the invention are illustrated below, the present invention may be implemented using any number of techniques, whether currently known or not. The present invention should in no way be limited to the example implementations, drawings, and techniques illustrated below. Additionally, the drawings are not necessarily drawn to scale.","Situational awareness tools may provide situational information that may aide a decision maker in making decisions. For example, in military applications, a soldier may use situational information, such as the location of a sniper, to make tactical decisions. Accordingly, the teachings of some embodiments may allow users of a situational awareness tool to share communications and observations with each other.","In some embodiments, the communications and observations about a particular location may be collected by a user, such as an agent, or a device. Examples of an agent may include a person or a vehicle. Examples of a device may include an Unmanned Aircraft Vehicle (UAV), a surveillance camera, or any device suitable for gathering information. In some embodiments, the agent may be equipped with a camera configured to collect images of the location. The data, such as the camera images, may be embedded with geographic coordinates indicating the location corresponding to the data. In some embodiments, the data may be continually updated by one or more agents or devices thereby creating a continuous journal of information about an area. The journal may be based on contributions from any agent or device that has previously reckoned the area. For example, a border patrol agent may collect and share an image of a hole in a fence. Later, a second border patrol agent may observe a change in the size of the hole. The second border patrol agent may collect and share an updated image of the hole. Thus, a user retrieving information about the fence may have access to the cumulative knowledge of both agents. Over time, a large amount of situational information may accumulate, thereby providing users with detailed information about areas of interest. In some embodiments, access to cumulative knowledge may allow the user to have increased situational awareness.","In some embodiments, a user may access the situational information from a mobile device. The mobile device may display a background image on which the situational information may be overlaid. In some embodiments, the background image may be a three-dimensional visualization image. In some embodiments, the background image may be selected according to the geospatial perspective of the device. That is, the background image may be selected according to the position and viewing angle of the device. For example, a user located in a battlefield may be interested in knowing if any Improvised Explosive Devices (IEDs) have exploded in the area in the last month. The user may point the device toward a region of the battlefield to view the location of recent IED explosions within that region. Additionally, the user may move or rotate the device to change the perspective displayed. Thus, the user may be able to obtain information about other regions within the battlefield.",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1","b":["100","110","120","120","124","126","124","130","100"]},"The device  may be any suitable device for displaying an image. In some embodiments, the device  may be portable. For example, the device  may be a mobile phone, goggles, or a laptop computer. In other embodiments, the device  may not be portable. The device  may be configured to provide a variety of features. In some embodiments, a user may access and\/or control the features of the device  through the feature buttons . The feature buttons  may be any suitable user interface for the device , such as a keyboard or keypad, a mouse, or a touch screen. In some embodiments, the feature buttons  may be located remotely from the device .","The feature buttons  may provide access to and\/or a control interface for one or more features such as, but not limited to, mapping features, tracking features, communications features, video features, global visualization features, and\/or any other suitable feature. Internet features may include internet browsing as well as downloading and uploading of data. Mapping features may be configured to provide maps and travel directions to a user. Tracking features may include tracking one or more moving subjects or objects. For example, in military applications, members of allied troops may be tracked in one color and members of enemy troops may be tracked in a different color. Communications features may provide voice call, text messaging, chat session, and notification capabilities. Video features may include recording, playing, pausing, fast forwarding, and rewinding of video. Global visualization features may allow a user to select a location of the globe to be represented in a three-dimensional view. In some embodiments, an application may use capabilities of multiple feature buttons  at the same time. For example, a situational awareness application may use the internet feature, the communications feature, the global visualization feature, and\/or any other suitable feature simultaneously. As another example, the situational awareness application may use the tracking feature, the mapping feature, and\/or any other suitable feature simultaneously.","In some embodiments, one or more features may generate a display on the display screen . In some embodiments, the display screen  may be any component suitable to display an image such as a Cathode Ray Tube (CRT), a Liquid Crystal Display (LCD), a Plasma Display Panel (PDP), or a projector. In some embodiments, the display screen  may be a touch screen that may allow a user to control the image or the device . For example, the user may control the image by touching the display screen  to make changes such as zooming in or out, moving the image up, down, left, or right, rotating the image, or adjusting the viewing angle. As another example, the feature buttons  may be integrated on the display screen  to allow the user to control the device  by touching the display screen . In some embodiments, the display screen  may be configured to change the image displayed according to changes in the position and\/or viewing angle of the device .","In some embodiments, the image displayed on the display screen  of the device  may comprise the background image . In some embodiments, the background image  may be selected according to the geographic region in which the device  is located in order to provide information about the live scene  of that geographic region. For example, the background image  may be selected according to the geospatial data comprising the position and the viewing angle of the device .","In some embodiments, the position of the device  may be determined using a Location Based Services (LBS) system. An LBS system may be any system suitable for locating the latitude, longitude, and\/or elevation coordinates of the device . For example, an LBS system may use a satellite system such as a Global Positioning System (GPS) to locate the device . As another example, an LBS system may use multilateration techniques based on the signals sent and\/or received by the device  such as Time Difference Of Arrival (TDOA) techniques or Enhanced Observed Time Difference (E-OTD) techniques.","In some embodiments, the viewing angle of the device  may be determined using any suitable systems such as, but not limited to, accelerometers, gyroscopes, and\/or compasses onboard the device . The viewing angle may comprise azimuth data, compass direction data, and\/or orientation data. Azimuth data may describe the rotation of the device  around a horizontal axis , the horizontal axis  running substantially parallel to the surface of the earth. For example, azimuth data may indicate whether the device  is pointed down toward the ground or up toward the sky. Compass direction data may describe the rotation of the device  around a vertical axis , the vertical axis  running substantially perpendicular to the surface of the earth. In some embodiments, the compass direction data may range from 0 to 360 degrees. For example, the compass direction may be 0 degrees when the device  faces East, 90 degrees when the device  faces North, 180 degrees when the device  faces West, and 270 degrees when the device  faces South. Orientation data may indicate whether the device  is turned on its side, for example, according to a device orientation angle . The device orientation angle  may represent the rotation around an axis in a third dimension, the axis in the third dimension running perpendicular to both the horizontal axis  and the vertical axis . By way of non-limiting illustration, Google's G1 mobile phone running on the Android platform and Apple's Iphone contain tools to recognize location and viewing angle of the respective mobile device.","In some embodiments, the device  may be configured to display the background image  corresponding to geospatial coordinates selected by a user of the device . That is, a user may override the function that selects the background image  corresponding to the perspective of the device . Overriding the device perspective may allow the user to obtain information about a position or viewing angle for which the user would like to obtain situational information. In some embodiments, the position and viewing angle of the device may be used to generate a default background image that may be the starting image when the user enables the override function. Thus, a user may continue to view information about a surrounding scene without having to continuously hold the device in the same position.","In some embodiments, the background image  may be displayed to provide context for situational information. In some embodiments, the characteristics of the situational information being conveyed may be used to determine the type of background image  to be displayed, if any. For example, a background image  may not be required to convey the name of a shopkeeper. As another example, a two-dimensional image, such as a map or a blueprint, may be well-suited to conveying the address where a shop is located or the floor plan of the shop. As yet another example, a three-dimensional visualization image may be well-suited to conveying the shooting angle of a sniper located at a particular entrance of the shop. In some embodiments, the three-dimensional visualization image may be provided by a three-dimensional visualization tool. In some embodiments, the three-dimensional visualization tool may be a Commercial Off-The-Shelf (COTS) tool like Google Earth or NASA World Wind.","In some embodiments, the display screen  of the device  may display one or more geotags  to provide situational information about the displayed image. The geotags  may be in any format suitable to convey the situational information. For example, the geotags  may be in visual form, such as text, icons, photographs, color codes, and\/or drawings, audio form, such as voice recordings or sound effects, or a combination, such as video. In some embodiments, the geotags  may comprise geographic coordinates that indicate a location corresponding to the geotag. In some embodiments, the geographic coordinates may indicate the latitude, longitude, and\/or elevation described by the situational information. For example, if the situational information indicates that an IED exploded, the geographic coordinates may indicate where the IED exploded. The geotags  may be overlaid on the background image . For example, the geotags may be overlaid according to their geographic coordinates. Geotags may be generated using any suitable method, device, or technique that places coordinates on a piece of information. The coordinates may be two-dimensional, three-dimensional, or four-dimensional (including time). As a non-limiting example, geotags may be generated using the method of U.S. Ser. No. 12\/501,969 to generate geotags.","In some embodiments, the geotags  may comprise social network geotags, historical geotags, identification geotags, annotation geotags, or a combination. For example, social network geotags may indicate social opinion information like where to find the best coffee in town, social relationship information like a shop owner's brother is a military detainee, social observation information like a sniper has been observed in a particular location, or any other information available through a social network.","Historical geotags may provide historical information such as the number of Improvised Explosive Devices (IEDs) that detonated in the area in the last month.","Identification geotags may provide identification information. For example, an identification geotag may identify an orphanage one hundred yards away. As another example, an identification geotag may translate Grid Reference Graphics (GRG) information. GRG information may provide a naming convention for describing a location. The GRG information may comprise a name that denotes a particular building, a color that denotes a floor number of the building, and a number that denotes an entrance of the building. For example, a soldier may receive GRG information \u201cMatilda, green, 2\u201d indicating the location of a sniper. However, understanding this GRG information may require knowledge of the naming convention. In some embodiments, the geotags  may provide the information of the GRG reference without requiring the user to know the GRG naming convention. Thus, the soldier may be able to visualize where the sniper is located and\/or the sniper's shooting angle when deciding how to safely approach the building.","Annotation geotags may comprise notes that a user makes about a scene. For example, a user may annotate the background image  using a grease pen function that allows the user to draw or write on the display screen  by hand or a computerized annotation function that allows a user to select descriptive icons, labels, or color codes to be incorporated into the underlying scene at the option of the user.","In some embodiments, the geotags  may be given a rating. For example, determining where to find the best coffee in town may be based on the highest percentage of favorable ratings according to a large number of users. As another example, ratings may be affected by the date and time the geotag  was generated. For example, more current geotags may be given a more favorable rating than older geotags. In some embodiments, a rating system may help to ensure a user is provided access to more informative geotags. For example, if a first geotag is a photograph with a clear view and a second geotag is a blurry photograph of the same view, the first geotag may be given a more favorable rating.","A component described in  may include an interface, logic, memory, and\/or other suitable element used to carry out the above-described functions. An interface receives input, sends output, processes the input and\/or output, and\/or performs other suitable operation. An interface may comprise hardware and\/or software.","Logic performs the operations of the component, for example, executes instructions to generate output from input. Logic may include hardware, software, and\/or other logic. Logic may be encoded in one or more tangible media and may perform operations when executed by a computer. Certain logic, such as a processor, may manage the operation of a component. Examples of a processor include one or more computers, one or more microprocessors, one or more applications, and\/or other logic.","In particular embodiments, the operations of the embodiments may be performed by one or more computer readable media encoded with a computer program, software, computer executable instructions, and\/or instructions capable of being executed by a computer. In particular embodiments, the operations of the embodiments may be performed by one or more computer readable media storing, embodied with, and\/or encoded with a computer program and\/or having a stored and\/or an encoded computer program.","A memory stores information. A memory may comprise one or more tangible, computer-readable, and\/or computer-executable storage medium. Examples of memory include computer memory (for example, Random Access Memory (RAM) or Read Only Memory (ROM)), mass storage media (for example, a hard disk), removable storage media (for example, a Compact Disk (CD) or a Digital Video Disk (DVD)), database and\/or network storage (for example, a server), and\/or other computer-readable medium.","Modifications, additions, or omissions may be made to systems described herein without departing from the scope of the invention. The components of the systems may be integrated or separated. Moreover, the operations of the systems may be performed by more, fewer, or other components. Additionally, operations of the systems may be performed using any suitable logic comprising software, hardware, and\/or other logic. As used in this document, \u201ceach\u201d refers to each member of a set or each member of a subset of a set.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 2","FIG. 1"],"b":"100"},"In some embodiments, the situational information may be stored locally, obtained from a network, or a combination of both. Examples of a network may include, but are not limited to, a public or private data network; a local area network (LAN); a metropolitan area network (MAN); a wide area network (WAN); a wireline or wireless network; a local, regional, or global communication network; an optical network; a satellite network; an enterprise intranet; other suitable communication links; or any combination of the preceding. In some embodiments, the network may comprise a client-server network with one or more central databases for storing, sorting, and pulling geotags. In some embodiments, the network may comprise a peer-to-peer network. A peer-to-peer network may comprise a plurality of peers, each peer capable of acting as both a client and a server. Thus, the situational awareness tool may not require a central database in some embodiments. In some embodiments, the network may comprise a combination of client-server and peer-to-peer networks. For example, a client-server configuration may be used for normal operations, and a peer-to-peer network may be formed ad hoc as needed, such as when a signal tower goes down, when two or more users are out of range of the signal tower, or when a peer-to-peer configuration would otherwise be efficient.","In some embodiments, access to some or all of the geotags may be restricted to certain users. Determining whether a user is authorized to access the geotag may be based on predetermined criteria such as, but not limited to, user name, password, device serial number, and\/or any suitable criteria.","In some embodiments, the system of  may comprise a device , which may be like the device  of . The device  may be configured with a mobile situational awareness tool. In some embodiments, the device  may comprise an Operating System (OS) Activity , an Application Programming Interface (API) , and\/or a three-dimensional visualization tool . In some embodiments, the device  may receive inputs such as device inputs  and\/or user inputs  to generate a device output . In some embodiments, the OS Activity  may comprise a Mobile Situational Awareness (MSA) . In some embodiments, the API  may be coupled to a geotag database . In some embodiments, the three-dimensional visualization tool  may be coupled to a visualization database .","In some embodiments, the OS Activity  may be an interface between the hardware and the software of the device . For example, OS Activity  may comprise base classes that interact with the hardware architecture of the device . In some embodiments, the OS Activity  may manage a situational awareness application. For example, the OS Activity  may receive the device inputs  and direct them to the situational awareness application. In some embodiments, the device inputs  may comprise geospatial data defining a geographic region in which the device  is located. For example, the geospatial data may comprise position data, such as latitude data, longitude data, and elevation data, and\/or viewing angle data, such as azimuth data, compass direction data, and orientation data. In some embodiments, the device inputs  may comprise situational information to be pushed from the device to a the situational awareness tool. For example, the device inputs  may comprise a new geotag, such as a photograph, to be pushed to the geotag database .","In some embodiments, the MSA Activity  of the OS Activity  may extend the base capabilities of the OS Activity . In some embodiments, the MSA Activity  may receive user inputs  from a user interface. For example, the user inputs  may comprise user search criteria and\/or user viewing criteria. In some embodiments, user search criteria may indicate the characteristics of the geotags that the user is interested in retrieving. For example, the user search criteria may indicate that the user has requested to see the names of store clerks on the block. As another example, the user search criteria may indicate that the user has requested to see the location of a hole in a fence. The user search criteria may be used to request any suitable characteristics. In some embodiments, user viewing criteria may indicate the view that the user is interested in seeing. For example, the user may request to modify the viewing angle of the current view. As another example, the user may request to view the geographic region corresponding to a particular set of geographic coordinates.","In some embodiments, the MSA Activity  may send the device inputs  and\/or the user inputs  to the API . The API  may process the inputs. In some embodiments, the API  may process a new geotag being pushed by a user so that the geotag may be stored in the geotag database . In some embodiments, the API  may process a request for data. For example, the API may process the user search criteria of the user inputs  to pull a geotag from the geotag database . As another example, the API  may process geospatial data received from the device inputs  or from the user viewing criteria of the user inputs  to pull a three-dimensional visualization image from the three-dimensional visualization tool . In some embodiments, the API  may format the geotags in a file format that may be used by the three-dimensional visualization tool . For example, the geotag translator  may format the geotags in Keyhole Markup Language (KML) format or Key Length Value (KLV) format.","In some embodiments, the API  may be coupled to the geotag database . The geotag database  may be local, for example, it may be located on the device configured with the API . Alternatively, the geotag database  may be remote, for example, it may be located at a network server. The geotag database  may receive, store, sort, and\/or send a plurality of geotags. In some embodiments, the mobile situational awareness tool may receive a request to pull a geotag from the geotag database . The geotags stored in the geotag database  may be candidates for responding to the request. The geotag database  may store hundreds, thousands, or more candidate geotags. If a candidate geotag fits the criteria of the request, the candidate geotag may be sent to the requester. For example, the request may comprise geospatial data that defines a geographic region in which the device  is located. The geospatial data may be based on the device inputs  and\/or the user inputs . In some embodiments, the geotag database  may send a candidate geotag in response to the request if the geographical coordinates of the candidate geotag are within the geographic region of the request. In some embodiments, the request may comprise user search criteria indicating one or more characteristics of the geotag requested from the database. The geotag database  may send a candidate geotag if the characteristics of the candidate geotag match the characteristics requested in the request.","In some embodiments, the three-dimensional visualization tool  may be used to generate a background image, such as the background image  of . The background image may be selected according to geospatial data such as latitude, longitude, elevation azimuth, compass direction, and\/or orientation. In some embodiments, the geospatial data may be based on the device inputs , the user viewing criteria of the user inputs , or a combination. For example, a background image selected according to the device inputs  may be refined according to the user viewing criteria. In some embodiments, the user viewing criteria may allow the user to modify the perspective of the view by accessing features of a COTS three-dimensional visualization tool such as Google Earth or NASA World Wind. For example, the user may be able to zoom in or zoom out of the area surrounding the location shown in the video, shift the image up, down, left, or right, change the compass direction, or change the viewing angle. Refining the background area according to the user viewing criteria may provide the user with more information which may allow for greater situational awareness.","According to some embodiments, the user viewing criteria may also comprise any criteria that may be entered into the three-dimensional visualization tool . That is, the user viewing criteria may be used to access any feature of the three-dimensional visualization tool  such as a COTS three-dimensional viewing tool. For example, the user viewing criteria may request that information be displayed such as geographic borders, names of geographic locations, names of landmarks, or street locations and names. The user viewing criteria may also modify the displayed image to provide more information about the view. For example, buildings may be displayed in a three-dimensional form, photographs of street views may be accessed, or terrain information may be shown. The user viewing criteria may also be used to view current conditions in the area such as traffic and\/or weather conditions.","In some embodiments, the three-dimensional visualization tool  may be coupled to a database, such as a visualization database . The visualization database  may be local, for example, it may be located on the device configured with the three-dimensional visualization tool . Alternatively, the visualization database  may be remote, for example, it may be located at a network server. According to some embodiments, the visualization database  may be a COTS database. The visualization database  may hold three-dimensional visualization images depicting a plurality of locations. In some embodiments, the images may comprise satellite images, aerial photography images, Geographic Information System (GIS) images, or a combination. The three-dimensional visualization tool  may query the visualization database  to obtain images of a particular location.","In some embodiments, the API  may return the requested data, such as a geotag or a background image comprising a three-dimensional visualization image, to the OS Activity  via the MSA Activity . The OS Activity  may output the data at the device output . In some embodiments, the device output  may be used to convey the information to a user. For example, the device output  may be used to display the information at a display. In some embodiments, the device output  may be input into another system. For example, the device output  may be output to a computer where the data may be further processed or displayed.","Modifications, additions, or omissions may be made to the methods described herein without departing from the scope of the invention. The methods may include more, fewer, or other steps. Additionally, steps may be performed in any suitable order.","Although several embodiments have been illustrated and described in detail, it will be recognized that substitutions and alterations are possible without departing from the spirit and scope of the present invention, as defined by the appended claims.","To aid the Patent Office, and any readers of any patent issued on this application in interpreting the claims appended hereto, applicants wish to note that they do not intend any of the appended claims to invoke 6 of 35 U.S.C. \u00a7112 as it exists on the date of filing hereof unless the words \u201cmeans for\u201d or \u201cstep for\u201d are explicitly used in the particular claim."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["For a more complete understanding of certain embodiments of the present invention and features and advantages thereof, reference is now made to the following description taken in conjunction with the accompanying drawings, in which:",{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 2"}]},"DETDESC":[{},{}]}
