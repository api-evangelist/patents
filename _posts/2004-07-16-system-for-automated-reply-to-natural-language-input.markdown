---
title: System for automated reply to natural language input
abstract: Method and agent network architecture for processing a subject message, where each agent has a view of its own domain of responsibility. An initiator agent which receives a user-input request and does not itself have a relevant interpretation policy, queries its downchain agents whether the queried agent considers such message to be in its domain of responsibility. Each queried agent recursively determines whether it has an interpretation policy of its own that applies to the request, and if not, further queries its own further downchain neighboring agents. The further agents eventually respond to such further queries, thereby allowing the first-queried agents to respond to the initiator agent. The recursive invocation of this procedure ultimately determines one or more paths through the network from the initiator agent to one more more leaf agents. The request is then transmitted down the path(s), with each agent along the way taking any local action thereon and passing the message on to the next agent in the path. In the event of a contradiction, the network is often able to resolve many of such contradictions according to predetermined algorithms. If it cannot resolve a contradiction automatically, it learns new interpretation policies necessary to interpret the subject message properly. Such learning preferably includes interaction with the user (but only to the extent necessary), and preferably localizes the learning close to the correct leaf agent in the network.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07761499&OS=07761499&RS=07761499
owner: Sybase, Inc.
number: 07761499
owner_city: Dublin
owner_country: US
publication_date: 20040716
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CLAIM OF PRIORITY","REFERENCE TO COMPUTER PROGRAM LISTING AND TABLE APPENDICES","COPYRIGHT DISCLAIMER","BACKGROUND","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION","Individual Agent Functions","Interconnection of Agents","Special Purpose Agents","Agent Network Embodiment","Communication Among Agents","Object-Oriented Agent Network Implementation","Typical Network Message Flow","Example","Industrial Applicability","Sample Source Code"],"p":["This application is a Continuation of U.S. patent application Ser. No. 10\/004,042, filed Dec. 4, 2001, now U.S. Pat. No. 6,772,190, which is a Continuation of U.S. patent application Ser. No. 09\/624,763, filed Jul. 24, 2000, now U.S. Pat. No. 6,594,684, which is a Continuation of U.S. patent application Ser. No. 09\/183,764, filed Oct. 30, 1998, now U.S. Pat. No. 6,144,989, which claims the benefit of Provisional Application No. 60\/089,394 filed Jun. 15, 1998. All of the predecessor applications are incorporated herein by reference.","Computer program listings and Table appendices comprising duplicate copies of a compact disc, named \u201cDEJI 1000-17\u201d, accompany this application and are incorporated by reference. The machine format is IBM-PC, the operating system compatibility is MS-Windows, and the files contained on the compact discs are as follows:",{"@attributes":{"id":"p-0004","num":"0003"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"91pt","align":"center"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"APPENDIX I.txt","59 Kbytes","created Sep. 19, 2002"]},{"entry":[{},"APPENDIX II.txt","\u20027 Kbytes","created Sep. 19, 2002"]},{"entry":[{},"APPENDIX III.txt","\u20023 Kbytes","created Sep. 19, 2002"]},{"entry":[{},"APPENDIX IV.txt","24 Kbytes","created Sep. 19, 2002"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}}}},"A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the U.S. Patent and Trademark Office patent file or records, but otherwise reserves all copyright rights whatsoever.","1. Field of the Invention","The invention relates to user-machine interfaces, and more particularly, to software methods and techniques for implementing an agent-oriented architecture which is useful for user-machine interfaces.","2. Description of Related Art","Most human-machine interfaces in use today are relatively complicated and difficult to use. Frequently this is a consequence of the growing number of features to which the interface is expected to provide easy access.","Users usually have the following problems with current interfaces:\n\n","User interfaces that adapt their characteristics to those of the user are referred to as adaptive interfaces. These interactive software systems improve their ability to interact with a user based on partial experience with that user. The user's decisions offer a ready source of training data to support learning. Every time the interface suggests some choice, the human either accepts that recommendation or rejects it, whether this feedback is explicit or simply reflected in the user's behavior.","The following general features may be desirable in a user interface:\n\n","Various attempts have been made to reduce the navigation effort in menu hierarchies:\n\n","Most human-computer interfaces today are programmed in standard sequential or object-oriented software. Another software paradigm exists, however, which has not heretofore been used effectively for human-machine interfaces. Under this paradigm, which is known generally as an agent-based software architecture, a given task is divided up into several sub-tasks and assigned to different \u201cagents\u201d in the system. \u201cAgents\u201d are communicating concurrent modules, each of which handles a part of the decision-making process. If the agents are capable of learning, they are referred to as adaptive agents.","Some examples of situations in which agent-based interaction have been used are as follows:\n\n","One predominant approach to the use of Agents in user interaction has been to concentrate a large bulk of the interaction responsibilities in a single agent, thus reverting to a centralized architecture. Nevertheless many real world problems are best modeled using a set of cooperating intelligent systems. Our society, for example, consists of many interacting entities. If we are interested in modeling some aspects of our society, it would be desirable to structure our model in the same way. As another example, since data often originates at different physical locations, centralized solutions are often inapplicable or inconvenient. In addition, using a number of small simple adaptive agents instead of one large complicated one may simplify the process of solving a complicated problem. In other words, agents collectively exhibit emergent behavior, where the behavior of the agent population as a whole is greater than the sum of its parts.","The invention, roughly described, involves a computer-implemented method for processing a subject message, by a network of agents each of which has a view of its own domain of responsibility. An initiator agent which receives a user-input request and does not itself have a relevant interpretation policy, queries its downchain agents whether the queried agent considers such message, or part of such message, to be in its domain of responsibility. Each queried agent recursively determines whether it has an interpretation policy of its own that applies to the request, and if not, further queries its own further downchain neighboring agents. The further agents eventually respond to such further queries, thereby allowing the first-queried agents to respond to the initiator agent. The recursive invocation of this procedure ultimately determines a path, or a set of paths, through the network from the initiator agent to one or more leaf agents. The request is then transmitted down each given path, with each agent along the way taking any local action thereon and passing the message on to the next agent in the path. In the event of a contradiction, the network is often able to resolve many of such contradictions according to predetermined automatic algorithms. If it cannot resolve a contradiction automatically, it learns new interpretation policies necessary to interpret the subject message properly. Such learning preferably includes interaction with the user (but only to the extent necessary), and preferably localizes the learning as close to the correct leaf agent in the network as possible. Preferably, though, the learning takes place prior to the leaf agent itself.","The methods and techniques of the present invention can be implemented in software on almost any type of computer system, microcomputer or embedded processor. As an illustration,  is a simplified symbolic block diagram of one type of computer system on which software implementing the present invention can be operated. The system of  includes a CPU , which may be, for example, a Pentium\u00ae microprocessor available from Intel Corporation, Santa Clara, Calif. The CPU  is connected to a CPU bus , which is connected further to a core logic chip set  and a memory array . The core logic chip set  also connects to the memory array . The core logic chip set  is further connected both to an ISA bus  and a PCI bus . A standard video adapter  is connected to the PCI bus , and further drives a display monitor . A keyboard and a mouse  are connected via well-known means to the ISA bus . The ISA bus  is also connected to a standard sound card , which is connected further to a microphone  and a speaker  used for user voice interaction. The system of  further has a serial port  which is connected to the ISA bus , and which has an output  connected to a serial control input of a machine , which may, for example, be a home entertainment system. The system of  further includes a hard disk drive  which is connected to the ISA bus  as well. As it pertains to the present invention, the purpose of the system of  is to control the home entertainment system  in response to user interaction occurring via the display monitor , the keyboard and mouse , the microphone  and the speaker .","In operation, when the user interface is activated, software stored on the hard disk  is brought into memory , either entirely or as needed to perform the functions of the system.",{"@attributes":{"id":"p-0042","num":"0059"},"figref":["FIG. 2","FIG. 1"],"b":["210","130","212","210","212","212","132","213","132","212","138","124","126"]},{"@attributes":{"id":"p-0043","num":"0060"},"figref":"FIG. 3","b":["310","312","314","316","314","312","314","316","312","314","310","316"]},"The primary responsibility of the communications unit  is to facilitate communicative functions of the agent, including interpretation of messages and routing of messages to other agents. It comprises an input unit , which receives input messages from other agents. These messages may be in an extended form of a standard agent communication language, such as KQML. KQML is described in the above-incorporated KQML 1993 reference. The extensions are described below. As used herein, the term \u201cmessage\u201d includes, among other things, queries, commands, and responses to queries.","Input unit  performs some preliminary processing on the input message and passes it to an interpreter . The interpreter  decides whether the input message is within the domain of responsibility of the agent . As used herein, a message is considered to be within the domain of responsibility of a given agent if: (a) the message, or part of it, is within the given agent's local domain of responsibility (i.e., the special processing unit  of the agent  has itself been assigned the responsibility to take some action in response to the message, or in response to part of the message), and\/or (b) the message, or part of it, is within the given agent's downchain domain or responsibility (i.e., the agent  knows of one or more further agents to whom the message should be routed). Note that it is possible for an agent  to forward a message to more than one further agent, thus creating competition among agents.","The interpreter unit  refers to an interpretation policy unit  to determine whether the input message is within the domain of responsibility of the agent . The interpretation policy unit  can be, for example, a table containing various words or tokens in the message that the agent  is assigned to recognize. This table also indicates what the agent  should do in response to a message containing a token that the agent has recognized. Preferably, but not essentially, some predetermined set of policies is preprogrammed into the interpretation policy unit  for each agent by the designer of the system, in order to ensure that the system will be functional from the beginning. In addition, for agents which are adaptive, the interpretation policy unit also receives interpretation policies from the rewards unit  via a learning module . At the time of the system reset, the information in the interpretation policy unit  reverts back to the basic hard-coded start-up information. The interpretation policy stored in unit  therefore includes a preset knowledge base, as well as a learned knowledge base. In a system intended for use with different users, several learned knowledge bases are acquired on a per-user basis. The learning module  is responsible for contradiction resolution in knowledge base entries with regard to feedback received on the processing of previous requests. Previous requests, and their ultimate disposition within the agent , are also stored in a temporary request storage unit  in anticipation of their feedback.","The interpreter unit  further communicates with an address book , which maintains an address list of other agents known by the agent  to be useful, or known by the agent  to have a capability of processing certain input that cannot be processed by the agent . An agent  may pass messages to other agents when the agent  has received a message that it does not know how to handle (e.g., a query for which there is no entry in the interpretation policy unit ), or when the agent  has processed a message and one or more new messages have been generated as a result. In the embodiment described herein, every agent has an address, and there is a special name-server unit (not shown). The name-server unit provides agents with their unique addresses at run time, so that new agents can be introduced to the system at run time. The address list kept in the address book  should be dynamic, and therefore adaptive. It may be limited, in the sense that unwanted or intruding agents may be kept out. It may also contain information (such as performance or accuracy statistics) on agents that normally send their requests to the agent  (sometimes referred to herein as \u201cupstream agents\u201d). In may ways, the address book  can be thought of as an extension of the interpretation policy unit , and therefore in some embodiments, the two units are implemented as a single module.","The address book  communicates with a useful agents unit , which stores a knowledge base of useful agents in much the same way that the interpretation policy unit  stores the interpretation policies for the interpreter . In addition to entries preprogrammed by the system designer, the useful agents unit  also contains entries which have been learned and stored there by the learning unit  in response to feedback from the rewards unit  and entries which have been added due to receipt of a Register message from another agent.","The agent  also includes an output unit  which is responsible for sending requests or outputs to other agents using the address book . In one embodiment, the output unit  adds a confidence factor to certain of the messages that it outputs based on the interpretations that were made to resolve or redirect input messages. As set forth in more detail below, confidence factors can be used when the agent  has chosen from suggestions made by competing agents who have responded to queries from the agent .","The rewards unit  processes two kinds of feedback: incoming and outgoing. An agent  is responsible for distributing and propagating rewards that have been fed back to it. Such rewards might originate from, for example, a special purpose agent (not shown in ) which determines whether user input constitutes feedback regarding the acceptability or unacceptability of the system's response to a particular input message. When a reward reaches the agent , rewards unit  determines for itself what portion of the incoming reward it deserves and how much should be propagated on to other agents. The rewards unit  provides feedback to the learning unit  in response to such rewards, so that the interpreter  can update its interpretation policy. The rewards unit  also provides feedback in response to such rewards to the learning unit  to assist the address book  in adapting to the needs and specifications of other agents. In addition, in agents whose special processing unit  can benefit from feedback, the rewards unit  can provide feedback here as well.","The rewards propagated through the agent network might in some embodiments be direct quantifications of user states. In most embodiments, however, the rewards will constitute interpretations of user actions made by an agent which is responsible for such interpretations.","The special processing unit  is the portion of agent  that does the local work for which the agent  is responsible, other than routing. For some agents in a particular embodiment, particularly some agents that are located deep in the interior of the agent network, their role is mainly to direct requests to the appropriate agents and learn or resolve contradictions that may occur at their juncture. For these agents, the special processing unit  is extremely simple or omitted entirely. The special processing unit  is sometimes referred to herein as a \u201cblack box\u201d because the designer of the system can use whatever method he or she deems suitable to implement the local processes unique to the requirements of a given agent. The only constraint placed on the special processing unit  is that it is preferably limited to the facilities provided by the communications unit  for its communications with other agents.","The special processing unit  is used primarily by agents which interact outside of the agent network. Agents responsible for user I\/O are examples of such agents. These agents generally generate requests or initiate reward propagation in the agent network, or simply output results.","Another example of a special processing unit  is an existing conventional non-agent-oriented program which has been \u201cagentified\u201d. Programs can be \u201cagentified\u201d by adding a communications unit such as  (and optionally a rewards unit such as ) as a transducer to mediate between the existing program and other agents. Transducers are described in, for example, the above-incorporated Software Agents paper, by Genesereth, et al. One advantage of using a transducer to \u201cagentify\u201d an existing program is that the transducer requires no knowledge of the preexisting program other than its communication behavior. Other approaches to agentification (wrapper and rewriting) are discussed in the above-incorporated Software Agents paper, by Genesereth, et al.","The agent-oriented interpretation unit  () includes a number of agents similar to that of , each having a domain of responsibility. In one embodiment, the agents are organized as a hierarchy. The top-level agent acts as an input agent, receiving messages from the speech-to-text converter . The messages propagate down the hierarchy to the (hopefully) proper leaf agent, with each agent along the way performing an adaptive routing function.","In another embodiment, the agents in the agent-oriented interpretation unit  are interconnected in a way that does not meet the strict definition of a hierarchy. That is, for example, in some cases more than one intermediate agent can transmit a message to a single leaf agent. As another example, agents further down in the structure can transmit requests back up to other agents that are higher up (closer to the input agent). In some embodiments, the arrangement of agents might, for example, satisfy the definition of a hyperstructure, as described in the above-incorporated Self-Organizing Symbiotic Agent paper. In general, the arrangement of agents in the agent-oriented interpretation unit  can be described as a network. It will be appreciated that hyperstructures and hierarchies are special cases of a network. Furthermore, a simple chain of agents is a special case of a hierarchy and a single agent is a special case of a chain of agents. All these forms and others are considered herein to be kinds of networks.","The different agents in the network are \u201cinterconnected\u201d with each other in the sense that agents receive queries and commands only from a predetermined subset of other agents (referred to herein as \u201cupchain\u201d agents) in the network, and agents transmit queries and commands only to another subset of agents (referred to herein as \u201cdownchain\u201d agents) in the network. Both subsets are adaptable in the sense that new agents coming online can ask to be added to the list of downchain agents for their prospective upchain neighbors, (via an ADVERTISE performative, for example), and agents already in a subset can ask to be removed (via an UNADVERTISE performative, for example). Because the agent network topology is not restricted in any way, one agent can be both upchain and downchain of another agent.","If desired in a particular embodiment, the agents in an agent network can be grouped into agent communities. A \u201ccommunity\u201d contains one or more agents, all having the same domain of responsibility. In a degenerate case, an agent by itself also constitutes a community of only the one agent. Various embodiments can employ different conventions for communicating between communities of agents. For example, in one embodiment, a query is performed only of an entire community of agents, not of any single agent within the community. Responses may come from the individual agents in the community or, in an embodiment, only from the community as a whole. Thus, as used herein, an agent which is part of a community of agents can be queried, in an appropriate embodiment, by querying the community of which it is part. That is, the querying of a group of agents is considered herein to include the querying of one or more agents within the group. Note that other types of agent groupings are possible in a given embodiment, other than communities. Note also that in a given embodiment, not all agents having the same domain of responsibility need to be within the same community.","When designing a network such as that in the interpretation unit , the software as a whole can be thought of as a society, striving to satisfy a set of requests. The input requests are therefore propagated, processed by agent modules that may in turn create requests to other agents. Preferably the designers of the system will devise an initial breakdown of the overall responsibilities of the network, to break down the system as they feel suitable. Hierarchies of agents are possible and agents can be assigned to be responsible for the minutest processes in the system. It is advisable (but not essential) that each agent be kept simple in its responsibilities and be limited in the decisions it needs to make to enhance its learning abilities. Too great a proliferation of simple agents is not always advisable either, however, as the overhead of the white box should be taken into consideration.","In some embodiments, agents can be replaced at run-time with other more complete agents. The replacement can even be a hierarchy or network of new agents (sub-agents) breaking down the responsibilities of their predecessor. This feature provides for the incremental design and evaluation of software.","It is desirable that each agent's responsibilities and actions be clearly defined at design time. As mentioned above, it is also desirable that many aspects of the white box units be preset for each agent according to its definition. To have a working system from the beginning, the designers should pre-define the preliminary communication links between the agents at design time. It should be noted that these communications might change through time, for instance in the case of the introduction of newer agents. Thus, one important phase in the design of software with this methodology will be to determine the participating agents and their capabilities; even though the precise details of how they will eventually communicate with each other may not be known at design time.","In a typical agent network, many agents have a common structure and follow similar internal routines. However, some special purpose agents may be used depending on the application, for example, agents directly involved with initiating requests to the system, or an agent which interprets the actions of the user as different levels of reward. Some of these special-purpose type agents will now be described.","Input Agents. Inputs to the system may be from more than one source. In such systems, one or a network of special purpose input agents might be included, which unify inputs from different sources into one request, and\/or determine commands that all fall into a single request set. For example, if the user's natural language (\u201cNL\u201d) input is: \u201cInformation on this\u201d and the mouse is then pointed at an item on the display, an input agent might perform the function of unifying these two inputs as a single request.","Interactive input could benefit also from the use of input agents to determine the end of an input stream. For instance in NL input a phrase (e.g., Do! or Please!), or a relatively long pause, could determine the end of the stream. A different policy here would be to interpret the input in real-time and redirect it to the appropriate agent.","Feedback Agents. Any adaptive system needs a reward feedback that tells it how far from the optimum its responses have been. This reward could be explicitly input to the system, or implicitly judged by the system itself from input responses. In an embodiment with implicit rewarding, a feedback agent could be responsible for the interpretation of the input behavior and translating it into rewards. The criteria to use depends on the system. For instance in an interactive software application, a repeat of a command, remarks indicating satisfaction or dissatisfaction, user pause between requests or other such input could be translated into rewards to different output.","Some embodiments have more than one feedback agent depending on different judgment criteria, and a hyper-structure or hierarchy might be designed to create the rewards.","In addition to normal agents and special purpose agents, the interpretation unit  also includes a name server unit to make possible the dynamic introduction of new agents to the system. Each new agent obtains its name (or address) from this name server so that conflicts do not occur and so agents can be referred to throughout the system. Input requests or commands to the system are tagged with a request-id (and further with the user-id of the user that has issued them, because interpretation is done on a per-user basis), and rewards fed back to the system incorporate the request-id to which the reward belongs.",{"@attributes":{"id":"p-0068","num":"0085"},"figref":["FIG. 4","FIG. 2","FIG. 4","FIG. 4","FIG. 4","FIG. 4"],"b":"212"},"In , input from the speech-to-text converter  is received by a Text Input agent , whereas input from the mouse  is received by a Mouse agent . The agents  and  are special-purpose agents, and each performs the function of receiving non-agent I\/O, converting it to agent format and providing it to an Input Regulator agent . The Text Input agent  also performs the function of determining when a request or command from the user is complete enough for the interpretation unit  to attempt an interpretation. The Text Input agent  is an \u201coriginator\u201d of certain commands propagating through the network of . It originates such messages in response to the input that it receives from the speech-to-text converter . The Text Input and Mouse agents  and  also can omit many of the more sophisticated communication functions of the basic agent, since they do not need to receive input from other agents, they do not need to learn, and they are preprogrammed to transmit all incoming messages to a single destination agent. Thus, for example, the Text Input and Mouse agents  and  can omit the input unit , the rewards unit , and all of the learning capability of the agent as shown in . Alternatively, generalized, full-featured agents can be used, although certain functions of the agents will never be utilized and certain other functions would be added. The non-agent I\/O for the Text Input and Mouse agents  and  is performed by the specialized processing unit  () of the respective agent.","(As used herein, a given message, signal or event is \u201cresponsive\u201d to a predecessor message, signal or event if the predecessor signal or event influenced the given signal or event. If there is an intervening processing element or time period, the given message, event or signal can still be \u201cresponsive\u201d to the predecessor signal or event. If the intervening processing element combines more than one message, signal or event, the output of the processing element is considered \u201cresponsive\u201d to each of the message, signal or event inputs. If the given message, signal or event is the same as the predecessor message, signal or event, this is merely a degenerate case in which the given message, signal or event is still considered to be \u201cresponsive\u201d to the predecessor message, signal or event.)","The Input Regulator  is a special-purpose agent which performs the functions of unifying the inputs from the Text Input agent  and the Mouse agent . It is upchain of a TV agent , a VCR agent  and a Feedback agent . The Input Regulator may also be upchain of other agents or agent communities (not shown) which are responsible for other portions of the home entertainment system . When the Input Regulator agent  formulates a query, it transmits the query to all of its downchain neighbors , ,  and .",{"@attributes":{"id":"p-0072","num":"0089"},"figref":"FIG. 4","b":["416","418","420","414","410","138","416","418","418","420","410"]},"Feedback agent  is a special-purpose agent which determines whether the input message carries an implicit or explicit judgement from the user about the acceptability or unacceptability of the system's response to a previous user request. As with Query or Command agent , Feedback agent  is shown with broken lines because it is only optional to break this function out into a separate agent. In the present embodiment, the feedback detection function, which takes the form of user dissatisfaction detection, is included in the Text Input agent  itself.","In one embodiment which does have a separate Feedback agent , this agent never responds to a query from the Input Regulator , or if it does, it responds with an extremely low priority such that it will never be selected. Instead, once the Feedback agent  believes it has received feedback from the user, it transmits a REWARD command to the Input Regulator  for propagation throughout the rest of the network. REWARD commands issued by the Feedback agent  carry a \u201cTHIS-IS-YOURS\u201d performative, or alternatively carry performatives specific to reward propagation.","The VCR agent  is upchain of a number of other agents, only two of which ( and ) are shown in . The VCR subnetwork is shown in  only for illustration purposes to emphasize that the decision-making responsibility of Input Regulator  includes routing of a message to one of several subnetworks responsible for different components in the home entertainment system . The VCR subnetwork need not be further described herein.","The TV agent  is upchain of a Power agent , a Sound agent , a Viewport agent , and a Channel agent . The Viewport agent  in turn is upchain of a Magnification agent  and a Shifting agent . Shifting agent  is upchain of a Right agent  and a Left agent . The Power, Sound, Magnification, Right, Left and Channel agents , , , ,  and , respectively, are all upchain of a special purpose TV Actuator agent , whose special processing unit  () functions to unify all of the commands from all of its upchain neighbors and to provide them, through the non-agent I\/O port () to the home entertainment system  via a single serial port  (). The Power, Sound, Magnification, Right, Left and Channel agents , , , ,  and , respectively, also store, in their Special Processing Units , the current value of the various settings of the home entertainment system  for which they are responsible. For example, Sound agent  includes a register for storing the current volume setting so that it can properly answer a user query about the current volume setting. TV Actuator  is a highly degenerate agent, omitting many of the functions shown in . For example, the following could be omitted: learning unit , interpretation policy unit , useful agents unit , temporary request storage unit , learning unit  and rewards unit . A different embodiment might retain some or all of these elements, and simply never use them. Alternatively, the TV Actuator  can be thought of (and programmed as) a non-agent process.","The various agents in the agent-oriented interpretation unit  receive and reply to messages using a conventional declarative knowledge representation language known as KIF (Knowledge Interchange Format), a conventional communication language KQML (Knowledge Query and Manipulation Language) and a library of formal ontologies defining the vocabulary of various domains. KQML is described in the KQML 1993 reference incorporated above. KQML is a standard language for programs to use to communicate attitudes about information, such as querying, stating, believing, requiring, achieving, subscribing, and offering. KQML messages (also called \u201cperformatives\u201d) include a number of fields, including a message-content field and a field indicating what the recipient is supposed to do with the information in the message-content field. The present embodiment extends KQML by adding a number of new performatives as follows. These performatives are all general and therefore pre-implemented in the white box modules of these agents.","Register","Agents need to register themselves with each other to be able, to send messages to one another. Unlike other agent-based systems, in the present embodiment, all agents need not be aware of all other agents and registration may be much more distributed and localized. In particular, each agent need only register with its upchain and downchain neighbors. Each agent, upon receiving a REGISTER message, adds the registering agent's name and address to its address book. Registration may take place at run time. The REGISTER performative is itself conventional.","Advertise and Unadvertise","Agents advertise their domains of responsibility in order to draw requests from other agents. When an agent receives an ADVERTISE message it updates its interpretation policy so as to redirect certain requests to the advertising agent. This information is removed from the interpretation policy once an UNADVERTISE message is received. An ADVERTISE message indicates a community to which the advertising agent belongs. For example, an ADVERTISE message from Viewport agent  to TV agent  might say, \u201cI want to receive all input messages containing the words Viewport, Magnify, Shift, Left, or Right.\u201d If the agent receiving this message already knows of another agent that wants to receive all of the same messages, then it will add the newly advertising agent to the community already containing the prior agent. If the recipient agent does not recognize such a community in its current interpretation policy, it may add it as a new community. This allows for more than one agent to be members of an interpretation community of another agent. The ADVERTISE or UNADVERTISE performatives themselves are conventional.","This-is-Yours","When an agent is successful in interpreting a message (i.e., the agent has made a routing determination for the message), the message must be forwarded to an agent in the interpreted community. The performative under which this message is forwarded is called THIS-IS-YOURS. The receiving agent knows that if it cannot interpret this message, then the point of contradiction is itself. For example, assume the Input Regulator agent  receives \u201cTV to the right\u201d from the text-input agent , and Input Regulator agent  has an interpretation policy that all messages containing the word \u201cTV\u201d should be routed to TV community . Then Input Regulator agent  will forward the message to an agent in that community. In the present example, we only have one agent per community so a THIS-IS-YOURS performative with the input message as its content will be sent to the TV agent .","Is-this-Yours?, It-is-Mine, Not-Mine and Maybe-Mine","As previously mentioned, the interpretation of input is distributed over the network of agents so there may well be situations in which an agent cannot directly interpret a message and will have to query the communities it knows and wait for their response. If an agent cannot itself interpret a received message (i.e., has no interpretation policy that applies to the message), then it queries each of its downchain communities using an IS-THIS-YOURS performative. If an agent receiving such a performative has an interpretation policy for the message, the agent responds with an IT-IS-MINE performative. An agent will have an interpretation policy for a message if the message (or part of it) is within its own local domain of responsibility or the agent knows that the message (or part of it) is within the domain of responsibility of one of the agent's downchain neighbors. In this sense the term \u201cdomain of responsibility\u201d is defined recursively.","If the agent receiving the IS-THIS-YOURS performative does not have an interpretation policy for the message, and none of its own downchain neighbors (if any) have such a policy, then the agent responds with a NOT-MINE performative. If the agent receiving the IS-THIS-YOURS performative has more than one further downchain agent claiming the message in a contradictory manner, then the agent responds with a MAYBE-MINE performative.","Commit and Dissatisfied","These performatives are used to force the system to resolve contradictions experienced by the system. In adaptive embodiments, contradiction plays an important role in learning. Pinpointing the agent which is responsible for a contradiction and resolving it there ensures a correct distribution of responsibilities in the agent network. In the present embodiment, contradictions occur in the following cases:\n\n","The first two of these cases can implicate the COMMIT performative, whereas the third case implicates the DISSATISFIED performative.","As previously mentioned, one of the functions of the Text Input agent  in  is to determine when it has received enough of an input message from the user in order for the system to try interpreting it. For example, the Text Input agent  might be programmed to send the input message as it then stands down to the Input Regulator agent  with a THIS-IS-YOURS performative after every word spoken by the user until the interpretation is successful. Normally, if an input message results in either of contradiction situations (1) or (2) above, then the message simply dissipates after the Input Regulator  receives its replies back from all of its downchain neighbors. No action is taken by the system, which simply awaits more input. The next message transmitted down by the Text Input agent  is longer with the addition of the user's next word, which hopefully will enable an interpretation. At some point, however, the user might imply or express a desire for the system to respond to the input thus far. In this case Text Input agent  sends the input message as it then stands down to the Input Regulator agent  with a COMMIT performative. Note that in one embodiment, the COMMIT performative is implemented as a THIS-IS-YOURS performative with a COMMIT flag set.","If the pending contradiction is at the Input Regulator  when the COMMIT performative is issued, then the Input Regulator  proceeds to resolve the contradiction. Any predefined contradiction resolution procedure can be programmed into the system. It is most desirable, however, if it includes a step of querying the user directly, preferably as a last resort. For example, if the Input Regulator  has a contradiction because all of its downchain neighbors have returned NOT-MINE, then the Input Regulator  can ask the user whether the input message refers to a TV or a VCR function. The Input Regulator  then adjusts its interpretation policy  in accordance with the user's response. By involving the user in this way, both the interaction and the learning is limited to the point of contradiction. Unnecessary interaction is thereby reduced, and a correct distribution of learning across the agent network is ensured.","After the Input Regulator  resolves its contradiction, it sends the message on down to its resolved downchain neighbor with a COMMIT performative. If the Input Regulator  was not the point of contradiction (that is, that the Input Regulator  already had an interpretation of the input message), then in this case too, the Input Regulator  sends the input message to the interpreted downchain neighbor with a COMMIT performative. The COMMIT performative propagates down a chain of agents in the network, forcing each agent in the chain which has a contradiction, to resolve its contradiction and pass the COMMIT performative on to the next agent in the chain. The overall contradiction resolution process may well involve several user interactions in which the system asks the user for a decision.","The actual contradiction resolution procedure used in the Input Regulator agent  is described in more detail below with respect to . All other agents in the network of  use the same contradiction resolution procedure, although in a different embodiment, different agents can use different contradiction resolution procedures. Since more than one agent in the network needs to be able to query the user, all of the agents route such queries through a common I\/O Actuator  which controls the I\/O port through which such user interaction occurs. In one embodiment, this user interaction takes place via the keyboard  and display . In another embodiment, it takes place via the speaker  and microphone . In yet another embodiment, it takes place via components of the home entertainment system .","The DISSATISFIED performative is used not when the system determines for itself that a contradiction has occurred (contradiction cases (1) and (2) above), but when an outside authority, such as the user, informs the system that a contradiction has occurred (contradiction case (3) above). In this case, the system does not have a pending contradiction internally, but rather, has already taken some action in response to the user's prior input. (For this reason the agent sensing user dissatisfaction typically precedes the DISSATISFIED performative with a RESTORE performative in order to undo the most recent action taken.) Since the system does not know where the contradiction point is in the agent network, it queries the user at each step in the chain until a leaf agent is reached. For example, if the Input Regulator  (or the Feedlock agent , in an appropriate embodiment) recognizes user dissatisfaction in an input message, for example by the presence of the exclamation, \u201cWrong!\u201d, then it asks the user a question such as \u201cDo you mean TV or VCR?\u201d If the user responds \u201cTV\u201d, then the Input Regulator  learns that messages having characteristics of the input message that resulted in the user dissatisfaction, belong to TV agent  and not VCR agent . Input Regulator  then passes the erroneously interpreted message on down to TV agent , with a DISSATISFIED performative. TV agent  then queries the user, \u201cDo you mean power, sound, viewport or channel?\u201d When the user responds, the TV agent  learns the new interpretation policy as did Input Regulator , and passes the erroneously interpreted message on further to the designated downchain neighbor with the DISSATISFIED performative. This process continues until the correct leaf agent is reached and the desired action is taken.","The user interaction which the various agents perform in response to the DISSATISFIED performative can take place via the same I\/O Actuator  as is used for contradiction resolution in response to the COMMIT performative.","Unlearn","When the user resolves a contradiction by interacting with the agent at a contradiction point, that agent learns this contradiction resolution as a new interpretation policy. For example, the Input Regulator agent  might learn that input messages containing certain words should be routed to the TV agent . As a rule, each agent that learns a new interpretation policy should ask all agents it knows to \u201cunlearn\u201d that policy. An UNLEARN performative translates to: \u201cIf you are interpreting this message, and the interpretation is that this message belongs to me, then un-learn this interpretation policy.\u201d Not all embodiments need to implement the UNLEARN performative, but those that do will be better able to localize these learned policies in the agents which are most appropriate for each policy. Such localization of learning helps to keep interpretation policy databases small, thereby increasing the speed with which such databases are searched by each agent and the responsiveness and performance of the overall system.","Learn","The LEARN performative, which is conventional but included here for completeness, is used by agents teaching each other agents global abstractions such as \u201cmore\u201d and \u201ctoo\u201d.","Forget-Problem","Normally, when an agent receives an IS-THIS-YOURS? query, and either passes it on to its downchain agents or replies to the upchain source of the query, the agent remembers that it has already handled this message. As previously mentioned, the agent stores such problems in temporary request storage unit  (), together with the problem-I.D. In this way, when the agent receives a subsequent THIS-IS-YOURS message, for example, the agent does not need to refigure its interpretation or propagate the message on to downchain neighbors which have already rejected ownership of the message.","Problem storage differs from learned interpretation policies in that stored problems, and any stored resolution of such problems, do not influence the interpretation of any new message spoken by the user, even if the text of the new message is identical to the text of the stored problem. Rather, all reference to stored problems occurs by problem-I.D. FORGET-PROBLEM differs from LEARN\/UNLEARN also in that whereas LEARN\/UNLEARN takes place in response to the resolution of contradictions, problem storage occurs regardless of the resolution of, or even the presence of, contradictions. Still further, problems are stored in the temporary request storage unit  only temporarily.","In the present embodiment, agents delete locally stored problems only upon receipt of a FORGET-PROBLEM performative referencing the problem I.D. to be deleted, and Text-Input agent  originates a FORGET-PROBLEM performative referencing the most recent problem-I.D. whenever it is about to originate a new problem. This policy is believed to be the best policy for managing the size of each agent's temporary request storage unit  database. In another embodiment a different policy can be used, such as by deleting stored problems whenever the agent receives a THIS-IS-YOURS, COMMIT or DISSATISFIED performative identifying the same problem-I.D.","In some situations, the user will ask the system to abort processing of a particular request. For example, after starting to state a request, the user might stop and say, \u201cScratch that\u201d or \u201cNevermind\u201d. If the Text Input agent  (or some other agent charged with this responsibility) recognizes such a desire then it immediately deletes the temporarily stored problem from its temporary request storage unit  and then forwards the problem-I.D. to its downchain neighbors with a FORGET-PROBLEM performative. Each of the downchain neighbors deletes the identified problem from its own temporary request storage unit , if it was there, and forwards the problem-I.D. on to its own downchain neighbors with a FORGET-PROBLEM performative, and so on. In one embodiment, an agent does not pass the FORGET-PROBLEM message on to its downchain neighbors if the problem-I.D. was not present in its own temporary request storage unit . In another embodiment, an agent which did have the problem-I.D. in its temporary request storage unit , passes the message on to only those of its downchain neighbors which it knows have previously received the problem designated by the problem-I.D.","The agent-oriented interpretation unit  () is implemented in one embodiment using an object-oriented programming language such as Java. A main object class is defined that includes methods and data structures that are common to the great majority of agents in the network. Certain of the special-purpose agents, such as Feedback agent , Query Or Command agent , Text Input agent  and the various actuators in the network, are objects that have been subclassed from the main object class in order to allow certain methods of the main object class to be replaced, and others added, so that the agent can perform the specific functions of its special purpose. In an embodiment, all of the agents in the network represent objects in separate subclasses, because despite their great similarities, they all differ from each other slightly. For example, each is programmed separately to send REGISTER and ADVERTISE messages to different neighboring agents, depending on their location in the network as pre-determined by the system designer. As another example, each agent is pre-programmed with its own default set of interpretation policies. As yet another example, each agent is programed separately with its own \u201cblack box\u201d procedures, if any. In this sense all agents in the network might be considered special purpose agents. Other object-oriented and non-object-oriented implementations for the agent network will also be apparent to the reader.",{"@attributes":{"id":"p-0098","num":"0118"},"figref":"FIG. 5"},"Referring to , in a step , the agent first performs any initialization required. In embodiments in which the agent name is not hard-coded, this step can include contacting a name server to obtain a name for this agent.","In step , the agent then sets any of its start-up defaults. In step , the agent registers itself with all of the other agents which are to be its upchain and downchain neighbors. This is accomplished by transmitting a REGISTER performative to each of such neighbors, with the agent's name as the message content.","In a step , the agent advertises its abilities to other agents from which this agent wants to receive requests. This is accomplished by, for example, sending a message to all of the agent's prospective upchain neighbors with an ADVERTISE performative, and a preprogramed list of words or tokens. If the upchain neighbor later receives an input message containing any of the words or tokens identified by the advertising agent, it will include the advertising agent as one of those to which the message will be routed.","After step , the agent enters an event loop which periodically checks for new events directed to the agent. In a step , the agent first determines whether it is still alive. If not, then in step , the agent terminates its operations. If the agent is still alive, then in a step , the agent performs any agent-specific communication functions. In the main object class for the agents in the agent network, there are no agent-specific communication functions and therefore step  performs no functions. As will be seen below, certain special purpose agents which do need to perform special communication functions, do so in a procedure which substitutes for this step . In a step , the agent then determines whether it has received any incoming messages. If not, then the agent goes back to sleep and returns to step . If it has received incoming messages, then it proceeds to a PROCESS MESSAGE step  further described hereinafter. After the message is processed, then the agent again goes to sleep and control again is returned to step .",{"@attributes":{"id":"p-0103","num":"0123"},"figref":["FIG. 6","FIG. 5","FIG. 6"],"b":["524","610"],"ul":{"@attributes":{"id":"ul0011","list-style":"none"},"li":["ADVERTISE ","UNADVERTISE ","IS-THIS-YOURS? ","IT-IS-MINE ","NOT-MINE ","THIS-IS-YOURS ","COMMIT ","DISSATISFIED ","MAYBE-MINE ","UNLEARN ","FORGET-PROBLEM ","AGENT-SPECIFIC PERFORMATIVE ","USER-RESPONSE ","RESTORE "]}},"An agent may also be able to handle other performatives, but these are omitted from  for purposes of clarity. After a method specific to the performative of the received message is executed, the PROCESS MESSAGE step  terminates (step ).",{"@attributes":{"id":"p-0105","num":"0139"},"figref":"FIG. 7","b":["700","710","712","712","714","328"]},{"@attributes":{"id":"p-0106","num":"0140"},"figref":"FIG. 8","b":["810","328","812","816","328"]},{"@attributes":{"id":"p-0107","num":"0141"},"figref":"FIG. 9","b":["900","326","910","920","922","924","924","926"]},"If in step , it is determined that the interpretation performed in step  was unsuccessful (that is, the agent does not claim the input message for itself and also does not have an interpretation policy for the message), then in step , the agent checks its address book  to determine whether it has any downchain communities. If not, then it returns NOT-MINE to its upchain neighbor (step ). If the agent does have downchain neighbors, then in step , the agent stores the problem in its temporary request storage unit . It then queries all of its downchain agents with the same IS-THIS-YOURS? performative (step ). The method then terminates (step ).","Returning to step , if the message subject of the IS-THIS-YOURS? performative has previously been interpreted by this agent, as indicated in the agent's temporary request storage unit , then in step , the agent retrieves the interpretation from the temporary request storage unit . The temporary request storage unit  stores not only the problems that have been seen by this agent, but also the responses that have been returned by all of the agent's downchain neighbors. In step , the agent executes a PROCESS ANSWERS step as described below with respect to . The procedure then ends (step ).",{"@attributes":{"id":"p-0110","num":"0144"},"figref":"FIG. 10","b":["1022","326","1024","1026"]},{"@attributes":{"id":"p-0111","num":"0145"},"figref":["FIG. 11","FIGS. 9"],"b":["1100","934","1024","1244","1316","10","12","13"]},"Referring to , in step , the PROCESS ANSWERS routine begins by switching on the performative which caused the agent to enter this routine (referred to herein as the entry performative). If the performative was IT-IS-MINE, MAYBE-MINE, or NOT-MINE, then in step , the quality criteria established for the present agent is applied to the response. In the present embodiment, no action at all is taken in step . In another embodiment, step  rejects certain IT-IS-MINE and MAYBE-MINE responses which have a very low quality level, essentially by replacing them with NOT-MINE performatives.","In step , the agent determines whether the new response creates a contradiction with any previously received response. Note that even if two downchain agents both claim a message with an IT-IS-MINE performative, there still may be no contradiction if, for example, each claims a different part of the message. For example, if the input message is \u201cTV and VCR On,\u201d then no contradiction is created in the Input Regulator agent  when both TV agent and VCR agent claim the message. Both need to receive it ultimately.","In order to accommodate multiple non-contradictory claimants of a message, the concept of \u201cfocus\u201d is introduced. Each agent which claims ownership of a message, returns, with its IT-IS-MINE or MAYBE-MINE performative, an indication of which part or parts of the message caused the agent to claim the message. The indication of a particular part or parts of a message which caused an agent to claim the message, is referred to as the \u201cfocus\u201d of the claim. The focus of the claim can be either a contiguous or discontiguous part of the message. If the message was actually claimed by two or more further downchain agents, then the agent preparing the IT-IS-MINE or MAYBE-MINE response specifies a focus given by the union of the parts of the message claimed by the further downchain agents.","Step  utilizes focus, as well as other techniques described below with respect to , to attempt to resolve any new contradictions.","In step , the agent increments a variable referred to herein as TheyKnowCount if the newly received response is, and after steps  and  remains, a THIS-IS-MINE performative. The agent also increments variable TheyMayKnowCount if the newly received response is (still) a MAYBE-MINE performative. Then, in step , it is determined whether all queried communities have answered. If one or more communities have not yet answered, then the PROCESS ANSWERS routine ends (step ) to await further responses. In the present embodiment, an agent considers the first response that it receives from an agent in a given community to constitute the community's response. Subsequent responses from agents within that community, if any, are ignored. In a different embodiment, or embodiment, or in different agents within the same embodiment, different policies may be employed for determining whether a sufficient response has been received from a downchain agent or community.","If in step  all queried communities have now answered, or if the performative which caused the agent to enter the PROCESS ANSWERS routine was a COMMIT performative, then flow continues at step .","In step , if TheyKnowCount equals zero, then in step , it is determined whether TheyMayKnowCount also equals zero. If so then, in step , if the performative which caused the agent to enter the PROCESS ANSWERS routine was not a COMMIT performative (i.e. it was a response to an IS-THIS-YOURS query or a response to a THIS-IS-YOURS performative), then in step , the agent sends a NOT-MINE performative to the upchain neighbor which sent the problem. The routine then ends (step ). If in step  the performative which caused the agent to enter the PROCESS ANSWERS routine was a COMMIT performative, then the agent has a situation in which it is required to determine which of its downchain neighbors, all of whom have rejected the current message, is to nevertheless receive the message. Accordingly, in step , the agent asks the user to resolve the contradiction. The routine then terminates (step ), the user's response entering through the USER RESPONSE performative handled in step  ().","If TheyKnowCount equals zero (step ) but TheyMayKnowCount not equals zero (step ), then in step , it is determined whether the entry performative was a COMMIT performative. If so, then in step , the agent again asks the user to resolve the contradiction arising from more than one MAYBE-MINE query response. The routine then ends (step ). If in step  the entry performative was not a COMMIT performative, then in step , the agent returns MAYBE-MINE to its upstream querying agent. The routine then ends (step ).","If in step  it is determined that TheyKnowCount does not equal zero, then in step  it is determined whether TheyKnowCount equals 1. If so, then there is no contradiction because exactly one downchain neighbor has claimed the subject message unconditionally. If the subject message carried an IS-THIS-YOURS performative (step ), then in step , the agent returns IT-IS-MINE to its upchain querying agent. The routine then ends (step ). If in step  the message carried something other than an IS-THIS-YOURS performative, for example a THIS-IS-YOURS performative, then in step , the agent passes the message on to all of its downchain neighbors who have claimed it. The routine then ends (step ). If in step , more than one downchain agent has claimed the subject message with an IT-IS-MINE performative, but the focuses of the claims do not overlap, then there is no contradiction. The agent either sends an IT-IS-MINE performative to an upchain querying agent (step ), or sends the stored performative to all claiming downchain agents (step ) just as if exactly one downchain agent had claimed the message with an IT-IS-MINE performative.","If more than one downchain agent has claimed the message with a sufficient level of quality to satisfy the present agent (TheyKnowCount greater than one), and the focuses of the claims overlap (step ), then a contradiction is indicated. Control transfers to step , described above. If the entry performative was a COMMIT performative, then again the system asks the user (step ) to resolve the contradiction and the routine ends (step ). If the entry performative was not a COMMIT performative, then again, instead of resolving the contradiction at this time, the agent simply returns a MAYBE-MINE performative to the upchain sender of the IS-THIS-YOURS message (step ). The routine then ends (step ). The agent does not try to resolve the contradiction at this stage because, for example, this agent might not be in any of the final message paths as ultimately determined.",{"@attributes":{"id":"p-0122","num":"0156"},"figref":"FIG. 12","b":["1222","316","1224"]},"In all cases after the agent-specific steps  or  are taken, the white box routing steps shown in the remainder of  take place. In particular, in step , the agent first determines whether the input message has previously been interpreted by this agent. This involves checking the temporary request storage unit . If not, then in step , the agent determines whether it has any further downchain communities. If not, then the procedure of  ends (step ). The agent has done its own work and has no further downchain agents who might have their own work to perform in response to the input message. If in step  it is determined that the agent does have downchain communities, then in step , the agent attempts to interpret the message. As with step  (), this involves checking the interpretation policy unit  to determine whether the input message fits the criteria of any preprogrammed or learned interpretation policy. Unlike step , however, there is no need for step  to recognize interpretation policies calling for the current agent to perform local work. In step , if the interpretation was successful (i.e., the agent knows of a subset (proper or improper) of its downchain agents which are interested in receiving the message), then in step , the agent sends the message performative (RESTORE, THIS-IS-YOURS or COMMIT) to all of the relevant communities identified in the interpretation policy. The procedure of  then ends (step ). Each of the agents receiving performatives in accordance with step  typically will handle it in accordance with this same  procedure.","If in step  the agent does not have an interpretation policy for this message, then the agent stores the problem in its temporary request storage unit  (step ) and queries all of its downchain agents with an IS-THIS-YOURS? performative (step ). The procedure of  then ends (step ). Any responses will come through the procedures of ,  and .","Returning to step , if the agent determines that it has previously interpreted the message subject of the RESTORE, THIS-IS-YOURS? or COMMIT performative, then in step , the agent retrieves all of the answers that it has stored in its temporary request storage unit  in conjunction with this problem. In step , the agent executes the PROCESS ANSWERS routine described above with respect to . The procedure of  then ends (step ).",{"@attributes":{"id":"p-0126","num":"0160"},"figref":["FIG. 13","FIG. 4","FIG. 11","FIG. 13","FIG. 14"],"b":["446","1130","446","326","1310","326","1312","1314"]},"In step , the agent then interprets the problem again and attempts to respond to the original message (as stored in the temporary request storage unit ). This is accomplished by providing the problem ID again to the PROCESS MESSAGES routine of . The procedure then ends (step ).",{"@attributes":{"id":"p-0128","num":"0162"},"figref":["FIG. 14","FIG. 13"],"b":["1312","1410","322","1412"]},{"@attributes":{"id":"p-0129","num":"0163"},"figref":["FIG. 15","FIG. 13"],"b":["1314","1510","322","1512"]},{"@attributes":{"id":"p-0130","num":"0164"},"figref":["FIG. 16","FIG. 13"],"b":["1608","1610","1612","322","1613","1314","1614","1616"]},{"@attributes":{"id":"p-0131","num":"0165"},"figref":"FIG. 17","b":["1710","326","1712"]},{"@attributes":{"id":"p-0132","num":"0166"},"figref":["FIG. 18","FIG. 18"],"b":["326","316","1810","316","1812"]},"As previously mentioned, the agent network of  includes certain agents which are instantiations of objects in special object classes which extend the main object class. Indeed in one embodiment, all agents in the network are instantiations of objects in special object classes which extend the main object class. One of such agents, in particular the Text Input agent  (), will now be described. This agent differs from other agents in the network not only in its list of neighboring agents, but also in the functions that it performs in the agent-specific communication functions step  of .  is a flowchart of the agent-specific communication functions  performed by Text Input agent .","It will be recalled that the agent-specific communication functions take place within the event loop of . Whenever the Text Input agent  awakens, in step , it first determines whether there has been a user voice-entry timeout. In particular, the agent determines whether a predetermined pause period has expired, without any further changes or input from the user. If so, then in step , the Text Input agent  sends the input message, as it currently stands, to all of its downchain neighbors with a THIS-IS-YOURS performative. The step  then ends (step ). It will be appreciated that the Input Regulator agent , which is the only agent downchain of Text Input agent , will respond to this message by attempting an interpretation, and querying its own downchain agents, all as described above.","Returning to , if a user voice-entry timeout has not yet occurred, but the user has otherwise indicated (for example, by pressing the enter key on a keyboard) that he or she wishes to commit the message as it currently stands (step ), then in step , the Text Input agent  sends the message as it currently stands to all of its downchain agents with a COMMIT performative. Again, the only downchain agent, Input Regulator , responds as described previously. The step  then ends (step ).","If no user voice-entry timeout has occurred, and no user commit indication has been detected, then in step , the Text Input agent  determines whether the user has indicated dissatisfaction with the response of the system to the user's most recent query or command. If so, then in step , the Text Input agent  sends the prior message to its downchain agents with a RESTORE performative, to cause the system to undo its incorrect action, and then in step , the Text Input agent  again sends the prior message to its downchain agents, this time with a DISSATISFIED performative. Step  then ends (step ).","If no user voice-entry timeout has occurred, and no user commit indication has been detected, and no user dissatisfaction indication has been indicated, then a step , Text Input agent  determines whether the user has indicated a desire to undo the previous action. If so, then in step , the Text Input agent  sends the prior message to its downchain agents with a RESTORE performative, similarly to step . However, the Text Input agent  does not follow this with a DISSATISFIED performative. Instead, step  then ends (step ). If no user voice-entry timeout has occurred, and no user commit indication has been detected, nor has any user dissatisfaction been indicated or an undo command been indicated, then in step , the Text Input agent  determines whether the user has requested that the previous action be redone. If so, then in step , the Text Input agent  sends the last message to its downchain agents with a THIS-IS-YOURS performative, thereby causing the system to repeat the most recent action. Step  then ends (step ).","Most of the flowcharts described above represent object class methods of individual agents. The overall functioning of the agent network as a whole results from intercommunication among the agents and the performance, internally to each agent, of methods such as those described above. In order to better explain the overall functioning of the agent network as a whole, , ,  and  are flowcharts describing the sequence of operation that the network of  performs in response to certain typical user voice input. These flowcharts are not intended to cover all possible sequences of events, but rather, illustrate some common or typical sequences.","Referring to , the flowchart begins when the Text Input agent  () detects a pause in the user's voice input (step ). In step , in accordance with step  (), the Text Input agent sends the input message as it currently stands to the Input Regulator agent  with a THIS-IS-YOURS performative. In step , it is assumed that the Input Regulator agent  has not seen this problem before (step , ), and does have downchain communities (step , ). Accordingly, the Input Regulator agent  attempts an interpretation (step , ).","In step , the Input Regulator agent  determines whether it was able to interpret the input message (step , ). If so, then in step , the Input Regulator  sends THIS-IS-YOURS to all relevant downchain communities identified in the interpretation policy (see step , ). In step , each agent downchain of the Input Regulator agent  which receives such a THIS-IS-YOURS performative, recursively performs steps similar to those of  as described herein.","If in step  the Input Regulator agent did not have an interpretation policy for this input message, then in step , the Input Regulator agent  stores the problem in its temporary request storage unit  () and queries all of its downchain agents with an IS-THIS-YOURS? performative (steps  and , ).","Eventually, all of the agents downchain of the Input Regulator agent  respond to the query (step ). Each response passes through the Input Regulator agent's procedure implementing  herein, including the application of quality criteria (step ) and attempts to automatically resolve contradictory claims of ownership (step ). The contradiction resolution attempt at this stage follows automated contradiction resolution algorithms only; the user is not yet asked for a resolution if the automated procedures fail. After all agents respond, in step , the Input Regulator agent  determines whether it has received one or more non-contradictory claims of ownership from its downchain agents (see steps  and , ). If it has, then the flow returns to step , in which the Input Regulator agent sends THIS-IS-YOURS to all relevant downchain neighbors (step  in ). Each downchain neighbor then recursively performs steps similar to those of  as described herein.","If in step  there are multiple contradictory claimants, then in step , the Input Regulator agent  merely returns MAYBE-MINE (see step , ) to the Text Input agent . Receipt of a NOT-MINE performative from an agent in response to a THIS-IS-YOURS performative indicates that a contradiction has occurred. Another embodiment could use a different performative for this purpose, such as CONTRADICTION, but in the present embodiment the MAYBE-MINE performative is available and has no other meaning when received in response to a THIS-IS-YOURS performative. Upon receipt of MAYBE-MINE, in step , the procedure ends and the input message is simply ignored.",{"@attributes":{"id":"p-0144","num":"0178"},"figref":["FIGS. 21","FIG. 4","FIGS. 21"],"b":["22","23","414","414","2022","2024","21","23","2110","418","420","22","23"]},"In a step , the agent determines whether the message is within its own local domain of responsibility, or it knows of a downchain agent or agents who should receive the message. If so, then control transfers to the flowchart of , described hereinafter. If the agent does not claim the message for itself, and does not have any interpretation policy (preprogrammed or learned) stored which fits the input message, then in step , the agent determines whether it has any downchain communities. If not, then in step , the agent returns NOT-MINE to its upchain sender. (See step  in .) If the agent does have downchain communities, then in step , it queries all its downchain communities with an IS-THIS-YOURS? performative (step  in ). In step , these steps repeat recursively in each downchain agent. Eventually, in step , Agent #i has received all responses from its downchain agents, applying quality criteria to each response and attempting to automatically resolve contradictory claims of ownership (steps  and  in ). In step , Agent #i determines whether it is left with non-contradictory responses from one or more of its downchain agents claiming the message or parts of the message. If so, then control transfers to the flowchart of . If not, then control transfers to the flowchart of .","Referring to , in step , now that Agent #i has received non-contradictory responses from one or more downchain claimants, it returns IT-IS-MINE to its upchain sending agent (, step ). All of the agents in the path back up to the agent which initiated the IS-THIS-YOURS? query, in this case Input Regulator , perform actions similar to those set forth herein with respect to Agent #i.","The Input Regulator agent  transmitted its query because it had received a THIS-IS-YOURS performative from its own upchain neighbor (Text Input agent ) in step  (), and it had no applicable interpretation policy. After all agents downchain of the Input Regulator agent  have responded (step ), if all contradictory claims of ownership were resolvable automatically, then the Input Regulator agent sends a THIS-IS-YOURS performative to all relevant downchain communities (step ). One of the responses being considered by Input Regulator agent  might be from an agent in the path leading to Agent #i, and any resolution of contradictory claimants may or may not resolve in favor of that path. Any agents between Input Regulator agent  and Agent #i in the path may also have multiple claimants to resolve, and these decisions may or may not resolve in favor of the path leading to Agent #i. Returning to , therefore, in step , the system by this process determines whether all contradictions occurring upchain of Agent #i resolve in favor of the path leading to Agent #i. If not, then in step , the message will be handled by some other agent in the network (using steps such as those beginning in step ). If so, then eventually, in step , Agent #i's upchain neighbor will eventually send a THIS-IS-YOURS performative to Agent #i. In step , Agent #i takes any agent-specific action in response to the input message (as in step  or , ), and in step , it passes THIS-IS-YOURS on to other relevant agents downchain of Agent #i. This is the manner in which the network determines the correct path(s) to the correct ultimate leaf agent(s), and then causes each agent in the path to perform any agent-specific functions that it needs to perform in response to the message.","As mentioned, in step  (), if the messages received from Agent #i's downchain neighbors, either all decline the message or claim the message in a contradictory manner, and the contradictions were not resolvable automatically, then control passes to the flowchart of . In step , if all of the responses were NOT-MINE performatives, indicating that all downchain neighbors have declined the message, then in step , Agent #i returns NOT-MINE to its upchain sender. Agent #i therefore will not be in any ultimately chosen path for the present input message (unless the user explicitly selects the path through the use of DISSATISFIED).","If in step  Agent #i's received responses are not all NOT-MINE's, then more than one of Agent #i's neighbors have claimed the message in a contradictory manner. Depending on the quality criteria employed by Agent #i, such claims might include both MAYBE-MINE performatives received as well as IT-IS-MINE performatives received, or may be limited to only IT-IS-MINE performatives received. In any event, in step , an agent which has received contradictory claims of ownership from its downchain neighbors returns MAYBE-MINE to its upchain sender (see step , ). Agent #i does not ask the user to resolve its contradiction at this time, in part because the ultimately chose path(s) for the input message might not even include Agent #i.","Eventually, as with step  in , the system determines whether Agent #i is to be within a path of action for the input message. All upchain contradictions would have to be resolved in favor of a path leading to Agent #i for Agent #i to eventually receive the message. If that is not the case (step ), then in step , the message is eventually handled by other agents. If Agent #i is eventually determined to be within the path for the input message (or within one of several paths for the input message), then in step , it will soon receive the input message from its upchain neighbor with a THIS-IS-YOURS performative (step ). However, since the agent has a contradiction that it is unable to resolve through its automatic algorithms, the agent merely returns MAYBE-MINE to its upchain sender (step ). The system then awaits further user input.","If the user has finished inputting, and the system nevertheless has not taken action, the user may issue a COMMIT. It is assumed that the COMMIT performative eventually reaches Agent #i (step ). Agent #i takes any agent-specific action that is required (step ), and proceeds to resolve the contradiction indicated by the responses that it previously received in step  to its IS-THIS-YOURS? queries. Agent #i resolves its contradiction by interacting with the user (step ). Then, in step , it sends the message on to its resolved downchain agent(s) with the COMMIT performative. Each such downchain agent receiving the message takes appropriate action in response to the message, beginning at step  of its own implementation of the flowchart of  (if that agent had previously received non-contradictory responses from one or more of its own downchain claiming neighbors), or at step  of the flowchart of  (if that agent had previously received contradictory claims of ownership from its own downchain neighbors for this message).",{"@attributes":{"id":"p-0152","num":"0186"},"figref":["FIG. 24","FIG. 11","FIG. 11"],"b":["2400","1130"]},"In the algorithm of , it is assumed first that IT-IS-MINE and MAYBE-MINE responses from downchain neighbors that have been queried with an IS-THIS-YOURS? performative, carry with them an indication of the priority of the responding agent. In the present embodiment, agent priorities are preprogrammed into each agent object class. Example priorities are shown in , and it can be seen that agents which are closer (fewer hops) to the typical originator of IS-THIS-YOURS? queries (Input Regulator agent ) have been assigned higher priorities than agents which are more distant (greater number of hops) from the originator agent. If an agent claims a message because of its own interpretation policy, then it passes its own priority level upchain with the IT-IS-MINE performative. If an agent claims a message only because one of its downchain agents has claimed the message, then the agent passes upchain the priority level that was specified in the downchain agent's IT-IS-MINE (MAYBE-MINE) performative. Thus, together with the choice of a performative (MAYBE-MINE or IT-IS-MINE), the priority level returned with a query response indicates a confidence level with which the agent believes that it is the owner of the input message. Such indications of confidence not only can be used by upchain agents in determining whether to discard the claim of ownership, as previously described, but are also used in the contradiction resolution step of .","In particular, in step , the agent first determines whether the focus of the newly received ownership claim (IT-IS-MINE or MAYBE-MINE) overlaps with the focus of any claim previously received. If not, then there is no contradiction and the routine returns (step ). If focuses do overlap, then in step , the agent determines whether there is a tie, among all of its downchain neighbors claiming the message, for the highest priority level indicated by the responses with overlapping focuses. If not, then the agent whose response carried the highest priority level wins. The lower priority claim is changed in the agent's temporary request storage unit  to a NOT-MINE performative and, if that claim had previously caused either TheyKnowCount or TheyMayKnowCount to be incremented, such count is now decremented (step ). The routine then returns with the contradiction resolved (step ).","If there is a tie in priority levels among ownership claims with overlapping focus, then resolution continues at the next stage of the algorithm, determining which of the highest priority claimants with overlapping focus had received an input message most recently (step ). This stage of the algorithm is predicated on the observation that when a user makes a request related to one part of the home entertainment system , the user's next request is more likely than not to relate to the same component. For example, the user might say, \u201cTurn the volume up!\u201d, followed by \u201cUp!\u201d. If the first of these requests resolves eventually to leaf agent  in  (the Sound agent), then it is likely that the second of these requests also should be resolved to the same agent, rather than to Channel agent  in , for example. Accordingly, returning to , if in step , the agent determines that of the two or more claiming agents with overlapping focus and having the highest priority, they are nevertheless distinguishable on the basis of recency, then in step , the claim having weaker recency is changed to a NOT-MINE and TheyKnowCount or TheyMayKnowCount is (if appropriate) decremented. In step  the routine returns with the contradiction having been resolved.","If neither of the first two stages of the contradiction resolution algorithm were able to resolve the contradiction, then in step , the routine returns without having resolved the contradiction. If in the future a COMMIT performative forces the agent to resolve the contradiction, it will do so by asking the user which of its downchain neighbors should receive the input message (See step , ). This may be accomplished by, for example, offering the user the names or descriptions of such downchain neighbors. In one embodiment, the agent offers all of its downchain neighbors for selection. In another embodiment, the agent first narrows the choices to be offered to the user in accordance with one or more of the automatic tests of its contradiction resolution algorithm, such as the tests of steps  and . In any event, the user eventually responds and the system learns the response in accordance with the flowchart of .","As an example of system message flow, assume Text Input agent  () detects a user voice-input message, \u201cPicture to the right.\u201d It passes the message to the Input Regulator agent  with a THIS-IS-YOURS performative. Assuming the Input Regulator agent  has no interpretation policy for this input message, it sends an IS-THIS-YOURS? query to both the TV agent  and the VCR agent . The VCR agent  also cannot interpret the message, so it sends IS-THIS-YOURS? performatives on to each of its own downchain neighbors  and . After further communication among agents in the VCR subnetwork, eventually the VCR agent  receives NOT-MINE from all of its downchain neighbors. It therefore responds NOT-MINE to the Input Regulator agent .","In the meantime, TV agent  does have an interpretation policy for the input message, namely that all messages containing the word \u201cPicture\u201d are within the domain of responsibility of Viewport agent . It therefore returns IT-IS-MINE to the Input Regulator agent . Since the Input Regulator agent  has now received exactly one response claiming the input message (that from TV agent ), it sends the message back to TV agent , this time with a THIS-IS-YOURS performative. TV agent  performs any special processing local to that agent (which in this case is none), and passes the THIS-IS-YOURS performative on to the viewport agent  in accordance with its interpretation policy. Viewport agent  performs any special processing local to that agent. Then, since the Viewport agent  does have downchain neighbors (Magnification and Shifting agents  and , respectively), and it does not yet know which if any of such neighbors should now receive the input message, it queries both of its downchain communities by sending them IS-THIS-YOURS? messages. It then waits until it has received responses from all agents it has queried.","The Magnification agent , not itself recognizing any word in the input message and not having any downchain communities (TV actuator does not count, because it has not advertised itself as having any particular domain of responsibility), responds with NOT-MINE. The Shifting agent community  does recognize the input message as belonging to the Right Agent  (because of the presence of the word \u201cright\u201d in the message text), so it claims the message by returning an IT-IS-MINE message to the Viewport agent . Viewport agent , which was the originator of the present query, has now received exactly one IT-IS-MINE response. It therefore knows that the message belongs to Shifting agent . It transmits the message again to Shifting agent , this time with a THIS-IS-YOURS performative. The Shifting agent  compares the input message to its stored list of problems (in temporary request storage unit ), and determines that it has previously seen this problem and that the message belongs to Right agent . Thus, Shifting agent  retransmits the input message to Right agent  with a THIS-IS-YOURS performative. The Right agent , in its local processing step  (), instructs TV Actuator  to cause the home entertainment system  to make the proper adjustment in response thereto.","Assume that Shifting agent  does not have a pre-existing interpretation policy which applies to the phrase, \u201cTV to the right.\u201d In this case, upon receipt of the IS-THIS-YOURS? query from Viewport agent , instead of responding IT-IS-MINE, it responds NOT-MINE. Viewport agent  therefore receives all NOT-MINE's from its downchain neighbors, even though it has received a THIS-IS-YOURS performative from TV agent . This agent now has a contradiction. The agent therefore returns MAYBE-MINE to the TV agent , and this message is passed back up the chain to Text Input agent , where it dissipates with the system simply awaiting further input.","Assume that the user recognizes that the system is not going to perform the intended action, and issues a Commit indication. Text Input agent  recognizes this and transmits a COMMIT performative to Input Regulator agent . Input Regulator agent  has already seen the subject problem and previously determined that the message belongs to the TV subnetwork. It therefore passes the message on to TV agent  with a COMMIT performative. TV agent  also determines that it has seen the subject problem before and previously determined that the message belongs to the Viewport subnetwork. It therefore passes the message on to the Viewport agent  with a COMMIT performative. Viewport agent  also determines that it has previously seen the subject problem, and further that it has a contradiction. The COMMIT performative requires the Viewport agent  to resolve its contradiction. Since in this case the contradiction is in the form of NOT-MINE responses received from all of the Viewport agent's downchain communities, it interacts with the user to resolve the contradiction. For example, it asks the user, \u201cDo you mean Magnification or Shifting?\u201d The user answers \u201cShifting.\u201d","Upon receipt of the user's answer, the Viewport agent learns an interpretation policy such as (depending on the particular learning algorithm used), that input messages containing the word \u201cRight\u201d should be routed to the Shifting agent community . It then sends an UNLEARN performative to each upchain neighbor of Viewport agent . The only agent neighbor upchain of Viewport agent  is TV agent , which does not currently have an interpretation policy for messages containing the word \u201cRight\u201d. TV agent  therefore ignores the UNLEARN message.","After learning the new interpretation policy and sending the UNLEARN message, Viewport agent  sends the message on to Shifting agent  with a COMMIT performative. Shifting agent  also has a contradiction, having previously received NOT-MINE responses from both of its downchain neighbors in response to its prior query on the subject problem. It therefore interacts with the user as above and determines that the message should be routed to the Right agent . Shifting agent  learns the new interpretation policy and sends an UNLEARN performative to its upchain neighbor, Viewport agent . Viewport agent  removes its previously learned interpretation policy in response to the UNLEARN performative, thereby eliminating a learning redundancy in the network and localizing the learned policy more closely to the ultimate proper leaf agent.","After learning the new interpretation policy and sending the UNLEARN message, Shifting agent  finally sends the message to Right agent  with the COMMIT performative. Right agent  acts on the message (step , ) in the only way it knows how, by sending an AGENT-SPECIFIC performative to TV Actuator  to cause it to move the viewport to the right by an increment. In this way the network learns, in a properly localized manner, that messages containing the words \u201cPicture\u201d and \u201cRight\u201d should be routed through TV agent  to Right agent .","In conventional multi-agent systems, the problems of learning have been largely ignored. Designing agents that would learn about anything in the world goes against the basic philosophy of distributed artificial intelligence. This may be one reason why some conventional systems are ill-behaved (the more they learn, the slower they perform). By allowing the agents to adapt, refine and improve, automatically or under user control, a holistic system can be created in which the whole is significantly more than the sum of its parts.","In the embodiment described herein, the combination of machine learning and multi-agent systems has benefits for both. Multi-agent systems having learning capabilities can reduce cost, time, and resources and increase quality in a number of forms:\n\n","On the other hand machine learning in a multi-agent set-up becomes faster and more robust.","The agents described herein are adaptable in the following ways:\n\n","Viewing software as a network of Agents (considered as intelligent beings) can result in designs that are much different in structure and modularization than conventional multi-agent designs. Some of the benefits of this approach are noted here.\n\n","Set forth in the file APPENDIX I.txt in the CD-ROM appendix hereto is sample Java code for the main object class used by the agents in the network of . APPENDIX II.txt in the CD-ROM appendix hereto contains Java code illustrating the object class for a Text Input agent, such as agent  (). APPENDIX III.txt in the CD-ROM appendix hereto contains Java code implementing the object class for an input regulator agent like Input Regulator agent  (). APPENDIX IV.txt in the CD-ROM appendix hereto contains Java code illustrating the object class for a Menu agent, which implements a TV Actuator agent such as  ().","In addition,  illustrates an alternative agent network diagram for controlling the home entertainment system . In , the dark three-dimensional units communicate with both the actuator  and the menu agent , whereas the lighter shaded three-dimensional units communicate with the menu agent  but not with the actuator . The two-dimensional units are proxy agents only, and do not communicate with either the actuator  or the menu agent . They do perform interpretation functions, but the only local work they perform is to notify an upchain neighbor to perform relevant work. For example, the Play agent , which is downchain of both the DVD agent  and the VCR agent , interprets \u201cPlay\u201d commands for both the DVD and VCR agents. But when the Play agent  finally receives a THIS-IS-YOURS performative, its black-box function merely requests the DVD agent  or the VCR agent , as the case may be, to activate the Play function of the home entertainment system . This request, which is communicated via an AGENT-SPECIFIC PERFORMATIVE, permits all DVD-related functions (and VCR-related functions) to be controlled and maintained in the black-box of a single agent (the DVD agent  or the VCR agent ).","Program list  in  is merely a small database which is accessible from the black-box software of Program agent , Remove agent , and Add agent . The Program list  contains user-programmed requests for actions to take place with respect to the home entertainment system  at specified future times.","The foregoing description of preferred embodiments of the present invention has been provided for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise forms disclosed. Obviously, many modifications and variations will be apparent to practitioners skilled in this art. For example, although the embodiment described herein is shown implemented in software running on a single-processor computer system, it will be appreciated that other embodiments can run on multi-processor systems, or can be distributed across multiple computer systems or microcomputers communicating, for example, via TCP\/IP. In addition, some or all agents can be implemented in hardware, rather than software. Other variations will be apparent. As another example, whereas the described embodiment attempts automatic contradiction resolution in response to each query response received from downchain agents, another embodiment could collect all responses and attempt automatic contradiction resolution only upon receipt of a COMMIT performative or its equivalent. The embodiments described herein were chosen in order to best explain the principles of the invention and its practical application, thereby enabling others skilled in the art to understand the invention for various embodiments and with various modifications as are suited to the particular use contemplated. It is intended that the scope of the invention be defined by the following claims and their equivalents."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0018","num":"0035"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0036"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0020","num":"0037"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0021","num":"0038"},"figref":["FIG. 4","FIG. 2"]},{"@attributes":{"id":"p-0022","num":"0039"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0023","num":"0040"},"figref":["FIG. 6","FIG. 5"]},{"@attributes":{"id":"p-0024","num":"0041"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0025","num":"0042"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0026","num":"0043"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0027","num":"0044"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0028","num":"0045"},"figref":["FIG. 11","FIGS. 9"],"b":["10","12","13"]},{"@attributes":{"id":"p-0029","num":"0046"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0030","num":"0047"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0031","num":"0048"},"figref":["FIG. 14","FIG. 13"]},{"@attributes":{"id":"p-0032","num":"0049"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0033","num":"0050"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0034","num":"0051"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0035","num":"0052"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0036","num":"0053"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0037","num":"0054"},"figref":["FIGS. 20","FIG. 4"],"b":["21","22","23"]},{"@attributes":{"id":"p-0038","num":"0055"},"figref":["FIG. 24","FIGS. 20 and 23"]},{"@attributes":{"id":"p-0039","num":"0056"},"figref":["FIG. 25","FIG. 2"]}]},"DETDESC":[{},{}]}
