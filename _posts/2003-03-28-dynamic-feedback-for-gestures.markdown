---
title: Dynamic feedback for gestures
abstract: Gesture feedback techniques are discussed that provide prompt feedback to a user concerning the recognition of one or more gestures. The feedback may be employed to confirm to a user that a gesture is being correctly recognized. The feedback may alternately warn a user that a desired gesture is not being correctly recognized, thereby allowing the user to cancel the erroneous gesture before it is invoked
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07886236&OS=07886236&RS=07886236
owner: Microsoft Corporation
number: 07886236
owner_city: Redmond
owner_country: US
publication_date: 20030328
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS","CONCLUSION"],"p":["Various embodiments of the present invention relate to dynamic feedback for gestures. Some embodiments of the invention have particular application to providing feedback to a user making a gesture that confirms recognition of the gesture before the gesture is completed.","As the field of computer science has matured, a variety of devices have been developed to allow users to input information into computer devices. One group of these devices is referred to as pointing devices. As the user moves the device or a component of the device, the pointing device generates position data corresponding to the movement of the pointing device. This position data is in turn translated into movement of a pointer image rendered on a display. Thus, by moving the pointing device, a user can associate the pointer image with data represented by other images rendered on the display. A user can then manipulate that data by activating a command action associated with the pointer, such as depressing a command button.","One particular category of pointing device allows a user to input information into a computer by moving a pen or stylus relative to a surface. For example, some computers now include a digitizing tablet that detects the position of a stylus relative to the tablet. As the stylus moves across (or, in some cases, above) the surface of the tablet, the tablet produces position data based upon the position of the stylus. With these computers, the digitizing tablet may be separate from the display, or it may be incorporated into the display. One example of this type of input device is employed by the Microsoft TabletPC.","The stylus pointing device conveniently allows a user to input data using the natural input technique of handwriting. For example, the Microsoft TabletPC can convert position data generated by writing on a tablet surface with the stylus into electronic ink, much like an actual pen writes ink onto paper. In an effort to increase the capability of the stylus pointing device, some computers are even capable of recognizing \u201cgestures\u201d made with a stylus. More particularly, these computers recognize specific movements made with the stylus as commands, such as commands to perform an action or to produce a character. For example, this type of computer may recognize an oversized \u201cS\u201d movement made with the stylus as a command to save an open file, or recognize a \u201c<\u201d or \u201c>\u201d movement made with a stylus as a command to shift the images rendered on the display left or right, respectively. Alternately or additionally, this type of computer may recognize the movement of the stylus in a \u201cv\u201d shape or in an \u201cc\u201d shape as a command to produce the text character \u201cv\u201d or \u201cc\u201d, respectively.","While the use of gestures significantly enhances the capabilities of a stylus pointing device, it is sometimes difficult for a user to know when a particular gesture has been properly recognized. Because the movement of the stylus will be different each time a gesture is made by a user, a particular gesture cannot always be accurately recognized. Accordingly, a user must typically make a complete gesture, and then wait to see if the gesture was accurately recognized. If the computer does not recognize a gesture, it will not take the desired action. Even worse, if the computer incorrectly recognizes the movement of the stylus as another gesture, it will subsequently perform an undesired operation which the user must then undo. Alternately, a user may inadvertently move the stylus and make a gesture that was not intended. With conventional computers, a user would not realize that he or she had accidentally made a gesture until the corresponding operation was executed. If the user does not realize that the computer accepts gestures made with a stylus, the user may not even understand why the operation was executed.","Advantageously, various embodiments of the invention may be employed to provide prompt feedback to a user that indicates when a gesture has been recognized. More particularly, various embodiments of the invention provide feedback to a user that indicates when a gesture has been recognized even before the user has finished making the gesture. If the user's gesture has been correctly recognized, this prompt feedback reassures the user that the corresponding gesture command will be accurately invoked. Alternately, if the user's gesture has not been correctly recognized, the user may quickly restart the gesture. Further, if the user's gesture has been incorrectly recognized as another gesture, the user can continue to move the stylus so as to cancel the incorrectly recognized gesture.","With various embodiments of the invention, a gesture recognition module receives position data from a pointing device being manipulated by user. The gesture recognition module continuously analyzes the received position data, in order to recognize if the pointing data corresponds to a gesture. When the gesture recognition module recognizes that the received position data corresponds to a gesture, a gesture feedback module provides feedback to the user indicating that a gesture has been recognized from the position data. As the user continues to manipulate the pointing device, the gesture recognition module continues to analyze the position data received from the pointing device. If the position data continues to correspond to a recognized gesture, then the gesture will be invoked when the user stops manipulating the pointing device. If, however, the position data does not continue to correspond to a recognized gesture, then the gesture feedback module provides new feedback to the user indicating that a gesture is no longer being recognized from the position data. This new feedback may expressly indicate that a gesture is no longer being recognized, or it may simply be a deletion of the earlier feedback.","Overview","The present invention relates to a gesture feedback tool that recognizes commands from gestures made by a user. Moreover, when the gesture feedback tool recognizes that a gesture corresponds to a command, it provides the user with feedback indicating the command that the tool has recognized from the gesture. As will be discussed in detail below, the tool provides the feedback after the gesture is recognized, but before the user completes the gesture. For example, if the tool recognizes the user's gesture as a command to perform an action, then the tool may provide the user with feedback in the form of an icon representing that action. Alternately or additionally, if the tool recognizes the user's gesture as a command to generate a text character, then the tool may provide the user with feedback in the form of, for example, the recognized text character superimposed over the space where the user is making the gesture.","As previously noted, the tool may provide the feedback before the user has completed the gesture. This prompt feedback allows the user to confirm that the gesture has been correctly recognized before the corresponding command is invoked. Further, if the user's gesture is almost complete but has not been correctly recognized, then the user may quickly restart the gesture without fruitlessly waiting for the command to be invoked. Further, if the user's gesture has been incorrectly recognized as another gesture, the user can continue to move the pointing device so as to cancel the incorrectly recognized gesture.","A gesture feedback tool according to the invention may be implemented using a variety of techniques. For example, some embodiments of the invention may be implemented using circuitry formed with solid state electronics. Still other embodiments of the invention may be implemented using instructions executed on a programmable computing device. Accordingly, an exemplary computing environment for executing such instructions will be described. Various interfaces demonstrating the operation and use of the invention will also be described, along with the components and functions of a gesture feedback tool according to various embodiments the invention.","Exemplary Operating Environment","As previously noted, the gesture feedback tool of the invention may be implemented using instructions that can be executed on a programmable computer, sometimes referred to as software. That is, the gesture feedback tool may be described in the general context of computer-executable instructions, such as program modules, executed by one or more computing devices. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. Typically the functionality of the program modules may be combined or distributed as desired in various embodiments.","Because the invention may be implemented using software, it may be helpful for a better understanding of the invention to briefly discuss the components and operation of a typical programmable computer on which various embodiments of the invention may be employed. Such an exemplary computer system is illustrated in . The system includes a general-purpose computer . This computer  may take the form of a conventional personal digital assistant, a tablet, desktop or laptop personal computer, network server or the like.","Computer  typically includes at least some form of computer readable media. Computer readable media can be any available media that can be accessed by the computer . By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by the computer .","Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.","The computer  typically includes a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. The system memory  includes read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within the computer , such as during start-up, is stored in the ROM .","The computer  may further include additional computer storage media devices, such as a hard disk drive  for reading from and writing to a hard disk, a magnetic disk drive  for reading from or writing to a removable magnetic disk , and an optical disk drive  for reading from or writing to a removable optical disk , such as a CD ROM or other optical media. The hard disk drive , magnetic disk drive , and optical disk drive  are connected to the system bus  by a hard disk drive interface , a magnetic disk drive interface , and an optical disk drive interface , respectively. The drives and their associated computer-readable media provide nonvolatile storage of computer readable instructions, data structures, program modules, and other data for the personal computer . It will be appreciated by those skilled in the art that other types of computer readable media that may store data that is accessible by a computer, such as magnetic cassettes, flash memory cards, digital video disks, Bernoulli cartridges, random access memories (RAMs), read only memories (ROMs), and the like, may also be used in the example operating environment. Also, it should be appreciated that more portable embodiments of the computer , such as a tablet personal computer or personal digital assistant, may omit one or more of the computer storage media devices discussed above.","A number of program modules may be stored on the hard disk drive , magnetic disk , optical disk , ROM , or RAM , including an operating system , one or more application programs , other program modules , and program data . A user may enter commands and information into the computer  through various input devices, such as a keyboard  and a pointing device  (for example, a mouse, touchpad, or pointing stick). As previously noted, the invention is directed to a tool for providing feedback when a gesture is recognized. As will be appreciated by those of ordinary skill in the art, while the gesture input can be generated using a variety of pointing devices, the most convenient pointing device for creating this type of input is often a pen or stylus. Accordingly, the computing device  will typically include a digitizer  (sometimes referred to as a graphics pad) and a stylus or pen , which a user may employ to create handwriting input that can be recognized as a gesture. As will be appreciated by those of ordinary skill in the art, with some embodiments, the digitizer  receives handwriting input when the stylus or pen  contacts the surface of the digitizer . With other embodiments, the digitizer  may receive handwriting input from a light beam generated by the pen , by tracking the angular movement of a mechanical arm supporting the pen , or by another suitable technique.","These and other input devices often are connected to the processing unit  through a serial port interface  that is coupled to the system bus , but may be connected by other interfaces, such as a parallel port, game port, IEEE-1394B bus, or a universal serial bus (USB). Further still, these devices may be coupled directly to the system bus  via an appropriate interface (not shown). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video adapter . In addition to the monitor , personal computers typically include other peripheral output devices (not shown), such as speakers and printers. As will be appreciated by those of ordinary skill in the art, the monitor  may incorporate the digitizer , to form a digitizing display . This arrangement conveniently allows a user to employ the pen  to point directly to objects displayed on the digitizing display by contacting the display screen of the display .","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a server, a router, a network PC, a peer device, or other common network node, and typically includes many or all of the elements described above relative to the computer , although only a memory storage device  with related applications programs  have been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet, and thus will not be explained in detail here.","When used in a LAN networking environment, the computer  is connected to the local network  through a network interface or adapter . When used in a WAN networking environment, the personal computer  typically includes a modem  or other means for establishing a communications link over the wide area network , e.g., to the Internet. The modem , which may be internal or external, may be connected to the system bus  via the serial port interface . In a networked environment, program modules depicted relative to the personal computer , or portions thereof, may be stored in a remote memory storage device. Of course, it will be appreciated that the network connections shown are exemplary and other techniques for establishing a communications link between the computers may be used. The existence of any of various well-known protocols such as TCP\/IP, Ethernet, FTP, HTTP and the like is presumed, and the system may be operated in a client-server configuration to permit a user to retrieve web pages from a web-based server. Any of various conventional web browsers may be used to display and manipulate data on web pages.","Gesture Recognition without Prompt Feedback","In order to better distinguish the prompt and dynamic feedback features of the invention, an example of a gesture recognition process that does not employ the dynamic feedback of the invention will first be discussed. Referring now to , shape  is a pattern that a gesture recognition module will recognize as a gesture corresponding to a command. In particular, shape  is an \u201cS\u201d shape that will be recognized as, for example, a command to save an open file or to generate the text character \u201cS\u201d. It should be appreciated that the shape  is typically not displayed to a user, and thus is illustrated with a dotted line in . In order to make the gesture represented by the shape , the user employs a stylus  to produce the handwriting input , as shown in . In this figure, the handwriting input  is illustrated as a solid line. It should be noted, however, that some gesture recognition modules may not display the handwriting input  generated with the stylus .","As also seen in this figure, while the user has generated handwriting input  corresponding to most of the gesture shape , the gesture recognition module still does not provide feedback to the user indicating whether or not the handwriting input  has been recognized as the gesture corresponding to the shape . At the position illustrated in , the gesture recognition module may have recognized the handwriting input  as the gesture represented by the shape . Even if the gesture recognition module has made this recognition, however, the user is unaware of this recognition.","Referring now to , even if the user completes the handwriting input  corresponding to the gesture shape , the gesture recognition module still does not provide any feedback to the user to indicate whether the appropriate gesture has been recognized. With some gesture recognition modules, after the user stops making a gesture (that is, when the user has completed the handwriting input  and removed the stylus  from the surface of the digitizer ), the gesture recognition module may still not provide any feedback to the user indicating whether or not the gesture has been correctly recognized, as illustrated in . Thus, the user must wait to see whether or not the command corresponding to the desired gesture is invoked to determine if the user's gesture has been correctly recognized.","The Gesture Feedback Tool",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 3","b":["301","301","301","303","305","319","321"]},"Referring first to the user input device , the user input device  may be any device through which a user can generate position data corresponding to the position of the pointing device. For example, the input device  may be any type of conventional pointing device, including a mouse, touch pad, joystick, or trackball. As will be appreciated by those of ordinary skill in the art, these types of pointing devices generate virtual position data based upon the location of displayed pointer icons controlled by movement of (or movement over) the pointing device.","In the illustrated embodiment, however, the input device  is a stylus , which can conveniently be employed by a user to generate absolute position data in the form of handwriting input data. That is, the stylus  generates absolute position data based upon the position of the stylus  relative to the surface of a digitizer . It should be noted that the position data generated by the stylus  and digitizer  may be more than just simple coordinate values on an x-y plane. As will be appreciated by those of ordinary skill in the art, some types of digitizers may be able to determine the distance between the stylus  and the surface of digitizer , the angle at which the stylus  is held relative to the surface of the digitizer , and may even be able to determine the amount of pressure applied by the stylus  against the surface of the digitizer . One or more of these characteristics (or any other position characteristic that can be determined for any type of pointing device) may be used to produce position data for making a gesture according to various embodiments of the invention.","The input interface module  may then be any type of user interface module for providing data to the tool  based upon the position data created with the input device . Thus, if the input device  is a stylus , then the input interface module  may be an application programming interface (API) for converting the position data created by moving the stylus  over the surface of the digitizer  into data that can be employed by the tool . For example, the input interface module  may convert the absolute position data created with the stylus  into electronic ink data made up of discrete samples of the position data with corresponding of vector information for each sample. Of course, the input interface module  may convert the position data into any data format useful to the tool . Various types of input interface modules  using position data created by pointing devices are well-known in the art, and thus will not be discussed in more detail here.","Referring back now to , the tool  includes a gesture recognition module . The gesture recognition module  may employ a neural net  and\/or a heuristic recognizer  for recognizing when position data created using the input device  corresponds to a gesture. It should be noted that, while the illustrated embodiment includes both a neural net  and a heuristic recognizer  for recognizing gestures, additional or alternate techniques may be employed to recognize gestures from position data created with the input device . The use of these alternate techniques, as well as the use of the neural net  and the heuristic recognizer , are well known in the art, and thus will not be discussed in further detail.","The tool  also includes a gesture feedback module . As seen in , the gesture feedback module  includes a position calculation module  and a layered window management module . When the gesture recognition module  recognizes that position data generated with the input device  corresponds to a gesture, the gesture recognition module  reports the recognized gesture to the gesture feedback module . In response, the position calculation module  determines what type of gesture feedback should be displayed to the user in order to inform the user that the gesture has been recognized. With some embodiments of the invention, for example, the position calculation module  may employ a look-up table to determine a gesture feedback corresponding to the recognized gesture provided by the gesture recognition module . Of course, still other embodiments of the invention may employ any desirable technique for determining the form of the gesture feedback that will be displayed to the user in response to recognition of a particular gesture. Also, as will be discussed in detail below, the gesture feedback may take a variety of different forms, including the display of one or more icons, text messages, colors changes, and animation, the playback of an audible sound, or a combination of two or more of these forms.","The position calculation module  also determines a position at which the feedback corresponding to the recognized gesture will be displayed to the user. For example, with some embodiments of the invention, the position calculation module  may determine that the gesture feedback (that is, the feedback indicating that the gesture has been recognized) will be displayed at a fixed distance below the lowest position data making up the gesture, or at a fixed distance above the highest position data making up the gesture. Alternately, the position calculation module  may determine a bounding area in which the entire gesture should be contained. The position calculation module  may then determine that the gesture feedback will be displayed at a fixed distance above, below or to either side of this bounding area. Still further, the position calculation module  may track the changes in position data as the user employs the input device  to make the gesture. The position calculation module  may then continuously determine a new position for the gesture feedback corresponding to the new position data created with the input device .","With some embodiments of the invention, the position calculation module  may even determine the type or form of gesture feedback that will be displayed to the user based upon the location of the position data making up the gesture. For example, if the position data making up the gesture is contained within a relatively small display area, then the position calculation module  may determine that a small icon should be displayed as the gesture feedback rather than a longer text message. It should be appreciated, however, that with alternate embodiments of the invention, determining the form of the gesture feedback and determining the position at which the gesture feedback will be displayed to the user may be performed by different components, rather than by the single position calculation module .","With the embodiment of the invention illustrated in , the gesture feedback is displayed using multiple transparent layered windows. As known to those of ordinary skill in the art, this type of transparent layered window is a graphical user interface in which only the content contained within the window is displayed. Thus, this type of transparent layered window will not typically include visible borders, toolbars, task bars, edit controls or other types of controls, thereby minimizing the processing overhead required to display the content. Moreover, with the illustrated embodiment, a single gesture feedback may be rendered using multiple small transparent layered windows, further minimizing the processing overhead of the system.","Accordingly, once the position calculation module  has determined the form of the gesture feedback and the position at which the gesture feedback will be displayed to the user, the layered window management module  instructs the layered window generation module  to generate that gesture feedback at the determined position on the user interface . The layered window generation module  may be, for example, a conventional application programming interface (API) for managing the appearance and content of windowed graphical user interfaces. Similarly, the user interface  may be any type of conventional display, including, for example, a cathode ray tube (half) display, a plasma screen display, or a liquid crystal (LCD) display, each of which are well known in the art. The layered window management module  can then be any type of module for controlling the operation of the layered window of generation module  to display the desired gesture feedback.","Operation of the Gesture Feedback Tool",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 4","b":["301","401","403","301","307","303"]},"If the gesture is not yet recognized, then, in step , feedback is provided to the user indicating that the gesture has not yet been recognized. With some embodiments of the invention, this non-recognition feedback may be active feedback positively indicating to the user that a gesture has not yet been recognized. For example, the gesture feedback module  may instruct the layered window generation module  to generate a window with text message content stating that a gesture has not yet been recognized. With still other embodiments of the invention, however, the non-recognition feedback may be passive feedback, where no action is taken (that is, where the user interface  remains unchanged) when a gesture has not been recognized by the gesture recognition module. While positive non-recognition feedback actively informs the user that the gesture has not yet been recognized, passive non-recognition feedback requires little or no processing overhead by the gesture feedback module.","In step , the gesture recognition module determines if the user has stopped making the gesture. For example, with the embodiment of the invention illustrated in , the gesture recognition module  determines if the input device  is continuing to produce position data. If the input device  is no longer producing position data (that is, if the user has lifted the stylus  from the surface of the digitizer ), then in step  no further action is taken by the tool . If, however, the user is continuing to draw the gesture, then the process loops around to step , where the gesture recognition module continues to attempt to recognize the gesture in step .","When the gesture recognition module recognizes the user's gesture in step , the gesture feedback module provides feedback to the user indicating that the gesture has been recognized in step . For example, with the embodiment illustrated in , when the gesture recognition module  has recognized a gesture from the position data provided by the input device , the gesture feedback module  provides feedback to the user interface  indicating that the gesture has been recognized.","With some embodiments of the invention, the recognition feedback may simply indicate to the user that a gesture has been recognized from the position data, without specifically identifying which gesture was recognized by the gesture recognition module. Thus, the recognition feedback may be an icon that the user will recognize as confirmation that a gesture has been recognized, a text message simply stating that a gesture has been recognized, or other visible display that will indicate to a user that a gesture has been recognized. Alternately or additionally, an audible indicator may be played to inform the user that a gesture has been recognized from the position data. For example, some embodiments of the invention may play a specific tone when the gesture is recognized, or playback a voice message stating that a gesture has been recognized from the position data.","With still other embodiments of the invention, however, the recognition feedback will specifically identify the gesture recognized from the position data. For example, if the gesture is recognized as corresponding to a command to take some action, then the gesture feedback module (for example, the gesture feedback module  for the embodiment of the invention illustrated in ) may display an icon, text message, or other image that the user will associate with that action. Thus, if the gesture recognition module  recognizes that input position data corresponds to a gesture for saving an open file, then the gesture feedback module  may display an icon informing the user that an open file has been saved. Alternately, the gesture feedback module  may display a text message reading, for example, \u201cfile saved.\u201d If, on the other hand, the gesture is recognized as corresponding to a command to provide one or more text characters, then the gesture feedback module may display those characters. For example, if the gesture is recognized as a command to generate the letter \u201cA\u201d, then the gesture feedback module may display the letter \u201cA\u201d to inform the user that the gesture was recognized.","It should also be appreciated that the speed at which the feedback provided by the gesture feedback module may be dependent upon the speed at which the gesture recognition module  recognizes a gesture from the position data. If the operation of the gesture recognition module  is too slow to process each new piece of position data created by the input device , then the gesture recognition module  may only periodically sample the position data generated by the input device  to recognize a gesture. Other techniques may alternately or additionally be employed to speed up the operation of the gesture recognition module , such as, for example, performing the gesture recognition process using a dedicated programming thread. In any case, if the gesture recognition module  recognizes a gesture more slowly than position data is created to make that gesture, then the feedback provided by the gesture feedback module  may also lag behind the creation of the position data. Accordingly, some embodiments of the invention may change the feedback by, for example, changing the color or luminosity of displayed feedback, to indicate the delay at which a gesture is being recognized.","For some embodiments of the invention, the gesture recognition module (for example, the gesture recognition module  of the embodiment illustrated in ) may provide a confidence level in the recognition of a gesture. For example, when a user has only partially completed a gesture, the gesture recognition module may correctly recognize the gesture, but have a relatively low confidence level in the accuracy of its recognition. As the user continues to complete the gesture (and the recognition system receives additional position data from the input device ), the confidence level for the accuracy of the recognized gesture may increase. Accordingly, gesture feedback may be provided by various embodiments of the invention that further informs the user as to the confidence level in the recognition of the gesture.","For example, if the gesture recognition module has a relatively low confidence in the accuracy of a recognized gesture, then the gesture feedback module may provide an icon both identifying the recognized gesture and having a red color to indicate that the confidence in the recognition of this gesture is relatively low. If the gesture recognition module then increases its confidence level in the recognition of the gesture, the gesture feedback module may change the color of the icon from red to yellow, to indicate to the user that the confidence in the recognition of the gesture had increased. If the confidence in the gesture continues to increase, the gesture feedback module may then change the color of the icon again, for example, from yellow to green, to indicate to the user that the confidence in the recognition of the gesture had increased further.","It should be appreciated that, in addition to color, still other techniques can be used to identify the confidence level in the recognition of a gesture. For example, some embodiments of the invention may employ differently-sized icons or other images to inform the user as to the confidence level in the recognized gesture. Still other embodiments of the invention may alternately or additionally use text messages to inform the user as to the confidence level in a recognized gesture. Further, various embodiments of the invention may employ different icons or other images, audible sounds or spoken messages, or still other techniques, including a combination of one or more of the above-mentioned techniques, to inform the user as to the confidence level in a recognized gesture.","With some embodiments of the invention, the gesture recognition module may recognize more than one gesture from a set of position data. For these embodiments, the gesture feedback module may provide gesture feedback identifying each recognized gesture. For example, a gesture recognition module may recognize a gesture made in a \u201cC\u201d shape (as, for example, a gesture corresponding to a command to copy selected data onto a computer's clipboard) and recognize a different gesture made in a \u201cS\u201d shape (as, for example, a gesture corresponding to a command to save an open file). When a user begins to make the gesture corresponding to the \u201cS\u201d shape, the gesture recognition module may initially be unable to differentiate this gesture from the gesture corresponding to the \u201cC\u201d shape. Instead, the recognition system may \u201crecognize\u201d the gesture as corresponding to both the \u201cS\u201d shape and the \u201cC\u201d shape. In this situation, various embodiments of the invention may provide gesture feedback identifying both gestures.","Still further, some of these embodiments of the invention may provide gesture feedback that identifies both each recognized gesture and a confidence level associated with each of the recognized gestures. Thus, in the above example, if the gesture recognition module initially assigns the same confidence level to both the gesture corresponding to the \u201cS\u201d shape and the gesture corresponding to the \u201cC\u201d shape, the gesture feedback module may provide the user with icons identifying both gestures and having the same color. As the user continued to complete the \u201cS\u201d-shaped gesture, the gesture recognition module would increase the confidence level in the recognition of the \u201cS\u201d-shaped gesture relative to the confidence level in the recognition of the \u201cC\u201d-shaped gesture. In response, the gesture feedback module may change the color of the icon identifying the \u201cS\u201d-shaped gesture, to inform the user that the confidence level in the recognition of the \u201cS\u201d-shaped gesture has increased.","With still other embodiments of the invention, the gesture feedback module may provide gesture feedback that allows a user to select the execution of one recognized gesture over another recognized gesture. Thus, with the above example, the gesture feedback module may initially display icons identifying both the \u201cC\u201d-shaped gesture and the \u201cS\u201d-shaped gesture. The user can then select the desired gesture by, for example, directing the pointer for the pointing device over the icon identifying the desired gesture and then activating a command button (or making an equivalent action), commonly referred to as \u201cclicking\u201d on the icon. It should be appreciated, however, that a variety of techniques can be employed to both identify two or more recognized gestures and to allow a user to select a recognized gesture for invoking a desired command.","Returning now to , in step  the gesture recognition module  determines if the user is continuing to create the gesture (that is, if the user is continuing to generate position data). If the user has stopped creating the gesture (for example, if the user has lifted the stylus  from the surface of the digitizer ) then, in step , the command represented by the recognized gesture (or the recognized gesture having the highest confidence level) is invoked. If, however, the user is continuing to complete the gesture, then the process loops back to step , and the gesture recognition module  determines if the gesture continues to be recognized in step .","As will be appreciated from this process, a gesture may begin to be recognized before the user has completed the gesture. Moreover, feedback identifying the gesture may be provided to the user before the gesture is complete. Conveniently, if a gesture is being incorrectly recognized as another, undesired gesture, this prompt feedback allows the user to cancel the gesture being incorrectly recognized before the command corresponding to the gesture is invoked. For example, if the user is making a \u201cC\u201d-shaped gesture that is being incorrectly recognized as another gesture, the user may be informed that the gesture is not being correctly recognized by gesture feedback identifying the undesired gesture. When the user realizes that the desired gesture is not being correctly recognized, the user may move the pointing device so as to cancel the recognition of the undesired gesture. Thus, in response to the gesture feedback identifying the undesired gesture, the user may then move the pointing device away from the gesture in a direction that will prevent the gesture recognition module from continuing to recognize the undesired gesture.","Dynamic Gesture Feedback",{"@attributes":{"id":"p-0055","num":"0054"},"figref":["FIG. 5","FIG. 3","FIG. 5","FIG. 6"],"b":["166","203","201","201","307","313","501","203","601","201","307","203","601","313","501","313","603"]},{"@attributes":{"id":"p-0056","num":"0055"},"figref":["FIG. 7","FIG. 8"],"b":["307","203","313","701","203","313","703","203","201","307","203","203","313","701","703","203","313","701"]},"With some embodiments of the invention, the gesture feedback module  can even provide gesture feedback in cooperation with other applications or software tools. For example, some stylus-based computers provide the user with an input user interface that allows the user to create text data with the stylus. Thus, this type of computer may provide the user with a text input panel  as shown in . As seen in this figure, the text input panel may display many of the keys found on a conventional keyboard, such as an \u201cEnter\u201d key . Accordingly, if a user makes a gesture representing a command that is also represented by a key in the text input panel , the gesture feedback module  may distinguish the appearance of a key corresponding to a recognized gesture. With the illustrated embodiment, the user has employed the stylus  to generate handwriting data  corresponding to a \u201c\u201d-shaped gesture  representing a command to enter data. In response, the gesture feedback module  may change the shade, color, or other appearance feature of the \u201cEnter\u201d key  as shown in .","Still further, some embodiments of the invention may employ gesture feedback to assist a user in making a proper gesture. For example, if a user is employing a stylus  with a text input panel to submit data, the gesture feedback module  may display ideal gestures in response to the activation of keys on an input user interface. Thus, if a user employs the stylus  to activate the \u201cEnter\u201d key  in the text input panel , the gesture feedback module  may display the corresponding \u201c\u201d-shaped gesture  in response, as shown in . This type of gesture feedback may be employed to effectively teach a user the gestures representing different commands, thereby allowing the user to forego using the input user interface to execute those commands in the future.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIGS. 11A and 11B","b":["166","165","166","165","307","166","307","313","1101","166","165"]},"As the stylus continues to be held in position, the gesture feedback module  continues to display additional circle images to complete the ring about the point of contact, as illustrated in . That is, the number of circles images  making up the ring is proportional to the amount of time that the stylus  is held stationary, with the final circle image  completing the ring being displayed just before the gesture recognition module  invokes the command corresponding to the press-and-hold gesture. Accordingly, the display of each additional circle image  confirms to the user that the gesture recognition module  is continuing to recognize a press-and-hold gesture. Further, each circle image  is displayed at a time increment proportional to the amount of threshold time that the stylus  must be held in place before the press-and-hold gesture is invoked. The display of this feedback thus informs the user as to how long the user must continue to hold the stylus  in place before the press-and-hold gesture is invoked.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 12","b":["203","1201","307","203","313","1203"]},"As discussed above, the gesture feedback techniques according to various embodiments of the invention provide a user with feedback informing the user regarding recognition of one or more gestures. This feedback may advantageously be employed to confirm to a user that a gesture is being correctly recognized. Further, this feedback may warn a user that a desired gesture is not being correctly recognized, allowing the user to cancel the erroneous gesture before it is invoked.","The invention may include the elements and steps described herein in any combination or sub combination. Accordingly, there are any number of alternative combinations for defining the invention, which incorporate one or more elements from the specification, including the description, claims, and drawings, in various combinations or sub combinations. It will be apparent to those skilled in the relevant technology, in light of the present specification, that alternate combinations of aspects of the invention, either alone or in combination with one or more elements or steps defined herein, may be utilized as modifications or alterations of the invention or as part of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIGS. 2A-2D"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIGS. 5-12"}]},"DETDESC":[{},{}]}
