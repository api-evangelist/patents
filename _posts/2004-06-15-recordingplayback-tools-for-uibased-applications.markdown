---
title: Recording/playback tools for UI-based applications
abstract: Techniques and tools are described for recording input from user actions in a user interface (UI) and replicating the UI activity on a computing device. When recording and replicating UI activity, these techniques and tools improve the readability of the recorded input data and the reliability of playback. The techniques and tools may be used in combination or separately. For example, a recording tool uses a set of filters, which aggregates recorded data into basic, readable primitive methods. The recording tool converts the aggregated data into playback code by converting the playback primitive methods into corresponding computer language instructions. A playback tool may then replicate the initial recorded UI activity by playing back the computer language instructions.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07627821&OS=07627821&RS=07627821
owner: Microsoft Corporation
number: 07627821
owner_city: Redmond
owner_country: US
publication_date: 20040615
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Tools and techniques are described for recording user activity within graphical user interfaces. For example, a tool formats and filters recorded steps performed against a computer application that supports graphical user interface in a meaningful way for readability and playback.","I. Graphical User Interface (GUI)","On many modern computer systems, users interact with software programs through a graphical user interface (GUI). Basically, a GUI is an interface between computer and user that uses pictures rather than just words to solicit user input and present the output of a program. The typical GUI is made up of user interface elements (UI elements), which are those aspects of a computer system or program that are seen, heard, or otherwise perceived or interacted with by a user. For example, UI elements include items such as icons, pushbuttons, radio buttons, dialog boxes, edit boxes, list boxes, combo boxes, scroll bars, pick lists, and various components of World Wide Web pages (e.g., hyper-links and images). In a typical computer program it is common to encounter literally thousands of UI elements.","Although an individual element of a GUI may appear to the user as a single item, it may actually consist of a number of separate items or sub-elements that have been combined together. For example, a toolbar item may consist of a list element, a combo box element, a scroll bar element, etc. Furthermore, each of these sub-elements themselves may be composed from other sub-elements. In this manner, UI elements can serve as building blocks for building other, more complex, UI elements. Such an approach is useful because the software managing the user interface can re-use the definitions of certain common elements when assembling them into composite elements.","Many UI elements in a GUI environment represent features of a program and are displayed on the computer screen so users can interact with the program by selecting, highlighting, accessing, and operating them. This user interaction is done by maneuvering a pointer on the screen (typically controlled by a mouse or keyboard) and pressing or clicking buttons while the pointer is pointing to a UI element. For example, in a word processor, a user can maneuver the mouse to select an item on the program's menu bar, to click an icon from the tool bar, or to highlight blocks of text in the viewer window. Similarly, a user can use keyboard input to interact with a computer application. For instance, in the word processing program, a user can press \u201cALT-F,\u201d \u201cCTRL-B,\u201d or other predefined keystroke combinations to access program features. Based on the input from the mouse or keyboard, the computer adds, changes, and manipulates what is displayed on the screen. GUI technologies provide convenient, user-friendly environments for users to interact with computer systems.","II. UI Automation","UI Automation (UIA) is an accessibility framework for Microsoft Windows intended to address the needs of assistive technology products and automated test frameworks by providing programmatic access to information about the user interface (UI). For example, UIA allows a screen reader program to access information about the user interface of a word processor, which gives the reader program the information it needs to provide audible cues to a visually impaired user. Through an application programming interface (API) set of methods, UIA provides a well-structured mechanism for creating and interacting with a UI. Control and application developers use the UIA API set to make their products more accessible to different users through existing or new software (potentially written by other people) to access program menus and other UI elements. For example, braille screens, screen readers, narrators, and other software in Microsoft Windows can use UIA to facilitate computer use for users who otherwise may not have access.","In practice, UI Automation uses a hierarchy of UI elements located in a tree structure to provide reliable UI information to the operating system and computer applications.  illustrates one such tree structure representation  of a typical GUI on a computer. More particularly,  illustrates how elements of a GUI can be shown as nested within each other in order to accurately describe their organization. At the very top of the tree structure  is a desktop element  that is representative of the GUI's \u201cdesktop\u201d or default background area. The desktop element  has within it several application elements (e.g., A, B and C) for application programs that have been invoked and are ready to execute according to a user's instructions (e.g., a typical Microsoft Windows desktop may have several instances of applications such as Microsoft Word, Microsoft Excel, etc. loaded and ready to execute). At a lower level in the tree structure hierarchy are several frames (e.g., A, B and C) associated with an application B (e.g., a word processor application may have several frames visible to a user at any given time). Within each of the frames (e.g., B) may be several documents (e.g., A and B), each document containing within it several UI elements. Document B B contains controls A, B and C (buttons, listboxes, etc.). UI elements (e.g., A, B and C) may themselves be composites of other UI elements. For example, the element B (such as a dialog box, or a combo box) in turn may contain other UI elements such as a button control at . Furthermore, the button element  itself may contain other UI elements such as control . Such nesting can be arbitrarily deeper and include an arbitrary number of branches depending on the user interface and its component elements.","For some operating system platforms, an instance of a UI element is assigned an identifier to help distinguish that particular UI element from other UI elements. For example, in a Microsoft Windows based operating system, applications are associated with module identifiers that identify applications within a given desktop context. Also, some user interface platforms (e.g., Microsoft Windows, Swing for Java) use a numeric identifier (control ID) for certain UI elements. In some computing environments, such as a Microsoft Windows environment, UI elements are often associated with a class name associated with the control class to which they belong. For instance, in a Microsoft Windows based system, common UI elements such as combo box, list box, and button are associated with class names such as ComboBox class, ListBox class, and Button class, respectively. Similarly, other UI frameworks may have names for their respective classes of UI elements.","Notably, these techniques identify a UI element's object class or type, but do not singularly provide a strong identifier that uniquely identifies a UI element across a reboot of the computer running the program, across a different build of the program when still in development, across the opening of an another instance of the same program, or for opening of the same program on another computer.","UIA overcomes these deficiencies by generating a composite ID that uniquely identifies a UI element in a GUI tree. UIA generates the composite identifier by adding identification information (e.g., control name or control type) that is directly associated with an UI element to hierarchical identification information (e.g., parent control, child control, and\/or sibling controls) and control pattern-specific information (e.g., depth of the UI element in the tree). For example, in , an identifier for target UI element  may be generated by collecting identifying information related to parent UI elements (e.g., , B, B, B, B, and ) that describe the hierarchical arrangement between a target leaf UI element () and the root element at desktop . Through the concept of a path, the related identifiers for a UI element's unique hierarchy and parentage can be leveraged to identify it uniquely and persistently.","The unique identifier (persistent ID) provides easy access to individual UI elements so that the functionality of a program hosting UI elements can be programmed and tested, and so that a particular UI element can be identified to other program modules.","For additional information about UIA, see, for example, the documentation available through the Microsoft Developer Network.","III. UI Recording and Playback","The ability to record and playback a user's interaction with computer applications in a GUI environment has the potential to benefit multiple parties, including users, software developers, and computer support personnel. For example, users benefit by creating macros or scripts that combine a series of inputted actions into a single step playback action. Software developers can potentially use the ability to record user actions to help generate test cases for software under development. Computer support personnel can record user actions to discover the reason for computer crashes or hangs, or to help users understand how to use software. Conventional UI recorders, such as a macro recorder, have attempted to provide some of these benefits to users. However, current recording tools have drawbacks that limit their usefulness.","A main drawback to many conventional macro programs (which are different from a UI recorder that actually records user actions) is that the scripts they generate do not represent an actual step-by-step readable recording of UI activity (e.g., user actions against a UI-based application). Furthermore, these generated scripts often miss some important input steps such as the expansion of selected pop-up menus. The generated scripts show the internal commands and actions taken by the operating system or application to perform a certain function, but they do not show in a meaningful way actions actually performed by the user. Moreover, in many instances, users must independently develop scripts based on a set of scripting commands and complex programming constructs. Thus users have to understand programming logic and, to some extent, the underlying logic of the programs being controlled to create and use a macro. For example, AutoMate, a macro program, uses a drag-and-drop task builder to create a script by dragging and dropping specific steps into the order they should be executed. As another example, consider Macro Scheduler; it is a macro creation program that allows a user to write a macro script using its more than 200 script commands and programming constructs (not including actual declared variables and other user-defined structures). The complexity required to create and edit the scripts generated by these macro programs and the fact that they do not show actual user input lessens those macro programs' usefulness, particularly to novice users and to computer support personnel and software developers attempting to troubleshoot problems.","Other macro creating programs, such as Borland's Superkey, let users create keyboard macros, rearrange the keyboard, and encrypt data and programs. However, they focus just on keyboard input, rather than recording user activity and representing it in a meaningful way.","Many conventional UI recorders have similar drawbacks to those described above, in that they use complex scripting commands and programming constructs to represent data. On the other hand, one drawback to conventional UI recorders that attempt to record actual UI activity is that they record extraneous data that makes output hard to read. Basically, conventional recording tools record everything that happens on the computer, including activity that is irrelevant to the particular task that is the subject of the recording. For example, this irrelevant activity may include Windows messages, unrelated API calls, and extraneous mouse movements. Recording all this extra data floods the recording pipe with actions and messages that are unnecessary for playback and, ultimately, makes the recorder output difficult to read and understand.","Another drawback to conventional recorders relates to problems with the context for playback of recorded data, and these problems are exacerbated by the presence of irrelevant data as described above. A conventional playback component simply plays back the recorded data exactly as the data were recorded. This makes playback inefficient and, in many case, causes playback to simply fail. Part of the reason for failure is that conventional playback is very dependent on the recording computer's pre-existing conditions. For example, playback may depend on a certain hardware configuration, software installation, and\/or the dynamic state of the runtime environment (such as the availability or location of a UI element for a particular recorded interaction). Using a conventional playback tool, any changes to those pre-existing conditions may cause playback to fail. For instance, suppose a user records UI activity at a low monitor\/desktop resolution. Later, the user changes to a higher monitor\/desktop resolution. In this case, playback would most likely fail because the screen position of all the UI elements has changed. Similarly, playback may fail because a call to an unrelated API was recorded and on playback the API does not exist. Hence, as the computer environment changes more, or as larger volumes of irrelevant data are recorded, playback becomes increasingly unreliable.","As another example, suppose user actions are recorded for the following simple activities: the user mouse-clicks a drop down button of a combo box to show a list box with names of states, scrolls through the list box to by moving the thumb wheel of a mouse, and mouse-clicks on an item such as the state \u201cWashington.\u201d When the steps are played back exactly as they were recorded, there may not be the same number of items in the list box, so moving the thumb wheel the same way as recorded may result in selection of a different item. The recorded wheel movement may not even make the item that needs to be selected visible. Or, the item may not even exist in the list box (e.g., if the combo box has an edit control). Finally, if filling the list box takes time, then a synchronization problem may arise. Recording conditions are critical to reliable playback and any changes in those conditions can cause playback to fail.","As noted above, conventional UI recorders frequently do not support synchronization mechanisms, which, depending on the workload of the computer being recorded, the workload of the playback computer, as well as other factors, can cause playback to fail. For example, a user records the necessary steps to launch an application. On playback, the tool automatically tries to run each recorded instruction within a certain amount of time based on the recorded timeframe. If a step fails to finish within the predetermined timeframe, it can cause an entire chain of steps to fail when subsequent steps rely on predecessor steps.","For instance, in a Microsoft Windows 3.1 environment, suppose a recording tool records the series of steps necessary to launch a word processor and open a file in it. On subsequent playback, if the application takes longer than expected to launch, a conventional playback tool would try to open a file before the application is ready, and playback would fail. For additional information about macro recording in Microsoft Windows 3.1, see, for example, the reference entitled, User's Guide for Microsoft Windows for Workgroups, at page .","In conclusion, these prior recording and playback systems provide unreliable techniques for recording and playing back user actions on a computer. Thus, there is a need in the art for tools that record user actions performed against UI-based applications and selectively filter and adjust data to provide more reliable playback. There is also a need in the art for tools that provide more readable output so recorded data can be read, interpreted, and edited according to user needs. Further, there is a need in the art for tools that address the synchronization problems of past recording technologies. These and other advantages may be achieved by the tools and techniques described herein.","Techniques and tools are presented herein for recording and reliably replicating user interface (UI) activity. In various common situations involving UI activity, these techniques and tools dramatically improve the user's ability to interpret and modify recorded UI input, and dramatically improve the reliability of playback to replicate the user activity. For example, the tools and techniques improve the ability to read and playback UI activity through the use of filters and playback primitives.","According to a first aspect, a tool records input data describing user activity in a GUI. For example, the tool receives raw input data from input devices and aggregates the recorded data into meaningful data using filters. Based on the filtered data, the tool may generate playback code to replicate the recorded UI activity. Using this tool and its techniques improves the reliability of playback code by filtering irrelevant data.","According to a second aspect, a tool filters recorded input data into playback primitives. Primitives represent basic actions performed by a user in a graphical user interface that are meaningful for UI recording and\/or playback. For example, the tool filters data from input devices into primitives that are readable and meaningful. The tool uses the primitives to generate readable playback code, which may be edited to enhance playback and then saved.","According to a third aspect, a tool replicates user activity by processing playback code. For example, the tool receives a series of programming instructions that correspond to playback primitives, then processes the programming instructions to play back user actions. This allows the tool to drive a UI-based application.","Additional features and advantages of the invention will be made apparent from the following detailed description of implementations that proceeds with reference to the accompanying drawings.","The following description is directed to techniques and tools for recording and playing back user interaction with a computer. For example, a tool records the steps a user performs when interacting with a UI-based application, represents these steps in a meaningful, human-readable way, and generates code that reflects the steps, where the code may subsequently be played back to recreate the user interaction. In various common situations, these techniques and tools dramatically improve the readability of UI playback code and the reliability of UI recording and playback. The various techniques and tools may be used in combination or separately.","Recording the raw steps (e.g., mouse clicks, keystrokes) that a user performs interacting with a UI-based application is relatively simple; the challenges are in how to represent and process this information in ways that facilitate human review and improve the reliability and robustness of playback. Conceptually, some techniques and tools improve UI recording and playback performance by providing users with an abstract, user-friendly interface through which they may read UI input and convert the UI input into playback code. The raw steps are filtered using filtering techniques and basing the output on a foundational set of limited number of playback primitive methods. A primitive can be a function, an object method, a routine, or other mechanism that is called, and in a particular context may take the form of computer language instruction(s), a definition, a descriptive term, a link, a command, a macro call, a macro routine, or any other similar expression. The filters (or aggregators) that convert raw steps into meaningful output can be defined and adjusted by a user.","The techniques and tools create human-readable output that defines user interaction with a computer. Once the user interactions have been recorded, those actions may be converted into programming code for playback on the same or different computer. The graphical nature and readability of the outputted code generated by these tools and techniques also means new code may be changed, deleted, and\/or added as needed. The components that constitute the recording part of the tool such as collectors, aggregator, and code generator are pluggable and can be replaced by a user.","These techniques and tools make UI recording and playback reliable, since meaningful data is recorded and displayed. Moreover, the tools and techniques provide users with an interface for smooth, reliable playback. The techniques and tools can be implemented in various ways.","The UI recording and playback techniques and tools may be used for various purposes. Technical support is one field of use. For example, suppose a user has encountered a problem using software. With a UI recording and playback tool as described herein, the user records the steps he has performed and sends the log file to the technical support personnel. The technical support personnel then have the information they need to exactly reproduce and analyze the steps performed by the user so as to spot a problem with the software or the user's interaction with it.","Software testing is another field of use. For example, suppose a tester is supposed to evaluate a new UI-based application program for robustness in various scenarios. With a UI recording and playback tool as described herein, the tester quickly generates tests against the UI-based application by recording his steps and generating test code.","End user macros and scripts are yet another field of use. For example, suppose a user routinely performs a procedure with a UI-based application. With a UI recording and playback tool as described herein, the user records the procedure as a script and plays back the script when he needs to perform the procedure.","I. UI Recording and Playback Tool","The UI recording and playback framework described herein is an extensible framework designed to facilitate the recording and playback of UI activity.  shows an exemplary UI recording and playback tool  in which the techniques described herein may be implemented. This tool includes elements of software and\/or hardware. As input, the tool  receives information from one or more user input devices  such as a mouse, a keyboard, a touch pad, touch screen, Braille screen, joystick, microphone, or other similar device. Also it may monitor events from the operating system. The tool  receives the input data and produces playback code  that, when sent to a playback module , replicates the recorded meaningful user activity. The playback code  may be output in a variety of programming language formats, including C#, XML, C++, JAVA, or any other similar programming or document-oriented language. The code  may be played back on the same computer or, alternatively, on a different computer(s). In some implementations, the code is automatically interpreted by the UI recording and playback tool .",{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 2","b":["200","220","250","260","200"]},"The recording module  records data received from the input device(s)  and events raised by the operating system. The input data is derived from actions performed by a user in a GUI environment (e.g., from raw user input actions like mouse movements, mouse clicks, and keystrokes). The recording module  uses a pluggable set of filters to aggregate the recorded data. The aggregated data is represented using a set of playback primitives, which abstractly indicate the basic recordable actions performed by a user. One implementation, as illustrated in , uses 14 kinds of playback primitives to represent recorded data. Alternative implementations may use more or less kinds of primitives.","The playback primitives provide a meaningful and effective way to represent the set of recorded user actions and operating system events. The recording module  displays recorded data as playback primitives in a viewer, such as a debugger window, source code browser, or text editor so users may read and browse the data for errors. Once the recorded data has been filtered, it is saved to a file, such as a log file, a text file, or other similar structure for analysis. In alternative implementations, the tool includes additional and\/or different modules for presenting or recording the UI data.","After the UI recording and playback tool  aggregates the recorded data, the tool  generates reliable playback code . Using the data received from other modules, the code generating module  maps recorded UI information to corresponding instructions in an output programming language. For example, the code generating module  converts each instruction from the recorded data into a corresponding instruction in C#. Alternatively, the code generating module  converts the recorded data into another programming or document-oriented language.","As illustrated in , the code generating module  is pluggable to the recording module , so a developer can reuse a recorder but change the way code is generated by switching to another code generator. In alternative implementations, the code generating module  is separate from the recording module , or more tightly integrated. The generated playback code  may be viewed, saved, edited, modified, added to, deleted from, compiled, or otherwise used prior to playback. In alternative implementations, the tool includes additional and\/or different modules for generating playback code from the recorded UI data.","Once the playback code  has been generated, it is sent to the playback module . The playback module is in essence an engine used by a program to programmatically control a UI-based application. The playback module  receives as input the generated playback code  from the code generating module  and processes the code , replicating the recorded UI activity through programmatic interaction with the UI-based application. In one implementation, the playback module  compiles the code before running it. In other implementations, the tool includes additional and\/or different modules for code playback.","A. The Recorder","A recorder tool records mouse and keyboard input as well as other important input events, such as focus change, selection change, window creation, etc. The recorder tool may be incorporated into the UI recording and playback tool  of  (i.e., as the recording module). Or, the recorder tool may be a separate tool.","This recorder tool is extensible and includes a pluggable and adjustable filter designed to facilitate the recording and display of UI activity.  illustrates such a recorder tool  (or, alternatively, the recording module  of ). The recorder tool implements techniques described herein. This tool includes elements of software and\/or hardware. As input, the tool  receives input from input device(s)  and events from the operating system. The tool  converts that input into playback code .",{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 3","b":["300","320","330","340","300"]},"1. The Collector","The collector  is an extensible module whose purpose is to collect UI-related data. Basically, this module is responsible for monitoring input device activity . In some implementations, the collector  monitors input activity in conjunction with UI system architecture software  such as UI Automation (UIA) software. GUI technologies like UIA create a framework that allows UI information to be accurately recorded and played back. In other words, UI system architecture software  provides a robust framework for acquiring input data; its output is predictable and reliable. In other implementations, the UI system architecture software  follows the Microsoft Active Accessibility (MSAA) framework. In still other implementations, a different UI system architecture is used.","In UIA, each UI element is uniquely identifiable by a persistent ID. The collector , in UIA implementations, uses the persistent ID to identify UI elements that have been accessed by a user during recording. In addition to the persistent ID, the collector  may maintain additional information relating to a user's actions. For example, the collector  collects information about the runtime environment, keeps track of running applications, OS version, localization information, default UI language, current UI language, hardware devices and configurations, security modes, and\/or other data that may help describe or recreate the proper environment for reliable playback. Similarly, other information relating to recorded mouse\/keyboard actions and UIA events may also be recorded. For instance, the time of an action is recorded, the state of keyboard (e.g., CTRL key is pressed), the name, class, and type of a UI element, mouse coordinates, etc. Different implementations record combinations of all these factors and\/or additional user actions or events.","The collector  identifies the target of user input and records it, along with other meaningful information, as noted above. Basic recordable input may be divided into three categories: mouse actions, keyboard actions, and other events. Mouse actions include input data received from a mouse, e.g., pressing the left button, clicking the right button, moving the mouse, moving a thumb wheel, etc. Recorded keyboard actions include keyboard input such as pressed keys, keys pressed with the CAPS lock or Num-lock on, keys pressed in combination with other keys (e.g., CTRL-S or ALT-F4), etc. Data from other input devices may also be recorded. Finally, other events are recorded; other events include categorized events such as select events, expand events, and value change events.","Select events involve identifying when a user selects or unselects a UI element. When a user selects (by left-clicking with their mouse) one of a number of elements in a list, that event is recorded. Or, if a user unselects an option that event is also recorded. For instance, on some registration web pages, a user is presented with a check box option to \u201copt into\u201d receiving subscription email from the site's sponsor. If the user checks the box, that select event is recorded. Similarly, if the user unchecks the box, that unselect event is recorded. One of the reasons for tracking this type of event is to provide consistent, reliable playback. For example, suppose an element selected during recording is already selected on playback. Playing back the data as a recorded mouse click, without taking select events into account, would cause the element to be improperly unselected\u2014playback would click the element changing it from a \u201cselected\u201d state to an \u201cunselected\u201d state. This creates inconsistencies between the playback's expected result and the actual result. Hence, the collector  records a select event rather than the just the action (e.g., the user clicking on the UI element). By doing so, the tool  facilitates consistent and reliable playback.","In addition to select events, the collector  records expand events. Expand events include those instances when a list, menu, tree, or other expandable UI element is expanded or collapsed. For example, in versions of Microsoft Outlook, a user clicks on a \u201c+\u201d symbol to expand and show all of their mailbox folders. Alternatively, a user collapses the expanded list of mailbox folders by clicking on a \u201c\u2212\u201d sign. A reason for tracking this type of event is to provide consistent, reliable playback. For example, on playback, an element expanded during recording may already be expanded on playback. As noted above in connection with the select event, under normal circumstances, this may cause playback of a mouse click to fail since the actual result may differ from the expected result. Hence, the collector  records an expand event rather than just the mouse click action.","The act of hovering over an expandable UI element may create recording problems for conventional recording systems. For example, suppose a computer application includes a menu bar which has the menu items \u201cFile,\u201d \u201cEdit,\u201d \u201cView,\u201d \u201cFormat,\u201d and \u201cHelp\u201d that expand when a user hovers the pointer over them. In this case, a user hovers over \u201cFile,\u201d causing the \u201cFile\u201d menu to expand. At this point, the user is presented with additional \u201choverable\u201d options, such as \u201cNew\u201d and \u201cSave.\u201d When the pointer hovers over \u201cNew,\u201d a side menu expands, revealing further options such as \u201cProject\u201d or \u201cFile.\u201d The user selects \u201cProject\u201d from the \u201cNew\u201d side menu, launching a new instance of a Project. In this example, a conventional recording system would not record the expand events since no discernible user action (e.g., a mouse click) caused the menus to expand. Playback by the conventional systems would fail since important steps in the process would not be recorded. The collector  records this type of expand event.","Additional optimizations may be implemented to prevent the collector  from recording extraneous hover-expand events. For example, in the scenario described above, suppose the user hovers the pointer over \u201cNew,\u201d automatically causing its side menu to expand, and then moves the pointer down the \u201cFile\u201d menu and hovers over \u201cSave,\u201d causing another side menu to expand. As described above, the collector  records both expand events, even though one of the events (New) is extraneous. Recording this extra information typically will not cause playback to fail, but may cause playback to be inefficient. Moreover, the extra data may make reading the recorded input more difficult as troubleshooters and software developers sort through the data to decipher what actions a user input into a UI.","To avoid these problems, in some implementations, expand events are placed on a stack with an associated hierarchal identifier. The stack is maintained by the collector  or by some other module of the recording tool . The hierarchal identifier represents a level within the UI hierarchy (e.g., where the expand event element is located in the UI tree). For example, in the scenario above the \u201cFile\u201d menu option is assigned a level one hierarchal identifier when it is at the first level within the UI hierarchy. \u201cNew\u201d and \u201cSave,\u201d are then each assigned a level two identifier, and elements of the side menus are assigned level three identifiers, since they are three levels down in the UI hierarchy.  in the top right-hand window illustrates a sample hierarchal structure.","As each expand event takes place, information about the event is added to the stack, including the hierarchal identifier. Once a non-expand event takes place (e.g., user clicks on \u201cProject\u201d), entries on the stack are popped off and entries with superseded hierarchal level identifiers are filtered out so only the most recent expand event is recorded by the collector .","For example, when the user expands \u201cFile,\u201d an entry (including a hierarchal identifier) is made to the stack. As the user hovers the pointer over \u201cNew,\u201d another entry, with an appropriate identifier, is added to the stack. If the user hovers over the \u201cProject\u201d option on the \u201cNew\u201d side menu, a third entry is added to the stack. Subsequently, the user moves the pointer down the File menu and hovers the pointer over \u201cSave,\u201d and then its side menu option \u201cDocument;\u201d two new entries are added to the stack. When the user clicks on \u201cDocument,\u201d the most recent stack entries with unique hierarchal identifiers are retained. In some implementations, as new stack entries are made, previous stack entries with hierarchy identifiers equal to or greater than the current identifier values are deleted or overwritten to limit the size of the stack to the depth of the UI tree. Numerous implementations could be employed to maintain the stack, including use of an array, linked list, or other data structure in memory, on disk, or otherwise accessible to the collector  and\/or recording tool .","The collector  also tracks value change events. Value change events are events where the value(s) contained in a UI element change. For example, suppose an edit box initially contains the string \u201cABC,\u201d and a user adds the letters \u201cDEF\u201d to the box. The result of these actions is the edit box containing the six-character string \u201cABCDEF.\u201d Normally, conventional recording systems only record added input, so, on playback, they would only play the string \u201cDEF.\u201d Obviously, this may cause inconsistent playback results. To address this concern, on playback, the collector  records the final value contained in certain UI elements. There is at least one notable exception.","Certain sensitive forms of data may not be recorded. For example, data entered into a detectable password field is not recorded. On playback, when a password field is encountered, the user is prompted to enter the password rather than having it automatically filled. Alternatively, bogus information such as zeroes or stars could be entered into the password field. In some implementations, UI elements requesting sensitive data are designated by the application provider. Alternatively, the user designates fields containing sensitive data.","Referring again to , once actions and events have been recorded, the collector  outputs the recorded data to a collector queue . The collector queue  includes the combined and processed input data from the input device(s)  and UI system architecture software  before being parsed and filtered by aggregators . The collector queue  is of a fixed size (i.e., an array of data) or alternatively, it is of variable size (i.e., a linked list). Depending on implementation, the filtering does not commence until all data has been recorded, or the recorded data in the collector queue  is filtered as it is collected, or the collector queue  data is filtered on a convenience basis, for example, when the computer has a lighter workload.","2. Aggregators","The aggregator  illustrated in  is an extensible tool whose purpose is to eliminate redundant data without loss of essential information. This allows a UI recording and playback tool such as the tool  shown in  to avoid generating and playing back code for steps that are not necessary to replicate UI activity. At a high level, the aggregator  performs a first set of tasks to screen out certain categories of UI data and capture other categories of UI data, and concurrently or subsequently performs a second set of tasks to streamline or simplify the UI data.","For the first set of tasks, for example, the user defines one or more patterns for UI data that the aggregator  should record, and the user defines one or more patterns for UI data that the aggregator  should filter out. The user sets any number of entries for different patterns. Each entry includes information such as a description of an action, an identifier of the UI element that playback should interact with for the action, an identifier of the parent UI element, an identifier of the container (e.g., window) that owns the interacting UI element, mouse pointer coordinates relative to the top, left corner of the interacting UI element, and a timestamp. These items typically provide enough information to find a UI element and handle timing problems on playback. One combination of the items is, for example, the action \u201cselect item\u201d for a list item with identifier \u201citem\u201d which belongs to a list box with the identifier \u201clist\u201d which is owned by a container \u201cwindow.\u201d One example of a record pattern is: always show a mouse left-button click on a UI element with a button identity. An example of a filter out pattern is: never show a mouse left-button click on a UI element with an edit box identity. The actual parameterization of these patterns depends on implementation.","For the second set of tasks, for example, the user defines one or more patterns for UI data that should be absorbed into\/replaced by later UI data, and the user defines one or more patterns for UI data that may be combined with other UI data as specified in the pattern(s). Again, the user sets any number of entries for different patterns, and each entry includes information such as mentioned in the previous paragraph. One example of an absorbing pattern is: if previous and current steps are changes to a value in an edit box, do not record the previous one, but instead just record the current one that has the more recent update. An example of a combining pattern is: if steps are mouse clicks on the menus File, New, and Project, they may be combined into one File->New->Project step. Again, the actual parameterization of these patterns depends on implementation.","A simple aggregation example is as follows. Suppose the following recorded steps are in the collector queue , where the numbers in (x, y) format represent pointer coordinates: Mouse Button Down(10,10), Mouse Move(10, 10), Mouse Move(20,20), Mouse Move(30,30), and Mouse Button Up(30,30). The aggregator  reduces that set of recorded instructions to something more user-friendly such as Mouse Drag(start(10,10), end(30, 30)).","The aggregator  applies an extensible set of rules to the data collected in the collector queue  and transfers the aggregated data to an aggregated list  of instructions. For example, the aggregator  parses an XML rules sheet to identify aggregation rules, then applies those rules to collected data, and finally transfers the aggregated data to the aggregated list . In other implementations, other rule application mechanisms are used.","The filters in the aggregator  help make recorded UI activity more readable and accessible. The final output of the aggregator  can be human-readable output, compiled code, a set of API instructions, or other form of information to control playback. Depending on implementation, the aggregator  applies filters to recorded data as it is being recorded, or the aggregator  applies the filters to the data once it has been recorded. One exemplary form of output is illustrated in the tracking dialog (main window) of .","Consider for example, a scenario where a collector  records the following UI activity: a user clicks on a File menu, selects \u201cNew,\u201d types in the name of a project, and presses the \u201cEnter\u201d key. As listed here, there are four main actions and events: clicking on the file menu, selecting \u201cNew,\u201d typing the name of the project, and pressing the \u201cEnter\u201d key. However, in the process of recording these main actions, a lot of other input data has also been recorded. For example, mouse coordinates as the mouse moves from one location to another, extraneous mouse clicks, and irrelevant keystrokes (including \u201cBackspaces\u201d and \u201cDels\u201d) can be included in the collected data. As user activity increases in size, duration, and complexity, so does the amount of collected data. That data is filtered into meaningful information.","The aggregator  filters the data in the collector queue  into readable actions and events. Four types of filters are used on the recorded data: removing filters, keeping filters, absorbing filters, and combining filters. Each filter is selectable so a user may decide which filters will be applied to recorded input data, and a user may create user-defined filters to make the recorded input data more readable, more useful, or otherwise more descriptive of meaningful actions. Alternatively, other filters are used, more or fewer filters are used (e.g., by combining or splitting functionality in the four filters or adding new filters), or the filters follow pre-defined templates or patterns that give the user less control in customizing filtering.","The aggregator's  removing filter is a filter that removes unnecessary input data from the collector queue . For example, a user may decide to filter out clicks on the scroll bar because they are irrelevant to the actual steps necessary for playback, so the user establishes a removing filter rule for screening out such input. Or, the user creates filters to filter out right-clicks, API calls, windows messages, a specific UI element based on its ID, clicks on a menu bar, password information, application data, and\/or any number of other actions or events. By removing this type of data from the collector queue , the aggregator  keeps the relevant input data for display and playback; Basically, it makes the recorded data much easier to read and troubleshoot, and it removes data that incorrectly affects playback performance.","A keeping filter ensures certain types of data are reflected in the recorded output . For example, a user may set a keeping filter to keep all the input data related to a specific application, to retain input data related to left-mouse clicks for a specific UI element, to retain input data related to keystrokes, and\/or to record data based on any number of other factors. In some implementations, the keeping filter overrides conflicting setting in other filters.","The aggregator  also implements an absorbing filter that absorbs strings of data into one instruction. For example, when a user types a hundred characters into a word processor, instead of recording a separate instruction for each keystroke, the absorbing filter aggregates the data into one string. That string is recorded and output as one action in the aggregated list . The user may set the maximum or minimum number of entries that may be absorbed into one action.","Finally, the aggregator  uses a combining filter to combine multiple user actions of different types into one action. For example, left-clicking a mouse button, repeatedly moving the mouse, and finally releasing the mouse button may be combined into one drag-and-drop step. Basically, dozens or hundreds of recorded actions may be collapsed into a single command.","A user defines the set of filters used by the aggregator  to aggregate recorded input data. This may be accomplished by presenting the user with a dialog box or other similar UI element where the user selects and\/or defines the filters. The filters are basically patterns or rules that keep, remove, absorb, or combine input in specific ways. For example, a user is presented with a dialog box with four separate tabs, one for each of the four filters discussed above: removing filter, keeping filter, absorbing filter and combining filter. In this example, each tab allows a user to define filters by presenting a template pattern with one, two, or more fields that the user fills in to define the filter pattern.","In UIA implementations, the filters may contain the UI element's persistent ID. For instance, on the removing and keeping filter tabs a combo box allows a user to select from a list, based on persistent ID, which UI elements to remove or keep in the aggregated list . Similarly, the absorbing and combining tabs may have a series of combo boxes that allow users to define which UI elements should be absorbed and combined together. The user may use Boolean expressions to define combining and absorbing filters. Other implementations use other techniques for selecting and defining filters.","The following scenario describes how a user, presented with the tabbed dialog box described above, defines an absorbing filter. In this case, the user accesses the absorbing filter tab, which contains a dropdown list box that allows the user to select absorbable UI elements based either on their persistent ID or any set of identifiers such as name, class name, type, etc. Here, the user wants to absorb value changes in a combo box such as one commonly encountered on a registration Web page. For example, suppose a registration page requests a user to enter a billing address and, as part of the billing address, the user is presented with a combo box, listing all of the states in the United States. The act of selecting a state from the combo box's list involves expanding the combo box list, scrolling down the list, and selecting a state from the list. A recording tool recording this process will record the mouse movements required to activate the list, the click to expand the list in the combo box, the changes in value as the user scrolls through the list, the selection of an item in the list, the change in the value of the combo box, etc. To define the absorbing filter that aggregates these steps into one action, from the absorbing tab, the user selects the UI element ID that corresponds to the list of states and the UI element ID of the combo box. The user then proceeds to define additional properties of the filter. For example, the user defines that when the list element is a child of the combo box, only changes in the combo box's value should be recorded. The following table illustrates how a filter rule may look, where the UI data in first column are absorbed into\/superseded by the UI data in second column:",{"@attributes":{"id":"p-0087","num":"0086"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"105pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["UI element ID A","UI element ID B"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["action = selected","action = value changed"]},{"entry":["type = list","Type = combo box"]},{"entry":["immediate parent type = combo","Immediate parent type = DontCare"]},{"entry":"box"},{"entry":["immediate parent name = B.name","Immediate parent name = DontCare"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"This means that if the action \u201cvalue changed\u201d on element B is recorded after the action \u201cselected\u201d on element A, then the line that reflects the action on element A is hidden by the filter.","After a user defines the filter rules, those rules are saved in an XML file or other kind of file that can later be re-loaded (and edited). Thus, a user defines one or more filters parsed and used by the aggregator  to aggregate data in the collector queue .","Alternative implementations use a filter-defining interface with more or fewer tabs, or use a different type of interface to define filter rules, or use preset filters that attempt to optimally filter data according to some pre-defined criteria.","In summary, the aggregator  converts the data in the collector queue  into readable data that may be displayed in the aggregated list . In some implementations, the aggregator  filters the data in the collector queue  into primitives.","3. Playback Primitives","Playback primitives are basic recordable playback units. Conceptually, playback primitives are a limited set of descriptors for efficiently representing user actions input into a UI. More concretely, playback primitives are function calls, method calls, or other instructions to control the functionality of a playback component such as the playback module  of . The limited set of playback primitives is used to programmatically control a UI-based application through the playback component, which implements the functions, methods, or other functionality for the instructions. Because the playback primitives are somewhat abstract, the primitives are by-and-large application independent, allowing reuse across many different kinds of UI-based applications. Users can easily learn how to work with the relatively small number of playback primitives, and the playback primitives are intuitive, which makes it easier for users to record activities interacting with UI-based applications and generate robust playback code for the activities.","For example, for the sake of comparison, reconsider the example introduced in the Background in which a user clicks on a combo box's dropdown button and scrolls through a list of states to select a state. Prior UI recorders often fail to provide correct playback due to changes in the constituents of the list. With a playback primitive, instead of recording every step and mouse movement, the collective action is recorded as a single playback primitive such as SetComboBoxString (\u201cWashington\u201d). This simplifies UI activity output and provides a mechanism for robust playback even when, on playback, the list of items has changed. Whereas performing the scrolling actions exactly as recorded may not highlight the proper item, the playback primitive above avoids that issue by simply inputting the proper item into the combo box. Moreover, playback primitives typically provide more human readable output.","The number, syntax, and semantics of playback primitives are implementation dependent, but experimentation has indicated that around fourteen primitives provide a solution that balances the need for readably illustrating UI activity, while still providing enough data to drive UI-based applications efficiently and reliably.  list the fourteen input-related playback primitives (as well as two additional methods as discussed below). The primitives are implemented so they use mouse and keyboard input to interact with UI elements. Because the playback primitives are based on recognizable standards (mouse and keyboard technology), they are basically technology independent in terms of interaction. Most input devices use mouse and keyboard channels to input data, which means recording mouse and keyboard input allows UI activity to be accurately determined no matter what input device is used. As standards change for input data, other input data channels may be monitored to record data from input devices.","In addition to the fourteen input-related playback primitives, two additional methods are illustrated in : Verify and Verificationinfo. These two primitive methods support verification of a UI element, e.g., whether it is available and visible for interaction on playback, whether it is selected, etc. For example, on playback, the Verify method may be used to check if a UI element is available and is in the correct state. This can be done for pure testing purposes or for verification of whether the target application is ready for the next step. For example, a target application has a button that becomes \u201cenabled\u201d when a listbox item is available for selection. In this case, the Verify method may repeatedly check to see if an appropriate listbox item is available and notify the proper playback component when the button becomes enabled (e.g., ready to be pushed). While these verification methods are implemented as part of the set of primitives in , alternatively, another application, or other method verifies the availability of UI elements and information related to them.","An additional benefit of having small number of playback primitives is that it is easier to generate unambiguous playback code using them. The primitives as illustrated in  are: \u201cEnsureVisible\u201d (ensures a UI element is visible on the screen), \u201cLeftButtonClick,\u201d \u201cRightButtonClick,\u201d \u201cDoubleClick,\u201d \u201cSelect,\u201d \u201cSetValueAsComboBox\u201d (sets a value selected for a combo box in a drop-down list and other similar UI element in the combo box), \u201cSetValueAsEditBox\u201d (sets a value (e.g., absorbed from multiple entered values) for an edit box), \u201cCheck,\u201d \u201cUncheck,\u201d \u201cExpand,\u201d \u201cCollapse,\u201d \u201cSendKeys\u201d (represents input keystrokes), \u201cStartDragging,\u201d and \u201cStopDragging.\u201d As noted above, these primitives form one exemplary set of descriptors\/methods that may be used to represent input data and drive UI-based applications. Alternative implementations combine these primitives into a fewer number of primitives, separate them into a greater number of primitives, or introduce other and\/or additional primitives.",{"@attributes":{"id":"p-0098","num":"0097"},"figref":"FIG. 5"},"Action in this context refers to those actions a user can perform interacting with a Ul-based application. For example, the list of actions includes those primitive action listed in , e.g., LeftMouseClick, RightMouseClick, LeftDoubleMouseClick, etc. The list also includes primitives for verifying the state, value, etc. for UI elements. (For these primitives, the actual values associated with the type UIelementVerificationInfo depend on what needs to be verified, and may include, for example, name, class, type, or state.) The Container ID is a persistent ID. More generally, the Container ID includes a set of attributes that define the container. For example, the Container ID includes properties such as application name, hierarchal identifier, class type, container name, etc. The container acts as the starting point for a search for a UI element. At the same time, the container may be used to guard against synchronization problems.","The UIelement ID is the persistent ID of the UI element. More generally, the UIelement ID includes a set of attributes that define a UI element. For example, the UIelement ID includes application name, UI element name, and class type of the UI element.","In order to make the function signatures in  more readable, container ID and UIelement ID are used as parameter types. In practice, as noted above, each of these IDs can have multiple items of information associated with it. Container ID and UIelement ID may be implemented as classes so objects of these classes are initialized before they are sent as parameters to a primitive. Or, each attribute may be sent as a separate parameter, or the primitives are implemented in a different way.",{"@attributes":{"id":"p-0102","num":"0101"},"figref":"FIG. 7A","b":["335","1","7","8","12","4","7","13","16","17","19","20"]},"At several of the illustrated steps in , multiple user actions and\/or events have been filtered into a readable, meaningful playback primitive. For example, step  combines multiple steps (such as mouse movements and a left click) into one simple, readable primitive that plainly shows that the user left-clicked on the \u201cStart\u201d button.","Referring back to , recorded data that has been filtered into playback primitives is converted into playback code .","4. Code Generator","The code generator  is an extensible component whose purpose is to convert an aggregated recorded step list into programming language code, scripting code, or other commands or instructions for a playback interface or other mechanism to drive UI-based applications. For example, the code generator  parses an XML rule sheet that describes how to convert playback primitives into playback code and applies those rules to the data in aggregated list , generating playback code (e.g., a set of commands and\/or programming instructions) to drive a UI-based application via a playback component. The playback code includes function calls, method calls, or other instructions to control the functionality of a playback component. Basically, there is a relation between the code generator  and the playback module  from , since the output of one matches the expectations of the other. In some implementations, there is a direct correspondence between the playback primitives in an aggregated data list, the set of commands and\/or programming instructions in the playback code, and functions called in an interface of the playback component (which are sometimes themselves be called primitives).","Other information may be used to help convert the playback primitives into playback code .  illustrates some of the additional data that may be captured and used. For example, information such as the point coordinates for mouse clicks, string values, container information, persistent ID, timestamp information, and other similar factors is maintained to facilitate generating the playback code.",{"@attributes":{"id":"p-0108","num":"0107"},"figref":["FIGS. 6A and 6B","FIG. 7A","FIG. 7A","FIG. 6A","FIG. 6A","FIG. 7A","FIGS. 6A and 6B","FIG. 7A"],"b":["1","12","340","1","610"]},"Once the code generator  has generated the playback code , the playback code  may be modified, edited, added to, or deleted from. Being able to edit the playback code  provides users with a convenient and powerful mechanism for creating macros, generating automatic test cases, automating steps in a program, etc. The generated code may be edited to add conditional expressions, to change variables, to add loops, and other programming instructions to the code. For example, on playback, suppose a piece of playback code alters a system file and requires that a user to be logged on with Administrator rights. So, a conditional expression is added to the playback code, which checks for the appropriate rights before running the piece of code. As another example, suppose software developers want to stress test a program by repeating the same series of instructions over and over again; so, a for loop is added to the playback code, which causes the playback code to be repeated a certain number of times.","In summary, the code generator  generates playback code  that may be played by a playback component. It provides the ability to edit the playback code, which creates a versatile and robust environment for replicating UI activity.","5. Recording Method",{"@attributes":{"id":"p-0112","num":"0111"},"figref":["FIG. 8","FIG. 3"],"b":["800","300","800","800","300","800"]},"The recording tool converts UI input into playback code by identifying and recording the targets of input devices  such as mice and tracking keystrokes . The process of recording UI input continues until a user selectively terminates the recording process or until a designated UI element has been accessed and\/or a number of UI elements reached .","The tool aggregates the recorded data into meaningful, readable output  and converts the aggregated data into playback code . For example, using a set of defined filters, the tool aggregates the input data  by removing, keeping, combining, and\/or absorbing input data, and the filtered data is represented using a limited set of playback primitives. Once UI input data has been recorded and aggregated, the tool generates playback code based on rules associated with converting primitives to code .","Alternatively, various stages of the technique  are separately or in various combinations performed in conjunction with other stages. For example, while  shows the aggregation  and conversion  occurring after there is no more UI input, alternatively aggregation  is performed concurrently with raw UI input recording.","As for the user interface for the tool, initially, the tool presents a user with an interface such as the interfaces illustrated in .  illustrates a recorder tool located next to the Start menu button, which allows users to record and actively view the recorded input.  shows another implementation of the recording tool pinned to the Taskbar, which allows a user to start and stop the recording process without interrupting other computer activities. The displayed interfaces are operated like a VCR. A user presses a \u201cRecord\u201d button (alternatively a \u201cPlay\u201d or \u201cStart\u201d button) to begin recording data. To interrupt the recording process, the user presses the \u201cPause\u201d button. The \u201cStop\u201d button stops the recording process. Alternatively, different user interfaces are used to record UI activity.","B. Playback","A playback tool replicates UI activity by receiving playback code and driving UI-based applications using the code. The playback tool may be incorporated into the UI recording and playback tool  of  (i.e., as the playback module). Or, the playback tool may be a separate tool.",{"@attributes":{"id":"p-0119","num":"0118"},"figref":["FIG. 9","FIG. 2"],"b":["900","260","900","950","340"]},"The playback tool  is an extensible tool whose purpose is to read and interpret playback code because, as input, the tool  receives playback code  from a code generator such as the code generator  illustrated in  or elsewhere. In connection with code playback, the tool  also interacts with a set of APIs and\/or system files  (e.g., Win32 APIs) and UI system architecture software  (e.g., UI Automation). In some implementations, the playback tool is a software service exposed through an API. Alternatively, the playback tool is a stand-alone application that programmatically controls UI-based applications. The playback tool itself may interact with UI-based programs through the set of APIs  or through application-specific mechanisms.","The playback tool may be configured to indicate how playback is to take place. For example, the tool is configured to replicate only mouse clicks, or only keystrokes, or only mouse clicks and keystrokes, or any combination of these actions and events. Moreover, the playback tool may be configured to pause during playback. For example, the user clicks a \u201cPause\u201d button on the playback tool to pause playback while the user responds to an email. Or, the tool pauses when user input is required to continue processing the playback code. In some implementations, multiple playback scripts are run simultaneously against separate applications. The playback tool provides these and other configurable options.",{"@attributes":{"id":"p-0122","num":"0121"},"figref":"FIG. 9","b":["900","910","920","940","930","900","900"]},"The reader module  of the playback tool  receives playback code , verifies the code , and passes the code  to the player module . Verifying the code consists of an intelligent verification of the steps or instructions listed in the playback code for an action to be completed. For example, the playback tool receives a file containing playback code and attempts to verify that the file is internally consistent and consistent with the current status of the system. If a UI element listed in the playback code cannot be found, the user is notified, and, in some implementations, the user is asked to manually complete the step. Alternatively, playback is terminated.","The reader module  assembles the code  into a format executable by the player module , and passes the formatted code to the player module . In some implementations, the reader module  or, alternatively, the player module  directly implements the functionality of the primitives called in playback code . For example, for playback primitives expressed as function or method calls in the playback code , the player module  implements the playback primitive functions or methods called to control the UI-based application.","The player module  replicates UI activity by implementing the functionality called, scripted, or otherwise controlled by the playback code in a uniform way. Playback code  represents a sequence of recorded user actions and events converted into code. In some implementations, the playback code is self-executing and requires no additional input or action by a user or tool. Alternatively, these actions are put into an internal action queue , which allows the player module  to process each action or event in order.","Processing an action by the player module  involves the following steps: (1) get an action from the action queue ; (2) find\/wait for the appropriate UI element or container to open (and verify that the window is visible, enabled and ready for input); (3) wait for the target process to be ready for user input; (4) find the targeted UI element in the window; (5) ensure that this UI element is visible when necessary; (6) if the UI element has a window associated with it, verify that the window is visible, enabled, and ready for input; (7) wait for the target process to be ready for user input; (8) perform the action; and (9) report the result of the action to the playback tool  or elsewhere.","If any of steps , ,  and  fail, the processor module  waits a certain period of time before attempting the step again. This allows playback failures to be handled gracefully without crashing the playback tool or any other associated applications.","Performing playback in this way also avoids the synchronization problems of conventional recording systems. Moreover, if a technology other than mouse and keyboard is used for user input and driving a UI-based application, on playback, these steps are discrete and simple enough that only step  is changed. For instance, assume that step  performs the action of expanding a UI element by calling an Expand( ) function when a mouse cursor passes over the UI element. If a different mechanism is used to control the expansion\/collapse of UI elements for an application, the player module  simply redirects the Expand( ) call to the appropriate API  or other function. Alternatively, the call is simply changed by the player tool  or its other support modules . Hence, the UI system architecture software  and APIs  provide the application support for replicating recorded actions.","In summary, the playback tool  receives playback code  and processes the code  in conjunction with its support modules to accurately and reliably replicate recorded UI activity.","1. Playback Method",{"@attributes":{"id":"p-0131","num":"0130"},"figref":["FIG. 10","FIG. 9"],"b":["1000","900","1000","1000","900","1000"]},"The tool receives playback code generated from a series of aggregated UI actions , verifies actions in the series , and processes the series of actions . In some implementations, the playback code is placed into a queue and each action in the series is processed in order. Alternatively, user actions are received one at a time from a separate tool. For example, a code generating tool transmits one instruction at a time to the playback tool implementing the technique .","Verifying the user actions  includes such tasks as making sure that a UI element exists, that the persistent IDs are correct, that the application containing the UI element is visible and ready for input, and other such factors. If a user action cannot be verified, the user may be prompted to terminate playback or, alternatively, to enter the information or perform the action.","Processing user actions  involves replicating each user action as smoothly as possible with little or no interference by a user. The tool performing the technique  communicates with UI system architecture software to provide proper instructions to applications. Alternatively, the tool communicates directly with the application(s) through APIs or another mechanism.","Various stages of the technique  may be separately or in various combinations performed in conjunction with other stages.","II. Method for UI Recording and Playback","To summarize the preceding discussion with reference to a combined implementation,  illustrates a technique  for converting UI input into playback code. A tool such as the UI recording and playback tool  shown in  performs the technique , and the ordering of stages in the technique  generally tracks the modules of the tool . Alternatively, another tool performs the technique , or a group of tools performs the technique .","The tool records and aggregates input data by using filters , generates code based on the aggregated data , and replicates the UI activity by playing back the code , driving UI-based applications. In some implementations, the playback stage is performed by a component independent of the tool. Various stages of the technique  are separately or in various combinations performed in conjunction with other stages.","A recorder tool or other recording module performs the first stage  of the technique. Various screen shots illustrating implementations of the recording tool are shown in . The recording tool has a \u201cRecord\u201d button that allows users to start recording UI activity and a \u201cStop\u201d button to terminate the recording process. A user clicks the \u201cRecord\u201d button, and the recording tool starts collecting input data and displaying it on screen in its aggregated form. Filters may be defined and selected as described in connection with the recording tool in . The filters aggregate recorded data into basic, readable units called playback primitives.","For example, in a Microsoft Windows environment, when a user clicks on the \u201cStart\u201d button and launches the program Notepad, a host of input data is collected. Predefined filters aggregate the data into playback primitives.  show an example set of playback primitives resulting from such UI activity. The set of playback primitives used represent UI activity is limited to a small number, so that the recording tools output is readable.  show an example set of playback primitives. Once the user has finished recording his UI activity, he may stop the recording process.  illustrates a \u201cstop\u201d button. Alternative implementations of a recording tool have other and\/or additional features.","In the second stage of the technique , a code generator converts the aggregated data into playback code. This can be done automatically, or alternatively, the user clicks a \u201cGenerate\u201d code option in a UI recording and playback tool. The process of generating the playback code involves converting primitives into computer language instructions in a programming language, scripting language, document processing language, or other format. For example, each recorded primitive from steps - in  is converted to a corresponding instruction in C# as illustrated in . Alternatively, the code is exported into a different format.","Once the code has been generated, it may be edited. For example, a conditional expression is added to the code in  so that the code is played back only when an Administrator is logged onto a computer. In some implementations, the code corresponds directly to the playback primitives.","The third stage of the technique  is performed by a playback tool or other playback module. On playback the generated code replicates the same series of commands as were recorded. In some implementations, UI Automation or another UI framework provides support for playing back recorded user actions.","In conclusion, the techniques and tools described create readable code that may be reliably played back to replicate UI activity. This is accomplished through the use of various filters and a limited set of playback primitives.","III. Computing Environment","The above described UI recording and playback tool  () and UI recording and playback techniques can be implemented on any of a variety of computing devices and environments, including computers of various form factors (personal, workstation, server, handheld, laptop, tablet, or other mobile), distributed computing networks, and Web services, as a few general examples. The UI recording and playback tool and techniques can be implemented in hardware circuitry, as well as in software  executing within a computer or other computing environment, such as shown in .",{"@attributes":{"id":"p-0145","num":"0144"},"figref":"FIG. 12","b":["1200","1200"]},"With reference to , the computing environment  includes at least one processing unit  and memory . In , this most basic configuration  is included within a dashed line. The processing unit  executes computer-executable instructions and may be a real or a virtual processor. In a multi-processing system, multiple processing units execute computer-executable instructions to increase processing power. The memory  may be volatile memory (e.g., registers, cache, RAM), non-volatile memory (e.g., ROM, EEPROM, flash memory, etc.), or some combination of the two. The memory  stores software  implementing the UI recording and playback tool  and techniques.","A computing environment may have additional features. For example, the computing environment  includes storage , one or more input devices , one or more output devices , and one or more communication connections . An interconnection mechanism (not shown) such as a bus, controller, or network interconnects the components of the computing environment . Typically, operating system software (not shown) provides an operating environment for other software executing in the computing environment , and coordinates activities of the components of the computing environment .","The storage  may be removable or non-removable, and includes magnetic disks, magnetic tapes or cassettes, CD-ROMs, CD-RWs, DVDs, or any other medium which can be used to store information and which can be accessed within the computing environment . The storage  stores instructions for the UI recording and playback software .","The input device(s)  (e.g., for devices operating as a control point in the device connectivity architecture) may be a touch input device such as a keyboard, mouse, pen, or trackball, a voice input device, a scanning device, or another device that provides input to the computing environment . The output device(s)  may be a display, printer, speaker, CD-writer, or another device that provides output from the computing environment .","The communication connection(s)  enable communication over a communication medium to another computing entity. The communication medium conveys information such as computer-executable instructions, audio\/video or other media information, or other data in a modulated data signal. A modulated data signal is a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media include wired or wireless techniques implemented with an electrical, optical, RF, infrared, acoustic, or other carrier.","The UI recording and playback software herein can be described in the general context of computer-readable media. Computer-readable media are any available media that can be accessed within a computing environment. By way of example, and not limitation, with the computing environment , computer-readable media include memory , storage , communication media, and combinations of any of the above.","The techniques herein can be described in the general context of computer-executable instructions, such as those included in program modules, being executed in a computing environment on a target real or virtual processor. Generally, program modules include routines, programs, libraries, objects, classes, components, data structures, etc. that perform particular tasks or implement particular abstract data types. The functionality of the program modules may be combined or split between program modules as desired in various embodiments. Computer-executable instructions for program modules may be executed within a local or distributed computing environment.","For the sake of presentation, the detailed description uses terms like \u201cdetermine,\u201d \u201cgenerate,\u201d \u201cadjust,\u201d and \u201capply\u201d to describe computer operations in a computing environment. These terms are high-level abstractions for operations performed by a computer, and should not be confused with acts performed by a human being. The actual computer operations corresponding to these terms vary depending on implementation.","In view of the many possible embodiments to which the principles of my invention may be applied, I claim as my invention all such embodiments as may come within the scope and spirit of the following claims and equivalents thereto."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIGS. 4A-B"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIGS. 6A-B"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIGS. 7A-C"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 12","FIG. 2"]}]},"DETDESC":[{},{}]}
