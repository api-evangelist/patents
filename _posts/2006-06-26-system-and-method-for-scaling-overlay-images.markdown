---
title: System and method for scaling overlay images
abstract: A system and method for scaling a composite overlay image, wherein the composite overlay image comprises a plurality of pixels and each pixel comprises at least one color channel and at least one alpha channel, and further wherein at least one pixel of the composite overlay image has an alpha value of zero and a color value that is not well defined. First, a set of pixels of the composite overlay image are identified as pixels to be dilated. The color channels of the identified pixels are then dilated to form dilated composite overlay image. Finally, the dilated composite overlay image is scaled.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08072472&OS=08072472&RS=08072472
owner: AGFA Healthcare Inc.
number: 08072472
owner_city: Toronto
owner_country: CA
publication_date: 20060626
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The embodiments described herein relate to the processing of electronic images and in particular to an image transformation system and method for scaling images comprising multicolor and multilayer overlay images.","Modern electronic computing devices are becoming increasingly pervasive. These devices commonly include graphic displays that offer the ability to display images of increasing detail and complexity. Often, the images displayed on the graphic displays are multicolored and multilayered and consist of a background image and one or more overlay images. These combined images have applications in a variety of fields including medical imaging applications, such as in Picture Archive and Communication Systems (PACS), and computer graphics generally.","Each pixel of an electronic image, such as that displayed on a computer monitor, may be represented as a series of values. For example, it is common for each pixel of a color electronic image to be represented by the vector (R, G, B, A), where R represents red, G represents green, B represents blue, and A represents the alpha or the opacity. R, G, and B may be referred to as color channels. Similarly, A may be referred to as an alpha channel. Each of the colors channels can take on a value between a predetermined minimum value and a predetermined maximum value. According to one standard, the minimum value is 0 and the maximum value is 255. In addition, according to that standard, each channel can take on an integer value between the minimum and maximum value inclusive, allowing for a total of 256 values. A color channel with a value of 0 generally denotes the absence of that color in the given pixel and a color channel with a value of 255 represents the pixel being fully saturated with that color. The alpha channel (represented as A) may also take on a value between 0 and 255, where 0 represents the pixel being fully transparent and 255 represents the pixel being completely opaque. For example, a pixel represented as (0, 0, 255, 255) is a pixel that is fully blue and fully opaque. However, if the alpha value is set to 100 then the pixel is represented as (0, 0, 255, 100). Such a pixel is fully blue but is translucent.","However, as used from here on in, the terms color channel and alpha channel will be associated with normalized values. Thus, for the color channels 0 will represent the absence of a particular color, while 1 will represent a fully saturated color. Similarly, for the alpha channel, 0 will represent full transparency and 1 will represent full opacity.","An image having an alpha channel may be overlaid on top of another image. Regardless of whether the underlying image has an alpha channel or not, combining the two images may require the blending of colours. Consider the case where the overlay image has an alpha channel and the underlying image does not. Thus, each pixel of the overlay image may be represented as (R, G, B, A) and each pixel of the underlying image may be represented as (R, G, B). When one image with an alpha channel is overlaid on top of another image, which does not have an alpha channel, the color that a particular pixel takes on is dependent on the colors of the pixels of the overlay and background images at that position, as well as the opacity of the overlay image at that position. Thus, for a particular pixel of a combined image, the color values may be calculated as:\n\n*(1)\u2003\u2003(1)\n\nwherein Crepresents the normalized color channels of the resulting image, Crepresents the color channels of the overlay image, Crepresents the color channels of the background image, Arepresents the alpha value of the overlay image. Each of the C, C, and Care in fact vectors containing each of the color channels of the particular pixel. For example, C=(R, G, B). The above-described process by which the color channels are combined may be referred to as alpha blending.\n","It is often necessary to scale and\/or rotate images that contain a background image and at least one overlay image. Some prior art methods scale the overlay image and the background image separately before combining the two through the use of alpha blending. This leads to a number of undesirable qualities, such as distortion or artifacts. In particular, in the final image, overlay lines appear thinner than they should. In addition, the edges of overlays may be tinged with a dark shade, which in turn, results in a choppy shadow around the overlay features.",{"@attributes":{"id":"p-0008","num":"0007"},"figref":["FIGS. 1A to 1I","FIGS. 1A to 1C","FIG. 1A","FIG. 1B","FIG. 1A","FIG. 1C","FIGS. 1A and 1B"],"b":["2","4","6","2","6","2","2","2"],"sub":["overlay","overlay"]},{"@attributes":{"id":"p-0009","num":"0008"},"figref":["FIGS. 1D to 1F","FIGS. 1A to 1C"],"b":["2","2","8","8","8","8"]},{"@attributes":{"id":"p-0010","num":"0009"},"figref":["FIGS. 1G to 1H","FIGS. 1A to 1C"],"b":["2","2","2","2"]},"One method to overcome these problems is to combine the overlay image with the background image and then scale the combined image. However, this leads to additional problems. In particular, it is often the case that the background image changes or is modified relatively frequently, while the overlay images remain relatively constant. In such a case, this method would be overly computationally intensive and inefficient. Thus, there is a need for a system and method that overcomes the above-mentioned problems and can scale images having a background image and at least one overlay image.","The embodiments described herein provide in one aspect, a method of scaling a composite overlay image, wherein the composite overlay image comprises a plurality of pixels and each pixel comprises at least one color channel and at least one alpha channel, and further wherein at least one pixel of the composite overlay image has an alpha value of zero and a colour value that is not well defined, said method comprising:\n\n","The embodiments described herein provide in another aspect, a system for scaling a composite overlay image, wherein the composite overlay image comprises a plurality of pixels and each pixel comprises at least one color channel and at least one alpha channel, and further wherein at least one pixel of the composite overlay image has an alpha value of zero and a colour value that is not well defined, said system comprising:\n\n","Further aspects and advantages of the embodiments described herein will appear from the following description taken together with the accompanying drawings.","It will be appreciated that for simplicity and clarity of illustration, elements shown in the figures have not necessarily been drawn to scale. For example, the dimensions of some of the elements may be exaggerated relative to other elements for clarity.","It will be appreciated that for simplicity and clarity of illustration, where considered appropriate, reference numerals may be repeated among the figures to indicate corresponding or analogous elements or steps. In addition, numerous specific details are set forth in order to provide a thorough understanding of the exemplary embodiments described herein. However, it will be understood by those of ordinary skill in the art that the embodiments described herein may be practiced without these specific details. In other instances, well-known methods, procedures and components have not been described in detail so as not to obscure the embodiments described herein. Furthermore, this description is not to be considered as limiting the scope of the embodiments described herein in any way, but rather as merely describing the implementation of the various embodiments described herein.","The embodiments of the systems and methods described herein may be implemented in hardware or software, or a combination of both. However, preferably, these embodiments are implemented in computer programs executing on programmable computers each comprising at least one processor, a data storage system (including volatile and non-volatile memory and\/or storage elements), at least one input device, and at least one output device. For example and without limitation, the programmable computers may be a personal computer, laptop, personal data assistant, and cellular telephone. Program code is applied to input data to perform the functions described herein and generate output information. The output information is applied to one or more output devices, in known fashion.","Each program is preferably implemented in a high level procedural or object oriented programming and\/or scripting language to communicate with a computer system. However, the programs can be implemented in assembly or machine language, if desired. In any case, the language may be a compiled or interpreted language. Each such computer program is preferably stored on a storage media or a device (e.g. ROM or magnetic diskette) readable by a general or special purpose programmable computer, for configuring and operating the computer when the storage media or device is read by the computer to perform the procedures described herein. The inventive system may also be considered to be implemented as a computer-readable storage medium, configured with a computer program, where the storage medium so configured causes a computer to operate in a specific and predefined manner to perform the functions described herein.",{"@attributes":{"id":"p-0055","num":"0062"},"figref":"FIG. 2A","b":["10","10","12","14","16","18","20","22","30","24","26","30","32","34","36","10","32"]},"Overlay image scaling system  is used to scale multicolor and multilayer images comprising a background image and at least one overlay image. More specifically, it can be used to scale images having multiple overlay planes each of which may have separate colors. Various embodiments of overlay image scaling system  may be applied to a variety of image formats. In particular, it can be applied to any overlay image that has at least one color channel and at least one alpha channel. For example, some common formats to which embodiments of the image scaling system  may be applied include: the gray scale image format, which utilizes one color channel, the RGB (red, green, blue) image format, which utilizes three color channels, and the CYGM (cyan, yellow, green, magenta) image format, which utilizes four color channels. The above example is meant to be illustrative only and is not intended to be limiting in any way.","As will be explained below, overlay image scaling system  combines the overlay images into one composite overlay image. It then dilates the colors of the composite overlay image. It then scales the dilated composite overlay image and background images separately. Finally, it combines the scaled composite overlay image and the scaled background image. Overlay image scaling system  operates such that the resulting image is free from any obvious artifacts that may occur in the prior art. In addition, combining the multiple overlays into a single multi-colored overlay prior to scaling, allows for the use of a single color buffer and a single alpha buffer during the execution of scaling algorithms.",{"@attributes":{"id":"p-0058","num":"0065"},"figref":"FIG. 2B","b":["200","10","202","204","210","206","208","210","206","208","18","210","214","212","212","214","216","20","34"]},{"@attributes":{"id":"p-0059","num":"0066"},"figref":["FIG. 3","FIG. 2B"],"b":["300","10","300","206","302","304","306","306","308"]},"At step (), the alpha channel dilation module  dilates the alpha channels of the binary image to form a dilated binary image. In other embodiments, in which a binary image is not used, this step would form a dilated binary alpha representation. At step (), the set of pixels of the composite overlay image that should be dilated are identified. As will be explained below, this step involves subtracting the original binary image from the dilated binary image. At step (), the colours are dilated into the pixel locations identified in the previous step. Then the process ends at step (). The overlay image that results from this process will be referred to as a dilated composite overlay image.",{"@attributes":{"id":"p-0061","num":"0068"},"figref":["FIG. 4","FIG. 3"],"b":["400","12","400","308","12"]},"The process begins at step (). At step () a blank binary image is created. At step (), the binary image creation module  selects a pixel of the overlay image. The pixel may be selected in any suitable manner. A previously selected pixel is preferably not selected again.","At step (), it is determined whether the alpha channel of the overlay image pixel selected at step () is greater than 0. If yes, then step () is executed. At step (), the alpha channel of the equivalent binary image pixel is set to 1. A binary image pixel is equivalent to an overlay pixel if it is in the same row and column position. In contrast to the above, if at step () it is determined that the alpha value of the overlay image pixel is equal to 0, then step () is executed. At step (), the alpha channel of the equivalent binary image pixel is set equal to 0. Regardless of whether step () or step () is executed, the next step is (). At step (), it is determined whether or not the overlay image has a pixel that has not yet been processed. If not, that is if all pixels have been processed, then the process ends at step (). If, on the other hand, there are pixels that have not yet been processed, then step () is repeated.","It should be understood that this is exemplary only. Other embodiments do not store the binary alpha values in an image format, but rather use other suitable representations. In particular, the binary alpha representation need not be a raster scan. The term raster scan is used to refer to a representation in which each element is individually defined. For example, in the above-mentioned binary image, each pixel is individually defined as being either a 1 or a 0. In contrast, in a second embodiment, the binary alpha representation is an array of objects. Instead of specifying the alpha value of each pixel individually, this array comprises objects that define ranges of consecutive appearance of a particular value of alpha. Each of these objects may be referred to as a range object. Since the alpha channels of the binary alpha representation are binary, only one of the alpha values needs to be considered. This follows from the fact that if the alpha channel of a particular pixel is not a 0 then it must be a 1 and vice versa. Thus, each range object could be the vector (row#, start_column, end_column), where row# defines the row number of the image, start_column defines the column at which the particular value of alpha begins, end_column defines the column at which it ends. Thus, if the second row of an image has non-zero alpha channels from the third to the ninth column, then one of the range objects in the array would comprise the vector (2, 3, 9). Another alternative is to use an array that stores transition points. Each object would store the point after which the alpha channel changes from a 0 to 1 or vice versa.","Regardless of what method is used, it preferably possible to discern from the binary alpha representation whether each pixel of the overlay image has a zero or non-zero alpha channel. Thus, both alpha channel and position information are preferably stored. In the case of the binary image, the position information is present in that the binary values are stored in pixel position that correspond to the pixel positions of the alpha channels that they represent.",{"@attributes":{"id":"p-0066","num":"0073"},"figref":"FIG. 5","b":["500","14","400"]},"The process begins at step (). At step () a blank binary image is created. At step (), the alpha dilation module  selects a pixel of the binary image. The pixel may be selected in any suitable manner. Preferably, a previously selected pixel is not selected again. At step (), a kernel, which can also be referred to as a structuring element, is applied to the binary image. The kernel is applied by placing its origin over a pixel of the image. Examples of two possible kernels are illustrated in .","At step (), it is determined whether or not any of the 1's within the kernel intersect with any of the pixels in the binary image that have an alpha channel of 1. If yes, then step () is executed. At step (), the alpha channel of the corresponding pixel of the dilated binary image is set equal to 1. The corresponding dilated binary image pixel is the pixel at the same column and row position as the binary image pixel to which the kernel is applied. After step (), step () is executed. If at step () it is determined that there are no pixels with an alpha value of 1 intersect with the 1's in the kernel, then step () is bypassed and step () is executed. At step (), it is determined whether the last pixel of the binary image has been reached. If not, then step () is repeated. If yes, then the process ends at step ().","In an alternative embodiment the kernel may be applied in a different manner. In particular, a two-dimensional kernel, such as the one illustrated in , can be separated into one-dimensional components. Thus, the image may first be dilated along each row and then the resulting image may be dilated along each column. In embodiments utilizing a binary representation that is in the form of a raster as described above, this alternative allows for very simple dilation along the row direction. This follows from the fact that the representation already stores the locations at which the alpha channel changes values. The dilation of the columns is performed by the union of regions from the rows above and below a selected row. This alternative application may be particularly efficient when the binary alpha transitions are sparse, or in other words when the alpha channel is relatively uniform.","The steps  illustrated in  may be repeated more than once. The number of times that steps  are performed depends in part on the scaling algorithm used when scaling the overlay image. For example, if bilinear interpolation is utilized, then a single binary dilation is sufficient. A single binary dilation corresponds to a single pass through steps . On the other hand, if the scaling algorithm utilizes a larger kernel-size, then more than one pass may be required. Generally, the larger the kernel size utilized by the scaling algorithm, the greater the number of binary dilations or repetitions of steps  required.",{"@attributes":{"id":"p-0071","num":"0078"},"figref":"FIGS. 6A and 6B","b":["610","620","14","610","620","610","620","612","622","610","620"]},"Reference is now made to .  illustrates an exemplary binary image  that is 9 pixels wide and 9 pixels tall and contains binary alpha channels. Image  represents a binary image created by binary image creation module  according to steps  of . Every pixel of image  having a 0 corresponds to a pixel of an overlay image pixel having a 0 alpha channel. Every pixel of image  having a 1 corresponds to a pixel of an overlay image pixel having a nonzero alpha channel.  illustrates the image  that results from the application of kernel  to image  of  by alpha dilation module  according to steps  of .",{"@attributes":{"id":"p-0073","num":"0080"},"figref":["FIGS. 7C and 7D","FIGS. 7A and 7B","FIG. 7C","FIG. 7A","FIG. 7D","FIG. 7B"],"b":["720","710","722","712"]},{"@attributes":{"id":"p-0074","num":"0081"},"figref":"FIG. 8","b":["800","16","802","804"]},"At step (), a pixel of the subtracted binary image is selected in any suitable manner. Preferably, a previously selected pixel is not selected again. At step (), it is determined whether the alpha channel of the pixel is equal to 1. If yes, then step () is executed. At step (), the pixel is identified as a pixel requiring color dilation. If the answer reached at step () is no, then step () is executed in place of step (). At step (), the pixel is identified as a pixel not requiring dilation. Regardless of whether step () or () is executed, step () is executed next. At step () it is determined whether there are pixels that have not yet been examined. If not, then the process ends at step (). If yes, then step () is repeated.",{"@attributes":{"id":"p-0076","num":"0083"},"figref":["FIGS. 9A","FIG. 8"],"b":["9","9","910","912","914","910","12","400","912","910","500","14","914","910","912","804"]},{"@attributes":{"id":"p-0077","num":"0084"},"figref":["FIGS. 9D","FIG. 9A","FIGS. 9D","FIGS. 9D"],"b":["9","9","920","922","924","9","9","920","910","922","912","924","914","9","9","9","9"]},{"@attributes":{"id":"p-0078","num":"0085"},"figref":["FIG. 10","FIG. 8","FIG. 3"],"b":["16","1002","1004","810","312","1006","18"]},"At step (), it is determined whether the color channels of all the pixels in the neighborhood are the same. If yes, then step () is executed. At step (), the color settings of the pixel are set to be the same as that of its neighbors. However, if the answer reached at step () is no, then step () is executed. At step (), the color channels of the neighbors are averaged and the color channels of the selected pixels are set to the average. The averaging may be performed by any suitable means. For example, in an embodiment in which the original images already have binary alpha values and where only the 8 neighboring pixels are used, the averaging step can be achieved by a simple average. However, in other embodiments the averaging may be accomplished by a weighted average. The weights can be determined by a number of factors including the alpha value at the pixel, the proximity of the pixel, and the position of the pixel. As an example of where the position may be used to affect the weighting, if a 3\u00d73 kernel is used, then the corner pixels may be given less weight than the pixels that are horizontally or vertically adjacent. Similarly, an example of where the proximity may be used to affect the weighting is in a 5\u00d75 kernel the pixels that are immediately horizontally or vertically adjacent may be given greater weight than the pixels that are two pixels away in the horizontal or vertical direction. In the exemplary embodiment, the color of the pixel is calculated according to the following Equation:",{"@attributes":{"id":"p-0080","num":"0087"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["C","average"]},"mo":"=","mfrac":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":[{"mi":["C","i"]},{"mi":["A","i"]}],"mo":"\u2062"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["A","i"]}}]}}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}},"br":{},"sub":["average ","i ","i "]},{"@attributes":{"id":"p-0081","num":"0088"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mrow":{"mi":"C","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},"mi":"average"},"mo":"=","mfrac":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mrow":{"mo":"-","mn":"1"}},"mn":"1"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mrow":{"mo":"-","mn":"1"}},"mn":"1"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mrow":[{"mi":"K","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"mi":"C","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":["x","i"],"mo":"+"},{"mi":["y","j"],"mo":"+"}],"mo":","}}},{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":["x","i"],"mo":"+"},{"mi":["y","j"],"mo":"+"}],"mo":","}}}],"mo":["\u2062","\u2062"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mrow":{"mo":"-","mn":"1"}},"mn":"1"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mrow":{"mo":"-","mn":"1"}},"mn":"1"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mrow":[{"mi":"K","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":["x","i"],"mo":"+"},{"mi":["y","j"],"mo":"-"}],"mo":","}}}],"mo":"\u2062"}}}]}}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}},"br":{},"sub":"average "},"K(i,j) are the kernel weights used for averaging the colors. In this alternative embodiment, the kernel is a 3\u00d73 kernel and therefore the i and j values range from \u22121 to +1. However, in other embodiments the kernel may be of a different size and the i and j values would vary appropriately. In this alternative embodiment, K(0,0), which represents the center of the kernel, is 0. This means that for the purpose of Equation (3), the summation may be made shorter by skipping the step for which (i,j)=(0,0). In addition, the kernel values at each corner are also 0, which may be represented as K(\u00b11,\u00b11)=0. The above equation is meant to be exemplary only. As mentioned above, the number of pixels used is in part dependant on such things as the scaling algorithm used. For example, for bilinear scaling choosing n=8 is sufficient. However, for bicubic scaling a larger number of pixels are used. Specifically, for bicubic scaling a 5\u00d75 dilation kernel may be used. This would give 24 neighboring pixels, 8 of which are immediately adjacent and 16 of which are two pixels away. In addition, in one embodiment neighboring pixels with an alpha channel of 0 are ignored and the alpha channel of the original image is already binary. In such an embodiment, the calculation of Ccan be written according to the following pseudo code:",{"@attributes":{"id":"p-0083","num":"0090"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"ColorTotal = {0,0,0}"]},{"entry":[{},"NumAlphas = 0"]},{"entry":[{},"For each n"]},{"entry":[{},"{"]},{"entry":[{},"\u2003\u2003if Alpha!= 0"]},{"entry":[{},"\u2003\u2003{"]},{"entry":[{},"\u2003\u2003\u2003\u2003C_average += Color"]},{"entry":[{},"\u2003\u2003\u2003\u2003NumAlphas += 1"]},{"entry":[{},"\u2003\u2003}"]},{"entry":[{},"}"]},{"entry":[{},"C_average = ColorTotal \/ NumAlphas"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"The actual method used to determine the color of the pixel that is dilated into, may be determined according to the particular implementation utilized. One of the above-described methods may be more efficient than the other in one implementation, but may be less efficient in a second implementation. Thus, knowledge of the particular implementation is helpful in determining which method to use.","Regardless of whether step () or () is executed, step () is executed next. At step (), it is determined whether there are pixels that have not yet been examined. If not, then the process ends at step (). If yes, then step () is repeated. It is important to note that color dilation module  does not affect the alpha channels of the overlay image; only the color channels of the overlay image are affected by color dilation module  during steps .","The flowchart presented in  is meant to be exemplary only. There are other possible methods. For example, steps () and () could be replaced with a step that performs some form of convolution. A convolution could achieve the affects of both steps () and () in one step. As a second example, if the overlay is layered then the color chosen to be dilated into a given pixel could be the top most color of the overlay at that location. This method is simpler allows some of the dilation to occur as the overlay images are combined into one image. However, the results produced may not be as good as those achieved by the above-described process. Another alternative could be to use edge detection techniques. A further alternative is to use knowledge of the domain in order to determine which color should dominate.",{"@attributes":{"id":"p-0087","num":"0094"},"figref":["FIG. 11","FIG. 2A"],"b":["1100","22","1102","1104","1106"]},{"@attributes":{"id":"p-0088","num":"0095"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["A","composite"]},"mo":"=","mrow":{"mn":"1","mo":"-","mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msub":{"mi":["A","upper"]}}},{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msub":{"mi":["A","lower"]}}}],"mo":"\u2062"}}},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"4"}}]},{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["C","composite"]},"mo":"=","mfrac":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mrow":{"msub":{"mi":["A","upper"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msub":{"mi":["A","lower"]}}}},"mo":"\u2062","msub":{"mi":["C","upper"]}},{"msub":[{"mi":["A","lower"]},{"mi":["C","lower"]}],"mo":"\u2062"}],"mo":"+"}},"msub":{"mi":["A","composite"]}}},{"msub":{"mi":["A","composite"]},"mo":">","mn":"0"}],"mo":","}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}]}}},"br":{},"sub":["composite ","upper ","lower ","composite ","upper ","lower ","composite","composite ","lower "],"b":["10","10"]},"At step (), it is determined whether there remains an overlay image that has not yet been processed. If not, then the process ends at step (). If yes, then step () is executed. At step (), the next lowest overlay is selected. Then step () is executed. At step (), the next lowest overlay is combined with the previous composite overlay to form a new composite overlay. The alpha and color channels are calculated according to the equation above. The previous composite overlay is now the lower overlay and the overlay selected at step () is the upper overlay. After step () is executed, step () is repeated.","In order to better illustrate step () of , reference is now made to .  illustrates the color channel portion of an overlay image . The color portion of the overlay image  comprises a strip of uniform color .  illustrates the alpha channel portion of the overlay image  of . The alpha channel portion comprises a strip of uniform alpha values  in the same position as the strip of color . Thus, strip  represents the color channels of a set of pixels in overlay image  and strip  represents the alpha channels of the same set of pixels.  are similar to  except that they are for a different overlay image.  respectively illustrate the color channels and the alpha channels of an image  formed by combining overlay images  and .","Only the points of intersecting color or alpha channels require new values to be calculated. Thus, the set of pixels corresponding to square color portion  are the only pixels for which new color channel values must be calculated. Similarly, the set of pixels corresponding to square  are the only pixels for which new alpha channel values must be calculated. In this example, Equation (5), which is given above, could be used to calculate the color values for square . Similarly, Equation (4) could be used to calculate the alpha values .","The process illustrated in  is exemplary only. For example, in many applications the alpha channels of the overlay images may be binary, as they are in some medical imaging technology such as IMPAX\u00ae and other Picture Archive and Communication Systems (PACS). In such a case, at any intersection point the color channel of the composite is more easily determined, as each pixel of each layer is either fully opaque or fully transparent.","It will be appreciated that while the embodiments of the overlay image scaling system  have been described in the context of various methods including methods for scaling multicolor and multilayer overlay images, it should be understood that it is equally applicable to other types of images. The system, processes and methods described are capable of being distributed in a computer program product comprising a computer readable medium that bears computer usable instructions for one or more processors. The medium may be provided in various forms, including one or more diskettes, compact disks, tapes, chips, wireline transmissions, satellite transmissions, internet transmission or downloadings, magnetic and electronic storage media, digital and analog signals, and the like. The computer useable instructions may also be in various forms, including compiled and non-compiled code.","It should be understood that various modifications can be made to the embodiments described and illustrated herein, without departing from the embodiments, the general scope of which is defined in the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["For a better understanding of the embodiments described herein and to show more clearly how they may be carried into effect, reference will now be made, by way of example only, to the accompanying drawings which show at least one exemplary embodiment, and in which:",{"@attributes":{"id":"p-0016","num":"0023"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0017","num":"0024"},"figref":["FIG. 1B","FIG. 1A"]},{"@attributes":{"id":"p-0018","num":"0025"},"figref":["FIG. 1C","FIG. 1A","FIG. 1B"]},{"@attributes":{"id":"p-0019","num":"0026"},"figref":"FIG. 1D"},{"@attributes":{"id":"p-0020","num":"0027"},"figref":["FIG. 1E","FIG. 1D"]},{"@attributes":{"id":"p-0021","num":"0028"},"figref":["FIG. 1F","FIG. 1D","FIG. 1E"]},{"@attributes":{"id":"p-0022","num":"0029"},"figref":"FIG. 1G"},{"@attributes":{"id":"p-0023","num":"0030"},"figref":["FIG. 1H","FIG. 1G"]},{"@attributes":{"id":"p-0024","num":"0031"},"figref":["FIG. 1I","FIG. 1G","FIG. 1H"]},{"@attributes":{"id":"p-0025","num":"0032"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0026","num":"0033"},"figref":["FIG. 2B","FIG. 1"]},{"@attributes":{"id":"p-0027","num":"0034"},"figref":["FIG. 3","FIG. 2A"]},{"@attributes":{"id":"p-0028","num":"0035"},"figref":["FIG. 4","FIG. 2A"]},{"@attributes":{"id":"p-0029","num":"0036"},"figref":["FIG. 5","FIG. 2A"]},{"@attributes":{"id":"p-0030","num":"0037"},"figref":["FIG. 6A","FIG. 2A"]},{"@attributes":{"id":"p-0031","num":"0038"},"figref":["FIG. 6B","FIG. 2A"]},{"@attributes":{"id":"p-0032","num":"0039"},"figref":"FIG. 7A"},{"@attributes":{"id":"p-0033","num":"0040"},"figref":["FIG. 7B","FIG. 6A","FIG. 7A","FIG. 2A"]},{"@attributes":{"id":"p-0034","num":"0041"},"figref":"FIG. 7C"},{"@attributes":{"id":"p-0035","num":"0042"},"figref":["FIG. 7D","FIG. 6A","FIG. 7C","FIG. 1"]},{"@attributes":{"id":"p-0036","num":"0043"},"figref":["FIG. 8","FIG. 2A"]},{"@attributes":{"id":"p-0037","num":"0044"},"figref":"FIG. 9A"},{"@attributes":{"id":"p-0038","num":"0045"},"figref":["FIG. 9B","FIG. 6A","FIG. 9A","FIG. 2A"]},{"@attributes":{"id":"p-0039","num":"0046"},"figref":["FIG. 9C","FIG. 9A","FIG. 9B"]},{"@attributes":{"id":"p-0040","num":"0047"},"figref":["FIG. 9D","FIG. 9A"]},{"@attributes":{"id":"p-0041","num":"0048"},"figref":["FIG. 9E","FIG. 6A","FIG. 9D","FIG. 2A"]},{"@attributes":{"id":"p-0042","num":"0049"},"figref":["FIG. 9F","FIG. 9D","FIG. 9E"]},{"@attributes":{"id":"p-0043","num":"0050"},"figref":["FIG. 10","FIG. 2A"]},{"@attributes":{"id":"p-0044","num":"0051"},"figref":["FIG. 11","FIG. 2A"]},{"@attributes":{"id":"p-0045","num":"0052"},"figref":"FIG. 12A"},{"@attributes":{"id":"p-0046","num":"0053"},"figref":["FIG. 12B","FIG. 12A"]},{"@attributes":{"id":"p-0047","num":"0054"},"figref":"FIG. 13A"},{"@attributes":{"id":"p-0048","num":"0055"},"figref":["FIG. 13B","FIG. 13A"]},{"@attributes":{"id":"p-0049","num":"0056"},"figref":["FIG. 14A","FIGS. 12A and 13A"]},{"@attributes":{"id":"p-0050","num":"0057"},"figref":["FIG. 14B","FIGS. 12B and 13B"]}]},"DETDESC":[{},{}]}
