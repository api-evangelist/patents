---
title: System and method for recommending items in multi-relational environments
abstract: A system, method, and computer program product for making a recommendation to a user of a social network to associate an existing tag with a social media entity instance are provided. The method includes generating a random walk model that includes the social media entity instance for at least a portion of the social network, determining weighted values for the random walk model, generating a weighted random walk model based on the random walk model and the weighted values, performing a random walk on the weighted random walk model starting at the social media entity instance, and recommending an existing tag to the user based on the random walk.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08433670&OS=08433670&RS=08433670
owner: Xerox Corporation
number: 08433670
owner_city: Norwalk
owner_country: US
publication_date: 20110303
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","BRIEF DESCRIPTION","DETAILED DESCRIPTION","EXAMPLES"],"p":["The exemplary embodiment relates to a system and method for recommending items in multi-relational environments such as social networks. Social networks are represented logically as relational graphs where entities belonging to the social networks are linked by one or more relations.","Large social media networks such as media sharing sites Flickr and YouTube contain many (e.g., billions) of images and videos uploaded and annotated by many (e.g., millions) of users. The ability to tag media objects (such as images and videos) within social networks is a powerful mechanism for improving media sharing and search facilities. In such social networks, tags play the role of metadata for the associated media objects. However, these tags are often provided in a free form reflecting an individual user's unique perception of a media object rather than a uniform and consistent methodology for identifying and tagging on object. The lack of uniformity in tagging can reduce the effectiveness of searching based on tags, since the searcher and the tagger may employ different terminology. Despite this free individual choice, some common usage topics emerge when people agree on the semantic description of a given media object or a group of objects.","In the case of media sharing sites such as Flickr and YouTube, the wealth of annotated and tagged objects on the sites form a base for suggesting tags for new and existing media objects. Recommendation systems are particularly useful in bootstrap and querying modes. In the bootstrap mode, a recommendation system suggests the most relevant tags for newly uploaded objects. In the query mode, a user annotating an image is presented with recommended tags that can augment the existing image tags. Both modes can ease the annotation task for the user and help expand the coverage of the tags annotating the images.","In a broader sense, the activity on social network sites often spans along multiple dimensions involving a variety of entity types (e.g. \u201centities\u201d) and relationships (relations) between them. Thus, tag recommendation is just one of many possible scenarios of recommending data to a user of a social networking site based on meta-data of other social network objects. For example, other recommendation scenarios may concern recommending contacts or a group for a user, recommending an image for a group, etc. These recommendations may be provided based on multiple relationships between entities in a social network. Accordingly, it is desirable to know, for a given recommendation task, which relations between entities are relevant to the recommendation task and how the relations are used to recommend items in an optimal manner.","In accordance with one aspect of the exemplary embodiment, a method for making a recommendation to a user of a social network to associate an existing tag with a social media entity instance is provided. The method includes generating a random walk model that includes the social media entity instance for at least a portion of the social network, determining weighted values for the random walk model, generating a weighted random walk model based on the random walk model and the weighted values, performing a random walk on the weighted random walk model starting at the social media entity instance, and recommending an existing tag to the user based on the random walk.","In another aspect, a system for performing a recommendation task is provided. The system includes memory for storing a relational graph representing a social media data model of a social media network and instantiated social media data. The system also includes a relational graph unfolding module adapted to determine an unfolded relational graph by unfolding the instantiated social media data into co-occurrence matrices based at least in part on the relational graph, a general random walk generator adapted to generate a random walk model based at least in part on the recommendation task and the unfolded relational graph, a weighted random walk generator adapted to generate a weighted random walk model based on the random walk model and weighted values, and a social media selection module adapted to perform a random walk on the weighted random walk model, and output a recommendation based at least in part on the random walk.","In yet another aspect, an apparatus for performing a recommendation task is provided that includes a processor configured to generate a random walk model for a social media data model based at least in part on the recommendation task by determining a Markov chain over a set of states S specified by an initial distribution Pover S, and a set of state transition probabilities P(S|S), learn weighted values for the random walk model, generate a weighted random walk model based on the random walk model and the learned weighted values, and perform a random walk on the weighted random walk model to generate one or more recommendations. The Markov chain state transition probabilities are reset with a probability \u03b1>0 according to the initial state distribution P, and the stationary distribution \u03c0 is defined as",{"@attributes":{"id":"p-0009","num":"0008"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"\u03c0","mo":"=","mrow":{"mi":"\u03b1","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"t","mo":"=","mn":"0"},"mi":"\u221e"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"\u03b1"}},"mi":"t"},"mo":["\u2062","\u2062"],"msub":{"mi":"P","mn":"0"},"mrow":{"msup":{"mi":["P","t"]},"mo":"."}}}}}}}},"Disclosed herein are a system and method for recommending items in multi-relational environments such as social networks. To this end, the exemplary embodiments relate to a multi-relational framework capable of integrating a number of different entities and relations between them, using the relations to build data models for different recommendation tasks, and finding the optimal contribution of each relation to a given recommendation task. Social networks, as used herein, refer to an interconnected electronic network structure composed of nodes (entities) having relationships (relations) between nodes based on the properties of the nodes. For example, a social network may represent relationships between electronic representations of people, groups, organizations, animals, computers, media objects (such as audiovisual works or images), metadata elements (such as comments or tags) and so forth.","In a multi-relational setting such as a social network, entities of same or different types are connected to form multiple relations. Each relation in the network may be represented by a uni-type edge (for same type entities, like user-to-user) or a bi-partitive edge (for entities of different types, like user-to-image). In the exemplary system and method, the entities and relations that form a social network are not limited to one specific social network and may integrate entities from multiple social networks. In one embodiment, personal profiles and data from separate social networks are connected via common entities (such as common personal credentials). For example, some social networking sites (such as Facebook\u00ae, MySpace\u00ae, Google Friend Connect\u00ae) provide an application programming interface (API) that allows for determining common users across platforms via social-network connectors. In some embodiments, publicly accessible data (such as page recommendations in the Delicious social network, and relevant tweets on Twitter) are used to construct a unified social network. For purposes of explanation, the social media site Flickr is used as an example of a social media sharing system. Flickr is a social media site that allows users to tag and comment on images uploaded by the same or other users. The users themselves may be logically connected to other uses or be members of groups.","As used herein, a recommendation task concerns the recommendation of one or more instances of one entity in the social network for an instance of a second entity in the network. The first and second entities may be of the same type or of differing types. For example, a recommendation task may involve recommending a tag for an image, recommending a contact or group for a user, or recommending a user for a user. Additionally, as used herein, an \u201centity\u201d is a description of single object about which data can be stored, and an instance of an entity is a single occurrence of the entity. For example, a social network may have a \u201cuser\u201d entity, wherein an instance of the user entity is \u201cBob Jones.\u201d To this end, \u201cinstantiated\u201d social media data refers to a collection of one or more social media data instances.","At a high level, for a given recommendation task, the exemplary embodiment obtains a relational graph representing a social network model. The social network model may be a model of a single social network, or it may be an integration of multiple social network models. The relational graph representing the social network model is transformed into a Markov Chain where the strength of each relation between two entities in the social network model depends on a random walk between the two entities. To perform this transformation, the relational graph, in conjunction with an instantiation of social network data relating to the relational graph, is unfolded into co-occurrence matrices (one for each relation between entities) which are then combined with a weighted average optimized on a pre-annotated training set. A random walk is then performed on the weighted unfolded matrices to obtain a set of recommendations.","With reference to , an illustrative relational graph  representing a social media data model (such the Flickr network) is shown. The relational graph  includes entities , , , ,  connected by relations , , , , , , . Each relation defines how two entities can be related. For example, user owns image, and so the user entity  is linked with the image entity  by the relation \u201cowner\u201d . Similarly, an image may be tagged with a tag, and so the image entity  is linked with the tag entity  by the \u201ctagged_with\u201d relation . As yet another example, two users can be linked, for example as contacts, and this is indicated in the relational graph  of  by including the \u201ccontact\u201d uni-type edge relation .","At a logical level, the relational graph  allows for the integration of all entities and relations of the social network in one uniform way. In mathematical terms, the relational graph  may be written as G=(E,R), where entity types e\u03b5E are represented as nodes and relations r\u03b5R between entity types eand eare represented as (typed) links. Note that for a uni-type relation such as the \u201ccontact\u201d relation , k=l. When instantiated, however, eand ewill be instantiated as instances of two different user entity instances. In , the illustrative relational graph  has no more than one relation between any two entity types eand e. However, relational graphs may have more than one relation between any two entities eand e. Moreover, some entities may have no allowable relation\u2014for example, there is no relation between the tag entity type  and the comment entity type  in the relational graph  of .","Each relation in the relational graph is internally homogeneous in a sense that the same values in a relation tend to have to same importance for a recommendation task. For any given recommendation task, different relations may differ in importance relative to a given recommendation task. For example, the tagged_with relation  between image entity  and tag entity  is expected to be more important to a tag recommendation task than the member relation  between the user entity  and group entity .",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 2","b":["100","100","102","104","106","108","123","104","106","108","123","100","104","106","108","123","100","102","100"]},"The system  includes data memory  for storing the single instance of social media data , social media data model , instantiated social media data  and optional pre-configured weights  during processing. Main memory  of the system  stores instructions  for performing the exemplary method, including a relational graph unfolding module , a general random walk generator , an optional weight learning module , a weighted random walk generator, and a social media selection module . It is to be appreciated that the two memories ,  may be embodied as a single memory unit, or that one or both of the memories ,  may comprise two or more component memory units. The instructions  are suitably executed on a digital processor such as an illustrated computer processor . The computer processor can be variously embodied, such as by a single core processor, a dual core processor (or more generally by a multiple core processor), a digital processor and cooperating math coprocessor, a digital controller, or the like. Outputs from modules , , , ,  may be stored in memories ,  and\/or output via an output device  to a client terminal , optionally through a network  such as the Internet. In one illustrative example, the user accesses the social network using a mobile device, but the system  is a service provided by the social network. In this case, the system  is located at a server supporting the social network (which server may be a distributed or \u201ccloud\u201d computing network), the input  and output  are suitably an Internet portal of the server, the processor  and memory ,  are suitably embodied by the digital processor (e.g., microprocessor or parallel array of microprocessors) and memory component(s) of the server, the network  is suitably the Internet together with any downstream networks (e.g., the cellular telephone network or WiFi network), and the client terminal  is suitably the mobile device including its display screen for displaying output.","The relational graph unfolding module  receives as input a social media data model  and instantiated social media data  via the input device . As described above, the social media data model  is, or may be converted to, a relational graph such as the relational graph  illustrated by . The module  unfolds the instantiated social media data  into co-occurrence matrices (i.e., the unfolded relational graph ) reflecting the entity relationships defined by the social media relational graph. This unfolding process is described in more detail with respect to step S of .","The general random walk generator  receives as input the unfolded relational graph  generated by the relational graph unfolding module  and constructs a random walk model . The random walk model  is generated by constructing a Markov chain from the unfolded relational graph . As will be appreciated by one of ordinary skill, a Markov chain (or Markov model) is a model having states wherein the next state for any given state depends only on the given state. In the exemplary embodiment, the Markov chain itself is designated as the random walk model . The process of generating the random walk model  from the unfolded relational graph  is described in more detail with respect to step S of .","The optional weight learning module  determines a set of weighted values  that represent the weighted contributions of each relation in the relational graph (e.g., , relational graph ) for a given recommendation task. For example, with respect to the relational graph  of , if a recommendation of a tag  is to be made with respect to a given image , the owner relation  may be weighted more heavily than the appears_in relation  if it is determined that the owner relation  is a better indicator of which tag  to recommend for a given image . This process of determining a set of weighted values  is described in more detail below with respect to step S of .","The weighted random walk generator  receives as input the set of weighted values  from the weight learning module  and the random walk model  from the general random walk generator . In an alternate embodiment, weighted values  are provided from a source other than the weight learning module , such as values directly input by an operator of the system . The weighted random walk generator  then applies the set of weighted values  to the random walk model  to create a weighted random walk model . In the exemplary embodiment, the weighted random walk model  is the random walk model  with a stationary distribution \u03c0 adjusted according to the set of weighted values . The generator  then provides the weighted random walk model  to the social media selection module . The process of generating the weighted random walk model  is described in more detail below with respect to step S of .","The social media selection module  receives as input the weighted random walk model  from the weighted random walk generator  and performs a random walk on the weighted random walk model  to select one or more entity instances for the given recommendation task with respect to the input instance of social media data . The selected entity instances are then output as recommendations  for the given input entity . For example, a simplified weighted random walk model  is provided in  with respect to an image to be tagged (noted by state S). In this example, a random walk performed on the model  will likely result in the tag represented by state Sto be selected since the random walk provides a 50% chance that Swill be the next state as opposed to the 20% chance for Sand 30% chance for S. The random walk may be performed multiple times to select multiple entity instances. This process of selecting entity instances from the weighted random walk model  is described in more detail below with respect to step S of .","In the exemplary embodiment, components , , , , , ,  comprise software instructions stored in main memory , which are executed by a computer processor . The processor , such as the computer's CPU, may control the overall operation of the computer system  by execution of processing instructions stored in memory . Components , , , , , , , , , ,  may be connected by a data control bus .","As will be appreciated, system  may include fewer or more components while still having the same functionality. For example, components , , , , ,  may be combined to form fewer components, or may be functionally separated to form more individual components.","The system  may comprise one or more computing devices, such as a personal computer, PDA, laptop computer, server computer, or combination thereof. Memories ,  may be integral or separate and may represent any type of computer readable medium such as random access memory (RAM), read only memory (ROM), magnetic disk or tape, optical disk, flash memory, or holographic memory. In one embodiment, the memories ,  comprise a combination of random access memory and read only memory. In some embodiments, the processor  and memory  and\/or  may be combined in a single chip.","The system  may output the recommendations  to an output device, such as a client terminal , a server, or the like. The output device  may be connected directly with the system  or linked thereto, e.g., via a wired to wireless link , such as a local area network, wide area network, or the Internet. The system  or client terminal  may generate a graphical user interface (GUI) for display to a user. The exemplary GUI (not shown) enables a user to interact with the system  via the display screen of the client terminal  with a user input device, such as a cursor control device, keyboard, keypad, joystick, or the like. In the exemplary embodiment, the client terminal  may include a web browser which allows the user to interact with the system , which may be implemented by a server computer.","The term \u201csoftware\u201d as used herein is intended to encompass any collection or set of instructions executable by a computer or other digital system so as to configure the computer or other digital system to perform the task that is the intent of the software. The term \u201csoftware\u201d as used herein is intended to encompass such instructions stored in a storage medium such as RAM, a hard disk, optical disk, or so forth, and is also intended to encompass so-called \u201cfirmware\u201d that is software stored on a ROM or so forth. Such software may be organized in various ways, and may include software components organized as libraries, Internet-based programs stored on a remote server or so forth, source code, interpretive code, object code, directly executable code, and so forth. It is contemplated that the software may invoke system-level code or calls to other software residing on a server or other location to perform certain functions.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 4","FIG. 2"],"b":"100"},"At S, the social media recommendation system  receives into memory  and\/or  a single instance of social media data  (such as an image) upon which a recommendation task is to be performed. For explanatory purposes, it is assumed that the recommendation task is to recommend one or more tags for an input image. However, the recommendation task generally covers the recommendation of one or more instances of one entity in the social network for an instance of a second entity in the network.","At S, the social media recommendation system  receives into memory  and\/or  a relational graph  representing a social media data model. For example, relational graph  of  is a representation of the Flickr social media data model and may be input into the system .","At S, the social media recommendation system  receives into memory  and\/or  instantiated social media data . The instantiated social media data contains one or more social media entity instances (such as images, tags, users, etc) that conform to the input social media data model .","At S, the relational graph unfolding module  generates an unfolded relational graph  by creating co-occurrence matrices based on the social media data model  and the instantiated social media data . As stated above, the social media data model  is a graph given by G=(E,R), where entity types e\u03b5E are represented as nodes and relations r\u03b5R between entities of types eand eare represented as (typed) links. To create the unfolded relational graph , each relation ris unfolded (instantiated) in the form of a matrix A={a}, i=1, . . . , |e|, j=1, . . . , |e|, where aindicates the relation between entity i\u03b5eand entity j\u03b5e(for example, in the tagged_with relation  of , a=1 in relation rif image i is tagged with tag j, 0 otherwise). In the general case, aare real values from [0,1] range. Assuming that the relational graph includes b entity P types, e, . . . , e. The total number of entities is",{"@attributes":{"id":"p-0039","num":"0038"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"N","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"b"},"mo":"\u2062","mrow":{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mi":["e","k"]}},"mo":"."}}}}},"br":{},"b":"119","sup":"2 ","sub":["k","l","kl","km","ml ","kl "]},"With respect to the Flickr relational model  of , there are seven basic relations , , , , , , , which fill corresponding blocks in P and can compose other relations. The tag co-occurrence relationship is an example of a composed relation. If matrix Adescribes relation tagged_with (IMAGE,TAG), the tag co-occurrence matrix can be obtained by A=A\u2032A. Higher values in Aindicate that occurrence more images are tagged with a given tag pair.","At S, the general random walk generator  generates a random walk model  by constructing a Markov chain from the unfolded relational graph . The Markov chain constructed by the general random walk generator  has a stationary distribution \u03c0 that works well for specific prediction tasks. A Markov chain over a set of states S is specified by an initial distribution Pover S, and a set of state transition probabilities P(S|S). A Markov chain defines a distribution over sequences of states, via a generative process in which the initial state Sis first sampled from according to P, and then states S(for t=1, 2, . . . ) are sampled in order according to the transition probabilities. The stationary distribution of the Markov chain is given by \u03c0(s)=limP(S=s), if the limit exists.","To ensure that the Markov chain has a unique stationary distribution, the module  resets the process with a probability \u03b1>0 according to the initial state distribution P. The probably \u03b1 is a tuning parameter for the method, and in practice, a proper a probability prevents the chain from getting stuck in small loops. In the exemplary embodiment values of \u03b1 ranging from about 0.05 to 0.40 produce good results, however other values for \u03b1 are contemplated. Having the Markov chain S, S, . . . with the initial state Sdistributed according to S, state transitions given by P and resetting probability \u03b1, it is straightforward to express the stationary distribution \u03c0 as follows:",{"@attributes":{"id":"p-0043","num":"0042"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"\u03b1","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"t","mo":"=","mn":"0"},"mi":"\u221e"},"mo":"\u2062","mrow":{"msup":[{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"\u03b1"}},"mi":"t"},{"mi":["P","t"]}],"mo":["\u2062","\u2062"],"msub":{"mi":"P","mn":"0"}}}}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}}},"Equation (1) can be used to efficiently compute \u03c0. Because terms corresponding to large t have very little weight (1\u2212\u03b1), when computing \u03c0, this sequence may be truncated after the first few (on the order of",{"@attributes":{"id":"p-0045","num":"0044"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mn":"1","mi":"\u03b1"},"mo":")"}}},"br":{},"b":["120","121","121"]},"At S, the weight learning module  determines a set of weighted values  that represent the weighted contributions of each relation in the relational graph  for a given recommendation task. The weighted values  are used by the weighted random walk generator  to create a weighted random walk model  that combines the weighted values  and the previously created random walk model . In alternate embodiments, the weighted values  may be input into the system  without having to be calculated.","For illustration purposes, consider a given random walk model. A weight wexpresses the relative contribution of a given relation rin the random walk model between entities eand e. The weighted sum of relations expressed by A=\u03a3wA, and \u03c0(s)is a projection of the stationary distribution \u03c0 on the entity type j.","To initiate a random walk on the random walk model, the initial distribution Pis composed of b vectors \u03b4, i=1, . . . , b, with all elements available for querying. Consequently, Pmay be defined as a normalization of [\u03b4, \u03b4, . . . , \u03b4]. Thus, if weights are known or recommended by an expert, equation (1) may be used for estimating the stationary distribution \u03c0 and its projection \u03c0. If the weights are unknown a priori, then the weight learning module  finds values for weights wwhich minimize a certain loss function.","Weight Learning","To learn the weights of a relational random walk, a stationary distribution \u03c0 is approximated with the truncated version and the optimization problem is expressed on weights was a minimization of loss function when a prediction is applied to a training set. Thus, the weighted random walk is defined by a weighted Markov chain query which results in a probability distribution. Nodes having more links (e.g. relations between entities) with higher weights will accumulate more probability than nodes having less links and of lower weights. Moreover, weights on links can be inferred from the training set, where a model is an instantiation of the Markov model weights which minimizes the prediction error on a training set T.","Square Loss for Probability Estimation","To assist in the weight learning, a scoring function H is employed that assigns a [0,1] value to an entity of type e. The weight learning module  learns the function H from a set of known relations between entities, such as that derived from the social media data model  and\/or the unfolded relational graph . The function H estimates the probability p for a given object i. Let y denote the true probability of i and let p its estimation by H. The price paid when predicting p in place of y is defined as a loss function l(y,p). The square loss between y and p is expressed as:\n\n()=(1)+(1)\u2003\u2003(2)\n","Note that the first and second partial derivatives in p are",{"@attributes":{"id":"p-0052","num":"0051"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mfrac":{"mo":"\u2202","mrow":{"mo":"\u2202","mi":"p"}},"mo":"\u2062","mrow":{"msub":{"mi":["l","sq"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["y","p"],"mo":","}}}},{"mn":"2","mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mi":["p","y"],"mo":"-"}}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0053","num":"0052"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":{"mfrac":{"msup":{"mo":"\u2202","mn":"2"},"mrow":{"msup":{"mo":"\u2202","mn":"2"},"mo":"\u2062","mi":"p"}},"mo":"\u2062","mrow":{"msub":{"mi":["l","sq"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["y","p"],"mo":","}}}},"mo":"=","mn":"2"},"mo":","}}},"br":[{},{}]},"Without loss of generality, a tag recommendation task is presented to illustrate the square loss function. Assume that a tag entity set has L tag instances. For a given image, let Ydenote a binary vector Y={y, . . . , y} here yis 1, if the image is tagged with tag i,i=1, . . . , L. The probability distribution over the tag set TAG is Y=(y, . . . , y) where yis 0 or",{"@attributes":{"id":"p-0055","num":"0054"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mn":"1","mrow":{"mo":["\uf603","\uf604"],"msub":{"mi":["Y","B"]}}},"mo":","}}},"br":{}},"Let P denote an estimated tag probability distribution, P=(p, . . . p), where",{"@attributes":{"id":"p-0057","num":"0056"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"L"},"mo":"\u2062","msub":{"mi":["p","i"]}},"mo":"=","mn":"1."}}},"br":{}},{"@attributes":{"id":"p-0058","num":"0057"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["L","sq"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Y","P"],"mo":","}}},{"mfrac":{"mn":"1","mi":"L"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"L"},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":["l","sq"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["y","i"]},{"mi":["p","i"]}],"mo":","}}},"mo":"."}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}}},"For the distribution square loss L, the derivatives have the form:",{"@attributes":{"id":"p-0060","num":"0059"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mfrac":{"mo":"\u2202","mrow":{"mo":"\u2202","mi":"P"}},"mo":"\u2062","mrow":{"msub":{"mi":["L","sq"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Y","P"],"mo":","}}}},{"mrow":[{"mfrac":{"mn":"1","mi":"L"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"L"},"mo":"\u2062","mrow":{"mfrac":{"mo":"\u2202","mrow":{"mo":"\u2202","msub":{"mi":["p","i"]}}},"mo":"\u2062","mrow":{"msub":{"mi":["l","sq"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["y","i"]},{"mi":["p","i"]}],"mo":","}}}}}},{"mfrac":{"mn":"2","mi":"L"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"L"},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["y","i"]},{"mi":["p","i"]}],"mo":"-"}}}}],"mo":"="}],"mo":"="},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0061","num":"0060"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mfrac":{"msup":{"mo":"\u2202","mn":"2"},"mrow":{"msup":{"mo":"\u2202","mn":"2"},"mo":"\u2062","mi":"P"}},"mo":"\u2062","mrow":{"msub":{"mi":["L","sq"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Y","P"],"mo":","}}}},{"mrow":{"mfrac":{"mn":"1","mi":"L"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"L"},"mo":"\u2062","mrow":{"mfrac":{"msup":{"mo":"\u2202","mn":"2"},"mrow":{"msup":{"mo":"\u2202","mn":"2"},"mo":"\u2062","msub":{"mi":["p","i"]}}},"mo":"\u2062","mrow":{"msub":{"mi":["l","sq"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["y","i"]},{"mi":["p","i"]}],"mo":","}}}}}},"mo":"=","mn":"2"}],"mo":"="}}}},"If a training set T of images has a tag probability distribution Y, the weight learning module  finds a scoring function H which minimizes the empirical loss over T, defined as:",{"@attributes":{"id":"p-0063","num":"0062"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":"Loss","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"H"}},{"mfrac":{"mn":"1","mrow":{"mo":["\uf603","\uf604"],"mi":"T"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":["j","T"],"mo":"\u2208"}},"mo":"\u2062","mrow":{"msub":{"mi":["L","sq"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["Y","j"]},{"mi":["P","j"]}],"mo":","}}}}}],"mo":"="},"mo":","}}},"br":{},"sub":["j ","j "]},"The weighted sum of composed of b distinct entity types",{"@attributes":{"id":"p-0065","num":"0064"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"A","mo":"=","mrow":{"munderover":{"mo":"\u2211","mi":["kl","b"]},"mo":"\u2062","mrow":{"msub":{"mi":["w","kl"]},"mo":"\u2062","mrow":{"msub":{"mi":["A","kl"]},"mo":"."}}}}}},"br":[{},{},{}],"sub":["kl ","kl ","kl ","l","kl","kl","kl","kl ","w",{"sub2":"kl"},"kl","l","kl"],"in-line-formulae":[{},{},{},{}],"i":["H","s.t.","\u2266w","w",", k=",", . . . , b."]},"The constrained optimization problem (5) can be transformed into unconstrained one by introducing variables v, k,l=1, . . . , b and representing w=e\/\u03a3exp(v). The problem constrained on wbecomes unconstrained on v.","To solve problem (5), the weight learning module  uses a limited memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) method. The L-BFGS algorithm is a member of the broad family of quasi-Newton optimization methods. These methods approximate the well-known Newton's method, a class of hill-climbing optimization techniques that seeks a stationary point of a (twice continuously differentiable) function. For such problems, a necessary condition for optimality is that the gradient be zero. Newton's method and the BFGS methods need not converge unless the function has a quadratic Taylor expansion near an optimum. Generally speaking, these methods use the first and second derivatives.","In quasi-Newton methods, the Hessian matrix of second derivatives need not be evaluated directly. Instead, the Hessian matrix is approximated using rank-one updates specified by gradient evaluations (or approximate gradient evaluations). The Broyden-Fletcher-Goldfarb-Shanno (BFGS) method is one of the most popular members of this class.","The L-BFGS uses a limited memory variation of the BFGS to approximate the inverse Hessian matrix. Unlike the original BFGS method which stores a dense n\u00d7n approximation, L-BFGS stores only a few vectors that represent the approximation implicitly. An optimization package with the L-BFGS routine is used in both Matlab and Python\/Scipy environments.","The above iterative scheme may be generalized to all wdimensions, including the gradient \u2207L(W) and the inverse of the Hessian matrix, HL(W), where W=(w), k,l=1, . . . , b. This gives the following iterative sequence of approximated solutions W, W. . . :\n\n()](),0.\u2003\u2003(6)\n","In order to deploy the quasi-Newton methods for the weighted random walks, the derivatives of the loss function with respect to variables ware obtained:",{"@attributes":{"id":"p-0072","num":"0071"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mfrac":{"mrow":[{"mo":"\u2202","mrow":{"mi":"Loss","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"H"}}},{"mo":"\u2202","msub":{"mi":["w","kl"]}}]},"mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"mo":["\uf603","\uf604"],"mi":"T"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":["j","T"],"mo":"\u2208"}},"mo":"\u2062","mrow":{"mfrac":[{"mo":"\u2202","mrow":{"mo":"\u2202","msub":{"mi":["P","j"]}}},{"mrow":[{"mo":"\u2202","msub":{"mi":["P","j"]}},{"mo":"\u2202","msub":{"mi":["w","kl"]}}]}],"mo":["\u2062","\u2062"],"mrow":{"msub":{"mi":["L","sq"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["Y","j"]},{"mi":["P","j"]}],"mo":","}}}}}}},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"7"}}]}}}},"br":{}},{"@attributes":{"id":"p-0073","num":"0072"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["P","j"]},"mo":"=","mrow":{"mi":"\u03b1","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"t","mo":"=","mn":"1"},"mi":"k"},"mo":"\u2062","mrow":{"msup":[{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"\u03b1"}},"mi":"t"},{"mi":["A","t"]}],"mo":["\u2062","\u2062"],"msubsup":{"mi":["P","j"],"mn":"0"}}}}}}},"br":{},"sub":"0","sup":"t "},"The power series A, t=1, 2, . . . are the only terms in Pdependent on wand their first derivatives are provided by:",{"@attributes":{"id":"p-0075","num":"0074"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mfrac":{"mrow":[{"mo":"\u2202","msup":{"mi":["A","t"]}},{"mo":"\u2202","msub":{"mi":["w","kl"]}}]},"mo":"=","mrow":{"mrow":[{"mfrac":{"mo":"\u2202","mrow":{"mo":"\u2202","msub":{"mi":["w","kl"]}}},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"msup":{"mi":"A","mrow":{"mi":"t","mo":"-","mn":"1"}},"mo":"\u2062","mi":"A"}}},{"mrow":[{"mfrac":{"mrow":[{"mo":"\u2202","msup":{"mi":"A","mrow":{"mi":"t","mo":"-","mn":"1"}}},{"mo":"\u2202","msub":{"mi":["w","kl"]}}]},"mo":"\u2062","mi":"A"},{"msup":{"mi":"A","mrow":{"mi":"t","mo":"-","mn":"1"}},"mo":"\u2062","msub":{"mi":["A","kl"]}}],"mo":"+"}],"mo":"="}},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"8"}}]}}}},"br":{}},{"@attributes":{"id":"p-0076","num":"0075"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":{"mrow":[{"msup":[{"mo":"\u2202","mn":"2"},{"mi":["A","t"]}],"mo":"\u2062"},{"msup":{"mo":"\u2202","mn":"2"},"mo":"\u2062","msub":{"mi":["w","kl"]}}]},"mo":"=","mrow":{"mrow":[{"mfrac":{"mrow":[{"msup":[{"mo":"\u2202","mn":"2"},{"mi":"A","mrow":{"mi":"t","mo":"-","mn":"1"}}],"mo":"\u2062"},{"msup":{"mo":"\u2202","mn":"2"},"mo":"\u2062","msub":{"mi":["w","kl"]}}]},"mo":"\u2062","mi":"A"},{"mn":"2","mo":["\u2062","\u2062"],"mfrac":{"mrow":[{"mo":"\u2202","msup":{"mi":"A","mrow":{"mi":"t","mo":"-","mn":"1"}}},{"mo":"\u2202","msub":{"mi":["w","kl"]}}]},"msub":{"mi":["A","kl"]}}],"mo":["+","+"]}}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}}}}},"At S, the weighted random walk generator  generates a weighted random walk model  by applying the set of weighted values  from the weight learning module  to the random walk model  from the general random walk generator . In the exemplary embodiment, the set of weighted values  comprises a weight wfor each relation rin the random walk model . Thus, each link transition probability between entities having a relation rin the random walk model  is multiplied by the value wto create the weighted random walk model .","At S, the social media selection model  performs one or more random walks on the weighted random walk model  to identify one or more social media instances within the instantiated social media data . The initial query Pis used to initiate the random walk. The random walk starts from the state representing the single instance of social media data  upon which the recommendation task is to be performed. In the exemplary embodiment, the random walk then proceeds to successive states (i.e., entity instances) until a entity of the type requested (such as a TAG for an IMAGE) is found. This process may be repeated multiple times to select multiple entity instances for recommendation.","At S, the social media selection module  outputs the selected entity instance(s) as recommendation(s) via the output device . In the exemplary embodiment, a list of entity instances is output, however in alternate embodiments, the entity instances themselves may be output.","The method illustrated in  may be implemented in a computer program product that may be executed on a computer. The computer program product may comprise a non-transitory computer-readable recording medium on which a control program is recorded, such as a disk, hard drive, or the like. Common forms of non-transitory computer-readable media include, for example, floppy disks, flexible disks, hard disks, magnetic tape, or any other magnetic storage medium, CD-ROM, DVD, or any other optical medium, a RAM, a PROM, an EPROM, a FLASH-EPROM, or other memory chip or cartridge, or any other tangible medium from which a computer can read and use.","Alternatively, the method may be implemented in transitory media, such as a transmittable carrier wave in which the control program is embodied as a data signal using transmission media, such as acoustic or light waves, such as those generated during radio wave and infrared data communications, and the like.","The exemplary method described above may be performed in either bootstrap or query mode. In bootstrap mode, the task is to recommend an entity instance (e.g., a specific tag) to associate with a newly uploaded social network entity instance (e.g., a specific image). By way of illustrative example, in bootstrap mode tag recommendations are provided for a newly uploaded image or video clip. In query mode, an entity instance already has pre-existing entity instances related to it (for example, an image already has some assigned tags), and these pre-existing relations are included in the unfolding process so that they are considered when making a recommendation.","A quantitative evaluation was performed on a Flickr data set downloaded through the Flickr API. The dataset includes about 2,000 users, 500,000 images with about 1.7 million comments and 200,000 tags.","Weighted random walk learning was tested on three entity types, IMAGE, TAG and USER. The three core relations are R=tagged_with (IMAGE,TAG), R=owner (USER,IMAGE) and R=contact (USER, USER). Composed relations depend on the recommendation task.","For the tag recommendation, the image-to-image matrix was composed as A=AA\u2032, and was additionally weighted by the similarity using the visual features, extracted with the help of a visual categorization toolbox. Other composed relations are tag-to-tag A=AA\u2032and user-to-tag A=AA, and their inversion. For user contact recommendation, the composed matrices are A=AA\u2032and A=AA. The matrix A is a l\u00d7l block-wise with l=3 and the optimization is done on lweights w.","Two of the tested recommendation tasks are tag recommendation for images and contact recommendation for users. The former runs either in the bootstrap or query mode. In bootstrap mode, the task is to predict tags for a newly uploaded image. In query mode, an image may have some tags and the prediction task is to expand the set of tags by recommending new tags. In both modes, the performance of predicting the top 5 and \u2018size\u2019 tags where the number |size| of tags vary from image to image is known in advance (and equals to the test tag set). Contact recommendation was tested in the query mode only.","Precision, recall and F1 evaluation metrics defined in the multi-labeled mode were used. Let Yand Pdenote the true and prediction tag vectors for image i, respectively. Then, precision and recall are defined as",{"@attributes":{"id":"p-0088","num":"0087"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["P","r"]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mfrac":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":["Y","i"]},{"mi":["P","i"]}],"mo":"\u22c3"}},{"mo":["\uf603","\uf604"],"msub":{"mi":["Y","i"]}}]}}}}},"br":{}},{"@attributes":{"id":"p-0089","num":"0088"},"maths":{"@attributes":{"id":"MATH-US-00019","num":"00019"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":"Re","mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mfrac":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":["Y","i"]},{"mi":["P","i"]}],"mo":"\u22c3"}},{"mo":["\uf603","\uf604"],"msub":{"mi":["P","i"]}}]}}},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0090","num":"0089"},"maths":{"@attributes":{"id":"MATH-US-00020","num":"00020"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mn":"2","mo":"\u2062","mrow":{"mfrac":{"mrow":[{"mi":["Pr","Re"],"mo":"\u00b7"},{"mi":["Pr","Re"],"mo":"+"}]},"mo":"."}}}}},"The weights of random walks are learned and compared to baseline performance results given by the unweighted schema. The unweighted schema is composed with core and composed relations with the equal weights. The initial distributions vary in the function of query type. The average values are reported over 5 independent runs.",{"@attributes":{"id":"p-0092","num":"0091"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0093","num":"0092"},"figref":["FIG. 6","FIG. 7"]},"Additionally, the query-based scenario has been tested on the users' contact recommendation task. Like in the previous test, 50% of a user's contacts are randomly selected to form a query, and the remaining 50% contacts are used for testing.  reports precision and recall values for the top five recommended contacts, wherein the number of users vary from 100 to 1900. One can observe a much higher gain in precision than in recall.","Finally,  illustrates the impact of different truncations in Equation (1) on the performance reported for the precision and recall values for two cases of 1,000 and 20,000 images, when the sequence is truncated after 1, 2, 3, 4, 5 or 10 iterations. As  suggests, both measures achieves their top values for very small values, such as 2 or 3.","It will be appreciated that variants of the above-disclosed and other features and functions, or alternatives thereof, may be combined into many other different systems or applications. Various presently unforeseen or unanticipated alternatives, modifications, variations or improvements therein may be subsequently made by those skilled in the art which are also intended to be encompassed by the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 4","FIG. 2"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIGS. 5-9"}]},"DETDESC":[{},{}]}
