---
title: Storage management system for virtual machines
abstract: A computer system (a method) for providing storage management solution that enables server virtualization in data centers is disclosed. The system comprises a plurality of storage devices for storing data and a plurality of storage management drivers configured to provide an abstraction of the plurality of the storage devices to one or more virtual machines of the data center. A storage management driver is configured to represent a live disk or a snapshot of a live disk in a virtual disk image to the virtual machine associated with the driver. The driver is further configured to translate a logical address for a data block to one or more physical addresses of the data block through the virtual disk image. The system further comprises a master server configured to manage the abstraction of the plurality of the storage devices and to allocate storage space to one or more virtual disk images.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08914567&OS=08914567&RS=08914567
owner: VMware, Inc.
number: 08914567
owner_city: Palo Alto
owner_country: US
publication_date: 20090914
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS","System Overview","Storage Management System "],"p":["The present application claims priority under 35 U.S.C. \u00a7119(e) to U.S. Provisional Patent Application No. 61\/096,918, filed on Sep. 15, 2008, entitled \u201cSTORAGE MANAGEMENT SYSTEM FOR VIRTUAL MACHINES\u201d which is incorporated by reference in its entirety.","1. Field of the Invention","The invention relates generally to virtualization of computer resources. Particularly, the invention relates to providing a storage solution that enables server virtualization in data centers.","2. Description of the Background Art","Server virtualization is the masking of server resources, including the number and identifications of individual physical servers, processors and operating systems, from server users. Server virtualization can be used to make more efficient use of server resources, to improve server availability, and to assist in data backup, testing and development in data centers. Traditionally, server virtualization in a data center depends on a hypervisor and a virtual machine monitor to perform desired operations in the data center, such as monitoring memory pages as seen by a guest operation system (OS), copying data from memory pages in sync with processor registers and persevering all relevant sate of virtual hardware. However, dependence on hypervisor for server virtualization without an optimized storage management leads to system performance that is not scalable for server virtualization in data centers.","Another challenge facing the traditional server virtualization using conventional volume managers to manage data storage is lack of support for managing large volumes of data storage devices, e.g., millions of different volumes of data storage devices. Traditional volume managers deal with relatively few volumes and a simple block map for keeping track of the relatively few volumes. However, complex server virtualization operations, such as taking a snapshot of a whole OS image and continuing its execution at a later time from the exact point it was stopped, consumes a large quantity of data storage space. Traditional volume managers for server virtualization are most likely to fail to provide functionality that complements the needed functionality of server virtualization.","Hence, there is a lack of a system and method that implements data storage with functionality that enables server virtualization in data centers with enhanced system performance.","The invention overcomes the deficiencies and limitations of the prior art by providing a system and method for virtualization of compute resources in general, and for providing a storage management solution in particular that enables server virtualization in data centers. In one embodiment, the computer system comprises a plurality of storage devices for storing data at the data centers and a plurality of storage management drivers configured to provide an abstraction of the plurality of the storage devices to one or more virtual machines of the data center. A storage management driver is configured to represent a live disk or a snapshot of a live disk in a virtual disk image to the virtual machine associated with the driver. The driver is further configured to translate a logical address for a data block to one or more physical addresses of the data block through the virtual disk image. The system manages the disk space of the plurality of the storage devices in terms of two or more logically divided spaces including a log space, a live space and an optional history space. A plurality of data are written sequentially into the disk space via the log space. The data written into the log space can be flushed into the live space and optionally into the history space for performance optimization. The system further comprises a master service configured to manage the abstraction of the plurality of the storage devices and to allocate storage space to one or more virtual disk images.","A system and method for providing functionality that enables server virtualization in data centers is described. In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the invention. It will be apparent, however, to one skilled in the art that the invention can be practiced without these specific details. In other instances, structures and devices are shown in block diagram form in order to avoid obscuring the invention. For example, the invention is described in one embodiment below with reference to user interfaces and particular hardware. However, the invention applies to any type of computing device that can receive a data and commands, and any peripheral devices providing services.","Reference in the specification to \u201cone embodiment\u201d or \u201can embodiment\u201d means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the invention. The appearances of the phrase \u201cin one embodiment\u201d in various places in the specification are not necessarily all referring to the same embodiment.","Some portions of the detailed descriptions that follow are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here, and generally, conceived to be a self consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers or the like.","It should be borne in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussion, it is appreciated that throughout the description, discussions utilizing terms such as \u201cprocessing\u201d or \u201ccomputing\u201d or \u201ccalculating\u201d or \u201cdetermining\u201d or \u201cdisplaying\u201d or the like, refer to the action and processes of a computer system, or similar electronic computing device, that manipulates and transforms data represented as physical (electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.","The invention also relates to an apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes, or it may comprise a general-purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, and magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, flash memory including Universal Serial Bus (USB) keys with non-volatile memory or any type of media suitable for storing electronic instructions, each coupled to a computer system bus.","Finally, the algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general-purpose systems may be used with programs in accordance with the teachings herein, or it may prove convenient to construct more specialized apparatus to perform the required method steps. The required structure for a variety of these systems will appear from the description below. In addition, the invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.",{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 1A","b":["100","200","100","110","130","110","130","120","130","132"],"i":["a","n ","a","n ","a","n"]},"Each physical machine -is divided into multiple isolated virtual environments, also called virtual machines (VMs), or guest virtual machines . A guest virtual machine  has a guest operating system  and one or more software applications . Each physical machine  runs a hypervisor  and a storage management system (SMS) . The hypervisor , also called virtual machine monitor (VMM), is a computer software\/hardware that allows multiple guest operating systems to run concurrently on a physical machine hosting the operating systems. A guest VM  also has one or more block devices (not shown in ). These block devices, seen by a guest VM  as regular disk devices, such as C: or \/dev\/sda, are an abstraction of the underlying data storage devices -provided by the storage management system . For each block device visible to a guest VM , the SMS  manages disk block maps that translate logical addresses in input\/output (I\/O) requests to physical addresses on the underlying storage devices -","SMS  does not manage low level storage devices  directly, such as disk spindles. Existing technologies, such as logical volume management (LVM) or RAID, can be used to directly manage low level disk spindles. A SMS  is logically located above the low level storage devices layer. A SMS  treats the low level storage devices as a set of block devices or volumes. Depending on a particular virtualization platform, these block devices can represent individual disk spindles, a RAID aggregation of disk spindles, or intelligent storage devices such as disk arrays. SMS  is further described in conjunction with description of .","The block devices are visible to guest VMs  from the SMS  via hypervisor  facilities, which are similar to facilities used by standard Redundant Array of Inexpensive Disks) RAID controllers or other block device drivers. The SMS  itself functions as a device driver from hypervisor infrastructure point of view. A SMS  instance running on a specific physical machine  is called a SMS driver from herein and throughout the entire specification.","Device drivers may run in a special guest OS, for example, dom0 in XEN or simply embedded in hypervisor like device drivers in traditional operating systems in case of VMware systems. Device drivers may also run in isolated specialized VMs, called service domains, which are specifically designed to run device drivers in an insulated address space. In one embodiment, a SMS  runs in a service domain to provide abstraction of physical storage to guest VMs. SMS drivers provide a unified view of the block devices that they serve to guest VMs. Multiple SMS drivers do not communicate with each other. Instead, multiple SMS drivers asynchronously communicate with a single cluster-wide management device, master service, to simplify SMS cluster management.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 1B","FIG. 1A","FIG. 1A","FIG. 1B","FIG. 1B"],"b":["200","200","114","110","110","110","114","200","110","114","114","110","118","110","130","120","130"],"i":["a","b ","a ","a ","a ","b","a","b ","a","b ","a","d ","a","d "]},"The SMS  running in the service domain -SD comprises a SMS driver , a master service , a device emulator , a back end driver  and a block device driver . The SMS  presents the abstraction of the physical volumes -as multiple block devices to the guest VM -. In the para-virtualized guest VM case, the SMS  provides a para-virtual block device driver, e.g., frontend driver , running in the guest VM , and the frontend driver communicates with the backend driver . In the fully virtualized guest VM case, the SMS  provides a standard block device driver, e.g., small computer system interface (SCSI) driver , to the guest VM . The SCSI driver communicates with an emulated hardware, e.g., device emulator , which in turn communicates with the backend driver . The backend driver  communicates with the SMS driver  that translates logical address space to physical addresses on the underlying physical volumes -responsive to the I\/O requests from the backend driver . The block device driver  reads from and\/or writes into the physical volumes -based on the address space translation from the SMS driver .","In addition to address space translation service provided by a SMS driver , a SMS  also includes a master service  to provide various other services, such as virtual disk image (VDI) identifications management and disk space allocation. The master service  can run on one of the physical machines in a virtualization platform. The master service  is further described in conjunction with descriptions of .","In other embodiments, depending on the features of a particular virtualization platform, SMS  runs as an integral part of the hypervisor  in monolithic hypervisor runtime environments, such as VMware runtime environment. In VMware runtime environment, SMS  operates as a block device driver in a guest OS, similar as hardware RAID controller driver, and presents virtual disk images as block devices to the guest OS. VMware tools can be used to map these block devices to guest OS visible block devices.","Turning now to ,  is a block diagram illustrating the modules ,  and  of a storage management system  according to one embodiment of the invention. The SMS  comprises a SMS driver , a master service  and a communication interface . The SMS  communicates with a hypervisor  via the communication interface . The SMS driver  translates\/maps logical address space to physical address space for each I\/O request. The SMS driver  communicates with the master service  via the communication interface . The master service  maintains a consistent view of all the mapping information for an entire data storage space. The master service  is configured to manage virtual disk image identifications and disk space allocation. The SMS  receives an incoming I\/O request containing information about the location of the data in terms of logical disk address and translates the incoming I\/O request into a new I\/O request to the physical disk location via the SMS driver .",{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 3","FIGS. 4-8","FIGS. 9-11","FIG. 14"],"b":["300","300","300","310","320","330","310","320","200","330","310","320","330"]},"A SMS driver  addresses a data block in a physical storage volume by a unique address that is a combination of a SMS internal volume identification (ID) and an offset in the volume. The unique address of the data block is viewed by the SMS driver  as a low-level or physical address. Thus, the SMS driver  provides an abstraction of the physical volumes to a guest VM and the physical data block address space in the virtualization system becomes sparse. In one embodiment, the SMS driver  provides the abstraction of the physical volumes via virtual disk images through the VDI management module .","The VDI management module  is configured to create new empty VDIs and snapshot live VDIs. The VDI management module  is further configured to destroy live VDIs and snapshot VDIs, clone snapshot VDIs, allocate VDI identifications, send notification about VDI failure and I\/O errors and collect statistic data about I\/O requests and disk space allocation.","VDI Map and VDI Map Blocks","A virtual disk image (VDI) is an image of a block device as seen by a virtual machine at some moment in time of a computing process. A guest OS that runs in a virtual machine sees a VDI as a block device in its native environment. In a fully virtualized hardware model, the virtual machine allows running the guest OS without modifications. In the para-virtualized model, the virtual machine requires installing special device driver that is responsible for transferring I\/O requests from a guest OS to a SMS driver  in an efficient manner. Specific details of this transfer depend on a particular virtualization platform and can be significantly different. However, a guest OS running in its native environment views a data block as a block device interface in SMS . This means that there can be multiple (up to few hundreds potentially) concurrent I\/O requests in process between the guest OS and the corresponding VDI, just like in common SCSI layer on a traditional compute platform. One example of such an API is libaio where VDI is an implementation of libaio and the plumbing is a client.","A VDI can represent a live disk as being accessed and written into by one or more running virtual machines. A VDI can also represent a snapshot of a live disk at a historical point in time. A VDI representing a live disk is referred to as a live VDI and a VDI representing a snapshot of a live disk at a historical point in time is called a snapshot VDI. A snapshot VDI once created is unchangeable or read only. Thus, a snapshot VDI is also referred to as a frozen VDI. The term \u201csnapshot VDI\u201d and the term \u201cfrozen VDI\u201d are used interchangeably from herein and the throughout the entire specification.","A VDI is logically a block device, potentially visible to a virtual machine. It has its own logical address space with data blocks numbered from 0 to n\u22121 (assuming total number of data blocks is n). These data blocks, however, are physically located on low-level storage volumes. Thus, a VDI address space represents a virtual disk address space mapping of an underlying physical address space accessed by a guest OS. The VDI management module  is responsible for directing I\/O requests from a guest OS against the live VDI (virtual disk) address space into appropriate data blocks on the underlying physical volumes. The VDI management module  maintains VDI maps that map a logical address (i.e., a logical VDI address) for a data block as seen by a virtual machine to physical addresses for that data block on the underlying physical volumes. Maps are persisted on the underlying volumes as well. Each physical machine has maps for all VDIs that are active on this physical machine.","VDI map is a mechanism that translates a logical offset in a virtual disk, e.g., a VDI, into physical block addresses within a SMS  storage repository. A VDI block map contains one or more map blocks of a uniform size, such as 4 kilobytes (KB). One of the map blocks is a root block. VDI maps are extent based, where each map block contains a map block header and variable number of fixed size records (e.g., 128 bits). A record in a VDI map describes continuous extent (also called data extent) and contains an address of the beginning of the extent and its length. An extent is a contiguous area of logical VDI address space. An extent can also be contiguous in physical space (e.g., leaf nodes of the block map), or a concatenation of multiple data extents. In one embodiment, one record is for one data extent.","Turning now to ,  is a diagram of an example of a root block  of a virtual disk image map according to one embodiment of the invention. The root block  of the VDI map has a root pointer  pointing to the root block . The root block  contains a VDI map block header  and multiple records -. In one embodiment, the total number of the records for the root block  is 254 (e.g., record  to record ). Each of the record  is associated with an extent (e.g., extent logical block address).","A map block header represents the signature of a map block. In one embodiment, a map block header includes logical block address (LBA) for the first block not covered by this map block. For the root block, it is the first logical address outside of the VDI map range. The map block header also includes the level of this block in a VDI map tree, a current VDI ID and a parent VDI (if any) ID, as well as cyclic redundancy check (CRC) code and a magic number. The magic number and CRC are used for sanity check in runtime and\/or for consistency check\/repair by utilities external to the SMS . Level of a map block in the VDI map tree helps with traversal of the VDI map tree.","Taking the root block  of the VDI map illustrated in  as an example, the VDI map block header  comprises two records: record and record . The record contains a magic number (e.g., magic #), a CRC code, and the first LBA outside the root block. The record contains a current VDI ID, a parent VDI ID, a reserved field and map level information.","A VDI map is organized in a tree structure, called VDI map tree. There is a single map block at the root of the VDI map tree and it is called root block. Depending on how many extents are there in a VDI map, a VDI map tree can include one or more leaf records in it, or references to other map blocks in the map tree. A VDI map tree can contain several levels of map blocks. There are two kinds of the records in a VDI map\u2014leaf records and map records. A leaf record refers to real data extent in the VDI map, and describes not only logically contiguous but also physically contiguous data extent. A map record refers to another map block rather than real data extent in the VDI map.","Taking the root block  of the VDI map illustrated in  as an example, the root block  comprises multiple records -. Record is a map record that refers to a map block\/data extent  at next map level, which in turn refers to a map block\/data extent  at next map level.","There are three kinds of leaf records: unallocated, allocated\/unwritten, and regular (allocated and written) extent. An unallocated leaf record refers to an extent that does not exist yet in a data storage device. An unallocated leaf record reads zeros on a read request and needs a new allocation on a write request. An allocated\/unwritten leaf record refers to an extent that has existed in a data storage device. An allocated\/unwritten leaf record reads zeros on a read request. A written request for an allocated\/unwritten leaf record can go directly through. An allocated and written leaf record refers to an extent that has existed in a data storage device and has data written in the extent.","Each record contains a logical block address (LBA), a physical block address (PBA) of next level map block or data extent and one or flags indicating record type. Addresses are in 512 bytes units or disk sectors. Records are sorted in the order of logical addresses and represent one contiguous extent in the VDI address space.","Taking the root block  of the VDI map illustrated in  as an example, the record has the PBA  of next map block or data extent, the extent LBA  and three flags -to describe the record type of record . The three flags to describe the record type of record  are an allocated and unwritten extent flag , a map block\/data flag and a shared\/private flag . A flag can take a value of 0 or 1. An allocated and unwritten extent flag of a record set to 1 means that the record is allocated and unwritten. An allocated and unwritten extent flag of a record set to 0 means that the record is allocated and written. An unallocated extent (i.e., a \u201chole\u201d) is indicated by a PBA  having a value of \u22121 (i.e., negative 1). For an unallocated extent, the allocated and unwritten extent flag value is not used in describing the record type. A map block\/data flag of a record set to 1 indicates that the record is a leaf record that refers to real data extent in the VDI map. A map block\/data of a record set to 0 means that the record is a map record that refers to another map block, rather than a real data extent in the VDI map. A shared\/private flag of a record set to 1 indicates that the underlying physical storage described by this record is writable and shared by other VDIs. Shared\/private flag can be used for implementing VDI snapshot described later in the specification.","VDI map is a powerful mechanism that allows for very flexible data allocation and placement in the storage management system. It interacts very efficiently with the parent\/child VDI concept. It also supports data placement in various storage areas like log and live space. To write new data into a child VDI or sparsely allocated VDI can be efficiently done by allocating a new map block in a convenient place, and the active VDI map is updated to reflect new data placement.","The method for modifying a VDI map during a write operation is described with reference to , B and C. The following , B and C illustrate the VDI map at different points during a write operation.  is a diagram of a VDI map  after initialization according to one embodiment of the invention. The VDI block map  is newly created during initialization and does not contain any valid data. The VDI block map  has size N and contains three records -. The content of the VDI is one unallocated extent described by record . Specifically, the unallocated extent (i.e., a \u201chole\u201d) is indicated by a PBA having a value of \u22121 and the extent LBA is 0. The flags -of the record describe the record type of record . Since the extent is an unallocated extent, the allocated and unwritten extent flag is not considered to describe the record type of record . The map block\/data flag set to 1 indicates that record refers to a data extent. The shared\/private flag indicates that the underlying physical storage described by record is writable and shared by other VDIs.",{"@attributes":{"id":"p-0066","num":"0065"},"figref":["FIG. 5B","FIG. 5A"],"b":["542","540","500","530","542","540","540","530","542","542","532","530","550"]},"As writes continue, more and more records get added into the VDI map  illustrated in .  is a diagram of the VDI map  after performing the exemplary writes illustrated in . The VDI map  contains 8 records -. The first two records -contains the VDI map header . Record is the first record after the VDI map header . Record records an unallocated data extent (i.e., \u22121 for PBA) and data extent of 0 (i.e., 0 for extent LBA). The record type flags of record indicate that it is a data record, not allocated extent and writable. Next record indicates a live page with a LBA at offset 4M. Record is a data record, allocated and not written extent and writable. Record corresponds to the write at 4M-8M boundary illustrated in . The PBA of record is at 2M beyond the live page indicated by record . The LBA of record is at 6M offset. Record is a data record, an allocated and written extent and writable. Record corresponds to the write at the 8M boundary illustrated in . The PBA of record is at 4M beyond the live page indicated by record . The LBA of record is at 8M offset. Record is a data record, an allocated and written extent and writable. Record corresponds to the write at 8M-12M boundary illustrated in . The PBA of record is at 6M beyond the live page indicated by record . The LBA of record is at 10M offset. Record is a data record, an allocated and not written extent and writable. Last record records a data extent, not allocated (i.e., \u22121 for PBA), writable at offset of 12M.","Depending on the particular write configuration, records get added into a VDI map  as necessary. In the embodiment illustrated in , the size of the map block is fixed and is 4 KB in size. In the worst possible case of fragmentation, each 4 KB page of data in a map block requires its own leaf record. Each first level map block covers 256*4 KB=1 MB of data, or 2^8 pages. Assuming 4 levels in a VDI map tree, the maximum is (2^8)^4=2^32 pages or 16 TB maximum in a physical volume. Responsive to a map block being full, the VDI management module  allocates another 4K map block, moves the second half of the records from the full block into newly allocated one and initializes the header of the newly allocated map block accordingly. Resulting from allocating the map block are two map blocks covering the same LBA range as the original full map block, the original block covering the head of the LBA range and the second covering the tail of the LBA range.",{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 6A","b":["1","0","602","1","0","604","2","1","2","1","1","606","127","606","128","606","254","606","2","2"],"i":["a","b","c","d"]},{"@attributes":{"id":"p-0070","num":"0069"},"figref":["FIG. 6B","FIG. 6A"],"b":["310","0","310","2","1","310","2","3","1","2","1","3","1","606","2","2","1","127","128","128","2","1","129","3","1","254","2","3","1","310","1","0","3","1","3","1","1","0"],"i":"e "},"VDI Creation and Destruction","In order to gain access to the point in time a snapshot VDI represented, a VDI needs to be cloned. A cloning operation applies to a snapshot\/frozen VDI and creates a live VDI that point to the same data blocks as the snapshot. The newly created live VDI is called child, and the original one is parent. A parent VDI is also called a \u201cgolden\u201d image. A child VDI represents the most current or latest state of the disk as seen by a virtual machine using it, while a parent VDI represents some historical state that was there some times ago. Writes to the child will not modify the parent's content or its map, but instead are routed to newly allocated data blocks and child's map is changed accordingly. The VDI management module  keeps a VDI map for each snapshot VDI in addition to the VDI maps for live VDIs. A snapshot VDI map reflects the mappings to the data blocks at the time of the snapshot.","There are two kinds of new VDIs\u2014thinly provisioned and fully allocated. A thinly provisioned VDI has no disk space allocated to it except its map root block, while a fully allocated VDI has disk space allocated for its size and marked as unwritten. A VDI created from scratch is like a brand new disk\u2014it contains no usable data. In SMS , a newly created VDI reads all zeroes.","Creating a derived VDI from an existing VDI is like copying of an existing disk\u2014the new disk of the same size has exact copy of the data from the old one. There are two operations to create derived VDIs\u2014snapshot and cloning. Snapshot operation produces an unchangeable copy from a live disk, while cloning produces a live disk from an unchangeable copy. Specifically, snapshot is an operation that applies to a live VDI and produces a snapshot VDI. A snapshot VDI represents an image of a VDI at the moment of the snapshot. As described in VDI definition section above, the snapshot VDI becomes a parent VDI, and the live VDI becomes a child VDI. Live VDI continues \u201cto live\u201d and be available for one or virtual machines. If any virtual machine is using this live VDI (i.e., corresponding virtual disk), the virtual machine does not even notice that the live VDI has been snapshot.","Creating snapshot VDIs is a simple operation in SMS . In order to maintain parent\/child relationships among multiple VDIs and track common blocks shared by multiple VDIs, VDI management module  creates one or more copies of the VDI map.","Parent VDIs are unchangeable: neither the VDI map nor the underlying data of a parent VDI can change. The VDI management module  does not allow any operation on a parent VDI. However children of a parent VDI are live VDIs. In order to support snapshot operations, VDI map mechanism has a way to distinguish among maps of a parent VDI and its children. In one embodiment, the VDI management module  creates snapshot VDIs using the shared flag of a VDI map block.","TABLE I below illustrates combinations of the shared flag and allocated and unwritten flag of a VDI map block. \u201c-\u201d symbol means that the corresponding flag is not set (i.e., having a value of 0) and \u201cx\u201d symbol means that the corresponding flag is set (i.e., having a value of 1). \u201cS\u201d represents the shared flag of a VDI map block and \u201cAW\u201d for the allocated and unwritten flag of the VDI map block.",{"@attributes":{"id":"p-0077","num":"0076"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE I"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Shared Flag and Allocated and Written Flag"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"S","AW","Meaning"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},"\u2014","\u2014","Normal data extent"]},{"entry":[{},"x","\u2014","Shared map entry; immutable: new"]},{"entry":[{},{},{},"allocation is necessary to accommodate"]},{"entry":[{},{},{},"new data"]},{"entry":[{},"\u2014","x","Allocated and not written; writes are"]},{"entry":[{},{},{},"allowed to go through, but reads return"]},{"entry":[{},{},{},"zeros"]},{"entry":[{},"x","x","Shared, allocated and unwritten; reads go"]},{"entry":[{},{},{},"to parent's data blocks; writes do not"]},{"entry":[{},{},{},"make new allocation and uses the"]},{"entry":[{},{},{},"allocated and unwritten space; shared flag is"]},{"entry":[{},{},{},"cleared after writes"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}]}}},"Specifically, if the shared flag is set, it means that the underlying physical storage that this record describes is shared with other VDIs and cannot be changed. If a child live VDI encounters a write into such a region, it behaves similarly to an unallocated region\u2014new storage gets allocated to accommodate the write request and child's VDI map gets updated to reflect this allocation. Because this new allocation is not shared with any other VDI, it is marked as private so that further write operations into that range go as normal.","The new allocation can be larger than a particular write operation. In this case child's VDI map has allocated\/unwritten extent. This extent, even though it is private to the child, is still marked as shared as well as allocated and unwritten. This is done so that a read from that region goes to the parent's data blocks. However write into this region does not make new allocation, and writes uses the allocated\/unwritten space. The shared flag is cleared after writes.","Using shared flag to help create snapshot VDIs allows for VDI map copy optimization. As the shared flag applies to the whole region in a VDI logical address space, there is no need to copy the whole VDI map. Instead, only the root map block of the VDI map is copied, and all the records in the root map block are marked shared. The rest of the map is shared between the two maps. As a disk lookup process traverses the VDI map tree, the first encountered shared flag triggers shared region functionality and it applies to all of the extents underneath. When the lower level map blocks are split or updated, shared flag gets propagated accordingly, reflecting what parts of the VDI map and data are still shared.","Using the shared flag in a VDI map as described above, the root map block of a live VDI gets copied and the original root map block gets all records in it marked as shared. The live VDI becomes a child of the original VDI in this operation. Live child VDI is released right after copying and is ready to be used by virtual machines. The VDI management module  waits for all I\/O that have been started at the moment of creating snapshot to complete. After that, a snapshot VDI is created.","Turning now to cloning operation, a cloning operation applies to a snapshot VDI and produces a new live VDI that is a child of the snapshot VDI. The child VDI shares data with the parent as long as the data is not changed by writing into the child address space. In one embodiment, the VDI management module  creates new VDIs using the shared flag of a VDI map block. Comparing with snapshot operation described above, the VDI management module  sets the shared flag of a VDI map in a copy of the root map block as if the copy of the root map block belongs to the newly created child VDI.","A single frozen VDI can be cloned multiple times and the frozen VDI becomes a parent VDI of one or more children VDIs through cloning operation. Initially the children have the exactly same data as the parent VDI. Changes made to children VDIs by one or more writes from a virtual machine make the children VDIs more and more different from their parent VDI with time depending on the pattern of writes.","For example, the SMS  starts multiple virtual machines from the same carefully created and preconfigured disk image\u2014called golden image. The golden image is cloned to start a number of live VDIs, which are children of the golden image. The newly created live VDIs have a lot of data blocks that are common among all of them and the golden image itself.","A golden image can be carefully created by running a virtual machine that is dedicated to golden image creation. A golden image accommodates common applications, system and application patches, etc. When a new golden image is ready, a system administrator of the SMS  creates a snapshot VDI, i.e., a new golden image. A dedicated virtual machine, i.e., a golden image creator, can continue using the same live VDI as it is one of the ancestors. This can be done for final testing of the golden image, or to start creating the next golden image. The administrator can stop all virtual machines that use a previous golden image at some time, optionally destroy its children VDIs, and restart the children VDIs from the new golden image though cloning.","In one embodiment, cloning is not an automatic operation, and it's an administrative action performed by human. Some rather infrequent cloning operations can be started automatically. For example, a snapshot VDI can be cloned in order to start backup job. Live VDIs can be created en masse by a virtual machine management application to start a large number of virtual machines from the same golden image.","Live VDIs can be accessed by a virtual machine running on any physical machine in a SMS cluster. Access to the same live VDI (shared) from multiple physical hosts is not allowed. If read only access to the same disk image is required by a VDI, the VDI has to be frozen and the newly created frozen VDI later can be cloned. Newly created live VDI has the same content as its parent VDI at creation and it can be made accessible in a read only fashion. Each VDI has a unique system wide VDI ID that is used to address data blocks on that VDI. VDI ID can be used to obtain pointer to a persistent VDI map that fully describes VDI metadata.","To efficiently represent a parent\/child relationship among multiple VDIs, the VDI management module  represents a VDI map as a VDI map tree. Maintaining parent\/child relationships among multiple VDIs allows for common block tracking and associated storage savings by the VDI management module  because the VDI management module  allows the SMS  to only store data blocks that are changed between a child and a parent. VDI map also simplifies disk image management as the VDI map makes it possible to present the map tree to the administrator for tracing ancestry of each VDI. The parent\/child relationship captured by a VDI map also reflects common block sharing\u2014the older a VDI is on the map tree, the more common data it represents.","A VDI map tree can be represented as directed graph. Parents are represented as nodes, and edges represent relationships between a parent and one or more children. All VDIs have a common great grandparent VDI. The common great grandparent is a thin provisioned, empty frozen VDI.  is a diagram of a VDI map tree  illustrating a parent-child relationship among multiple live and frozen VDIs according to one embodiment of the invention. VDI # () is the common great grandparent of all the VDIs in the VDI map tree . It is an empty frozen VDI. Patent  () was created as an empty VDI by cloning its parent, i.e., the VDI #. Parent  as a result of cloning becomes a live VDI and its parent VDI # becomes a frozen VDI. Patent  was loaded with data, for example, as a result of guest OS installation, and later Parent  was frozen as a snapshot VDI representing a snapshot of a live disk at a historical point in time. SMS  treats a snapshot VDI as new one. Live VDI that was used to create a snapshot VDI continues its life with the same identity. In other words, a virtual machine which is the owner of the VDI map tree  continues using Parent  while the virtual machine can continue creating one or more live VDIs.","Parent  (a snapshot VDI) was cloned several times. For example, Parent  was cloned to create three live VDIs, V., V. and V.. The three live VDIs (i.e., V., V. an V.) are served as virtual disks for a guest machines. The 4cloned live VDI from Parent  later became a snapshot VDI, Parent  (). Parent  was cloned twice to create live VDIs, V. and V.. Turning now to the 5child of Parent : this live VDI gave life to Parent  () which later becomes Parent  (), that is a golden image for multiple live VDIs, V., V., V., up to V.n, where n is a predetermined a threshold. The live VDIs, V.-V.n, can be connected to different virtual machines that run on different physical machines.","There are two kinds of snapshots\u2014light and heavy. Children of a lightweight snapshot VDI have higher fragmentation and, as a result, worse performance characteristics. A heavyweight snapshot generally takes more time to create, but a heavyweight snapshot eliminates extra data fragmentation for its children. Taking  as an example, Parent  is a lightweight snapshot. Parent  can be created as a heavyweight snapshot. As a child of lightweight snapshot Parent , the data of VDI . is also present at its parent (i.e., Parent ) disk space, and its grand parent (i.e., Parent ) disk space. As children of heavyweight snapshot Parent , the data of live VDIs V.-V.n are only shared with their immediate parent, Parent , despite of their grandparents Parent  and Parent .","Some VDIs become useless after a while. The VDI management module  provides for a mechanism to get rid of useless VDIs and reclaim the space. In one embodiment, the VDI management module  destroys useless VDIs explicitly according to an administrative request. However, some computer applications like disk backup create transient snapshot VDIs that need to be destroyed when the disk backup job is done. In order to perform disk backup, a snapshot of a live VDI is created. The snapshot of the live VDI is then cloned to create a new live VDI, and the newly created live VDI is used as the source of backup data. Depending on a particular embodiment of implementation, the new live VDI can be read only, or even writable to support functionality such as application log replay. When backup operation is done, the new live VDI used for backup and its parent are not needed any more and are destroyed automatically as a part of post-backup procedure by the VDI management module .","Any live VDIs can be destroyed if it is not active. This is a relatively light weight operation because the VDI management module  only needs to de-allocate any allocated non-shared data and the map blocks associated with the destroyed live VDIs. A snapshot VDI cannot be destroyed quite that easily because it shares data with its children. Children have accumulated changes but refer to the snapshot for the common blocks. This means that destroying snapshots is generally performed if there are no children. In case of a snapshot VDI not having any children, destroying the snapshot VDI follows the same destruction procedure of a live VDI.","Turning now to , an example of a VDI map having multiple VDIs during VDI creation, snapshot and cloning operations according to one embodiment of the invention is shown. The VDI map  have multiple golden images, old golden image , current golden image  and a future golden image . The thick black line  illustrates a trace of golden image VDIs during VDI creation, snapshot and cloning operations over a period of time. The dashed line prior to the old golden image  indicates additional operations by VDI management module  which are not shown in . Responsive to a VDI being useless, the VDI management module  destroy the VDI. As illustrated in , multiple children VDIs  of the old gold image  are destroyed after being used. The children VDIs  of the current gold image  represent live VDIs, and one of them (e.g., VDI ) becomes the future gold image which is to be cloned for future operations upon requests from virtual machines.","VDI Metadata and Management","A SMS  instance on every physical machine maintains certain amount of information in memory (e.g., a cache memory) to manage VDIs that are open on this physical machine. This information in the SMS  is called VDI metadata. The memory to store VDI metadata is called map block cache. Main part of this information is map blocks that describe active areas in the VDIs. VDI metadata cache is not required for SMS  functionality, but it is used in one embodiment for many performance optimizations, such as write transaction optimization. VDI metadata cache also makes VDI maps interpretation fast.","Map blocks in memory are exact replicas of on-disk map blocks. As on-disk map blocks refer to each other by physical address, the same logic applies in memory. In other words, a tree traversal from a map block to the next is done by physical address. In one embodiment, map block cache is managed as a hash table with hash function based on the physical address of the map block on a physical storage. Map blocks are referred to by their physical address. Map blocks are accessed in a manner similar to traditional inode cache in an O\/S. The function returns the pointer to the block header in memory, either after it is found in memory or a new block is allocated and read in from the newly allocated block.","Each map block in memory has a separate structure associated with it that is used to maintain the cache. The structure is referred to as map block header. Map block header has a block physical address field, a flag\/state field, pointers for hash chain list and a free\/dirty list, a reference count, a lock (e.g., a mutex scheme) protecting the structure, and a pointer to the 4K map block itself.","There are two linked lists a map block can be on\u2014a free\/dirty list, and a hash list. All map blocks are linked via free\/dirty list pointers and either on the free list or the dirty list depending on the block's state. A map block on the free list is either an uninitialized map block or a clean map block. A map block on the dirty list is a dirty map block with data that needs to be written back to storage. A hash list is used to find a map block in memory. First, a hash function identifies the hash chain, which is scanned linearly to find the block by the physical address of the block. Uninitialized blocks are not on the hash chain.","In one embodiment, a map block and its header can be in the following states:\n\n","There are multiple dirty lists of map blocks. For example, there are two dirty lists for periodic snapshots maintenance, and another one for user initiated per VDI snapshot. Each dirty map block is on one of these dirty lists. Dirty map blocks do not get flushed in any automatic fashion. In one embodiment, a user of a map block cache has to call functions, such as vs_map_flush (dirty_list) function, to initiate map blocks writes. After writes are complete, the map blocks become clean and available for reuse.","TABLE II illustrates an embodiment of multiple map block cache Application Programming Interfaces (APIs). Those skilled in the art will recognize that TABLE II represents only one example of a set of APIs, and a variety of other sets of APIs with the same or different functions can be used to implement the map block cache.",{"@attributes":{"id":"p-0102","num":"0104"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"266pt","align":"center"}},"thead":{"row":{"entry":"TABLE II"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Map Block Cache APIs"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["API","Meaning"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["vs_map_get(pba)","Given physical address of a map block, first look up in the"]},{"entry":[{},"memory cache for the given PBA. If the block is not in the"]},{"entry":[{},"cache, get a free block from a free list or allocate a new one as"]},{"entry":[{},"appropriate and read the block from the new allocation."]},{"entry":[{},"Increment reference count and return blocks address."]},{"entry":["vs_map_alloc(pba)","Get a free block from free list or allocate a new one as"]},{"entry":[{},"appropriate, initialize it, increment reference count, mark it"]},{"entry":[{},"dirty, and return it. No I\/O is necessary. As an additional"]},{"entry":[{},"check, look up the \u201cpba\u201d to make sure it is not in the cache."]},{"entry":["vs_map_put(block)","Decrement reference count. If reference count drops to zero"]},{"entry":[{},"and the map block is not dirty, put it on the free list."]},{"entry":["vs_map_dirty(list)","Marks given list of map blocks dirty. Removes the blocks from"]},{"entry":[{},"the free list which makes them unavailable for reallocation."]},{"entry":["vs_map_flush(list)","Initiate I\/O operation to put the block on the list on the storage"]},{"entry":[{},"as appropriate, and return to the caller. When I\/O is done,"]},{"entry":[{},"mark the block as clean"]},{"entry":["vs_map_init_pool(buf)","Initialize temporary map cache from an array of map blocks."]},{"entry":[{},"This is used for instance in flushers to read in log mark and"]},{"entry":[{},"traverse submaps that are recorded in it."]},{"entry":[{},"It is assumed that the traverse never reaches outside of the set"]},{"entry":[{},"of map blocks in the log mark. Map blocks in such a pool"]},{"entry":[{},"never become dirty and never need to be reallocated and\/or"]},{"entry":[{},"flushed."]},{"entry":["vs_map_get_pool( )","This function is similar to vs_map_get( ) function but"]},{"entry":[{},"retrieves map blocks from temporary submap pool initialized"]},{"entry":[{},"by vs_map_init_pool( ). It is intended for submap"]},{"entry":[{},"traversal in the assumption that all of the submap resides in the"]},{"entry":[{},"buffer provided to vs_map_init_pool( ) so no I\/O is ever"]},{"entry":[{},"performed."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"Map block cache is based on 4K pages that are same as the map block size. The map block cache may grow and shrink according to predetermined cache-min and cache-max parameters. Initially metadata cache has a cache-min size. Cache-max value depends on total amount of physical memory available in Dom0 (e.g., Service Domain or Console OS). In one embodiment, heuristics are used to decide when to allocate memory for map block cache.","Physical Disk Space Allocation","A disk space in a SMS  represents the underling physical address space in the SMS . The storage space management module  is configured to manage the disk space in the SMS . The term \u201cdisk space\u201d and term \u201cphysical address space\u201d are used interchangeably from herein and throughout the entire specification. The storage space management module  addresses data blocks in the SMS  by a unique address that is a combination of a SMS internal volume ID and an offset in the volume. The SMS  treats this unique address as a \u201clow-level\u201d or physical address. In one embodiment, a physical address of 62 bits is divided into an offset of 46 bits and a volume ID of 16 bits in 512-byte sections of a volume. This allows 64K volumes of a very large physical address space size, and thus, a sparse physical address space.","The disk space management module  divides a disk space into three major categories: log space, live space and an optional history space. Log space is allocated per physical machine or SMS instance. Log space has a log (also called data log) associated with it. The main reason for log space is to mitigate transactional nature of writes imposed by complex block maps in SMS . Log space also helps to optimize disk heads contention between virtual machines running on different physical machines, and perform additional optimization based on write cancellation and aggregation. In addition, log space segregates reads from writes. For performance optimization log space may be allocated on dedicated spindles so that a SMS instance is solely responsible for disk heads scheduling on the SMS instance. Log space also helps to maintain VDI snapshots in the SMS .","Live space, also called production space, represents the current data as seen by virtual machines. Except for relatively small amount of transient data located in the log space, all live VDIs data is located in the live space. It means that majority of read operations from virtual machines is satisfied from live space.","In order to preserve sequential read throughput from live VDIs, live space is allocated in large extents or pages (e.g., 4 MB). Live space contains both parents' VDI data and data written in live VDIs. Live VDIs (leaves in the VDI map tree) may contain sparsely written large extends or pages. Data for these VDIs is obtained by reading both from parent VDI large extent and the active VDI large extent as appropriate in an interspersed manner.","As live VDI is getting one or more snapshoot, the multiple snapshots links in a chain. A single read operation from a virtual machine becomes multiple reads across multiple number of disk locations associated with the multiple snapshots in order to assemble the pieces across the multiple snapshots. While potentially acceptable for historical snapshots, multiple snapshots of a live VDI may not be appropriate for live space. An active live VDI data is always in both live space and log space. For example, live space contains the data from the latest flushed periodic snapshot of a live VDI, while the most recent data written since then resides in the log space.","In order to support cloning of already cloned children without significant performance penalty, live space has a notion of heavyweight snapshots. If an active VDI needs to be cloned and become a base for other live VDIs, the sparse large extents need to be eliminated by copying missing data into the unwritten holes. In other words, the snapshot needs to become a heavyweight snapshot. Depending on the particular embodiment, this copying may need to be done with or without active access to children VDIs.","Optional history space contains historical data of VDIs. History space contains the data written in the SMS  (ignoring very transient data blocks that were written and rewritten within very short period of time, basically between snapshots). If history space is enabled, the SMS  offers inherent disk to disk backup capability and fast disk failure recovery for server virtualization.","Optional history space gets its content from the log of the log space. As the data is digested and placed into history space, the storage space management module  creates automatic periodic snapshot in history space for each VDI. Frequency of these snapshots is configurable and does not depend on the behavior of live space. As log data is getting flushed from the log space into the live space, the old data for the same logical location can be also obtained from the log space and gets flushed into the history space.","Optional history space performance requirements are less stringent than that of live space allocation. Reads and writes in the history space does not have to occur in large extends (as live space) and can be done in natural I\/O sizes. This means that reading from older snapshots may require multitude of disk seeks and hence be slow. Space allocation in history space is similar to live space. In one embodiment, it is based on fixed size 4M pages.","A data write in the SMS  is first written into log space for minimizing disk heads contention. Additionally, data writes into log space first also allows mitigation of transactional writes, write cancellation and aggregation, and separation of writes from majority of reads. Multiple writes to log space are strictly sequential because physical disks have much better data throughput in sequential access than other means of multiple writes. Sequential writes to log space is maintained by the storage space management module  by allocating log space on a per physical machine basis and the physical machine contains dedicated disk spindles for the log space allocation.","Log (i.e., log space data log) in log space is flushed periodically into various destinations depending on configuration of SMS . In one embodiment, history space is not enabled, and log space data gets flushed into live space. Log space wraps around after flushing the data to make space for new writes. In another embodiment, history space is enabled and configured. Log in the log space then have two data flushes: a first data flush into live space by a live flusher and a second data flush into history space by a history flusher. Periodic data flush into history space creates snapshot VDIs representing corresponding live VDI at some point in a computing process. Frequency of the historical snapshots can be set in a policy setting of the history flusher. The history flusher can accumulate multiple data flushes over periods of time and collapse the accumulated data flushes into a single snapshot into the history space.","History space contains complete data for the historical snapshots. Periodic history snapshots represent near continuous data protection feature that SMS  provides. If history space is added to an existing SMS , there is an initial copy of live space data into the history space. The history flusher take care of the changes in the live space. It corresponds to a full disk backup followed by incremental disk backups.","For newly created VDIs or a live VDI with no write in a while, log space is empty and all VDIs data resides in the live space. New writes into a VDI go to the log space of the physical machine that manages this VDI. For some period of time, the newly written VDI's data resides in the log space only, and the VDI resides in both log space and live space. The VDI's maps contain pointers to the right locations in the log space and live space. All virtual machines running in the same physical machine share the same log space, and data from all live VDIs on the physical machine is interspersed in the log space.","Log from the log space is flushed into live space with a predetermined system specific frequency. In one embodiment, a typical number for the frequency of flushing data into the live space can be between 30 and 300 seconds. As log space is dedicated to a physical machine, the frequency is not long because all data has to reach live space before a VDI can become available on a different physical machine as needed for virtual machines mobility.","A snapshot VDI from the history space can be cloned to create a new live VDI. However, such live VDI exists in history space only. Furthermore, the data that belongs to this VDI must not be flushed to live space but in history space only.",{"@attributes":{"id":"p-0119","num":"0121"},"figref":"FIG. 9","b":["900","900","910","920","930","912","910","902","910","320","950","960","910","920","930","1","902","910","1","2","902","930","960","3","902","920","950","902","3","902","940","902"]},"Log associated with the log space in the SMS  is designed for write optimization. Each write in a SMS  is a transaction of writing data and map VDI map blocks from a logical address space represented by VDI maps to a physical address space represented by the log space. If data fragmentation is relatively high, number of map blocks that must be modified within a transaction can be substantial (e.g., up to five). The log in the SMS  is designed to make this transaction asynchronous. The log in the SMS  coalesces all the write operations that happened in certain time interval (30-300 seconds). A live flusher at a later time writes all of the data and corresponding metadata into the live space in much fewer I\/O operations, making it one large asynchronous transaction instead of multiple small synchronous ones.","Log content is flushed once (into live space only) or twice (into live and history spaces). Log content can be also replicated to remote site for disaster recovery functionality. In one embodiment, log has three nested regions:\n\n","In one embodiment, each data record in the log has the following parts: header (metadata), variable size data and tail. Metadata contains data extent magic number, sequential number, LBA and length. Tail contains magic number and sequential number. Tail helps to identify cases when the record is incomplete (for example, physical machine crashed in the middle of writing into the log).","Maps for the data blocks that are in the log for the duration are maintained in memory as a part of all VDI map data in memory. This is called a submap. Submap data gets written in the log space twice: the storage space management module  first puts just enough metadata information in every record in the log to make it possible to replay the log and recover the maps. In other words, submap data gets spread among all of the log records. Second writes happens periodically, for example, every 30-300 seconds, when the storage space management module  writes the entire submap accumulated during this time into the log. The corresponding log record is called log mark. In other words, a log mark contains the submap for the data in the log written in the last time interval.","These two kinds of submap data are used for log replay in case of system crash to ensure data and metadata consistency. Log replay starts with the last log mark, then reads the individual log records and reconstructs submap in memory. Log mark is associated with all VDIs that are managed by a specific physical machine. Submap in memory can grow large. In response to submap in the memory growing larger, the storage space management module  writes log mark ahead of a scheduled time interval and reuses the memory after writes. This effectively creates an extra unscheduled snapshot.","In one embodiment, marks in the log are done based on a technique similar to memory barriers such that log mark is a guarantee that all data writes in the log before it have completed. A log mark can also be used as a crash consistent snapshot mark. For example, the storage space management module  uses the log mark through a history flusher to construct snapshots in the history space. If writing into the log is faster than writing into live space, amount of un-flushed data in the log grows. The storage space management module  guarantees that metadata cache contains all of the maps data describing data in the log.","A log mark looks exactly like any other record in the log. It contains a header, variable size of data, and a tail. There are two kinds of log marks\u2014periodic and user requested. A periodic log mark contains VDI map blocks for all VDIs on a specific physical machine. A user requested log mark logically contains only map blocks for VDIs involved in the user requested snapshots. Log mark format is the same for both kinds, except that the user requested log mark has VDIs of interest marked with a flag. This flag is used later by a data flusher (e.g., history flusher or live flusher) to propagate the snapshot into the live space as a user visible snapshot.","A log mark data record contains:\n\n","Snapshots can be taken on a VDI during its normal read\/write operation. The snapshots semantics are strictly asynchronous; snapshots are issued directly into the stream of IO requests in a manner similar to log mark. In other words, a VDI snapshot is a log mark that contains only submap for this VDI. The snapshot is said to be \u201ccomplete\u201d when the snapshot mark is correctly placed in the log. These snapshot semantics enable the SMS  to complete a snapshot without pausing or delaying the IO requests, by allowing both pre-snapshot and post-snapshot IO to complete on their respective views of the disk after the completion of the snapshot.","In order to simplify locating the latest log mark, the storage space management module  maintains a short fixed size record that contains pointers to log marks. This short-fixed size record is log mark registry. The log mark registry is stored in a predefined place in the log space. The log mark registry is stored in a transactional manner. The log mark registry does not have to be stored as part of a log mark transaction because log mark data can be recovered as long as the storage space management module  can find a recent log mark and replay the log from that point.","A log mark registry shares the same log space with data log. The log mark registry does not affect write performance in the log space because the log mark registry modification is fairly infrequent, e.g., once per snapshot, or even every several snapshots (that is presumably once per 3-5 minutes). The log mark registry has a fixed size that can be estimated as following: N*8, where \u2018N\u2019 is a maximum number of live VDIs that are active on a physical machine. In one embodiment, \u2018N\u2019 is set to 1024 by the storage space management module .",{"@attributes":{"id":"p-0131","num":"0141"},"figref":["FIG. 10","FIG. 10","FIG. 10"],"b":["1010","101","0","1014","8","1012","910","1010","910","901","903","905","907","902","1014","902","910","902","910","902","902"],"i":["a","b","a","d ","b ","a ","c ","d "]},"Live and history spaces are allocated in large (e.g., 2 GB), contiguous units in physical address space extents, called SMS allocation units (VAU). Each physical machine is fully responsible for allocation inside the VAU for VDIs currently running on it. Each VAU is divided into multiple 4M pages that are contiguous in physical address space. At any point in time, a single SMS  instance has one or two active VAUs: one for live space and another\u2014optional\u2014for history space. A live VDI is not mixed with a snapshot VDI in a VAU because live space is optimized for performance and optionally can reside on separate storage pool with better quality of service. For example, live space can reside on fast SAS drives and history space on high capacity SATA drives.","A VAU is identified by a unique number. A VAU cannot cross underlying volumes boundaries. VDIs reside on multiple VAUs. Several VDIs can share a same VAU. Each VAU can be assigned to a specific physical machine or belong to master service . Master service  is to be described further in conjunction with description of . Majority of VAUs are pre-allocated among physical machines. This way of allocation minimizes communication with the master service  for additional VAU allocation at runtime.","Each VAU at any given point in time is being used for allocation by a single physical machine. VAU that is being consumed by a physical machine for allocation is called an active VAU for this physical machine. All VDIs running on this physical machine share the same active VAU. VDIs spread across multiple VAUs, active and not, such that many VAUs are accessible for reading.","Each VAU assigned to a physical machine can be in one of several states: unassigned, full, active or assigned. Master service  owns a predefined number of VAUs to be assigned to a physical machine on demand. A full VAU was active and has been filled out completely. SMS drivers  release full VAUs back to the master service . An active VAU is being used by a physical machine for physical space allocation. An assigned VAU is given to a physical machine to use and becomes active upon being used by the physical machine.","VDI map and data live in a single log and multiple VAUs. VAUs contain the VDI map blocks and VDI data extents. Multiple VDIs share the single VAU. However, each physical machine having a SMS  instance running on this machine controls space allocation in the active VAU. Multiple physical machines can read the VDI maps and data from the same VAU.","For example, assuming that a physical machine handles two VDIs, each of which belongs to two different virtual machines  and  respectively. Data extents and map blocks of the VDIs are mixed in the same active VAU. If later at least one of these virtual machines will be restarted on another physical machine, the two physical machines read the same VAU that contains the data extents and map blocks from both VDIs.","There are several objectives to be considered in space allocation algorithms by the storage space management module . One of them is to minimize data fragmentation in live space. In one embodiment, a physical machine, i.e., the owner of one or more VAUs, allocates space inside the active VAU in fixed size 4M pages. The way these 4M pages are used in live space and history space is different. Live space is more performance sensitive. The storage space management module  minimizes data fragmentation in live space by allocating a whole 4M page contiguously in physical space and VDI logical space exclusively for a specific VDI. In history space, multiple VDIs from the same historical period share a same 4M page. The storage space management module  switches to the new page when current page is full or it moves to the next snapshot in history space. As the storage space management module  switches to the new VDI for new history snapshot, the previously active page is left partially unused. Virtual machines using inactive VDIs can result in significant space overhead. In this case, the history flusher may decide to skip the periodic snapshot since there is very little value doing it anyways. Keeping space allocation localized per historical snapshot allows for much easier space reuse when snapshots are removed from history space.","Another objective to be considered in space allocation algorithms by the storage space management module  is to ease de-allocation and garbage collection by separating objects by their time of de-allocation. Live and history spaces are allocated in a context of flushers, not in a context of requests from virtual machines (I\/O steams optimization might be an exception). Map blocks and data extents share VAU space but use separate pages. Space allocation for map blocks and data extents is identical and is page based. A single page may contain data extents (called data page) or VDI map blocks (metadata page). In order to simplify free space management in live space, the storage space management module  does not mix map blocks from different VDIs in a single metadata page. However in history space multiple VDI map blocks do share the same page. History space allocation is not a problem because historical snapshots deletion is done by the whole pages allocated per historical period. This means that 4M page is the smallest object that needs to be considered by garbage collector and space reuse logic.","The first 4M page in each VAU is metadata page. In most cases this is the only metadata page in the VAU. If written data is very fragmented, there may be a need for more metadata pages. They are allocated intermixed with data pages in the VAU. Metadata pages contain fixed size map blocks with 4K each. The first metadata page in each VAU contains two 4K extents as a redundant free pages bitmap. Free blocks and free pages bitmaps share same 4K extent. Redundant free pages bitmap makes its changes transactional. If the storage space management module  has to modify the free pages bitmap, the storage space management module  writes the second copy first and then the first copy.","In one embodiment, a bitmap extent of 4K size comprises a header of 64 bytes long, a free pages map of 64 bytes, another free pages bitmap of 128 bytes long, a data\/metadata bitmap of 128 bytes long and a tail of 64 bytes. The header contains the magic number, sequential number, total number of free blocks and total number of free pages. It is followed by free blocks and free pages bitmaps (64 and 128 bytes respectively), reserve field and tail. Tail also contains magic number and sequential number that guarantee together that bitmap extent has been written completely.","Log, live, and optional history spaces reside on the set of block devices called SMS volumes or simply volumes. Each SMS block device has a private region or a SMS label that identifies it. The label contains the following information: magic number, SMS ID that this volume belongs; volume ID and PBA of VAU that contains Master VDI. Master VDI is to be further described below. If the SMS label does not exist or does not contain appropriate information (for instance, the SMS ID does not match current one), the block device cannot be used.","SMS ID identifies the SMS the volume belongs to. The SMS ID prevents from moving storage from one SMS entity to another. Volume ID is a 16-bit number that uniquely identifies a volume within the SMS . Volume ID presents in PBA in bits [46:61]. Being set once, the volume ID does not change. The PBA of VAU that contains Master VDI allows for an easy way to locate Master VDI root map block without any external assistance. It is possible because its location in the VAU is fixed. This allows a SMS driver  to locate Master VDI and provide for master service bootstrap.","SMS label is written once by the SMS driver  under master service control, and the SMS driver  runs on the same physical machine that the Master VDI does. Upon boot the SMS drivers  discovers SMS storage volumes, open them, and read labels from all volumes\u2014members of this SMS instance. The SMS drivers  maintain the table that links volume ID with block device handle. Each time when a VDI is going to be connected, master service  checks that all SMS volume devices presence in the system. If not, it rejects the VDI connect request.","Turning now to ,  is a block diagram of a SMS data storage space  according to one embodiment of the invention. The SMS data storage space  comprises a log space of dedicated logs -and a shared live and history space . Each dedicated log  corresponds to a volume  which is a set of physical data storages devices . The shared live and history space  comprises multiple VAUs. Two or more VAUs correspond to a volume  which is a set of physical data storage devices . The storage space management module  manages the physical address space represented by the sets of volumes as described above. For example, the storage space management module  allocates the log space per physical machine basis. If a physical machine is no longer present, the log needs to stay for duration of flushing into live and (optionally) history space. Once log is completely flushed, it can be reused for some other computing purposes.","Methods","The SMS  presents the abstraction of physical volumes as multiple block devices to guest VMs via SMS drivers . The SMS drivers  translate logical address to physical addresses on the underlying physical volumes responsive to the I\/O requests from a backend driver. A block device driver reads from and\/or writes into the physical volumes -based on the address space translation from the SMS driver .",{"@attributes":{"id":"p-0147","num":"0157"},"figref":["FIG. 12","FIG. 2"],"b":["200","200","1202","200","1204","200","1206","200","1208","1210","200","200"]},"PBA contains two parts\u2014log mark number and relative offset inside log mark. Unique log mark number helps the SMS  keeping multiple log marks: new blocks with same offset from different log marks have different PBAs. The SMS  parse LBA and uses the log mark number as key for searching a log mark registry in order to obtain absolute map block address inside the log. The SMS  performs  the write operation into the log based on the above translation. Further, the SMS  modifies  affected map blocks and allocates new ones if needed. Modified map blocks do not stay in place. Instead, the modified map blocks are reallocated into the log mark area. Allocation is done as described in step . For map blocks that are already in the log mark, these map blocks are already dirty. The SMS  obtains new map blocks after relative PBA is determined. This requires translation of original LBA into a chain of affected map blocks. Responsive to the write into the log being complete, the SMS  confirms  the write request. The SMS  returns to step  to receive next I\/O request after the write confirmation.","Responsive to the I\/O request being not a write request, the SMS  checks  whether the I\/O request being a read request. If the I\/O request is not a read request, the SMS  performs  the requested operation. Responsive the I\/O request being a read request, the SMS  performs  the read request as illustrated in .  is a flow chart illustrating an example of processing a read request by the SMS  illustrated in  according to one embodiment of the invention. Initially, the SMS  receives  a read request from a virtual machine. In one embodiment, the read request contains information of a logical block address and buffer length requested. The SMS  obtains  the LBA parameter and buffer length from the read request. The SMS  calculates the offset in the log based on the LBA and buffer length in the read request and translates  the LBA to the PBA through VDI map similar to step  illustrated in . The SMS  performs  the read operation from the log based on the above translation. Responsive to the read from the log being complete, the SMS  confirms  the read request.",{"@attributes":{"id":"p-0150","num":"0160"},"figref":"FIG. 14","b":"200"},"Initially, the SMS  obtains  the snapshot mark that needs to be flushed into the live space. In one embodiment, a live flusher of the SMS  uses the log mark registry to determine the snapshot to be flushed and gets information, such as log mark offset in the log, log mark size, etc. of the determined snapshot. The live flusher allocates  memory to accommodate the whole log mark in the memory and reads the content into this buffer (i.e., the newly allocated memory). The log mark registry allows such memory allocation because the log mark registry has an area that contains information about all the modified map blocks. The live flusher traverse  the submap of the log and creates a list of data blocks in the log that need to be written into the live space. After traversing the submap, the live flusher discards the log mark in memory and frees the memory containing the log mark. No I\/O operation is needed to free the log mark in memory. The live flusher starts looping through  the list of data blocks reading data extents from the log and writing the data extents into the live space. For example, the live flusher accesses map blocks from the live space. The live flusher modifies the map blocks accordingly and maintains the list of dirty map blocks. The modified map blocks need to be reallocated in the live space to help maintain transactional nature of flush, e.g., allocate new PBA for a map block and to obtain map block in memory.","New data and map block allocation changes free bitmaps in an active VAU. These changes are kept in memory. The bitmaps is stored simultaneously with the VDI root pointer as a transaction now needs to be updated to reflect new location. The live flusher updates  the affected map blocks to reflect the new locations. In one embodiment, the SMS  updates the affected map blocks using a \u201clazy-cutoff\u201d procedure, which is further described in detail below. Responsive to the data flush being complete, the live flusher flushes  the list of dirty map blocks. The map blocks are marked clean in the cache automatically by the live flusher. The live flusher switches  to the updated VDI maps in the live space for all affected VDIs. The live flusher modifies the VDI root pointer as a transaction. Allocation information\u2014changes to free bitmaps\u2014is also recorded as part of this transaction.","Generally, log marks and data are not overwritten in the log until they are flushed into history space. A history flusher works almost identical to the live flusher described in conjunction with  with only one exception: the history flushers creates a snapshot VDI when it flushes a snapshot. Snapshot VDI can be created per each flushed snapshot or less frequently based on instructions from a SMS administrator.","The active VDIs map needs to be updated in memory (log space ) as a live flusher  relocates data blocks from the log into the live space. The active VDIs map can be updated proactively or lazily. Proactively updating the VDIs map can become a performance bottle neck. In lazy VDIs map update, the SMS  maintains the range of valid physical address in the log, checks every address reference for validity, and fetches the correct address when necessary from the live space. The range of valid physical addresses in the log is easy to determine: it is the un-flushed area. Every physical address that refers to the log space  is checked for validity by the SMS . If a physical address points into the area of the log that is already flushed, it means that the map record needs to be updated. A valid physical address is obtained by looking up the logical address in question in the live space. These new physical address replaces the invalid one in the cached map block using the lazy cutoff procedure. No disk map blocks need to be touched.",{"@attributes":{"id":"p-0155","num":"0165"},"figref":"FIG. 18","b":["1800","200","1802","200","1804","200","1806","400","200","1808","400","960"]},"Responsive to a virtualization platform starting a virtual machine on the new physical machine, the SMS  on the new physical machine sends the master service  a connect request to obtain  VDI ID to root map block translation. The master service  returns references to the root map blocks in the old log as well as previously saved log mark registry from the old physical machine. The SMS  on the new physical machine creates  full log mark for active VDIs before the SMS  confirms VDIs being moved. This log mark is used as synchronization barrier between flushers on the new and old physical machines. As the virtual machine on the new physical machine is running, new data is written in the new log of the new physical machine.","As the VDIs maps have references to the old log, the lazy cutoff algorithm is fully deployed for the VDIs being moved. The live flusher  on the new physical machine keeps flushing  the log  until it reaches the point where the VDIs being moved are connected. It is noted that the live flusher  in the new physical machine cannot cross this point until the live flusher  on the old physical machine completes flushing the data for the VDIs being moved. At the same time, the live flusher  on the old physical machine keeps flushing  data from the old log to the live space. When the flusher on the old physical machine gets to the log mark that was created upon VDIs being moved, the SMS  sends  a notification to the master service , which relays the notification to the new physical machine. As a result, the updated data effectively validates the old log registry data. The old and new physical machines complete the lazy-cutoff procedure and resume normal operations.","Master Service ","Referring back to the SMS  illustrated in , in SMS , a virtual machine runs a single, system cluster wide management service called Master Service  or simply Master. Master Service  provides multiple functionalities to the SMS  including global VDI ID to root map block translation, allocating VAU to VDI IDs upon SMS driver  request, maintaining VDI namespace and SMS objects database, and communicating with a virtualization platform management system that runs a SMS graphical user interface (GUI). The Master Service  communicates with the SMS drivers  via a communication interface  using one or more SMS internal communication protocols.","In one embodiment, Master Service  runs as a special virtual machine or virtual appliance. It can run on any physical machine in the SMS . It is assumed that a virtualization platform guarantees that single copy of Master Service  always runs in a SMS cluster (except for short period of time when Master Service  is restarted or moved\/failed-over on another physical machine).","Master Service  uses local API to communicate with a local SMS driver . The API provides specific access to the SMS physical storage that allows Master Service  to implement functions like garbage collection, destroying VDI, etc. without having direct access to the SMS physical storage. In other words, Master Service  accesses physical storage indirectly via the API. A SMS driver  on a physical machine can start without Master Service . However, it is more practical to have a Master Service  to activate\/connect any VDIs to virtual machines.","Master Service  manages multiple persistent system objects that depend from each other in a system-wide object database. Each system object in the object database has state, attributes and methods. Methods associated with an object are specific to the object and do not change. Attributes are persistent qualities of the object and are stored in the object database. State is not persistent and is kept only in memory. Table III illustrates some system objects in the objects database of the SMS . Those skilled in the art will recognize that TABLE III represents one example of an embodiment for groupings of object, state, attribute and extension of the object database of the SMS . A variety of other embodiments for groupings of the object, state, attribute and extension of the object database are possible.",{"@attributes":{"id":"p-0162","num":"0172"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"center"}},"thead":{"row":{"entry":"TABLE III"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"System Objects Database"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"70pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Object","State","Persistent Attributes","State Extension"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["Physical","Present and","SMS volume ID","Detailed information"]},{"entry":["Volume","working","Space it belongs to (Log or","describing the reason"]},{"entry":[{},"Present and","Live\/History space)","of volume failure"]},{"entry":[{},"failed","Owner: valid only for volumes that"]},{"entry":[{},"Not present","contains Log; indicating physical"]},{"entry":[{},{},"machine ID that owns the log"]},{"entry":["Physical","Present","Machine ID"]},{"entry":["Machine","Not present","SMS driver cluster ID running on this"]},{"entry":[{},{},"machine"]},{"entry":["SMS Entity","Working","SMS ID","Detailed information"]},{"entry":["Object","In jeopardy","Master Cluster ID (e.g., cluster-wide","describing the reason"]},{"entry":[{},"(e.g., master","IP address)","of the SMS failure"]},{"entry":[{},"VDI has failed)","Volume ID","(e.g., not all physical"]},{"entry":[{},"Failed","VAU number that contains Master","volumes present,"]},{"entry":[{},{},"VDI","object database down;"]},{"entry":[{},{},{},"Master VDI failed)"]},{"entry":["VDI",{},"Status:"]},{"entry":[{},{},"1. connected and clean"]},{"entry":[{},{},"2. connected and not clean"]},{"entry":[{},{},"3. disconnected and clean"]},{"entry":[{},{},"4. disconnected and not clean"]},{"entry":[{},{},"5. destroying"]},{"entry":[{},{},"6. merging data into a single"]},{"entry":[{},{},"child"]},{"entry":[{},{},"VDI name"]},{"entry":[{},{},"VDI ID"]},{"entry":[{},{},"Physical machine ID running this"]},{"entry":[{},{},"VDI"]},{"entry":[{},{},"Type (live VDI or snapshot VDI)"]},{"entry":[{},{},"Reference count"]},{"entry":[{},{},"Claimed size"]},{"entry":[{},{},"Size on disk"]},{"entry":[{},{},"Quotas (disk space and bandwidth"]},{"entry":[{},{},"limitations)"]},{"entry":["VAU",{},"Owner (physical machine ID; 0"]},{"entry":[{},{},"means Master)"]},{"entry":[{},{},"Available size"]},{"entry":["Available",{},"Owner (physical machine ID; 0"]},{"entry":["VDI ID",{},"means Master)"]},{"entry":["Regions",{},"VDI ID range (e.g., [from:to] format)"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}]}}},"It is noted that VDI and VAU objects are persistent system objects that do not have state. The SMS entity object represents the whole SMS  in terms of system object. In other words, the SMS  is fully functional if the SMS entity object indicates that the SMS physical storage repository is working properly and the Master Service  fully is functioning. For example, without the Master Service  fully functioning, new VDIs cannot be connected and new virtual machines cannot be started. Master Service  is not treated as an independent SMS entity object in the SMS , but as a part of the SMS entity object. An administrator of the SMS  has access to all types of the system objects in the object database of the SMS .","Each VDI in the SMS  is identified by a unique ID, which is used to link the VDI to its root map block. The Master Service  provides a mechanism to translate the VDI ID into its root map block pointer. For VDIs that are not active (connected) on any physical machine at the moment of running, the system object database contains information about the inactive VDIs, e.g., their root map pointers. For an active VDI, the object database has a record pointing to the physical machine that serves this VDI at the moment of the request. The actual root map block is maintained by that physical machine.","When active VDI is being deactivated\/disconnected (e.g., a virtual machine shuts down or has to be moved elsewhere), a log data flusher must flush the log first and then interact with Master Service  to report both the deactivation of the VDI and its final root map block location. Master Service  marks the final root map block location in the object database. Conversely, when a VDI is being activated or connected, the SMS driver  that performs the connecting interacts with Master Service . Master Service  provides the root map block address and registers the VDI as active. This is when and how the SMS  ensures exclusive access to VDIs.","Each snapshot VDI has an ID that can be used to obtain the snapshot VDI's root map block for cloning operation. Snapshot VDIs are translated through the same mechanism as for live VDIs. A running physical machine maintains current mapping for active and most recently created snapshot VDIs. The mapping has to be persisted in a local private area maintained by this physical machine\u2014local ID translation table\u2014so that this information can be recovered on reboot. This is also where the information is stored if Master Service  is temporarily unavailable.","A SMS driver  needs VDI ID to be assigned to newly created snapshot VDIs in live and history spaces. A VDI ID can be obtained from Master Service . In order to avoid \u201curgent\u201d communication with Master Service, Master Service  provides a range of available VDI IDs to each SMS driver . The information of the available VDI IDs is stored in the \u201cAvailable VDI ID Regions\u201d object in the object database of the SMS .","Master Service  is responsible for VAU allocation to physical machines. Further VAU usage is managed by specific physical machine. VAU allocation in the SMS  is designed in such a way that communication between the SMS drivers  and Master Service  is very infrequent. Furthermore, a SMS driver  can handle VDI I\/O requests even if Master Service  is down for relatively long period of time.","Specifically, Master Service  is responsible for managing VAU allocation for SMS drivers running on all physical machines in the SMS , and provides this information to the SMS drivers  on their start, on request, and on changes in physical layout of the SMS  such as adding new physical machines and\/or storage volumes. Master Service  also performs reallocation of unused assigned VAUs on demand from a physical machine running out of space. Unassigned VAUs (owned by Master Service ) can be assigned to a specific physical machine for exclusive usage. If the physical machine has been removed from the service (i.e., does not belong to the SMS cluster anymore), its VAUs is transferred\/reassigned among the rest of physical machines in the cluster.","A physical machine as a new member of the SMS  gets from Master Service  dedicated log and a set of VAUs. It means that a system administrator needs to keep a number of unallocated spindles that can be used for logs. Master Service  keeps information regarding all VAUs persistently in the object database. For Master Service  owned VAUs, there is available space information that is used to organize these VAUs in buckets by available space. For VAUs assigned to physical machines, only this assignment is stored in the object database. A physical machine notifies Master Service  when it is done with a VAU and is ready to release it back to the Master Service . This happens when an active VAU has no more usable space. It allows Master Service  to provide cluster-wide and per physical machine storage prediction and VAU allocation management.","SMS driver , through the VDI namespace module , keeps information about its VAUs status changes (from assigned to full) in the local persistent store that is a part of physical machine log space. This store is cleaned by the SMS driver  when Master Service  has handled the VAU status change notification and changed VAU ownership in the objects database (from physical machine to Master Service ).","Turning now to Master Service  implementation, Master Service  uses special VDI (like an inode in a file system) that contains namespace database using standard I\/O service to access this special VDI. The special VDI is referred to as Master VDI. Master VDI is always live and visible in Master Service . Normally, Master Service  boots off the Master VDI and mounts it as its root partition. High level configuration is stored in a file system tree on this Master VDI.","Master VDI (or more precisely, a file system mounted on this VDI) contains all configuration and management information that is required for running the SMS . Master VDI is created as a part of SMS  initialization process. Its location is discovered by SMS driver  without Master Service  assistance because Master Service  needs Master VDI first to start its service.","A SMS driver  finds the Master VDI or its root map block by canning all available volumes and locating volumes that belong to a SMS storage device. At least one of the scanned volumes contains Master VDI. The SMS driver  further reads the SMS label from each volume and finds the volume that has Master VDI indicator set. The SMS label has a pointer (i.e., a VAU index) at the VAU that contains Master VDI.",{"@attributes":{"id":"p-0175","num":"0185"},"figref":["FIG. 16","FIG. 16"],"b":["300","1600","300","1620","1600","1620","1620","1630","1650","1640","300"]},"Master VDI is fully allocated, unlike regular VDIs that are typically allocated as thin provisioned. It means that new writes goes directly to the disk without VDI map modification. In other words, it allows Master VDI to never write data in the log of log space. It simplifies Master Service  fail-over and bootstrap.","Master VDI contains a standard file system. Master Service  mounts (or boots off) Master VDI and accesses information in Master VDI via regular file system calls. In one embodiment, Master VDI includes the following sections (in form of files or directories):\n\n","It is noted that Master Service  allocates groups of available VDI IDs for each physical machine to let it be independent as much as possible from Master Service . SMS drivers  need new VDI ID when live or history flusher need to create a snapshot VDI. The live or history flusher does not want to wait for Master Service  that may have failed and to be in a failover process.","VDI Namespace Module ","Turning now to VDI namespace module  of the SMS driver , the VDI namespace module  is configured to manage a vast number of VDIs for server virtualization in a human readable manner. Specifically, to facilitate administrative operations, the VDI namespace module  maintains several name spaces or views that represent various aspects of VDIs. Different views can be used for different I\/O operations. In one embodiment, the VDI namespace module  provides an active VDI view, a parent-child ancestry view, a live VDIs view and an arbitrary view.","In an active VDI view\/namespace, the VDI namespace module  provides a system-wide view of all active VDIs. The VDI namespace module  also allows each physical machine to handle active VDIs associated with the physical machine under the active VDI view. The active VDI view presents a list and aggregated status information on some or all active VDIs in the SMS . The VDI namespace module  can group all the active VDIs together based on the scope of view. In one embodiment, Master VDI maintains the list of all active VDIs in the SMS . Master Service  reflects this information in the SMS objects database. The Master VDI gets a list of VDIs running on a specific physical machine also from the objects database. VDI object contains corresponding physical machine ID. An active VDIs namespace has only 2 levels: root that contains set of subdirectories. Each subdirectory represents a physical machine\u2014member of the SMS cluster, and contains list of active VDIs running on the corresponding physical machine.","The VDI namespace module  maintains full history of VDIs parent-child relationships that can be viewed as a tree. It helps administrators to visualize ancestry of VDIs and facilitate creation of virtual machines running with the appropriate disk images. Traversing this view allows the administrators to visualize the following information that represents parent-child relationship:\n\n","In one embodiment, the VDI namespace module  uses a file system directory structure to represent parent-child relation tree. A system administrator can traverse parent-child tree as a regular hierarchical tree starting from a grandparent VDI. The tree is build so that live VDIs are represented as leaves and are pushed down (root on top) the tree each time a new level of hierarchy is created. VDIs that have children or snapshots are represented as directories. Each directory contains a short file that describes whether this VDI has children and\/or snapshots and how many, along with VDI ID, attributes, flags etc. There are also up to two files listing children and their corresponding snapshots. In most cases, VDIs that do not have children or snapshots are represented by the record in one of the list files\u2014snapshot list file or children list file some other VDI. VDIs that do not have children or snapshots can also be represented as directories. In this case, the children and snapshot count is zero, and the list files are empty (or absent).",{"@attributes":{"id":"p-0183","num":"0211"},"figref":"FIG. 15","b":["1500","1500","1510","1510","1","1520","1510","1","1520","1510","1","1520","1530","1","1520","2","1520","1500","2","1","1540","3","1520","3","1520","1540","3","1520","1530","1","2","3","1550"],"i":["a","a","a","a ","a","b","c","c","b","c","b"]},"The VDI namespace module  also manages an arbitrary hierarchy created for a particular job which can be external to the SMS objects. For example, a particular workflow of server virtualization is represented by grouping together VDIs that belong to this workflow regardless of their ancestry or parent-child relationship. The VDI namespace module  helps a SMS administrator to create the needed arbitrary hierarchy and directory content (tree leaf and VDIs). Each level of hierarchy is represented by a subdirectory in the tree. The system administrator uses the VDI namespace module  to create any number of arbitrary name space trees. Some of these arbitrary trees can be controlled by an application such as backup to represent VDIs involved in a particular job. Note that backup agent may notify Master Service  directly about start and completion of backup session (via pre-backup and post-backup scripts). These events cause inserting or removing VDIs to\/from the backup specific group of VDIs.","The VDI namespace module  present the name space hierarchies, such as active, parent-child and arbitrary, as a hierarchical trees. A namespace browser\u2014integrated with platform management software or standalone\u2014sends VDI namespace requests to Master Service  for further process. For leaf nodes (representing specific VDIs), Master Service  returns a list of structures, which contains VDI name, VDI ID and VDI state. A SMS system administrator may require additional information about a specific VDI (for example, detailed status, I\/O statistics, etc.) using VDI ID as an identification parameter. VDI ID is shared between a virtualization platform and the SMS  to identify the requested VDI.","Communication Interface ","The SMS  communication has a star structure. Master Service  is in the center of the star and individual SMS drivers  are end points of the star. The communication interface  is configured to couple the individual SMS drivers  with Master Service . The individual SMS drivers  do not communicate with each other but only with Master Service  through one or more SMS internal communication protocols. Master Service  and each SMS driver  have a unique cluster ID that is used to implement a SMS internal protocol. Master Service  and each SMS driver  acquire their cluster ID from Master VDI upon SMS  boot procedure. Physical machines in SMS  are connected via a network connection, such as Ethernet. A SMS internal communication protocol is implemented on top of the Ethernet connection.","A SMS communication protocol supports both synchronous and asynchronous requests. The synchronous requests are logically similar to function calls\u2014when returned the action is complete and the result is known. An asynchronous requests means that the action is queued and there is a form of notification (rendezvous) to deliver results of the action. From time to time a SMS driver  and Master Service  communicates to notify each other of certain events or ask for service. TABLE IV is an example of a list of communication requests in the SMS . Other embodiments may a list of different communication requests in the SMS . Those skilled in the art will recognize that there may be any number of other types of request with different functionality and different components.",{"@attributes":{"id":"p-0188","num":"0216"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"center"}},"thead":{"row":{"entry":"TABLE IV"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"SMS Communication Request"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"210pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["SMS Component","SMS Communication Requests"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["VDI Management","Create new empty VDI"]},{"entry":[{},"Destroy live VDI"]},{"entry":[{},"Destroy snapshot VDI"]},{"entry":[{},"Snapshot live VDI"]},{"entry":[{},"Clone snapshot VDI"]},{"entry":[{},"Available region of VDI IDs allocation for SMS driver"]},{"entry":[{},"Notification about VDI failure and I\/O errors"]},{"entry":[{},"Statistics (I\/O related, disk space related)"]},{"entry":["Namespace","Handle notification from live or history flusher that snapshot VDI has"]},{"entry":[{},"been created to reflect that in VDI namespace"]},{"entry":[{},"Handle notification that snapshot VDI has been merged and destroyed"]},{"entry":["VAU Management","VAU allocation for SMS drivers upon request"]},{"entry":[{},"VAU rebalance (take assigned VAU back to assign them to another"]},{"entry":[{},"more needy physical machine)"]},{"entry":[{},"Releasing ownership of VAUs (a SMS driver gives up VAU ownership"]},{"entry":[{},"if VAU is full)"]},{"entry":["VDI","Translation of VDI ID into root map block pointer upon VDI"]},{"entry":["Connect\/Disconnect","connection"]},{"entry":["Arbitration","Final object database update when VDI switches from active to"]},{"entry":[{},"inactive state (e.g., new root map location and statistics)"]},{"entry":["SMS Backup","Assign physical machine to flush whole Log that belonged to a"]},{"entry":[{},"physical machine that crashed."]},{"entry":["VAU","Owner (physical machine ID; 0 means Master)"]},{"entry":[{},"Available size"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},{"@attributes":{"id":"p-0189","num":"0217"},"figref":"FIG. 17","b":["1700","1700","1710","1720","1730","1720","1710","1720","1700","1730","1740","1760","1740","1730","1720"],"i":["a","c"]},"When a virtual machine starts, the console server  decides which physical machine  to use, and asks the management daemon  to create and start the virtual machine according to its configuration. The management daemon  performs one or more steps to create a virtual CPU, memory, buses, and connects the required devices, after which the newly created virtual machine starts execution. One of the virtual machine of a physical machine (e.g., ) is selected to be Master Service .","As some of the devices that are being connected in a virtual machine are VDIs backed up block devices, the SMS driver  associated with the virtual machine is notified at this stage as well. The management daemon  of a physical machine  communicates with the SMS driver  on this physical machine  using an API. The management daemon  provides the set of VDI IDs that correspond to virtual disks for virtual machine being started. The SMS driver opens required VDIs. Starting from this moment, the SMS instance  is set to perform I\/O operations from guest virtual machine.","The SMS cluster  has its own internal communication protocol  among Master Service  and SMS drivers -. Master Service  in turn has a special communication channel  with the SMS driver  on the same physical machine. This communication channel is used by Master Service  to perform its operations when access to low level storage is needed. In one embodiment, communication messages in the SMS cluster  can be classified as following:","Administrative messages\u2014from the console server  to a SMS driver \n\n","Notification messages\u2014from the SMS driver  to the console server :\n\n","VDI runtime control messages\u2014from the console server  or management daemon  to the SMS driver :\n\n","As noted above, the storage management system  provides the functionality that enables server virtualization in data centers with enhanced system performance. For example, the storage management system  provides support for managing large volumes of data storage device, e.g., millions of different volumes of data storage devices. Complex server virtualization operations, such as taking a snapshot of a whole OS image and continuing its execution at a later time form the exact point it was stopped, are efficiently supported by the disclosed storage management system .","The foregoing description of the embodiments of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. It is intended that the scope of the invention be limited not by this detailed description, but rather by the claims of this application. As will be understood by those familiar with the art, the invention may be embodied in other specific forms without departing from the spirit or essential characteristics thereof. Likewise, the particular naming and division of the modules, routines, features, attributes, methodologies and other aspects are not mandatory or significant, and the mechanisms that implement the invention or its features may have different names, divisions and\/or formats. Furthermore, as will be apparent to one of ordinary skill in the relevant art, the modules, routines, features, attributes, methodologies and other aspects of the invention can be implemented as software, hardware, firmware or any combination of the three. Also, wherever a component, an example of which is a module, of the invention is implemented as software, the component can be implemented as a standalone program, as part of a larger program, as a plurality of separate programs, as a statically or dynamically linked library, as a kernel loadable module, as a device driver, and\/or in every and any other way known now or in the future to those of ordinary skill in the art of computer programming. Additionally, the invention is in no way limited to implementation in any specific programming language, or for any specific operating system or environment. Accordingly, the disclosure of the invention is intended to be illustrative, but not limiting, of the scope of the invention, which is set forth in the following claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The invention is illustrated by way of example, and not by way of limitation in the figures of the accompanying drawings in which like reference numerals are used to refer to similar elements.",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 1B","FIG. 1A"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 5B","FIG. 5A"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 5C","FIG. 5B"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 6B","FIG. 6A"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 12","FIG. 2"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 13","FIG. 2"]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 18"}]},"DETDESC":[{},{}]}
