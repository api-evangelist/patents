---
title: Multimedia print driver dialog interfaces
abstract: The system of the present invention includes a media-printing interface that allows users to interact with a multimedia transformation process and format multimedia data to generate a representation of multimedia data. The present invention provides a user interface that permits users to interact with media content analysis and media representation generation. A media analysis software module receives media content analysis instructions from the user through the user interface, and the media analysis software module analyzes and recognizes features of the media content, such as faces, speech, text, etc. The media representation can be generated in a paper-based format, in digital format, and in any other representation formats. The user interface includes a number of fields through which the user can view media content and modify the media representation being generated. The methods of the present invention include interacting with a user interface to control the media data analysis and media representation generation, and analyzing features of media data. The methods also include driving the media data analysis, and driving the media representation generation by receiving instructions and sending instructions regarding media representation parameters. The methods can also include generating a media representation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07861169&OS=07861169&RS=07861169
owner: Ricoh Co. Ltd.
number: 07861169
owner_city: Tokyo
owner_country: JP
publication_date: 20040330
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCES TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["This application claims the benefit of the following provisional patent applications, each of which is incorporated by reference in its entirety: U.S. Provisional patent application entitled \u201cPrinter Including One or More Specialized Hardware Devices\u201d filed on Sep. 25, 2003, having Ser. No. 60\/506,303, and U.S. Provisional patent application entitled \u201cPrinter Driver, Interface and Method for Selecting and Printing Representations of Audio, Video or Processed Information\u201d filed on Sep. 25, 2003, having Ser. No. 60\/506,206","This application is related to the following co-pending U.S Patent Applications (hereinafter referred to as the \u201cVideo Paper Applications\u201d), each of which is hereby incorporated by reference in its entirety: U.S. patent application Ser. No. 10\/001,895, \u201cPaper-based Interface for Multimedia Information,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/001,849, \u201cTechniques for Annotating Multimedia Information,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/001,893, \u201cTechniques for Generating a Coversheet for a paper-based Interface for Multimedia Information,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/001,894, \u201cTechniques for Retrieving Multimedia Information Using a Paper-Based Interface,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/001,891, \u201cPaper-based Interface for Multimedia Information Stored by Multiple Multimedia Documents,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/175,540, \u201cDevice for Generating a Multimedia Paper Document,\u201d filed Jun. 18, 2002; and U.S. patent application Ser. No. 10\/645,821, \u201cPaper-Based Interface for Specifying Ranges,\u201d filed Aug. 20, 2003.","This application is related to the following co-pending U.S Patent Applications, each of which is hereby incorporated by reference in its entirety: U.S. patent application Ser. No. 10\/081,129, to Graham, entitled \u201cMultimedia Visualization and Integration Environment,\u201d filed on Feb. 21, 2002; U.S. patent application Ser. No. 10\/701,966, to Graham, entitled \u201cMultimedia Visualization and Integration Environment,\u201d filed on Nov. 4, 2003; U.S. patent application Ser. No. 10\/465,027, to Graham, et. al., entitled \u201cInterface For Printing Multimedia Information,\u201d filed on Jun. 18, 2003; U.S. patent application Ser. No. 10\/465,022 entitled \u201cTechniques For Displaying Information Stored In Multiple Multimedia Documents,\u201d to Graham, et. al., filed on Jun. 18, 2003; U.S. patent application Ser. No. 10\/174,522, to Graham, entitled \u201cTelevision-Based Visualization and Navigation Interface, filed on Jun. 17, 2002; and U.S. patent application Ser. No. 10\/795,031 to Graham, entitled \u201cMultimedia Visualization and Integration Environment,\u201d filed Mar. 3, 2004.","This application is also related to the following co-pending patent applications, each of which is hereby incorporated by reference in its entirety: U.S. patent application entitled, \u201cPrinter Having Embedded Functionality for Printing Time-Based Media,\u201d to Hart et al., filed Mar. 30, 2004, U.S. patent application entitled, \u201cPrinter With Hardware and Software Interfaces for Peripheral Devices,\u201d to Hart et al., filed Mar. 30, 2004, U.S. patent application entitled, \u201cPrinter User Interface,\u201d to Hart et al., filed Mar. 30, 2004, U.S. patent application entitled, \u201cUser Interface for Networked Printer,\u201d to Hart et al., filed Mar. 30, 2004, and U.S. patent application entitled, \u201cStand Alone Multimedia Printer With User Interface for Allocating Processing,\u201d to Hart et al., filed Mar. 30, 2004, U.S. Patent Application entitled \u201cNetworked Printing System Having Embedded Functionality for Printing Time-Based Media,\u201d to Hart, et al., filed Mar. 30, 2004, U.S. Patent Application entitled \u201cPrintable Representations for Time-Based Media ,\u201d to Hull, et. al., filed on Mar. 30, 2004,and U.S. Patent Application entitled \u201cPrinting System with Embedded Audio\/Video Content Recognition and Processing,\u201d to Hull et. al., filed on Mar. 30, 2004.","1. Field of the Invention","The present invention relates to systems and methods for providing a multimedia printing interface. In particular, the present invention relates to systems and methods for providing a print driver dialog interface that allows users to format multimedia data to generate a representation of multimedia data.","2. Description of the Background Art","Printers in modern systems today are not designed to generate multimedia documents. Currently, there is not any effective method for generating an easily readable representation of multimedia content in either paper or digital format. Several different techniques and tools are available for accessing and navigating multimedia information (e.g., existing multimedia players). However, none of these provide the user with the option of creating a multimedia document that the user can easily review and through which a user can gain access to multimedia content.","Printers in modern systems today are also not designed to facilitate interaction with multimedia content or with print content, in general. Standard printer dialog boxes provide users with some general formatting options in a print job, such as number of pages to print, number of copies to be made, and the like. However, printer drivers in modern operating systems are not designed to facilitate interactive information gathering. Since the print job can be redirected to another printer, or the printing protocol does not allow such interactive sessions, the operating system does not encourage interaction with the user.","Due to these limitations in printer interaction, the user cannot define more detailed printing preferences in standard printing. Additionally, the user cannot define any printing preferences at all regarding multimedia content, since such printing capabilities are not currently available. Thus, a user cannot use current print dialog boxes to select segments of multimedia content that are of interest for printing. Current print dialog boxes also do not permit a user to preview any multimedia content. Additionally, there is not any way for a user to search through a lengthy multimedia segment for particular features of interest. For example, a user cannot currently search through a news segment for content covering a particular topic, nor can a user search for specific faces or events in a news segment. Moreover, there is no way to define a printing format for selected segments of multimedia content, and there is no way to preview or modify printing formats directly through a print dialog box.","Therefore, what is needed is a system and methods for permitting user interaction with and control over generation of a multimedia representation that overcomes the limitations found in the prior art.","The present invention overcomes the deficiencies and limitations of the prior art with a system and method providing a user interface that permits users to interact with media content analysis processes and media representation generation processes. The system of the present invention includes a user interface for allowing a user to control the media content analysis and media representation generation. A media analysis software module analyzes and recognizes features of the media content. In addition, the system can include an output device driver module that receives instructions from the user and drives the media content analysis and the media representation generation. For example, the media software analysis module recognizes features, such as faces, speech, text, etc. The system can also include an augmented output device for generating a media representation. Processing logic manages the display of a user interface that allows the user to control generation of a multimedia representation. Processing logic also controls the generation of a printable multimedia representation. The representation can be generated in a paper-based format, in digital format, or in any other representation format. The user interface includes a number of fields through which the user can view media content and modify the media representation being generated.","The methods of the present invention include interacting with a user interface to control the media data analysis and media representation generation. The methods further include analyzing features of media data for media representation generation, driving the media data analysis, and driving the media representation generation by receiving instructions and sending instructions regarding media representation parameters. Additionally, the methods can include generating a media representation.","A system and method for providing a graphical user interface or print driver dialog interface that allows users to interact with a process of multimedia representation generation is described. According to an embodiment of the present invention, a graphical user interface is provided that displays multimedia information that may be stored in a multimedia document. According to the teachings of the present invention, the interface enables a user to navigate through multimedia information stored in a multimedia document.","For the purposes of this invention, the terms \u201cmedia,\u201d \u201cmultimedia,\u201d \u201cmultimedia content,\u201d \u201cmultimedia data,\u201d or \u201cmultimedia information\u201d refer to any one of or a combination of text information, graphics information, animation information, sound (audio) information, video information, slides information, whiteboard images information, and other types of information. For example, a video recording of a television broadcast may comprise video information and audio information. In certain instances the video recording may also comprise close-captioned (CC) text information, which comprises material related to the video information, and in many cases, is an exact representation of the speech contained in the audio portions of the video recording. Multimedia information is also used to refer to information comprising one or more objects wherein the objects include information of different types. For example, multimedia objects included in multimedia information may comprise text information, graphics information, animation information, sound (audio) information, video information, slides information, whiteboard images information, and other types of information.","For the purposes of this invention, the terms \u201cprint\u201d or \u201cprinting,\u201d when referring to printing onto some type of medium, are intended to include printing, writing, drawing, imprinting, embossing, generating in digital format, and other types of generation of a data representation. Also for purposes of this invention, the output generated by the system will be referred to as a \u201cmedia representation,\u201d a \u201cmultimedia document,\u201d a \u201cmultimedia representation,\u201d a \u201cdocument,\u201d a \u201cpaper document,\u201d or either \u201cvideo paper\u201d or \u201caudio paper.\u201d While the words \u201cdocument\u201d and \u201cpaper\u201d are referred to in these terms, output of the system in the present invention is not limited to such a physical medium, like a paper medium. Instead, the above terms can refer to any output that is fixed in a tangible medium. In some embodiments, the output of the system of the present invention can be a representation of multimedia content printed on a physical paper document. In paper format, the multimedia document takes advantage of the high resolution and portability of paper and provides a readable representation of the multimedia information. According to the teachings of the present invention, a multimedia document may also be used to select, retrieve, and access the multimedia information. In other embodiments, the output of the system can exist in digital format or some other tangible medium. In addition, the output of the present invention can refer to any storage unit (e.g., a file) that stores multimedia information in digital format. Various different formats may be used to store the multimedia information. These formats include various MPEG formats (e.g., MPEG 1, MPEG 2, MPEG 4, MPEG 7, etc.), MP3 format, SMIL format, HTML+TIME format, WMF (Windows Media Format), RM (Real Media) format, Quicktime format, Shockwave format, various streaming media formats, formats being developed by the engineering community, proprietary and customary formats, and others.","In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the invention. It will be apparent, however, to one skilled in the art that the invention can be practiced without these specific details. In other instances, structures and devices are shown in block diagram form in order to avoid obscuring the invention. For example, certain features of the present invention are described primarily with reference to video content. However, the features of the present invention apply to any type of media content, including audio content, even if the description discusses the features only in reference to video information.","Reference in the specification to \u201cone embodiment\u201d or \u201can embodiment\u201d means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the invention. The appearances of the phrase \u201cin one embodiment\u201d in various places in the specification are not necessarily all referring to the same embodiment.","Referring now to , an exemplary system  for providing a graphical user interface that allows users to format multimedia data for generating a multimedia representation is shown. In this embodiment, there is shown an augmented output device or a printer  for generating multimedia representations. The printer  displays multimedia data, such as audio or video data, which the user can manage and edit through the user interface or print driver dialog interface (PDDI) . While the term \u201cprint driver dialog interface\u201d or \u201cPDDI\u201d will be used to refer to the graphical user interface, the graphical user interface is not limited to printers and may be any graphical user interface that provides the functionality described below. The multimedia information that is displayed in the PDDI  may be stored in a multimedia document that is accessible to system . The multimedia information may be stored directly on system , or it may be information stored on an external storage device or a server (not shown) from which multimedia information may be accessed by system  via connection .","In other embodiments, instead of accessing a multimedia document, the system  may receive a stream of multimedia information (e.g., a streaming media signal, a cable signal, etc.) from a multimedia information source. According to an embodiment of the present invention, system  stores the multimedia information signals in a multimedia document and then generates the interface  that displays the multimedia information. Examples of sources that can provide multimedia information to system  include a television, a television broadcast receiver, a cable receiver, a video recorder, a digital video recorder, a personal digital assistant (PDA), or the like. For example, the source of multimedia information may be embodied as a television that is configured to receive multimedia broadcast signals and to transmit the signals to system . In this example, the information source may be a television receiver\/antenna providing live television feed information to system . The information source may also be a device such as a video recorder\/player, a DVD player, a CD player, etc. providing recorded video and\/or audio stream to system . In alternative embodiments, the source of information may be a presentation or meeting recorder device that is capable of providing a stream of the captured presentation or meeting information to system . Additionally, the source of multimedia information may be a receiver (e.g., a satellite dish or a cable receiver) that is configured to capture or receive (e.g., via a wireless link) multimedia information from an external source and then provide the captured multimedia information to system  for further processing. Multimedia content can originate from a proprietary or customized multimedia player, such as RealPlayer\u2122, Microsoft Windows Media Player, and the like.","In alternative embodiments, system  may be configured to intercept multimedia information signals received by a multimedia information source. System  may receive the multimedia information directly from a multimedia information source or may alternatively receive the information via a communication network.","The augmented output device or printer  comprises a number of components that including a conventional printer , a media analysis software module , processing logic , and digital media output . The conventional printer  component of the printer  can include all or some of the capabilities of a standard or conventional printing device, such as an inkjet printer, a laser printer, or other printing device. Thus, conventional printer  has the functionality to print paper documents, and may also have the capabilities of a fax machine, a copy machine, and other devices for generating physical documents. More information about printing systems is provided in the U.S. Patent Application entitled \u201cNetworked Printing System Having Embedded Functionality for Printing Time-Based Media,\u201d to Hart, et al., filed Mar. 30, 2004, and which was incorporated by reference previously.","The media analysis software module  includes audio and video content recognition and processing software. The media analysis software module  can be located on the printer  or can be located remotely, such as on a personal computer (PC). Some examples of such multimedia analysis software include, but are not limited to, video event detection, video foreground\/background segmentation, face detection, face image matching, face recognition, face cataloging, video text localization, video optical character recognition (OCR), language translation, frame classification, clip classification, image stitching, audio reformatter, speech recognition, audio event detection, audio waveform matching, audio-caption alignment, video OCR and caption alignment. Once a user selects \u201cprint\u201d within system , the system  can analyze multimedia content using one or more of these techniques, and can provide the user with analysis results from which the user can generate a document.","In the embodiment shown in , the printer  additionally comprises processing logic  that controls the PDDI  and manages the printer's  generation of a multimedia document  or media representation. For example, the processing logic  manages the display of the PDDI  that allows the user control certain printer actions, such as the processing of the multimedia content or the format in which the multimedia content will be displayed in a multimedia representation. Alternatively, the functionality of the PDDI  can be provided by a web interface, allowing the user to manage printer actions, such as formatting issues, through this web interface.","In the example shown in , the PDDI  displays a user's selections which include the printing of a multimedia document  that displays video content. In this example, the user has selected to have the multimedia content printed in video paper format, and the video paper will display one frame per scene. Additionally, the interface  includes a preview field  that displays a preview of the multimedia representation that the user is creating. In the  example, the PDDI  shows thumbnail pictures  of the video frames.","Additionally, the PDDI  can allow the user to set formatting preferences with regard to the multimedia document  produced. In some embodiments, the user can set preferences as to document format and layout, font type and size, information displayed in each line, information displayed in a header, size and location of schedule columns, font colors, line spacing, number of words per line, bolding and capitalization techniques, language in which the document is printed, paper size, paper type, and the like. For example, the user might choose to have a multimedia document that includes a header in large, bold font showing the name of the multimedia content being displayed (e.g., CNN News segment), and the user can choose the arrangement of video frames to be displayed per page.","As shown in the embodiment of , a data structure called a Document Format Specification (DFS)  is generated by print driver software. The DFS  represents the transformation(s) of the multimedia data. The DFS  is used to populate the PDDI  and is modified by the system . The DFS  determines the feature extraction options presented to the user, which can be applied to the multimedia data. The DFS  also determines the format guidelines used to produce the output document. The DFS  can be supplied by an external application, such as a print driver on a PC, or it can be determined internally, within the printer .","The DFS  can include meta data information about a multimedia file, such as information about the title of the multimedia content, the producer\/publisher of the multimedia content, and the like. The DFS  can also include other information, such as beginning and ending times of a multimedia segment (e.g., beginning and ending times of an audio recording), and a specification for a graphical representation of the multimedia data that can be displayed along a time line (e.g., a waveform showing the amplitude of an audio signal over time). The DFS  can further include a specification for time stamp markers and meta-data for each time stamp (e.g., textual tags or bar codes) that could be displayed along the timeline, and layout parameters that determine the appearance of the physical multimedia document . More information about the DFS  and examples are provided in the U.S. Utility Application entitled \u201cPrintable Representations for Time-Based Media ,\u201d to Hull, et. al., filed on Mar. 30, 2004, which is incorporated by reference herein, in its entirety.","The multimedia document  generated by the printer  can comprise various formats. For example, the multimedia document  can comprise a paper document, such as video paper of the form shown in . The multimedia document  produced by the printer  can be also stored on digital media . As shown in , this embodiment of the printer  includes digital media output device or interface . The digital media writing hardware can include, for example, a network interface card, a digital video disc (DVD) writer, a secure digital (SD) writer, a compact disc (CD) writer, and the like. The multimedia content can be stored on digital media , such as flash media, a DVD, a CD, and the like.","The multimedia document  can have a number of different types of layouts and can display various types of information.  provides an example of a video paper document displaying video frames from one or more news segments. In the  example, the video paper document includes thumbnail images or frames  extracted from video information and displaying video content that the user can preview. In this embodiment, the user can designate formatting preferences for the video paper document through the PDDI . The layout and format information may specify the sampling rate for extracting the multimedia frames , the number of frames  that are to be extracted from the video information, the order and placement of the frames  on the medium, and other like information. For video information, the printer  can extract frames  that capture salient features of the video (or frames that are informative) for a particular segment of the multimedia information. Additionally, as discussed previously, the printer  may include feature recognition capabilities (e.g., face recognition, face detection, OCR, and the like), allowing the user to search within a video segment for items of interest, such as particular face images, particular words displayed as text, and the like. For example, the printer  can use face recognition techniques to extract frames displaying images of the faces of particular persons for which the user has an interest in viewing.","In another embodiment of the present invention, user-selectable identifiers  (e.g., a barcode) are associated with each frame . In the  example, the user selectable identifiers  are displayed under each frame , but these can alternatively be displayed anywhere on the page. The user-selectable identifiers  act as an interface to permit users to access or retrieve the multimedia content displayed on the multimedia document . A user selects the user-selectable identifier  by scanning the appropriate barcode on the printed paper document using any type of device that has a barcode scanner incorporated into it, such as a cell phone or a PDA. For example, by scanning the barcode of , the user can cause the video clip to be displayed on a display device (e.g., a television, a PC monitor, a cell phone screen, a PDA, and the like) and the user can view the content. As another example, the paper multimedia document  can also or alternatively include numerical identifiers included near each frame , and the user can type these numerals into a keypad or touchpad associated with a device to direct the system  to display a video clip on the display device. Alternatively, if the video paper document shown in  were in digital format, the system  could be configured so that a user could select the frame  (i.e., by clicking on the frame with a mouse or other selection device) causing the video content to be displayed on a display device.","The printer  is capable of retrieving multimedia information corresponding to the user-selectable identifiers . The signal communicated to the printer  from the selection device (i.e., device with barcode scanner or keypad for entering in numerical identifiers) may identify the multimedia content frame  selected by the user, the location of the multimedia content to be displayed, the multimedia paper documents from which the segments are to be selected, information related to preferences and\/or one or more multimedia display devices (e.g., a television set) selected by the user, and other like information to facilitate retrieval of the requested multimedia information. For example, the system  can access a video file stored on a PC, and the system can play this video content on the user's command.","The example of  further shows text information next to each frame  in the multimedia document . The text information includes the speaker name field  or a field displaying the name (e.g., Brit Hume) of the person shown in the frame  of the video. The text information further includes the subject field  that displays information about the video segment subject (e.g., Intro Intel-gate). Additionally, the text information includes the time field , which displays the length of time of the video segment (e.g., 3 mins, 52 secs.).","The user might also choose to have included in the multimedia document  some of the audio information for a frame , which is displayed as text. For example, the user may choose to have a portion of the transcript of a multimedia segment (i.e., a transcript of a news program segment) displayed next to the multimedia frame . As another example, the user might opt to include in the printed document a text description or summary of the content of each frame , such as a brief summary of a particular television segment or program. The user can use the print driver dialog interface  to identify techniques to be used for converting the audio information to text information (i.e., techniques for generating a text transcript for the audio information), the format and styles for printing the audio transcript (which may be the same as for printing text information), formats and styles for printing summary text about multimedia content, and the like. Additionally, information about retrieving multimedia information and annotating multimedia information is provided in the Video Paper Applications, referenced previously.","Referring now to , there is shown the architecture of an embodiment of the present invention. In this embodiment, the system  includes a printer  that is coupled to a data processing system, which is a PC  in the embodiment of , but could also be a portable computer, a workstation, a computer terminal, a network computer, a mainframe, a kiosk, a standard remote control, a PDA, a game controller, a communication device such as a cell phone, or any other data system. The printer  can also optionally be coupled to an application server  in a network environment.","In the example of , the printer  comprises the following components: a conventional printer , a processor , a multimedia storage , and the digital media input\/output . The conventional printer  includes the standard printing capabilities that a conventional printer generally has, as discussed previously.","The processor  processes data signals and may comprise various computing architectures including a complex instruction set computer (CISC) architecture, a reduced instruction set computer (RISC) architecture, or an architecture implementing a combination of instruction sets. Although only a single processor is shown in , multiple processors may be included. Main memory (not shown) may store instructions and\/or data that may be executed by processor , including the software and other components of system . The instructions and\/or data may comprise code for performing any and\/or all of the techniques described herein. Main memory (not shown) may be a dynamic random access memory (DRAM) device, a static random access memory (SRAM) device, or some other memory device known in the art.","As described previously, the printer  accesses or receives multimedia information, such as an audio or video file, from some source. In one embodiment, the multimedia file is stored on a data processing system, such as PC , which is coupled to the printer  by signal line . In the embodiment of , the multimedia file can be stored in the multimedia file storage  on PC . The multimedia file may also be accessible from some remote source (not shown). As another example, the multimedia file might be stored on the printer , itself, in the printer multimedia storage , and the file is accessed from this storage .","A user can view multimedia content on a display device (not shown) to select particular content for printing with printer , as described above. The display device (not shown) can include a cathode ray tube (CRT), a flat-panel device such as a liquid crystal display (LCD), a projection device, and the like. In other embodiments, the printer  includes an LCD display panel or other type of display panel, and the user can display multimedia content on the printer, itself.","In the  embodiment, the user views a multimedia file using a multimedia rendering application (MRA)  on PC  that allows the user to play back, store, index, edit, or manipulate multimedia information. Examples of MRAs  include proprietary or customized multimedia players (e.g., RealPlayer\u2122 provided by RealNetworks, Microsoft Windows Media Player provided by Microsoft Corporation, QuickTime\u2122 Player provided by Apple Corporation, Shockwave multimedia player, and others), video players, televisions, PDAs, or the like. In the embodiment of , MRA  is coupled to multimedia file storage  by bus . Stored multimedia content can be accessed by MRA  and transferred to MRA  to be viewed by the user. More information about multimedia visualization is provided in the following U.S. Patent Applications, each of which is hereby incorporated by reference in its entirety: U.S. patent application Ser. No. 10\/081,129, to Graham, entitled \u201cMultimedia Visualization and Integration Environment,\u201d filed on Feb. 21, 2001; U.S. patent application Ser. No. 10\/701,966, to Graham, entitled \u201cMultimedia Visualization and Integration Environment,\u201d filed on Nov. 4, 2003; U.S. patent application Ser. No. 10\/465,027, to Graham, et. al., entitled \u201cInterface For Printing Multimedia Information,\u201d filed on Jun. 18, 2003; U.S. Patent Application entitled \u201cTechniques For Displaying Information Stored In Multiple Multimedia Documents,\u201d to Graham, et. al., filed on Jun. 18, 2003; U.S. patent application Ser. No. 10\/174,522, to Graham, entitled \u201cTelevision-Based Visualization and Navigation Interface, filed on Jun. 17, 2002; and U.S. Patent Application, to Graham, entitled \u201cMultimedia Visualization and Integration Environment,\u201d filed Mar. 3, 2004.","In the embodiment of , the system  also includes an output device driver module or a printer driver software module , which can be located on PC  or another location. The printer driver software module  is configured at installation time to perform certain functions. The printer driver software  adds a \u201cprint\u201d function to an existing MRA , such as Windows Media Player. An optional application plug-in  may be required for adding the \u201cprint\u201d function. As an alternative, a user can install a separate MRA  designed for this purpose. When the printer  is invoked (i.e., the user selections a print button on a MRA ), the printer driver software module  receives a print request from the MRA , along with multimedia data and other relevant information through signal line . The printer driver software module  transfers multimedia data to the printer  through bus  and instructs the printer to apply specified transformation routines (e.g., face recognition). The printer driver software module  can additionally prompt the user as necessary to confirm results and layout decisions that the user has made.","When printer  receives a print request, the request and the associated multimedia data are transferred to processor . The processor  interprets the input and activates the appropriate module. The processor  is coupled to and controls the multimedia transformation software module (MTS) (not shown) for transforming multimedia content. If the processor  has received a print request, the processor  may then activate the MTS (not shown) depending on whether or not the user has requested transformation of the multimedia data. The transformations to the multimedia content can be applied on the printer , on a PC  (i.e., by software installed with the print driver ), or at some other location. The MTS (not shown) applies specified transformation functions to a given audio or video file. The MTS (not shown) generates the appropriate document-based representation and interacts with the user through the print driver dialog interface to modify the parameters of the transformation and to preview the results. The results and parameters of the multimedia transformation are represented in the Document Format Specification (DFS) that was described previously.","As described above, printer  can include multimedia storage , for storing multimedia data, such as video or audio files. The processor  is coupled to multimedia storage  and can transfer multimedia data, through bus , to the multimedia storage . This data can be stored while a print job is progressing. Storage  may include a number of memory types including a main random access memory (RAM) for storage of instructions and data during program execution and a read only memory (ROM) in which fixed instructions are stored. Storage  may also include persistent (non-volatile) storage for program and data files, such as a hard disk drive, a floppy disk drive, a CD-ROM device, a DVD-ROM device, a DVD-RAM device, a DVD-RW device, or other like storage device known in the art. One or more of the drives or devices may be located at remote locations on other connected computers.","The processor  also controls a digital media input\/output . the processor  transfers information to and receives information from digital media input\/output , through bus . Multimedia documents created can be converted into some type of digital format, as described previously. The digital media writing hardware can include, for example, a network interface card, a digital video disc (DVD) writer, a secure digital (SD) writer, a compact disc (CD) writer, and the like. The digital output  documents can be stored on digital media, including a CD, a DVD, flash media, and the like. Thus, the user can create a digital output  version of input audio or video file, and this can be viewed on a specified target device, such as a PC, a cell phone, or a PDA.","The processor  also manages generation of a multimedia document , such as a video or audio paper document. Multimedia information can also be displayed in a paper document or multimedia document , as shown in . The processor  communicates with and sends print job information to a conventional printer , through bus , and the conventional printer  generates a paper output. The multimedia document  generated includes a paper representation of input audio or video file information, as derived by recognition software. The  embodiment of the multimedia document  can also include user-selectable identifiers, such as barcodes, and other links to multimedia data stored by the printer  or stored in a specified online database.","The processor  also controls external communication hardware, such as through a network interface. The processor  can transmit information to and receive information from an application server  through bus . The printer  can also communicate with and obtain information from an application server  (e.g., \u201cWeb services\u201d or \u201cgrid computing\u201d systems).","In one embodiment, the system  includes a communication monitoring module or a user interface listener module  (UI Listener). In the embodiment of , the UI Listener  is located on the PC , but the UI Listener can be alternatively located on the printer , on an application server , or at some other remote location. The UI Listener  is coupled to and communicates with MRA , and can send and receive data over bus . Specifically, the UI Listener  receives print requests from the user to the MRA and sends requests to the user from remote components (e.g., the printer , an application server , etc.). The UI Listener  is also coupled to and communicates with printer , and can send and receive data over bus . Specifically, the UI Listener , sends print requests to the printer and receives requests from the printer  for further information from the user. Additionally, UI Listener  can be coupled to and communicate with an application server  over a network, and can send and receive data over network connection (not shown). The UI Listener  receives information from application server , such as requests for information from the user, and the UI Listener  can return a response. The UI Listener  and its functionality is discussed in more detail below.","Referring now to , there is shown a graphical representation of interactive communication with the printer , within the system . Printer drivers typically do not facilitate interactive information gathering. Once initial printer settings are captured, further interactions with the printer  are generally not allowed. One approach to this problem is to embed metadata into the print stream itself. However, the printer  could need to ask the user  for more information, in response to computations made from the data supplied by the user. In addition, the printer  might, itself, delegate some tasks to other application servers , which might in turn need more information from the user .","In order to allow this interaction without modifying printer driver architecture of the underlying operating system, an extra mechanism, such as the one shown in , can be constructed. One solution is to construct a UI Listener , a program, which listens to a network socket, accepts requests for information, interacts with a user  to obtain such data, and then sends the data back to the requester. Such a program might have a fixed set of possible interactions, or accept a flexible command syntax, which would allow the requester to display many different requests. An example of such a command syntax would be the standard web browser's ability to display HTML forms. These forms are generated by a remote server and displayed by the browser, which then returns results to the server. In this embodiment, the UI listener  is different from a browser, though, in that a user  does not generate the initial request to see a form. Instead, the remote machine generates this request. Thus, in this embodiment, the UI listener  is a server, not a client.","Because network transactions of this type are prone to many complex error conditions, a system of timeouts allows efficient operation. Each message sent across a network generally either expects a reply or is a one-way message. Messages that expect replies can have a timeout, or a limited period of time during which it is acceptable for the reply to arrive. In this invention, embedded metadata would include metadata about a UI listener  that will accept requests for further information. Such metadata consists of at least a network address, port number, and a timeout period. It might also include authentication information, designed to prevent malicious attempts to elicit information from the user , since the user  cannot tell whether the request is coming from a printer , a delegated server , or a malicious agent. If the printer  or a delegated application server  wishes more information, it can use the above noted information to request that the UI Listener  ask a user  for the needed information. The UI Listener  program can be located on a user's  interaction device (e.g., a PC, a cell phone, or a PDA), on the printer  (i.e., for user interaction on a LCD panel located on the printer), or another remote location.",{"@attributes":{"id":"p-0073","num":"0072"},"figref":["FIG. 3","FIG. 3"],"b":["302","200","204","302","304","204","302","204","306","210","210","102","304","308","204","102","308","210"]},"In the example of , the printer  sends a request for information  to the UI Listener  program located on the user's  interaction device. For example, the printer  could request further information about a particular layout preference selected by the user for a video paper print job or could newly confrm that a default layout should be used. The UI Listener  then delivers this request to the user , and a dialog box is displayed  to the user  allowing the user  to respond to the request by selecting information within the dialog box. The user's  reply  is sent to the printer , in answer to the printer's  request for information .","Additionally, in the example of , the printer  sends a request for information  to the application server . For example, the printer  could request specific data necessary to the print operation from a database, and the database may need to gather more information from the user. In the  example, the application server  sends a request for information  to the UI Listener , which then forwards the request  to the user . A dialog box is displayed  to the user , allowing the user  to respond to the request . The UI Listener  then forwards the user's  reply  to the application server , and the application server  can then send a reply  to the printer , regarding the printer's  request  for information.","Referring now to , there is shown a graphical representation of an MRA  with a \u201cPrint\u201d button  added into the MRA . In this example, the MRA  box is a Windows Media Player (WMP) application, but it is possible to use other types of MRAs , as discussed previously. A user can select a print option by clicking on the Print button , causing the printer to generate a multimedia document. A print option can be added to the WMP, version  by utilizing the plug-in feature provided by Microsoft. The plug-in feature allows developers to create an application that supplements the WMP in some way. Several types of plug-ins can be created: \u201cdisplay,\u201d \u201csettings,\u201d \u201cmetadata,\u201d \u201cwindow and background,\u201d and the like. Microsoft provides an explanation of what a plug-in is and how to build a plug-in. Using one of the user interface plug-in styles, it is possible to add a button or panel to the WMP screen. More information about adding a print option to an application is provided in the U.S. Patent Application entitled \u201cPrinting System with Embedded Audio\/Video Content Recognition and Processing,\u201d to Hull et. al., filed on Mar. 30, 2004, which is incorporated herein by reference in its entirety.","In operation, the system  provides methods for printing multimedia content. The user selects a print option in an MRA, and an initial print driver dialog interface (PDDI)  appears to the user. The initial PDDI  is populated with information about the abilities of the printer  to transform multimedia data. The initial PDDI  can display options available to the user for transforming the data, or it can show the result of performing a default transformation with a default set of parameters. The user can choose which of these two options the user prefers, and the user's preference can also be set in the printer's  properties. The flow of operations for each of these options is depicted in , discussed below. More information about different transformations that can be performed and options available to the user for transformation is provided in the U.S. Patent Application entitled \u201cPrinter with Embedded Audio\/Video Content Recognition and Processing,\u201d to Hull et. al., filed on Mar. 30, 2004, which was incorporated by reference previously.","Referring now to , there is shown a flowchart that describes the flow of operations in the system  when the PDDI  is displayed to the user before any multimedia transformation is performed. In this embodiment, the user enters a \u201cprint\u201d command into the system by pressing  a print button (e.g., ) in an MRA. The user can use an initial PDDI  to define preferences with regard to the multimedia document to be generated before any transformation has been conducted. The user selects  parameters for a transformation that will be applied to the multimedia content. For example, the user can opt to have the document show a particular number of video frames, displayed in a user-defined arrangement.","The system  then waits  for the user to press the Update button or the OK button on the PDDI . If the user selects the Cancel button, then the system  exits and the PDDI  disappears from view. Once the user has selected the Update button or the OK button, the system  sends  parameters and other user-selection information to the printer . The system  determines if the multimedia data has already been transferred to the printer . As described previously, this multimedia data may be located on a PC, a cell phone, a PDA, or other device that can contain multimedia content. If the multimedia data has not yet been transferred to the printer , then the system  transfers  multimedia data to the printer , and then continues with the operation flow. If the multimedia data has already been transferred to the printer , then the system  determines whether or not the multimedia transformation with the user-defined parameters has already been performed. If not, the printer performs  the transformation on the multimedia data. If so, the system  then determines whether or not the user pressed the Update button after entering in the parameters, or if the user alternatively pressed the OK button. If the user did not press the Update button, and instead pressed the OK button, the printer  generates  a document, multimedia data, and control data that links the paper document with the multimedia data. Additionally, the system  assigns identifiers (e.g., a barcode) to the multimedia data, providing the user with an interface by which to access the multimedia content. If necessary, before generating the document, the printer  may first prompt the user for further information regarding the print job. Metadata about the multimedia data and the commands entered into the PDDI  are represented in the DFS .","If the user pressed the Update button, rather than the OK button, the user is not yet requesting that the printer  create a multimedia document. Instead, the user presses the Update button when the user has modified the user selection parameters in the PDDI , and the user wants the preview field of the PDDI  to be updated. If the user pressed the Update button, the system  will interactively return  results for display in an interactive PDDI . This allows the user to preview how the multimedia document will appear with the newly added parameter modifications. The flow of operation then returns to the point at which the user has the opportunity to select  parameters, and the system  can cycle through the flow again, continuing to modify parameters in the interactive PDDI  until a final document is generated.","Referring now to , there is shown a flowchart that describes the flow of operations in the system  when the system  is configured to transfer the multimedia data, perform the default transformation, and display its results in a PDDI . In this embodiment, the user presses  a print button in a multimedia rendering application. The system  reads  the default transformation and parameters from the printer properties information stored on the printer , on a PC, or other location. The system  then determines if the multimedia data has already been transferred to the printer . If the multimedia data has not yet been transferred to the printer , then the system  transfers  multimedia data to the printer , and then continues with the operation flow. If the multimedia data has already been transferred to the printer , then the system  determines whether or not the transformation with the defined parameters has already been performed. If not, the printer performs  the transformation on the multimedia data. If so, the system  then displays  a PDDI  to the user, showing the results of the transformation. The user modifies  parameters for transformation that was applied to the multimedia content. The system  then waits  for the user to press the Update button or the OK button on the PDDI . If the user selects the Cancel button, then the system  exits and the PDDI  disappears from view. If the user pressed the OK button, the printer  generates  a document, multimedia data, and control data that links the paper document with the multimedia data, and the system  assigns an identifier to the multimedia data. If the user pressed the Update button, the system  will send  the parameters for transformation to the printer , and the flow of operation then cycles again.",{"@attributes":{"id":"p-0082","num":"0081"},"figref":["FIGS. 7-19","FIG. 6","FIGS. 7-19","FIG. 5","FIG. 5"],"b":["122","122","122","122"]},"AUDIO",{"@attributes":{"id":"p-0083","num":"0082"},"figref":["FIG. 7","FIG. 7"],"b":["122","122","122","704","706","708","122","710","712","714"]},"As is found in standard print dialog boxes, the top of the PDDI  includes a file name field  that displays the name (e.g., \u201clocomotion.mp3\u201d) of the multimedia file being printed. In the Printer field , the user can select which printer will carry out the print job, and other options with regard to properties of the print job, printing as a image or file, printing order, and the like. Additionally, the Printer field  displays the status of the selected printer, the type of printer, where the printer is located, and the like. The Print Range field  allows the user to make selections about what portions of a document will be printed and the like. The Copies and Adjustments field  permits a user to designate the number of copies to be generated in a print job, the size of the print job pages relative to the paper, the positioning of the print job pages on the paper, and the like. Although not shown, this dialog box could also include any of the various combinations of other conventional print parameters associated with outputting representations of video, audio, or text documents.","In the embodiment of , the Advanced Options field  provides the user with options that are specific to the formatting and layout of multimedia content. In this embodiment, the user selects the segmentation type that the user would like to have applied to the multimedia content. In this embodiment of the invention, the user can click on the arrow in the segmentation type field , and a drop-down menu will appear displaying a list of segmentation types from which the user can choose. Examples of segmentation types include, but are not limited to, audio event detection, speaker segmentation, speaker recognition, sound source localization, speech recognition, profile analysis, video event detection, color histogram analysis, face detection, clustering, face recognition, optical character recognition (OCR), motion analysis, distance estimation, foreground\/background segmentation, scene segmentation, automobile recognition, and license plate recognition. In the example, the user has not selected any segmentation type in the segmentation type field , so the segmentation type is shown as \u201cNONE.\u201d Thus, in this example, the user manually selects an audio range within the audio waveform timeline  by moving a selector  around within the Content Selection field .","Each segmentation type can have a confidence level associated with each of the events detected in that segmentation. For example, if the user has applied audio event detection that segments the audio data according to applause events that occur within the audio data, each applause event will have an associated confidence level defining the confidence that an applause event was correctly detected. Within the Advanced Options field , the user can define or adjust a threshold on the confidence values associated with a particular segmentation. The user sets the threshold by typing the threshold value into the threshold field . For example, the user can set a threshold of 75%, and only events that are above this threshold (i.e., more than 75% chance that the event was correctly detected to be an applause event) will be displayed. In other embodiments, a threshold slider (not shown) is included in the PDDI , and the user can move the slider along a threshold bar that runs from 0% to 100% to select a specific threshold within that range.","In one embodiment, the user can also make layout selections with regard to the multimedia representation generated. The user sets, within the \u201cFit on\u201d field , the number of pages on which the audio waveform timeline  will be displayed. The user also selects, within the timeline number selection field , the number of timelines to be displayed on each page. Additionally, the user selects, within the orientation field , the orientation (e.g., vertical or horizontal) of display of the timelines on the multimedia representation. For example, as shown in , the user can choose to have one timeline displayed on one page, horizontally, and this will display the entire audio waveform timeline  horizontally on a page. As another example, the user can choose to have the audio waveform timeline  broken up into four portions that are displayed vertically over two pages (i.e., two timelines per page).","In the embodiment of , there are also shown various buttons, including an Update button , a Page Setup button , an OK button , and a Cancel button . As described regarding , the user can select the Update button  when the user has modified the print job parameters within the PDDI , and the user would like to see an updated image of how the multimedia representation will appear. The image of the multimedia document shown in the Preview field  will be updated to display any new changes the user has made within the PDDI . Alternatively, the system can be designed to automatically update the Preview field  any time changes are made in the PDDI . In one embodiment, when the user selects the Page Setup button , a different dialog interface box is displayed to the user, giving the user various print formatting options. This is discussed in more detail below. The embodiment of  also includes an OK button , and when the user selects this button, the printer then prepares to generate a multimedia document under the current user-defined preferences set in the PDDI . If the user selects the Cancel button  at any point in the process, the creation of the print job ends and the PDDI  disappears.","In the embodiment of , the Content Selection field  shows an audio information waveform on a timeline displaying the audio data selected by the user for transformation and printing. In this example, the top of the audio waveform timeline  shows the time \u201c00:00:00,\u201d or the start time of this audio content. The bottom of the audio waveform timeline  shows the time \u201c00:07:14,\u201d or the end time of the audio content. Thus, the audio information in this example is seven minutes and fourteen seconds long. The user can slide the selector  along the audio waveform timeline  to select certain segments of the audio content for which corresponding markers or identifiers will be displayed on the multimedia document generated. For example, the user can use a mouse or other selection device to click on and slide the selector  to the segment , which is shown as a selected segment in . In one embodiment, once the selector  is located at the segment of audio content that the user would like to select, the user can click or double-click on the selector  to select segment . In this embodiment, the user can select a longer segment of audio content by clicking on and dragging the selector  across the distance of the audio segment that the user would like to select. The audio waveform timeline  could also be displayed in a number of alternative manners, such as showing a horizontal timeline, showing more than one timeline side-by-side, showing a different waveform appearance, showing a waveform that is colored according to a particular schematic, and the like.","In the embodiment shown in , the user selected three regions of the audio waveform timeline  to be marked on the multimedia document. The user selected segment , segment , and segment . Each of these selected segments has a separate corresponding marker or identifier  (e.g., a barcode) displayed on the print preview of the multimedia document. For example, in the Preview field  of  there is shown an image of a multimedia document. The document shows one page including one horizontal timeline displayed with the beginning of the audio timeline to the left and the end to the right. In this example, the full audio waveform timeline  is displayed on the multimedia document page. Additionally, the timeline displayed in the Preview field  includes three markers or identifiers , one for segment , one for segment , and one for segment . Each marker  includes a barcode and a time stamp giving the location of the segment within the audio content. In addition, the  example shown in the Preview field  includes a header, which can include information about the audio content (e.g., the title of the audio content, the musician who created the audio content, and the date of the audio content. The multimedia document further includes a play marker  or play identifier, which can be located anywhere in the document (i.e., bottom, center).","The user can play the audio content in a number of ways. For example, the user can click on the play selectors or play arrows  on the audio waveform timeline  to cause the segment to begin to play. Additionally, the system can be configured so that selecting a play arrow  will cause the full audio content on the audio waveform timeline  to begin to play. The user can also right click on any one of the selected segments to delete the corresponding marker on the multimedia document. A paper multimedia representation also can provide an interface for playing the audio content. A user can select any of the markers (i.e., scan the barcodes) for any of the selected segments on the paper documents, and this will cause the selected audio segment to play. For example, the user can scan a barcode with a cell phone or PDA device with a barcode scanner. The user can listen to the selected clips on the cell phone or PDA, or the user can hear the content via the sound card on his\/her PC. Additionally, the user can select the play marker  that acts as a pause button, so that if the user has selected any of the markers on the page and the corresponding audio content is playing, the user can pause this by selecting the play marker . The user can resume the playing of the audio content by selecting the play marker  again, or the user can select another marker on the page to play the corresponding audio content.","Referring now to , there is shown of a graphical representation of a PDDI  for multimedia document page setup, or a page setup dialog interface . When a user selects the Page Setup button , discussed previously, the page setup dialog interface  appears and the user can select formatting options. In the Paper field , the user can select the paper size (e.g., letter) and paper source (e.g., auto select) for the multimedia print job. In the Orientation field , the user can designate whether the document will be oriented in portrait or landscape format. In the Preferences field , the user can set the title and text font types and sizes (e.g., Helvetica, size 22 inches), the media type (e.g., video), the location of markers on the page (e.g., above waveform), and the user can decide whether or not to print a waveform, a center title, timeline barcodes and their frequency, and time labels. Each of the page setup options shown in the page setup dialog interface  can alternatively be incorporated into the main PDDI , such as the PDDI shown in . The page setup options are not limited to those shown in , and in other embodiments, various different page setup options are provided to the user.","Referring now to , there is shown a graphical representation of a PDDI  that generates a two-page summary of an audio file. The PDDI  is similar to that shown in , however the user has selected, in the timeline number selection field , to include three timelines printed per page of the multimedia document. Additionally, the user has selected, in the page fit field  to print the multimedia document over two pages. The user has selected, in the Content Selection field , four segments of audio content for which markers will be displayed. The selected segments include segment , segment , segment , and segment .","The multimedia document shown in the Preview field  of  displays three timelines on a page, and shows that two pages have been generated. The time stamps  at the beginning of each horizontal timeline display the start time of that timeline. The timelines shown on the top page in the Preview field  correspond to half of the audio waveform timeline  shown in the Content Selection field . More specifically, the multimedia document displays the upper half of the audio waveform timeline , split into three separate timelines. The markers corresponding to selected segments  and  are displayed on the page shown in the Preview field . The markers corresponding to selected segments  and  are displayed on the second page, the content of which is not visible in the Preview field .","The document in the Preview field  of  additionally includes timeline markers  near the beginning and the end of each of the three timelines displayed on the page. These provide the user with additional intermediate interface points in the printed document through which the user can access the multimedia content. The timeline markers  denote locations in the audio content that correspond to the beginning or end of each printed timeline, and the user can access these locations by selecting the marker (i.e., scanning the barcode, as discussed previously) to cause the audio content to begin to play at that location in the audio file. The timeline markers  in  are displayed below the timelines, but these timeline markers  could also be displayed above or near the timelines. These timeline markers  will also appear in the printed document, providing another interface by which user can access multimedia content at defined locations.",{"@attributes":{"id":"p-0096","num":"0095"},"figref":["FIG. 10","FIG. 7"],"b":["122","122","720","722","734","714","734","1002","1004","1006","1008"]},"Referring now to , there is shown a graphical representation of a PDDI  in which the timeline is divided into two vertical parts, and a segmentation type and threshold level have been applied. In this example, the user has selected, in the timeline number selection field , to include two timelines printed per page of the multimedia document. Additionally, the user has selected, in the \u201cFit on\u201d field  to print the multimedia document over two pages. The user has also selected, in the orientation field  to display the timelines vertically in the multimedia document. Thus, the audio waveform timeline  shown in the Content Selection field  is divided in half, and the upper half is displayed on the page shown in the Preview field . The lower half is included on the second page, the content of which is not displayed in the Preview field .","In the example of , instead of manually selecting segments of the audio waveform timeline  with the selector , the user has applied a segmentation type to the audio data. The user has selected, in the segmentation type field , to conduct audio detection for applause events on the audio data. The system  will search for all applause events within the audio data. However, the user has also selected, within the threshold selection field , to apply a threshold of 75%. Thus, only audio events that are more than 75% likely to be applause events will be displayed in the PDDI . The applause events are displayed in the Segmentation Display field . Each event segment  shown within the Segmentation Display field  corresponds to an event that is more than 75% likely to be an applause event.","The event segments  are shown as staggered boxes in . However, these might also be lines stretching across the Segmentation Display field  or other visual indicators. The user can right click on any one of the event segments  to delete the event segment . Markers (i.e., a barcode, an RFID tag, a URL, or some other indication for the location where the multimedia data can be retrieved from)  corresponding to each applause event segment  are shown in the multimedia document displayed in the Preview field . In this example, timestamps  are also included with each marker . The user can click on the arrows  located near each event segment  to play the audio content that likely contains applause. Thus, the user can check the event segments  shown, before printing the document, to ensure that the event segments  really do correspond to applause events. Additionally, the user can select the markers in the printed document that correspond to applause events to play the applause content. Besides the audio detection event example described in , there are a number of other segmentation types that can be applied to audio content or other kinds of multimedia content. Each of these segmentation types can be displayed in a menu in the segmentation type field , and the user can select from the menu which segmentation type should be applied. The following is a summary of examples of various different segmentation types that can be applied. Speaker segmentation is one example, in which each segment corresponding to different speaker is shown in a different color or by a different icon. The segments that were produced by the same speaker are shown in the same color or by the same icon. Speaker recognition is another example, in which the name of each speaker is accompanied by a confidence that it was detected correctly. The PDDI  includes a series of check boxes that let the user choose which speakers to display. The user can alternatively apply sound source localization, in which the direction from which sound was detected is displayed as a sector of a circle. Each sector is accompanied by a confidence that it was detected correctly. The user interface includes a series of check boxes arranged around the circumference of a prototype circle that let the user choose which directions to display. Speech recognition is another example of a segmentation type, in which the timeline displays text and optionally confidence values for each word or sentence spoken during the audio content.","VIDEO",{"@attributes":{"id":"p-0100","num":"0099"},"figref":["FIG. 12","FIG. 12"],"b":["122","122","122","122","704","706","708","122","710","712","714"]},"In the embodiment of , the Advanced Options field  provides the user with options that are specific to the formatting and layout of multimedia content. In this embodiment, the user selects the segmentation type in the segmentation type field  that the user would like to have applied to the video content. The menu of segmentation types for generating a video document will include at least the segmentation types already discussed previously in reference to creating an audio document in . In the example, the user has not selected any segmentation type in the segmentation type field , so the segmentation type  is shown as \u201cNONE.\u201d Thus, in this example, the user manually selects start and end times for segments of a given video file by moving the selector  within the Content Selection field  and clicking on the portions of the video timeline display that the user would like to select.","Within the Advanced Options field , the user can define or adjust a threshold on the confidence values associated with a particular segmentation, as discussed previously. The user sets the threshold by typing the threshold value into the threshold field . For example, the user can set a threshold of 75%, and only frames that are above this threshold (i.e., more than 75% chance that the frame includes a face in a face detection analysis) will be displayed. In other embodiments, a threshold slider is included in the PDDI , and the user can move the slider along a threshold bar that runs from 0% to 100% to select a specific threshold within that range. In addition, the buttons shown in the embodiment of , including an Update button , a Page Setup button , an OK button , and a Cancel button , function in a manner similar to the corresponding buttons discussed regarding .","In the embodiment of , the Content Selection field  shows video frames and text on a timeline, which were extracted at regular intervals throughout some defined video content. For example, the system can save video frames of a CNN News segment every second, and the video timeline will display all or at least some of the saved frames on the video timeline. The extracted frames will be displayed with the frames starting at time \u201c00:00:00,\u201d in the CNN News segment, at the top of the timeline and continuing to be displayed along the timeline until the end, at time \u201c00:12:19.\u201d In this example, the top of the video timeline shows the time \u201c00:00:00,\u201d or the start time of this video content displayed in the timeline. The bottom of the video timeline shows the time \u201c00:12:19,\u201d or the end time of the video content. In some embodiments, the video frames can be displayed in reverse order along the timeline.","Additionally, there are three columns , , and  displayed in Content Selection field . One column  displays text information, and the other two columns  and  display video frames. The video frames displayed in  in the two columns  and  are displayed side-by-side. For example, the first frame selected is displayed at the top left of the timeline, and the second frame selected is displayed next to the first frame. The third frame selected is displayed below the first frame, and the fourth frame selected is displayed below the second frame. The video frame display continues along the timeline in this pattern. In other embodiments, the video frames could be displayed in different patterns, or could be displayed in one column, or in more than two columns along the timeline. The transcript of text is also displayed along the timeline in , from top to bottom, generally near the corresponding video frame. In other embodiments, the text is displayed in two or more columns, or on the other side of the video frames, or is not displayed at all on the timeline.","The user can slide the selector  along the video timeline to select certain segments of the video content, which will be displayed on the multimedia document generated. In one embodiment, once the selector  is located at the segment of video content that the user would like to select, the user can click on the selector  to select segment . The video timeline could also be displayed in a number of alternative manners, such as showing a horizontal timeline, showing more than one timeline side-by-side, showing a different video frame appearance, and the like. As discussed above, while the video timeline in the embodiment of  displays both video frames and associated text, the video timeline can also display only video frames without the associated text, in some embodiments. In these embodiments where the timeline displays only video frames, the multimedia representation generated can still include both text and video frames, or it can be limited to video frames alone.","In the example shown in , the user selected four regions of the video timeline to be marked on the multimedia document. The user selected segment , segment , segment , and segment . Each of these selected segments will be displayed as one or more video frames and associated text on the multimedia document. In the Preview field  of  there is shown an image of a multimedia document. The document of the  example shows one page including five video frames  and associated text . The displayed video frames  and associated text  each correspond to the segments that were selected in the Content Selection field . For example, the first two video frames  starting at the top left of the multimedia document correspond with the selected segment . In the  example, the video frame  shown in the bottom left hand corner of the multimedia document corresponds to selected segment  on the video timeline. The video frame  in the top right corner of the document corresponds to selected segment , and the video frame  in the bottom right corner corresponds to selected segment .","Additionally, the location of each displayed video frame within the video timeline is displayed above each video frame as a time marker . In , each time marker  corresponds to a segment within the time frame of \u201c00:00:00\u201d to \u201c00:12:19,\u201d the total length of the video content displayed on the video timeline. For example, the video frame  at the top left hand corner of the multimedia document for a CNN News segment includes a time marker  of \u201c00:04:21.\u201d Thus, the video content associated with this video frame  begins at four minutes and twenty-one seconds into the CNN News segment. Additionally, the text  associated with this video frame  displays a transcript of the video frame , and the transcript begins at four minutes and twenty-one seconds into the CNN News segment.","The user can also play the video content in a number of ways. For example, the user can click on the play arrows  next to each selected segment on the video timeline to cause the segment to begin to play. In the embodiment of , the video frames  displayed on the multimedia document each have a corresponding marker or identifier  (e.g., a barcode) located below the video frame . These identifiers  also can provide an interface for playing the video content. A user can select any of the identifiers  (i.e., scan the barcodes) for any of the selected segments on the document, and this will cause the selected video segment to play, as discussed previously in reference to audio segments.","When a user selects an identifier , the associated video content will begin to play starting at the time displayed on the corresponding time marker . In the  embodiment, the dialog associated with the video frame  will begin at the start of the associated transcript of text . For example, if the user scans the barcode shown below the video frame on the top left-hand corner of the multimedia document shown in the Preview field  of , a video clip of the CNN News segment will play, beginning four minutes and twenty-one seconds into the news show.","The multimedia document shown in the embodiment of  further shows control markers or identifiers for controlling video content display. In , there is shown a play marker , a fast forward (FF) marker , and a rewind marker . The user can select the play marker  in a printed document (i.e., by scanning the barcode with a cell phone or other device), which acts as a pause button. If the user has selected any of the identifiers  on the printed page and the corresponding video content is playing on some type of display device (not shown), such as a cell phone, the user can pause this by selecting the play marker . The user can resume the playing of the video content by selecting the play marker  on the printed document again, or the user can select another identifier  on the page to play the corresponding video content. Additionally, if the user has selected any of the identifiers  on the printed page and the corresponding video content is playing, the user can fast forward or rewind through the video clip by selecting the fast forward marker  or the rewind marker , respectively.","In the  example, the multimedia document shown in the Preview field  also includes a header, which can include information about the video content (e.g., the title of the video content and the date of the video content). For example, the header in  identifies the video content as \u201cCNN News,\u201d and the news segment was played on \u201cSep. 19, 2001.\u201d","The Preview field  shown in the  embodiment further includes a preview content field . This preview content field  marks whether a user is previewing a paper version of the multimedia document or previewing the video content associated with a video frame  displayed on the multimedia document. The user can preview the selected video content associated with a video frame  through a video player embedded in the PDDI  by selecting the \u201cVideo\u201d radio button.","In the  embodiment, the multimedia document is displayed in the Preview field  according to one particular layout. However, the document can be arranged in a number of different formats. For example, the document could include no header, the time markers  could be displayed below the video frames , the identifiers  could be shown above the video frames, and the like.",{"@attributes":{"id":"p-0114","num":"0113"},"figref":"FIG. 12","b":["1280","714","1280","1222","1302","1222","1280"]},"Referring now to  there is shown a graphical representation of the PDDI  of , in which the user is previewing a video clip. A user can select a play arrow  located near each selected segment along the video timeline in the Content Selection field  to cause the clip to begin to play. Alternatively, the system can be configured so that the full video content represented by the video timeline will begin to play when the play arrow  is selected. When the video is playing in the Preview field , the associated segment along the timeline (e.g., segment ) will be highlighted, and the play arrow  next to the segment will change form (e.g., double lines) to denote that the segment is being played. Alternatively, the system can be designed so that the user can select a video frame and cause it to begin to play just by clicking or double-clicking on the particular video frame in the multimedia document in the Preview field  or by clicking on the frame in the video timeline. Additionally, in some embodiments, if a user right-clicks on a segment (e.g., ) in the video timeline, a dialog box will appear giving the user an option to play the video (staring at the beginning of the segment). The user can select the play option in the dialog box, and the video frame will begin to play in the Preview field .","When the user selects a particular video segment for preview, a media player that is embedded in the PDDI  starts to play the video segment in the Preview field  from the start of the video segment. For example, in , the video segment can begin to play at time four minutes and twenty-one seconds into the news segment, and this corresponds to the beginning of the selected clip that runs from \u201c00:04:20-00:06:35.\u201d As discussed previously, the video content could alternatively start playing from \u201c00:00:00\u201d on the video timeline, rather than at the specific clip. Alternatively, the system may be designed such that the media player does not begin playing the video clip until the user selects the play button . Thus, upon selecting a video segment to be previewed, the media player appears with the slider  at the beginning of the segment, the user must actually click the play button  to cause the content to begin to play.","The media player in the Preview field  also includes the features of many standard multimedia players (e.g., Microsoft Windows Media Player), such as a pause button  for stopping\/pausing the display of the video clip, a rewind button  for rewinding within the video content, a fast forward button  for fast forwarding within the video content, and a volume adjuster  for setting the volume for display. A slider  is also included, which can allow the user to move around within the video content. The slider bar , along which the slider moves , can correspond to the length of the full video content displayed along the time line or it can correspond only to the length of the clip. The user can click on and drag the slider  along the slider bar  to move around within the video content. The fast forward button  and the rewind button  can be configured to allow the user to only move within the selected segment, or can alternatively allow the user to move within the full video content associated with the video timeline. The media player can be missing any one of the control buttons shown in , or it can include other buttons for controlling display of a video.",{"@attributes":{"id":"p-0118","num":"0117"},"figref":["FIG. 13","FIG. 12"],"b":["1280","714","714"]},"Referring now to , there is shown a graphical representation of a PDDI  in which a video clip is being displayed in the Preview field .  shows the creation of a segment through use of the beginning marker button  and the end marker button  included in the media player in this embodiment. The media player can be designed so that the beginning of the slider bar  corresponds with the beginning of the video content associated with the video timeline (e.g., at \u201c00:00:00\u201d) or with the beginning of the selected clip. When the video content is playing, the user can use beginning marker button  and end marker button  to mark segments of interest. For example, if a user is interested in video content within a news segment that discusses a particular actor, the user can play the video content in the media player. When the user reaches a segment discussing the actor, the user can click beginning marker button  to mark the location. When the segment ends, the user can click end marker button . The user can continue to do this throughout the news segment, marking segments of interest to be printed or for any other purpose.",{"@attributes":{"id":"p-0120","num":"0119"},"figref":["FIG. 15","FIG. 12","FIG. 15"],"b":["122","714","1502","1502","1502","1502"]},"Referring now to  there is shown a graphical representation of the PDDI  of  in which the user has selected the edit option in the dialog box . Upon selecting the edit option in the dialog box , an edit dialog box  appears allowing the user to select further options. In the edit dialog box , the user can modify the start time or the end time for a segment by modifying the start time field  and the end time field . Thus, the user can choose to have the segment include some of the time that comes before or after the segment. For example, the user may be interested in seeing the video content that occurred in a CNN News segment 45 seconds before the defined start time for the segment because there may be an introduction or some lead-in in which the user has an interest. Additionally, the user may be interested in seeing the video content that comes a few seconds after the defined end time for a segment. The user can alternatively modify the start and end time of a segment to shorten the segment and remove extraneous content in which the user does not have an interest. After modifying either the start time, the end time, or both, the user can select the OK button to apply the modifications, or the user can select the Cancel button to end the task and make the edit dialog box  disappear.","In the example of , instead of manually selecting segments of the video timeline with the selector , the user has applied a segmentation type to the video data. The user has selected, in the segmentation type field , to conduct face detection, in which the system will search for images of faces within the video content. When face detection is selected, the PDDI  shows segments along a timeline that contain face images. Each segment can be accompanied by an integer that expresses the number of faces detected in a clip as well as a confidence value. The user has also selected, within the threshold selection field , to apply a threshold value of 80%. Thus, only video frames that are more than 80% likely to include face images will be displayed in the PDDI . The face detection results are displayed in the Segmentation Display field . Each event segment  shown within the Segmentation Display field  corresponds to a video frame or set of video frames that are more than 80% likely to include a face image.","The event segments  are shown as staggered boxes in . However, these might also be lines stretching across the Segmentation Display field  or other visual indicators. The user can right click on any one of the event segments  to delete the event segment . Markers (e.g., barcodes) corresponding to the event segments  can be shown in the multimedia document displayed in the Preview field . The user can click on the play arrows  located near each event segment  to play the video content that likely contains a face image. Additionally, a preview window  appears as the user moves the selector  along the video timeline, providing the user with an opportunity to view the video frames in the event segments  to ensure that a face image is present. Additionally, the system might be configured to merge video content showing an image of the same face into one video frame, rather than displaying a separate video frame for each instance of a particular face image.","Besides the face detection example of , there are numerous other segmentation types that can be applied to video content or other kinds of multimedia content. Each of these segmentation types can be displayed in a menu in the segmentation type field , and the user can select from the menu which segmentation type should be applied. The following is a summary of examples of various different segmentation types that can be applied. Video event detection is a segmentation type that a user can apply, in which the PDDI  shows the results of applying a video event detection algorithm along a timeline. Examples of video events include the cases when people stood up during a meeting or when people entered a room. Color histogram analysis is another segmentation type that a user can apply, in which the PDDI  shows the results of applying a color histogram analysis algorithm along a timeline. For example, the PDDI  could show a hue diagram at every 30-second interval, allowing an experienced user to quickly locate the portions of a video that contain sunsets. In addition, clustering can be applied to cluster the face images so that multiple instances of the same face are merged into one representation face image.","Face recognition is another segmentation type, in which the PDDI  shows names along a timeline that were derived by application of face recognition to video frames at corresponding points along the time line. Also, a series of checkboxes are provided that let the user select clips by choosing names. Optical character recognition (OCR) is a segmentation type, in which OCR is performed on each frame in the video content, and each frame is subsampled (i.e., once every 30 frames). The results are displayed along a timeline. A text entry dialog box is also provided that lets the user enter words that are searched within the OCR results. Clips that contain the entered text are indicated along the timeline. In addition, clustering can be applied so that the similar results in performing OCR to each frame are merged. Clusters that contain the entered text are indicated along the timeline.","In addition to the above segmentation types, there are other examples of that could be applied. Motion analysis is another segmentation type, in which the PDDI  shows the results of applying a motion analysis algorithm along a timeline. The results can be shown as a waveform, for example, with a magnitude that indicates the amount of detected motion. This would allow an experienced user to quickly locate the portions of a video that contain a person running across the camera's view, for example. Distance estimation is another segmentation type, in which the PDDI  shows the results of applying a distance estimation algorithm along a timeline. For example, in a surveillance camera application using two cameras a known distance apart, the distance of each point from the camera can be estimated. The user can set the threshold value to select portions of a given video file to print, based on their distance from the camera. For example, the user may wish to see only objects that are more than 50 yards away from the camera. Foreground and background segmentation can also applied, in which the PDDI  shows the results of applying a foreground\/background segmentation algorithm along a timeline. At each point, the foreground objects are displayed. A clustering and merging algorithm can be applied across groups of adjacent frames to reduce the number of individual objects that are displayed. A user can set the threshold value to select portions of a given video file to print based the confidence value of the foreground\/background segmentation, as well as the merging algorithm. Scene segmentation is another type that the user can apply, in which the PDDI  shows the results of applying a shot segmentation algorithm along a timeline. Each segment can be accompanied by a confidence value that the segmentation is correct.","Segmentation types for recognizing automobiles or license plates can also be applied. Automobile recognition might be useful, for example, to a user who operates a surveillance camera that creates many hours of very boring video. Such a user often needs to find and print only those sections that contain a specific object, such as a red Cadillac. For this purpose, each frame in the video is input to an automobile recognition technique and the results are displayed along a timeline. License plate recognition might also be useful to a user operating a surveillance camera and may need to search the surveillance video for sections containing a specific license plate number. For this purpose, each frame in the video is input to a license plate recognition technique and the results (plate number, state, plate color, name and address of plate holder, outstanding arrest warrants, criminal history of the plate holder, etc.) are displayed along a timeline. With either automobile or license plate recognition, the user can set a threshold value to select portions of a given video file to print based on the confidence values that accompany the automobile or license plate recognition results. A text entry dialog box is also provided that allows the user to enter identifiers for the make, model, color, and year for an automobile, or plate number, state, and year, etc. for a license plate. These text entries are searched for within the recognition results. Clips that contain the entered information are indicated along the timeline.","Referring now to  there is shown a graphical representation of a PDDI  that includes video content from multiple sources displayed on more than one timeline. For example, the video content could originate from two different CNN News segments, or it could originate from both a CNN News segment and a CSPAN news segment. The system can be configured to print video frames from one news segment on one page of the multimedia document and video frames from another news segment on another page.  displays two separate Content Selection fields, and , each with a separate video timeline displaying extracted video frames and associated text. Each video timeline includes a selector, and for making selections within the video timelines and event segments  that denote frames in which a face image was detected with a more than 80% chance. Each video timeline also includes a separate Segmentation Display field  associated with it that shows the even segments  that resulted from the application of face detection to that video source. Thus, the user can independently move selector and around each timeline until the user has viewed the preview windows  and determined which video frames to select for display in a multimedia document. While  shows two video timelines, it is also possible for the user to compare multiple sources, and thus generate multiple timelines in the PDDI .","The user can apply a number of different segmentation types to video content using the PDDI. The user may choose to apply both audio detection and speaker recognition to one twelve-minute-long CNN News show, for example.  shows the PDDI  of , in which face detection was applied. However,  shows the results of the application of both the face detection video OCR. The system is configured, in some embodiments, to include a drop-down menu in the segmentation type field. The menu can list each segmentation type, one-by-one, within the menu. Thus, in this embodiment, the user can click on more than one segmentation type in the menu (i.e., by holding down the CTRL key while making selections) and apply all of the selected segmentation types.","In other embodiments, the menu might also include a number of different combination options, allowing the user to select one item in the menu that includes more than one segmentation type. For example, audio detection plus speaker recognition may be one combination item on the menu. By selecting this option in the menu, the user causes audio detection and speaker recognition to be performed on the multimedia content. This combination menu items may be preset in the printer  properties as a default list of segmentation types and segmentation combination types. In addition, the user can define his or her own combination types. When the user creates a user-defined segmentation type, the user can give the segmentation type a name, and this option will appear in the drop-down menu of segmentation types. The segmentation type in  is entitled \u201cCombo,\u201d and it is a user-defined combination of single segmentation types. Additionally, the threshold field  is disabled because a combination of more than one segmentation technique could produce a huge number of parameters that could be tuned. Thus, each combination of techniques can have a default set of parameter values that are proven to function well. However, the user can modify them in the dialog box (not shown) that appears when the Options button  is clicked.","As shown in , the Content Selection field  includes two Segmentation Display fields , one for each segmentation type that was applied to the video content. In this example, there is one Segmentation Display field  for each of the two segmentation types that make up \u201cCombo.\u201d The Segmentation Display field  to the left shows the results of applying the face detection that was shown in . However, the event segments  are not staggered as they were in , and are instead lined up one over the other. The Segmentation Display field  to the right shows the results of applying video OCR to the video content. The event segments  shown in this Segmentation Display field  appear different from those shown in the Segmentation Display field  to the left. However, in some embodiments, the event segments  shown in different Segmentation Display fields  could appear the same. In some embodiments, the event segments  are arranged in a different format in the two Segmentation Display fields , or the PDDI  can contain only one Segmentation Display field  that shows event segments  for all segmentation types applied.","Besides the example of  in which a combination of segmentation types is applied (e.g., Combo), there are numerous other combinations of segmentation types that can be made. Each of these combinations of segmentation types can be displayed in a menu in the segmentation type field , and the user can select from the menu which segmentation type should be applied. The following is a summary of examples of various different combinations of segmentation types, though numerous other combinations that are not discussed below can also be made. The user can apply motion analysis in combination with distance estimation, in which the PDDI  shows the results of applying a motion analysis algorithm and a distance estimation algorithm along one timeline or two separate timelines. The motion analysis timeline could include a waveform whose magnitude indicates the amount of detected motion. The user can set a threshold value allowing the user to select portions of a given video file to print, based on the amount of motion that was detected and the distance of that motion from the camera. Scene segmentation and face detection is another combination that a user could apply, in which the PDDI  shows the results of applying a shot segmentation algorithm along a timeline. Color or a special icon, for example, can indicate segments on the timeline that contain face images. Each segment can be accompanied by a confidence value that the scene segmentation is correct and can be accompanied by an integer that expresses the number of faces detected as well as a confidence value. Scene segmentation and OCR is another combination that could be applied, in which the PDDI  shows the results of applying a shot segmentation algorithm along a timeline. OCR is also performed on each frame in the video content, and the content is subsampled. The results are displayed along a same or different timeline. The user can also conduct text searches in the OCR results and segments containing the search words can be displayed along the timeline.","When applying combinations of segmentation types to multimedia content, the user is not limited to applying just two types in a combination. The user can apply three or more segmentation types, and such combinations can be shown in the segmentation type menu by default or they can be created by the user. Scene segmentation, OCR, and face recognition can be applied in combination, in which the PDDI  shows the results of applying a shot segmentation algorithm along a timeline. Each frame in the video has OCR performed on it and is subsampled, and the results are displayed along the same or different timeline. Names that were derived by application of face recognition to video frames are also shown on the same or different timeline. Also, a series of checkboxes are provided that let the user select clips by choosing names. The user can set threshold values for the results, allowing the user to select portions of a given video file to print based on the confidence values that accompany the shot segmentation, OCR, and face recognition results. Alternatively, the user could apply face detection with OCR and scene segmentation. The PDDI  would display the OCR and scene segmentation results as described above. The same or different timeline could also include segments that contain face images. Each segment can be accompanied by an integer that expresses the number of faces detected in the clip as well as a confidence value.","Automobile recognition plus motion analysis could be another alternative segmentation type combination, in which each frame in the video is input to an automobile recognition technique and the results are displayed along a timeline. Also, a motion analysis technique is applied to the video to estimate the automobile's speed from one frame to the next. A text entry dialog box is also provided that allows the user to enter identifiers for the make, model, color, and year for an automobile, and the automobile speed. These items are searched within the automobile recognition and motion analysis results, and clips that contain the entered information are indicated along the timeline.","While  shows an example of more than one segmentation types (e.g., Combo) being applied to video content, it is possible to apply more than one segmentation type to audio content or any other type of multimedia content. The following is a summary of different combinations of segmentation types that can be applied, although numerous other combinations can be made that are not discussed below. Audio event detection plus classification is one example of a combination. The PDDI  shows the results of applying audio event detection, such as clapping, yelling, or laughing, along a timeline. Each detected event is accompanied by a confidence that it was detected correctly. The PDDI  includes a series of check boxes that let the user choose which events to display. Speaker segmentation and speaker recognition is another example of a combination. Each segment is shown in a different color or by different icon along a timeline, and segments that were produced by the same speaker are shown in the same color or by the same icon. The speaker recognition results include text and optionally confidence values for each speaker name. Multiple speaker names could be associated with each segment. Sound source localization and audio event detection could alternatively be applied by a user. The direction from which sound was detected is displayed as a sector of a circle. Each sector is accompanied by a confidence that it was detected correctly. The user interface includes a series of check boxes arranged around the circumference of a prototype circle that let the user choose which directions to display. Each detected audio event is accompanied by a confidence that it was detected correctly, and the PDDI  includes a series of check boxes that let the user choose which events to display. A user could alternatively apply speech recognition and profile analysis, in combination. A timeline in the PDDI  shows text and optionally confidence values for each word or sentence spoken. The speech recognition results are matched against a pre-existing text-based profile that represents the user's interests. The user can adjust a threshold on the confidence values, and the user can also adjust a threshold on the degree of match between the profile and the speech recognition results. Speech recognition and audio event detection is another example of a combination that could be applied. The timeline(s) include text and optionally confidence values for each word or sentence spoken, along with the results of applying audio event detection.","When applying combinations of segmentation types to multimedia content, the user is not limited to applying just two types in a combination. The user can apply three or more segmentation types, and such combinations can be shown in the segmentation type menu by default or they can be created by the user. Speech recognition, audio event detection, and speaker recognition can be applied in combination. The speech recognition results include text and optionally confidence values for each word or sentence. Audio events detected are shown on the same or different timeline. The PDDI  also displays the name of each speaker detected, accompanied by a confidence that it was detected correctly. The user interface includes a series of check boxes that let the user choose which speakers to display. Speech recognition, audio event detection, and speaker segmentation could alternatively be applied. The application is the same as above, except speaker segmentation events are shown instead of speaker recognition events. Each speaker segment is shown in a different color or with a different icon, and segments that were produced by the same speaker are shown in the same color or with the same icon. As another example, speech recognition, audio event detection, and sound localization could be applied in combination. The timeline(s) will show text and optionally confidence values for each word or sentence, along with audio events detected. The timeline(s) also display the direction from which sound was detected as a sector of a circle. Each sector is accompanied by a confidence that it was detected correctly. The user interface includes a series of check boxes arranged around the circumference of a prototype circle that let the user choose which directions to display.","Referring now to  there is shown a multimedia representation (e.g., a video paper document) that displays a representation of another embodiment of a multimedia document that can be produced by the system. This document  shows eight video frames , and some of the video frames are accompanied by text , which could be a transcript of the dialog, a summary of the video content, and the like, that could have been produced by the PDDI in . Dividers  separate each video frame  in this embodiment, and time stamps  showing the start time to end time of each segment of video content are included in each divider . In addition, a header  is shown displaying information about the video content. In this example, the header  shows the title, CNN News, the time of the news show (e.g., 10:00 am), the date of the show (e.g., Sep. 19, 2001), and the duration of the show (e.g., twelve minutes and nineteen seconds long).","Identifiers  are shown under each video frame , and the user can select any one of these identifiers  to cause the video content associated with the video frame  to begin to play. The video frame  can begin to play at a point at which the speaker is starting to recite the associated text  transcript. The video frames  for which no text is shown or for which the phrase \u201cno text\u201d is displayed could include video content in which the person in the clip is not speaking, or may represent examples in which the user selected not to show text.","The multimedia document shown in the embodiment of  further shows control markers or identifiers for controlling video content display. In , there is shown a play marker , a fast forward (FF) marker , and a rewind marker . The markers provide an interface to the multimedia data, as described previously.","While the present invention has been described with reference to certain preferred embodiments, those skilled in the art will recognize that various modifications may be provided. Variations upon and modifications to the preferred embodiments are provided for by the present invention, which is limited only by the following claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The invention is illustrated by way of example, and not by way of limitation in the figures of the accompanying drawings in which like reference numerals refer to similar elements.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 20"}]},"DETDESC":[{},{}]}
