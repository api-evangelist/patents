---
title: System and methods for removing obsolete data in a distributed system of hybrid storage and compute nodes
abstract: A distributed garbage collection in a distributed storage system is described, where the storage controller functions of the distributed storage system are separated from that of distributed storage system storage media. In an exemplary embodiment, a storage controller server generates a live object map of live objects stored on the distributed storage system in a plurality of block segments distributed across a plurality of storage controller servers. The storage controller server further scans the plurality of block segments to generate segment summary statistics, where the segment summary statistics indicates the number of live objects stored in the plurality of block segments. In addition, the storage controller server compacts each of the plurality of block segments that have a low utilization based on the segment summary statistics. Furthermore, the live object map is a probabilistic data structure storing a list of valid objects.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09448927&OS=09448927&RS=09448927
owner: Springpath, Inc.
number: 09448927
owner_city: Sunnyvale
owner_country: US
publication_date: 20131219
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","FIELD OF INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE DESCRIPTION","DETAILED DESCRIPTION"],"p":["Applicant claims the benefit of priority of prior, provisional application Ser. No. 61\/739,685, filed Dec. 19, 2012, the entirety of which is incorporated by reference.","This invention relates generally to a storage system and more particularly to distributed garbage collection in a distributed storage system.","Enterprise storage systems currently available are proprietary storage appliances that integrate the storage controller functions and the storage media into the same physical unit. This centralized model makes it harder to independently scale the storage systems' capacity, performance and cost. Users can get tied to one expensive appliance without the flexibility of adapting it to different application requirements that may change over time. For small and medium scale enterprise, this may require huge upfront capital cost. For larger enterprise datacenters, new storage appliances are added as the storage capacity and performance requirements increase. These operate in silos and impose significant management overheads.","These storage systems either build storage systems as in-place filesystem (where data being overwritten in place), log-structured (where data being written is redirected to a new location) or copy on write (where the data is written in place, but a copy of the original data is written to new location). In all of these approaches, cleaning of up data to reclaim space, that was generated either by invalidation of old data by new writes or user triggered deletes, poses a challenging problem.","In addition, storage systems build a reference counting mechanism to track data accessible by the user. Whenever a data block or segment reaches a reference count of 0, it becomes a viable candidate for reclamation. That approach is efficient on a single node where there is no requirement to coordinate the reference count on a datablock. However, this mechanism becomes a challenge in a distributed multi-node environment.","A distributed garbage collection in a distributed storage system is described, where the storage controller functions of the distributed storage system are separated from that of distributed storage system storage media. In an exemplary embodiment, a storage controller server generates a live object map of live objects stored on the distributed storage system in a plurality of block segments distributed across a plurality of storage controller servers. The storage controller server further scans the plurality of block segments to generate segment summary statistics, where the segment summary statistics indicates the number of live objects stored in the plurality of block segments. In addition, the storage controller server compacts each of the plurality of block segments that have a low utilization based on the segment summary statistics. Furthermore, the live object map is a probabilistic data structure storing a list of valid objects.","Other methods and apparatuses are also described.","A distributed garbage collection in a distributed storage system is described, where the storage controller functions of the distributed storage system are separated from that of distributed storage system storage media. In the following description, numerous specific details are set forth to provide thorough explanation of embodiments of the present invention. It will be apparent, however, to one skilled in the art, that embodiments of the present invention may be practiced without these specific details. In other instances, well-known components, structures, and techniques have not been shown in detail in order not to obscure the understanding of this description.","Reference in the specification to \u201cone embodiment\u201d or \u201can embodiment\u201d means that a particular feature, structure, or characteristic described in connection with the embodiment can be included in at least one embodiment of the invention. The appearances of the phrase \u201cin one embodiment\u201d in various places in the specification do not necessarily all refer to the same embodiment.","In the following description and claims, the terms \u201ccoupled\u201d and \u201cconnected,\u201d along with their derivatives, may be used. It should be understood that these terms are not intended as synonyms for each other. \u201cCoupled\u201d is used to indicate that two or more elements, which may or may not be in direct physical or electrical contact with each other, co-operate or interact with each other. \u201cConnected\u201d is used to indicate the establishment of communication between two or more elements that are coupled with each other.","The processes depicted in the figures that follow, are performed by processing logic that comprises hardware (e.g., circuitry, dedicated logic, etc.), software (such as is run on a general-purpose computer system or a dedicated machine), or a combination of both. Although the processes are described below in terms of some sequential operations, it should be appreciated that some of the operations described may be performed in different order. Moreover, some operations may be performed in parallel rather than sequentially.","The terms \u201cserver,\u201d \u201cclient,\u201d and \u201cdevice\u201d are intended to refer generally to data processing systems rather than specifically to a particular form factor for the server, client, and\/or device.","A distributed garbage collection in a distributed storage system is described, where the storage controller functions of the distributed storage system are separated from that of distributed storage system storage media. In one embodiment, the StorFS system writes incoming data to a new location on the persistent storage. This means that when an object or a logical offset within a file gets overwritten, the old object or file content needs to be removed (e.g. cleaned or garbage collected.) Because of this, the StorFS system needs to determine a list of valid (e.g., live) objects. Due to the presence of snapshots, clones and deduplication, multiple files, or file systems may reference the same data object. In one embodiment, the StorFS system traverses the metadata tree to compile a list of valid data objects, which form the leaf of the metadata tree. Because a cluster may contain billions of valid objects, this list can be gigantic and would not fit in the main memory.","To address this issue, and in one embodiment, the StorFS system uses a space-efficient probabilistic data structure to store the list of valid objects. In one embodiment, the space-efficient probabilistic data structure is space-efficient approximate membership data-structure such as bloom filter or quotient filter. For example and in one embodiment, a bloom filter can be used to store the list of valid objects. The bloom filter permits membership tests with very little memory compared to the number of object entries it stores. The garbage collection process involves generating a live object map, cleaning the segments, and compacting the segments. In one embodiment, the live object map generation includes traversing the metadata tree and populating the bloom filter. In one embodiment, cleaning the segments includes scanning the segments to check the number of live objects contained in the segments and generating a segment summary statistic. In one embodiment, compacting the segments includes compacting segments with low utilization based on segment summary statistics.",{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 1","FIG. 1"],"b":["100","100","102","116","102","100","100","102","108","110","110","108","108","110","110","110","102","112","102","114"]},"In one embodiment, the design of the StorFS system  distributes both the data and the metadata, and this system  does not require storing a complete global map for locating individual data blocks in our system. The responsibility of managing metadata is offloaded to each individual storage nodes A-C. In one embodiment, a cluster manager (CRM) resides on each SC Server  maintains some global metadata, which is small compared to the local metadata. In one embodiment, each logical file (or entity) is partitioned into equal sized \u201cstripe units\u201d. The location of a stripe unit is determined based on a mathematical placement function Equation (1):",{"@attributes":{"id":"p-0031","num":"0030"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":["Virtual_Node","#"],"mo":"\u2062"},{"mrow":{"mi":"Hash","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["Entity","id"]},"mo":",","mrow":{"mi":["Stripe_Unit","#"],"mo":"\u2062"}}}},"mo":["\u2062","\u2062","\u2062"],"mi":["%","Total_Vitual","_Nodes"]}],"mo":"="},{"mrow":[{"mi":["Stripe_Unit","#"],"mo":"\u2062"},{"mfrac":{"mi":"offset","mrow":{"mi":["Stripe_Unit","_Size"],"mo":"\u2062"}},"mo":["\u2062","\u2062","\u2062","\u2062"],"mi":["%","Stripe_Unit","_Per","_Stripe"]}],"mo":"="}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}},"br":{},"sub":["Id ","Id ","Id ","Id "],"b":["100","100","100"]},"In one embodiment, the StorFS  system receives the Entityand offset as input for each requested storage operation from an application A-C. In this embodiment, the StorFS system  uses the offset to compute a stripe unit number, Stripe_Unit#, based on the stripe unit size, Stripe_Unit_Size, and the number of virtual nodes that the entity can be spread across, Stripe_Unit_Per_Stripe. Using the stripe unit number and the entity identifier (Entity), the StorFS system  computes the virtual node identifier. As described below, the StorFS system  uses a hash function to compute the virtual node identifier. With the virtual node identifier, the StorFS  can identify which physical node the storage entity is associated with and can route the request to the corresponding SC server A-C.","In one embodiment, each vNode is a collection of either one or more data or metadata objects. In one embodiment, the StorFS system  does not store data and metadata in the same virtual node. This is because data and metadata may have different access patterns and quality of service (QoS) requirements. In one embodiment, a vNode does not span across two devices (e.g. a HDD). A single storage disk of a storage node A-C may contain multiple vNodes. In one embodiment, the placement function uses that a deterministic hashing function and that has good uniformity over the total number of virtual nodes. A hashing function as known in the art can be used (e.g., Jenkins hash, murmur hash, etc.). In one embodiment, the \u201cStripe_Unit_Per_Stripe\u201d attribute determines the number of total virtual nodes that an entity can be spread across. This enables distributing and parallelizing the workload across multiple storage nodes (e.g., multiple SC servers A-C). In one embodiment, the StorFS system  uses a two-level indexing scheme that maps the logical address (e.g. offset within a file or an object) to a virtual block address (VBA) and from the VBAs to physical block address (PBA). In one embodiment, the VBAs are prefixed by the ID of the vNode in which they are stored. This vNode identifier (ID) is used by the SC client and other StorFS system  components to route the I\/O to the correct cluster node. The physical location on the disk is determined based on the second index, which is local to a physical node. In one embodiment, a VBA is unique across the StorFS cluster, where no two objects in the cluster will have the same VBA.","In one embodiment, the cluster manager (CRM) maintains a database of virtual node (vNode) to physical node (pNode) mapping. In this embodiment, each SC client and server caches the above mapping and computes the location of a particular data block using the above function in Equation (1). In this embodiment, the cluster manager need not be consulted for every I\/O. Instead, the cluster manager is notified if there is any change in \u2018vNode\u2019 to \u2018pNode\u2019 mapping, which may happen due to node\/disk failure, load balancing, etc. This allows the StorFS system to scale up and parallelize\/distribute the workload to many different storage nodes. In addition, this provides a more deterministic routing behavior and quality of service. By distributing I\/Os across different storage nodes, the workloads can take advantage of the caches in each of those nodes, thereby providing higher combined performance. Even if the application migrates (e.g. a virtual machine migrates in a virtualized environment), the routing logic can fetch the data from the appropriate storage nodes. Since the placement is done at the stripe unit granularity, access to data within a particular stripe unit goes to the same physical node. Access to two different stripe units may land in different physical nodes. The striping can be configured at different level (e.g. file, volume, etc.) Depending on the application settings, the size of a stripe unit can range from a few megabytes to a few hundred megabytes. In one embodiment, this can provide a good balance between fragmentation (for sequential file access) and load distribution.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 2","b":["200","220","218","220","216","214","212","208","210","208","206","202","204","222","224"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 3A","b":["302","304","310","308","10"]},"In one embodiment, the garbage collection module includes a live object map , segment cleaner , and segment compactor . In one embodiment, the live object map  is a map of the live objects stored in the StorFS system. In one embodiment, the garbage collector  further includes live object map full module  that builds a full live object map as described in  below and a live object map generation  that updates the live object map  for a generation as described in  below. In one embodiment, the segment cleaner  scans the block segments to check the number of live objects they contain and generate a segment summary statistic. In one embodiment, the segment compactor  compacts segments whose utilization drops below a certain threshold.","In one embodiment, the StorFS system writes incoming data to a new location on the persistent storage. This means that when an object or a logical offset within a file gets overwritten, the old object or file content needs to be removed (e.g. cleaned or garbage collected.) Because of this, the StorFS system needs to determine a list of valid (e.g., live) objects. Due to the presence of snapshots, clones and deduplication, multiple files, or file systems may reference the same data object. In one embodiment, the StorFS system traverses the metadata tree to compile a list of valid data objects, which form the leaf of the metadata tree. Because a cluster may contain billions of valid objects, this list can be gigantic and would not fit in the main memory. To address this issue, the StorFS system uses a space-efficient probabilistic data structure to store the list of valid objects. For example and in one embodiment, a bloom filter can be used to store the list of valid objects. The bloom filter permits membership tests with very little memory compared to the number of object entries it stores. The garbage collection process involves generating a live object map, cleaning the segments, and compacting the segments. In one embodiment, the live object map generation includes traversing the metadata tree and populating the bloom filter. In one embodiment, cleaning the segments includes scanning the segments to check the number of live objects contained in the segments and generating a segment summary statistic. In one embodiment, compacting the segments includes compacting segments with low utilization based on segment summary statistics.",{"@attributes":{"id":"p-0039","num":"0038"},"figref":["FIG. 3B","FIG. 3","FIGS. 4 and 5"],"b":["350","350","304","350","352","350"]},"At block , process  scans the segments to check the number of live objects contained in the segments and generates a segment summary statistic. In one embodiment, once the live object map has been created, the process  scans the block segments to check the number of live objects they contain and generates a segment summary statistic of the utilization of the segments, (e.g. the ratio of number of the live-objects to the total number of objects in the segment). In one embodiment, the summary statistics can be built in two ways: (1) by a complete block segment scan and (2) using and in essential statistics update. In one embodiment, the complete block segment scan operates by having process  iterates over all the segments to check for valid objects. This approach can have more overhead because of a large number of I\/Os the approach generates.","In one embodiment, in the incremental summary statistics update, process  uses the dead object hint log generated by the \u2018Write Log Flusher\u2019. The objects in this log are tested for their membership in the live object map. If the test is negative, process  confirms that the object is actually dead. In addition, process  updates its segment summary statistics by decrementing the utilization.","Process  compacts the segments with low utilization at block . In one embodiment, compact segmentation compacts segments whose utilization drops below a certain threshold. In this embodiment, each segment can contain four types of entities: Live objects, dead objects, object tombstone entry, and segment tombstone entry. These entities are dealt as follows during compaction:\n\n","In one embodiment, metadata traversal can cause a lot of random I\/Os that can lead to very high overhead in HDD. File metadata, for example, is organized in a hierarchical tree format to locate data blocks on the persistent storage. In one embodiment, the StorFS system employs a smart traversal algorithm that efficiently reads the whole metadata tree with very little random I\/O to the HDD. If there is sufficient space on the faster flash drive to hold the metadata vNode, the StorFS system copies the entire metadata vNode onto the faster flash drive. The random read I\/Os during the traversal are sent to faster flash drives, which have much higher random read performance compared to HDD. In addition, the StorFS system caches the top few levels of the metadata tree in the DRAM to further expedite the tree traversal.","The live object map can be generated for the complete metadata tree using the algorithm shown in . This makes sure that the live objects for the tree are captured in the corresponding bloom filter.  is a flow diagram of one embodiment of a process  to perform a full metadata tree walk for garbage collection. In one embodiment, this walk is performed by the garbage collection module  as shown in . In , process  begins by performing a processing loop (blocks -) to perform the metadata tree walk for each metadata vNode. At block , process  determines the number of data keys that could be potentially inserted into a Bloom Filter. In one embodiment, the number of data keys that could be inserted could be based on an estimate from the previous run of the algorithm or some information provided by metadata file tree about the number of keys in the File System.","Process  instantiates a bloom filter to manage the data keys at block . In one embodiment, this bloom filter is called the D-Bloom. At block , process  instantiates a bloom filter to manage and clean the Metadata vNode, which are metadata keys. In one embodiment, this metadata bloom filter is called the M-bloom. In one embodiment, the size of the M-bloom is up to an order of magnitude smaller that the D-bloom bloom filter. In one embodiment, this bloom filter is a space-efficient probabilistic data structure that is used to test whether an object is a member of a live object map. Process  creates a cache to store intermediate metadata blocks for file tree traversal at block .","At block , process  obtains the head segment ID of the Snapshot being cleaned and the head segment ID of the last cleaned snapshot. The later is referred to as the tail segment. Process  fetches the current list of blocks being deduplicated from the deduplication module . In one embodiment, for each entry in the deduplication list with reference count greater than zero that reside between Head Segment and Tail Segment, process  adds this entry to the D-Bloom list. In addition, at block , process  removes those entries from the Deduplication Module whose reference count is equal to zero. For example and in one embodiment, the Deduplication Module is the Deduplication Module  as described in  above. In one embodiment, process  removes these entries by sending a request to the Deduplication module. At block , process  traverses the metadata tree. In one embodiment, process  traverses the metadata tree by for each entry that is a metadata key, adding it to the M-Bloom filter and for each entry that is a data key, adding it to the D-Bloom filter.","In one embodiment, this complete metadata traversal, however, comes at a cost. In one embodiment, instead of walking the whole tree each time, StorFS implements an approach to incrementally clean the segments written in a particular time duration (e.g. in a day.) Consider the scenario as illustrated in  below, where the full filetree cleaner is executed at (t-) hours. In one embodiment, the segments written between times (t-) and (t) can be of three types: (i) Segments\/objects that were compacted and moved by the segment cleaner; (ii) Segments\/objects that were written because of the incoming writes from the client and are still valid; and (iii) Segments\/objects that were written because of the incoming writes from the client, but were invalidated by subsequence writes in that time window.",{"@attributes":{"id":"p-0048","num":"0051"},"figref":["FIG. 6","FIG. 3"],"b":["600","600","604","602","610","604","606","608","610"]},{"@attributes":{"id":"p-0049","num":"0052"},"figref":["FIG. 5","FIG. 5"],"b":["304","500","500","502","518","504","500","506","500","500","508"]},"At block , process  creates a cache to store intermediate metadata blocks for filetree traversal. Process  obtains a head segment ID and the generation number of the snapshot being cleaned now at block . In one embodiment, the head segment ID and the generation number are recorded along with other snapshot attributes when the snapshot is written to the persistent storage. Process  obtains the head segment ID and the generation number from the snapshot attributes. In addition, process  obtains the head segment ID and the generation number of the last cleaned snapshot. In one embodiment, the head segment ID of the last cleaned snapshot is called the tail segment.","At block , process  fetches the current list of blocks being deduplicated. In one embodiment, process  fetches this list from the deduplication module. In one embodiment, at block , process  further, for each entry in the deduplication list with a reference count greater than zero that resides between Head Segment and Tail Segment, adds that entry to the D-Bloom list. In addition, process , for each entry with a reference count that is equal to zero, removes that entries. In one embodiment, process  removes the entry by sending a request to the deduplication module.","Process  traverse those portions of the metadata tree with a generation number that is between the head generation number and the tail generation number. During the traverse, is the entry is a metadata key, process  adds that entry to the M-Bloom bloom filter. If the entry is data key, process  adds that entry to the D-Bloom bloom filter.","In one embodiment, the incremental cleaner cleanses this last category of the segments\/objects. In order to achieve this, the StorFS system stores a \u201cgeneration number\u201d in the metadata tree for each object it writes. The incremental cleaner traverses those portions of the metadata tree whose generation number that is greater than the last generation number it cleaned and populated the live object map. In this embodiment, the segment cleaner cleanses those segments that were written during that time interval. In one embodiment, a system administrator can configure when an incremental full cleaners are ran. For example and in one embodiment, a system administrator may set policies to run the incremental cleaner on weekdays and full cleaner on weekends.","As described above, the garbage collection module  compacts segments that have low utilization.  is a flow diagram of one embodiment of a process  to compact segments. In one embodiment, process  is performed by a process to compact segments, such as process  as described in , block  above. In one embodiment, process  begins by performing a processing loop (blocks -) to compact segments for each segment between logand logof a vNode. In one embodiment, process  analyzes each of these segments to determine which of the segments has low utilization of live objects. At block , process  determines if the segment generation number is less than X. In one embodiment, process  analyzes segments that are between values Xand X. If the segment generation number is less than X, process  proceeds to block  to analyze another segment. If the segment generation number is greater than or equal to X, process  further determines if the segment generation number is greater than Xat block . If the segment generation number is greater than X, process  returns. If the segment generation number is less than or equal to than X, process  builds a keylist for the segment at block . In one embodiment, by building a keylist, process  can verify if the keys represent live or dead objects for that segment.","At block , process  verifies the number of live keys in the live object map. In one embodiment, the live object map is a probabilistic data structure such as a bloom filter as described above. In one embodiment, process  verifies the number of live keys in the M-Bloom or D-Bloom filter. For example and in one embodiment, if the vNode is a metadata vNode, process  verifies the number of live keys in the M-Bloom filter for this metadata vNode. As another example and embodiment, if the vNode is a data vNode, process  verifies the number of live keys in the D-Bloom filter for this data vNode. In one embodiment, process  verifies the number of live keys by querying the live object map for membership of each key. If the key is present process  counts the key as live and increments the count. If not, process  determines the key are dead. With the number of live keys determined, process  determines if the number of live keys is less than a threshold at block . In one embodiment, the threshold is the number of live keys that represents a low utilization for that segment. If a segment has a low utilization, the objects for that segment can be moved to another segment and this segment can be deleted. If the number of live keys is greater than or equal to the threshold, process  proceeds to block  to analyze another segment. If the number of live keys is less than the threshold, process deletes the segment at block . In one embodiment, process  deletes the segment by moving the keys for this segment forward, adding a tombstone for the remaining keys, and deleting the segment. In one embodiment, by deleting the segment, the storage taken up by this segment is freed and can be used for other segments and\/or storage.","In one embodiment, each segment can contain four types of entities: Live objects, dead objects, object tombstone entry, and segment tombstone entry. Process  handles these entities as follows at block : tombstone entries are discarded and need not be carried forward; live objects are copy forwarded to the new segments and the corresponding index for that object is updated; a tombstone entry is added for each dead objects; and a segment tombstone is added for the segment being compacted. Execution proceeds to block ",{"@attributes":{"id":"p-0057","num":"0060"},"figref":["FIG. 8","FIG. 4","FIG. 4","FIG. 4","FIG. 4","FIG. 4","FIG. 4","FIG. 4"],"b":["318","802","804","806","808","810","812","814","802","404","804","406","806","408","808","412","810","414","812","416","814","410"]},{"@attributes":{"id":"p-0058","num":"0061"},"figref":["FIG. 9","FIG. 5","FIG. 5","FIG. 5","FIG. 5","FIG. 5","FIG. 5","FIG. 5"],"b":["320","902","904","906","908","910","912","914","902","504","904","506","906","508","908","512","910","514","912","516","914","510"]},{"@attributes":{"id":"p-0059","num":"0062"},"figref":["FIG. 10","FIG. 7","FIG. 7","FIG. 7","FIG. 7","FIG. 7"],"b":["316","316","1002","1004","1006","1008","1010","1002","704","708","1004","710","1006","712","1008","714","1010","716"]},{"@attributes":{"id":"p-0060","num":"0063"},"figref":["FIG. 11","FIG. 1","FIG. 11"],"b":["1100","1100","102"]},"As shown in , the computer system , which is a form of a data processing system, includes a bus  which is coupled to a microprocessor(s)  and a ROM (Read Only Memory)  and volatile RAM  and a non-volatile memory . The microprocessor  may retrieve the instructions from the memories , ,  and execute the instructions to perform operations described above. The bus  interconnects these various components together and also interconnects these components , , , and  to a display controller and display device  and to peripheral devices such as input\/output (I\/O) devices which may be mice, keyboards, modems, network interfaces, printers and other devices which are well known in the art. Typically, the input\/output devices  are coupled to the system through input\/output controllers . The volatile RAM (Random Access Memory)  is typically implemented as dynamic RAM (DRAM), which requires power continually in order to refresh or maintain the data in the memory.","The mass storage  is typically a magnetic hard drive or a magnetic optical drive or an optical drive or a DVD RAM or a flash memory or other types of memory systems, which maintain data (e.g. large amounts of data) even after power is removed from the system. Typically, the mass storage  will also be a random access memory although this is not required. While  shows that the mass storage  is a local device coupled directly to the rest of the components in the data processing system, it will be appreciated that the present invention may utilize a non-volatile memory which is remote from the system, such as a network storage device which is coupled to the data processing system through a network interface such as a modem, an Ethernet interface or a wireless network. The bus  may include one or more buses connected to each other through various bridges, controllers and\/or adapters as is well known in the art.","Portions of what was described above may be implemented with logic circuitry such as a dedicated logic circuit or with a microcontroller or other form of processing core that executes program code instructions. Thus processes taught by the discussion above may be performed with program code such as machine-executable instructions that cause a machine that executes these instructions to perform certain functions. In this context, a \u201cmachine\u201d may be a machine that converts intermediate form (or \u201cabstract\u201d) instructions into processor specific instructions (e.g., an abstract execution environment such as a \u201cprocess virtual machine\u201d (e.g., a Java Virtual Machine), an interpreter, a Common Language Runtime, a high-level language virtual machine, etc.), and\/or, electronic circuitry disposed on a semiconductor chip (e.g., \u201clogic circuitry\u201d implemented with transistors) designed to execute instructions such as a general-purpose processor and\/or a special-purpose processor. Processes taught by the discussion above may also be performed by (in the alternative to a machine or in combination with a machine) electronic circuitry designed to perform the processes (or a portion thereof) without the execution of program code.","The present invention also relates to an apparatus for performing the operations described herein. This apparatus may be specially constructed for the required purpose, or it may comprise a general-purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, and magnetic-optical disks, read-only memories (ROMs), RAMs, EPROMs, EEPROMs, magnetic or optical cards, or any type of media suitable for storing electronic instructions, and each coupled to a computer system bus.","A machine readable medium includes any mechanism for storing or transmitting information in a form readable by a machine (e.g., a computer). For example, a machine readable medium includes read only memory (\u201cROM\u201d); random access memory (\u201cRAM\u201d); magnetic disk storage media; optical storage media; flash memory devices; etc.","An article of manufacture may be used to store program code. An article of manufacture that stores program code may be embodied as, but is not limited to, one or more memories (e.g., one or more flash memories, random access memories (static, dynamic or other)), optical disks, CD-ROMs, DVD ROMs, EPROMs, EEPROMs, magnetic or optical cards or other type of machine-readable media suitable for storing electronic instructions. Program code may also be downloaded from a remote computer (e.g., a server) to a requesting computer (e.g., a client) by way of data signals embodied in a propagation medium (e.g., via a communication link (e.g., a network connection)).","The preceding detailed descriptions are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the tools used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here, and generally, conceived to be a self-consistent sequence of operations leading to a desired result. The operations are those requiring physical manipulations of physical quantities. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like.","It should be kept in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the above discussion, it is appreciated that throughout the description, discussions utilizing terms such as \u201creceiving,\u201d \u201cdetermining,\u201d \u201ctransmitting,\u201d \u201ccomputing,\u201d \u201cdetecting,\u201d \u201cperforming,\u201d \u201cgenerating,\u201d \u201ccommunicating,\u201d \u201creading,\u201d \u201cwriting,\u201d \u201ctransferring,\u201d \u201cupdating,\u201d \u201cscanning,\u201d \u201ccompacting,\u201d or the like, refer to the action and processes of a computer system, or similar electronic computing device, that manipulates and transforms data represented as physical (electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.","The processes and displays presented herein are not inherently related to any particular computer or other apparatus. Various general-purpose systems may be used with programs in accordance with the teachings herein, or it may prove convenient to construct a more specialized apparatus to perform the operations described. The required structure for a variety of these systems will be evident from the description below. In addition, the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.","The foregoing discussion merely describes some exemplary embodiments of the present invention. One skilled in the art will readily recognize from such discussion, the accompanying drawings and the claims that various modifications can be made without departing from the spirit and scope of the invention."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings in which like references indicate similar elements.",{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
