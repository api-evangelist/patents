---
title: System and method for a task management library to execute map-reduce applications in a map-reduce framework
abstract: An improved system and method for a task management library to execute map-reduce applications is provided. A map-reduce application may be operably coupled to a task manager library and a map-reduce library on a client device. The task manager library may include a wrapper application programming interface that provides application programming interfaces invoked by a wrapper to parse data input values of the map-reduce application. The task manager library may also include a configurator that extracts data and parameters of the map-reduce application from a configuration file to configure the map-reduce application for execution, a scheduler that determines an execution plan based on input and output data dependencies of mappers and reducers, a launcher that iteratively launches the mappers and reducers according to the execution plan, and a task executor that requests the map-reduce library to invoke execution of mappers on mapper servers and reducers on reducer servers.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09619291&OS=09619291&RS=09619291
owner: Yahoo! Inc.
number: 09619291
owner_city: Sunnyvale
owner_country: US
publication_date: 20091220
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["The invention relates generally to computer systems, and more particularly to an improved system and method for a task management library to execute map-reduce applications in a map-reduce framework.","Cloud computing involves many powerful technologies, including map-reduce applications, that allow large online companies to process vast amounts of data in a short period of time. Tasks such as analyzing traffic, extracting knowledge from social media properties or computing new features for a search index are complex by nature and recur on a regular basis. Map-reduce applications are often used to perform these tasks to process large quantities of data. A map-reduce application may be executed in a map-reduce framework of a distributed computer system where input data is divided and loaded for processing by several mappers, each executing on mapper servers, and partial results from processing by mappers are sent for integration to one or more reducers, each executing on reducer servers. In the domain of research and development, a flexible environment is needed to quickly experiment with different configurations for map-reduce applications.","Unfortunately, usage of these technologies requires a technical expertise that, in many cases, constitutes a barrier to entry. For example, Hadoop is an open source Java implementation of a map-reduce framework with an infrastructure that includes a Hadoop core or map-reduce library to support distributing map-reduce applications over multiple machines. Hadoop has quite a steep learning curve, requiring a developer to become familiar with several technologies within the Hadoop framework such as a data serialization system, a data collection system, a distributed file system, a data warehouse infrastructure, and a high-level data-flow language and execution framework for parallel computation. Additionally, a developer must learn to program data analysis applications in the programming model for processing large data sets including specifying map functions that process an input set of key\/value pairs to generate a set of intermediate key\/value pairs, and reduce functions that merge intermediate values associated with the same intermediate key into an output set of key\/value pairs.","What is needed is a way for a developer to focus on programming data analysis applications in a map-reduce programming model without needing to become familiar with the technical details of several technologies within the Hadoop framework. Such a system and method should allow for easily chaining and parallelizing tasks of a map-reduce application in a map-reduce framework.","Briefly, the present invention may provide a system and method for a task management library to execute map-reduce applications in a map-reduce framework. In an embodiment of a distributed system, a map-reduce application may be operably coupled to a task manager library and a map-reduce library on a client device, also referred to as a gateway. The map-reduce application may specify mappers configured to process data from an input file by executing on mapper servers and reducers configured to integrate results of processing data from the input file by executing on reducer servers. The map-reduce application may further specify wrappers to parse data input values of the map-reduce application. The map-reduce application may include functionality for invoking the task manager library that interfaces with a map-reduce library to manage the execution of mappers and reducers. The task manager library may include a wrapper application programming interface that provides application programming interfaces invoked by a wrapper to parse data input values of the map-reduce application. The task manager library may also include a configurator that extracts data and parameters of the map-reduce application from a configuration file to configure the map-reduce application for execution, a scheduler that determines an execution plan based on input and output data dependencies of mappers and reducers, a launcher that iteratively launches the mappers and reducers according to the execution plan, and a task executor that requests the map-reduce library to invoke execution of mappers on mapper servers and reducers on reducer servers.","For a task management library to execute map-reduce applications in a map-reduce framework, a configuration file on a client device specifying a map-reduce application for execution may be parsed to extract information, including the names of wrappers, mappers and reducers, to determine task dependencies. In an embodiment, task dependencies of mappers and reducers may be automatically determined. Mappers and reducers without task dependencies blocking execution may first be executed, and then remaining mappers and reducers with task dependencies unblocked by the completion of tasks may next be executed. In various embodiments, mappers and reducers without task dependencies may be executed concurrently. Results of data processing from execution may be integrated and sent to the map-reduce application on the client device.","Advantageously, the task management library of the present invention may provide easy configuration of parameters, specification of map-reduce task settings, automated determination of the number of reducers as needed, and task execution control for easily chaining and parallelizing tasks of a map-reduce application. In addition, the task management library may support file caching to allow the usage of external files in mapper and reducers. Files and folders can be specified, and the task management library will automatically add the contents for a given folder to the cache. As a result, a developer may focus on programming data processing applications in a map-reduce programming model without needing to become familiar with the technical details of several technologies within a map-reduce framework.","Other advantages will become apparent from the following detailed description when taken in conjunction with the drawings, in which:","Exemplary Operating Environment",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},"The invention may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, and so forth, which perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in local and\/or remote computer storage media including memory storage devices.","With reference to , an exemplary system for implementing the invention may include a general purpose computer system . Components of the computer system  may include, but are not limited to, a CPU or central processing unit , a system memory , and a system bus  that couples various system components including the system memory  to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.","The computer system  may include a variety of computer-readable media. Computer-readable media can be any available media that can be accessed by the computer system  and includes both volatile and nonvolatile media. For example, computer-readable media may include volatile and nonvolatile computer storage media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can accessed by the computer system . Communication media may include computer-readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. For instance, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer system , such as during start-up, is typically stored in ROM . Additionally, RAM  may contain operating system , application programs , other executable code  and program data . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by CPU .","The computer system  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, and storage device  that may be an optical disk drive or a magnetic disk drive that reads from or writes to a removable, a nonvolatile storage medium  such as an optical disk or magnetic disk. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary computer system  include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  and the storage device  may be typically connected to the system bus  through an interface such as storage interface .","The drives and their associated computer storage media, discussed above and illustrated in , provide storage of computer-readable instructions, executable code, data structures, program modules and other data for the computer system . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other executable code  and program data . A user may enter commands and information into the computer system  through an input device  such as a keyboard and pointing device, commonly referred to as mouse, trackball or touch pad tablet, electronic digitizer, or a microphone. Other input devices may include a joystick, game pad, satellite dish, scanner, and so forth. These and other input devices are often connected to CPU  through an input interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A display  or other type of video device may also be connected to the system bus  via an interface, such as a video interface . In addition, an output device , such as speakers or a printer, may be connected to the system bus  through an output interface  or the like computers.","The computer system  may operate in a networked environment using a network  to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer system . The network  depicted in  may include a local area network (LAN), a wide area network (WAN), or other type of network. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet. In a networked environment, executable code and application programs may be stored in the remote computer. By way of example, and not limitation,  illustrates remote executable code  as residing on remote computer . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used. Those skilled in the art will also appreciate that many of the components of the computer system  may be implemented within a system-on-a-chip architecture including memory, external interfaces and operating system. System-on-a-chip implementations are common for special purpose hand-held devices, such as mobile phones, digital music players, personal digital assistants and the like.","A Task Management Library to Execute Map-Reduce Applications in a Map-Reduce Framework","The present invention is generally directed towards a system and method for a task management library to execute map-reduce applications in a map-reduce framework. A map-reduce framework may support an implementation of a map-reduce application that includes at least one task that may be separated into a map phase and a reduce phase. As used herein, a map-reduce application means an application that includes at least one mapper or at least one reducer configured for execution in a map-reduce system framework. A map-reduce application may be configured with a task manager library and a map-reduce library on a client device. The task manager library may include a wrapper application programming interface that provides application programming interfaces invoked by a wrapper to parse data input values of the map-reduce application. The task manager library may also include a configurator that extracts data and parameters of the map-reduce application from a configuration file to configure the map-reduce application for execution, a scheduler that determines an execution plan based on input and output data dependencies of mappers and reducers, a launcher that iteratively launches the mappers and reducers according to the execution plan, and a task executor that requests the map-reduce library to invoke execution of mappers and reducers.","As will be seen, a configuration file on a client device specifying a map-reduce application for execution may be parsed to extract information, including the names of wrappers, mappers and reducers, to determine task dependencies. Tasks may be executed sequentially where there are task dependencies and concurrently where there are no task dependencies. As will be understood, the various block diagrams, flow charts and scenarios described herein are only examples, and there are many other scenarios to which the present invention will apply.","Turning to  of the drawings, there is shown a block diagram generally representing an exemplary architecture of system components for a task management library to execute map-reduce applications in a map-reduce framework. Those skilled in the art will appreciate that the functionality implemented within the blocks illustrated in the diagram may be implemented as separate components or the functionality of several or all of the blocks may be implemented within a single component. For example, the functionality for the program executor  may be included as a component of the task executor . Or the functionality of the program executor  may be implemented as a separate component. Moreover, those skilled in the art will appreciate that the functionality implemented within the blocks illustrated in the diagram may be executed on a single computer or distributed across a plurality of computers for execution.","In various embodiments, a client computer  may be operably coupled to one or more mapper servers  and to one or more reducer servers  by a network . In other embodiments, one or more mappers and\/or one or more reducers may execute on the same server. The client computer  may be a computer such as computer system  of . The network  may be any type of network such as a local area network (LAN), a wide area network (WAN), or other type of network. A map-reduce application  may execute on the client computer  and may be operably coupled to a task manager library  and a map-reduce library . The map-reduce application  may include functionality for invoking the task manager library  that interfaces with a map-reduce library  to manage the execution of executable code for mappers and reducers.","The task manager library  may include executable code of a wrapper  that parses data input values and a wrapper API  that provides application programming interfaces invoked by the wrapper . The task manager library  may also include a configurator  that extracts data and parameters of map-reduce application from a configuration file. The task manager library  may also include a scheduler  that receives a list of tasks and properties of tasks, and returns an execution plan based on input and output data dependencies. The task manager  may further include a launcher  that iteratively launches tasks according to the execution plan based on input and output data dependencies. The task manager library  may also include a program executor  that may execute external programs and a task executor  that may execute executable code of a mapper or a reducer.","Each of these components may be any type of executable software code that may execute on a computer such as computer system  of , including a kernel component, an application program, a linked library, an object with methods, or other type of executable software code. Each of these components may alternatively be a processing device such as an integrated circuit or logic circuitry that executes instructions represented as microcode, firmware, program code or other executable instructions that may be stored on a computer-readable storage medium. Those skilled in the art will appreciate that these components may also be implemented within a system-on-a-chip architecture including memory, external interfaces and an operating system.","The map-reduce library  may be a map-reduce library such as Apache Hadoop Core provided by the Apache Software Foundation for running map-reduce applications on mapper servers and reducer servers. In general, a map-reduce application may have a map stage, where part of the input data distributed across mapper servers may be loaded and processed by executable code of a mapper to produce partial results, and a reduce stage, where one or more reducer servers receive and integrate the partial results of data distributed and processed by executable code of mappers to produce final results of data processing by the map-reduce application.","In various embodiments, one or more mapper servers  may be operably coupled to one or more reducer servers  by network . The mapper server  and the reducer server  may each be a computer such as computer system  of . The mapper server  may include a mapper  that has functionality for processing a part of the input data distributed across mapper servers  and sending partial results from processing to a reducer server  for integration to produce final results for output. The reducer server  may include a reducer  that has functionality for receiving partial results of processing parts of the input data from one or more mappers , and outputting final results of data processing by the map-reduce application. Each mapper and each reducer may be any type of executable software code, including a kernel component, an application program, a linked library, an object with methods, or other type of executable software code. Each of these components may alternatively be a processing device such as an integrated circuit or logic circuitry that executes instructions represented as microcode, firmware, program code or other executable instructions that may be stored on a computer-readable storage medium. Those skilled in the art will appreciate that these components may also be implemented within a system-on-a-chip architecture including memory, external interfaces and an operating system.","Users rarely run a single task in a map-reduce application for a data processing project and need to chain data processes, transforming the data, retrieving results and reusing obtained results. Multiple tasks can be specified in a configuration file, and the task management library will execute them all, one after the other, allowing for the usage of the results of one task as input for the next one. Additionally, a task can be specified to be executed concurrently with other tasks in the configuration file, where the data the task uses does not depend on any task which has not yet finished execution. In order for the task manager library to manage chaining and parallelizing execution of tasks of a map-reduce application in a map-reduce framework, tasks and parameters of the map-reduce application need to be specified in the configuration file. For instance, mapper, reducer and wrapper executable code referenced by their qualified name may be specified in the configuration file. A set of pathnames of input files or folder can be specified for input data of a single task. And a pathname of an output file or folder can be specified for output of a single task. Once these parameters are defined, a developer can execute the map-reduce application without further need to implement a launcher that may read arguments and initialize the task objects.",{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 3","b":["302","304"]},"At step , the names of executable code of wrappers to parse input data may be inserted in a configuration file specifying a map-reduce application. For example, wrapper=\u201ccom.yahoo.cs.DocumentsWrapper\u201d may represent the qualified name of executable code of a mapper that may be inserted into the configuration file specifying a particular task. Small differences in the data format often imply replication of mappers and reducers with modifications such as changing a constant value, for example, or duplicating functions. A wrapper may create a <key; value> pair for a given input value. Thus, an existing mapper and reducer may be reused to solve a common task without changing the mapper and reducer to different types of input data. Instead, a different Wrapper may be implemented for different kinds of input data. Wrappers may be implemented in an embodiment through an extendable IWrapper interface, with the signatures:",{"@attributes":{"id":"p-0035","num":"0034"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public Writable wrap ( Writable obj );"]},{"entry":[{},"public Writable key ( Writable obj );"]},{"entry":[{},"public void setConfiguration"]},{"entry":[{},"( Hashtable<String, String> confTable );"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},{"@attributes":{"id":"p-0036","num":"0035"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public void map( ... )"]},{"entry":[{},"{"]},{"entry":[{},"Writable wrappedfivalue = wrapper.wrap( value );"]},{"entry":[{},"Writable wrappedfikey = wrapper.key( value );"]},{"entry":[{},"(...)"]},{"entry":[{},"output.collect("]},{"entry":[{},"( Text ) wrappedfikey,"]},{"entry":[{},"( Text ) wrappedfivalue"]},{"entry":[{},");"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"At step , the pathname of a data input file may be inserted in a configuration file specifying a map-reduce application. For example, input path=\u201cdocuments.dat\u201d may represent the pathname of an input file that may be inserted into the configuration file specifying a particular task. Multiple input files may be inserted in the configuration file specifying a particular task. At step , the pathname of a data output file may be inserted in a configuration file specifying a map-reduce application. Output delete=\u201c1\u201d path=\u201coutputIDF\u201d, for example, may represent the pathname of an output file that may be inserted into the configuration file specifying a particular task.","Furthermore, the pathnames of files for file caching may be inserted in a configuration file specifying a map-reduce application at step . File caching allows for the usage of external files by mapper and reducer classes, and the pathnames of files for caching may be inserted into the configuration file specifying a particular task. For example, cache path=\u201c\/user\/lluis\/otherresults.dat\u201d may represent the specification of a pathname of a file for caching that may be inserted into the configuration file specifying a particular task. Multiple specification of files for caching may be inserted in the configuration file specifying a particular task.","At step , declarations of task dependency for the names of executable code of mappers and reducers may be inserted in a configuration file specifying a map-reduce application. Task dependencies may be specified by the \u201cdependsOn\u201d declaration in a configuration file. For example, task id=\u201cMatchTFs\u201d dependsOn=\u201cTFDocuments,TFQueries\u201d may represent the specification of task dependencies of a task that may be inserted into the configuration file specifying a particular task. The task management library may use the declarations of task dependency to plan the order of execution of mappers and reducers, waiting for results and launching new tasks. In an embodiment, the task management library may execute tasks without dependencies concurrently, wait for their completion of execution, and start the dependent tasks afterwards. Note that the \u201cdependsOn\u201d declaration may also be used to specify a task without a dependency in a configuration file which may be indicated, for example, by setting the dependency of a task to the null string, such as the declaration, task id=\u201cIDF\u201d dependsOn=\u201c \u201d. In various embodiments where the task management library automatically determines dependency of tasks without the \u201cdependsOn\u201d declaration, the \u201cdependsOn\u201d declaration may be used to enforce consecutive execution of tasks. Those skilled in the art will appreciate that other parameters can be specified in a configuration file such as a task ID for tracking the execution progress of a task. In addition, a task ID may also be used for dependency references or other options.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 4","b":["402","404","406"]},"At step , the pathname of a data input file may be extracted from a configuration file specifying a map-reduce application. For example, input path=\u201cdocuments.dat\u201d may represent the pathname of an input file that may be extracted from the configuration file specifying a particular task. At step , the pathname of a data output file may be extracted from a configuration file specifying a map-reduce application. Output delete=\u201c1\u201d path=\u201coutputIDF\u201d, for example, may represent the pathname of an output file that may be extracted from the configuration file specifying a particular task.","At step , the pathnames of files for file caching may be extracted from a configuration file specifying a map-reduce application. Cache path=\u201c\/user\/lluis\/otherresults.dat\u201d, for example, may represent the specification of a pathname of a file for caching that may be extracted from the configuration file specifying a particular task. And declarations of task dependency for the names of executable code of mappers and reducers may be extracted at step  from a configuration file specifying a map-reduce application. For example, task id=\u201cMatchTFs\u201d dependsOn=\u201cTFDocuments,TFQueries\u201d may represent the specification of task dependencies of a task that may be extracted from the configuration file specifying a particular task. Those skilled in the art will appreciate that other parameters can be extracted from the configuration file such as a task ID for tracking the execution progress of a task.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":["FIG. 5","FIG. 5"],"b":["502","504","508","510","508"]},{"@attributes":{"id":"p-0044","num":"0043"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<task id=\u201cIDF\u201d dependsOn=\u201c\u201d"]},{"entry":[{},"mapper=\u201ccom.yahoo.cs.IDFMapper\u201d"]},{"entry":[{},"reducer=\u201ccom.yahoo.cs.IDFReducer\u201d"]},{"entry":[{},"wrapper=\u201ccom.yahoo.cs.DocumentsWrapper\u201d>"]},{"entry":[{},"<input path=\u201cdocuments.dat\u201d \/>"]},{"entry":[{},"<input path=\u201cdocuments\/*\u201d \/>"]},{"entry":[{},"<output delete=\u201c1\u201d path=\u201coutputIDF\u201d \/>"]},{"entry":[{},"<arg name=\u201cNUMfiDOCUMENTS\u201d value=\u201c2766679\u201d \/>"]},{"entry":[{},"<reducers min=\u201c50\u201d \/>"]},{"entry":[{},"<\/task>."]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{},"b":"510"},{"@attributes":{"id":"p-0045","num":"0044"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<task id=\u201cTFDocuments\u201d dependsOn=\u201c\u201d"]},{"entry":[{},"mapper=\u201ccom.yahoo.cs.TFMapper\u201d"]},{"entry":[{},"reducer=\u201ccom.yahoo.cs.TFReducer\u201d"]},{"entry":[{},"wrapper=\u201ccom.yahoo.cs.DocumentsWrapper\u201d>"]},{"entry":[{},"<input path=\u201cdocuments.dat\u201d \/>"]},{"entry":[{},"<input path=\u201cdocuments\/*\u201d \/>"]},{"entry":[{},"<output delete=\u201c1\u201d path=\u201coutputTF\u201d \/>"]},{"entry":[{},"<\/task>."]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"The queries  may be input data to a process to calculate the query term frequency . The task to calculate the query term frequency  may be specified in a configuration file as follows:",{"@attributes":{"id":"p-0047","num":"0046"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<task id=\u201cTFQueries\u201d"]},{"entry":[{},"mapper=\u201ccom.yahoo.cs.TFMapper\u201d"]},{"entry":[{},"reducer=\u201ccom.yahoo.cs.TFReducer\u201d"]},{"entry":[{},"wrapper=\u201ccom.yahoo.cs.QueriesWrapper\u201d>"]},{"entry":[{},"<input path=\u201cqueries.dat\u201d \/>"]},{"entry":[{},"<input path=\u201cqueries\/*\u201d \/>"]},{"entry":[{},"<output delete=\u201c1\u201d path=\u201coutputTFQueries\u201d \/>"]},{"entry":[{},"<\/task>"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"The results of calculating the document term frequency  and the query term frequency  are input to a process to match term frequencies  from document term frequency  and query term frequency . The task to match term frequencies  may be specified in a configuration file as follows:",{"@attributes":{"id":"p-0049","num":"0048"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<task id=\u201cMatchTFs\u201d dependsOn=\u201cTFDocuments,TFQueries\u201d"]},{"entry":[{},"mapper=\u201ccom.yahoo.cs.MatchTFMapper\u201d"]},{"entry":[{},"reducer=\u201ccom.yahoo.cs.MatchTFReducer\u201d"]},{"entry":[{},"wrapper=\u201ccom.yahoo.cs.QueryDocumentsWrapper\u201d>"]},{"entry":[{},"<input path=\u201coutputTF\/*\u201d \/>"]},{"entry":[{},"<input path=\u201coutputTFQueries\/*\u201d \/>"]},{"entry":[{},"<output delete=\u201c1\u201d path=\u201coutputMatchTF\u201d \/>"]},{"entry":[{},"<\/task>"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"The output of the inverse document frequency  and the output of matched term frequencies  are input to calculating the cosine similarity distance  between the inverse document frequency and the matched term frequencies. The task to calculate the cosine similarity distance  between the inverse document frequency and the matched term frequencies may be specified in a configuration file as follows:",{"@attributes":{"id":"p-0051","num":"0050"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<task id=\u201cCosineSimilarity\u201d dependsOn=\u201cMatchTFs, IDF\u201d"]},{"entry":[{},"mapper=\u201ccom.yahoo.cs.csMapper\u201d"]},{"entry":[{},"reducer=\u201ccom.yahoo.cs.csReducer\u201d"]},{"entry":[{},"wrapper=\u201ccom.yahoo.cs.csWrapper\u201d>"]},{"entry":[{},"<input path=\u201coutputMatchTF\/*\u201d \/>"]},{"entry":[{},"<input path=\u201coutputIDF\/*\u201d \/>"]},{"entry":[{},"<output delete=\u201c1\u201d path=\u201coutputcs\u201d \/>"]},{"entry":[{},"<\/task>"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{},"figref":"FIG. 5"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIG. 6","FIG. 4"],"b":["602","604"]},"At step , task dependency may be determined for each mapper and reducer blocked for execution until other mappers and reducers complete execution. In an embodiment, a scheduler in the task management library may determine task dependency and generate an execution plan that specifies the order of execution of tasks including mappers and reducers. In an embodiment, any order of execution may be specified for mappers and reducers without a dependency blocking execution. At step , mappers on mapper servers and reducers on reducer servers without a dependency blocking execution may be executed. In an embodiment, unblocked mappers and reducers may be executed in any order. At step , mappers on mapper servers and reducers on reducer servers unblocked by the completion of execution of other mappers and reducers may be executed. In an embodiment, unblocked mappers and reducers may be executed in any order.","At step , results integrated by reducers on reducer servers from partial results of execution of mappers on mapper servers may be received on a client device. In an embodiment, one or more reducers may integrate the partial results of execution of mappers. And results received on a client device from execution of a map-reduce application may be output at step .","Other parameters of a map-reduce application may also be specified in a configuration file and extracted from the configuration file that support a developer programming data processing applications in a map-reduce programming model. For instance, task parameters such as job format may be specified in a configuration file as follows:",{"@attributes":{"id":"p-0056","num":"0055"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<jobformat"]},{"entry":[{},"input=\u201corg.apache.hadoop.mapred.TextOutputFormat\u201d"]},{"entry":[{},"output=\u201ccom.yahoo.hadooputils.CSOutputFormat\u201d \/>"]},{"entry":[{},"<joboutput"]},{"entry":[{},"key=\u201corg.apache.hadoop.io.Text\u201d"]},{"entry":[{},"value=\u201ccom.yahoo.hadooputils.CSElement\u201d \/>"]},{"entry":[{},"<!-- Compress the output -->"]},{"entry":[{},"<jobparam"]},{"entry":[{},"name=\u201cmapred.output.compress\u201d"]},{"entry":[{},"value=\u201ctrue\u201d \/>"]},{"entry":[{},"<jobparam"]},{"entry":[{},"name=\u201cmapred.output.compression.codec\u201d"]},{"entry":[{},"value=\u201corg.apache.hadoop.io.compress.GzipCodec\u201d \/>."]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"As another example, the task management library may also support passing of defined parameters such as a range of values to a task for repeated execution of the same task or sequence of tasks with different data sets. For instance, loop iteration variables may be defined to control executing a task with different arguments without needing to recompile the map-reduce application or tasks. A task may be specified in a configuration file to pass parameters for repeated execution of the task as follows:",{"@attributes":{"id":"p-0058","num":"0057"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"< var name=\u201dN\u201d value=\u201d10\u201d \/>"]},{"entry":[{},"<loop"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"id=\u201dloopid\u201d"]},{"entry":[{},"loopvar=\u201dcounter\u201d"]},{"entry":[{},"from=\u201d0\u201d to=\u201d$N\u201d inc=\u201d+1\u201d"]},{"entry":[{},"mapper=\u2033com.yahoo.cs.LoopMapper\u2033"]},{"entry":[{},"reducer=\u2033com.yahoo.cs.LoopReducer\u2033"]},{"entry":[{},"wrapper=\u2033com.yahoo.cs.CounterWrapper\u2033>"]},{"entry":[{},"parallel=\u201d1\u201d dependsOn=\u201dloop0\u201d>"]},{"entry":[{},"<input path=\u201dloop\/$counter\u201d \/>"]},{"entry":[{},"<output delete=\u201d1\u201d path=\u201doutput\/$counter\u201d \/>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<arg name=\u201diteration\u201d value=\u201d$counter\u201d \/>"]},{"entry":[{},"<\/loop>."]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"Thus, the task management library of the present invention may provide easy configuration of parameters, specification of map-reduce task settings, automated determination of the number of reducers as needed, and task execution control for easily chaining and parallelizing tasks of a map-reduce application. The flexible environment provided by the task management library allows a developer to focus on programming data analysis applications in the programming model of a map-reduce framework and to quickly experiment with different configurations for map-reduce applications.","As can be seen from the foregoing detailed description, the present invention provides an improved system and method for a task management library to execute map-reduce applications. A map-reduce application may be configured with a task manager library and a map-reduce library on a client device. The task manager library may include a wrapper application programming interface that provides application programming interfaces invoked by a wrapper to parse data input values of the map-reduce application. The task manager library may also include a configurator that extracts data and parameters of the map-reduce application from a configuration file to configure the map-reduce application for execution, a scheduler that determines an execution plan based on input and output data dependencies of mappers and reducers, a launcher that iteratively launches the mappers and reducers according to the execution plan, and a task executor that requests the map-reduce library to invoke execution of mappers on mapper servers and reducers on reducer servers. Such a system and method may provide a layer on top of a map-reduce library that abstracts technical details of a map-reduce library for a developer while harnessing the computation facilities offered by the programming model in a map-reduce framework. As a result, the system and method provide significant advantages and benefits needed in contemporary computing and in large scale applications.","While the invention is susceptible to various modifications and alternative constructions, certain illustrated embodiments thereof are shown in the drawings and have been described above in detail. It should be understood, however, that there is no intention to limit the invention to the specific forms disclosed, but on the contrary, the intention is to cover all modifications, alternative constructions, and equivalents falling within the spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
