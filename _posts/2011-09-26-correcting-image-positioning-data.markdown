---
title: Correcting image positioning data
abstract: An image positioning system provides an interactive visualization that includes a representation of a geographic area and several camera pose indicators, each of which indicates a location within the geographic area at which a corresponding image was obtained. An operator may select one a pose indicators and adjust the position of the pose indicator relative to the representation of the geographic area. In response, the image positioning system may automatically generate a corrected location at which the image corresponding to the selected pose indicator was obtained. The corrected location then may be stored in a database and used for various applications that utilize image positioning data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09218789&OS=09218789&RS=09218789
owner: Google Inc.
number: 09218789
owner_city: Mountain View
owner_country: US
publication_date: 20110926
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATION","FIELD OF THE DISCLOSURE","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application is a continuation of and claims priority to U.S. patent application Ser. No. 13\/098,761, filed on May 2, 2011, and entitled \u201cCorrecting Image Positioning Data,\u201d the entire disclosure of which is hereby expressly incorporated by reference herein.","This disclosure relates to determining and adjusting positioning data with which an image, such as a photograph of a street, is associated.","The background description provided herein is for the purpose of generally presenting the context of the disclosure. Work of the presently named inventors, to the extent it is described in this background section, as well as aspects of the description that may not otherwise qualify as prior art at the time of filing, are neither expressly nor impliedly admitted as prior art against the present disclosure.","Many images, such as photographs and video recordings, are stored with metadata that indicates the geographic location at which the image was created. For example, a camera equipped with a Global Positioning Service (GPS) receiver determines the position of the camera in the GPS coordinate system at the time a photograph is taken and stores the determined GPS coordinates with the photograph. These coordinates later can be used to determine what is depicted in the photograph (e.g., which building in what city), for example.","However, in some situations, metadata stored with an image fails to indicate the geographic location with the desired precision. For example, GPS generally has a margin of error of approximately 25 meters. In so-called \u201curban canyons,\u201d or city locations at which tall buildings obscure or reflect GPS signals, the problem of imprecise coordinates is particularly prevalent.","In an embodiment, image pose data that indicates respective geographic locations at which a plurality of images were obtained is stored on a computer-readable medium. A method for correcting the image pose data includes causing a representation of a geographic area to be displayed on a display device, determining a respective position of each of a plurality of pose indicators relative to the representation of the geographic area based on the respective geographic locations in the image pose data, causing the plurality of pose indicators to be displayed over the representation of the geographic area on the display in accordance with the determined respective positions, receiving an indication of a modified position of a selected one of the plurality of pose indicators relative to the representation of the geographic area on the display device, determining a corrected geographic location at which the one of the plurality of images was obtained based on the received indication of the modified position, and modifying the pose data in accordance with the corrected geographic location. According to the embodiment, each of the plurality pose indicators corresponds to a respective one of the plurality of images.","In another embodiment, an image positioning system includes a database to store a plurality pose records, where each of the plurality of pose records includes an image and pose data to indicate a geographic location at which the image was obtained. The image positioning system also includes a pose rendering engine communicatively coupled to the database and configured to generate a representation of a geographic area to be displayed at a client device, determine a respective position of each of a plurality of pose indicators relative to the representation of the geographic area based on the respective geographic locations in the respective pose records, and generate a representation of the plurality of pose indicators to be displayed over the representation of the geographic area at the client device in accordance with the determined respective positions. Each of the plurality pose indicators corresponds to a respective one of the plurality of images. The image positioning system further includes a pose calculation engine configured to, in response to receiving an indication that an operator modified a position of a selected one of the plurality of pose indicators relative to the representation of the geographic area at the client device, determine a corrected geographic location at which the image corresponding to the selected one of the plurality of poses was obtained based on the modified position of the selected one of the plurality of pose indicators, and modify the corresponding one of the plurality of pose records in accordance with the corrected geographic location.","In another embodiment, instructions executable by one or more processors are stored on a tangible non-transitory computer-readable medium. When executed by the one or more processors, the instructions cause the one or more processors to cause a representation of a geographic area to be displayed on a display device, determine a respective position of each of a plurality of pose indicators relative to the representation of the geographic area based on the respective geographic locations in the image pose data, cause the plurality of pose indicators to be displayed over the representation of the geographic area on the display in accordance with the determined respective positions, receive an indication of a modified position of a selected one of the plurality of pose indicators relative to the representation of the geographic area on the display device, determine a corrected geographic location at which the one of the plurality of images was obtained based on the received indication of the modified position, and modify the pose data in accordance with the corrected geographic location. Each of the plurality pose indicators corresponds to a respective one of the plurality of images, according to the embodiment.",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1","b":"10"},"Generally speaking, the interactive visualization includes one or more pose indicators, such as pictograms, representing poses in the corresponding locations in the geographic area. The interactive visualization is displayed via a user interface that includes a display device and an input device, for example. The operator uses the pose indicators to select one or more poses that appear to be in wrong locations and, when appropriate, moves the selected poses to the locations in the geographic area where the operator believes the corresponding images likely were obtained. For example, the operator may see that a pose indicator representing a pose that is associated with a certain position of a vehicle is rendered over an image of a building, and conclude that the pose is likely incorrect. The operator may then adjust the position of the pose indicator in the interactive visualization so as to place the corresponding pose into a nearby location in a street. In some cases, the operator may also inspect one or more images associated with a certain pose to more accurately determine whether and how the pose should be adjusted. In response to the user adjusting the location of a pose indicator in the interactive visualization, or accepting as valid the currently displayed location of the pose indicator, the corresponding pose is updated. For example, if the pose includes GPS coordinates, new GPS coordinates may be automatically calculated and stored in accordance with the updated location to which the operator has moved the pose indicator.","According to an example scenario, a camera mounted on a vehicle traveling along a certain path periodically photographs the surrounding area and obtains pose data, such as GPS coordinates, for each photograph. A series of camera poses collected along the path corresponds to the trajectory of the vehicle, and is referred to herein as a \u201cpose run.\u201d The photographs and the corresponding poses are then uploaded to an image and pose database . The images and poses stored in the pose database  may be used to provide on demand street-level views of geographic regions, for example, or in other applications. However, because GPS coordinates are not always accurate, one or more operators may use the image positioning system  to verify and, when needed, adjust poses of some of the images stored in the database .","To select and adjust one or more poses in a pose run, the operator may use a computing device  that implements a pose correction user interface (UI) component . In general, the pose correction UI component  displays a visualization of a geographic area and a representation of a pose run superimposed on the visualization of the geographic area on a display device. To represent a pose run, the pose correction UI component  may display pose indicators (e.g., graphic symbols such as circles, alphanumeric symbols, images, etc.) at the locations on the map corresponding to the poses and, in an embodiment, also display lines or arrows interconnecting consecutive pose indicators to illustrate the path the camera has travelled. The pose correction UI component  allows the operator to select and reposition the pose by dragging the corresponding pose indicator over to the desired location on the map, for example. In response to the user repositioning one or several pose indicators, the pose correction UI component , or another software component executing in the computing device , forwards the updated pose information to a pose rendering engine  for further processing.","In an embodiment, the pose rendering engine  operates in a front-end server  to which the pose rendering engine  is communicatively coupled via a network . The front-end server  in turn may be communicatively coupled to the image and pose database , one or several back-end servers  in which corresponding instances of a pose correction engine  operate, and a geographic image database  via a communication link . In this embodiment, the computing device  operates as a client device that receives geographic area data, pose data, etc. from the front-end server  and the back-end server . During operation, the pose rendering engine  may report pose corrections received from the pose correction UI component  to the pose correction engine , receive updated pose run data from the pose correction engine , and provide an updated visualization of the geographic area and the pose run to the pose correction UI component . The pose correction engine  may process the pose corrections received from the pose rendering engine  and, when appropriate, update the image and pose database . For example, the pose correction engine  may determine whether a pose correction submitted by an operator is within an allowable range and whether the pose correction conflicts with another pose correction, submitted by another operator at the same time or previously. Further, in some embodiments, the pose correction engine  automatically adjusts one or more poses in a pose run (e.g., poses , , , and ) based on the received corrections to one or more other poses in the same pose run (e.g., poses  and ). Still further, the pose correction engine  may analyze pose data adjusted or accepted by an operator to detect pose trends, such as a consistent \u201cdrift\u201d in the originally stored GPS coordinates, for example. In an embodiment, the pose correction engine  utilizes the detected trends in automatic correction of pose data.","In an embodiment, the pose correction UI component  prompts the operator for authentication information (e.g., login and password) prior to granting the operator access to pose data stored in the image and pose database .","In general, the functionality of the pose correction UI component , the pose rendering engine , and the pose correction engine  can be distributed among various devices operating in the image positioning system  in any suitable manner. For example, if desired, both the pose rendering engine  and the pose correction engine  can be implemented in a single device such as the front-end server . As another example, the pose correction UI component , the pose rendering engine , and the pose correction engine  can be implemented in a single computing device such as a PC. As yet another example, the rendering of a geographic area and a pose run mapped onto the geographic area can be implemented in the computing device . In one such embodiment, a browser plug-in is installed in the computing device  to support the necessary rendering functionality. In another embodiment, the pose correction UI component  is provided in a separate application executing on the computing device .","Depending on the implementation, the network  may be the Internet, an intranet, or any other suitable type of a network. The communication link  may be an Ethernet link or another type of a wired or wireless communication link. Further, as discussed in more detail below, the computing device  may be a desktop personal computer (PC), a laptop PC, a tablet PC, a mobile device such as a smartphone, etc.","Next, an example data structure that may be used to store and process image and pose data for use in the image positioning system  is described with reference to , followed by a discussion of the user interface supported by the image positioning system , as well as various features of the image positioning system  accessible via the pose correction UI , with reference to . In particular,  illustrate several example interactive screens that may be displayed on a display device and using which an operator may verify and adjust image pose data.","First referring to , a data structure  may include several pose records , (i.e., pose records -, -, . . . -K). The image and pose database  illustrated in , for example, may store the pose records  on a computer-readable medium. The pose records  may correspond to one or more pose runs , , . . . N, which may include the same number of pose records or different numbers of pose records, depending on the implementation. Each pose record  may include one or more images  and pose data such as location\/positioning data  and a timestamp . For example, the pose records - includes images --, --, and --, which may be photographs taken at the same time from the same point in space using cameras pointing in different directions. The pose records - and -, generated during or following the same pose run, include similar sets of images. On the other hand, the pose record -K includes a single image -K, which may be a panoramic photograph, for example.","In an embodiment, the location data  includes GPS coordinates. In another embodiment, the location data  includes local positioning service (LPS) data such as an identifier of a proximate WiFi hotspot, for example. In general, the location data  can include any suitable indication of a location with which the one or several images  are associated.","The timestamp  stores time data in any suitable manner. For example, the timestamp  may indicate the year, the month, and the day the corresponding images were obtained. In some implementations, the timestamp  may additionally indicate the hour and the minute, for example. The timestamp  in other implementations may indicate a time relative to a certain event, e.g., the time the first photograph in the corresponding pose run is taken, or the timestamp  may be implemented as any other suitable type of a time metric.","Further, in some embodiments, images and poses may be sequentially labeled to simplify a reconstruction of the order in which the images were collected during a pose run. For example, a certain pose record  may include a sequence number (not shown) to indicate the order of each pose record  within a certain run i relative to other pose records  within the same run i. Still further, the pose records  may include pose run identifiers (not shown) to differentiate between the pose runs , , . . . N. Accordingly, in this embodiment, images collected during the same pose run may be assigned the same pose run identifier.","Still further, in an embodiment, the data structure  includes flags (not shown) indicating whether pose data has been verified and\/or adjusted by one or more operators. For example, a binary flag may be set to a first value (e.g., logical \u201ctrue\u201d) if the corresponding pose data has been verified, and to a second value (e.g., logical \u201cfalse\u201d) if the corresponding pose data has not yet been verified. Depending on the implementation, each of the pose records  may include a record-specific flag, or flags may be set on a per-pose-run basis. In another embodiment, flags are implemented in a configuration database that is physically and\/or logically separate from the image and pose database .","Now referring to , the pose correction UI component  may generate an interactive screen  to allow an operator to adjust image positioning data. Depending on the implementation, the interactive screen  may be displayed in a browser application, in a standalone application, or another type of an application. Further, depending on the configuration or the computing environment in which the software displaying the interactive screen  executes, the operator may interact with the interactive screen  using a mouse, a touchpad, a keyboard, a touch screen, a voice input device, or another suitable type of an input device.","In the example illustrated in , the interactive screen  includes a satellite image  of several city blocks, displayed in the background, and a series of pose indicators  (i.e., -, -, . . . -L) displayed in the foreground. In this example, the number of pose indicators L is eleven. In general, however, any number of pose indicators  can be simultaneously displayed in the interactive screen  or a similar interactive screen. The pose indicators -, -, . . . -L are displayed according to the corresponding pose data, e.g., the GPS coordinates stored in the pose data. For example, referring back to , each of the pose indicators -, -, . . . -L may be superimposed on the satellite image  according to the information in the location data field  in the corresponding pose data record . Arrows  interconnect the pose indicator -, -, . . . -L to indicate the order in which the corresponding images were collected. The interactive screen  may also include a zoom scrollbar  and a navigation control  to allow the operator to zoom in and out of certain portions of the displayed satellite image  and adjust the center of the satellite image , respectively. Depending on the implementation, the interactive screen  also may include other controls, such as a compass control to select the orientation of the satellite image , for example.","In another embodiment, arrows similar to the arrows  are used to indicate the orientation of the vehicle at the time when the corresponding image was collected. In yet another embodiment, arrows that indicate the order of the images as well as arrows that indicate the orientation of the vehicle can be displayed in an interactive screen using different styles or colors, for example.","During operation, the operator may select a certain pose run R via an interactive screen (not shown) provided by the pose correction UI component , for example. The selection of the pose run R may be based on the date and time when the pose run R took place, the identity of a vehicle used to conduct the pose run R, the identity of the driver of the vehicle, a description of the geographic region in which the pose run R took place, etc. In response to the operator selecting the pose run R, the pose rendering engine  (see ) or another component may retrieve the pose records  that describe poses in the selected pose run R from the image and pose database , use the location data  in the retrieved pose records  to determine a geographic area with which the pose records  are generally associated, retrieve the satellite image  or another representation of the geographic area, determine where each pose indicator -, -, . . . -L should be displayed relative to the background satellite image , and display each pose indicator -, -, . . . -L in the corresponding location. Depending on the embodiment, pose pictographs -, -, . . . -L are displayed for every pose in the pose run R or only for a subset of the poses in the pose run R. For example, to reduce clutter on the interactive screen , a respective pose pictograph may be displayed only for every n-th (e.g., fifth, tenth) pose in the pose run R. In general, a pose indicator may be an alphanumeric symbol, a non-textual symbol such as a circle or a triangle, a representative icon, a miniaturization of the photograph corresponding to the pose, or any other type of an indicator. In the example of , each pose indicator -, -, . . . -L is a circle.","If pose data includes GPS coordinates, the pose rendering engine  may utilize both the surface positioning data, e.g., the latitude and the longitude, and the altitude data. The pose correction UI component  accordingly may allow the operator to adjust the position of a pose indicator in three dimensions. Alternatively, the pose rendering engine  may utilize only the surface positioning data.","In some embodiments, the pose rendering engine  automatically determines the size and\/or the zoom level of the satellite image  based on the retrieved pose records . To this end, in one embodiment, the pose rendering engine  identifies which of the poses in the pose run R are at the boundaries of an area that encompasses the entire pose run R. For example, if the satellite image  of  is displayed with the common north-at-the-top orientation, the pose corresponding to the pose indicator - is at the western boundary of the pose run R, the pose corresponding to the pose indicator - defines the southern and the eastern boundaries of the pose run, and the pose corresponding to the pose indicator - corresponds to the northern boundary of the pose run. Upon identifying the area that encompasses the entire pose run, the pose rendering engine  may select a geographic area that includes at least the identified area (e.g., the identified area and a certain offset in each of the four cardinal directions). In another embodiment, the pose rendering engine  determines which of the poses in the pose run R is in the most central position relative to the rest of the pose run R, and centers the satellite image  around the most central pose. In yet another embodiment, the pose rendering engine  determines the centroid of the poses in the pose run R and centers the satellite image  around the determined centroid. Further, in yet another embodiment, the pose correction UI component  and\/or the pose rendering engine  allows the user to select the satellite image  prior to selecting the pose run R.","Using a mouse, for example, the operator may point to the pose indicator -, left-click on the pose indicator -, drag the pose indicator - to a new location, and release the left mouse button. Because the pose indicator - appears to be on a sidewalk, the operator may move the pose indicator - to a new location in the street, as schematically illustrated in  using dashed lines. Thus, in this scenario, the operator primarily relies on visual cues to determine where the pose indicator - should be moved. Moreover, in a scenario that involves collecting images and pose information using a car, the operator typically can assume that a pose indicator displayed in a pedestrian area is incorrect and accordingly requires adjustment.","The pose correction UI component  may automatically adjust the length and\/or the orientation of the arrows  that interconnect the pose indicator - with the neighbor pose indicators - and -. Further, the pose correction UI component  may forward the position of the pose indicator - in the interactive screen  to the rendering engine . In response, the rendering engine  and\/or the pose correction engine  may calculate the new geographic location data, such as a new set of GPS coordinates, of the pose represented by the pose indicator -. However, in some embodiments, the pose correction UI component  forwards the new positions of pose indicators to the rendering engine  only after a certain number of pose indicators (e.g., three, four, five) have been moved. In another embodiment, the pose correction UI component  forwards adjusted or accepted pose data to the rendering engine  after the operator activates a certain control provided on the interactive screen , such as an \u201caccept\u201d or \u201csubmit\u201d button (not shown), for example. Further, in some embodiments, the automatic adjustment of the arrows  may be implemented in the pose rendering engine  or the pose correction engine  rather than, or in addition to, in the pose correction UI component .","In a certain embodiment, the pose correction UI component  imposes a limit on how far the operator may move a selected pose indicator or otherwise restricts the ability of the operator to correct pose data. For example, if the operator attempts to move the pose indicator - beyond a certain distance from the original position of the pose indicator -, the pose correction UI component  may display a pop-up window (not shown) or another type of a notification advising the operator that the operation is not permitted. Depending on the implementation, the operator may or may not be allowed to override the notification. As another example, the operator may attempt to adjust the position of a pose indicator in the interactive screen  so as to modify the order in which the poses appear in the corresponding pose run. Thus, if a modified position of a pose indicator indicates that the corresponding pose now results in different order in the succession of poses, and thus suggests that the vehicle at some point moved in the opposite direction during the pose run, the pose correction UI component  may prevent the modification or at least flag the modification as being potentially erroneous.","Further, in some embodiments, the pose correction UI component  permits operators to mark certain poses for deletion. An operator may decide that certain pose runs should be partially or fully deleted if, for example, images associated with the poses are of a poor quality, or if the operator cannot determine how pose data should be adjusted. Conversely, an operator may decide that none of the poses in a pose run require correction and accept the currently displayed pose run without any modifications.","In some situations, an operator may wish to view the image (or, when available, multiple images) corresponding to a certain pose indicator prior to moving the pose indicator. For example, referring to an interactive screen  illustrated in , the operator may decide that a pose indicator - probably should be moved, but the operator may not be certain how far the pose indicator - should be moved. In other situations, an operator may not be certain regarding the direction in which a pose indicator should be moved, or the operator may not be entirely convinced that a certain pose indicator should be moved at all. To provide better guidance to the operator, the pose correction UI component  may display a set of images  in response to the operator right-clicking on the pose indicator -, for example. In other embodiments, the pose correction UI component  may provide other controls (e.g., interactive icons, commands in a toolbar, etc.) to allow the operator to view images associated with pose indicators.","As discussed above with reference to , a pose may be associated with a single image, such as a panoramic photograph, or several images collected at the same location, typically but not necessarily at the same time. The set of images  in the example of  includes images - and -, each of which corresponds to a different orientation of a camera mounted on a vehicle during the pose run represented by the pose indicators -, -, etc. The user may scroll through the set  and view several photographs to better estimate a new location of the pose indicator -. However, in some situations, the set  includes a single photograph.","Now referring to , it may be desirable that the operator review a pose run relatively quickly, particularly if the operator is responsible for a large number of pose runs, each including numerous poses. To expedite pose correction, the pose correction UI component  may allow the operator to adjust only non-consecutive poses, or poses separated by no less than N intermediate poses. For example, in an interactive screen , pose indicators -, -, and - are adjustable, but the pose indicators - through -, as well as the pose indicators - through -, are not adjustable. Poses that are not adjustable and poses that are adjustable may be represented by different symbols, e.g., circles of two different colors. In an embodiment, the pose correction UI component  and\/or the pose rendering engine  determine whether a particular pose is adjustable based on the proximity of the pose to a pose that is adjustable, so that an operator can adjust only every eighth pose, for example. In various implementation, other factors, such as the minimum spatial separation between two consecutive adjustable poses can be used.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 6","FIG. 3"],"b":["400","20","100","400","404","8","404","9","404","10","404","8","404","9","404","10","404","8","400","20"]},"Although the interactive screens , , and  discussed above utilize satellite imagery to represent a geographic area, the pose rendering engine  and\/or the pose correction UI component  in other embodiments or configurations may render the geographic area as a street map, a topographic map, or any other suitable type of a map. For example,  illustrates an interactive screen  that includes a street map , displayed in the background, and a series of pose indicators , displayed in the foreground. In an embodiment, the operator can switch between a satellite view and a street map view, for example, according to the operator's preference. Generally speaking, the image positioning system  may provide interactive screens, similar to the examples illustrated in , that can be configured according to the desired type (e.g., satellite, schematic, topographic), level of detail, color, amount and type of labeling, etc.","In general, the image positioning UI component , the pose rendering engine  and the pose correction engine  may be implemented on dedicated hosts such as personal computers or servers, in a \u201ccloud computing\u201d environment or another distributed computing environment, or in any other suitable manner. The functionality of these and other components of the image positioning system  may be distributed among any suitable number of hosts in any desired manner. To this end, the image positioning UI component , the pose rendering engine , and the pose correction engine  may be implemented using software, firmware, hardware, or any combination thereof. To illustrate how the techniques of the present disclosure can be implemented by way of more specific examples, several devices that can be used in the image positioning system  are discussed next with reference to . Further, another embodiment of an image positioning system, in which multiple operators may verify and adjust image positions via a crowdsourcing server, is discussed with reference to .","Referring to , a computing device  may be used as the computing device  in the image positioning system , for example. Depending on the embodiment, the computing device  may be a workstation, a PC (a desktop computer, a laptop computer, a tablet PC, etc.), a special-purpose device for verifying and adjusting image positioning data in the image positioning system , a smartphone, etc. The computing device  includes at least one processor , one or several input devices , one or several output devices , and a computer-readable memory . In an embodiment, the processor  is a general-purpose processor. In another embodiment, the processor  includes dedicated circuitry or logic that is permanently configured (e.g., as a special-purpose processor, such as a field programmable gate array (FPGA) or an application-specific integrated circuit (ASIC)) to perform certain operations. The computing device  may utilize any suitable operating system (OS) such as Android\u2122, for example. Depending on the embodiment, the input device  may include, for example, a mouse, a touchpad, a keyboard, a touchscreen, or a voice input device, and the output device  may include a computer monitor, a touchscreen, or another type of a display device.","The memory  may be a persistent storage device that stores several computer program modules executable on the processor . In an embodiment, the memory  may store a user interface module , a browser engine , an image position correction module . During operation of the computing device , the user interface module  supports the interaction between various computer program modules executable on the processor  and the input device  as well as the output device . In an embodiment, the user interface module  is provided as a component of the OS of the computing device . Similarly, the browser engine  may be provided as a component of the OS or, in another embodiment, as a portion of a browser application executable on the processor . The browser engine  may support one or several communication schemes, such as TCP\/IP and HTTP(S), required to provide communications between the computing device  and another device, e.g., a network host.","With continued reference to , the image position correction module  implements at least a portion of the functionality of the pose correction UI component . Depending on the embodiment, the image position correction module  may be a plugin compatible with a browser application that utilizes the browser engine , or a standalone application that interacts with the browser engine  to communicate with other devices, for example. In operation, the image position correction module  may utilize the user interface  receive and process operator commands and provide interactive screens similar to those illustrated in  to the operator.",{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 9","b":["650","652","654","650","652","650","652","650","652","650","652","650","652","652","650"]},"The front-end server  may execute a pose processing module  and a map processing module  to retrieve, render, and position foreground pose data and background map data, respectively. Referring back to , the modules  and  may be components of the pose rendering engine . The back-end server  may include a pose correction engine . In an embodiment, the pose correction engine  operates as the pose correction engine .","Now referring to , an example image positioning system  includes several computing devices -, -, and -, each of which implements a pose correction UI component , a front-end server  that implements a pose rendering engine , a back-end server  that implements a pose correction engine , an image and pose database , and a geographic image database . A crowdsourcing server  is coupled to the computing devices -, -, and - and the servers  and  via a network  to allow a greater number of human operators to participate in verification and correction of pose data.","In general, the crowdsourcing server  uses human operators to verify and, when necessary, correct image positioning in the image positioning system . The crowdsourcing server  receives human intelligence tasks (HITs) to be completed by operators using the computing devices -, -, and -. In particular, the HITs specify pose runs stored in the image and pose database  that require verification correction. The crowdsourcing server  may support one or several application programming interface functions (APIs) to allow a requestor, such as an administrator responsible for the image and pose database , to specify how a HIT is to be completed. For example, the HIT may automatically link an operator that uses the computing devices - to a site from which the necessary plugin or application (e.g., the image position correction module  of ) can be downloaded, specify which pose runs are available for verification, and list various other conditions for completing a pose run verification task. In an embodiment, the crowdsourcing server  receives a HIT that specifies multiple pose runs, automatically distributes the pose runs among several computing devices, and manages the status of the tasks assigned to the computing devices. Further, according to an embodiment, the crowdsourcing server  receives pose data corresponding to one or several pose runs for each HIT. For example, the back-end server  may retrieve a set of pose data records from the image and pose database , forward the retrieved set to the crowdsourcing server  and, upon completion of the corresponding task at the crowdsourcing server , receive the updated set of pose data from the crowdsourcing server . The back-end server  may then update the image and pose database .","Further, the crowdsourcing server , alone or in cooperation with the servers  and , may automatically determine whether particular operators are qualified for pose run verification. For example, when a candidate operator requests that a certain pose verification task be assigned to her, a component in the image positioning system  may request that the operator provide her residence information (e.g., city and state in which she lives), compare the geographic area with which the pose run is associated to the candidate operator's residence information, and determine whether the operator is likely to be familiar with the geographic area. Additionally or alternatively, the image positioning system  may check the candidate operator's age, his prior experience completing image positioning tasks, etc. The back-end server  or another component of the image positioning system  may periodically poll the crowdsourcing server  to determine which HITs are completed. In an embodiment, the crowdsourcing server  operates as a component in the Mechanical Turk system from Amazon.com, Inc.","Several example methods that may be implemented by the components discussed above are discussed next with reference to . As one example, the methods of  may be implemented as computer programs stored on the tangible, non-transitory computer-readable medium (such as one or several hard disk drives) and executable on one or several processors. Although the methods of  can be executed on individual computers, such as servers or PCs, it is also possible to implement at least some of these methods in a distributed manner using several computers, e.g., using a cloud computing environment.",{"@attributes":{"id":"p-0062","num":"0061"},"figref":["FIG. 11","FIG. 1"],"b":["800","800","20","14","702","1","702","2","702","3","20","704","800","802","22","712","20","704","20","704"]},"At block , visual pose indications are rendered in the interactive screen over the map or other visual representation of the geographic area generated at block . For example, pose indications may be pose indicators that are superimposed on the map in accordance with the corresponding location data. The pose indicators may define an upper layer in the interactive visualization, and the map may define a lower layer in the interactive visualization. In this manner, the pose correction UI component  or  can easily re-render pose indicators in response to operator commands while keeping the background map image static. In some embodiments, the pose rendering engine  or  generates the pose indicators as a raster image, forwards the raster image to the pose correction UI component  or , and the pose correction UI component  or  renders the raster image on the display. In one such embodiment, the pose rendering engine  or  generates a raster image that includes both the map data and the pose indicators. In another embodiment, the pose correction UI component  or  receives a map image from the pose rendering engine  or , superimposes pose indicators onto the received map image, and renders the resulting image on the display.","At block , pose corrections (or adjustments) are received from the operator. For example, the operator may use a pointing device, such as a mouse or a touchpad, to select a pose indicator and move the pose indicator to a new position in the interactive screen. The operating system may process several events received from the pointing device and forward the processed events to the pose correction UI component  or . If needed, the operator may adjust multiple poses at block . Next, at block , pose data is updated in accordance with the adjusted positions of the corresponding pose indicators. According to an embodiment, the operator activates a control in the interactive screen (e.g., a \u201csubmit\u201d button) to trigger an update of the appropriate records in the image and pose database  or . In another embodiment, the image and pose database  or  is updated after the operator adjusts a certain number of poses. In yet another embodiment, the image and pose database  or  is updated periodically, e.g., once every two minutes. Once pose data is updated at block , the flow returns to block , unless the operator terminates the method .",{"@attributes":{"id":"p-0065","num":"0064"},"figref":["FIG. 12","FIG. 11"],"b":["830","800","712","20","704","712","20","704","800","806"]},"At block , an adjusted pose, e.g., a new position of a pose indicator in an interactive screen, is received from an operator via an interactive screen. In response, at block , the pose correction UI component  or  may disable pose correction for N (e.g., five, ten) subsequent poses to prevent the operator from attempting to move every pose that appears to be incorrect. The poses for which correction is disabled may be selected along the direction in which the corresponding pose run progresses or along both directions, depending on the implementation. In an embodiment, the number N is configurable. To indicate that the N poses subsequent or adjacent to the adjusted pose cannot be modified, the corresponding pose indicators may be rendered using a different color, a different pictogram or symbol, or in any other manner. At block , a pose indicator corresponding to the adjusted pose, as well as pose indicators corresponding to the poses for which correction is disabled, are rendered in the appropriate positions in the interactive screen.",{"@attributes":{"id":"p-0067","num":"0066"},"figref":["FIG. 13","FIG. 10"],"b":["850","714","852","854","856","720"]},"The following additional considerations apply to the foregoing discussion. Throughout this specification, plural instances may implement components, operations, or structures described as a single instance. Although individual operations of one or more methods are illustrated and described as separate operations, one or more of the individual operations may be performed concurrently, and nothing requires that the operations be performed in the order illustrated. Structures and functionality presented as separate components in example configurations may be implemented as a combined structure or component. Similarly, structures and functionality presented as a single component may be implemented as separate components. These and other variations, modifications, additions, and improvements fall within the scope of the subject matter herein.","Certain embodiments are described herein as including logic or a number of components, modules, or mechanisms. Modules may constitute either software modules (e.g., code embodied on a machine-readable medium or in a transmission signal) or hardware modules. A hardware module is tangible unit capable of performing certain operations and may be configured or arranged in a certain manner. In example embodiments, one or more computer systems (e.g., a standalone, client or server computer system) or one or more hardware modules of a computer system (e.g., a processor or a group of processors) may be configured by software (e.g., an application or application portion) as a hardware module that operates to perform certain operations as described herein.","Unless specifically stated otherwise, discussions herein using words such as \u201cprocessing,\u201d \u201ccomputing,\u201d \u201ccalculating,\u201d \u201cdetermining,\u201d \u201cpresenting,\u201d \u201cdisplaying,\u201d or the like may refer to actions or processes of a machine (e.g., a computer) that manipulates or transforms data represented as physical (e.g., electronic, magnetic, or optical) quantities within one or more memories (e.g., volatile memory, non-volatile memory, or a combination thereof), registers, or other machine components that receive, store, transmit, or display information.","As used herein any reference to \u201cone embodiment\u201d or \u201can embodiment\u201d means that a particular element, feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase \u201cin one embodiment\u201d in various places in the specification are not necessarily all referring to the same embodiment.","Some embodiments may be described using the expression \u201ccoupled\u201d and \u201cconnected\u201d along with their derivatives. For example, some embodiments may be described using the term \u201ccoupled\u201d to indicate that two or more elements are in direct physical or electrical contact. The term \u201ccoupled,\u201d however, may also mean that two or more elements are not in direct contact with each other, but yet still co-operate or interact with each other. The embodiments are not limited in this context.","As used herein, the terms \u201ccomprises,\u201d \u201ccomprising,\u201d \u201cincludes,\u201d \u201cincluding,\u201d \u201chas,\u201d \u201chaving\u201d or any other variation thereof, are intended to cover a non-exclusive inclusion. For example, a process, method, article, or apparatus that comprises a list of elements is not necessarily limited to only those elements but may include other elements not expressly listed or inherent to such process, method, article, or apparatus. Further, unless expressly stated to the contrary, \u201cor\u201d refers to an inclusive or and not to an exclusive or. For example, a condition A or B is satisfied by any one of the following: A is true (or present) and B is false (or not present), A is false (or not present) and B is true (or present), and both A and B are true (or present).","In addition, use of the \u201ca\u201d or \u201can\u201d are employed to describe elements and components of the embodiments herein. This is done merely for convenience and to give a general sense of the invention. This description should be read to include one or at least one and the singular also includes the plural unless it is obvious that it is meant otherwise.","Upon reading this disclosure, those of skill in the art will appreciate still additional alternative structural and functional designs for a system and a process for correcting pose image data through the disclosed principles herein. Thus, while particular embodiments and applications have been illustrated and described, it is to be understood that the disclosed embodiments are not limited to the precise construction and components disclosed herein. Various modifications, changes and variations, which will be apparent to those skilled in the art, may be made in the arrangement, operation and details of the method and apparatus disclosed herein without departing from the spirit and scope defined in the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 8","FIG. 1"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 9","FIG. 1"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
