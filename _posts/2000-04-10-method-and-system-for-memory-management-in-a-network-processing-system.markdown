---
title: Method and system for memory management in a network processing system
abstract: A method and system for memory management in a network processing system provides for allocation of physical memory areas within network processors coupled to a control point processor by a bus. The allocation scheme provides a memory management layer without requiring a complete operating system interface and supports asynchronous completion of the allocation requests. Multicast allocation is supported allowing an allocation to be simultaneously requested on multiple network processors. The allocation mechanism returns a token, which may then be used to access the memory location via a protocol over the bus, and a single token may refer to an allocation made on several network processors where the actual physical addresses and memory configurations are different.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06981027&OS=06981027&RS=06981027
owner: International Business Machines Corporation
number: 06981027
owner_city: Armonk
owner_country: US
publication_date: 20000410
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF PREFERRED EMBODIMENT"],"p":["1. Technical Field","The present invention relates in general to computer networks, and in particular, to a network processor for managing network traffic. Specifically, the invention relates to memory management between a control point processor and network processors.","2. Description of the Related Art","Computer networks have evolved to a point where switch routers are insufficient to handle complex network routing and filtering requirements. Network processors, such as the International Business Machines (IBM) Network Processor (NP) have been developed to fill this need. Utilizing a connection similar to that of a network switch, the NP provides a level of control and flexibility that surpasses that of the network switch. Parallel lookup operations can be performed on a frame, complex modifications can be performed on packets, and policies can be managed at complex levels. Multiple processors are used to achieve a very high frame processing throughput.","It is not desirable to have a high overhead operating system running on a network processor. Due to the requirements of high frame processing throughput, the NP support tasks need to be reduced to a minimum. However, there is a need for memory allocation for data structures and control instructions that control the network processor. In addition, the NP may execute local applications, for example complex filtering applications performing frame filtering and blocking. These NP-based applications require a memory allocation scheme that does not require constant communication with a central control point. In addition, it is disadvantageous to require direct mapping of address space between central control point applications or operating systems running on a central processor and data structures or programs running on NPs.","Therefore, it would be desirable to provide a method and system for managing memory in a network processing system so that access to the memory can be achieved without requiring high processing overhead and direct mapping of address spaces between a control point processor and one or more network processors.","The objective of managing memory in a network processing system without requiring direct memory mapping is achieved in a method and system for managing memory in a network processing system, which includes a control point processor and multiple network processors (NPs). A dynamic memory manager, having a control point processor (CP) component and a network processor component, is provided for registering applications for allowing those applications to request allocation of memory on the NPs by transmitting a request from the CP component to the NP component over a bus. In response to a request, the NP allocates physical memory and returns a token representing the allocation from the NP component to the CP component. The token is used to provide read\/write and other access to the physical memory.","All objects, features, and advantages of the present invention will become apparent in the following detailed written description.","With reference to the figures, and in particular to , a network processing system in accordance with an embodiment of the present invention is depicted. A packet routing switch  is coupled to a group of network processors (NPs) A\u2013C. NPs A\u2013C provide media interfaces for connecting to networks having various protocols, such as 10 base-T or  base-T ethernet connections A\u2013E or other types of communication interfaces that are known in the art. Thus, NP A may route frames received at any of the media interfaces to port  on packet routing switch , and may perform address translations, respond to Quality-of-Service (QoS) requests, block packets, or perform any complex routing or frame processing function on the incoming frames. NP A also receives frames from port  on packet routing switch  via an Egress interface and may perform similar complex operations to route frames to the media interfaces. Control memory  provides storage for control software that drives the routing functionality and frame processing, and, specifically, the software managed tree (SMT) dynamic classifier of the present invention. Lookup ZBT SRAM  provides fast access memory for storing fixed match tree (FMT) hardware assisted matching trees and can be used to provide fast storage for SMTs or portions thereof. Control point central processing unit (CPU)  provides management of network processor operations and downloading of applications, classifier trees and other data. CPU  compiles and creates the SMTs for downloading. The SMTs are built by applications running on CPU , then downloaded to memory coupled to NPs A\u2013C.","Referring now to , a simplified block diagram of NP A is shown. Ingress Enqueue\/Dequeue\/Scheduling logic (EDS)  manages frame buffering and control for frames routed to switch fabric . Frames are received from the media interface connections by ingress physical MAC (Medium Access Control) multiplexer (PMM) , and are translated and processed by protocol processors . An ingress switch interface , provides a connection to switch fabric  and may connect to another NP or a packet routing switch . An egress switch interface  receives frame data from switch fabric  and the frame data is stored in egress data storage . Protocol processors  can then perform classifier searches to process the frames and route them through an egress PMM .","Referring now to , a detailed block diagram of NP A in accordance with a preferred embodiment of the invention is depicted. Memories  for storing frame data, classifier trees and applications data and instructions are coupled to the NP by control store arbiter , allowing core processing units  to share access to external and internal memory. Each core processing unit  contains dyadic protocol processing units (DPPU) A\u2013B and tree search engine . An instruction memory  is coupled to the core processing unit  for storing the picocode that drives the tree search engines  (TSEs). Power PC\u00ae processor core , provides management of the network processor unit . Software managed tree data and fixed match tree data may be downloaded into memories  to provide control for TSEs . Once a leaf in the tree is matched, it is loaded into internal registers in the network processor unit . The trees used with TSEs  are referred to as static or dynamic trees. Dynamic trees are so called because they may be updated incrementally and quickly to produce changes in the processing of frames. Static trees are not incrementally upgraded and require a reload of the tree each time the tree is modified. Static trees are useful for providing more complex matching such as applying a leaf to a range of IP addresses. Hardware classifier  pre-processes received frames to prepare for matching.","The present invention embodies a method and system for managing memory on NPs A\u2013C so that the applications on CPU  and applications running on NPs A\u2013C may allocate memory for use in storing control instructions, data, and frame classifier trees. This memory may be data storage for NP applications, data storage for CP applications, SMT storage for frame classifiers, etc.","Referring now to , the software modules that implement the method and system of the present invention are depicted. A dynamic memory manager includes two portions, namely, a control point memory manager (CPMM)  and an NP memory manager . The CP component of the dynamic memory manager resides within memory coupled to CPU , and the NP component resides within memory coupled to NP A. Within CPU , an application software  provides control of network processing performed by network processors A\u2013C. In order to allocate memory for data storage on NPs A\u2013C, application software  communicates with application programming interfaces (APIs) in CPMM . These APIs provide allocation and deallocation services for memory on NPs A\u2013C as well as read\/write access services and request for memory status information such as the remaining free space. The APIs may also provide selection of fast or slow memory allocation and transfer operations from one memory to another within NPs A\u2013C. Unlike ordinary procedure calls and ordinary memory allocation schemes within operating systems such as AIX (manufactured by IBM Corporation of Armonk, N.Y.) or UNIX, the APIs in the dynamic memory manager are not synchronous.","In order to provide allocation services without delaying application execution or interrupting NP A\u2013C processing, the response to allocation and access requests is asynchronous, reporting results after the transaction has propagated to NPs A\u2013C. The dynamic memory manager also supports multicast memory allocation and access, in that multiple NPs may be specified in each request, for example a multicast API allows CPU  to allocate space and write data on a particular subset of NPs A\u2013C in a single set of operations: a single allocate call and a single write call. The dynamic memory manager notifies the CP application  via CPMM  when all of the responses have been received or when an error (including timeout due to no response from one or more NPs) has occurred.","In order to accomplish asynchronous operation and organize data that is owned by applications, a Register( ) and De-Register( ) API are provided by the dynamic memory manager. Applications register themselves with the DMM and a table is built to record the allocations requested by the application. When the application calls De-Register( ), the DMM waits for pending requests to timeout, then deletes all of the tokens held by the application.","The operations supported by the dynamic memory manager CP component (the part of the dynamic memory manger resident within CPU ) include the Register( ) and De-Register( ) APIs, along with Read( ), Write( ), Resize( ), Allocate( ) and Deallocate( ) APIs. Additional inquiries are available to return the amount of free memory and information on availability of memories with different access speeds. For example, a CP application preparing to download a frame processing algorithm that will be used frequently may want to determine if enough free bytes are available in fast on-chip memory to hold the code implementing the algorithm. A CheckMemoryAvailability( ) API is provided this purpose.","Packets representing memory operations are propagated to a bus connecting CPU  with NPs A\u2013C. A device driver  provides packaging of the information required for the request, i.e. token and data for a write request, into stimuli for a bus interface . The bus that connects the NPs and the CPU  may be an Ethernet connection, an Fibre Channel connection or some other interface that allows bidirectional communications.","Within NP A, the bus packets are received by a bus interface  and decoded by guided cell handler , which then communicates the requests encapsulated within the packets to the NP component of the dynamic memory manager . The dynamic memory manager then may allocate or access memory  coupled to the NP. An SMT download facility  provides allocation for SMTs that are downloaded to NP A. Table initialization control  sets up the framework for the NP component  of the dynamic memory manager. The tables created track allocations and tokens that have been passed to applications and provide data for converting received token information to pointers so that physical locations within the NP can be accessed. Applications  executing within NP may also allocate and access memory using these mechanisms so that a common interface is provided between applications running on the CPU  and applications running on the NPs.","By using a single token to refer to a particular datum created by an application, multiple applications or multiple instances running on the various processors can refer to the same datum, even though it is located within different memories at unique addresses. For example a request to delete a particular record that was allocated on multiple processors could be broadcast to all processors. The deallocation would proceed on those processors for which the record exists and fail on those on which it did not exist. The results of a memory operation are returned to the application by a callback mechanism that is provided during application registration. The callback is made by the dynamic memory manager supplying the token and result for each of the targeted NPs. The callback routine in the application can then determine the results of the operations that were asynchronously queued earlier. The use of the token provides a mechanism that allows the application to identity which requests are completed and which are still pending.","The dynamic memory manager may also block requests depending on the status of pending requests associated with a given token. For example, the write operation should be blocked if an allocate request is pending, since the physical location has not been assigned and there is no target yet for the write data.","Referring to , a flowchart of a method for managing memory in a network processing system in accordance with an embodiment of the invention is depicted. An application registers with the dynamic memory manager (step ) and the dynamic memory manager builds a table of references for the application (step ). The application can then request allocation of memory (step ) and that request is propagated to one or more network processors on the bus (step ). Physical memory is allocated within the NP subsystem and a token is returned to refer to the allocation (step ). The responses to the allocation request are returned from the NPs and collected by the dynamic memory manager (step ). The application is then notified of the results of the allocation (step ).","Referring now to , a flowchart of a method of downloading an SMT in accordance with a preferred embodiment of the invention is depicted. The SMT download facility  provides storage allocation for the SMTs that are downloaded and the multiple storage allocations used to maintain frame classifier operation while the new SMT is downloaded. A new SMT is built on CPU  (step ) and the classifier timer is stopped if it is already running (step ). This prevents applications running on CPU  or NPs A\u2013C from making any additions or changes to the SMT while the download of a new SMT proceeds. The new SMT is checked to determine if rule changes have occurred which require download of the new SMT (step ) and if not, the process ends. If the SMT needs to be downloaded, it is generally first downloaded to slow storage (step ), since fast storage is a limited resource and there may not be enough fast storage (either internal memory within NP  or external memory  such as ZBT SRAM ).","The pointer that specifies the location of the active SMT for the NP frame processor TSE  is changed to point at the newly downloaded SMT (step ). Then the old SMT is purged from fast memory (step ). Another copy of the new SMT is downloaded to fast memory (step ). Finally, the active classifier tree pointer is changed to point at the new SMT copy in fast memory (step ), the SMT is purged from slow storage (step ), and the classifier timer is restarted (step ). This accomplishes an update of the SMT without halting operation of the TSE  while maximizing the size of available fast memory. If the SMT was not temporarily used from slow memory, then the fast memory would have to be larger to accommodate the old SMT and the new SMT, or the operation of TSE  would be interrupted while the download is being performed.","It is not necessary to perform the download twice to perform the method of the present invention. For instance, SMT download may occur in a network processing system where all memory is accessible at the same speed.","In this configuration, a single download is performed and the active pointer is switched to the new SMT location, since there would be no added benefit from recovering the location of the old SMT.","While the preferred embodiment of the invention has is illustrated with a configuration having a single CPU and multiple NPs, the present invention may be implemented in a system having multiple CPUs and a single NP, or other variants providing control of network routing and processing. It will be understood by those skilled in the art that various changes in form and detail may be made therein without departing from the spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The novel features believed characteristic of the invention are set forth in the appended claims. The invention itself however, as well as a preferred mode of use, further objects and advantages thereof, will best be understood by reference to the following detailed description of an illustrative embodiment when read in conjunction with the accompanying drawings, wherein:",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
