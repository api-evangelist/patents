---
title: Television-based visualization and navigation interface
abstract: Techniques for retrieving and displaying multimedia information are provided. A television (TV) interface is provided that displays multimedia information that may be stored in a multimedia document. The interface enables a user to navigate through multimedia information stored on the multimedia document.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07954056&OS=07954056&RS=07954056
owner: Ricoh Company, Ltd.
number: 07954056
owner_city: 
owner_country: JP
publication_date: 20020617
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCES TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This application is a continuation-in-part of and claims the benefit of U.S. patent application Ser. No. 10\/081,129, filed Feb. 21, 2002, entitled \u201cMultimedia Visualization & Integration Environment (MuVIE)\u201d, which in turn claims priority from and is a continuation-in-part (CIP) application of U.S. Non-Provisional patent application Ser. No. 08\/995,616, entitled \u201cAUTOMATIC ADAPTIVE DOCUMENT READING HELP SYSTEM\u201d filed Dec. 22, 1997, the entire contents of which are incorporated herein by reference for all purposes.","This application makes reference to the following commonly owned patent application, the entire contents of which are incorporated herein by reference for all purposes:","U.S. patent application Ser. No. 10\/001,895, filed on Nov. 19, 2001, entitled, \u201cPaper-Based Interface for Multimedia Information\u201d.","The present invention generally relates to displaying information on a television interface and more particularly to techniques for displaying a user interface on a television that facilitates navigation of multimedia information displayed by the television.","The advent of appliances that are capable of displaying stored multimedia information via a television (TV) interface has dramatically changed a user's television viewing experience. Examples of such appliances include digital video recorders (DVRs), digital video disc (DVD) players, and the like. A DVR is a device that is capable of recording TV broadcasts for replay at a later time. During playback of the recorded TV broadcast, the user can pause, fast forward, rewind, or perform other operations on the recorded TV broadcast information similar to operations that can be performed by a video cassette recorder (VCR) system.","A DVR is generally a data processing system that includes a storage subsystem (e.g., a hard drive) for storing recorded TV broadcasts. The DVR is capable of recording one or more TV broadcasts during time intervals that may be specified by the user. DVRs generally also provide a user interface for navigating and controlling playback of the recorded TV broadcast information. The user interface is designed to be controlled with a TV remote control device.","Various user interfaces have been designed that are displayed on a TV and enable a user to control and navigate the playback of recorded multimedia information (which may include recorded TV broadcast information) that is output via the TV. In one example, a television interface includes a time bar that is displayed alongside the multimedia information that is being replayed by the TV. The time bar indicates the total length of the multimedia recording and the time elapsed during playback of the multimedia information. Markers are also included on the bar representing time points in the multimedia information to which a user can \u201cjump\u201d. A user may use a remote control to \u201cjump\u201d to the time points in the video corresponding to the markers. In conventional interfaces, the markers simply represent precon-figured time points in the multimedia information and are not determined with reference to the content of the recorded multimedia information. For example, the markers may correspond to the one-quarter, one-half, and three-quarters time intervals in the multimedia information. Also, these markers are not user configurable and do not show the content of the multimedia information. Further, the markers are displayed just as lines on the time bar and do not show any information related to the contents of the multimedia information. Additionally, navigation through the recorded multimedia information is restricted to the predefined markers\u2014the time bar does not allow random access to sections of the recorded multimedia information that do not correspond to the markers.","A digital video disc (DVD) player generally allows a user to control playback and navigation of multimedia information stored on a DVD using predefined scenes. The user is presented a screen with a selection of scenes that include a picture associated with the scene. The user can select a scene to begin playback and the DVD begins playback of the multimedia information starting from the selected scene. The scene selection screen is not shown during the playback of the multimedia information. Thus, the DVD interface does not allow interactive navigation during playback of the multimedia information stored on a DVD. Once a user selects a scene, the multimedia information corresponding to the selected scene is played back on the TV. During playback, the user is not allowed to view the scene selection screen and navigate to other sections of the multimedia information. Further, the user is limited to navigating between the predefined scenes.","The present invention provides techniques for retrieving and displaying multimedia information. According to an embodiment of the present invention, a television (TV) interface is provided that displays multimedia information that may be stored in a multimedia document. According to teachings of embodiments of the present invention, the interface enables a user to navigate through multimedia information stored on the multimedia document.","In one embodiment, techniques for displaying multimedia information on a television display are provided. The embodiment is configured to display a section of the multimedia information in a first area of the display. Additionally, the embodiment is configured to display a navigation bar in a second area of the display. The navigation bar includes one or more thumbnail images, wherein each thumbnail image in the one or more thumbnail images is extracted from the multimedia information. Also, at least one thumbnail image in the one or more of thumbnail images is selectable while the section of multimedia information in the first area of the display is displayed.","In another embodiment, techniques for displaying multimedia information on a television display are provided. The embodiment is configured to display a section of the multimedia information in a first area of the display. Also, a second area of the display in which a navigation bar will be displayed is identified. The embodiment then determines one or more timestamps based on the second area of the display. A keyframe from the multimedia information corresponding to each timestamp is extracted. The navigation bar is then configured to include a keyframe extracted for at least one timestamp in the one or more time stamps. The navigation bar is then displayed in the second area of the display. In the navigation bar, at least one keyframe is included that is selectable by a user during display of the section of the multimedia information in the first area of the display.","In yet another embodiment, a data processing system is provided. The data processing system includes a processor and a memory coupled to the processor. The memory is configured to store one or more code modules for execution by the processor, where the one or more code modules are configured to perform techniques for displaying multimedia information in a television display as described.","In yet another embodiment, a computer program product for displaying multimedia information on a television display is provided. The computer program product includes code for executing techniques for displaying multimedia information in a television display as described.","In one embodiment, a TV remote control is provided to select thumbnail images displayed in the navigation bar.","A further understanding of the nature and advantages of the invention herein may be realized by reference of the remaining portions in the specifications and the attached drawings.","Embodiments of the present invention provide a navigation bar that is displayed on a television (TV) and allows control and navigation of multimedia information outputted on the TV. According to an embodiment of the present invention, a television user interface is provided that displays multimedia information that may be stored in a multimedia document. According to the teachings of embodiments of the present invention, the interface enables a user to navigate through multimedia information stored in a multimedia document. The interface provides both a focused and a contextual view of the contents of the multimedia document displayed by the TV.","As indicated above, the term \u201cmultimedia information\u201d is intended to refer to information that comprises information of several different types in an integrated form. The different types of information included in multimedia information may include a combination of text information, graphics information, animation information, sound (audio) information, video information, slides information, whiteboard images information, and other types of information. For example, a video recording of a television broadcast may comprise video information and audio information. In certain instances the video recording may also comprise close-captioned (CC) text information, which comprises material related to the video information, and in many cases, is an exact representation of the speech contained in the audio portions of the video recording. Multimedia information is also used to refer to information comprising one or more objects wherein the objects include information of different types. For example, multimedia objects included in multimedia information may comprise text information, graphics information, animation information, sound (audio) information, video information, slides information, whiteboard images information, and other types of information.","The term \u201cmultimedia document\u201d as used in this application is intended to refer to any electronic storage unit (e.g., a file) that stores multimedia information in a digital format. Various different formats may be used to store the multimedia information. These formats include various MPEG formats (e.g., MPEG 1, MPEG 2, MPEG 4, MPEG 7, etc.), MP3 format, SMIL format, HTML+TIME format, WMF (Windows Media Format), RM (Real Media) format, Quicktime format, Shockwave format, various streaming media formats, formats being developed by the engineering community, proprietary and customary formats, and others. Examples of multimedia documents include video recordings, MPEG files, news broadcast recordings, presentation recordings, recorded meetings, classroom lecture recordings, broadcast television programs, or the like.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 1","FIG. 1","FIG. 1","FIG. 1"],"b":["100","100","102","106","104","108","110","100"]},"Communication network  provides a mechanism allowing the various systems depicted in  to communicate and exchange information with each other. Communication network  may itself be comprised of many interconnected computer systems and communication links. While in one embodiment, communication network  is the Internet, in other embodiments, communication network  may be any suitable communication network including a local area network (LAN), a wide area network (WAN), a wireless network, an intranet, a private network, a public network, a switched network, or the like.","Communication links  used to connect the various systems depicted in  may be of various types including hardwire links, optical links, satellite or other wireless communications links, wave propagation links, or any other mechanisms for communication of information. Various communication protocols may be used to facilitate communication of information via the communication links. These communication protocols may include TCP\/IP, HTTP protocols, extensible markup language (XML), wireless application protocol (WAP), protocols under development by industry standard organizations, vendor-specific protocols, customized protocols, and others.","Accordingly, according to an embodiment of the present invention, server system , TV appliance , and\/or any combination thereof are configured to perform processing to facilitate generation of an interface that displays multimedia information according to the teachings of embodiments of the present invention. Also, TV appliance  and\/or server  are capable of receiving signals from a remote control and perform processing according to the signals.","If the interface is generated by server , server  may send the interface for display on TV systems  via communication network  or via communication network  and TV appliance . If the interface is generated by TV appliance , TV appliance  may send the interface for display on TV systems  through communication link . If the interface is generated by TV appliance  and server , TV appliance , server , or a combination thereof, may send the interface for display on TV systems . The interface generated by server  and\/or TV appliance  enables the user to retrieve and browse multimedia information that may be stored in a multimedia document.","The processing performed by server system  and\/or TV appliance  to generate the interface and to provide the various features according to the teachings of embodiments of the present invention may be implemented by software modules executing on server system  and\/or TV appliance , by hardware modules coupled to server system  and\/or TV appliance , or combinations thereof. In alternative embodiments of the present invention, the processing may also be distributed between the various systems depicted in .","The multimedia information that is displayed in the interface may be stored in a multimedia document that is accessible to server system  and\/or TV appliance . For example, the multimedia document may be stored in a storage subsystem of server system  and\/or TV appliance . Alternatively, the multimedia document may be stored in a memory location accessible to server system  and\/or TV appliance .","Users may use TVs  to view the interface generated by server system  and\/or TV appliance . Users may also use TV appliance  to interact with the other systems depicted in . For example, a user may use TV appliance  to select a particular multimedia document and request server system  and\/or TV appliance  to generate an interface displaying multimedia information stored by the particular multimedia document. A user may also interact with the interface generated by server system  and\/or TV appliance  using input devices coupled to TV appliance . TV appliance  may be of different types including a DVR, personal computer, a portable computer, a workstation, a computer terminal, a network computer, a mainframe, or any other data processing system.","According to an embodiment of the present invention, a single computer system may function both as server system  and as TV appliance . Various other configurations of the server system  and TV appliance  are possible.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":["FIG. 2","FIG. 1","FIG. 2"],"b":["200","200","200","202","204","206","208","210","212","214","216","200","216"]},"Bus subsystem  provides a mechanism for letting the various components and subsystems of computer system  communicate with each other as intended. The various subsystems and components of computer system  need not be at the same physical location but may be distributed at various locations within network . Although bus subsystem  is shown schematically as a single bus, alternative embodiments of the bus subsystem may utilize multiple busses.","User interface input devices  may include a remote control, a keyboard, pointing devices, a mouse, trackball, touchpad, a graphics tablet, a scanner, a barcode scanner, a touchscreen incorporated into the display, audio input devices such as voice recognition systems, microphones, and other types of input devices. In general, use of the term \u201cinput device\u201d is intended to include all possible types of devices and ways to input information using computer system .","User interface output devices  may include a display subsystem, a printer, a fax machine, or non-visual displays such as audio output devices. The display subsystem may be a cathode ray tube (CRT), a flat-panel device such as a liquid crystal display (LCD), a projection device, or the like. The display subsystem may also provide non-visual display such as via audio output devices. In general, use of the term \u201coutput device\u201d is intended to include all possible types of devices and ways to output information from computer system . According to an embodiment of the present invention, the interface generated according to the teachings of the present invention may be presented to the user via output devices .","Storage subsystem  may be configured to store the basic programming and data constructs that provide the functionality of the computer system and of the present invention. For example, according to an embodiment of the present invention, software modules implementing the functionality of the present invention may be stored in storage subsystem  of server system . These software modules may be executed by processor(s)  of server system . In a distributed environment, the software modules may be stored on a plurality of computer systems and executed by processors of the plurality of computer systems. Storage subsystem  may also provide a repository for storing various databases that may be used by the present invention. Storage subsystem  may comprise memory subsystem  and file storage subsystem .","Memory subsystem  may include a number of memories including a main random access memory (RAM)  for storage of instructions and data during program execution and a read only memory (ROM)  in which fixed instructions are stored. File storage subsystem  provides persistent (non-volatile) storage for program and data files, and may include a hard disk drive, a floppy disk drive along with associated removable media, a Compact Disk Read Only Memory (CD-ROM) drive, an optical drive, removable media cartridges, and other like storage media. One or more of the drives may be located at remote locations on other connected computers.","Computer system  itself can be of varying types including a personal computer, a portable computer, a workstation, a computer terminal, a network computer, a mainframe, a kiosk, a personal digital assistant (PDA), a communication device such as a cell phone, or any other data processing system. Server computers generally have more storage and processing capacity then client systems. Due to the ever-changing nature of computers and networks, the description of computer system  depicted in  is intended only as a specific example for purposes of illustrating the preferred embodiment of the computer system. Many other configurations of a computer system are possible having more or fewer components than the computer system depicted in .",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 3","FIG. 3"],"b":["300","300"]},"According to an embodiment of the present invention, interface  is displayed on a TV and is used to output multimedia information. Interface  also comprises features that allow a user to control and navigate playback of the multimedia information output via TV . As shown, interface  includes a first viewing area  and a second viewing area . It will be apparent that alternative embodiments of the present invention may include more or fewer viewing areas than those depicted in . Further, in alternative embodiments of the present invention, one or more viewing areas may be combined into one viewing area, or a particular viewing area may be divided into multiple viewing areas. Accordingly, the viewing areas depicted in  and described below are not meant to restrict the scope of the present invention as recited in the claims.","As depicted in , interface  displays multimedia information corresponding to a television broadcast recording. A television broadcast may be stored as a television broadcast recording in a memory location accessible to server system  and\/or TV appliance . It will be apparent that the present invention is not restricted to displaying television recordings. Other types of multimedia information that can be displayed via a TV interface, including other types of information, such as text information, closed-captioned (CC) text information, whiteboard information, or the like, may also be displayed in alternative embodiments of the present invention.","The multimedia information typically has a \u201cstart time\u201d and an \u201cend time\u201d. The start time denotes a time when recording of the multimedia information was started, and the end time denotes a time when recording of the multimedia information was stopped. The recorded multimedia information thus stores multimedia information between the start time and the end time. The time between the start time and the end time may be referred to as the duration of the multimedia information.","The television broadcast information that is output via interface  depicted in  may have been recorded using a variety of different techniques. According to one technique, the television broadcast is recorded and stored using a satellite receiver connected to a PC-TV video card of server system . Applications executing on server system  then process the recorded television broadcast to facilitate generation of interface . According to another embodiment of the present invention, the television broadcast may be captured using a digital video recorder. For example, a user may program a DVR to record a TV program on a particular channel. Examples of DVRs include devices TIVO\u2122 systems, ReplayTV\u2122 systems, set-top boxes, and the like.","First viewing area  outputs the multimedia information. As depicted in , multimedia information is being played back in first viewing area .","Second viewing area  displays a navigation bar  of the multimedia information being played back in first viewing area . As shown in , first viewing area  outputs multimedia information that may be stored in a multimedia document. Second viewing area  displays navigation bar  that is used to control navigation and playback of the information displayed in first viewing area . In one embodiment, navigation bar  displays a scaled representation of multimedia information being played in first viewing area . The user may select the scaling factor used for displaying information in navigation bar . According to a specific embodiment, a representation of the entire information (i.e., multimedia information between the start time and the end time associated with the playback of the multimedia information) is displayed in second viewing area . In this embodiment, one end of navigation bar  represents the start time of the multimedia video and the opposite end of navigation bar  represents the end time of the multimedia broadcast.","Navigation bar  displays a visual representation of multimedia information at certain times. Keyframes are extracted from the multimedia information in the multimedia document and displayed as thumbnail images in navigation bar . The thumbnail images may be used by a user to navigate the multimedia information. The user may use a remote control to select thumbnail images. Once a thumbnail image is selected, multimedia information being played back in first viewing area  is started at a time corresponding to the selected thumbnail image.","As shown in , according to one embodiment, navigation bar  includes one or more thumbnail images , a progress bar , and an action symbol . Each thumbnail image  represents a keyframe extracted from the stored multimedia information at a time. In the embodiment depicted in , the video information is displayed using video keyframes extracted from the video information included in the multimedia information stored by the multimedia document. The video keyframes may be extracted from the video information included in the multimedia document at various points in time between the start time and the end time.","A special layout style, which may be user configurable, is used to display the extracted thumbnail images  to enhance the readability of the thumbnail images. For example, a user may configure the thumbnail image height, thumbnail image width, width of navigation bar , and height of navigation bar . In , the thumbnail images are displayed such that two rows of thumbnail images are displayed.","One or more thumbnail images  may be displayed in navigation bar  based upon the different types of information included in the multimedia information being displayed. Although the thumbnail images displayed in second viewing area  depict keyframes extracted from the video information included in the multimedia information, it will be understood that in alternative embodiments of the present invention, the thumbnail images may be extracted from other types of information included in the multimedia information, such as text information, white board information, or the like. According to an embodiment of the present invention, the number of thumbnail images displayed in navigation bar  and the type of information represented by the thumbnail images is user configurable.","As depicted in , navigation bar  also includes a progress bar  that is displayed between the two rows of thumbnail images . The physical location of progress bar  indicates a time point in the multimedia document corresponding to the information being played back in first viewing area . In the embodiment depicted in , as multimedia information being displayed in first viewing area  is moving from an earlier time to a later time, progress bar  moves from left to right in navigation bar . Although progress bar  is shown in between the two rows of thumbnail images , it will be understood that progress bar  may be shown in different areas of interface . For example, progress bar  may be shown above the top row of thumbnail images , below the bottom row of thumbnail images , or in some other area.","Action symbol  shows the current state of playback of the multimedia information in first viewing area . As depicted in , the playback of multimedia information has been paused. As shown, a well known pause symbol is depicted as action symbol . Additionally, if the user is playing the multimedia information, action symbol  shows a standard triangle to represent a \u201cplay\u201d mode. If the user is fast forwarding or rewinding the multimedia information, action symbol  shows a standard set of triangles depicted moving in a forward or reverse direction. These symbols are well known in the art and may be found on most TV, VCR, and DVD systems and remote controls.","Interface  may also include a title section , a date recorded section , and a current time section  in one embodiment. Title section  displays the title of the multimedia information being played back in first viewing area . Date recorded section  displays the date that the multimedia information being played back was recorded. Current time section  displays the current time in the multimedia information being played back.","As shown in , a thumbnail image - and thumbnail image - are situated on the top left and bottom left side of the navigation bar. Additionally, a thumbnail image - and a thumbnail image - are depicted next to thumbnail images - and -, respectively. In one embodiment, thumbnail image - represents a keyframe extracted from the multimedia information at a first time t1. Also, thumbnail - is extracted from the multimedia information at a second time t2, where t2>t1, thumbnail image - is extracted from the multimedia information at a third time t3, where t3>t2, and thumbnail image - is extracted from the multimedia information at a fourth time t4, where t4>t3. Accordingly, the thumbnail images displayed in navigation bar  represent thumbnail images extracted from various times between the start time and end time of the multimedia information. It will be understood that thumbnail images  may be organized in various ways. For example, the progression of multimedia information may flow from left to right in the top row and then from left to right in the bottom row.",{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 4","b":["304","400","104","102","400","300","400","402"]},"As depicted in , location box  is displayed in navigation bar . A user can navigate the multimedia information displayed in first viewing area  using location box . Location box  does not necessarily indicate where in the multimedia information being played back in first viewing area  is currently located in navigation bar . Instead, location box  indicates one or more thumbnail images  that a user may select with remote control . Movement of location box  over the thumbnail images  can be controlled using the up, down, left, or right buttons on remote control .","Although location box  is shown superimposed over one thumbnail image , location box  may encompass multiple thumbnail images  or a range of thumbnail images . If a range of thumbnail images  is selected, the multimedia information in between the first and last thumbnail image  selected may be played in first viewing area .","Remote control  may be any standard remote control able to communicate with server , TV appliance , and\/or TV . According to an embodiment of the present invention, remote control  allows the user to control the TV  that is used to output the multimedia information. Remote control  may use infrared (IR) technology, wireless, wireline, or any other communication protocols in communicating commands to server  TV appliance , and\/or TV . Remote control  may be embodied as a TV remote control, a DVD remote control, a VCR remote control, a personal digital assistant (PDA), a cellular phone, or the like. Remote control  may also be incorporated as part of a TV, DVR, DVD, VCR, and the like.","As shown, remote control  includes arrow buttons  that facilitate navigation of location box  in second viewing area . Arrow buttons  may be used to move location box  to different thumbnail images . Thus, when a right arrow key is pressed, location box  may move one thumbnail image  to the right, when a left arrow key is pressed, location box  may move one thumbnail image  to the left, and so on. The navigation of a navigation bar will described in more detail below. In one embodiment, each click of a button  moves the location box one thumbnail image position in the direction corresponding to the clicked button. In other embodiments, upon selection of a button , location box  may continuously move in the direction of the selected button until the user indicates (for example, by re-clicking the previously selected button on the remote control) that the movement of the location box should stop.","An enter button  is also provided on remote control . Enter button  is used to select a thumbnail image  corresponding (or presently emphasized) by location box . For example, if location box  is positioned over a particular thumbnail image  and the user then selects enter button , the particular thumbnail image is marked as selected by the user. An operation may then be performed on the selected thumbnail image. According to an embodiment of the present invention, when a particular thumbnail image  is selected by pressing enter button , the multimedia information being played back in first viewing area  jumps to a portion of the multimedia information in the multimedia document corresponding to the selected thumbnail image. For example, according to an embodiment of the present invention, playback of multimedia information in first viewing area  jumps to a section of the stored multimedia information corresponding to a timestamp associated with the selected keyframe. Further details on how timestamps are associated with thumbnail images will be described below.",{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 5","b":["304","500","304"]},"Selected thumbnail image indicators  are used to highlight one or more thumbnail images  that that have been previously selected by the user. Each selected thumbnail image indicator  is represented such that is visually distinct from and can be differentiated from location box . For example, according to an embodiment of the present invention, selected thumbnail image indicator  is displayed in a color that is different from the color used to represent location box . In , selected thumbnail image indicator  is shown by displaying a colored-rectangle around a border of a selected thumbnail image . It will be understood that many other indicators may be used to indicate selected thumbnail images. For example, a symbol may be displayed proximal to a selected thumbnail image.","As shown in , second viewing area  includes a selected thumbnail image corresponding to thumbnail image -. As described above, according to an embodiment of the present invention, a user may have selected thumbnail image - using remote control . Upon selecting a particular thumbnail image (e.g. thumbnail image - depicted in ), a selected thumbnail image indicator  is displayed highlighting thumbnail image - as a selected image. As shown, a rectangle has been displayed around thumbnail image - to highlight the image. As mentioned above, a selected thumbnail image indicator  (e.g., the rectangle) may be drawn using a different color than that used to denote location box . After selecting thumbnail image -, the user can then move location box  to another thumbnail image (e.g., thumbnail image  depicted in ).",{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 6","b":["304","500"]},"As depicted in , multiple thumbnail images have been selected in second viewing area . Each selected image is indicated by a selected thumbnail image indicator . The selected thumbnail images represent various time points in the stored multimedia information that is displayed in first viewing area .","According to an embodiment of the present invention, the selected thumbnail images may be used for determining areas of the stored multimedia information that are of interest to the user. This information may also be used to generate a profile for a user where the profile indicates interests of the user. For example, if the user has selected one or more thumbnail images  that display images of \u201cPresident George W. Bush\u201d, it may be inferred from the selected images that the user is interested in content related to \u201cPresident George W. Bush\u201d. Additionally, if the user has selected thumbnail images  that correspond to sports-related content in the multimedia information, it may indicate that the user is interested in sports. Areas or topics of interest inferred from the selected thumbnail images may be used to generate a profile for the user. The user profile may be used to provide targeted advertising or targeted offers to the users. Targeted programming may also be offered to the user based upon the user's profile. For example, according to an embodiment of the present invention, if a user profile indicates that the user is interested in sports, then when the navigation bar is displayed to the user, all thumbnail images displayed in the navigation bar that correspond to sports-related content may be highlighted when displayed to the user via the TV interface.",{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 7","b":["700","700","701","702","703","704"]},"First viewing area  displays multimedia information from a multimedia document and is similar to first viewing area  described above.","Navigation bar  in second viewing area  includes thumbnail images  arranged vertically along the side of interface . In addition, progress bar , action symbol , selected thumbnail images indicators , and location box  are included in navigation bar . Accordingly, second viewing area  may include any of the features described above with reference to second viewing area . Second viewing area , however, displays thumbnail images  arranged in four vertical columns.","As shown, navigation bar  includes four columns of thumbnail images. The columns of thumbnail images are separated by progress bar  in one embodiment. It will be understood that progress bar  may be located in another area of second viewing area  or display .","As shown, a thumbnail image -, a thumbnail image -, a thumbnail image -, and a thumbnail image - are situated in the top row of the four columns of navigation bar . In one embodiment, thumbnail image - represents a keyframe extracted from the multimedia information at a first time t1. Also, thumbnail - is extracted from the multimedia information at a second time t2, where t2>t1, thumbnail image - is extracted from the multimedia information at a third time t3, where t3>t2, and thumbnail image - is extracted from the multimedia information at a fourth time t4, where t4>t3. A thumbnail image - is then extracted from the multimedia information at a fifth time t5, where t5>t4, so on. Accordingly, the thumbnail images displayed in navigation bar  represent thumbnail images extracted from various times between the start time and end time of the multimedia information. It will be understood that thumbnail images  may be organized in various ways. For example, the progression of multimedia information may flow from the top of a column to the bottom of the column, to the top of the next column to the bottom of that column, and so on.","Preview area  includes thumbnail images  that are used to preview multimedia information from the multimedia document. In one embodiment, thumbnail images  displayed in preview area  represent keyframes extracted from multimedia information found at certain intervals proximal (both coming before and after) to a current location of the multimedia information being played in first viewing area . As shown, a current location thumbnail image  is displayed that corresponds to a current time in the multimedia information being played back in first viewing area . The keyframe displayed in current location thumbnail image  may not correspond to the exact time of the current location of multimedia information being played back in first viewing area , but may be the keyframe closest in time to the time of the current location among keyframes displayed in preview area .","In preview area , in one embodiment, current location thumbnail image  may be visually formatted to be distinct from other thumbnail images . For example, current location thumbnail image  may have its background highlighted in a different color. Additionally, a symbol may be displayed proximal to (e.g., next to, above, or below) current location thumbnail image . As shown, a time is displayed in current location thumbnail image  and also in other thumbnail images . The time corresponds to the time elapsed (i.e., time from the start time of the recorded multimedia information) in the multimedia information. Thumbnail images  are shown corresponding to multimedia information occurring at time 21:50, 00:22:00, 00:22:10, 00:22:20, 00:22:30, and 00:22:40 in the stored multimedia information.","The range time surrounding the current location of the multimedia information being played back may be user configurable. For example, a time period interval between thumbnail images  for the preview area  may be specified. Using the time period interval, times for extracting keyframes corresponding to the current location are calculated. Then, as described below, keyframes are extracted at calculated times and displayed as thumbnail images .","In an alternative embodiment, preview area  may include keyframes that are extracted in a time period interval corresponding to location box 's position in navigation bar . In this case, when location box  is positioned over a particular thumbnail image , preview area  includes a number of keyframes extracted from intervals related in time to multimedia information corresponding to the position of the particular thumbnail image. The keyframes are then displayed in preview area  in the same manner as described above.",{"@attributes":{"id":"p-0086","num":"0085"},"figref":"FIG. 8","b":["800","800","802","804","800"]},"As shown in , second viewing area  includes a navigation bar  that includes two columns of thumbnail images  and a progress bar . Progress bar  is included to the side of thumbnail images . However, in other embodiments, progress bar  may be displayed in other areas of interface , such as to the right of thumbnail images .","An action symbol  is also included. As shown, action symbol  is offset to the left from progress bar . It will be understood that action symbol  is not limited to this position and may be located in other positions, such as being displayed on progress bar .","In one embodiment, topics of interests may be used to highlight thumbnail images in the above described interfaces. For example, if a user indicated a topic of interest, thumbnail images corresponding to that topic of interest may be highlighted. Topics of interest are described in U.S. patent application Ser. No. 10\/001,895, filed on Nov. 19, 2001, entitled, \u201cAutomatic Adaptive Document Help System\u201d.","In one example, a user may select one or more topics of interests. In one embodiment, a topic of interest corresponds to one or more keyword phrases. Once one or more topics of interests are selected, the corresponding keyword phrases are used to search for the selected topics of interests in the multimedia information. For example, a keyword search for the keyword phrases is conducted in closed captioned material, or any text material in the multimedia information. When a keyword phrase is identified, the time in the multimedia information corresponding to the identified keyword phrase is determined. A thumbnail image being displayed in the navigation bar that has been extracted from a time closest to determined time is then highlighted.","Interface Generation Technique According to an Embodiment of the Present Invention","The following section describes techniques for generating a navigation bar that is displayed on a TV interface according to an embodiment of the present invention. For purposes of simplicity, it is assumed that the multimedia information to be displayed in the interface comprises video information. However, it will be understood that other types of multimedia information, such as audio information, text information, whiteboard information, or the like, may also be included in the stored multimedia information and displayed on a TV interface in alternative embodiments of the present invention.",{"@attributes":{"id":"p-0092","num":"0091"},"figref":["FIG. 9","FIG. 3","FIG. 9"],"b":["305","304","305","305"]},"The variable duration represents the length (in seconds) of the stored multimedia information (i.e., of the video information for purposes of explaining the simplified embodiment of the invention). Various different units may be used to measure the duration of the stored multimedia information including seconds, minutes, hours, or any other unit representative of time length.","ImageWidth  represents the width of an individual thumbnail image that may be displayed in the navigation bar. ImageHeight  represents the height of an individual thumbnail image that may be displayed in the navigation bar. ImageContainerWidth  represents the width of the area for displaying the navigation bar. ImageContainerHeight  represents the height of the area for displaying the navigation bar.",{"@attributes":{"id":"p-0095","num":"0094"},"figref":["FIG. 10","FIG. 3","FIG. 10","FIG. 10"],"b":["1000","306","104","102","104","102","104","102","104","102","104"]},"As depicted in , server  receives a signal to display multimedia information from a stored multimedia information recording on a TV (step ). In response to the signal, server  then accesses multimedia information for display in the interface (step ). As previously stated, the multimedia information may be stored in a multimedia document accessible to server . As part of step , server  may receive information (e.g., a file name of the multimedia document) identifying the multimedia document and the location (e.g., a directory path) of the multimedia document. The user of the present invention may provide the multimedia document identification information. Server  may then access the multimedia document based upon the provided information. Server system  then uses the stored document to generate the interface according to teachings of the embodiments of the present invention.","Server  then extracts video information from the multimedia information accessed in step  (step ). In other embodiments, other information, such as text information, whiteboard information, or the like, may be extracted with or in place of the video information.","Server  then determines the length of the stored multimedia information (step ). In one embodiment, the length may be measured in seconds. The variable duration may be initialized to a value representing the length of the multimedia information.","The values for imageWidth and imageContainerWidth are then determined (step ). In one embodiment, the values may be predefined and retrieved from storage subsystem . Also, the values may be predefined and retrieved from any other system assessable to server .","Once the above values are determined, a maximum number of keyframes, maxKeyframes, is calculated (step ). The value maxKeyframes indicates how many keyframes may be displayed in a row of the navigation bar. For discussion purposes, two rows of thumbnail images will be assumed. In one embodiment, the calculation imageContainerWidth\/imageWidth=maxKeyframes is used. In this calculation, the width of navigation bar is divided by the width of a thumbnail image. The value maxKeyframes indicates how many keyframes may be displayed in a row of the navigation bar.","Server  determines an initial layout of cells that correspond to positions in second viewing area  where thumbnail images will be displayed (step ). Each thumbnail is a keyframe extracted from the video information. The cells may be associated with a pixel location in second viewing area .","Server  determines a seconds multiplier, sec_m (step ). In one embodiment, the seconds multiplier may be determined by the calculation sec_m=duration\/imageContainerWidth. Seconds multiplier, sec_m, is used to convert pixel locations in second viewing area  to a corresponding time value in seconds in the multimedia information.","Server  determines an X position in second viewing area  for a top keyframe that is associated with a cell position in the navigation bar (step ). The X position corresponds to a pixel location in interface . For example, the X position may be the position where thumbnail image - will be displayed on interface .","Server  determines an X position in second viewing area  for a bottom keyframe that is associated with a cell position in the navigation bar. In one embodiment, the top keyframe is a keyframe extracted at a time Tand the bottom keyframe is a keyframe extracted from the multimedia information at a time T, where T>T. The X position corresponds to a pixel location in interface . For example, the X position may be where thumbnail image - will be displayed on the interface.","In one embodiment, the X position for the bottom keyframe is calculated as the X position for the top keyframe in addition to half the value of the imageWidth value, which is half the width of a thumbnail image. It will be understood that other values may be used depending on the keyframe that is to be displayed in the bottom row. For example, the user may wish to display two keyframes that are close together and in this case, a smaller value than half the value of imageWidth may be used.","Referring to steps  and ,  shows possible X positions in second viewing area  according to one embodiment. As shown, X positions for the top row keyframes are represented by KF, KF, and KF. The X position calculated for a particular thumbnail image corresponds to upper-left hand coordinate for displaying the particular thumbnail image in the navigation bar. X positions for bottom keyframes are denoted by KF, KF, and KF. The X position for the bottom keyframes corresponds to a position in the middle of each thumbnail image.","Referring back to , server  then calculates a first timestamp for the top row keyframe by multiplying the seconds multiplier, sec_m, with the X position for the top row keyframe (step ). This calculation associates a time in the multimedia information with an X position on the navigation bar. As the X position value increases, the timestamp associated with the X position also increases. Accordingly, each increasing X position value represents a later time point in the stored multimedia information.","Server  then calculates a second timestamp for the bottom keyframe by multiplying the second multiplier, sec_m, with the X position of the bottom key frame (step ). In one embodiment, the X position of the bottom keyframe is the X position of the top keyframe plus half the width of the value of imageWidth. Accordingly, the second timestamp for the bottom keyframe will be for a later time than the timestamp for the top keyframe.","Server  retrieves, from the multimedia document, a top row and bottom row keyframe corresponding to the first and second timestamps calculated as described above (step ). Using the value of the first and second timestamps, which correspond to a time in the multimedia information, top and bottom keyframes are extracted that are closest in time to the timestamps.","A retrieved top row keyframe is then displayed in the corresponding cell position for the top row keyframe (step ). The retrieved bottom row keyframe is also displayed in the corresponding cell position for the bottom row keyframe (step ). The process then reiterates to step , where X positions for top row and bottom row keyframes for corresponding cell positions are determined, new timestamps are calculated, and top row and bottom row keyframes are retrieved for the new timestamps and displayed in the navigation bar at the corresponding cell positions.","In one embodiment, a cell corresponding to each thumbnail image  is an object, such as a JAVA object, including the coordinate information (X position), the keyframe, and the timestamp.",{"@attributes":{"id":"p-0112","num":"0111"},"figref":["FIG. 12","FIG. 7","FIG. 12","FIG. 12"],"b":["1200","306","8","104","102","104","102","104","102","104","102","104"]},"For discussion purposes, the generation of navigation bar  will be described. In this method, the navigation bar is displayed vertically instead of horizontally. Thus, a different seconds multiplier, sec_m, is used that corresponds to duration\/ImageContainerHeight. Also, the Y axis position is used to calculate the keyframes to retrieve and imageHeight is used to determine the right column keyframe to extract.","As depicted in , server  receives a signal to display multimedia information from a stored multimedia information recording on a TV (step ). In response to the signal, server  then accesses multimedia information for display in the interface (step ). As previously stated, the multimedia information may be stored in a multimedia document accessible to server . As part of step , server  may receive information (e.g., a file name of the multimedia document) identifying the multimedia document and the location (e.g., a directory path) of the multimedia document. The user of the present invention may provide the multimedia document identification information. Server  may then access the multimedia document based upon the provided information.","Server  then extracts video information from the multimedia information accessed in step  (step ). In other embodiments, other information, such as text information, whiteboard information, or the like, may be extracted with or in place of the video information.","Server  determines the length of the multimedia information. In one embodiment, the length may be measured in seconds (step ). The variable duration may be initialized to a value representing the length of the multimedia information.","The values for imageHeight and imageContainerHeight are then determined (step ). In one embodiment, the values may be predefined and retrieved from storage subsystem . Also, the values may be predefined and retrieved from any other system assessable to server .","Once the above values are determined, a maximum number of keyframes, maxKeyframes, is calculated (step ). The value maxKeyframes indicates how many keyframes may be displayed in a column on the navigation bar. For discussion purposes, two columns of thumbnail images will be assumed. In one embodiment, the calculation imageContainerHeight\/imageHeight=maxKeyframes is used. In this calculation, the height of navigation bar is divided by the height of a thumbnail image. The value maxKeyframes indicates how many keyframes may be displayed in a column of the navigation bar.","Server  determines an initial layout of cells that correspond to positions in the second viewing area where thumbnail images will be displayed (step ). Each thumbnail is a keyframe extracted from the video information. The cells may be associated with a pixel location in second viewing area .","Server  determines a seconds multiplier, sec_m (step ). In one embodiment, the seconds multiplier may be determined by the calculation sec_m=duration\/imageContainerHeight. Seconds multiplier, sec_m, is used to convert pixel locations in the second viewing area to a corresponding time in seconds in the multimedia information.","Server  determines an Y position in second viewing area  for a left keyframe that corresponds to a cell position in the navigation bar (step ). The Y position corresponds to a pixel location in the second viewing area. For example, the Y position may be the position where thumbnail image in the left column will be displayed on the interface.","Server  determines an Y position in the second viewing area for a right keyframe that corresponds to a cell position in the navigation bar (step ). In one embodiment, the left keyframe is a keyframe extracted at a time Tand the right keyframe is a keyframe extracted from the multimedia information at a time T, where T>T. The Y position corresponds to a pixel location in the second viewing area. For example, the Y position may be where a thumbnail image in the right column will be displayed on the interface.","In one embodiment, the Y position for the right keyframe is calculated as the Y position for the left keyframe in addition to half the value of the imageHeight value, which is half the height of a thumbnail image. It will be understood that other values may be used depending on the keyframe that is to be displayed in the right column. For example, the user may wish to display two keyframes that are close together and in this case, a smaller value than half the value of imageHeight may be used.","Referring to steps  and ,  shows possible Y positions in second viewing area  according to one embodiment. As shown, an Y position for the left column keyframes KF, KF, and KFare shown. The Y position corresponds to an upper left-hand coordinate of the display of thumbnail images. Additionally, the Y position for right column keyframes KF, KF, and KFis shown. The Y position for the right keyframes corresponds to a position in the middle of each thumbnail image  in the left column.","Referring back to , server  then calculates a first timestamp for the left column keyframe by multiplying the seconds multiplier, sec_m, with the Y position for the left row keyframe (step ). This calculation associates a time in the multimedia information with an Y position on the navigation bar. Thus, as the Y position increases, the timestamp also increases correspondingly and multimedia information later in the multimedia document is displayed as the Y position increases.","Server  then calculates a second timestamp for the right keyframe by multiplying the second multiplier, sec_m, with the Y position of the right key frame (step ). In one embodiment, the Y position of the right keyframe is the Y position of the left keyframe plus half the height of the value of imageHeight. Accordingly, the second timestamp for the right keyframe will be for a later time than the timestamp for the left keyframe.","Server  retrieves, from the multimedia document, a left and right keyframe corresponding to the first and second timestamps calculated as described above (step ). Using the value of the first and second timestamps, which correspond to a time in the multimedia information, left and right keyframes are extracted from a time closest in time to the timestamps.","A retrieved left keyframe is then displayed in the corresponding cell position for the left keyframe (step ). The retrieved right keyframe is also displayed in the corresponding cell position for the right keyframe (step ). The process then reiterates to step , where Y positions for left and right keyframes that correspond to cell positions are determined, new timestamps are calculated, and left and right keyframes are retrieved for the new timestamps and displayed in the navigation bar at their corresponding cell positions.","In one embodiment, a cell corresponding to each thumbnail image  is an object, such as a JAVA object, including the coordinate information (Y position), the keyframe, and the timestamp.","It will be understood that any number of rows or columns may be included in a navigation bar. In order to determine the X or Y axis position of each keyframe in the navigation bar, a different increment is calculated depending on the number of rows or columns. In one embodiment, for a vertical navigation bar, such as found in , an increment is equal to the variable imageHeight divided by the number of columns. The increment in  would be imageHeight divided by 4. Keyframes would then be extracted at each increment along the Y axis. The same process may be used if more than two rows of thumbnail images are to be included in a navigation bar. However, the variable imageWidth is divided by the number of rows and the increment is used along the X axis.","One example according to  will now be described. In this example, the multimedia information is a video that is one hour long. Thus, the value for duration=3600. Also, it is assumed that imageContainerWidth=760, imageWidth=36, and imageHeight=26. For one row of keyframes, the maximum number of keyframes is maxKeyframes=imageContainerWidth\/imageWidth=760\/36=21. Thus,  keyframes may be displayed from left to right on the horizontal axis. Assuming there are two rows of keyframes, such as found in ,  key frames in total will be displayed. Additionally, the ordering of keyframes is from top to bottom, and left to right, as explained above.","The second multiplier, sec_m is calculated as sec_m equals duration\/imageContainerWidth=3600\/760=4.7368. The X positions are then determined for thumbnail images . For example, if the following X positions are used, KF=0, KF=18; KF=36, KF=54; and KF=72, KF=90, the corresponding timestamp values are S=0, S=85.26; S=170.52, S=255.78; and S=341.04, S=426.31. The timestamps are calculated by multiplying the seconds multiplier sec_m by the X position.","Using the calculated timestamp for each corresponding position in the navigation bar, server  then retrieves a keyframe closest to that time and displays it in the navigation bar.","An example according to the method described in  will now be described. In this example, imageHeight=26, imageContainerHeight=540, and imageWidth=36.","The seconds multiplier is different in this example because the height of the navigation bar is different. Thus, second multiplier, sec_m=duration\/imageContainerHeight=3600\/540=6.6667.","Assuming the Y position values are KF=0, KF=13; KF=26, KF=39; and KF=52, KF=65, the corresponding timestamps are equal to S=0, S=86.67; S=173.33, S=260; and S=346.67, S=433.33. As described above, the timestamps are calculated as sec_m multiplied by the Y position.","Using the calculated timestamp for each corresponding position in the navigation bar, server  then retrieves a keyframe closest to that time and displays it in the navigation bar.",{"@attributes":{"id":"p-0138","num":"0137"},"figref":["FIG. 14","FIG. 14"],"b":"1400"},"Server  determines if a thumbnail image has been selected (e.g., if a thumbnail in the navigation bar has been highlighted by location box  and the \u201center\u201d button has been selected (step ). If not, the method reiterates to step , where server  determines whether a thumbnail image has been selected again.","If a thumbnail has been selected, server  determines a timestamp corresponding to the selected thumbnail image (step ). According to an embodiment of the present invention, the timestamp corresponding to the selected thumbnail image represents the timestamp associated with the cell in the navigation bar in which the thumbnail image is displayed. The timestamp associated with the selected thumbnail image is then used to reposition playback of the multimedia information displayed in the first viewing area.","Server  then starts playback of multimedia information at the time corresponding to the determined timestamp in the first viewing area (step ). In this case, the playback starts at a position in the stored multimedia information corresponding to the determined timestamp and continues thereon. The process then reiterates to step , where server  monitors for another selected image.","The navigation of the navigation bar will now be described according to one embodiment. In one embodiment, a remote control, such as remote control  depicted in , may be used to navigate or change the location of location box  in the navigation bar. As described above, arrow buttons  may be used to move location box  to different locations in the navigation bar.","As mentioned above, a request signal may be received to move location box in the up, down, left, or right locations. Upon receiving the signal, server  determines if the requested movement is feasible and moves the location box accordingly. The manner in which the request is handled may depend upon the type and layout (e.g., a navigation bar in which the thumbnails are displayed horizontally or vertically, etc.) of the navigation bar displayed on the TV.","Assuming the navigation bar of  is used, if the signal requested moving the location box in a down direction, the location box is moved down from the first row of thumbnails to the second row of thumbnails to a thumbnail image immediately below the current location of location box  in the first row. If the signal requested moving the location box in a right direction, the location box is moved to a thumbnail image in the column next (right of) to the current location of location box . Additionally, if the signal requested moving location box  to the left, location box  is moved to a column to left of the current position of location box . A move is considered not feasible if the location bar has been moved to its limit in any particular direction and a signal is received to further move the location bar in the particular direction. For example, if location box  is positioned over a thumbnail in the leftmost corner, then a request to move the location box to the left is not feasible and would yield no movement at all.","If location box  is located in the bottom row of the navigation bar, a request to move location box down will cause location box  to be moved to the top row of a column next to the current location of location box . The reasoning behind moving location box  to the next column is that the user decides to move location box  to a later time. Also, a request to move location box up will cause location box  to be moved to the bottom row of a column to the left of the current location of location box , if possible.","In the case of a vertically aligned navigation bar, a request to move right would move down the navigation bar row by row until it reached the bottom. Also a request to move in the left direction, would go back up the navigation bar until it reached the top. Additionally, up and down requests are processed as described above.","The above description is illustrative but not restrictive. Many variations of the invention will become apparent to those skilled in the art upon review of the disclosure. The scope of the invention should, therefore, be determined not with reference to the above description, but instead should be determined with reference to the pending claims along with their full scope or equivalents.","Although specific embodiments of the invention have been described, various modifications, alterations, alternative constructions, and equivalents are also encompassed within the scope of the invention. The described invention is not restricted to operation within certain specific data processing environments, but is free to operate within a plurality of data processing environments. Additionally, although the present invention has been described using a particular series of transactions and steps, it should be apparent to those skilled in the art that the scope of the present invention is not limited to the described series of transactions and steps.","Further, while the present invention has been described using a particular combination of hardware and software, it should be recognized that other combinations of hardware and software are also within the scope of the present invention. The present invention may be implemented only in hardware, or only in software, or using combinations thereof.","The specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense. It will, however, be evident that additions, subtractions, deletions, and other modifications and changes may be made thereunto without departing from the broader spirit and scope of the invention as set forth in the claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 9","FIG. 3"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 14"}]},"DETDESC":[{},{}]}
