---
title: Apparatus for adapting virtual gaming with real world information
abstract: A server device that incorporates teachings of the present disclosure may include, for example, a memory and a processor. The processor can identify first and second players present at first and second physical locations, to identify first and second boundary and topographical information of the first and second physical locations, to map the first and second boundary and topographical information of the first and second physical locations to a virtual gaming space, to capture first and second position and orientation information for the first and second players, to map the first and second position and orientation information to the virtual gaming space, to generate first and second virtual players corresponding to the first and second players, and to transmit to first goggles information representative of the second virtual player for display superimposed onto a transparent viewing apparatus for viewing of the virtual gaming space. Additional embodiments are disclosed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09155964&OS=09155964&RS=09155964
owner: STEELSERIES ApS
number: 09155964
owner_city: Valby
owner_country: DK
publication_date: 20110914
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE DISCLOSURE","BACKGROUND","DETAILED DESCRIPTION"],"p":["The present disclosure relates generally to an apparatus for adapting virtual gaming with real world information.","Electronic games are commonly played on gaming systems, such as a controller box coupled to a display screen or a computer device with an integrated display screen (laptop, mobile phone). Gamers typically engage other players on their system or play against computer-generated players. Gamers also frequently play along with other players in Massively Multiplayer On-line (MMO) games in team or individual competition. Gamers can have at their disposal accessories such as a keyboard, a general purpose gaming pad, a mouse, a gaming console controller, a headset with a built-in microphone to communicate with other players, a joystick, a computer display, or other common gaming accessories. Gamers commonly use such accessories to enjoy the gaming experience from their homes while participating in the gaming experienced generated and displayed on their gaming systems.","One embodiment of the present disclosure includes a server device having a memory and a processor. The processor can be operable to identify a first player physically present at the first physical location and a second player physically present at a second physical location. The first and second physical locations can disparate locations. The processor can also be operable to identify first boundary and topographical information of the first physical location and second boundary and topographical information of the second physical location. The processor can further be operable to map the first boundary and topographical information of the first physical location and the second boundary and topographical information of the second physical location to a virtual gaming space. The processor can be operable to capture first position and orientation information for the first player at the first physical location and second position and orientation information for the second player at the second physical location. The processor can also be operable to map the first position and orientation information for the first player and the second position and orientation information for the second player to the virtual gaming space. The processor can be further operable to generate a first virtual player corresponding to the first player and a second virtual player corresponding to the second player. The processor can be operable to transmit to first goggles of the first player information representative of the second virtual player. In turn, the first goggles can display the second virtual player superimposed onto a transparent viewing apparatus for viewing of the virtual gaming space.","One embodiment of the present disclosure includes a computer-readable storage medium including computer instructions. The computer instructions can identify a first player device physically present at a physical location. The computer instructions can also identify boundary and topographical information of the physical location. The computer instructions can further map the boundary and topographical information of the physical location to a virtual gaming space. The computer instructions can generate a virtual structure corresponding to the virtual gaming space. The computer instructions can also capture first position and orientation information for the first player device at the physical location. The computer instructions can map the first position and orientation information for the first player device to the virtual gaming space to generate a first virtual player corresponding to the first player device. The computer instructions can further transmit to the first player device information representative of the first virtual player. In turn, the first player device can display the first virtual player in the virtual structure.","One embodiment of the present disclosure includes a goggle apparatus having a memory and a processor. The processor can be operable to detect first position and orientation information relative to first boundary and topographical information of a first physical location for a first player physically present and wearing the goggle apparatus. The processor can also be operable to receive information representative of a virtual player at a virtual gaming space corresponding to a mapping of second boundary and topographical information of the second physical location and the first boundary and topographical information of the first physical location. The virtual player corresponds to second position and orientation information for a second player physically present at a second physical location. The processor can further be operable to display the virtual player superimposed onto a transparent viewing element for viewing of the virtual gaming space.",{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIGS. 1A","b":["1","2","2","3"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIGS. 4-6","FIGS. 1-3"],"b":["400","600","400","402","404"]},"In the present context, an accessory can represent any type of device which can be communicatively coupled to the computing device and which can control aspects of the OS and\/or a software application operating in the computing device. An accessory can represent for example a keyboard, a gaming pad, a mouse, a gaming console controller, a joystick, a microphone, or a headset with a microphone\u2014just to mention a few. An accessory can also represent for example, gaming goggles or apparel with sensors.","The keyboard and gaming pad represent accessories of a similar category since their operational parameters are alike. A mouse, on the other hand, represents an accessory having disparate operational parameters from the keyboard or gaming pad. For instance, the operational parameters of a keyboard generally consist of alphanumeric keys, control keys (e.g., Shift, Alt, Ctrl), and function keys while the operational parameters of a mouse consist of navigation data generated by a tracking device such as a laser sensor, buttons to invoke GUI selections, and settings thereof (e.g., counts or dots per inch, acceleration, scroll speed, jitter control, line straightening control, and so on). Such distinctions can be used to identify disparate categories of accessories. The joysticks, game controllers or any other input devices represent additional categories of accessories supported by the AMS.","In step , the AMS application presents a GUI  such as depicted in  with operationally distinct accessories such as the keyboard  and mouse . The GUI  presents the accessories - in a scrollable section . One or more accessories can be selected by a user with a common mouse pointer. In this illustration, the keyboard  and mouse  were selected with a mouse pointer for customization. Upon selecting the keyboard  and mouse  in section , the AMS application can present the keyboard  and mouse  in split windows , , respectively, to help the user during the customization process. Alternatively, gaming goggles  and a headset  can be selected and presented in the split windows  and , respectively. For example, the selected gaming goggles  can include buttons \u201cA\u201d , \u201cB\u201d , \u201cC\u201d , and \u201cD\u201d  and a viewing apparatus \u201c\u201d. The viewing apparatus  can utilize, for example, liquid crystal display technology to superimpose virtual gaming information (e.g., avatar representative of another player, virtual objects or obstructions, etc.) onto a transparent viewing display which enables a gamer to see real-world objects in a location of the gamer.","In step , the AMS application can be programmed to detect a user-selection of a particular software application such as a game. This step can be the result of the user entering in a Quick Search field  the name of a gaming application (e.g., World of Warcraft\u2122). Upon identifying a gaming application, the AMS application can retrieve in step  from a remote or local database gaming application actions which can be presented in a scrollable section  of the GUI represented as \u201cActions\u201d . The actions can be tactical actions , communication actions , menu actions , and movement actions , or any other types of actions, which can be used to invoke and manage features of the gaming application.","The actions presented descriptively in section  of the GUI can represent a sequence of accessory input functions which a user can stimulate by button depressions, navigation or speech. For example, depressing the left button on the mouse  can represent the tactical action \u201cReload\u201d, while the simultaneous keyboard depressions \u201cCtrl A\u201d can represent the tactical action \u201cMelee Attack\u201d. For ease of use, the \u201cActions\u201d  section of the GUI is presented descriptively rather than by a description of the input function(s) of a particular accessory.","Any one of the Actions  can be associated with one or more input functions of the accessories by way of a simple drag and drop action. For instance, a user can select a \u201cMelee Attack\u201d by placing a mouse pointer  over an iconic symbol associated with this action. Upon doing so, the symbol can be highlighted to indicate to the user that the icon is selectable. At this point, the user can select the icon by holding the left mouse button and drag the symbol to any of the input functions (e.g., buttons) of the keyboard  or mouse  to make an association with an input function of one of these accessories.","For example, the user can drag the Melee Attack symbol to the right mouse button thereby causing an association between the selection of the right mouse button and the gaming action of a Melee Attack. When the right button of the mouse  is selected during normal operation, the AMS application can detect the selection as a \u201ctrigger\u201d to generate the key sequence \u201cCtrl A\u201d which is understood by the gaming application as request for a Melee Attack. The gaming application receives from the AMS application by way of an operating system the \u201cCtrl A\u201d sequence as if it had been generated by a Qwerty keyboard.","As another example, the user can associate a function with button \u201cA\u201d  on the gaming goggles . For instance the user can select the \u201cTeam Chat\u201d function under the \u201cComm\u201d subsection  of the \u201cActions\u201d section  section of the GUI. The \u201cTeam Chat\u201d icon can be selected by holding down a mouse button and dragging the icon symbol to the \u201cA\u201d button  on the gaming goggles  to thereby associate presses of the \u201cA\u201d button  with the \u201cTeam Chat\u201d function. During a game, the AMS application can detect pressing of the \u201cA\u201d button  and substitute the \u201cTeam Chat\u201d function. In another example, the user can use the AMS application to associate a key press on the headset  or on a gaming accessory , such as a virtual gaming gun , with a gaming function. The user can use the AMS application to associate a single button press on the gaming goggles , the headset , or the gaming accessory  to a single substitute function or to a series of substitute functions.","With this in mind, attention is directed to step  where the AMS application can respond to a user selection of a profile. A profile can be a device profile or master profile invoked by selecting GUI button  or , each of which can identify the association of actions with input functions of one or more accessories. If a profile selection is detected in step , the AMS application can retrieve macro(s) and\/or prior associations of actions with the accessories as defined by the profile. The actions and\/or macros defined in the profile can also be presented in step  by the AMS application in the actions column  of the GUI  to modify or create new associations.","In step , the AMS application can also respond to a user selection to create a macro. A macro in the present context can represent a subset of actions that can be presented in the Actions column . Any command which can be recorded by the AMS application can be used to define a macro. A command can represent a sequence of input functions of an accessory, identification of a software application to be initiated by an operating system (OS), or any other recordable stimulus to initiate, control or manipulate software applications. For instance, a macro can represent a user entering the identity of a software application (e.g., instant messaging tool) to be initiated by an OS. A macro can also represent recordable speech delivered by a microphone singly or in combination with a headset for detection by another software application through speech recognition or for delivery of the recorded speech to other parties. In yet another embodiment a macro can represent recordable navigation of an accessory such as a mouse or joystick, recordable selections of buttons on a keyboard, a mouse, a mouse pad, a pair of gaming goggles, or a gaming accessory, and so on. In another embodiment, macros can be Macros can also be combinations of the above illustrations. Macros can be created from the GUI  by selecting a \u201cRecord Macro\u201d button . The macro can be given a name and category in user-defined fields  and .","Upon selecting the Record Macro button , a macro can be generated by selection of input functions on an accessory (e.g., Ctrl A, speech, etc.) and\/or by manual entry in field  (e.g., typing the name and location of a software application to be initiated by an OS). Once the macro is created, it can be tested by selecting button  which can repeat the sequence specified in field . The clone button  can be selected to replicate the macro sequence if desired. Fields  can also present timing characteristics of the stimulation sequence in the macro with the ability to customize such timing. Once the macro has been fully defined, selection of button  records the macro in step . The recording step can be combined with a step for adding the macro to the associable items Actions column , thereby providing the user the means to associate the macro with input functions of the accessories.","In step , the AMS application can respond to drag and drop associations between actions and input functions of the keyboard  and the mouse . If an association is detected, the AMS application can proceed to step  where it can determine if a profile has been identified in step  to record the association(s) detected. If a profile has been identified, the associations are recorded in said profile in step . If a profile was not been identified in step , the AMS application can create a profile in step  for recording the detected associations. In the same step, the user can name the newly created profile as desired. The newly created profile can also be associated with one or more software applications in step  for future reference.","The GUI  presented by the AMS application can have other functions. For example, the GUI  can provide options for layout of the accessory selected (button ), how the keyboard is illuminated when associations between input functions and actions are made (button ), and configuration options for the accessory (button ). Configuration options can include operational settings of the mouse  such as Dots-per-Inch or Counts-per-Inch, and so on. The AMS application can adapt the GUI  to present more than one functional perspective. For instance, by selecting button , the AMS application can adapt the GUI  to present a means to create macros and associate actions to accessory input functions as depicted in . Selecting button  can cause the AMS application to adapt the GUI  to present statistics in relation to the usage of accessories as depicted in , B, and . Selecting button  can cause the AMS application to adapt the GUI  to present promotional offers and software updates.","It should be noted that the steps of method  in whole or in part can be repeated until a desirable pattern of associations of actions to input functions of the selected accessories has been accomplished. It would be apparent to an artisan with ordinary skill in the art that there can be numerous other approaches to accomplish similar results. These undisclosed approaches are contemplated by the present disclosure.",{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 5","b":["500","400","500","502","504"]},"In step  the AMS application can receive instructions describing all or a portion of the input functions of the unknown accessory. These instructions can come from a user who defines each input function individually or responds to inquiries provided by the AMS application. The AMS application can for example make an assumption as to a keyboard layout and highlight each key with a proposed function which the user can verify or modify. Once the AMS application has been provided instructions in step , the AMS application can create an accessory identity in step  which can be defined by the user. In steps  and , the AMS application can associate and record the accessory instructions with the identity for future recognition of the accessory. In step , the AMS application can present a depiction of the new accessory with its identity along with the other selectable accessories in section .","Method  can provide a means for universal detection and identification of any accessory which can be used to control or manage software applications operating in a computing device.",{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 6","b":["600","600","602"]},"Once one or more stimulations have been detected in step , the AMS application can proceed to step  to determine if action(s) have been associated with the detected stimulation(s). If for example the stimulations detected correspond to keyboard and mouse button depressions, the AMS application can determine if actions have been associated and recorded for such stimulations. If these stimulations \u201ctrigger\u201d one or more actions, the AMS application can proceed to step  where it retrieves the stimulation definition of these actions for each accessory reporting a stimulation event. In step , the AMS application can substitute the detected stimulations with the stimulations defined by the action.","To illustrate this substitution, suppose for example that the detected stimulation was \u201cCtrl A\u201d simultaneously depressed on a keyboard. Suppose further that an action associated with this stimulus consists of a macro that combines mouse clicks with a navigation of the mouse (e.g., moving the mouse quickly in a forward motion for a given distance), and a request to invoke an instant messaging (IM) session with a particular individual using Skype\u2122 or some other common IM tool. In step , the AMS application would substitute \u201cCtrl A\u201d for stimulations consisting of the mouse clicks, navigation and a request for an IM application. The substitute stimulations would then be reported in step  to an operating system (OS). As another example, suppose that the detected stimulation was a \u201cC\u201d button  depressed on an input interface of the gaming goggles . Suppose further that an action associated with this stimulus consists of a macro that combines a function to display a mapping indicator showing location of a teammate player on a viewing apparatus  of the gaming goggles  and a function to activate a gaming accessory . In step , the AMS application would substitute the \u201cC\u201d button  for stimulations to perform the substituted functions and report these stimulations to the +.","In step , the OS can determine whether to pass the substitute stimulations to an active software application in operation (e.g., a gaming application) and\/or to invoke another software application. The active software application can be operating from the same computer system from which the OS and the AMS application operate or can be operating at a remote system such as an on-line server or family of servers (e.g., World of Warcraft) awaiting stimulation data from the computer system. In this illustration, the macro comprises both stimulation feedback for the active software application and a request to initiate an IM session. Accordingly, in the first example, the OS conveys in step  the mouse stimulation signals to the active software application (e.g., gaming application), and in a near simultaneous fashion invokes the IM session in step  with a specific individual (or organization). In the second example, the OS conveys in step  the stimulation signals to the active software application for the game to cause display of the teammate map on the viewing apparatus  of the pair of gaming goggles  and to activate the gaming accessory .","Referring back to step , the illustrations above cover a scenario in which the AMS application has detected an association of actions to accessory stimuli. If however the AMS application does not detect such an association, then the detected stimulus (or stimuli) supplied by one or more accessories is transmitted to the OS in step . For example, it may be that a stimulation based on the depressions of \u201cCtrl A\u201d has no particular association to an action. In this case, the AMS application passes this stimulation to the OS with no substitutes. In step  the OS can determine if this stimulation invokes a new software application in step  or is conveyed to the previously initiated software application.","Contemporaneous to the embodiments described above, the AMS application can also record in step  statistics relating to the detected accessory stimulations. A portion of the AMS application can operate as a background process which performs statistical analysis on the stimulations detected. By selecting button  in , the AMS application can provide an updated GUI which illustrates the usage of input functions of one or more accessories for which stimulations were detected in step . A keyboard accessory is shown in . In this illustration, certain keys (references , , , ) on the keyboard are color-coded to illustrate the frequency of usage of these keys. A color scale  defines the frequency of usage of the input functions of the keyboard. The first end of the scale (navy blue) represents a single detected depression, while an opposite end of the scale (bright red) represents 500 detected depressions. Based on this scale, the AMS application maps by color in step  stimulations of the keyboard. For example, the key grouping  depict a color coding with the highest detectable usage, while the F7 key (reference ) indicates the fewest depressions. Keys having zero depressions are not color coded to readily identify the color mapping of keys which were used at least once. In , gaming goggles  is shown. Buttons , , , and  on the gaming goggles are color-coded to illustrate the frequency of usage of these buttons. In this example, the \u201cC\u201d button  is depicted by a color coding showing the highest detectable usage, while the \u201cA\u201d button  indicates the fewest depressions. Keys having zero depressions, such as the \u201cB\u201d button , are not color coded to readily identify the color mapping of keys which were used at least once.","The AMS application provides additional functions in a playback panel of the GUI which can help a user understand how the color coded keys were used during an active software application such as a video game. In this section of the GUI, the AMS application can present the user with a playback control function  which the user can select to replay, pause, forward or rewind the usage of these keys. When usage playback is selected, the user can for instance see the color coded keys highlighted in real-time with a temporary white border to visualize how the keys were selected. A time clock  provides the user the elapsed time of the playback sequence. Button  allows the user to retrieve statistics from other sessions, while button  provides the user a means to save statistics from a given session.","The GUI of  could have been shown as a split screen with all accessories which generated one or more detected stimulations (e.g., keyboard, mouse, and microphone), each providing statistical symbolic results as described above for the keyboard. Although not shown, split screen embodiments are contemplated by the present disclosure for the GUI of .","In addition to a symbolic representation as shown in , the AMS application can provide the user a means to visualize raw statistics in a table format such as shown in  by selecting button . The table format shows raw data in section  and possible suggestions in section  for improving user performance which can be generated by the AMS application in step . Section  can be presented in a table format with a column identifying the key being analyzed, its usage, and number of key presses. The user can ascertain from this table the most and least frequently used keys as well as other identifiable patterns.","The AMS application can utilize an understanding of the layout of the accessory (in this case, the keyboard) to determine from the statistics ways that the user can improve response time or ergonomic use. For example, the AMS application can determine from a layout analysis that the key combination <Alt .> can be reassigned to a macro based on the trigger <Ctrl F> which could provide the user a faster response time and free up the user's right hand for other tasks. The AMS application can also provide alternative suggestions. For example, the AMS application can also suggest creating single button macros for each of the key combinations <Alt .> and <Ctrl A> which can be assigned to keys on the keyboard or left and right buttons of a mouse. The latter suggestion of assigning macros to the mouse can help the user free up his\/her left hand.","The AMS application can utilize present and next generation algorithms to determine how to improve response times and ergonomic usage of accessory devices. The AMS application can for example have at its disposal an understanding of the layout of each accessory, the type of software being controlled by the accessory (e.g., World of Warcraft), type of operations commonly used to control the software (e.g., known actions as shown in the actions column  of ), an understanding of the associations made by other users (e.g., gamers) to improve their performance when controlling the software, and so on. The AMS application can also be operable to communicate with the active software application by way of an Application Programming Interface (API) to receive additional usage statistics from the software which it can in turn use to improve the user's performance. The AMS application can also utilize common statistical and behavior modeling techniques to predict the behavior of the user and responses from the software application to identify possible ways to improve the user's performance.","From these illustrations, it would be apparent to an artisan of ordinary skill in the art that innumerable algorithms can be developed to analyze accessory usage and thereby suggest improvements. These undisclosed embodiments are contemplated by the present disclosure.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 7","b":["700","700","730","730","782","730","790","790","730","788","730","784","786","782","784","730"]},"The gaming server  can be in communication with physical locations  and . The physical locations  and  can be equipped as virtual gaming spaces. For example, each physical location  and  can have mobility networks  and  capable of communicating wirelessly with gaming devices  and  used in the respective physical locations  and . The physical locations  and  can be at disparate locations (e.g., first gaming center in New York, second gaming center in Chicago). The gaming devices  and  at the physical locations  and  can include gaming goggles  and  with keypad buttons  and , Global Positioning Satellite (GPS) sensing devices  and , headsets with microphones  and , gaming vests  and , and gaming accessories  and . Any or all of the gaming devices  and  of the first and second physical locations  and  can communicate with the gaming server  via the first and second mobility networks  and . The gaming devices  and  of the first and second physical locations  and  can also communicate with the gaming server  via infrared sensing devices  and . The gaming server  can further communicate with the gaming devices  and  at the first and second physical locations  and  via satellite . The gaming server  can communicate with any number of other physical locations and\/or with multiple gaming accessories for multiple players at each physical location.","The gaming server  can acquire the boundary and topological information from a database or can acquire the information by collecting GPS information from locations in the first and second physical location  and  over the first and second mobility networks  and . The gaming accessories at each physical location  and  can be worn and\/or used by players to allow the gaming server  to track player movements and player actions. For example, the gaming server  can track movements of players at the first and second physical locations  and  who are wearing GPS sensing devices  and . As the players move around the locations  and , the GPS sensing devices  and  can detect changes in player positions relative to the boundary and topological information of the physical locations  and  as identified by the gaming server . As another example, the gaming goggles  and  can include GPS sensing apparatus to allow the goggles to acquire the current positions of the players as the players move about the physical locations  and . The GPS sensing devices  and  and goggles  and  can include wireless communication capabilities, such as wireless cellular or infrared.","The gaming devices  and  can also include other sensory devices such as gyroscopes, compasses, accelerometers, level detectors, diode arrays, infrared detectors and\/or antennas, which can provide the gaming server  orientation, altitude, and location coordinates, as well as velocity, acceleration and\/or trajectory information. The gaming devices  and  can use these sensory devices to detect and report positioning and orientation information to the gaming server . For example, the gaming goggles  and  can use any or several of these sensory devices to determine orientation of a wearing player's head. By determining the player's head orientation, the gaming goggles  and  can allow the gaming server  to determine the physical and virtual field of view of the player.","The foregoing embodiments are a subset of possible embodiments contemplated by the present disclosure. Other suitable modifications can be applied to the present disclosure.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 8","b":["800","810","850","810","850","818","858","822","862","818","858","822","862","810","850","822","862","810","850","822","862","730","822","862","822","862","810","850"]},"The gaming server  can verify that the resulting first and second physical locations  and  are configured identically, or nearly identically, so a player at the first gaming space will experience exactly the same boundary and topographic limitations as a player at the second gaming space. Because the first and second gaming spaces  and  are of the same size and physical configuration, the gaming server  can map the boundary and topographical data that describes the two locations into a single gaming space, which is defined as the virtual gaming space that is common to both the first physical location  and the second physical location .","A first player  can physically enter the first gaming space . The gaming server  can recognize the presence and location of the first player  by, for example, communicating with gaming devices  and  worn or carried by the first player . For example, the first player  can wear gaming goggles  that include two-way communication capabilities between the goggles  and the gaming server . The communications may be directly between the gaming server  and goggles  or may be via another server device coupled directly to the first gaming space  and in communication with the gaming server . The gaming server  can identify the presence and location of the first player  through other means, such as wireless or infrared communications with the gaming goggles , a GPS sensing device  that may be a stand-alone device or that may be integrated into another gaming device, a headset device , a gaming vest , or a gaming accessory , such as a gun. The gaming server  can collect information based on other sensory devices, such as gyroscopes, compasses, accelerometers, level detectors, diode arrays, infrared detectors and\/or antennas, to detect position and orientation information for the first player  as this player moves about in the first gaming space . Similarly, the gaming server  can identify presence, position, and orientation information for a second player  who has entered the second gaming space  using similar sensors of the second player .","The gaming server  can further map the position and orientation information for the first player , who is physically at the first physical location , onto the boundary and topographical information for the first physical location . The gaming server  can also map the first player's position and orientation information on to a virtual gaming space. Similarly, the gaming server  can map the position and orientation information for the second player, who is physically located at the second physical location , onto the virtual gaming space. By mapping the second player  onto the virtual gaming space, the first and second players ,  can be present, virtually, in the virtual gaming space. Further, the first gaming goggles  worn by the first player  can be capable of superimposing video and still images onto a transparent viewing apparatus. The gaming server  can provide to the first gaming goggles  a virtual video or still image of the second player  or information that can be used to produce such a video or still image. When the first player  looks though the gaming goggles , the first player  sees the second player  virtually present at his first gaming location . Similarly, the gaming server  can provide a video or still image of the first player  to the gaming goggles  worn by the second player . In this way, the first server  can allow the first player  and the second player  to see their counterpart as a virtual player in their respective physical gaming space,  and , even if the two players are physically separated by great distances.","The gaming server  can also identify the other players physically present at the first or second gaming spaces  and . For example, a third player  can be physically present at the second gaming space . The third player  can be allied with either, or both, of the first and second players  and  in a virtual game or with neither of them. The gaming server  can track the position and orientation for the third player . For example, if the third player  is physically present at the first gaming space , then the gaming server  can map the physical position and orientation information for the third player  to the virtual gaming space. Information for a virtual third player  can be generated and sent to the gaming goggles  of the first player . The virtual third player  can be superimposed onto the transparent viewing apparatus of the gaming goggles  and  so that the first player  can see the virtual third player  in his field of view.","The gaming server  can detect a computer player that is attempting to join a virtual game at the virtual gaming space formed by mapping the first and second gaming spaces  and . A computer player  is a player that is controlled by a user at a computer device , mobile device , or gaming controller . The computer player  does not exist as a physical player and so is only available on the virtual gaming space as a virtual computer player  at the first game space  and the computer player  at the second game space . The virtual computer player  and  can be visible to the first and second players  and  through their gaming goggles  and  according to information supplied by the gaming server . The information supplied by the gaming server  can include an avatar representative of the computer player , and coordinate and orientation information to describe the movements, orientation and positioning of the computer player . The gaming server  can also detect a computer-generated player. The computer-generated is controlled by the virtual game running at computer device , mobile device , gaming controller , or the gaming server  and does not exist as a physical player. The computer-generated player is only available on the virtual gaming space as a virtual computer player. The virtual computer-generated player  and  can be visible to the first and second players  and  through their gaming goggles  and  according to information describing the computer-generated player. The information supplied by the gaming server  can include an avatar representative of the computer-generated player, and coordinate and orientation information to describe the movements, orientation and positioning of the computer-generated player.",{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 9","b":["900","910","910","910","730","920","730","930","910","730","730","910","940","910","940","940"]},"The gaming server  can detect the presence of one or more players  and  in the gaming location, who indicate a desire to play a virtual reality game in a virtual gaming space based on the physical space . The players  and  can be using computer devices , mobile devices , or gaming controllers  to access the virtual reality game. For example, one or more people can be accessing mobile devices  while at a library. The one or more people enter a virtual reality gaming application hosted, for example, by the gaming server  at the library. The gaming server  maps the airport terminal boundaries and topography to a virtual structure corresponding to an ancient castle , as shown. The gaming server  sends video or still images of the virtual structure  to the mobile devices  of the first and second players  and .","The gaming server  can also track the position and orientation of the first and second players  and . For example, the gaming server  can track GPS coordinates based on GPS sensing devices  and  of the players. The mobile devices  can be used to track player movements where these devices are capable of GPS detection and reporting. In another example, the players  and  do not physically move about at the physical location . Rather, the players move only in the virtual structure  as displayed on their mobile devices . In another example, a series of Wireless Fidelity (Wi-Fi) hotspots are distributed throughout the physical location . As the players  and  move about in the physical location, their mobile devices  can experience changing wireless signal strengths from the various Wi-Fi hotspots. For example, as the first player  carries a mobile device  closer to a one Wi-Fi hotspot, the signal strength of that hotspot can increase at the mobile device . In turn, signal strength between the same mobile device  and a different Wi-Fi hotspot can be decreasing. The gaming server  can capture data from the mobile devices  corresponding to the changing relative signal strengths of the different Wi-Fi hotspots. The gaming server  can interpolate the relative signal strengths and utilizing triangulation techniques based on the known locations of the hot spots to determine positioning of the mobile devices  throughout the physical location .",{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIGS. 10-12","FIGS. 1-7","FIG. 8"],"b":["1000","1200","1000","1200","1004","730","814","810","854","850","810","850","810","850","810","850"]},"In step , the gaming server  can identify boundary information  and topographical information  for the first physical location  and second boundary information  and topographical information  for the second physical location . In one example, the gaming server  can acquire the boundary and topological information  from a database. In another example, the gaming server  can acquire the boundary information  and topographical information  by collecting GPS information from the first and second physical location  and  over the first and second mobility networks  and .","In step , the server can control configurable deployment of physical objects  and  at the first and second physical locations  and . The physical objects and structures  and  of the first and second locations  and  can be selectively added or removed. In one example, the gaming server  can control placement or removal of physical objects and structures either directly or through a sub-server operating at the physical location. In one example, active structures and objects  and  can be raised above or lowered onto playing surfaces of the first and second locations  and . This approach can be well-suited to spaces located inside of buildings. In a first configuration, for example, first structures and objects  are lowered into placed onto the first gaming space , while second structures and objects are lifted and removed from the gaming space . To maintain consistency between the first and second locations  and , the setup of objects and structures must be the same for the first and second locations  and . In one example, the unused objects and structures are lowered and stored below the playing surface.","In step , the gaming server  can map the first boundary and topographical information of the first physical location  and the second boundary and topographical information of the second physical location  to a virtual gaming space. Because the first and second gaming spaces  and  are of the same size and physical configuration, the gaming server  can map the boundary and topographical data that describes the each of the locations  and  into a single gaming space. The gaming server  defines this single gaming space as a virtual gaming space. When a game is played by the first and second players  and , and another of the other participants, all of the virtual aspects of the game are referenced from the virtual gaming space. If a computer player  and  joins the game, then the location of a virtual computer player, who represents the computer player for purposes of the game, is references to the virtual gaming space. In this way, a single virtual game can be played involving multiple physical players at multiple physical locations and including a multiple computer players and computer-controlled players. All of the computer devices , mobile devices , gaming controller , and player game devices ,  for all of the participating players can be referenced to a common, virtual gaming space.","In step , the gaming server  can generate virtual objects  and  distributed within the virtual gaming space. The gaming server  can generate a wide-variety of backgrounds and images of objects within the virtual gaming space that can be seen by the players via the gaming goggles  and .","In step , the gaming server  can capture first position and orientation information for the first player  at the first physical location  and the second position and orientation information for the second player  at the second physical location . The gaming server  can recognize the presence and location of the first player  by, for example, communicating with gaming devices  and  worn or carried by the first player . For example, the first player  can where a pair of gaming goggles  that include two-way communication capabilities between the goggles  and the gaming server . The communications may be directly between the gaming server  and goggles  or may be via another server device coupled directly to the first gaming space  and in communication with the gaming server . The gaming server  can identify the presence and location of the first player  through other means, such as wireless or infrared communications with the gaming goggles , a GPS sensing device  that may be a stand-alone device or that may be integrated into another gaming device, a headset device , a gaming vest , or a gaming accessory , such as a gun. The gaming server  can further collect information based on other sensory devices, such as gyroscopes, compasses, accelerometers, level detectors, diode arrays, infrared detectors and\/or antennas, to detect position and orientation information for the first player  as this player moves about in the first gaming space . Similarly, the gaming server  can identify presence, position, and orientation information for a second player  who has entered the second gaming space .","In step , the gaming server  can map the first position and orientation information for the first player and the second position and orientation information for the second player to the virtual gaming space to generate a first virtual player corresponding to the first player and a second virtual player corresponding to the second player. Since the first physical location  can be mapped to a virtual gaming space, the gaming server  can map the first player's position and orientation information on to the virtual gaming space. Similarly, the gaming server  can map the position and orientation information for the second player, who is physically located at the second physical location , onto the virtual gaming space. By mapping the second player  onto the virtual gaming space, the second player  can also be present, virtually, in the virtual gaming space.","In step , the gaming server  can capture an image of the first or second player  and . If the image is captured and available for use, then gaming server  can adapt this image to generate a virtual player  and  in step . In one example, the gaming server  can adapt movements of the virtual player  and  to mimic movements of the physical player  and  represented by the virtual player.","In step , the gaming server  can identify another player playing at a computer device , mobile device , or gaming controller . If a computer player is identified, then, in step , the gaming server  can map position and orientation from the computer player to the virtual gaming space to generate a virtual computer player  and .","In step , the gaming server  can identify a computer-controlled player that is being commanded by a software application at a computer device , mobile device , or gaming controller . If a computer-controlled player is identified, then, in step , the gaming server  can map position and orientation from the computer-controlled player to the virtual gaming space to generate a virtual computer-controlled player  and .","In step , the gaming server  can detect any virtual objects  and  that would virtually obstruct at least a part of a view of one of the virtual players a perspective of another of the virtual players. If such a virtual object  and  obstruction is detected, then, in step , the gaming server  superimposes the identified part of the obstructing virtual object  and  at a display of the goggles  and\/or  if the virtual object is in a line of site of the players wearing these goggles, thereby causing a visual obstruction as if the object were in the location of the player(s).","In step , the gaming server  can capture activation and targeting information for a gaming accessory  of a player physically present at the first location . If activation is captured, then, in step , the gaming server  can map the activation and targeting information of the gaming accessory  to the virtual gaming space to generate virtual activation and targeting information. If the gaming server  determines a virtual effect from the virtual activation and targeting of the gaming accessory, in step , then the gaming server  can update the virtual effect in step . For example, in the case of a user targeting an opposing player a determination can be made by the gaming server  as to whether the opposing player was virtually hit. The gaming server  or the gaming accessory  can then transmitting a message to the opposing player's goggles or gaming accessory indicating that the virtual hit.","In step , the gaming server  can capture movement information for a physical accessory of a player  physically present at a physical location . If movement information for the physical accessory is captured, then, in step , the gaming server  can map the captured movement information of the physical accessory to the virtual gaming space to generate a virtual movement for the physical accessory. For example, the first player  can carry a physical accessory, such a as shield. If the first player  moves the physical shield to conceal himself from the view of the second player , in the virtual gaming space, then the gaming server  can detect the movement and position of the shield and map this movement and position to virtual gaming space such that the virtual first player is shield from the view of the second player (as seen through the gaming goggles  of the second player  according to information supplied by the gaming server  to the gaming goggles ). In step , the gaming server  can determine a virtual effect, if any, from the virtual movement of the physical accessory and the gaming server  can update the virtual effect in step .","In step , the gaming server  can transmit to the goggles  of a physical player , such as first physical player  at a first physical location , information representative of a virtual player , such as the virtual player  representing the second player, who is physically present at the second location  but only virtually present a the first location . The first goggles  display the second virtual player  superimposed onto a transparent viewing apparatus for viewing of the virtual gaming space. The gaming server  also can transmit to the goggles  information representative of virtual objects and virtual effects (e.g., shots being fired at one of the players as seen by the goggles of the targeted player based on virtual effect information supplied by the gaming server  to the goggles of the targeted player). The gaming server  can transmit streaming video to the goggles  representing virtual objects, effects, and players.","In step , the gaming server  can determine if it has received a request for communication between a first player and a second player. If a request is received in step , then the gaming server  can initiate a communications link between a first player and a second player. In one example, communications between players can be initiated by a depressing button on the gaming goggles  or on the headset . The gaming server  can detect the request and establish the necessary communications link. In one example, the gaming server  can route communications between a headset  of a first player and a headset  or a mobile device  of a second player by using one or more mobility networks , , and . In step , the gaming server  can receive messages from the first player and the other player. In step , the gaming server  can send messages to the first player and the other players.","In one embodiment, the gaming location can be a single physical space where multiple players are present, as depicted in the physical location  of . The gaming server  can identify first and second players  and  physically present at the physical location , who indicate a desire to play a virtual reality game in a virtual gaming space based on the physical space . The players  and  can use computer devices , mobile devices , or gaming controllers  to access a virtual reality game based in the single physical location . A virtual reality gaming application can hosted at the physical location  by the gaming server  or by another computer device. The gaming server  can identify boundary and topographical information for the physical location  and can further identify topographical features , such as the location walls, rooms, stairways, and large objects, within the physical space . The gaming server  can then map the boundary and topographical information of the physical location  to a virtual gaming space .","The gaming server  can also generate a virtual structure  corresponding to a visually interesting, virtual gaming space. For example a physical library building  can be mapped to a virtual castle , as shown. The virtual gaming space  can be a geological feature, such as a mountain, cave, or underwater world. The gaming server  can send video or still images of the virtual structure  to the mobile devices  of the first and second players  and . In step , the gaming server  can generate virtual objects within the virtual structure .","The gaming server  can capture and track position and orientation information for the first and second players  and  at the physical location . In another example, the virtual game can be structured such that the players  and  do not physically move about at the physical location . Rather, the players move only as virtual players within the virtual structure  as displayed on the players' computer devices  or mobile devices .","From the foregoing descriptions, it would be evident to an artisan with ordinary skill in the art that the aforementioned embodiments can be modified, reduced, or enhanced without departing from the scope and spirit of the claims described below. In one embodiment, the gaming server  can use a wireless devices distributed throughout a physical location to provide position information for players. The gaming server  can initiate several wireless communications links between a first player device, such as a mobile device, and wireless devices, such as a series of Wireless Fidelity (Wi-Fi) hotspots, in the virtual gaming space. The gaming server  can receive wireless signal strength readings from the mobile devices corresponding to the several wireless communications links established for the players' devices. As players move about in the physical location, their mobile devices can experience changing wireless signal strengths from the various Wi-Fi hotspots. The gaming server  can capture data from the mobile devices corresponding to the changing relative signal strengths of the different Wi-Fi communication links and can interpolate the relative signal strengths as against the known locations of the hot spots to determine positioning and orientation of the mobile devices.","In another embodiment, the gaming server  can consult a database holding boundary and topographical feature information for well-known locations, such as airports, malls, theme parks, museums, libraries, and parks. The gaming server  can use the database boundary and topographical feature information as a basis for generating a virtual gaming space.",{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 13","b":"1300"},"The machine may comprise a server computer, a client user computer, a personal computer (PC), a tablet PC, a laptop computer, a desktop computer, a control system, a network router, switch or bridge, or any machine capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that machine. It will be understood that a device of the present disclosure includes broadly any electronic device that provides voice, video or data communication. Further, while a single machine is illustrated, the term \u201cmachine\u201d shall also be taken to include any collection of machines that individually or jointly execute a set (or multiple sets) of instructions to perform any one or more of the methodologies discussed herein.","The computer system  may include a processor  (e.g., a central processing unit (CPU), a graphics processing unit (GPU, or both), a main memory  and a static memory , which communicate with each other via a bus . The computer system  may further include a video display unit  (e.g., a liquid crystal displays (LCD), a flat panel, a solid state display, or a cathode ray tube (CRT)). The computer system  may include an input device  (e.g., a keyboard), a cursor control device  (e.g., a mouse), a disk drive unit , a signal generation device  (e.g., a speaker or remote control) and a network interface device .","The disk drive unit  may include a machine-readable medium  on which is stored one or more sets of instructions (e.g., software ) embodying any one or more of the methodologies or functions described herein, including those methods illustrated above. The instructions  may also reside, completely or at least partially, within the main memory , the static memory , and\/or within the processor  during execution thereof by the computer system . The main memory  and the processor  also may constitute machine-readable media.","Dedicated hardware implementations including, but not limited to, application specific integrated circuits, programmable logic arrays and other hardware devices can likewise be constructed to implement the methods described herein. Applications that may include the apparatus and systems of various embodiments broadly include a variety of electronic and computer systems. Some embodiments implement functions in two or more specific interconnected hardware modules or devices with related control and data signals communicated between and through the modules, or as portions of an application-specific integrated circuit. Thus, the example system is applicable to software, firmware, and hardware implementations.","In accordance with various embodiments of the present disclosure, the methods described herein are intended for operation as software programs running on a computer processor. Furthermore, software implementations can include, but not limited to, distributed processing or component\/object distributed processing, parallel processing, or virtual machine processing can also be constructed to implement the methods described herein.","The present disclosure contemplates a machine readable medium containing instructions , or that which receives and executes instructions  from a propagated signal so that a device connected to a network environment  can send or receive voice, video or data, and to communicate over the network  using the instructions . The instructions  may further be transmitted or received over a network  via the network interface device .","While the machine-readable medium  is shown in an example embodiment to be a single medium, the term \u201cmachine-readable medium\u201d should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and\/or associated caches and servers) that store the one or more sets of instructions. The term \u201cmachine-readable medium\u201d shall also be taken to include any medium that is capable of storing, encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present disclosure.","The term \u201cmachine-readable medium\u201d shall accordingly be taken to include, but not be limited to: solid-state memories such as a memory card or other package that houses one or more read-only (non-volatile) memories, random access memories, or other re-writable (volatile) memories; magneto-optical or optical medium such as a disk or tape; and carrier wave signals such as a signal embodying computer instructions in a transmission medium; and\/or a digital file attachment to e-mail or other self-contained information archive or set of archives is considered a distribution medium equivalent to a tangible storage medium. Accordingly, the disclosure is considered to include any one or more of a machine-readable medium or a distribution medium, as listed herein and including art-recognized equivalents and successor media, in which the software implementations herein are stored.","Although the present specification describes components and functions implemented in the embodiments with reference to particular standards and protocols, the disclosure is not limited to such standards and protocols. Each of the standards for Internet and other packet switched network transmission (e.g., TCP\/IP, UDP\/IP, HTML, and HTTP) represent examples of the state of the art. Such standards are periodically superseded by faster or more efficient equivalents having essentially the same functions. Accordingly, replacement standards and protocols having the same functions are considered equivalents.","The illustrations of embodiments described herein are intended to provide a general understanding of the structure of various embodiments, and they are not intended to serve as a complete description of all the elements and features of apparatus and systems that might make use of the structures described herein. Many other embodiments will be apparent to those of skill in the art upon reviewing the above description. Other embodiments may be utilized and derived therefrom, such that structural and logical substitutions and changes may be made without departing from the scope of this disclosure. Figures are also merely representational and may not be drawn to scale. Certain proportions thereof may be exaggerated, while others may be minimized. Accordingly, the specification and drawings are to be regarded in an illustrative rather than a restrictive sense.","Such embodiments of the inventive subject matter may be referred to herein, individually and\/or collectively, by the term \u201cinvention\u201d merely for convenience and without intending to voluntarily limit the scope of this application to any single invention or inventive concept if more than one is in fact disclosed. Thus, although specific embodiments have been illustrated and described herein, it should be appreciated that any arrangement calculated to achieve the same purpose may be substituted for the specific embodiments shown. This disclosure is intended to cover any and all adaptations or variations of various embodiments. Combinations of the above embodiments, and other embodiments not specifically described herein, will be apparent to those of skill in the art upon reviewing the above description.","The Abstract of the Disclosure is provided to comply with 37 C.F.R. \u00a71.72(b), requiring an abstract that will allow the reader to quickly ascertain the nature of the technical disclosure. It is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition, in the foregoing Detailed Description, it can be seen that various features are grouped together in a single embodiment for the purpose of streamlining the disclosure. This method of disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather, as the following claims reflect, inventive subject matter lies in less than all features of a single disclosed embodiment. Thus the following claims are hereby incorporated into the Detailed Description, with each claim standing on its own as a separately claimed subject matter."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0004","num":"0003"},"figref":"FIGS. 1A","b":["1","2","2","3"]},{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIGS. 4-6"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIGS. 8-9"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":["FIGS. 10-12","FIGS. 1-9"]},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
