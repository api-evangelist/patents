---
title: Adding speech capabilities to existing computer applications with complex graphical user interfaces
abstract: At design time of a graphical user interface (GUI), a software component (VUIcontroller) is added to the GUI. At run time of the GUI, the VUIcontroller analyzes the GUI from within a process that executes the GUI. From this analysis, the VUIcontroller automatically generates a voice command set, such as a speech-recognition grammar, that corresponds to controls of the GUI. The generated voice command set is made available to a speech recognition engine, thereby speech-enabling the GUI. Optionally, a GUI designer may add properties to ones of the GUI controls at GUI design time, without necessarily writing a voice command set. These properties, if specified, are then used at GUI run time to control or influence the analysis of the GUI and the automatic generation of the voice command set.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09081550&OS=09081550&RS=09081550
owner: Nuance Communications, Inc.
number: 09081550
owner_city: Burlington
owner_country: US
publication_date: 20110426
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND ART","SUMMARY OF EMBODIMENTS","DETAILED DESCRIPTION OF SPECIFIC EMBODIMENTS","Voice User Interface Controller (VUIcontroller)","VUIcontroller Implemented as a Drag-and-Drop Tool","VUIcontroller Implemented as a Callable Script","Automatic Speech-Recognition Command Set Generation at GUI Run Time"],"p":["This application claims the benefit of U.S. Provisional Patent Application No. 61\/444,340, filed Feb. 18, 2011, titled \u201cAdding Speech Capabilities to Existing Computer Applications with Complex Graphical User Interfaces,\u201d the entire contents of which are hereby incorporated by reference herein, for all purposes.","The present invention relates to software development libraries, software development kits (SDKs), application programming interfaces (APIs) and other software components (collectively \u201csoftware development tools\u201d) and, more particularly, to software development tools for adding speech recognition capabilities to existing graphical user interfaces.","Many computer programs have graphical user interfaces (GUIs), which allow users to interact with the programs using images rather than text commands. A GUI represents information and actions by displaying graphical icons and visual indicators on a screen. A user interacts with the GUI through manipulation of the graphical elements using a mouse, trackball, joystick, touch screen or other input device. For example, a user may control the location of a cursor displayed on the screen by moving a mouse. The user may indicate a choice by moving the cursor to an icon and pressing a button on the mouse (\u201cclicking\u201d). Similarly, the user may move the cursor to a location within a rectangle (\u201ctext box\u201d) displayed on the screen, click to select the text box and then enter text into the box by typing on a keyboard. GUIs employ metaphors, such as buttons, check boxes, radio buttons, text boxes, pull-down lists (drop-down boxes), etc. (collectively referred to as \u201ccontrols\u201d), to facilitate human-computer interaction. GUIs are widely used in personal computers, embedded systems, such as automatic teller machines (ATMs) and point-of-sale terminals, hand-held devices, such as mobile telephones and MP3 players, and the like.","Although GUIs represent a significant advance over purely text-based user interfaces, GUIs nevertheless suffer from some shortcomings. For example, a user must be able and willing to manipulate a mouse or other pointing device and, in most cases, enter text by typing on a keyboard. People who do not have use of their hands, either because of a physical disability or because their hands are dedicated to performing some other tasks, can not use GUIs.","Automatic speech recognition (\u201cASR\u201d or \u201cSR\u201d) technology converts spoken words into text. For example, Dragon Naturally Speaking speech recognition software from Nuance Communications, Inc., Burlington, Mass., may be used to dictate text into a word processing document or into a text box of a GUI, once the text box has been selected. In some cases, voice commands may be used to navigate among controls in a GUI. Two conventional approaches are available for speech-enabling a software application.","In one approach, a speech recognition application parses a displayed GUI at run time and attempts to identify controls, such as buttons and text boxes. The speech recognition application enables the user to navigate among the identified controls by uttering simple commands such as \u201cNext field\u201d and \u201cPrevious field.\u201d In some cases, the speech recognition application can identify text displayed near the controls. For example, if the GUI is displayed by a browser rendering a web page, the speech recognition application may parse HTML code of the web page. Text that is displayed adjacent a control may be assumed to be a label for the control. The user is then able to navigate to a control by uttering \u201cGo to xxx,\u201d where \u201cxxx\u201d is the assumed label for the control. Once a control has been navigated to, the user may activate the control and\/or use the control, such as by dictating into a text box.","However, correctly identifying displayed text as labels is error prone and sometimes impossible. For example, not all GUI controls have near-by text, and any near-by text may not actually correspond to the control and may not, therefore, provide a suitable navigation label for the control.","Advantageously, this approach to speech-enabling a GUI requires no effort on the part of a GUI developer. However, the navigation capabilities provided by this approach are limited to simple, i.e., \u201cnext\u201d and \u201cprevious,\u201d navigation commands if suitable label text can not be identified. Furthermore, some GUIs include multiple pages or tabs, the contents of only one of which is displayed at a time. Such complex GUIs are often found in electronic medical record\/electronic health record (EMR\/EHR) and many other complex application programs. Unfortunately, using the first speech-enabling approach, it is not possible to navigate to, or activate, a control located on a page or tab other than the currently-displayed page or tab.","Another approach to speech-enabling a GUI provides richer and more complete speech navigation. However, this approach requires specifically designing the GUI for speech recognition. A developer who is skilled in voice user interface (VUI) design constructs a \u201cdialog\u201d that guides a user through voice interactions with the application. Thus, the speech recognition capabilities and programming are deeply integrated in the GUI. Furthermore, the language used to specify the voice interactions is distinct from the language used to describe the GUI. Although this approach can lead to a rich and sophisticated VUI, the development process is long, expensive and requires a skilled developer.","Application developers are, therefore, faced with a technical problem of speech-enabling complex GUIs, such as multi-page or multi-tab GUIs, without constructing speech dialogs when the GUIs are designed (\u201cGUI design time\u201d).","An embodiment of the present invention provides a voice user interface controller (VUIcontroller) for automatically speech enabling a graphical user interface (GUI). The VUIcontroller includes a software component that is configured for inclusion in the GUI at design time of the GUI. The VUIcontroller is configured such that the software component is automatically executed at run time of the GUI. (The definition of \u201cexecuted\u201d includes \u201cinstantiated.\u201d) The software component is further configured to automatically perform several actions at run time of the GUI. The software component automatically analyzes the GUI from within a process that executes the GUI. The software component also automatically generates a voice command set corresponding to controls of the GUI. (A voice command set may be implemented as a speech recognition grammar, a search graph, a speech-recognition engine-embedded state machine or any other construct or process for recognizing speech.) The voice command set is generated from the analysis. The software component also automatically makes the generated voice command set available to a speech-recognition engine.","The software component may include a drag-and-drop tool for use in a visual GUI integrated design environment (IDE) or a routine callable from a GUI markup document.","The software component may be stored on a server other than a computer that renders the GUI at run time of the GUI. The computer that renders the GUI and the server may be interconnected, at least in part, by the Internet. At least a portion of the analysis of the GUI may be performed by the server.","The software component may be configured to automatically analyze the GUI by constructing a data structure representing the controls of the GUI.","The software component may be configured to respond to GUI run-time dynamic changes in the GUI by revising the generated voice command set according to the changes in the GUI. The revision to the voice command set may be according to at least one user-settable property. The user-settable property may be settable to a value by a user at design time of the GUI.","The software component may be configured to respond to GUI run-time dynamic changes in the GUI by generating a revised voice command set according to the changed GUI. The revised voice command set may be generated according to at least one user-settable property. The user-settable property may be settable to a value by a user at design time of the GUI.","The software component may be further configured to augment each of the controls of the GUI (at design time of the GUI) with at least one corresponding user-settable property. The user-settable property may be settable to a value by a user at design time of the GUI.","The at least one user-settable property may include text of a voice command for navigating to the corresponding control of the GUI or an indicator of whether the corresponding control of the GUI is to be speech enabled.","The at least one user-settable property may include a unique identifier associated with the control of the GUI. The software component may be further configured to store, at design time of the GUI, an identifier of a user-specified speech recognition grammar associated with the unique identifier.","The software component may be further configured to augment, at design time of the GUI, each of the controls of the GUI with a unique identifier usable to identify an associated speech recognition grammar.","The software component may be further configured such that the automatic analysis of the GUI is performed according to at least one user-settable property. The user-settable property may be settable to a value by a user at design time of the GUI.","The software component may be further configured such that the automatic generation of the voice command set is performed according to at least one user-settable property. The user-settable property may be settable to a value by a user at design time of the GUI.","The software component may be further configured such that the automatic making available of the generated voice command set to the speech-recognition engine is performed according to at least one user-settable property. The user-settable property may be settable to a value by a user at design time of the GUI.","Another embodiment of the present invention provides a method for automatically speech enabling a graphical user interface (GUI). According to the method, at run time of the GUI, a VUIcontroller is automatically executed. The VUIcontroller was included in the GUI at design time of the GUI. The VUIcontroller automatically analyzes the GUI from within a process that executes the GUI and generates a voice command set corresponding to controls of the GUI, from the analysis of the GUI. The VUIcontroller also makes the generated voice command set available to a speech-recognition engine.","The VUIcontroller may be provided in a form of a drag-and-drop tool configured to be added to a visual GUI integrated development environment (IDE).","The GUI may be analyzed according to at least one user-settable property. The user-settable property may be settable to a value by a user at design time of the GUI.","The voice command set may be generated according to at least one user-settable property. The user-settable property may be settable to a value by a user at design time of the GUI.","The generated voice command set may be made available to the speech-recognition engine comprises according to at least one user-settable property. The user-settable property may be settable to a value by a user at design time of the GUI.","At run time of the GUI, in response to a change in the GUI, the generated voice command set may be revised, or a revised voice command set may be generated, according to the changes in the GUI. The revision or generation may be according to at least one user-settable property. The user-settable property may be settable to a value by a user at design time of the GUI.","Yet another embodiment of the present invention provides a non-transitory computer-readable medium having computer readable program code stored thereon for automatically speech enabling a graphical user interface (GUI). The stored program code includes program code for automatically executing a VUIcontroller at run time of the GUI. The VUIcontroller was included in the GUI at design time of the GUI. The stored program code also includes program code for performing several operations as a consequence of the automatic execution of the VUIcontroller, including automatically analyzing the GUI from within a process that executes the GUI and automatically generating a voice command set corresponding to controls of the GUI, from the analysis of the GUI. Also included is program code for automatically making the generated voice command set available to a speech recognition engine.","In accordance with embodiments of the present invention, methods and apparatus are disclosed for automatically speech enabling a graphical user interface (GUI) of a computer application program, without requiring a GUI designer to construct a dialog that guides a user through voice interactions with the application. Instead, a voice command set is automatically generated at GUI run time by analyzing the GUI from within a process that executes the GUI. (A voice command set may be implemented as a speech recognition grammar, a search graph, a speech-recognition-engine-embedded state machine or any other construct or process for recognizing speech.) Because the GUI is analyzed from within the GUI process, all the GUI controls of the application are available for analysis, regardless of whether the controls are visible or not visible on the current window. Thus, the automatically-generated voice command set can encompass the entire GUI and enables the user to navigate to, and activate, GUI controls that are on windows and tabs that are not currently visible, without requiring the GUI designer to construct a voice command set.","Nevertheless, some embodiments enable the GUI designer to optionally and simply add speech-enabling properties to one or more of the GUI controls, or one or more global properties, at GUI design time, without necessarily writing a voice command set. These properties, if specified, may then be used at GUI run time to control or influence the analysis of the GUI and the automatic generation of the voice command set. For example, the GUI designer can specify a name or other command the user can utter to navigate to or activate the GUI control. The name or other command may be stored as a property of the corresponding GUI control. Another property may be used by the GUI designer to specify that a particular GUI control is to be, or is not to be, speech enabled. Another property may be used to control automatic regeneration of the voice command set in response to programmatic changes to the GUI by the application program. Yet another property may be used by the GUI designer to associate a particular voice command set, such as a pre-defined grammar, or a particular problem domain, such as electronic medical records (EMR) or a particular field of medicine, such as radiology or oncology, with a particular GUI control. These properties may then be used at GUI run time to control or influence the analysis and\/or generation of the voice command set.","Thus, a complete GUI may be automatically speech-enabled, including GUI controls that are not on a currently visible page, without requiring the GUI designer to construct a voice command set. However, the GUI designer may control or influence speech-recognition aspects of selected GUI controls through the added GUI control properties, again without requiring the GUI designer to construct a voice command set. Consequently, the GUI designer obtains benefits of both prior art speech-enabling approaches, without incurring the penalties associated with the prior art.","According to some embodiments of the present invention, a \u201cvoice user interface controller\u201d (\u201cVUIcontroller\u201d) is used to automatically speech-enable a GUI. The VUIcontroller is a software component that is configured to be included in a GUI when the GUI is developed, i.e., at GUI design time. The VUIcontroller is further configured to be automatically instantiated or executed and connected to the GUI when the corresponding application program is executed and the GUI is displayed, i.e., at GUI run time.","At GUI run time, the VUIcontroller analyzes the GUI from within a process that executes the GUI. Analyzing from within the process that executes the GUI enables the VUIcontroller to access information about the entire GUI, not merely a currently displayed page or tab. From this analysis, the VUIcontroller automatically generates a voice command set that corresponds to controls of the GUI. The generated voice command set is made available to a speech recognition engine, thereby speech-enabling the GUI.","In some embodiments, such as when the GUI is being developed using an integrated development environment (IDE), the VUIcontroller may be implemented as a drag-and-drop tool that can be dropped into a GUI under development. In other embodiments, such as web-based GUIs, the VUIcontroller may be implemented as a routine, such as a script written in JavaScript, that is callable from a GUI markup document, such as a web page written in the HyperText Markup Language (HTML).","The VUIcontroller may be stored on the same computer that renders the GUI at run time or on a server other than the computer that renders the GUI at run time. For example, the VUIcontroller may be stored on a server that is accessible by the GUI-rendering computer at least partially via the Internet. The VUIcontroller, or a portion of the VUIcontroller, may be downloaded from the server to the GUI-rendering computer for execution. The automatic analysis and\/or automatic voice command set generation may be performed by the VUIcontroller on the GUI-rendering computer or on another server. For example, a downloaded portion of the VUIcontroller may send raw data describing the GUI to a remotely executed portion of the VUIcontroller for analysis.","In some cases, such as when part or all of the VUIcontroller is executed on a remote computer, services of the VUIcontroller may be provided by a third party commercial entity for a fee, such as under a license agreement. Thus, a company may provide a speech-enabled GUI by calling the VUIcontroller, without necessarily providing the VUIcontroller. The provider of the VUIcontroller may implement improvements in the VUIcontroller, without requiring the GUI application program to be modified or rebuilt. In such a case, the GUI application program obtains benefits from the improved VUIcontroller transparently.","Similarly, the speech-recognition engine that processes the automatically-generated voice command set may be executed by the same computer that executes the GUI or a different computer, such as a computer accessible via the Internet. In some cases, such as when the speech-recognition engine resides on a remote computer, services of the speech-recognition engine may be provided by a third party commercial entity for a fee, such as under a license agreement. Thus, a company may provide a speech-enabled GUI without necessarily also providing the speech-recognition engine. The provider of the speech-recognition engine may implement improvements in the speech-recognition engine, without requiring the GUI application program to be modified or rebuilt. In such a case, the GUI application program obtains benefits from the improved speech-recognition engine transparently.","Some embodiments of the present invention will now be described in greater detail.","Some GUI developers use visual IDEs, such as Visual Studio 2010 software from Microsoft Corporation, Redmond, Wash. 98052-6399, to design GUIs. An IDE is a software application that provides comprehensive facilities to computer programmers for software development. An exemplary user interface  to a visual IDE is shown schematically in . The IDE includes a window (\u201cdesign pane\u201d)  that graphically represents a GUI under development, as well as another window (\u201ctoolbox\u201d)  that display tools, such as GUI controls that can be dragged by the developer from the toolbox  and dropped into the design pane . The IDE may include other windows, such as a \u201cproperties\u201d window , in which the IDE displays, and the GUI developer may browse and, in appropriate cases, edit values of properties associated with GUI controls and other objects that have been added to the GUI under development. In the properties window , the IDE displays a scrollable list of properties and corresponding property values, if they have been defined or defaulted, associated with a GUI control or other object, such as a tab control , that has been selected in the design pane . Exemplary prior art properties include X and Y coordinates within the eventual run-time GUI window of a corner of each control.","As noted, the VUIcontroller may be implemented as a drag-and-drop tool  that the GUI developer can drag from the toolbox  and drop into the GUI design pane . Dropping the VUIcontroller  into the design pane  causes the IDE to add the VUIcontroller software component to the GUI under development, in the same, or similar, manner as the IDE adds other dragged-and-dropped tools, such as GUI controls. For example, adding the VUIcontroller  to the GUI under development may involve adding a class definition for the VUIcontroller to the GUI. The IDE adds the VUIcontroller to the GUI under development according to the GUI framework, under which the GUI is being developed. Exemplary GUI frameworks include .NET WinForms, Windows Presentation Foundation (WPF), Swing, ActiveX, iOS\/Objective C, Java and Win32 hwnd-based frameworks.","Typically, the VUIcontroller  needs to be added only once to a GUI application under development, even if the GUI includes more than one window, page or tab. The IDE may, but need not, display an icon in the GUI design pane  to indicate the VUIcontroller  has been added to the GUI under development.","Optionally, once the VUIcontroller  has been dropped into the GUI design pane , the VUIcontroller may extend GUI controls, such as buttons and drop-down lists, with additional custom properties. Optionally or additionally, the VUIcontroller may extend the GUI with global properties, i.e., properties that are not tied to particular GUI controls. The GUI developer may then easily give values to these properties using the IDE's properties browser . Three exemplary added properties ,  and  are shown; however, other additional properties and other numbers of additional properties may be added, and other names for the described properties may be used. The three exemplary additional properties will now be discussed in more detail.","The VuiConceptName property  may be used to allow the GUI developer to specify a voice command or a list of alternative voice commands that a user will be able to utter to navigate to the associated GUI control. In one embodiment, the VuiConceptName value may be entered by the GUI developer as a text string, with a predetermined character, such as vertical bar (\u201c|\u201d), to separate alternative voice commands. For example, in a travel-related application, a destination control may have a VuiConceptName value of \u201cdestination |I want to travel to |my destination is.\u201d The default value for the VuiConceptName property may be null.","The VuiEnabled property  may take one of two Boolean values, \u201ctrue\u201d and \u201cfalse,\u201d to indicate whether the corresponding GUI control should be speech-enabled or not. The default value may be \u201ctrue.\u201d","The GUI developer may add the VuiGUID property  to selected GUI controls. Optionally, the VUIcontroller  may automatically add the VuiGUID property  to each GUI control in the application. In either case, at GUI design time, the VUIcontroller  assigns a unique value, such as a globally unique identifier (GUID), to each VuiGUID property . Thus, the VuiGUID properties uniquely identify the associated GUI controls, at least within the application. The values used for the VuiGUID property  may, but need not, be 32-character hexadecimal stings.","The GUI developer may associate a voice command set or an individual grammar concept (i.e., one or more phrases that can be recognized when the grammar is active), such as in a pre-existing grammar or in a grammar expected to be available to the speech-recognition engine at GUI run time, with a particular VuiGUID value, thereby associating the voice command set or grammar concept with the GUI control having that VuiGUID property value. Most existing speech-recognition engines allow the association of individual grammar concepts with semantic attributes that are returned by the speech-recognition engine, together with a recognized phrase. The concrete VuiGUID value can be stored in such a semantic attribute. Thus, at GUI run time, if a user-uttered command is recognized using a speech-recognizer grammar associated with a VuiGUID value, the VUIcontroller is notified, and the VUIcontroller activates the GUI control associated with the VuiGUID value. For example, if the GUI control is a button, the VUIcontroller simulates a button click.","The GUI developer may add other properties and associated property values to GUI controls. For example, if a text box or pull-down control relates to a particular problem domain, such as radiology, oncology or automobile repair, a VuiDictationTopic property value may be set by the GUI developer to an appropriate value, such as a code or a text string that represents the problem domain. The value of this property may then be used at GUI run time to select an appropriate voice command set to increase speech recognition accuracy. Similarly, if the semantics of a field are known at GUI design time, the GUI developer may set a property value to store information about the semantics. For example, if valid values that can be entered into a field must fall within set boundaries, such as systolic blood pressure or body temperature, the property may be used to automatically select a voice command set that recognizes only utterances of numeric information within that range. For example, VuiSemantics=\u201cbodytemperature\u201d may be used to restrict recognition to values between 90\u00b0 F. and 110\u00b0 F. or 35\u00b0 C. and 42\u00b0 C.","The description of custom properties (above) is phrased in the context of a .NET WinForms framework. In other frameworks, other well-known concepts may be used to achieve similar results. For example, in iOS\/Objective C, extension interfaces may be used to implement these properties.","The VUIcontroller  may be provided by the IDE provider, or the VUIcontroller  may be added to the IDE's toolbox  as a custom tool. Instructions for adding custom tools to IDEs are typically provided by the IDEs' providers.","As noted, in other embodiments, the VUIcontroller may be implemented as a routine, such as a script written in JavaScript, that is callable from a GUI markup document, such as an HTML document. Also as noted, the script may be stored on the same computer that renders the GUI or on another computer, including a computer accessible to the GUI-rendering computer via the Internet. A block diagram of such an arrangement is shown schematically in . The VUIcontroller script  may be invoked from a JavaScript file that contains code that hooks into the \u201con Load\u201d event and is included in a web page via an HTML statement such as:",{"@attributes":{"id":"p-0062","num":"0061"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"<script type=\u201ctext\/javascript\u201d"},{"entry":"\u2003\u2003src=\u201chttp:\/\/danube.nuancehce.com\/Nuance.SpeechAnywhere.js\u201d>"},{"entry":"<\/script>"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The on Load event handler is used to execute a JavaScript after a page, frame or image has completely loaded. Thus, the VUIcontroller is executed after the GUI page has loaded and all the GUI controls of the page are accessible to the VUIcontroller for analysis.","Properties, such as the VuiConceptName property described above, may be defined as \u201cdata\u201d attributes in HTML 5, as in, for example:\n\n","When the application program that includes the developed GUI is executed, the VUIcontroller is executed or instantiated within a process that executes the GUI. For example, if the dropped-in VUIcontroller  () is a class, at GUI run time the GUI framework instantiates the VUIcontroller and associates the instantiated object with the GUI onto which the VUIcontroller  had been dropped. Thus, the VUIcontroller object can refer to other objects in the GUI, such as labels and controls.  is a schematic block diagram of an application program  that includes a GUI  that was designed, as described above, and an instantiated VUIcontroller object . The VUI controller object  analyzes the GUI  and automatically generates a voice command set  from the analysis.","In one embodiment, to generate the voice command set , a constructor routine in the VUIcontroller object  is executed when the VUIcontroller object  is instantiated. As noted, in HTML-based applications, the VUIcontroller may be executed by, or within, a JavaScript hooked to the \u201con Load\u201d event. Similar techniques for executing or instantiating the VUIcontroller upon execution of the GUI  are available in other GUI frameworks. For simplicity of explanation, the VUIcontroller is referred to below as the VUIcontroller object , regardless of the GUI framework involved.","The VUIcontroller object  automatically generates a hierarchical (tree) representation of the GUI , as will now be described using a hypothetical three-window GUI shown schematically in ,  and , and then the VUIcontroller object  automatically generates a voice command set  from the hierarchical representation. As shown in , the first window includes a three-tabbed tab control . The middle tab includes three radio buttons ,  and . As shown in , the second window of the GUI includes a text box  and two buttons  and . As shown in , the third window includes a two-tabbed tab control . The first tab includes a text box  and a button .","The VUIcontroller object  () analyzes the GUI () and generates a hierarchical representation , as shown in , of the controls in the GUI  (). This representation  may, but need not necessarily, include text, such as labels, in the GUI. The root  of the hierarchical representation  corresponds to the GUI  (). Successive nodes of the hierarchical representation  correspond to windows, tab groups, tabs, buttons, text boxes, etc.","The VUIcontroller object  may, for example, use the well-known process known as \u201creflection\u201d to observe the structure of the GUI . The VUIcontroller object  may use a reference, passed to the VUIcontroller object upon instantiation, to the GUI  as a starting point for an inspection\/reflection operation that allows the VUIcontroller object  to analyze the entire GUI  and identify all controls in the GUI .","Optionally or alternatively, the VUIcontroller object  may generate a non-hierarchical representation (not shown) of the controls in the GUI. Any form of representation that includes information about the relationships among the controls of the GUI  may be used. For simplicity of explanation, the representation is referred to as a hierarchical representation .","The VUIcontroller object  augments the information in the hierarchical representation  with information about the controls, as stored in the controls' properties. For example, if the GUI developer gave a value to the VuiConceptName property  () for a particular control at GUI design time, the VUIcontroller object  stores this value in the corresponding node of the hierarchical representation . For example, continuing the example described above with respect to the VuiConceptName property and , \u201cdestination,\u201d \u201cI want to travel to\u201d and \u201cmy destination is\u201d are added to the node that corresponds to the destination control.","If no VuiConceptName property  was defined for a control, but the analysis of the GUI  reveals that the GUI  includes text adjacent a control, the text may be used as a label for the control, and VUIcontroller object  adds the label text to the hierarchical representation . Thus, the user may navigate to the control with a speech command such as \u201cGo to xxx,\u201d where \u201cxxx\u201d is the label for the control. However, unlike the prior art, these navigation commands are available regardless of on which window, page or tab the control appears, because the VUIcontroller object  has access to the entire GUI  for analysis. In contrast, prior art run-time GUI analysis is performed from outside the application and, therefore, only the currently displayed window, page or tab is accessible for analysis, and cross-page navigation by speech is not possible.","To enable voice navigation to controls for which no VuiConceptName property value was specified and no appropriate text label is identified, the voice command set  may include relative navigation commands, such as \u201cNext\u201d and \u201cPrevious.\u201d","A \u201ctab order\u201d of the controls may be stored in the hierarchal representation . This tab order may be derived from the GUI framework, if the framework supports a tab order. For example, such a tab order is typically specified during GUI design time in an IDE.","Other property values, such as VuiEnabled  and VuiGUID  (), are also stored in the hierarchical representation . If the value of the VuiEnabled property  () for a control is \u201cfalse,\u201d the VUIcontroller object  omits automatically generating voice command set  information for the control, thereby making the control not speech-enabled.","Once the hierarchical representation  of the GUI  has been generated, the VUIcontroller object  automatically generates the voice command set  () from information in the representation  of the GUI. As shown schematically in , once the voice command set  has been generated and a speech-recognition engine  has been invoked, the VUIcontroller object  provides a user interface (VUI)  to the user. The VUI  makes the voice command set  available, and passes user utterances, to the speech-recognition engine . The speech-recognition engine  recognizes the utterances according to the voice command set  (if possible) and generates text. The text is returned to the VUI , which causes the GUI  to be navigated and controls to be operated, as appropriate.","As noted, the speech-recognition engine  may be executed by a server remote from the computer that executes the application program . Alternatively, the speech-recognition engine  may be executed by the same computer that executes the application program .","Some GUI frameworks enable an application to programmatically create, modify or delete GUI controls at GUI run time. Such a dynamic GUI may be used, for example, in an EMR\/EHR application to add or delete fields based on, for example, gender of a patient or answers to questions about the patient's history. Optionally, the VUIcontroller object  is configured to respond to such changes by creating a new hierarchical representation  () of the changed GUI and then generating a new voice command set  from the new representation  or by modifying the existing representation  and voice command set . In either case, the VUI  dynamically changes according to the then-current GUI .","Although an IDE may display an icon in the GUI design pane  during GUI design time to indicate the VUIcontroller  has been added to the GUI under development, no GUI control or other indicator needs to be displayed in the GUI  at run time to indicate the VUIcontroller  is present, unless for marketing or similar purposes such an indicator is desired. For example, the VUIcontroller object  may be represented by an icon that displays a speech-recognition vendor's logo. A user of the application GUI  does not need to directly interact with the VUIcontroller  as a GUI element, such as by clicking on it. However, optionally, clicking the VUIcontroller icon (if one is displayed) may display information about the speech-recognition vendor or automatically open a browser window and invoke a link to the vendor's web site.",{"@attributes":{"id":"p-0080","num":"0080"},"figref":"FIG. 9","b":["900","904"]},"At , the software component may be executed or instantiated (collectively herein referred to as \u201cexecuted\u201d) at GUI run time in the same process as executes the GUI. This may involve downloading the software component from a server, including a server coupled via the Internet to a computer that executes the GUI. At , the software component automatically analyzes the GUI from within the process that executes the GUI. Optionally, the analysis may be controlled or influenced by one or more of the properties that were defined for one or more of the GUI controls or a global property. For example, if a property, such as VuiEnable, has a value of \u201cfalse,\u201d in association for a given GUI control, the control may be omitted from the eventually automatically generated voice command set.","The analysis may be performed solely by the computer that executes the GUI or partially by another computer, such as the server from which the software component was downloaded. For example, the downloaded software component may inspect the GUI from within the process that executes the GUI and send information derived from the inspection to a remote server for further analysis. Nevertheless, the functions performed by the software component within the process that executes the GUI are referred to herein as analyzing the GUI from within a process that executes the GUI.","At , a representation, such as a hierarchical representation, of the GUI, is automatically generated according to the analysis. The representation includes information about the controls of the GUI. Optionally, the generation of the representation may be controlled or influenced by one or more of the properties that were defined for one or more of the GUI controls or a global property. The representation may be generated by the same computer that executes the GUI or by another computer, such as the server from which the software component may have been downloaded.","At , a voice command set is automatically generated from the representation of the GUI. Again, optionally, the generation of the grammar may be controlled or influenced by one or more of the properties that were defined for one or more of the GUI controls or a global property. For example, a property may specify a problem domain, which may be used to constrain the universe of user utterances or to select a dictionary, thesaurus or ontology to identify alternative or additional words or phrases to be included in the voice command set for a given input field or control or to identify groups of fields in the GUI that are semantically related. For example, if an application is identified as being related to health care and the GUI includes two fields labeled \u201csystolic\u201d and \u201cdiastolic,\u201d the VUI controller may generate a voice command set that accepts \u201cblood pressure\u201d followed by two numbers, optionally separated by \u201cover,\u201d as a single utterance. The two recognized numbers are automatically entered in to the systolic and diastolic fields.","The voice command set may be generated by the same computer that executes the GUI or by another computer, such as the server from which the software component may have been downloaded. Using a separate computer facilitates improving the analysis capabilities, without rebuilding the application, such as by augmenting the dictionary, thesaurus or ontology or the logic of the analyzer.","At , the voice command set is made available to an automatic speech-recognition engine. Aspects of how the voice command set is made available to the speech-recognition engine may be controlled or influenced by one or more properties. The speech-recognition engine may be executed on the same computer that executes the GUI or on a different computer. For example, digitized or partially recognized speech may be sent to the remote server for recognition, and corresponding recognized speech (in the form of text) may be returned to the GUI-executing computer. Utterances by a user are recognized by the speech-recognition engine, according to the voice command set, and the software component invokes appropriate controls, and fills in appropriate fields, of the GUI, according to the recognized utterances.","If the GUI is changed, such as programmatically by an application program, at , control may return to , and the representation and voice command set may be modified or generated anew. Whether control returns to  and aspects of the modification or generation of the representation or voice command set may be controlled or influenced by one or more of the properties that were defined for one or more of the GUI controls or by one or more global properties.","In some embodiments, the VUIcontroller may be implemented as a drag-and-drop tool or as a callable script, as described. In these and some other embodiments, the VUIcontroller may include or be part of a software development library, software development kit (SDK), application programming interfaces (API) and\/or other software component (collectively \u201csoftware development tool\u201d) that may be integrated into a third-party application program. Although addition of a VUIcontroller to a GUI-based application has been described in the context of dragging-and-dropping in a visual IDE and by adding a call to an HTML document, other mechanisms may be used. For example, a wizard may be used to modify an existing application program by adding code to the application program and rebuilding the application program.","A VUIcontroller may be embodied as software that may be stored in a memory and executed by a processor controlled by instructions stored in the memory. The memory may be random access memory (RAM), read-only memory (ROM), flash memory or any other memory, or combination thereof, suitable for storing control software or other instructions and data. Some of the functions performed by the VUIcontroller have been described with reference to flowcharts and\/or block diagrams. Those skilled in the art should readily appreciate that functions, operations, decisions, etc. of all or a portion of each block, or a combination of blocks, of the flowcharts or block diagrams may be implemented as computer program instructions, software, hardware, firmware or combinations thereof. Those skilled in the art should also readily appreciate that instructions or programs defining the functions of the present invention may be delivered to a processor in many forms, including, but not limited to, information permanently stored on non-writable tangible storage media (e.g. read-only memory devices within a computer, such as ROM, or devices readable by a computer I\/O attachment, such as CD-ROM or DVD disks), information alterably stored on writable tangible storage media (e.g. floppy disks, removable flash memory and hard drives) or information conveyed to a computer through communication media, including wired or wireless computer networks. In addition, while the invention may be embodied in software, the functions necessary to implement the invention may optionally or alternatively be embodied in part or in whole using firmware and\/or hardware components, such as combinatorial logic, Application Specific Integrated Circuits (ASICs), Field-Programmable Gate Arrays (FPGAs) or other hardware or some combination of hardware, software and\/or firmware components.","While the invention is described through the above-described exemplary embodiments, it will be understood by those of ordinary skill in the art that modifications to, and variations of, the illustrated embodiments may be made without departing from the inventive concepts disclosed herein. For example, although some aspects of VUIcontroller have been described with reference to a flowchart, those skilled in the art should readily appreciate that functions, operations, decisions, etc. of all or a portion of each block, or a combination of blocks, of the flowchart may be combined, separated into separate operations or performed in other orders. Moreover, while the embodiments are described in connection with various illustrative data structures, one skilled in the art will recognize that the system may be embodied using a variety of data structures. Furthermore, disclosed aspects, or portions of these aspects, may be combined in ways not listed above. Accordingly, the invention should not be viewed as being limited to the disclosed embodiments."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The invention will be more fully understood by referring to the following Detailed Description of Specific Embodiments in conjunction with the Drawings, of which:",{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIGS. 4-6"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIGS. 7A and 7B","FIGS. 4-6"]},{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 8","FIG. 3","FIGS. 7A and 7B"]},{"@attributes":{"id":"p-0039","num":"0038"},"figref":["FIG. 9","FIGS. 1-3"],"b":"8"}]},"DETDESC":[{},{}]}
