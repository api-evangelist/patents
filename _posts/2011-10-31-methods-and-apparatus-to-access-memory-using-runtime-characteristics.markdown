---
title: Methods and apparatus to access memory using runtime characteristics
abstract: Example methods, apparatus, and articles of manufacture to access memory are disclosed. A disclosed example method involves receiving at least one runtime characteristic associated with accesses to contents of a memory page and dynamically adjusting a memory fetch width for accessing the memory page based on the at least one runtime characteristic.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09146867&OS=09146867&RS=09146867
owner: Hewlett-Packard Development Company, L.P.
number: 09146867
owner_city: Houston
owner_country: US
publication_date: 20111031
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","DETAILED DESCRIPTION"],"p":["Traditionally, memories such as dynamic random access memories (DRAMs) have been designed for low-cost and fast access time. However, gains in cost and access speed have been made via tradeoff decisions resulting in increased power-consumption. A DRAM is made of thousands of transistors organized to form bit cells that store bit-level information. When accessed together, combinations of bit cells can store meaningful and\/or useful information. DRAM architectures include signal busses used to activate different combinations of bit cells for writing and\/or reading information at addressable storage locations.","Some traditional DRAM architectures are structured such that a DRAM can be operated to quickly retrieve data stored at sequential address locations in response to a single data request and address provided by a processor or memory controller. For example, processors are typically configured to retrieve one or more entire cache lines from DRAM based on a single read request. In a traditional DRAM module, a single conventional read operation requires pre-charging an entire row of bitlines in each DRAM chip of the DRAM module. Each pre-charged row typically corresponds to multiple cache lines.","Example methods, apparatus, and articles of manufacture disclosed herein may be used to perform memory accesses using dynamic memory fetch widths (MFWs). Unlike known memory access techniques that use fixed memory fetch widths to retrieve information from memory devices, example techniques disclosed herein use dynamic MFWs that can be adjusted dynamically during operation of a processor and memory controller to more efficiently fetch contents from memory device(s). That is, examples disclosed herein can be used to set dynamic MFWs during processor system operation to control how data is read from memory cells. For example, if a memory request wants to activate a single cache line, the dynamic MFW can be set equal to the length of the cache line so that the memory controller will not overfetch more contents from a memory device than requested. In this manner, dynamic MFWs can be used to access memory contents with more time efficiency and energy efficiency than known techniques by substantially reducing (e.g., eliminating) overfetching from memory devices.","Traditional dynamic random access memory (DRAM) designs use row buffers to capture locality in memory references. To increase performance, while maintaining or decreasing physical space requirements, some traditional DRAM architectures are structured such that a DRAM can be operated to quickly retrieve data stored at sequential address locations in response to a single data request and address provided by a processor or memory controller. However, such data access techniques typically result in retrieving more information from a memory than is necessary and, thus, unnecessarily consume more power by activating portions of memory that may not otherwise be needed. For example, processors are typically configured to retrieve one or more entire cache lines from DRAM based on a single read request. A cache line refers to the number of bits or bytes that make up the width of a processor's cache memory (e.g., a 32-byte cache line, a 64-byte cache line, a 128-byte cache line, etc.). In a traditional DRAM module, a single conventional read operation requires activating an entire row of bitlines in each DRAM chip of the DRAM module. Each activated row typically corresponds to multiple cache lines. Thus, even when a processor requests a single cache line, internal DRAM logic must activate all of the bitlines of the DRAM chip row(s) that store(s) the requested cache line. Such known access techniques, achieve fast access performance when there is high locality of adjacently stored information that is needed by the requesting processor in a consecutive manner. That is, by activating an entire row, every cache line stored in that row can be read-out to the requesting processor during consecutive low-latency read cycles (e.g., DRAM burst-mode reads or page-mode reads). While there is some initial overhead delay to read-out the first cache line, each subsequent consecutive cache line can be read out with relatively lower latency from a row buffer because the row buffer already stores the data from the activated row and access to the row buffer is relatively faster than reading from memory cells. However, if the requesting processor ends up using only one cache line from the activated row, significant energy is wasted using these known techniques, especially when memory access locality is reduced as core, thread, and socket counts increase in processor operations.","Multi-core processing decreases short-term memory locality. For example, fetching an 8 kilobyte (KB) row buffer to fulfill just one 64 byte (B) cache line request wastes a significant amount of energy and time and, thus, can create queuing delays. Examples disclosed herein use dynamic MFWs in connection with multiple-subarray access (MSA) to reduce or eliminate overfetch while usefully controlling the amount of memory contents fetched based on an amount of locality associated with such memory contents. That is, when low locality exists in requested memory contents, the dynamic MFW can be decreased to avoid inefficient overfetch. However, when high locality exists in requested memory contents, the dynamic MFW can be increased with low or no overfetch. In some examples, the dynamic MFW can be determined by one or more memory controllers and\/or one or more processors in a multi-core processor system. In some examples, the dynamic MFW can be determined by an operating system (OS) and\/or applications based on information available to the OS and\/or the applications regarding amounts of locality for different memory accesses. In this manner, the OS and\/or the applications can be written to improve (e.g., optimize) their memory accesses based on factors specific to their execution environment.","Some disclosed example methods, apparatus, and\/or articles of manufacture to dynamically determine a MFW involve receiving at least one runtime characteristic associated with accesses to contents of a memory page and dynamically setting a memory fetch width for accessing the memory page based on the at least one runtime characteristic. In some examples, the dynamic adjustment of the memory fetch width is performed by at least one of a memory controller, an operating system, or an application. In some examples, the at least one runtime characteristic is a filled and non-accessed micro-buffer count, and a memory reference count is also received. In such examples, the filled and non-accessed micro-buffer count is indicative of a quantity of data units (e.g., bits, bytes, words, cache lines, etc.) filled in a micro-buffer and not accessed from the micro-buffer, and the memory reference count is indicative of a quantity of fetches from the memory page. In such examples, the dynamic setting of the memory fetch width is performed by determining a ratio of a filled and non-accessed micro-buffer count to a memory reference count for a memory page. In such examples, if the ratio is greater than a first threshold, a dynamic MFW is decreased (e.g., divided by two), and if the ratio is less than a second threshold, the dynamic MFW is increased (e.g., multiplied by two). In some examples, before determining the ratio, it is determined whether the MFW of the memory page is set to a static value, and the ratio is determined only when the MFW of the memory page is not set to the static value. In some such examples, the static value is settable by an operating system or an application executing on a processor in communication with the memory controller. In some examples, the filled and non-accessed micro-buffer count, the memory reference count, and the MFW are stored in a translation lookaside buffer table entry corresponding to the memory page. In some examples, when the MFW is decreased and if the MFW is less than a threshold (e.g., a minimum) allowable MFW (minMFW), the MFW is set to the threshold (e.g., a minimum) allowable MFW (minMFW). In some examples, when the MFW is increased and if the MFW is greater than a threshold (e.g., a maximum) allowable MFW (maxMFW), the MFW is set to the threshold (e.g., a maximum) allowable MFW (maxMFW).","Some disclosed example methods, apparatus, and\/or articles of manufacture to access memory using a dynamic MFW involve a parameter modifier to, if a requested cache line is in a currently open memory page, update a memory reference count for the open memory page and, if the requested cache line is not in the currently open page, update a filled and non-accessed micro-buffer count. In such examples, the memory reference count is indicative of a quantity of fetches from the open memory page, and the filled and non-accessed micro-buffer count is indicative of a quantity of data units (e.g., bits, bytes, words, cache lines, etc.) filled in a row buffer of a memory and non-accessed from the row buffer. In such examples, a memory interface is provided to use a dynamic MFW to retrieve the requested cache line from a second memory page when the requested cache line is not in the currently open page. In some examples, the memory interface is also configured to release a portion of a row buffer when the requested cache line is not in the currently open memory page, and load the requested cache line from the second memory page into the portion of the row buffer. In such examples, a bit length of the portion of the row buffer is equal to the dynamic MFW. In some examples, the parameter modifier is to update the filled and non-accessed micro-buffer count based on a tag value stored in a data structure of a memory controller in association with an identifier of the currently open memory page. In some examples, a processor interface is provided to communicate with a processor and to retrieve the dynamic MFW set by an OS and\/or an application when executed on the processor. In some examples, a parameter interface is provided to communicate the memory reference count and the filled and non-accessed micro-buffer count to a processor. In some examples, a parameter interface is provided to access the memory reference count and the filled and non-accessed micro-buffer count in a data structure of a memory controller.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 1","FIGS. 4"],"b":["100","5","5","100","102","104","104","104","104","104","104"]},"The multi-core processor  of the illustrated example includes multiple cores represented as core  through core m . In addition, the example multi-core processor  includes multiple memory controllers represented as memory controller () through memory controller () . In the illustrated example, each of the cores -includes a respective level 1 (L1) cache -and a respective translation lookaside buffer (TLB) -. The multi-core processor  of the illustrated example also includes a level 2 (L2) cache . Although examples disclosed herein are described in connection with the multi-core processor  having multiple cores -and multiple memory controllers -, examples disclosed herein may additionally or alternatively be implemented in connection with single-core processor systems having one memory controller.","In the illustrated example, the L1 caches -store memory contents frequently and\/or recently accessed by the respective cores -. When memory contents for memory requests by the cores -are not found in the respective L1 caches -, the L2 cache  is checked to determine if the requested memory contents are cached therein. If the requested memory contents are not cached in the L2 cache , a memory access request is sent to one or more of the memory controllers -to retrieve the requested contents from the memory . In some examples, the caches -and  are inclusive meaning that when data is retrieved from the memory , it is written to all levels of cache to reduce the number of accesses to the memory .","In the illustrated example, the TLBs -are substantially similar or identical. Each TLB -of the illustrated example stores memory page information including virtual addresses , physical addresses , control bits , open\/closed page statuses , MFWs , memory reference counts (Fs) , and\/or filled and non-accessed micro-buffer counts (Ws) . In the illustrated example, the virtual addresses  indicate virtual addresses used by the cores -to reference memory pages, the physical addresses  indicate the physical addresses of the memory pages in the memory . The TLBs -of the illustrated example store virtual addresses in association with corresponding physical addresses to enable accessing corresponding memory contents at physical addresses in the memory  based on virtual addresses used by the cores -. The control bits  facilitate memory page accesses.","The open\/closed page statuses  of the illustrated example indicate when corresponding memory pages are open and when they are closed. The MFWs  of the illustrated example indicate MFW values dynamically set for corresponding memory pages. The MFWs  of the illustrated example are used to dynamically control the size or width of data to be retrieved from a memory page and is adjustable dynamically during runtime of the example processor system  as disclosed herein.","In examples disclosed herein, the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  are runtime characteristics of accesses to corresponding memory pages. In the illustrated examples disclosed herein, these runtime characteristics are used to dynamically determine and\/or adjust the MFWs  to dynamically control the size or width of data to be retrieved from corresponding memory pages. The memory reference counts (Fs)  of the illustrated example are indicative of quantities of fetches from corresponding memory pages. If contents from a particular memory page are highly frequently accessed, the memory reference count (F) for that memory page will be relatively larger than for a memory page having contents less frequently accessed.","The filled and non-accessed micro-buffer counts (Ws)  of the illustrated example are indicative of quantities of data units (e.g., bits, bytes, words, cache lines, etc.) filled in micro-buffers of the memory  for respective memory pages and not accessed from the micro-buffers. That is, if memory contents (e.g., a cache line) are retrieved from memory cells of the memory  and stored in micro-buffers (e.g., micro-buffer(s)  of ) but are not accessed from the micro-buffers for one or more of the cores -, resources have been wasted to retrieve such memory contents from memory cells of the memory . As such, the non-accessed cache lines buffered in the micro-buffers are considered wasted. Whenever such a wasted retrieval is detected for a memory page, a corresponding one of the filled and non-accessed micro-buffer counts (Ws)  is increased by the number of data units (e.g., a quantity of cache lines or a quantity of another selected data unit) not accessed from the micro-buffers.","In the illustrated example, the memory controller is provided with an apparatus , and the memory controller is provided with an apparatus . The apparatus -of the illustrated example are substantially similar or identical to one another and are provided to monitor fetches and accesses of memory contents. That is, in the illustrated example, the apparatus -update memory reference counts (Fs) and filled and non-accessed micro-buffer counts (Ws) for respective memory pages and send the memory reference counts (Fs) and the filled and non-accessed micro-buffer counts (Ws) to the respective core(s) -for storing as the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  of the corresponding TLB(s) -. In some examples, the apparatus -determine dynamic MFWs for respective memory pages based on the memory reference counts (Fs) and the filled and non-accessed micro-buffer counts (Ws) and send the dynamic MFWs to the cores -. In other examples, OS(s) and\/or application(s) executing on the core(s) -determine the dynamic MFWs  for respective memory pages based on the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws) , and the core(s) -send the MFW(s)  to the memory controller(s) -in corresponding memory access requests so that the memory controllers -access the memory  using selective activation of only portion(s) of memory arrays based on the dynamic MFWs.","In some examples, the MFWs  can be set to a fixed or static status indicating that the MFWs  should not be modified or changed. In such examples, the fixed or static status can be indicated by a particular binary code used only to indicate such a fixed or static status. In such examples, when an OS or an application encounters an MFW  with the fixed or static status code, the OS and\/or application detect the code and determine that the MFW  should not be updated. In some examples, a user, an OS and\/or an application can set an MFW  to fixed or static mode when such a mode is identified to optimize memory accesses for a particular type of performance and\/or software\/hardware compatibility. In other examples, such a fixed or static mode may be selected when it is desired for hardware\/software to not autonomously adjust (e.g., optimize) memory accesses.","In the illustrated example of , to analyze the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  and determine the MFWs , the core is provided with an example TLB interface , an example ratio determiner , an example parameter modifier , and an example comparator . In the illustrated example, the TLB interface , the ratio determiner , the parameter modifier , and the comparator  may be implemented as one or more logic circuits in the core and\/or machine readable instructions executable by the core . In some examples, the TLB interface , the ratio determiner , the parameter modifier , and the comparator  operate at the direction of logic circuit(s) in the core and\/or at the direction of an OS and\/or one or more application(s) executing on the core to determine the MFWs . In the illustrated example, the MFWs  are dynamically determined in the core by logic circuit(s), by the OS, and\/or by one or more application(s). In other examples, the MFWs  are dynamically determined in the memory controllers -. Although the TLB interface , the ratio determiner , the parameter modifier , and the comparator  are shown only in the core , the core also includes substantially similar or identical logic circuits and\/or machine readable instructions.","In the illustrated example, the TLB interface  is provided to access (e.g., read and\/or write) information in the TLB such as the virtual addresses , the physical addresses , the control bits , the open\/closed page statuses , the MFWs , the memory reference counts (Fs) , and the filled and non-accessed micro-buffer counts (Ws) . In the illustrated example, the ratio determiner  is provided to determine ratios of filled and non-accessed micro-buffer counts (Ws)  to respective memory reference counts (Fs)  (e.g., W:F ratios) of respective memory pages. In the illustrated example, the parameter modifier  is provided to modify the MFWs , the memory reference counts (Fs) , and the filled and non-accessed micro-buffer counts (Ws) . The comparator  of the illustrated example is provided to compare values such as comparing the MFWs  to threshold(s) (e.g., maximum and minimum values), comparing the W:F ratios to threshold value(s), and\/or performing other comparisons.","While an example manner of implementing the TLB interface , the ratio determiner , the parameter modifier , and the comparator  is illustrated in , one or more of the elements, processes and\/or devices illustrated in  may be combined, divided, re-arranged, omitted, eliminated and\/or implemented in any other way. Further, the TLB interface , the ratio determiner , the parameter modifier , and the comparator  of  may be implemented by hardware, software, firmware and\/or any combination of hardware, software and\/or firmware. Thus, for example, any of the TLB interface , the ratio determiner , the parameter modifier , and the comparator  could be implemented by one or more circuit(s), programmable processor(s), application specific integrated circuit(s) (ASIC(s)), programmable logic device(s) (PLD(s)) and\/or field programmable logic device(s) (FPLD(s)), etc. When any of the apparatus and\/or system claims of this patent are read to cover a purely software and\/or firmware implementation, at least one of the TLB interface , the ratio determiner , the parameter modifier , and\/or the comparator  is hereby expressly defined to include a tangible computer readable medium such as a memory, DVD, CD, etc. storing the software and\/or firmware. Further still, the example core illustrated in  may include one or more elements, processes and\/or devices in addition to, or instead of, those illustrated in , and\/or may include more than one of any or all of the illustrated elements, processes and devices.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 2","FIG. 1","FIG. 2","FIG. 2","FIG. 1"],"b":["104","104","202","104","202","202","204","202","204","202","206","208","108","208"],"i":["a","h","a","h ","e","h ","e","h","e","h ","e","h ","e","h","a","b ","e","h "]},"If a dynamic MFW is set to fewer than four (4) during a subsequent access, less than the four chips -are activated, and when the dynamic MFW is set to greater than four (4) during a subsequent access, more than the four chips -are activated. That is, the number of activated chips -is equal to the dynamic MFW. In examples in which the dynamic MFW is set to eight (8) or more, all eight of the chips -are activated.","In some examples, an OS selects a default setting for a memory page's dynamic MFW (e.g., the default MFW value could be selected on a per-application or per-process basis) and then adjusts corresponding memory page's dynamic MFW using per-page hardware metrics (e.g., the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  of the TLBs -) provided in a feedback loop. In such examples, the OS uses the metrics (e.g., the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  of the TLBs -) to determine when dynamic MFW values of respective memory pages lead to excessive overfetching or insufficient locality (e.g., filled and non-accessed micro-buffers). When overfetching or insufficient locality is detected for a particular memory page, the OS of the illustrated example can change the dynamic MFW for that memory page. In some examples, the OS is provided with an application programming interface (API) to allow applications executing in the OS environment to analyze and change dynamic MFW values based on the metrics (e.g., the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  of the TLBs -).","Examples disclosed herein are implemented using an open-page policy. In some examples, having smaller MFWs significantly improves parallelism in memory and reduces the probability of conflicts. As a result, relatively few accesses incur increased delay due to precharge operations being in the critical path.","Turning to , the DRAM chip is shown in detail with a plurality of bit cell array banks  that store information, a row decoder , and a column decoder . Each bit cell array bank  is arranged as rows of bit cells that store information. A row  is shown in one of the banks  and is also referred to herein as a wordline. In the illustrated example, the row decoder  receives the row address from a memory controller (e.g., one of the memory controllers -of ), and the column decoder  receives the column address from the memory controller (e.g., one of the memory controllers -of ). The row decoder  and the column decoder  then concurrently decode their respective address information to selectively activate a portion of the row  (or wordline) within a particular one of the cell array banks  containing the requested information. The activated portion of the row  is shown as the portion of  and denoted herein as a wordline segment , which is a portion of the row  that is activatable without requiring activation of other portions of the same row . In the illustrated example of , separate wordline segments of respective ones of the DRAM chips --can be activated and read out as discussed below with reference to the DRAM chip illustrated in . In this manner, the bits read out from the separate SDRAM chips --can be concatenated to form a cache line requested by a memory controller (e.g., one of the memory controllers -of ). In the illustrated example of , a 64-byte cache line is formed by concatenating 8-bit data outputs from each of the DRAM chips --to form eight 64-bit cache line portions or segments that are subsequently concatenated to form the entire cache line.","When the wordline segment is active, its bits are loaded into the row buffer for output via data I\/O buffer . The wordline segment can include a number of bits equal to or greater than the width of the data I\/O bus of the DRAM chip . In the illustrated example, each of the DRAM chips -() has an 8-bit data I\/O bus. Thus, for a cache line that is 64 bytes wide, each activated wordline segment (the wordline segment ) of each DRAM chip -stores a portion or segment of a requested 64-byte cache line. When each of the DRAM chips -retrieves 8 bits from its respective wordline segment, the 8 bits from each of the DRAM chips -are concatenated to form 64 bits output by the memory . This process can be repeated until the DRAM chips -have provided the entire 64-byte cache line. In such an example implementation, each of the DRAM chips -stores a respective 8 bytes of the 64-byte cache line.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 4","FIGS. 2 and 3","FIG. 4","FIG. 3"],"b":["202","104","304","306","202","202","208","308"],"i":["f ","f ","f ","f "]},"In the illustrated example of , two rows (or wordlines)  and  of the DRAM chip are shown. Each row  and  includes a main wordline (MWL) and controlling sub-wordlines (SWL). In some example implementations, the MWL's are formed in first-level metal and the SWLs are formed in a poly layer. In the illustrated example, access to the row  is enabled through assertion of a MWL line  and access to the row  is enabled through assertion of a MWL line . The SWL's connect to memory bit cells in different memory cell arrays. In the illustrated example, a SWL  connects to the wordline segment of  to enable selectively activating the wordline segment to transfer its bits to the data I\/O buffer .","To enable activating the SWLs, the DRAM chip of the illustrated example is provided with region select (RX) \u2018AND\u2019 gates, one of which is denoted by reference numeral . In addition, the DRAM chip is provided with SWL \u2018AND\u2019 gates, one of which is denoted by reference numeral . The RX \u2018AND\u2019 gates (e.g., RX-, RX-, RX-N) and the SWL \u2018AND\u2019 gates enable selecting particular SWLs within respective columns of memory arrays. Although \u2018AND\u2019 gates are shown in the illustrated example, other logic gates such as \u2018NOR\u2019 gates can be used instead. In examples employing NOR gates, the signal polarities of MWL and RX signal lines are inverted to operate with the \u2018NOR\u2019 gates. In the illustrated example, a first input of the SWL \u2018AND\u2019 gate  is connected to the RX-N \u2018AND\u2019 gate  and a second input of the SWL \u2018AND\u2019 gate  is connected to the MWL line . In addition, the output of the SWL \u2018AND\u2019 gate  is connected to the SWL  to activate the SWL  upon assertion of the MWL line  and the output of the RX-N \u2018AND\u2019 gate . The other SWL \u2018AND\u2019 gates of the DRAM chip are connected in an analogous manner so that any one of the SWLs of the DRAM chip can be selected for outputting based on selecting a corresponding combination of an RX \u2018AND\u2019 gate (e.g., the RX-N \u2018AND\u2019 gate ) and a MWL (e.g., the MWL line ).","As shown in , the MWL line  and the MWL line  are connected to the row decoder , and the RX \u2018AND\u2019 gates are connected to the column decoder . In an example implementation that uses 15 bits for row addresses, the row decoder  can decode the selection of up to 32,768 MWLs. In an example implementation that uses 11 bits for column addresses, the inputs of the RX \u2018AND\u2019 gates can be connected to the least significant 7 bits of the column address interface of the column decoder  to enable individual selection of any one of up to 128 SWLs. In the illustrated example, when the row decoder  asserts a high signal on the MWL line  and the address output by the column decoder  selects the RX-N \u2018AND\u2019 gate , the inputs of the SWL \u2018AND\u2019 gate  are both high, causing the output of the SWL \u2018AND\u2019 gate  to activate the wordline segment  for outputting its bits onto the data I\/O buffer .","In the illustrated example of , the MWL line  and the MWL line  are loaded only by a few SWL \u2018AND\u2019 gates, which significantly reduces the capacitance on the MWLs and, thus, their signal propagation delays. When only a subset of the CAS address is used to trigger RX signals associated with the RX \u2018AND\u2019 gates as discussed above, the activation area and wordline\/bitline energy is advantageously reduced (e.g., less address lines are routed). In addition, energy is also advantageously conserved because the MWLs are not directly connected to the memory cells. As a result of not being directly connected to the memory cells, activation of an MWL across a memory array does not result in destruction of data, because only a small subset of memory cells (e.g., the wordline segment ) connected to the active SWL read their data out.","In some example implementations, it may be die-area prohibitive or cost-prohibitive to provide the quantity of \u2018AND\u2019 gates (e.g., SWL \u2018AND\u2019 gates and RX \u2018AND\u2019 gates) to enable a single cache line per access. In such example implementations, less \u2018AND\u2019 gates can be provided with the tradeoff in energy required to activate and read out more cache lines per access. For example, the DRAM chip depicted in  can be implemented with less \u2018AND\u2019 gates to instead read out 16 cache lines per access (e.g., the SWLs become 16 times longer between \u2018AND\u2019 gates). Such an example implementation still produces relatively high energy savings over known DRAM chips.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 5","FIG. 1","FIG. 1","FIG. 5","FIG. 5","FIG. 5","FIG. 5","FIG. 5","FIG. 5"],"b":["136","136","104","136","502","504","506","508","510","512","516","518","520","136","136","502","504","506","508","510","512","516","518","520","136","136","502","504","506","508","510","512","516","518","520","136","136","502","504","506","508","510","512","516","518","520","136","136"],"i":["a ","a ","a ","a","b","a","b","a","b","a ","b ","a","b","a","b","a","b","a ","b ","a","b","a","b","a","b","a ","b ","a","b","a","b","a","b","a ","b "]},"In the illustrated example, the example apparatus is shown communicatively coupled to example micro-buffer(s)  in the memory  of . The example micro-buffer(s)  form a sub-set of a row buffer (e.g., the row buffer(s) -of ) in the memory  (e.g., DRAM). If a micro-buffer  has valid content corresponding to a memory request, then the requested data can be read from the micro-buffer  rather than needing to activate bitlines to read the data from corresponding memory cells.","The example memory controller of  controls operations of the DRAM memory  of . As part of such control, the apparatus of  is provided to facilitate dynamically determining MFWs and using such dynamic MFWs to access the memory . In the illustrated example of , the apparatus is provided with bank issue queues -to queue requests for read and\/or write accesses to the memory . In the illustrated example, the memory controller uses a First Ready First Come First Serve (FR-FCFS) policy to schedule requests in the bank issue queues -for the banks (e.g., the banks  of ) by prioritizing requests to the currently open memory page. In examples that supports multiple MFWs, cache lines from up to 128 different memory pages can be in a row buffer (e.g., the row buffer of ). Thus, the memory controller of the illustrated example of  tracks all the open cache lines to take advantage of the open page policy. The example memory controller tracks open cache lines by maintaining  tags for each DRAM bank. In some examples, while scheduling requests for use with dynamic MFW implementations, searching the bank issue queues -for all open cache lines in a row buffer may not be feasible. In such examples, a First Come First Serve (FCFS) policy is used to queue memory access requests.","The micro-buffer tracking tables -(i.e., micro-buffer tracking data structures) of the illustrated example are provided to track when data fetched and stored in the micro-buffers  is used (e.g., accessed for sending to the core(s) -of ). In the illustrated example, the memory  is provided with the micro-buffers  to store data fetched from memory cells (e.g., the portions  of the rows of ) of the memory  (). For each bank (e.g., the banks  of ) with a row-buffer size of 8 KB, the memory  maintains 128 64-byte micro-buffers (e.g., the micro-buffers ) in a row buffer (e.g., the row buffers -of ). The micro-buffer tracking tables -associate memory page numbers  and corresponding used\/unused tags  with each micro-buffer . The memory page numbers  of the illustrated example correspond to the most recent data fetched from the memory  and stored in the micro-buffers . Each used\/unused tag  is a bit indicating whether fetched data from a corresponding memory page has been used since it was fetched from memory cells of the memory  and stored in the micro-buffer(s) .","In the illustrated example of , the micro-buffer tracking table is shown tracking pages corresponding to three memory references. In examples disclosed herein, memory references are included in memory access requests and are used to identify sources (e.g., cores or process threads) of memory access requests made to memory controllers (e.g., the memory controllers -of ) from cores (e.g., the cores -of ). In , a first memory reference corresponds to memory page  micro-buffer tracking entries , a second memory reference corresponds to a memory page  micro-buffer tracking entry , and a third memory reference corresponds to memory page  micro-buffer tracking entries . In the illustrated example, the memory page  micro-buffer tracking entries  have a MFW equal to two (MFW=2), the memory page  micro-buffer tracking entry  has a MFW equal to one (MFW=1), and the memory page  micro-buffer tracking entries  have a MFW equal to four (MFW=4). The micro-buffer tracking table of the illustrated example is also shown as having two invalid entries  into which valid data from the memory  has not been stored. In some examples, an entry in the micro-buffer tracking table is indicated as invalid by storing an otherwise unlikely or impossible page number identifier value for a corresponding page number  of the invalid entry in the micro-buffer tracking table . In other examples, an entry in the micro-buffer tracking table is indicated as invalid by the use of an additional valid\/invalid tag bit field (not shown) in the micro-buffer tracking table ","When a memory access request having a memory reference associated with MFW=n is made by one of the cores -of  to address (A), the comparator  compares the page number for the address (A) against the page numbers  stored in the memory page micro-buffer tracking entries , , and . Each cache line request maps to an entry in the micro-buffer(s) , which can be identified from the memory reference address. If the page number of the memory reference matches the page number of the corresponding entry in the micro-buffer , then the memory access request is a hit (i.e., a hit to the micro-buffers ). That is, if the page number of the address (A) is three (i.e., page number ) and if it maps to the first or second entry in the micro-buffer  (e.g., noted in the memory page  micro-buffer tracking entries ), then the corresponding memory reference is a hit, meaning that the requested data from address (A) is buffered in the micro-buffer(s)  and can be retrieved therefrom rather than needing to fetch the data from the memory cells.","In the illustrated example, used\/unused tags  are set equal to zero (0) in micro-buffer tracking entries when a new page is activated. When a hit is detected, the parameter modifier  updates the used\/unused tag  of the number of corresponding page number entries equal to the MFW. For example, if the memory reference is for page number , first entry, the used\/unused tag  corresponding to the first entry of the memory page  micro-buffer tracking entries  is set equal to one (1) as shown in  meaning that it has been accessed from the micro-buffer(s)  since it was fetched from the memory . Used\/unused tags  that remain equal to zero (0) in other micro-buffer tracking entries of  mean that they have not been accessed from the micro-buffer(s)  since they were fetched from the memory . If MFW=1 and the memory reference is for page number , the memory page  micro-buffer tracking entry  is set to one (1) as shown in . In the illustrated example of , two of the four memory page  micro-buffer tracking entries  are set to one (1) meaning that at least two memory access requests have been made to the memory controller since the data corresponding to the memory page  micro-buffer tracking entries  has been fetched from memory cells of the memory  and stored in the micro-buffer(s) .","In the illustrated example, the apparatus is provided with the fetch and access status table to track memory reference counts (Fs)  and filled and non-accessed micro-buffer counts (Ws)  for respective memory pages . The memory pages  noted in the fetch and access status table correspond to the memory pages  tracked in the micro-buffer tracking table . In the illustrated example, the processor interface  sends the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  from the fetch and access status table to the cores -of  for storing as the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws) , respectively, of the TLBs -. In this manner, an OS and\/or application(s) executing on the core(s) -can use the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  to determine the dynamic MFW  (). In the illustrated example, the parameter modifier  determines the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws) , and the parameter interface  stores and retrieves the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  to\/from the fetch and access status table ","Although the fetch and access status table show the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  for use in the illustrated example for determining the MFWs  of , in other examples additional or alternative types of parameters may be useful for determining the MFWs . Such additional or alternative parameters may include the total number of bytes fetched from DRAM cells, the number of read stalls; or the mean depth of the bank issue queues -","Although the micro-buffer tracking table and the fetch and access status table are not shown in detail, the micro-buffer tracking table is substantially similar or identical to the micro-buffer tracking table and the fetch and access status table is substantially similar or identical to the fetch and access status table . In the illustrated example, the micro-buffer tracking table and the fetch and access status table are used in connection with memory access requests made via the bank  issue queue , and the micro-buffer tracking table and the fetch and access status table are used in connection with memory access requests made via the bank issue z queue ","The request interface  of the illustrated example is provided to retrieve memory access requests from the bank issue queues -. In addition, the request interface parses the information in the memory access requests to identify memory references, addresses, memory pages, and MFWs. In the illustrated example, the core(s) -send MFW values (e.g., the MFW  from the TLB(s) -) with memory access requests so that the memory controller(s) -can access the memory  using most recently updated MFWs for respective memory pages.","The memory interface  of the illustrated example is provided to access the memory  () to read and\/or write data from\/to the memory . In the illustrated example, the memory interface  causes the memory  to partially activate lines or portions of the memory as described above in connection with  to retrieve data based on dynamic MFWs.",{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIG. 6","FIG. 1","FIG. 1","FIGS. 7A and 7B","FIG. 1","FIGS. 6","FIGS. 1 and 5","FIG. 1"],"b":["128","104","128","7","7","106","108","136","106","108","136"],"i":["b","a","a ","a","b","b "]},"The example processes of , A, and B may be implemented using machine readable instructions that, when executed, cause a device (e.g., a programmable controller, processor (e.g., the multi-core processor  of ), or other programmable machine or integrated circuit) to perform the operations shown in , A, and B. For instance, the example processes of , A, and B may be performed using a processor, a controller, and\/or any other suitable processing device. For example, the example processes of , A, and B may be implemented using coded instructions stored on a tangible machine readable medium such as a flash memory, a read-only memory (ROM), and\/or a random-access memory (RAM).","As used herein, the term tangible computer readable medium is expressly defined to include any type of computer readable storage and to exclude propagating signals. Additionally or alternatively, the example processes of , A, and B may be implemented using coded instructions (e.g., computer readable instructions) stored on a non-transitory computer readable medium such as a flash memory, a read-only memory (ROM), a random-access memory (RAM), a cache, or any other storage media in which information is stored for any duration (e.g., for extended time periods, permanently, brief instances, for temporarily buffering, and\/or for caching of the information). As used herein, the term non-transitory computer readable medium is expressly defined to include any type of computer readable medium and to exclude propagating signals.","Alternatively, the example processes of , A, and B may be implemented using any combination(s) of application specific integrated circuit(s) (ASIC(s)), programmable logic device(s) (PLD(s)), field programmable logic device(s) (FPLD(s)), discrete logic, hardware, firmware, etc. Also, the example processes of , A, and B may be implemented as any combination(s) of any of the foregoing techniques, for example, any combination of firmware, software, discrete logic and\/or hardware.","Although the example processes of , A, and B are described with reference to the flow diagrams of , A, and B, other methods of implementing the processes of , A, and B may be employed. For example, the order of execution of the blocks may be changed, and\/or some of the blocks described may be changed, eliminated, sub-divided, or combined. Additionally, one or both of the example processes of , A, and B may be performed sequentially and\/or in parallel by, for example, separate processing threads, processors, devices, discrete logic, circuits, etc.","Turning to , the apparatus uses dynamic MFWs (e.g., the MFW(s)  of ) to access memory contents in the memory  (). Initially, the request interface  () selects a memory access request (e.g., a read request) from the bank  issue queue (block ). In the illustrated example, the request interface  parses the memory access request to identify the MFW (e.g., the MFW ), a memory reference (e.g., a memory reference corresponding to a requesting core and\/or process thread), and the address (A) of the memory location to which access is requested. The memory interface  () finds the cache line location of a requested cache line in a row buffer (block ). For example, the memory interface  finds the cache line location in the row buffer -() based on the address (A) from the memory access request.","The memory interface  determines whether the requested cache line is located in the currently open memory page (block ). That is, the contents in a row buffer correspond to a currently open memory page, and the memory interface  determines whether the requested cache line is in the row buffer if the contents of the cache line location found at block  correspond to the address (A) from the memory access request. If the requested cache line is located in the currently open memory page (block ), the memory interface  reads the requested cache line from the row buffer (block ). The parameter modifier  updates the memory reference count (F)  () for the currently open memory page (block ).","If the requested cache line is not located in the currently open memory page (block ), the memory interface  closes the currently open memory page (block ). The memory interface  retrieves the dynamic MFW  from the request interface  (block ) and writes back the data from the row buffer section demarcated by the cache line start bit location (e.g., corresponding to the address (A)) to the end of the dynamic MFW  (block ). For example, if the cache line start address is 0x0100h and the dynamic MFW  is two (e.g., two 32-bit words), the memory interface  writes back data from the row buffer that corresponds to bit locations 0x0100h through 0x0108h (i.e., write-back locations=(A)+0x0008h, where (A)=address 0x0100h, and 0x0008h corresponds to two 32-bit words in byte-addressable address locations). The memory interface  then releases or frees the row buffer section demarcated by the cache lines start and the end of the dynamic MFW  (block ).","The parameter modifier  updates the filled and non-accessed micro-buffer counts (Ws)  () for all the closed memory pages (block ). For example, for all the memory pages noted in the micro-buffer tracking table and that are currently closed, the parameter modifier  checks the used\/unused tags  to determine which are noted as zero (0). For those memory pages having a used\/unused tag  set to zero (0), the parameter modifier  increments a corresponding one of the filled and non-accessed micro-buffer counts (Ws)  in the fetch and access status table ","The memory interface  uses the dynamic MFW  to load\/read the requested cache line from the memory  into the row buffer -(block ). The processor interface  then returns the requested cache line from the row buffer -to a requesting one of the cores -of  (block ). The apparatus determines whether another memory access request is pending (block ). For example, the apparatus may poll the bank issue queue(s) -() to determine whether any other memory access requests are waiting to be serviced. If another memory access request is pending, control returns to block . Otherwise, the example process of  ends.","Turning to , the illustrated example process may be used to determine dynamic MFWs (e.g., the MFW(s)  of ). The example process of  is only an example manner useful to dynamically determine different values for the MFW(s) . In some examples, other manners of dynamically determining values for the MFW(s)  may be employed. In the illustrated example, the example process of  is performed periodically at a rate suitable to update the dynamic MFWs  at a rate (e.g., once every millisecond, once every second, etc.) that keeps the MFWs  relevant to the performance of the OS and\/or application(s) executing on the core . The example process of  is described as being implemented at the core of  using the TLB interface , the ratio determiner , the parameter interface , and the comparator  of  implemented as one or more logic circuits in the core and\/or as machine readable instructions executed on the core and accessible to an OS and\/or an application also executing on the core . In other example implementations, the example process of  is implemented substantially similarly or identically in the core , in the apparatus of the memory controller , and\/or in the apparatus of the memory controller ","Initially, the TLB interface  selects an entry of the TLB (block ) (). The TLB interface  determines whether the memory page of the selected TLB entry is set to a static MFW (block ). If the selected TLB entry is set to a static MFW, control advances to block  of . Otherwise, if the selected TLB entry is not set to a static MFW, the TLB interface  determines whether the TLB entry has been referenced recently (block ). For example, the TLB interface  may determine whether the entry has been recently accessed based on a recent access bit or similar bit in the control bits  (). If the selected TLB entry has not been recently referenced, control advances to block  of . Otherwise, if the selected TLB entry has been recently referenced, the ratio determiner  determines a filled and non-accessed micro-buffer count (W)-to-memory reference count (F) ratio (i.e., a W:F ratio) (block ) for the memory page of the selected TLB entry. For example, the ratio determines  retrieves the filled and non-accessed micro-buffer count (W)  and the memory reference count (F)  from the TLB for the memory page of the selected TLB entry and determines the W:F ratio based on the retrieved values.","The comparator  determines whether the W:F ratio is greater than a decrement threshold (decTHRESH) (block ). In the illustrated example, when the W:F ratio is greater than the decrement threshold (decTHRESH), a corresponding MFW  is decreased. In some examples, the decrement threshold (decTHRESH) is selected to control the maximum value of the MFW  in such a way that minimizes latency associated with accessing memory contents from the memory  of . If the W:F ratio is greater than the decrement threshold (decTHRESH) (block ), the parameter modifier  decreases the corresponding dynamic MFW  (block ). The comparator  determines whether the dynamic MFW  is less than a minimum allowable MFW (minMFW) (block ). In the illustrated example, when the MFW  is less than the minimum allowable MFW (minMFW), it is set equal to the minimum allowable MFW (minMFW). In some examples, the value of the minimum allowable MFW (minMFW) is selected so that inadvertent underfetching of data from the memory  does not cause an excessive amount of accesses to the memory  to retrieve data for a memory access request. If the dynamic MFW  is less than the minimum allowable MFW (minMFW) (block ), the parameter modifier  sets the dynamic MFW  of the selected TLB entry equal to the minimum allowable MFW (minMFW) (block ). After setting the dynamic MFW  of the selected TLB entry equal to the minimum allowable MFW (minMFW) at block  or if the comparator  determines that the dynamic MFW is less than the minimum allowable MFW (minMFW) at block , control advances to block  of .","If at block  the comparator determines that the W:F ratio is not greater than the decrement threshold (decTHRESH), control advances to block  of  at which the comparator  determines whether the W:F ratio is less than an increment threshold (incTHRESH) (block ) (). In the illustrated example, when the W:F ratio is less than the increment threshold (incTHRESH), a corresponding MFW  is increased. In some examples, the increment threshold (incTHRESH) is selected to control the minimum value of the MFW  in such a way that minimizes a quantity of access to the memory  necessary to retrieve requested memory contents from the memory  of .","If the W:F ratio is not less than the increment threshold (incTHRESH) (block ), control advances to block . Otherwise, if the W:F ratio is less than the increment threshold (incTHRESH) (block ), the parameter modifier  increases the corresponding dynamic MFW  (block ). The comparator  determines whether the dynamic MFW  is greater than a maximum allowable MFW (maxMFW) (block ). In the illustrated example, when the MFW  is greater than the maximum allowable MFW (maxMFW), it is set equal to the maximum allowable MFW (maxMFW). In some examples, the value of the maximum allowable MFW (maxMFW) is selected so that inadvertent overfetching of data from the memory  does not cause an excessive latency in accessing the memory  to retrieve data for a memory access request. If the dynamic MFW  is not greater than the maximum allowable MFW (maxMFW) (block ), control advances to block . Otherwise, if the dynamic MFW  is greater than the maximum allowable MFW (maxMFW) (block ), the parameter modifier  sets the dynamic MFW  of the selected TLB entry equal to the maximum allowable MFW (maxMFW) (block ).","In the illustrated example of , blocks ,  and  are useful to apply a decay rate on the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  of  so that the dynamic MFWs  can be modified at a suitable rate relevant to current performance needs and\/or desires of the OS and\/or applications executing on the core . That is, blocks ,  and  are useful to decay or lessen the effects of the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  when they become old or stale. If the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  are remembered for too long without adjusting, the core will be too slow in adapting to changing OS and\/or application behavior. If the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  are zeroed or forgotten too quickly, the dynamic MFW  may be changed abruptly based on short-term outlying noise. Blocks ,  and  facilitate decaying the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  using an exponentially-weighted moving average (EWMA). That is, on each periodic TLB scan of the illustrated example, the parameter optimizer  decays the memory reference counts (Fs)  and the filled and non-accessed micro-buffer counts (Ws)  based on an EWMA decay counter value (\u03b2). For example, the comparator  determines whether the EWMA decay counter value (\u03b2) is greater than one (1) (block ). If the EWMA decay counter value (\u03b2) is not greater than one (1), control advances to block . Otherwise, if the EWMA decay counter value (\u03b2) is greater than one (1), the parameter modifier  sets the memory reference count (F)  equal to the memory reference count (F)  divided by the EWMA decay counter value (\u03b2) (block ). In addition, the parameter modifier  sets the filled and non-accessed micro-buffer counts (W)  equal to the filled and non-accessed micro-buffer counts (W)  divided by the EWMA decay counter value (\u03b2) (block ).","The TLB interface  determines whether there is another TLB entry in the TLB to process (block ). If there is another TLB entry to process, the TLB interface  selects the next TLB entry (block ), and control returns to block  of . Otherwise, if there is not another TLB entry to process, the examples process of  ends.","Although the above discloses example methods, apparatus, and articles of manufacture including, among other components, software executed on hardware, it should be noted that such methods, apparatus, and articles of manufacture are merely illustrative and should not be considered as limiting. For example, it is contemplated that any or all of these hardware and software components could be embodied exclusively in hardware, exclusively in software, exclusively in firmware, or in any combination of hardware, software, and\/or firmware. Accordingly, while the above describes example methods, apparatus, and articles of manufacture, the examples provided are not the only way to implement such methods, apparatus, and articles of manufacture. Thus, although certain methods, apparatus, and articles of manufacture have been described herein, the scope of coverage of this patent is not limited thereto. To the contrary, this patent covers all methods, apparatus, and articles of manufacture fairly falling within the scope of the claims either literally or under the doctrine of equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0004","num":"0003"},"figref":["FIG. 1","FIGS. 6"],"b":["7","7"]},{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0007","num":"0006"},"figref":["FIG. 4","FIGS. 2 and 3"]},{"@attributes":{"id":"p-0008","num":"0007"},"figref":["FIG. 5","FIG. 1"]},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIGS. 7A and 7B"}]},"DETDESC":[{},{}]}
