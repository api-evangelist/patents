---
title: Generation and use of a data structure for distributing responsibilities among multiple resources in a network storage system
abstract: The technique introduced here includes generating a data structure for use in determining how responsibilities for services should be distributed amongst a plurality of resources in a network storage system. The technique includes an iterative process of optimizing the data structure for a plurality of performance/quality metrics, such as evenness of storage consumption across the storage system or a designated subset thereof, number of “hot spots”, degree of data scatter, and number of changes needed to reflect a change in storage system geometry. The data structure can be a striping table for striping logical containers of data across multiple storage resources, such as data volumes, or physical storage devices. The “responsibilities for services”, can include responsibility for storing a stripe of a logical container of data or responsibility for storing a segment of parity data for a logical container of data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08161076&OS=08161076&RS=08161076
owner: NetApp, Inc.
number: 08161076
owner_city: Sunnyvale
owner_country: US
publication_date: 20090402
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["At least one embodiment of the present invention pertains to network storage systems, and more particularly, to a technique for generating and using a data structure for distributing responsibilities among multiple resources in a network storage system.","A network storage controller is a processing system that is used to store and retrieve data on behalf of one or more hosts on a network. A storage server is a type of storage controller that operates on behalf of one or more clients on a network, to store and manage data in a set of mass storage devices, such as magnetic or optical storage-based disks or tapes. Some storage servers are designed to service file-level requests from hosts, as is commonly the case with file servers used in a network attached storage (NAS) environment. Other storage servers are designed to service block-level requests from hosts, as with storage servers used in a storage area network (SAN) environment. Still other storage servers are capable of servicing both file-level requests and block-level requests, as is the case with certain storage servers made by NetApp, Inc. of Sunnyvale, Calif.","A plurality of storage server nodes can be interconnected to provide a storage system environment configured to service many clients. Each storage server node can be configured to service one or more volumes, wherein each volume stores one or more logical containers of data (e.g., files, LUNs, etc.). Yet often a large number of data access requests issued by the clients are directed to a small number of such data containers serviced by a particular storage system of the environment. A solution to this problem is to distribute the volumes among all of the storage server nodes of the storage system environment. This, in turn, distributes the data access requests, along with the processing resources needed to service such requests, among all of the storage server nodes, thereby reducing the individual processing load on each node. However, a noted disadvantage arises when only a single data container, such as a file, is heavily accessed by clients of the storage system environment. As a result, the storage server node attempting to service the requests directed to that data container may exceed its processing resources and become overburdened, with a corresponding degradation of speed and performance.","One solution to this problem is to use a striped file system. A striped file system is a file system that includes multiple data volumes, where each file is distributed (\u201cstriped\u201d) across multiple volumes. For any given file, some amount of data for the file (the first \u201cstripe\u201d, for example, the first 1 MB of data) is stored contiguously within one volume, then a different volume is chosen to store the next stripe of data, and yet another volume is responsible for the stripe after that, and so on.","A consumer of a file is made aware of this striping pattern, so that the appropriate volume can be consulted to perform read or write access against the desired stripe of the file. The striping pattern is often stored in a data structure called a \u201cstriping table\u201d. A striping table is a data- or load-allocation data structure, which stores the pattern for striping data for a particular logical container of data (e.g., a file) across a plurality of storage resources (e.g., volumes). A particular striping table is made of multiple cells, where each cell corresponds to a different stripe of the logical data container and includes an identifier of the volume (or other storage resource) that contains that stripe. The table is considered infinitely repeating, so that if the desired stripe is beyond the end of the table, the \u201cowner\u201d volume for that stripe is given by the requested stripe modulo the number of cells in the table. Note that a striped file system typically hides the striping from the ultimate client, however, by embedding the knowledge of the striping pattern within a module that receives client requests and forwards them to an appropriate volume.","A particular striping table is tied to the number of constituent volumes (or other resources) making up the storage for the striped file system. For example, a striping table for storing data in a file system consisting of four volumes may not be suitable for a file system in which files are striped across three, five, or some other number of volumes.","Further, the particular layout of a striping table can affect the performance of a storage system. There are various performance related criteria on which one can judge the strength of a particular striping pattern (as represented in a striping table), such that some layouts of striped data may be preferable to others. One problem often encountered when generating a striping table, however, is that some of these criteria are mutually antagonistic, such that designing a striping pattern that is strong in one criterion might impair its performance in another criterion.","Another problem is associated with changes in the file system that increase or decrease the number of volumes across which data is striped. Because the striping table is tied to the number of volumes, the striping table needs to be modified when the geometry of the file system is changed in this way. Depending on the striping algorithm employed, adding or deleting even a single volume can necessitate modifying a significant portion of the striping table, which correspondingly implies having to migrate a large portion of the stored data to different volumes. Such data migration can be time-consuming and undesirably consumes computing resources and communications bandwidth.","The technique introduced here includes generating a data structure for use in determining how responsibilities for services should be distributed amongst a plurality of resources in a network storage system. The technique includes an iterative process of optimizing the data structure for a plurality of performance\/quality metrics. The plurality of the metrics can measure, for example, the evenness of storage consumption across the storage system or a designated subset thereof, the number of \u201chot spots\u201d (discussed below) in the storage system, the degree of data scatter in the storage system, and the number of changes needed to reflect a change in the geometry of the storage system. This technique therefore can be used to optimize the design of such data structure (e.g., a striping table) over essentially any number of different criteria, and can be used to reduce the number of changes required to the data layout in a storage system when the geometry of the storage system is changed (e.g., by adding or deleting volumes). The technique can be implemented in a network storage controller.","The data structure can be a striping table for use in striping logical containers of data (e.g., files or LUNs) across a plurality of storage resources, where each cell in the table corresponds to a different stripe and includes an identifier of the owner volume of that stripe. The resources can be, for example, data volumes, or physical storage devices in a redundant array of independent disks\/devices (RAID) group. The \u201cresponsibilities for services\u201d, can include, for example, responsibility for storing a stripe of a logical container of data or responsibility for storing a segment of parity data for a logical container of data.","In certain embodiments, the iterative technique includes successively adding regions to the data structure until the number of regions equals the number of volumes in the storage system. After each instance of adding a region to the data structure, the following is done before another region is added: For each of the existing regions, cells in the region are successively replaced with an identifier of a new volume (i.e., a volume not yet represented in the data structure), and the table is scored for the plurality of metrics after each such instance of replacing a cell; then one cell in the region is selected for replacement, based on overall results of said scoring, and the cell is replaced with the identifier of the new volume. The iterative process includes repeating this scoring and selection, for each region of the data structure, and then further repeating this process for all regions each time a region is added to the data structure, while the number of regions is less than or equal to the number of volumes in the storage system.","Other aspects of the technique will be apparent from the accompanying figures and from the detailed description which follows.","References in this specification to \u201can embodiment\u201d, \u201cone embodiment\u201d, or the like, mean that the particular feature, structure or characteristic being described is included in at least one embodiment of the present invention. Occurrences of such phrases in this specification do not necessarily all refer to the same embodiment.","This description describes a technique of data layout mainly in the context of striping file data in a distributed file system. Note, however, that this technique or a substantially similar technique is also suitable for use in a number of other types of systems and contexts. For example, another possible use is within a RAID subsystem, to choose which constituent of a RAID array should store parity data. By using this technique, one can increase RAID performance, reduce or eliminate latency resulting from sequential access (which is a very common workload) and still allow rapid expansion of the RAID array without rebuilding the majority of the RAID parity data.","Other applications for the technique introduced here can also be envisioned, potentially occurring wherever a collection of systems must distribute a shared responsibility granularly among themselves. Scheduling systems, queuing models and so forth are potential candidates for benefiting from the technique introduced here.","System Environment","Before discussing the technique introduced here, it is useful to consider a computing environment in which the technique can be implemented.  shows such a computing environment, which includes a plurality of nodes  interconnected as a cluster of a clustered computing environment. The nodes  are configured to provide storage services relating to the organization of information on storage devices, such as a disk array . The nodes  include various functional components that cooperate to provide a distributed storage system architecture of the cluster. Further, each node  is organized to include a network element (\u201cN-blade\u201d)  and a data element (\u201cD-blade\u201d) . The N-blade  includes functionality that enables the node  to connect to clients  over a connection system , while each D-blade  connects to one or more storage devices, such as disks  of a disk array . Note that another embodiment, the storage devices could be devices other than disks, such as flash memory, tape storage, etc. The nodes  are interconnected by a cluster switching fabric  which, in the illustrated embodiment, can be embodied as a Gigabit Ethernet switch.","The N-blades  and D-blades  cooperate to provide a highly-scalable, distributed storage system architecture of a clustered computing environment implementing exemplary embodiments of the present invention. Note that while there is shown an equal number of N-blades and D-blades in , there may be differing numbers of N-blades and\/or D-blades in accordance with various embodiments of the technique described here. For example, there need not be a one-to-one correspondence between the N-blades and D-blades. As such, the description of a node  comprising one N-blade and one D-blade should be understood to be illustrative only.","The clients  can be, for example, general-purpose computers configured to interact with the node  in accordance with a client\/server model of information delivery. That is, each client  may request the services of the node  (e.g., to read or write data), and the node  may return the results of the services requested by the client , by exchanging packets over the connection system . The client  may issue packets including file-based access protocols, such as the Common Internet File System (CIFS) protocol or Network File System (NFS) protocol, over the Transmission Control Protocol\/Internet Protocol (TCP\/IP) when accessing information in the form of files and directories. Alternatively, the client may issue packets including block-based access protocols, such as the Small Computer Systems Interface (SCSI) protocol encapsulated over TCP (iSCSI) and SCSI encapsulated over Fibre Channel (FCP), when accessing information in the form of blocks.",{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 2","b":["100","100","210","210","220","240","270","280","250","290","250","100","260","270","100","100","270","160","170"],"i":["a","b"]},"Each node  can be embodied as a dual processor storage system executing a storage operating system  that preferably implements a high-level module, such as a storage manager, to logically organize the information as a hierarchical structure of named directories, files and special types of files called virtual disks (hereinafter generally \u201cblocks\u201d) on the disks. Note, however, that the node  can alternatively comprise a single processor or more than two processor system. Illustratively, one processor can execute the functions of the N-blade  on the node  while the other processor executes the functions of the D-blade .","The memory  illustratively comprises storage locations that are addressable by the processors and adapters for storing software program code and data structures associated with the present invention. The processor and adapters may, in turn, comprise processing elements and\/or logic circuitry configured to execute the software code and manipulate the data structures. The storage operating system , portions of which is typically resident in memory and executed by the processing elements, functionally organizes the node  by, inter alia, invoking storage operations in support of the storage service provided by the node . It will be apparent to those skilled in the art that other processing and memory implementations, including various computer readable storage media, may be used for storing and executing program instructions pertaining to the technique introduced here.","The network adapter  includes a plurality of ports to couple the node  to one or more clients  over point-to-point links, wide area networks, virtual private networks implemented over a public network (Internet) or a shared local area network. The network adapter  thus can include the mechanical, electrical and signaling circuitry needed to connect the node  to the network of the connection system . Illustratively, the connection system  can be embodied as an Ethernet network or a Fibre Channel (FC) network. Each client  can communicate with the node  over the connection system  by exchanging discrete frames or packets of data according to pre-defined protocols, such as TCP\/IP.","The storage adapter  cooperates with the storage operating system  executing on the node  to access information requested by the clients . The information may be stored on any type of attached array of writable storage media, such as magnetic disk or tape, optical disk (e.g., CD-ROM or DVD), flash memory, solid-state disk (SSD), electronic random access memory (RAM), micro-electro mechanical and\/or any other similar media adapted to store information, including data and parity information. However, as illustratively described herein, the information is stored on disks  of the disk array . The storage adapter  includes a plurality of ports having input\/output (I\/O) interface circuitry that couples to the disks  over an I\/O interconnect arrangement, such as a conventional high-performance, Fibre Channel (FC) link topology.","Storage of information on each disk array  can be implemented as one or more storage volumes that include a collection of physical storage disks  cooperating to define an overall logical arrangement of volume block number (VBN) space on the volume(s). A \u201cvolume\u201d, as the term is used herein, is a logical container of data which is an abstraction of physical storage, combining one or more physical mass storage devices (e.g., disks) or parts thereof into a single logical storage object, and which is managed as a single administrative unit, such as a single file system. Each volume is generally, although not necessarily, associated with its own file system. A \u201cfile system\u201d, as the term is used herein, is a structured (e.g., hierarchical) set of stored logical containers of data, such as blocks, files, logical unit numbers (LUNs), directories and\/or other data containers. Note, however that a \u201cfile system\u201d, as the term is used herein, does not necessarily store data in terms of \u201cfiles\u201d per se. For example, a file system can implement block based storage, where a \u201cblock\u201d is defined herein as the smallest addressable unit of contiguous data used by a given file system to manipulate and transfer data, commonly (though not necessarily) 4 kbytes in size.","The disks within a volume\/file system are typically organized as one or more RAID groups. Most RAID implementations, such as RAID-4, enhance the reliability\/integrity of data storage through the redundant writing of data \u201cstripes\u201d across a given number of physical disks in the RAID group, and the appropriate storing of parity information with respect to the striped data. RAID-4 is an illustrative example of a RAID implementation, although other types and levels of RAID implementations can be used in accordance with the principles described herein. It should also be appreciated that RAID data \u201cstripes\u201d are different from the striping of across volumes, described further below.","The storage operating system  facilitates clients' access to data stored on the disks . In certain embodiments, the storage operating system  implements a write-anywhere file system that cooperates with one or more virtualization modules to \u201cvirtualize\u201d the storage space provided by disks . In certain embodiments, a storage manager  () logically organizes the information as a hierarchical structure of named directories and files on the disks . Each \u201con-disk\u201d file may be implemented as set of disk blocks configured to store information, such as data, whereas the directory may be implemented as a specially formatted file in which names and links to other files and directories are stored. The virtualization module(s) allow the storage manager  to further logically organize information as a hierarchical structure of blocks on the disks that are exported as named logical unit numbers (LUNs).","In the illustrative embodiment, the storage operating system  is a version of the Data ONTAP\u00ae operating system available from NetApp\u00ae, Inc. of Sunnyvale, Calif. and the storage manager  implements the Write Anywhere File Layout (WAFL\u00ae) file system from NetApp\u00ae, Inc. However, other storage operating systems are capable of being enhanced for use in accordance with the principles described herein.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 3","b":["230","230","310","310","160","312","120","310","310","340"],"i":"a "},"In addition, the storage operating system  includes a set of layers organized to form a storage server  that provides data paths for accessing information stored on the disks  of the node . The storage server  also forms the D-blade  in combination with underlying processing hardware. To that end, the storage server  includes a storage manager module  that organizes any number of volumes, such as volume-1, volume-2, . . . , volume-N, a RAID system module  and a storage driver system module . The storage manager  can implement a plurality of volumes as striped volume set (SVS). In addition, the storage manager  can compute the location of a data container content in a volume of the SVS to ensure consistency of such content served by the cluster. The RAID system  manages the storage and retrieval of information to and from the volumes\/disks in accordance a RAID redundancy protocol, such as RAID-4, RAID-5, or RAID-DP, while the disk driver system  implements a disk access protocol such as SCSI protocol or FCP.","The storage server  also includes a CF interface module to implement intra-cluster communication with N-blades and other D-blades. The CF interface modules and can cooperate to provide a single file system image across all D-blades  in the cluster. Thus, any network port of an N-blade  that receives a client request can access any data container within the single file system image located on any D-blade  of the cluster.","The CF interface module  implements the CF protocol to communicate file system commands among the blades of cluster. Such communication can be effected by a D-blade exposing the CF API to which an N-blade (or another D-blade) issues calls. To that end, the CF interface module  can be organized as a CF encoder\/decoder. The CF encoder of, e.g., CF interface on N-blade  can encapsulate a CF message as (i) a local procedure call (LPC) when communicating a file system command to a D-blade  residing on the same node  or (ii) a remote procedure call (RPC) when communicating the command to a D-blade residing on a remote node of the cluster. In either case, the CF decoder of CF interface on D-blade  de-encapsulates the CF message and processes the file system command.","In operation of a node , a request from a client  is forwarded as a packet over the connection system  and onto the node , where it is received at the network adapter  (). A network driver of layer  processes the packet and, if appropriate, passes it on to a network protocol and file access layer for additional processing prior to forwarding to the storage manager . At that point, the storage manager  generates operations to load (retrieve) the requested data from the disk  if it is not resident in memory . If the information is not in memory , the storage manager  indexes into a metadata file to access an appropriate entry and retrieve a logical VBN. The storage manager  then passes a message structure including the logical VBN to the RAID system ; the logical VBN is mapped to a disk identifier and disk block number (DBN) and sent to an appropriate driver (e.g., SCSI) of the disk driver system . The disk driver accesses the DBN from the specified disk  and loads the requested data block(s) in memory for processing by the node. Upon completion of the request, the node (and operating system) returns a reply to the client  over the connection system .","The data request\/response \u201cpath\u201d through the storage operating system  as described above can be implemented in general-purpose hardware executing the storage operating system  as software or firmware. Alternatively, it can be implemented at least partially in specially designed hardware. That is, in an alternate embodiment of the invention, some or all of the storage operating system  is implemented as logic circuitry embodied within a field programmable gate array (FPGA) or an application specific integrated circuit (ASIC), for example.","The N-blade  and D-blade  can be implemented as processing hardware configured by separately-scheduled processes of storage operating system ; however, in an alternate embodiment, the blades may be implemented as processing hardware configured by code within a single operating system process. Communication between an N-blade and D-blade is thus illustratively effected through the use of message passing between the blades although, in the case of remote communication between an N-blade and D-blade of different nodes, such message passing occurs over the cluster switching fabric . A known message-passing mechanism provided by the storage operating system to transfer information between blades (processes) is the Inter Process Communication (IPC) mechanism. The protocol used with the IPC mechanism is illustratively a generic file and\/or block-based \u201cagnostic\u201d CF protocol that comprises a collection of methods\/functions constituting a CF application programming interface (API).","Data Striping\/Striping Tables",{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 4A","FIG. 4A"],"b":["100","100"]},"The multiple nodes  communicate with one another via the cluster switching fabric . Specifically, the N\/D-blades of the nodes  communicate as described above. Each D-blade  includes a volume, such that each volume can store striped data. For example, as illustrated by , data volume-0 (DV-0) can store a stripe of data at a first location, data volume-1 (DV-1) can store a stripe of data at a second location, data volume-2 (DV-2) can store a stripe of data at a third location, and data volume (DV-3) can store a stripe of data at a fourth location.",{"@attributes":{"id":"p-0055","num":"0054"},"figref":["FIG. 4B","FIG. 4A","FIG. 4A"],"b":["1300","1300","0","1","2","3","1300","1300","1300","0","1","2","3"]},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 11","b":["1101","100","1102","100"],"i":"a "},"There are various performance related criteria on which one can judge the strength of a particular striping pattern in a striping table, such that some layouts of striped data may be preferable to others. One problem often encountered when generating a striping table, however, is that some of these criteria are mutually antagonistic, such that designing a striping pattern that is strong in one criterion might impair its performance in another criterion. The technique introduced here can optimize a striping table for multiple such criteria, using a plurality of corresponding metrics. The plurality of the metrics can measure, for example, the evenness of storage consumption across the storage system or a designated subset thereof, the number of \u201chot spots\u201d in the storage system, the degree of scatter in the storage system, and the number of changes needed to reflect a change in the geometry of the storage system.","Evenness of storage consumption relates to the goal that, in the striping table, each volume should have roughly the same number of references as all other volumes. If any volume is referenced significantly more frequently than others, then that volume is likely to become full more quickly than the other volumes.","\u201cHot spots\u201d relate to the fact that sequential input\/output (I\/O) is a very common access pattern. In sequential I\/O, a client works with one stripe, followed by the next stripe in series and so on. To achieve the best performance, such sequential I\/O should utilize all the resources in the storage system rather than overworking a small subset of volumes for a period of time while the rest of the volumes stand idle. A good striping table, therefore, avoids referencing the same subset of volumes repeatedly within a portion of the striping table, preferring instead to reference all volumes consistently throughout the table.","Lack of Repetition, or \u201cscatter\u201d, relates to the fact that sequential access while using a repetitive striping pattern can result in harmonics that adversely affect file system performance. Consider, for example, hundreds of clients working with a large striped file, each reading sequentially but those reads currently happening at essentially random starting spots throughout the file. If, for example, volume-2 becomes slow to respond for any reason\u2014even a second of transient delay, such as might reasonably happen in any storage system\u2014then that volume will accumulate a backlog of work to perform. As it works through that backlog, all of those clients who are now satisfied with their work against volume-2 now request data from volume-3. A flurry of requests therefore arrives at volume-3, which in turn slows down as it services all those requests. The effect is that most volumes in the storage system sit effectively idle while each volume takes turns being a bottleneck. This problem can be eliminated by ensuring that the striping table includes as little repetition as possible\u2014or, more precisely, that the striping table includes a high degree of \u201cscatter\u201d.","In addition, a striping table should be well suited to adapting to changes in geometry of the file system. For example, a four-volume striped file system might at some point in time become a five- or six-volume striped file system as the users' storage needs increase. When adding more volumes to a striped file system, the existing striped data will need to be redistributed to take advantage of the new storage, effectively migrating the striped files to use a new striping table that also references the new volume(s). That migration should ideally involve migrating only a small portion of the existing data onto the new storage; however, if striping tables do not take this concept into account, then migration might involve migrating almost all existing data to match the required new layout.","Note that one benefit of the technique introduced here is its flexibility: By simply inserting additional tests (metrics) for judging the strength of the striping table on new criteria, the algorithm can generate striping patterns that optimize the strength of those new criteria while only minimally impacting the strength of other existing criteria. Thus only minor, easily made revisions to the scoring process are sufficient to yield results that are custom-tailored for the task at hand.","Scatter in Striping Tables",{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 5A","b":["7","8","8","9","15","16"]},"Tallying these transitions on the two-dimensional chart in  shows the number of transitions encountered from one volume to another. This chart shows that after volume-1 stores a stripe of data, volume-2 always stores the next stripe\u2014never volume-0 or volume-3. A striping table with this lack of scatter implies a high degree of vulnerability to harmonics developing during sequential I\/O: essentially, if volume-1 slows down, then when it finishes volume-2 is going to be inundated with requests. Far preferable would be to ensure that after volume-1 stored a stripe of data, different transitions in the table would show volumes-0, -2 or -3 storing the next stripe (preferably not volume-1 again, as that would introduce a hot spot). For example, the striping table of  has a much better scatter pattern, where the transitions represented in the table of . This striping pattern has very little repetition; if volume 1 slowed down in servicing requests, then when it finished requests would next be spread well across volumes 0, 2 and 3.","Preparing for Expansion","Recall that a particular striping table is only suitable for use with a certain number of volumes; if the number of volumes changes, then data must be migrated to conform to a different striping table tied to the new geometry of the striped file system.","The striping tables for four- and five-volume round robin striping are shown as the top two tables in . Comparing the differences (A) between the two tables, represented in the bottom table in , shows the relative proportion of data that must be migrated from one volume to another if the striped file system were to change from using four volumes to using five (or vice versa), where \u201cX\u201d represents a change and \u201c-\u201d represents no change.","With the round robin algorithm, 16 of the 20 cells have changed values, representing a need to migrate 80% of a customer's data when changing the file system's storage. As the number of constituent volumes increases, this proportion increases as well, rising asymptotically towards the need to migrate almost all of the user's data for almost any change in storage.","A well-chosen striping algorithm can minimize this cost, by ensuring that successive striping tables have as few differences as possible while still supporting the appropriate number of constituent volumes. For example,  shows two striping tables for four and five constituent volumes. These tables differ in only four of 20 cells, as shown in the bottom table in , meaning that only 20% of a user's data would need to migrate for the new geometry.","In practice the technique described herein, which can generate the striping tables of , provides striping tables that have fewer and fewer differences as the number of volumes increase, asymptotically approaching the need to migrate only a fraction of a percent of data as the volume expands to large sizes.","Some of these goals mentioned above are mutually antagonistic: a good scatter pattern will introduce some degree of hot-spotting, and trying to avoid those hot spots might involve extra transitions with a concomitant increase in the amount of data migrated during restriping.","Addition and Removal of Volumes",{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 9","b":["1300","1410","1300","1420","1300"]},"As previously described, the striping table is an allocation data structure. Although illustrated as a linear structure, the allocation structure can be implemented with any type of structure, such as a three-dimensional structure, or an n-dimensional structure, as long as the n-dimensional structure accurately identifies striped data allocated among volumes of a particular geometry (or more generally, accurately identifies responsibilities allocated among multiple resources of a particular system).","Accordingly, the striping table  of  illustrates that the sequence of striped data of a file striped across three volumes is located on DV-0, DV-1, DV-2, DV-0, DV-1, DV-2, DV-0, DV-1, DV-2, DV-0, DV-1, and DV-2. Specifically, restriping processes are now described when adding and subsequently removing one volume, such as DV-3 (not shown). Specifically, when adding a volume to a cluster, the restriping process is an evolving algorithm, meaning that to generate a striping table for N+1 volumes, the algorithm operates on an existing striping table for N volumes. Alternatively, when removing a volume from a cluster, the restriping process is a devolving algorithm, meaning that to generate a striping table for N\u22121 volumes, the algorithm operates on an existing striping table for N volumes. Thus, by implementing at least one restriping process when changing the geometry, data can be well distributed while preventing hot spotting.","In the evolving algorithm illustrated by , the length of the striping table  is increased, where locations equate to the total number of volumes added. Further, the contents of the striping table  are grouped by the total number of volumes. For each group, counters are implemented, such that the counters identify the number of times a volume identifier appears in the group. Thus, in group , count equals two because the identifier for DV-0 appears twice. The identifier for DV-1 appears once, resulting in count equal to one, and the identifier for DV-2 appears once, resulting in count equal to one. However, in group , the identifier for DV-0 appears once, the identifier for DV-1 appears twice and the identifier for DV-2 appears once. Subsequently, within each group, the counter with the highest value is replaced, in the algorithm of , with an identifier corresponding to the newly added fourth volume, DV-3. Thus, as illustrated by striping table , the duplicate reference within each group is replaced by the new identifier, \u201c3\u201d. The evolving algorithm is implemented each time a volume is added to the cluster, which correspondingly modifies the striping table .","When removing a volume from the cluster, a restriping process is also implemented for each volume removed from the cluster. Such restriping process can be a devolving algorithm. The striping table is once more grouped, where each group is the total number of volumes resulting from the volume removal. Here, the total is three, because the striping table  identifies the location of striped data among four volumes. In each group that includes an identifier to the now removed fourth volume, the identifier should be replaced. The replacement identifier can be selected from the volume that is least represented within the group. For example, by keeping a count of the number of references to a volume within a group, the counter having the least number of references can be replaced. Specifically, group  includes an identifier for DV-0 and DV-2 but no identifier for DV-1. Thus, the identifier \u201c1\u201d is inserted as a content of the striping table . Correspondingly, group  includes an identifier for DV-0 and DV-1 but no identifier for DV-2. Thus, the identifier \u201c2\u201d is inserted in the striping table .","In other embodiments of the evolving and devolving algorithms illustrated in , the striping table  need not increase or decrease in size. Particularly, the striping table  can remain a constant size.","Iterative Generation of a Striping Table","The process of generating a striping table for a given storage system can be iterative: For example, one first builds a simple striping table for a single constituent volume (e.g., an array filled with zeroes) and remembers it as the canonical single-volume table. That table is then duplicated and an evolution algorithm is applied to it, changing some cells to include references to a second volume. The result is a striping table suitable for a file system striped across two volumes instead of just one. The process then repeats, permuting that two-volume striping table into one suitable for three volumes and so on. A typical storage system might support up to 255 constituent volumes, for example, and so would build 255 such striping tables using this process. An example of an iterative process of building a striping table is shown in , where the process proceeds from top to bottom, building from one constituent volume to five constituent volumes.","In certain embodiments, the number of cells modified is strictly limited in each iterative pass: No more than 1 out of every N cells may be changed, where N is the number of volumes supported by the to-be-built table. This restriction provides two benefits. First, by inserting references to the new volume at most this number of times, the algorithm ensures that the new volume is referenced no more times than is appropriate: When building a four-volume table, the fourth volume will be referenced in exactly one quarter of the cells of the striping table. Second, by limiting the changes from the previous table by a continuously decreasing amount, the migration cost between any two tables is guaranteed to decrease as the number of volumes increases.","The difficult part of the process is not so much to limit the number of cell replacements in this fashion, but rather to choose the best cells to replace.","Selection of Cells to Replace","In one embodiment, the iterative process begins by dividing the to-be-permuted striping table into regions, where the size of each region corresponds to the number of volumes that should be represented in the resulting table. Within each region the algorithm eventually makes exactly one change, replacing an existing volume reference with a reference to the as-yet-unrepresented new constituent volume. Before doing so, however, the algorithm tests a number of potential cell replacements.","This process effectively replaces each cell within the region in turn, then studies the resulting table to determine its relative strength in each of several metrics (as described above). A poorly chosen replacement might lower the overall table's strength on several metrics, while a stronger replacement might lower only a few metrics slightly while significantly boosting others. As the process iteratively attempts each replacement, it remembers which replacement generated the best overall score for the striping table. When the process has finished scoring replacements of each cell in the region, it chooses the best-scoring replacement and makes that change permanent, discarding the others. This process then repeats for the remaining regions in the striping table, each time scoring all possible replacements before ultimately selecting the best.","The algorithm used to evaluate a striping table depends on the criteria considered to be important. In one embodiment, the four criteria discussed above are used, and each criterion is granted a relative priority. The table is mathematically scored on each criterion, with higher scores representing a better distribution. The score for each criterion is multiplied by its relative priority value (for example, more-important criteria might have a multiplier of 1.1\u00d7 or 2\u00d7, while less-important criteria might have a multiplier of 0.9\u00d7 or 0.8\u00d7), and then the resulting scores for all criteria are summed. The result is the overall score for the striping table, used to decide which replacement is best within a region.","Some examples for mathematically judging criteria will now be discussed. First, evaluating evenness of consumption can be judged by counting the number of references to each volume throughout the table. These counts can be individually compared with a logical ideal number of references (calculated as X cells in the table, divided by N constituent volumes). The scoring system then tallies the absolute value of the difference between this ideal average and the actual number of references to each volume in turn, and returns a value of zero minus this result (such that a high value\u2014zero being the maximum possible\u2014is good, while a large negative value represents a significant amount of under- and over-utilized storage).","Hotspots can be judged by iteratively looking at each cell and comparing it with its neighbors out to some maximum distance (for example, 8 cells away). It is not necessary to only look at cells within the current region being examined. The number of times a particular cell's value is repeated in this close proximity is subtracted from the table's overall score, perhaps multiplying the penalty for a repetition by some factor that decreases its importance as the distance from the original cell increases.","Scatter can be judged as described above, e.g., by counting the transitions from each volume to each other volume, and comparing those counts against an ideal value. Any deviation from the ideal is subtracted from the table's score, such that tables with poor scatter characteristics will score badly overall and will be selected against.","Suitability for changes in geometry actually does not need be scored, as it is implicitly enforced to be most effective by the iterative striping table evolution process described above.","Note that, in practice, it is typically unnecessary to perform a full evaluation of the entire striping table after each theoretical replacement. Doing so is benign but relatively CPU-intensive. In practice, one can recall the score of the unmodified striping table, then consider only the impact of replacing a particular cell as a relative change from that original score. Such an evaluation is much faster to perform.","Having completed a single processing pass across the striping table and made an appropriate number of replacements, a second stage of refinement can then be performed, as described below.",{"@attributes":{"id":"p-0089","num":"0088"},"figref":"FIG. 12"},"Initially, at  the process initializes the striping table to have a predetermined number of cells, containing identifiers of an initial constituent volume, e.g. identifier \u201c0\u201d representing volume-0. A variable M, the purpose of which is explained below, is then initialized to have a value of one at , and then incremented by one at . The following operations are then performed while M is less than or equal to N (), where N is the number of volumes in the storage system that the striping table is intended ultimately to represent.","First, at  the process divides the table into a number of equal sized regions so that each region contains M cells, where M equals the number of volumes that are to be represented in the striping table in the current iteration. For example, initially, at  each region will have two cells (M=2), in the next iteration each region will have three cells (M=3), and so forth. In one embodiment, if the table currently is not evenly divisible into equal-sized regions of M cells each, then before the dividing is done at , the last group is omitted if it has fewer than N\/2 cells, or is treated as a full group and granted a replacement if it has at least N\/2 cells.","At  the process performs a first stage (\u201cfirst pass\u201d) of the striping table iteratively to optimize the striping table for multiple quality metrics (such as those discussed above), to generate a striping table for the desired number of volumes in the storage system. At , optionally, the system performs a second stage (\u201csecond pass\u201d) to refine the striping table according to one or more of the quality metrics.","The first stage of the iterative process, according to one embodiment, will now be described in greater detail with reference to . Initially, at  the process selects the next (initially, the first) region in the table as the current region to be examined. At  the process then selects the next (initially, the first) cell in the current region as the current cell to be processed. The process then replaces the current cell with the identifier of the new volume (the volume as-yet-to-be-represented in the table) at . Next, at  the process scores the table for each of multiple quality metrics, such as those discussed above, with the current cell replacement. After doing so, at  the process computes and saves the overall score for the table, for the current cell replacement, which may be done as described above, i.e., based on the combined scores of the various different quality metrics (e.g., using a weighting\/prioritization).","After all cells in the current region have been processed in this way (, ), at  the process then takes the cell replacement produced the highest overall score and adopts it as the \u201cfinal\u201d replacement (subject to modification in a subsequent refinement stage). Then, after all regions in the table have been processed in this manner (, ), the first stage  ends.","Having completed the first stage in which an appropriate number of replacements were made as described above, the second stage of refinement can then optionally be performed. This second stage is intended to further strengthen certain metrics. For example, in certain embodiments, even allocation across all constituent volumes is particularly important. During the first stage, that metric might be allowed to temporarily increase or decrease in score in order not to restrict unnecessarily the manipulation of other metrics (one replacement might temporarily reduce this score, while a second replacement would restore it, but ultimately this metric is desired to be as strong as possible.","Therefore, this second stage begins by counting the number of references to each constituent volume; if the most-referenced volume has significantly more references than the least-referenced volume (in practice, \u201csignificantly more\u201d might be as few as one or two additional references), then one earlier-chosen first-stage replacement is carefully selected and undone, and a different cell is instead carefully selected and replaced. The replacement that is reverted is chosen from among those that destroyed a reference to the now-under-represented volume, and the new replacement is chosen from among those cells that currently refer to a now-over-represented volume. In each case, the actual choice of replacements to revert and to apply can be made by scoring each candidate replacement against its other candidates, to select the one that best optimizes the table for all of the criteria. This second-stage process then repeats until there is no longer any significant deviation in usage among volumes.","At the end of the second stage, the resulting striping table is considered complete and the iterative evolution process uses it as a foundation for developing the next striping table in series.","The techniques introduced above can be implemented by programmable circuitry configured by software and\/or firmware, or entirely in special-purpose hardwired circuitry, or in a combination of such forms. Special-purpose hardwired circuitry may be in the form of, for example, one or more application-specific integrated circuits (ASICs), programmable logic devices (PLDs), field-programmable gate arrays (FPGAs), etc.","Software or firmware usable to implement the techniques introduced here may be stored on a machine-readable medium and may be executed by one or more general-purpose or special-purpose programmable microprocessors. A \u201cmachine-readable medium\u201d, as the term is used herein, includes any mechanism that can store information in a form accessible by a machine (a machine may be, for example, a computer, network device, cellular phone, personal digital assistant (PDA), manufacturing tool, any device with one or more processors, etc.). For example, a machine-accessible medium includes recordable\/non-recordable media (e.g., read-only memory (ROM); random access memory (RAM); magnetic disk storage media; optical storage media; flash memory devices; etc.), etc.","Although the present invention has been described with reference to specific exemplary embodiments, it will be recognized that the invention is not limited to the embodiments described, but can be practiced with modification and alteration within the spirit and scope of the appended claims. Accordingly, the specification and drawings are to be regarded in an illustrative sense rather than a restrictive sense."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["One or more embodiments of the present invention are illustrated by way of example and not limitation in the figures of the accompanying drawings, in which like references indicate similar elements and in which:",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 4B","FIG. 4A"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 5B","FIG. 5A"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 6B","FIG. 6A"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 13","FIG. 12"]}]},"DETDESC":[{},{}]}
