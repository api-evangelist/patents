---
title: Adaptive tap for full virtual machine protection
abstract: A method, system, and computer-readable storage medium for providing an adaptive tap for a virtual machine protection are disclosed. In one embodiment, an Input/Output (I/O) write is received from one of virtual machines. The virtual machines are executed on a server, and each virtual machine is configured to generate I/O writes to a VMFS file system on a primary storage. The I/O write includes data and an offset at which the data is to be stored in the VMFS file system. The server, and primary and secondary storage are coupled to a network. A virtual machine indicator is determined using the offset. A secondary write to a secondary storage is generated based on the I/O write. The secondary write includes the data and the VM indicator associated with the I/O write. The secondary storage is then accessed to write/store the secondary write.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08583852&OS=08583852&RS=08583852
owner: Symantec Operation
number: 08583852
owner_city: Mountain View
owner_country: US
publication_date: 20110901
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","DESCRIPTION OF THE RELATED ART","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This invention relates to data processing systems, and in particular, managing virtual data processing systems. Still more particularly, this invention relates to managing continuous data protection and\/or backup of virtual data processing systems.","A distributed computing system can include multiple computing nodes (nodes) that communicate with and access, using a network, data stored on a shared storage device. Each such node can implement multiple virtual machines that allow increased usage of hardware resources, i.e., by effectively turning hardware resources of each node into several virtual machines. Each virtual machine can execute a separate operating system, and can be interacted with, and used in substantially the same manner as, standalone operating system executing on independent hardware.","The nodes in this distributed computing system should be protected against data loss due to failures or errors. One way to safeguard against such data loss is by implementing a continuous data protection (CDP) and\/or a back-up system. A typical way of doing so it to use a backup application (e.g., an agent) on the nodes and\/or virtual machines. This backup application can perform CDP and\/or periodically backup the data stored on the shared storage device accessed by those nodes. In a CDP system, the agent can facilitate continuous saving (e.g., to secondary storage) of data that is written to the shared storage device. In the event of a failure that results in data loss or corruption, the data on the shared storage device can be recovered via a backup or data archive created by the backup application.","One drawback to using a backup application is that performing a backup of the entire shared storage device can be time and resource intensive (both in computing and network resources). A similar drawback to using a CDP system is that saving all of the data that is being written by a node can also be both time and resource intensive. Furthermore, the use of agents on the node(s) and\/or virtual machines is invasive and adds complexity. Thus, what is desirable is an approach that enables an easier and more efficient technique to provide protection of data used by virtual machines in a distributed computing system.","Various systems and methods for providing an adaptive tap for a virtual machine protection are disclosed. For example, one method involves receiving an Input\/Output (I\/O) write from a first virtual machine of a plurality of virtual machines. The virtual machines are executed on a server, and each of the virtual machines is configured to generate one or more I\/O writes to a VMFS file system on a primary storage. The I\/O write comprises data and an offset at which the data is to be stored in the VMFS file system on the primary storage. The server and the primary storage are coupled to a network. The method also involves determining a virtual machine (VM) indicator using the offset. The method also involves generating a secondary write to a secondary storage based on the I\/O write. The secondary storage is coupled to the network, and the secondary write includes the data and the VM indicator associated with the I\/O write. The method also involves accessing the secondary storage to write the secondary write. The secondary storage is operable to store the data using the VM indicator.","In some embodiments, prior to the generating, the method includes determining whether the VM indicator indicates that the first virtual machine is to be provided with continuous data protection\/back-up, where the generating and the accessing are performed if the first virtual machine is to be provided with the continuous data protection\/back-up. In some embodiments, the VM indicator comprises one or more of a first virtual machine disk (VMDK) associated with the first virtual machine, or an indication of the first virtual machine. In some embodiments, the first virtual machine is configured to save a plurality of data using two or more VMDKs used by the VFMS file system on the primary storage, and the two or more VMDKs comprise the first VMDK. In some embodiments, the I\/O write, as received from the first virtual machine, does not comprise the VM indicator. In some embodiments, the determining the VM indicator comprises querying a software entity on the at least one server using the offset to obtain the VM indicator. In some embodiments, the determining the VM indicator comprises accessing a map file on a tap device to obtain the VM indicator for the offset, where the map file comprises a plurality of mappings between offsets and corresponding VM indicators. In some embodiments, the method includes restoring the data for the first virtual machine from a plurality of data stored on the secondary storage. In some embodiments, the method includes monitoring the one or more I\/O writes from the plurality of virtual machines, and selectively generating secondary writes for the one or more I\/O writes to the secondary storage based on the monitoring. In some embodiments, the monitoring comprises analyzing one or more of the characteristics of the one or more I\/O writes from each of the plurality of virtual machines, and the one or more characteristics comprise frequency or size of the one or more I\/O writes from each of the plurality of virtual machines.","A system is disclosed that comprises a processing module, a mapping module, and a write generator. The processing module is configured to receive an Input\/Output (I\/O) write from a first virtual machine of a plurality of virtual machines. The virtual machines are executed on at least one server. Each of the virtual machines is configured to generate one or more I\/O writes to a VMFS file system on a primary storage. The I\/O write comprises data and an offset at which the data is to be stored in the VMFS file system on the primary storage. The at least one server and the primary storage are coupled to a network. The mapping module is coupled to the processing module and configured to determine a virtual machine (VM) indicator using the offset. The write generator is coupled to the processing module and is configured to generate a secondary write to a secondary storage based on the I\/O write. The secondary storage is coupled to the network. The secondary write comprises the data and the VM indicator associated with the I\/O write. The write generator is also configured to access the secondary storage to write the secondary write. The secondary storage is operable to store the data using the VM indicator.","In some embodiments, the VM indicator comprises one or more of a first virtual machine disk (VMDK) associated with the first virtual machine, or an indication of the first virtual machine. In some embodiments, the first virtual machine is configured to save a plurality of data using two or more VMDKs used by the VFMS file system on the primary storage, and the two or more VMDKs comprise the first VMDK. In some embodiments, the mapping module is configured to determine the VM indicator by performing at least one of querying a software entity on the at least one server using the offset to obtain the VM indicator, or accessing a map file on the tap device to obtain the VM indicator for the offset. The map file may comprise a plurality of mappings between offsets and corresponding VM indicators. In some embodiments, the processing module is further configured to monitor the one or more I\/O writes from the plurality of virtual machines, and selectively generate secondary writes for the one or more I\/O writes to the secondary storage based on the monitoring.","A computer readable medium is disclosed that contains program instructions that are executable by one or more processors. The program instructions are executable to receive an Input\/Output (I\/O) write from a first virtual machine of a plurality of virtual machines. The virtual machines are executed on at least one server. Each of the virtual machines is configured to generate one or more I\/O writes to a VMFS file system on a primary storage. The I\/O write comprises data and an offset at which the data is to be stored in the VMFS file system on the primary storage. The at least one server and the primary storage are coupled to a network. The program instructions are further executable to determine a virtual machine (VM) indicator using the offset. The program instructions are further executable to generate a secondary write to a secondary storage based on the I\/O write. The secondary storage is coupled to the network. The secondary write comprises the data and the VM indicator associated with the I\/O write. The program instructions are further executable to access the secondary storage to write the secondary write. The secondary storage is operable to store the data using the VM indicator.","In some embodiments, the VM indicator comprises one or more of a first virtual machine disk (VMDK) associated with the first virtual machine, or an indication of the first virtual machine. In some embodiments, the first virtual machine is configured to save a plurality of data using two or more VMDKs used by the VFMS file system on the primary storage, and the two or more VMDKs comprise the first VMDK. In some embodiments, the program instructions are executable to determine the VM indicator by performing at least one of querying a software entity on the at least one server using the offset to obtain the VM indicator, or accessing a map file on the tap device to obtain the VM indicator for the offset, where the map file comprises a plurality of mappings between offsets and corresponding VM indicators. In some embodiments, the program instructions are further executable to monitor the one or more I\/O writes from the plurality of virtual machines, and selectively generate secondary writes for the one or more I\/O writes to the secondary storage based on the monitoring.","The foregoing is a summary and thus contains, by necessity, simplifications, generalizations and omissions of detail; consequently those skilled in the art will appreciate that the summary is illustrative only and is not intended to be in any way limiting. Other aspects, inventive features, and advantages of the present invention, as defined solely by the claims, will become apparent in the non-limiting detailed description set forth below.","While the invention is susceptible to various modifications and alternative forms, specific embodiments of the invention are provided as examples in the drawings and detailed description. It should be understood that the drawings and detailed description are not intended to limit the invention to the particular form disclosed. Instead, the intention is to cover all modifications, equivalents and alternatives falling within the spirit and scope of the invention as defined by the appended claims.","Embodiments of the present invention are directed to using an adaptive tap (also referred to as a tap device) to provide selective data protection for one or more virtual machines. The virtual machines may be implemented by one or more nodes in a distributed computing system. Each virtual machine (also referred to as \u201cVM\u201d) may, for example, provide a self-contained instance of an executing operating system. Each virtual machine may access, e.g., over a network, primary storage to perform I\/O reads and writes. The primary storage may use a Virtual Machine File System (VMFS) file system for storing data received from the virtual machines. The tap device can couple to the network and be able to receive the I\/O writes from the nodes that implement the virtual machines. The tap device can determine which VM has generated each respective I\/O write, and only generate secondary writes for certain VMs. The tap device can access secondary storage to store data using these secondary writes. As a result, the secondary storage may only store data that was contained in I\/O writes from these certain virtual machines.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1","b":["100","100","102","1","102","2","104","106","108","102","1","102","2","104","106","108","102","1","102","2","100","102","1","102","2","110","1","110","6","102","1","102","2","102","1","102","2","108","102","1","102","2","104","106","108"]},"Each of primary storage  and secondary storage  may be a shared storage device, such as a cluster shared volume. For example, primary storage  may be implemented as a collection of hard disk drives aggregated to form at least one volume accessible for read and write operations by nodes () and () in distributed computing system . According to some embodiments, primary storage  can be formatted using a Virtual Machine File System (VMFS), such as offered by VMWARE, INC. of Palo Alto, Calif., or a similar file system that can be used by multiple virtual machines. Virtual machines ()-() can perform I\/O reads and writes to primary storage , such as to read and write data.","In some embodiments, primary storage , by implementing VMFS, can allow multiple nodes () and () to store data. In other embodiments, primary storage  may implement Network File System (NFS) and operate in a similar manner as described herein. In one embodiment, primary storage  can be implemented using remote device mapping (RDM). When implemented using VMFS, primary storage  may include one or more VMFS volumes. In one embodiment, each VMFS volume may be stored on a separate cluster of primary storage . In other embodiments, each VMFS volume may be distributed among various clusters of primary storage , or multiple VMFS volumes may be implemented on a single cluster of primary storage , as desired. Each VMFS volume may correspond to a separate logical unit number (LUN). Each VMFS volume can be divided into multiple Virtual Machine DisKs (VMDKs). In one embodiment, the VMFS volume on primary storage  can have multiple VMDKs (not illustrated).","For example, with reference to , primary storage  may implement one VMFS volume. Each VM ()-() may be associated with at least one distinct VMDK on primary storage. For example, VM () may be associated with a first VMDK, and VM () may be associated with a second VMDK. However, in some implementations, each VM ()-() may be associated with multiple distinct VMDKs. For example, VM () may be associated with two VMDKs on a single VMFS volume on primary storage .","Nodes () and () can also couple via network  to secondary storage . Secondary storage  can be used for providing data protection and\/or back-up for virtual machines ()-() using any one of various data protection\/back-up techniques. Typically, each node () and () may be implemented using a server, including one or more processors, memory, bus, etc. One example implementation of such a server is described below with reference to . Network  may be implemented as any one or more wired and\/or wireless networks, including any combination of a local area network (LAN), and\/or a storage area network (SAN), etc.","Each virtual machine ()-() may be a software implementation of a physical computer that executes computer instructions in the manner of physical computer hardware. Virtual machines ()-() may read and write data, i.e., using I\/O writes , to primary storage . As mentioned above, virtual machines ()-() and\/or nodes () and () may also implement (e.g., by using agents) a data protection\/back-up plan, such that would generate additional I\/O writes  to secondary storage . However, implementations of such data protection\/back-up plans by virtual machines ()-() and\/or nodes () and () may be costly in terms of complexity, usage of processing power, and even maintenance costs.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 2","b":["200","200","202","1","202","2","204","206","208","210","202","1","202","2","204","206","208","202","1","202","2","200","202","1","202","2","212","1","212","6","202","1","202","2","208"]},"Nodes () and () can also couple via network  to secondary storage . Secondary storage  can be used for providing data protection\/back-up for virtual machines ()-(). Typically, each node () and () may be implemented using a server, including one or more processors, memory, bus, etc. One example implementation of such a server is described below with reference to .","Each of primary storage  and secondary storage  may be a shared storage device, such as a cluster shared volume, similar to primary storage  and secondary storage  of , respectively. According to some embodiments, primary storage  can be formatted using VMFS, or a similar file system (e.g., NFS) that can be accessed by multiple virtual machines. Primary storage  may implement one or more VMFS volumes, each having multiple VMDKs, such as described above with reference to .","In some embodiments, each I\/O write from virtual machine ()-() may include data and an offset at which that data is to be stored in a VMFS file system on primary storage . Primary storage  may, upon receiving each of these I\/O writes, store data for each respective I\/O write using the corresponding offset in the VMFS file system. However, it may not be readily known, just by accessing the VMFS file system on primary storage , which of the virtual machines ()-() has generated each I\/O write. For example, primary storage  may receive an I\/O write B that includes data and an offset. However, primary storage  may use an internal algorithm to determine which VMDK on the VMFS volume corresponds to the offset for I\/O write B. Primary storage  may, for example, determine that the offset of I\/O write B corresponds to a third VMDK on a first VMFS volume. In one embodiment, primary storage  may not be aware (e.g., just from the offset and\/or the determined VMDK) which virtual machine ()-() generated this I\/O write B.","Network  may be implemented as any one or more wired and\/or wireless networks, including any combination of a local area network (LAN), and\/or a storage area network (SAN), etc. Network  may be substantially similar to network . As shown in , each of two nodes () and (), primary and secondary storage  and , respectively, and tap device , can communicate with each other using network .","Tap device  can monitor\/access substantially all I\/O reads and writes from nodes () and (), such as from virtual machines ()-(), to primary storage . In some embodiments, tap device  is also configured to generate secondary writes to secondary storage . Tap device  may propagate\/pass-through the I\/O reads and writes to access primary storage . Typically, during normal (e.g., non-recovery) operation, selected I\/O writes from virtual machines ()-() are propagated to secondary storage . Tap device  may select a subset of these I\/O writes (e.g., I\/O writes for accessing primary storage ) to be stored at secondary storage , as described below.","Tap device  includes a tap application . Tap application  may access the I\/O writes from nodes ()-() (e.g., from virtual machines ()-()). In some embodiments, tap application  may access substantially all I\/O reads and writes from nodes ()-(). Typically, during normal (e.g., non-recovery) operation, tap application  only propagates I\/O writes to secondary storage . Tap application  may propagate (e.g., pass-through) substantially all of these I\/O reads and writes to access primary storage . Tap application  may selectively generate secondary I\/O writes from a subset of these I\/O writes for accessing secondary storage .","For example, the I\/O writes may include an I\/O write A from a first virtual machine (). I\/O write A may include data and an offset (e.g., an offset as used by the VMFS file system). Tap application  may allow I\/O write A to pass through, such as by propagating I\/O write A to primary storage . As a result, primary storage  may receive I\/O write B that is the same, or substantially the same to I\/O write A. In some implementations, tap device  may propagate I\/O write A as I\/O write B without any noticeable delay in time.","In some embodiments, tap application  may determine a virtual machine indicator (VM indicator) for I\/O write A. The VM indicator may include a virtual machine disk (VMDK) identifier associated with, and\/or an indication of, the virtual machine that generated that I\/O write A (i.e., first virtual machine ()). Tap application  may implement continuous data protection\/back-up only for certain virtual machines. In accordance with the example above, tap application  may be configured to provide continuous data protection\/back-up for virtual machine (), but not for other virtual machines ()-(). For example, upon determining that VM indicator for I\/O write A indicates virtual machine (), tap application  may generate a secondary write .","Tap application  may propagate I\/O write A, i.e., as I\/O write B, to primary storage  regardless of the outcome of this determination. Tap application  can selectively generate secondary write  that corresponds to I\/O write A. In one embodiment, secondary write  includes the data (e.g., data contained in first I\/O write A) and the VM indicator (e.g., indicating that first virtual machine () generated I\/O write A). In one embodiment, secondary write  may also include the offset included in first I\/O write A.","Secondary storage  may store secondary write  using a variety of techniques. For example, secondary storage  may be implemented using VMFS. In this case, secondary storage  may store data of secondary write  at an offset at an VMDK (but also including the VM indicator). In some embodiments, secondary storage  may implement a continuous data protection (CDP) system, as described below. In this case, secondary storage  may store data of secondary write  in accordance with the given CDO implementation.","Each virtual machine ()-() may be a software implementation of a physical computer that executes computer instructions in the manner of physical computer hardware. Virtual machines ()-() may read and write data, i.e., using I\/O writes, to primary storage . Each virtual machine ()-() may be software implementations of a physical computer that execute computer instructions in the manner of physical computer hardware. Virtual machines ()-() may read and write data, i.e., using I\/O writes, to primary storage . Each virtual machine ()-() may be similar to VMs ()-() of . Virtual machines ()-() can perform I\/O reads and writes to primary storage , such as to read and write data.",{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 3","b":["300","302","302","102","1","102","2","202","1","202","2","302","304","304","308","1","308","3","304","302","302","308","1","308","3"]},"Host operating system  is the operating system that enables execution of hypervisor . Node  may also include a change tracker (not shown) that may keep track of changes to data made to the primary storage (e.g., primary storage  of ) by node , e.g., on behalf of virtual machines ()-(). The changes to data may be recorded by change tracker in a local change list.","Hypervisor  may be implemented in software and\/or hardware, and may provide node  the ability to concurrently support virtual machines ()-(). Hypervisor  may provide such ability by coordinating the distribution of computer resources (e.g., processing power, memory, etc.) among virtual machines ()-(), so that virtual machines ()-() operate similarly to physical computers. Virtual machines ()-() may be implemented in software (i.e., of node ) and execute computer instructions similarly to physical hardware. Each virtual machine ()-() may be able to operate as if the host computer (e.g., node ) were solely under that virtual machine's control, and so share the host computer system's resources. Hypervisor  may act as a coordinator or manager of computing resources (e.g., such as processor(s), memory, etc.) of node . Hypervisor  supports multiple virtual machines ()-() by coordinating processor resources to support the execution of instructions on behalf of various virtual machines ()-(), and performing memory management to help ensure that the virtual machines effectively share node's  system memory, for example.","Each virtual machine (VM) ()-() can be implemented using the same or different operating systems. A client interacting with a VM ()-() will typically interact in substantially the same manner that a client would interact with a standalone operating system operating on independent hardware. Virtual machines ()-() can be implemented using virtualization software, such as that provided by VMWARE.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIG. 4","FIG. 4","FIG. 2"],"b":["400","402","404","406","408","410","402","404","406","410","408","200","410","410"]},"Node  includes at least one virtual machine, such as any virtual machine () or (). Each virtual machine () or () may operate in manner similar to that described with reference to . Node  may also include a hypervisor . Hypervisor, in one embodiment, may facilitate the execution of virtual machines () and\/or (), such as in manner described with reference to . Node  (e.g., virtual machine () or ()) may generate I\/O writes to primary storage . For example, virtual machine () can generate an I\/O write A. I\/O write A includes various elements, including an offset in a VMFS file system of primary storage  and data to be written at the offset in the VMFS file system of primary storage .","Primary storage  and secondary storage  may be of any type of storage, such as described above with reference to  and\/or . Primary storage  may use a VMFS file system, such as provided by VMWARE. Primary storage  may allow data to be stored by nodes and\/or virtual machines, such as by receiving and processing I\/O writes from node  and\/or virtual machines () and (). Primary storage  may also allow stored data to be read by nodes and\/or virtual machines, such as by receiving and processing I\/O reads from node  and\/or virtual machines () and (). For example, primary storage  may receive and process I\/O write B that includes data and offset. Primary storage  may process I\/O write B such as by using the offset to determine where in the VMFS file system to store the data. For example, primary storage  may store data of I\/O write B by accessing an appropriate VMDK of an VMFS volume, as is indicated by the offset.","Secondary storage  is configured to receive and store I\/O writes, including a secondary I\/O write . In one embodiment, secondary storage  is configured to operate in similar manner to that of primary storage , such as simply receiving and processing I\/O writes as described above. In some embodiments, secondary storage  is configured to operate as a continuous data protection (CDP) system and\/or a back-up system, such as described below with reference to . In one implementation, secondary write  may include additional data elements that are not found in I\/O write A and\/or B. For example, secondary write  may include a VM indicator, such as a virtual machine disk (VMDK) associated with virtual machine (), and\/or an indication of virtual machine (). The indication of virtual machine () may, in one embodiment, simply indicate that virtual machine () is the virtual machine that initially generated I\/O write A.","Secondary storage  may store data that is included in secondary write  along with the VM indicator. As a result, during a recovery operation, secondary storage  may be able to easily locate any data that was generated by a specific virtual machine, such as virtual machine (). For example, a data recovery operation may want to only recover data that for virtual machine (), and not any of the other virtual machines.","Network  may be any type of a network, including a local area network (LAN), a storage area network (SAN), etc. For example, network  may be implemented using Ethernet, FibreChannel, and\/or any other type of LAN\/SAN. Network  connects nodes (e.g., node ) together with storage devices, e.g., primary storage  and secondary storage . Network  facilitates communication (e.g., I\/O access such as I\/O reads and writes) between node  and storage devices  and . In addition, tap device  may couple to network  and monitor and\/or propagate I\/O reads and writes.","Tap device  includes a processing module , a pass-through module , a write generator , a mapping module , and a map file . In one embodiment, tap device  illustrates a more detailed view of tap device  of . In one implementation, tap application  of  may be implemented using one or more of processing module , pass-through module , write generator , mapping module , and\/or map file .","In one embodiment, processing module  receives I\/O write A. Processing module  may process I\/O write A, such as by communicating with mapping module , write generator , and\/or pass-through module . In one embodiment, processing module  may use mapping module  (such as by passing an offset that is included in I\/O write A) to determine which virtual machine generated the I\/O write A.","The I\/O writes that use the VMFS file system, such as I\/O write A, usually include data and an offset. This offset typically indicates a location in a VMFS file system where the data is to be written. For example, the offset can be used by primary storage  to store the data at a certain VMDK, as described above.","Processing module  of tap device  may be pre-configured, such as by a user or a system administrator, to provide CDP\/back-up for I\/O writes from a selected virtual machine. For example, tap device  may be pre-configured to only provide CDP\/back-up for I\/O writes from virtual machine (), but not virtual machine () or any other virtual machine from node  or any other nodes. In some embodiments, the user or the system administrator can change, e.g., by accessing processing module , which virtual machine is to be provided with CDP\/back-up.","In some embodiments, processing module  can dynamically and\/or automatically select which virtual machines are to be provided with CDP\/back-up. Processing module  can monitor the I\/O writes from the virtual machines on node  (and\/or other nodes on network ). Processing module  can selectively generate secondary writes from the I\/O writes to secondary storage  based on the monitoring. Processing module  can monitor the I\/O writes (from VMs ()-()), and then analyze various characteristics of these I\/O writes. These characteristics include frequency and size of the data of these I\/O writes. For example, processing module  can analyze a frequency of I\/O writes from each virtual machine on node . Depending on desired characteristics, processing module  can select to provide CDP\/back-up for only a virtual machine that most frequently performs I\/O writes. In another example, processing module  may be initially set-up (e.g., by the administrator) to provide CDP of I\/O writes from both virtual machines () and (). However, based on monitoring of the I\/O traffic through tap device  to primary storage , processing module  may dynamically select only to provide CDP for I\/O writes from virtual machine () (and\/or any other selected virtual machine).","Mapping module  may determine a VM indicator for the offset of I\/O write A. In some embodiments, mapping module  may query, using the offset, a software entity on node  to obtain the VM indicator. For example, the software entity (that is queried by mapping module ) includes some portion of an operating system of node , or a hypervisor  of node . The software entity may then return the VM indicator that is associated with the offset of I\/O write A. The VM indicator includes a VMDK associated with the virtual machine that generated I\/O write A, or an indication of that virtual machine (such as a reference or identification of virtual machine ()).","In one embodiment, mapping module  may query an Application Programming Interface (API) that is implemented by the software entity on node . For example, node  may implement one or more VMWARE APIs that can be queried by mapping module , such as via network . In one embodiment, the software entity may implement an API command that returns a VM indicator. For example, node  may be programmed with a getVMDK (ESXid, offset_on_ESX) that returns a VMDK id for an offset on a given hypervisor (ESX) on that node . In some embodiments, mapping module  may call other API(s) on node  in addition to, or instead of, the one described above. For example, mapping module  may call a queryChangedDiskAreas function on node .","In some embodiments, mapping module  may access map file  that includes the VM indicator for the offset of I\/O write A. For example, mapping module  may create map file  that includes a plurality of mappings of offsets to VM indicators. In some embodiments, mapping module  may create map file  prior to processing the I\/O writes. In one embodiment, mapping module  can also first use map file  to find a VM indicator that corresponds to a given offset. If map file  does not contain that given VM indicator, mapping module  can then query the software entity on node  for the VM indicator. Mapping module  can then return the VM indicator to processing module . In one implementation, map file  may store VMDKs for a range of offsets. For example, offset  to , could map to a first VMDK, offset  to , could map to a second VMDK, etc.","Processing module  can, if the VM indicator of an I\/O write indicates a virtual machine that is to be provided with CDP\/back-up, selectively generate secondary writes to secondary storage . For example, if VM indicator associated with I\/O write A indicates that virtual machine () generated I\/O write A, processing module  may request that write generator  generates a secondary write, e.g., a secondary write , to be stored at secondary storage . On the other hand, if VM indicator associated with I\/O write A indicates another virtual machine ()-() generated I\/O write A, and only VM () is to be provided with CDP\/back-up, processing module  may just use pass through module  to propagates I\/O write A, as I\/O write B, to be stored at primary storage . In some embodiments, I\/O writes (e.g., B) propagated by pass-through module  are substantially similar to the I\/O writes (e.g., A) received by tap device . It is noted that I\/O write A is propagated as I\/O write B to primary storage  regardless of whether the VM indicator indicates a virtual machine that is to be provided with CDP\/back-up, only secondary writes are selectively generated.","Write generator  generates secondary writes (e.g., secondary write ) to secondary storage  based on the original I\/O writes (e.g., I\/O write A). Write generator generates secondary writes as requested by processing module . Each secondary write includes the data of the original I\/O write and the VM indicator associated with that I\/O write. For example, write generator  may generate secondary write  that includes the data included in I\/O write A. Secondary write  may also include the VM indicator associated with I\/O write A as well as the offset of I\/O write A. Write generator then can access secondary storage  to write secondary write . Secondary storage  is operable to store the data included in secondary write  using the VM indicator.","Referring now to , one embodiment of a method  for using a tap device in a distributed computing system is disclosed. Method  may be modified by those skilled in the art in order to derive alternative embodiments. Also, the steps in this embodiment are shown in sequential order. However, some steps may occur in a different order than shown, some steps may be performed concurrently, some steps may be combined with other steps, and some steps may be absent in another embodiment. Method  is described with reference to .","In step , an I\/O write is received from a virtual machine. In some embodiments, processing module  of tap  can receive I\/O write A from node . I\/O write A includes data and offset. Although virtual machine () may be generating this I\/O write A, I\/O write A itself does not indicate which virtual machine generated the I\/O write A. I\/O write A also does not indicate which VMDK (i.e., on the VMFS file system of primary storage ) that I\/O write A is accessing.","In step , a VM indicator is determined using an offset in the I\/O write. In some embodiments, processing module  can communicate with mapping module  to determine the VM indicator. Mapping module  may query a software entity (e.g., an operating system, a hypervisor, and\/or virtual machine(s)) on node  using the offset in I\/O write A. This software entity may then return a VM indicator, which may be a virtual machine disk (VMDK) associated with the virtual machine (i.e., VM ()) that generated I\/O write A, or an indication of virtual machine (). In some embodiments, mapping module  may access map file  to determine the VM indicator, e.g., instead of, or before, querying the software entity on node . The VM indicator may be communicated by mapping module  to processing module . In some embodiments, processing module  may keep a local cache of most-frequently and\/or most recently used offsets and corresponding VM indicators. In accordance with these embodiments, processing module may itself make a determination of the VM indicator, without communicating with mapping module .","In step , it is determined whether the VM indicator indicates a virtual machine that is to be provided with CDP\/back-up. In some embodiments, processing module  may make this determination. For example, processing module  may include a list (and\/or any other data structure) listing VM indicators (e.g., indications of virtual machines) that should be provided with CDP\/back-up by tap device . If it is determined that the VM indicates a virtual machine that is to be provided with CDP\/back-up, execution of the method  continues at step . If it is determined that the VM indicates a virtual machine that is not to be provided with CDP\/back-up, execution of the method  continues at step .","In some embodiments, if it is determined that the VM indicates a virtual machine that is not to provided with CDP\/back-up, processing module  may communicate with pass-through module  to forward (e.g., pass-through) I\/O write A as I\/O write B. In some implementations, I\/O write A and B are substantially similar. I\/O write B is then propagated to primary storage , which then can store data of I\/O write B using the corresponding offset.","In step , if the VM indicator indicates a virtual machine that is to be provided with CDP\/back-up, a secondary write is generated. In some embodiments, processing module  may communicate with write generator  to generate secondary write  based on I\/O write A. Write generator  may generate secondary write  that is propagated to secondary storage . Write generator  may generate secondary write  that is compatible with the CDP\/back-up technique used by secondary storage . In some embodiments, secondary write  includes data of I\/O write A and the determined VM indicator (i.e., as determined in step ). Secondary write  may also include the offset of I\/O write A.","In addition to the generation of secondary write , processing module  may communicate with pass-through module  to forward (e.g., pass-through) I\/O write A as I\/O write B. I\/O write B is then propagated to primary storage , which then can store data of I\/O write B using the corresponding offset. In other words, I\/O write A is propagated as I\/O write B to primary storage  regardless of whether the VM indicator is associated with a VM that is to be provided with CDP\/back-up.","In step , the secondary storage is accessed to store the data using the secondary write. In some embodiments, write generator  may access secondary storage  using secondary write , such as by propagating secondary write  to secondary storage . Secondary storage  may then store data of secondary write  using the VM indicator, and optionally also the offset, of secondary write .",{"@attributes":{"id":"p-0070","num":"0069"},"figref":["FIG. 6","FIG. 6"],"b":["600","600","602","610","606"]},"Node  may be implemented as node  of . In some embodiments, node  may implement dirty region logging (DRL) bitmap . In one embodiment, a region is a logical portion of a volume (e.g., in primary storage ) that is defined and used by DRL. When DRL is enabled for a volume (e.g., in primary storage ), a DRL bitmap  is created that represents this volume. When a region in this volume is modified (e.g., by an I\/O write by a VM on node ), a corresponding bit in DRL bitmap  is marked dirty before this I\/O write is made to the volume. After the I\/O write operation completes to the volume, DRL  doesn't remove the dirty bit. The bit isn't removed until it is the \u201cleast recently used.\u201d This DRL technique may be implemented in conjunction with secondary storage  being configured as a CDP backend. In accordance with this DRL technique, secondary storage  also includes a backend DRL bitmap  and a change log .","In some embodiments, this dirty bit may be also communicated (e.g., by node ) to secondary storage  (i.e., CDP backend ). CDP backend  may implement a two-stage commit technique, such as using a separate flag or state for this dirty bit. In some embodiments, the dirty bit may be marked by CDP backend  prior to generating and\/or sending of a secondary write that corresponds to the I\/O write for this dirty bit. Once primary storage  completes this I\/O write (e.g., by successfully storing data of this I\/O write), primary storage  may communicate a notification of a successful write back to node , which may then update the corresponding location in DRL bitmap (but may still wait for the secondary write to complete successfully). In some embodiments, CDP backend  may also keep track of a change log  that keeps track of changes to data for the virtual machine(s) that are to be provided with CDP\/back-up.","Furthermore, once secondary storage  successfully completes a corresponding I\/O write (e.g., of the secondary write), secondary storage  may update its own backend DRL bitmap  with a notification of a successful secondary write. In some embodiments, secondary storage  (i.e., CDP backend ) may communicate a notification of a successful write at secondary storage  back to node , which may then update the corresponding location in DRL bitmap. Therefore each bit in the DRL bitmap  on node  may not be totally updated until notifications are received from both primary storage  and secondary storage . In some embodiments, tap device  communicates with node  to only use the secondary storage notifications of DRL bitmap  for virtual machines that are to be provided with CDP\/back-up. DRL bitmap  may only be used for virtual machines that are to be provided with CDP\/back-up.","In some embodiments, when other CDP\/back-up techniques are used (e.g., instead of the CDP technique described above), secondary storage  may be correspondingly configured in conjunction with tap device . For example, secondary storage  may be configured to send successful secondary write notifications to tap device  and\/or node  for each secondary write that is successfully stored on secondary storage .","Elements of network architecture can be implemented using different computer systems and networks. An example of one such network environment is described below with reference to .",{"@attributes":{"id":"p-0076","num":"0075"},"figref":["FIG. 7","FIG. 7"],"b":["700","702","1","710","706","202","1","2","402","710","210","410","710","702","1","706","706","706"]},"As also depicted on , server  is coupled to a server storage device , which includes a data volume such as cluster shared volume. Server storage device  can be implemented as a single storage device or a collection of storage devices. Server storage device  can also be implemented as a storage area network, which couples remote storage devices to a server (e.g., server ), such that the remote storage devices appear as locally-attached storage devices to the server's OS, for example.","In light of the present disclosure, those of skill in the art will appreciate that server storage device  can be implemented by any type of computer-readable storage medium, including, but not limited to, internal or external hard disk drives (HDD), optical drives (e.g., CD-R, CD-RW, DVD-R, DVD-RW, and the like), flash memory drives (e.g., USB memory sticks and the like), tape drives and the like. Alternatively, those of skill in the art will also appreciate that, in light of the present disclosure, network architecture  can include other components such as routers, firewalls and the like that are not germane to the discussion of the present network and will not be discussed further herein. Those of skill in the art will also appreciate that other configurations are possible. For example, clients ()-(N) can be directly coupled to server storage device  without the user of a server or Internet; server  can be used to implement both the clients and the server; network architecture  can be implemented without the use of clients ()-(N); and so on.","As an example implementation of network architecture , server  (implemented with a node ()) services requests to data generated by clients ()-(N) to data stored in server storage device  (implemented with primary storage ). Other servers (not depicted) can be implemented with tap device . Virtual machines (e.g., virtual machines ()-() of  and\/or VM  of ) implemented on coordinator node ()-() can be used to service these requests by reading and writing data to and from primary storage . A tap application (e.g., tap application  of ) can be implemented using one of the other servers in the manner illustrated by , , and\/or .",{"@attributes":{"id":"p-0080","num":"0079"},"figref":"FIG. 8","b":["810","810","200","202","1","202","2","210","300","302","400","402","410","600","602","610","810","812","810","814","817","818","820","822","824","826","828","830","832","833","834","837","838","835","890","835","839","840","842","846","812","828","847","812","830","848","812"]},"Bus  allows data communication between central processor  and system memory , which may include read-only memory (ROM) or flash memory (neither shown), and random access memory (RAM) (not shown), as previously noted. The RAM is generally the main memory into which the operating system and application programs are loaded. The ROM or flash memory can contain, among other code, the Basic Input-Output system (BIOS) which controls basic hardware operation such as the interaction with peripheral components. Applications resident with computer system  are generally stored on and accessed via a computer readable medium, such as a hard disk drive (e.g., fixed disk ), an optical drive (e.g., optical drive ), a floppy disk unit , or other storage medium. Additionally, applications can be in the form of electronic signals modulated in accordance with the application and data communication technology when accessed via network modem  or interface .","Storage interface , as with the other storage interfaces of computer system , can connect to a standard computer readable medium for storage and\/or retrieval of information, such as a fixed disk drive . Fixed disk drive  may be a part of computer system  or may be separate and accessed through other interface systems. Modem  may provide a direct connection to a remote server via a telephone link or to the Internet via an interne service provider (ISP). Network interface  may provide a direct connection to a remote server via a direct network link to the Internet via a POP (point of presence). Network interface  may provide such connection using wireless techniques, including digital cellular telephone connection, Cellular Digital Packet Data (CDPD) connection, digital satellite data connection or the like.","Many other devices or subsystems (not shown) may be connected in a similar manner (e.g., document scanners, digital cameras and so on). Conversely, all of the devices shown in  need not be present to practice the present disclosure. The devices and subsystems can be interconnected in different ways from that shown in . The operation of a computer system such as that shown in  is readily known in the art and is not discussed in detail in this application. Code for the tap application and\/or for providing an adaptive tap for a virtual machine protection (such as described above with reference to the method  of ), etc., to implement the present disclosure can be stored in computer-readable storage media such as one or more of system memory , fixed disk , optical disk , or floppy disk . Memory  is also used for storing temporary variables or other intermediate information during the execution of instructions by the processor . The operating system provided on computer system  may be MS-DOS\u00ae, MS-WINDOWS\u00ae, OS\/2\u00ae, UNIX\u00ae, Linux\u00ae, or another known operating system.","Moreover, regarding the signals described herein, those skilled in the art will recognize that a signal can be directly transmitted from a first block to a second block, or a signal can be modified (e.g., amplified, attenuated, delayed, latched, buffered, inverted, filtered, or otherwise modified) between the blocks. Although the signals of the above described embodiment are characterized as transmitted from one block to the next, other embodiments of the present disclosure may include modified signals in place of such directly transmitted signals as long as the informational and\/or functional aspect of the signal is transmitted between blocks. To some extent, a signal input at a second block can be conceptualized as a second signal derived from a first signal output from a first block due to physical limitations of the circuitry involved (e.g., there will inevitably be some attenuation and delay). Therefore, as used herein, a second signal derived from a first signal includes the first signal or any modifications to the first signal, whether due to circuit limitations or due to passage through other circuit elements which do not change the informational and\/or final functional aspect of the first signal.","Although the present invention has been described in connection with several embodiments, the invention is not intended to be limited to the specific forms set forth herein. On the contrary, it is intended to cover such alternatives, modifications, and equivalents as can be reasonably included within the scope of the invention as defined by the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention may be better understood, and its numerous objects, features, and advantages made apparent to those skilled in the art by referencing the accompanying drawings.",{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
