---
title: Dynamically sizing a collaboration of concurrent computing workers based on user inputs
abstract: A dynamic collaboration of processes in a concurrent computing environment is disclosed. A user can modify the size of collaboration or the number of processes that execute a computational job after the processes have been launched on the concurrent computing environment. A launched or running process can establish a communication channel with other processes in the collaboration so that the launched or running process can join the collaboration to execute the job. The user can also release a process from the collaboration so the released process can join a new collaboration to execute a different job. Once a job is completed, the processes can leave the collaboration, and the processes are then free to join a new collaboration subsequently.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07765561&OS=07765561&RS=07765561
owner: The MathWorks, Inc.
number: 07765561
owner_city: Natick
owner_country: US
publication_date: 20051110
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["COPYRIGHT","TECHNICAL FIELD","BACKGROUND INFORMATION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure, as it appears in the Patent and Trademark Office patent file or records, but otherwise reserves all copyright rights whatsoever.","The present invention generally relates to a concurrent computing environment and more particularly to methods, systems and mediums for providing dynamic collaborations in the concurrent computing environment.","MATLAB\u00ae is a product of The MathWorks, Inc. of Natick, Mass., which provides engineers, scientists, mathematicians, and educators across a diverse range of industries with an environment for technical computing applications. MATLAB\u00ae is an intuitive high performance language and technical computing environment that provides mathematical and graphical tools for mathematical computation, data analysis, visualization and algorithm development. MATLAB\u00ae integrates numerical analysis, matrix computation, signal processing, and graphics in an easy-to-use environment where problems and solutions are expressed in familiar mathematical notation, without traditional programming. MATLAB\u00ae is used to solve complex engineering and scientific problems by developing mathematical models that simulate the problem. A model is prototyped, tested and analyzed by running the model under multiple boundary conditions, data parameters, or just a number of initial guesses. In MATLAB\u00ae, one can easily modify the model, plot a new variable or reformulate the problem in a rapid interactive fashion that is typically not feasible in a non-interpreted programming such as Fortran or C.","As a desktop application, MATLAB\u00ae allows scientists and engineers to interactively perform complex analysis and modeling in their familiar workstation environment. With many engineering and scientific problems requiring larger and more complex modeling, computations accordingly become more resource intensive and time-consuming. However, a single workstation can be limiting to the size of the problem that can be solved, because of the relationship of the computing power of the workstation to the computing power necessary to execute computing intensive iterative processing of complex problems in a reasonable time. For example, a simulation of a large complex aircraft model may take a reasonable time to run with a single computation with a specified set of parameters. However, the analysis of the problem may also require the model be computed multiple times with a different set of parameters, e.g., at one-hundred different altitude levels and fifty different aircraft weights, to understand the behavior of the model under varied conditions. This would require five-thousand computations to analyze the problem as desired and the single workstation would take an unreasonable or undesirable amount of time to perform these simulations. Therefore, it is desirable to perform a computation concurrently using multiple workstations when the computation becomes so large and complex that it cannot be completed in a reasonable amount of time on a single workstation.","Message Passing Interface (MPI) is a standard for an interface for message passing. MPI communications have been used for performing message passing between parallel machines or workstations in concurrent computing systems. In conventional concurrent computing systems, computing applications, which make use of MPI communications must be launched using a launcher program (usually called \u201cmpirun\u201d or \u201cmpiexec\u201d). An example of the syntax for calling mpirun is as follows.","mpirun-np<number of processes> <application name and arguments>","Once the applications have been launched on a concurrent computing system, the size of collaboration (the number of processes) is typically fixed for the duration of the applications. This is inconvenient in that if a user wishes to add processes to the concurrent computation, the user must completely repeat the entire launching processes. Therefore, it would be desirable to have a concurrent computing system in which the size of collaboration or the number of processes can be modified dynamically even after the applications have been launched on the concurrent computing system.","The present invention provides a computing environment in which a large computational job can be performed concurrently by multiple processes. This concurrent computing environment may include a client that creates the job. The job may include one or more tasks. The client may send the job or tasks to the multiple processes for the concurrent execution of the job. In the present invention, the processes may interact with each other, or may communicate with the client or an intermediary agent, such as a job manager, to execute the job. The remote processes execute the job and may return execution results to the client directly or indirectly via the intermediary agent.","The present invention provides a dynamic collaboration of the processes in the concurrent computing environment. The present invention enables a user to modify the size of collaboration or the number of processes that execute the job after the processes have been launched on the concurrent computing environment. The present invention enables a launched or running process to establish a communication channel with other processes in the collaboration so that the launched or running process can join the collaboration to execute the job. The present invention also enables a user to release a process from the collaboration so the released process can join a new collaboration to execute a different job. Once a job is completed, the processes can leave the collaboration and are free to join a new collaboration. As such, the present invention allows a user to dynamically modify the size of the collaboration at any time.","In one aspect of the present invention, a method and a medium holding instructions executable in a computer for performing the method are provided for a dynamic collaboration of concurrent computing programs to execute a computational job in a concurrent computing environment. The method includes the step of launching concurrent computing programs on the one or more computing devices. A number of the concurrent computing programs form a collaboration to execute the computational job. The collaboration includes a first concurrent computing program. The method also includes the step of enabling a second concurrent computing program outside of the collaboration to invoke interface function calls to establish a communication channel with the first concurrent computing program, and hence to dynamically join the collaboration.","In another aspect of the present invention, a method and a medium holding instructions executable in a computer for performing the method are provide for a dynamic collaboration of concurrent computing programs to execute a computational job in a concurrent computing environment. The method includes the step of launching concurrent computing programs on the one or more computing devices. A number of the concurrent computing programs form a collaboration to execute the computational job. The collaboration includes a first concurrent computing program. The method also includes the step of enabling the concurrent computing programs in the collaboration to invoke an interface function call to disconnect a communication channel with the first concurrent computing program, and hence the first concurrent computing program dynamically leaves the collaboration.","In another aspect of the present invention, a system is provided for a dynamic collaboration of concurrent computing programs to execute a computational job in a concurrent computing environment. The system includes a collaboration of concurrent computing programs launched on one or more computing devices to execute a computational job. The collaboration includes a first concurrent computing program. The system also includes a second concurrent computing program outside of the collaboration for invoking interface function calls to establish a communication channel with the first concurrent computing program, and hence joining the collaboration dynamically.","In another aspect of the present invention, a system is provided for a dynamic collaboration of concurrent computing programs to execute a computational job in a concurrent computing environment. The system forms a collaboration of concurrent computing programs launched on one or more computing devices to execute a computational job. The collaboration includes a first concurrent computing program. The concurrent computing programs in the collaboration invoke an interface function call to disconnect a communication channel with the first concurrent computing program, and hence the first concurrent computing program dynamically leaves the collaboration.","With the dynamic collaboration of the present invention, the processes involved in the concurrent computing system can establish a communication channel with other processes after the processes have been launched on the concurrent computing system. Therefore, the processes involved in the concurrent computing system of the present invention need not be launched using the conventional launcher program, such as \u201cmpiexec\u201d or \u201cmpirun,\u201d which significantly reduces the initial delay when launching the processes on the concurrent computing system.","Certain embodiments of the present invention are described below. It is, however, expressly noted that the present invention is not limited to these embodiments, but rather the intention is that additions and modifications to what is expressly described herein also are included within the scope of the invention. Moreover, it is to be understood that the features of the various embodiments described herein are not mutually exclusive and can exist in various combinations and permutations, even if such combinations or permutations are not made express herein, without departing from the spirit and scope of the invention.","The illustrative embodiment of the present invention provides a computing system that enables a user to execute a computational job concurrently using multiple remote workers. A job is a logical unit of activities, or tasks that are processed and\/or managed collectively. A task defines a technical computing command, such as a MATLAB\u00ae command, to be executed, and the number of arguments and any input data to the arguments. A job is a group of one or more tasks. In the illustrative embodiment, the concurrent computing system may include a client for creating the job. The client may send the job to one or more remote workers for the execution of the job. The remote workers execute the job and return the execution results to the client. The workers may interact with each other, or may communicate with the client or an intermediary agent, such as a job manager, to execute the job. As such, the illustrative embodiment of the present invention executes the job using a concurrent computing system.","The illustrative embodiment of the present invention provides a dynamic collaboration of the workers in the concurrent computing system. The illustrative embodiment enables a user to specify the size of collaboration or the number of workers that execute the job interactively after the workers have been launched. A worker may establish communication channels with other workers in the collaboration so that the worker can join the collaboration to execute the job. The illustrative embodiment also enables a user to release a worker from the collaboration so the released process can join a new collaboration. In the illustrative embodiment, once a job is completed, the workers are released from the collaboration, and they are then free to join a new collaboration. As such, the illustrative embodiment enables the workers in the concurrent computing system to take part in different collaborations in sequence.","The illustrative embodiment will be described solely for illustrative purposes relative to a MATLAB\u00ae-based technical computing environment. Although the illustrative embodiment will be described relative to a MATLAB\u00ae-based application, one of ordinary skill in the art will appreciate that the present invention may be applied to distributing the processing of technical computing tasks with other technical computing environments, such as technical computing environments using software products of LabVIEW\u00ae or MATRIXx from National Instruments, Inc., or Mathematica\u00ae from Wolfram Research, Inc., or Mathcad of Mathsoft Engineering & Education Inc., or Maple\u2122 from Maplesoft, a division of Waterloo Maple Inc.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 1","b":["100","102","106","104","106","106","106","102","114","102","110","112","110","112","114","102"]},"The computing device  may support any suitable installation medium , a CD-ROM, floppy disks, tape device, USB device, hard-drive or any other device suitable for installing software programs, such as the MATLAB\u00ae-based concurrent computing application . Moreover, the computing device  may be any computer system such as a workstation, desktop computer, server, laptop, handheld computer or other form of computing or telecommunications device that is capable of communication and that has sufficient processor power and memory capacity to perform the operations described herein.","Additionally, the computing device  may include a network interface  to interface to a Local Area Network (LAN), Wide Area Network (WAN) or the Internet through a variety of connections including, but not limited to, standard telephone lines, LAN or WAN links (e.g., 802.11, T1, T3, 56 kb, X.25), broadband connections (e.g., ISDN, Frame Relay, ATM), wireless connections, or some combination of any or all of the above. The network interface  may include a built-in network adapter, network interface card, PCMCIA network card, card bus network adapter, wireless network adapter, USB network adapter, modem or any other device suitable for interfacing the computing device  to any type of network capable of communication and performing the operations described herein.","The computing device  may further include a storage device , such as a hard-drive or CD-ROM, for storing an operating system and for storing application software programs, such as the MATLAB\u00ae-based concurrent computing application . The MATLAB\u00ae-based concurrent computing application  may run on any operating system such as any of the versions of the Microsoft\u00ae Windows operating systems, the different releases of the Unix and Linux operating systems, any version of the MacOS\u00ae for Macintosh computers, any embedded operating system, any real-time operating system, any open source operating system, any proprietary operating system, any operating systems for mobile computing devices, or any other operating system capable of running on the computing device and performing the operations described herein. Furthermore, the operating system and the MATLAB\u00ae-based concurrent computing application  can be run from a bootable CD, such as, for example, KNOPPIX\u00ae, a bootable CD for GNU\/Linux.","Those of skill in the art will appreciate that the computing device  may include multiple processors or multiple cores on a single machine, so that multiple concurrent computing applications can be running on the single machine.","The storage device  may also store interface function calls  that enable the MATLAB\u00ae-based concurrent computing application  to communicate with other computing applications or processes in a concurrent computing system. The interface function calls  provide various function calls for the MATLAB\u00ae-based concurrent computing application  to establish communication channels with other computing processes, or applications in the concurrent computing system. The interface function calls  may be provided as a shared library, such as DLL files on Windows and so files on UNIX. The shared library enables the concurrent computing application  to dynamically load and close the interface function calls , which is necessary for the concurrent computing application  to establish a communication channel when the concurrent computing application  joins a new collaboration.","Since the concurrent computing system may require extensive message passing between the computing processes, the interface function calls  may include message passing function calls, such as Message Passing Interface (MPI) function calls. MPI is a de facto standard, created by the group of vendors, computer scientists and users making up the MPI Forum. MPI is a message-passing library specification defining a collection of subroutines and arguments used for communication among nodes running a parallel program on a distributed memory system. Implementation of the MPI specification permits programs with separate address spaces to synchronize with one another and move data from the address space of one process to that of another by sending and receiving messages. The interface function calls  will be described below in more detail with reference to .",{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 2","b":["200","120","200","150","130","170","140","120","150","170"]},"The MATLAB\u00ae-based computing application  may include a technical computing client application , or technical computing client, running on a client  computer and a technical computing worker application , or technical computing worker, running on a workstation . The technical computing client  may be in communication through the network communication channel  on the network  with one, some or all of the technical computing workers . The technical computing workers  can be hosted on the same workstation, or a single technical computing worker  can have a dedicated workstation . Alternatively, one or more of the technical computing workers  can be hosted on the client .","The technical computing client  can be a technical computing software application that provides a technical computing and graphical modeling environment for generating block diagram models and to define mathematical algorithms for simulating models. The technical computing client  can be a MATLAB\u00ae-based client, which may include all or a portion of the functionality provided by the standalone desktop application of MATLAB\u00ae. Additionally, the technical computing client  can be any of the software programs available in the MATLAB\u00ae product family. Furthermore, the technical computing client  can be a custom software program or other software that accesses MATLAB\u00ae functionality via an interface, such as an application programming, interface, or by other means. One ordinarily skilled in the art will appreciate the various combinations of client types that may access the functionality of the system.","With an application programming interface and\/or programming language of the technical computing client , functions can be defined representing a technical computing task to be executed by either a technical computing environment local to the client computer , or remote on the workstation . The local technical computing environment may be part of the technical computing client , or a technical computing worker running on the client computer . The programming language includes mechanisms to define tasks to be distributed to a technical computing environment and to communicate the tasks to the technical computing workers  on the workstations , or alternatively, on the client . Also, the application programming interface and programming language of the MATLAB\u00ae-based client  includes mechanisms to receive a result from the execution of technical computing of the task from another technical computing environment. Furthermore, the MATLAB\u00ae-based client  may provide a user interface that enables a user to specify the size of the collaboration of the technical computing workers  for the execution of the job or tasks. The user interface may also enable a user to specify a technical computing worker  to be added to the collaboration or to be removed from the collaboration.","The technical computing worker  of the system  can be a technical computing software application that provides a technical computing environment for performing technical computing of tasks, such as those tasks defined or created by the technical computing client . The technical computing worker  can be a MATLAB\u00ae-based worker application, module, service, software component, or a session, which includes support for technical computing of functions defined in the programming language of MATLAB\u00ae. A session is an instance of a running technical computing worker  by which a technical computing client can connect and access its functionality. The technical computing worker  can include all the functionality and software components of the technical computing client , or it can just include those software components it may need to perform technical computing of tasks it receives for execution. The technical computing worker  may be configured to and capable of running any of the modules, libraries or software components of the MATLAB\u00ae product family. As such, the technical computing worker  may have all or a portion of the software components of MATLAB\u00ae installed on the workstation , or alternatively, accessible on another system in the network . The technical computing worker  is capable of performing technical computing of the task as if the technical computing client  was performing the technical computing in its own technical computing environment. The technical computing worker  also has mechanisms, to return a result generated by the technical computing of the task to the technical computing client .","A server  may be coupled to the network . The server  may include a job manager . The job manager  can provide control of delegating tasks and obtaining results in the concurrent computing system . The job manager  may provide an interface for managing a group of tasks collectively as a single unit called a job, and on behalf of a technical computing client , submitting those tasks making up the job, and obtaining the results of each of the tasks until the job is completed. This eases the programming and integration burden on the technical computing client . For multiple task submissions from the technical computing client , the job manager  can manage and handle the delegations of the tasks to the technical computing workers  and hold the results of the tasks on behalf of the technical computing client  for retrieval after the completion of technical computing of all the tasks.","Although the present invention is discussed above in terms of the MATLAB\u00ae-based concurrent computing application across the computing devices of a client , server  and workstation , any other system and\/or deployment architecture that combines and\/or distributes one or more of the technical computing client , job manager  and technical computing workers  across any other computing devices and operating systems available in the network  may be used. Alternatively, all the software components of the MATLAB\u00ae-based concurrent computing application can run on a single computing device , such as the client , server  or the workstation .",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 3","FIG. 2"],"b":["200","250","302","250","304","260","270","305","270","306","308","310","250","270","312","260","250","313","250","260","314"]},{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 4","FIG. 2","FIG. 5"],"b":["170","170","170","150","160","140","270","270","270","270","170","170","170","510","270","270","270","270","270","270","170","170","170"]},"For the dynamic collaboration of the technical computing workers A, B and C, the technical computing workers A, B and C established a communication channel  and form a collaboration . The technical computing workers A, B and C may communicate via a Message Passing Interface (MPI) communication channel . In other embodiments, the technical computing workers A, B and C can interface via socket based communications over TCP\/IP implementing a custom message specification. In further embodiments, the technical computing workers A, B and C may communicate using any available messaging communications products and\/or custom solutions that allow the execution environments to send and receive messages. In certain embodiments, the communication channel  may include a file interfacing mechanism such as reading and writing to files on a network accessible directory or common file system. Furthermore, the technical computing workers A, B and C can each be waiting or listening for messages from other technical computing workers A, B and C. One ordinarily skilled in the art will recognize the various types of interfaces to communicate messages between the technical computing workers A, B and C.","A user can modify or change the size of collaboration by adding another computing resource, such as the technical computing worker  running on the workstation  (step ). The user may be provided on the client  with a user interface to modify or change the size of collaboration or to designate a specific resource to add to or remove from the collaboration. The client  forwards the information to the job manager , which determines a technical computing worker to be added to or to be removed from the collaboration. The job manager  communicates with the determined technical computing worker, such as the technical computing worker . In response, the technical computing worker  dynamically joins or leaves the collaboration (step ), which will be described below in more detail with reference to .",{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 6","b":["270","270","270","541","543","410","260","270","270","270","270","545","270","270","546","547","544","260"]},"The \u201clead\u201d worker  then calls MPI_Open_port (via the helper function iOpenPort) which returns a description of the port that has been opened (step ). The format of this description is dependent upon the MPI implementation\u2014a typical implementation will return a hostname and TCP port number. Exemplary code for the iOpenPort function is provided as follows.",{"@attributes":{"id":"p-0050","num":"0049"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/*"},{"entry":"\u2009* iOpenPort - called by a server to open a port for others to connect to"},{"entry":"\u2009* Returns the port description. Clients need to know this in order to"},{"entry":"\u2009* call iClientConn, as does iServAccept."},{"entry":"\u2009*\/"},{"entry":"static void iOpenPort( int nlhs, mxArray * plhs[ ] ) {"},{"entry":"\u2003char portName[MPI_MAX_PORT_NAME];"},{"entry":"\u2003int status;"},{"entry":"\u2003status = MPI_Open_port( MPI_INFO_NULL, portName );"},{"entry":"\u2003\u2003mpiAssert( status, MPIGATEWAY_OPENPORTFAILED );"},{"entry":"\u2003\/* If we get here, we've opened a port. Return that. *\/"},{"entry":"\u2003if( nlhs == 1 ) {"},{"entry":"\u2003\u2003plhs[0] = mxCreateString( portName );"},{"entry":"\u2003}"},{"entry":"}"},{"entry":"\/*"},{"entry":"* Simple helper for server and client to extract the port name and number"},{"entry":"* of clients from the first two RHS args. This helper function translates"},{"entry":"* the input arguments to the function from the form that they exist in"},{"entry":"* MATLAB to a form useful in a C program."},{"entry":"*\/"},{"entry":"static void iNameAndNumberHelper( int nrhs, const mxArray *prhs[ ],"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003\u2003char ** name, int * number ) {"},{"entry":"\u2003if( nrhs == 3 &&"},{"entry":"\u2003\u2003mxIsChar( prhs[1] ) &&"},{"entry":"\u2003\u2003mxIsNumeric( prhs[2] ) ) {"},{"entry":"\u2003\u2003\/* OK *\/"},{"entry":"\u2003\u2003*name = mxArrayToString( prhs[1] );"},{"entry":"\u2003\u2003mxAssert( *name != NULL, \u201cFailed to allocate memory for"},{"entry":"\u2003\u2003port name\u201d );"},{"entry":"\u2003\u2003*number = (int) mxGetScalar( prhs[2] );"},{"entry":"\u2003} else {"},{"entry":"\u2003\u2003\u2003mexErrMsgIdAndTxt( MPIGATEWAY_OPENPORTFAILED,"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003\u201cInvalid arguments for MPI communicator manipulation\u201d );"},{"entry":"\u2003}"},{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The \u201clead\u201d worker  then calls iServAccept with this port information (step ) so that it can call iAcceptAndMerge N\u22121 times where N is the total number of workers to be involved (step ). The following is exemplary code for iServAccept and iAcceptAndMerge.","\/*","*RHS should be an integer specifying how many clients to expect","*\/","static void iServAccept(int nrhs, const mxArray *prhs[ ]) {","char * portName;","int numClients, i;","MPI_Comm comm;","iNameAndNumberHelper(nrhs, prhs, &portName, &numClients);","comm=MPI_COMM_WORLD;","\/* Loop, accept, and merge *\/","for(i=0; i<numClients; i++) {","iAcceptAndMerge(portName, &comm);","}","\/* Have finished with portName allocated by mxArrayToString, so free here *\/","mxFree(portName);","iFixUpCommunicators(comm);","}","\/* This is used by iServAccept and iClientConn to call accept and merge","* The communicator is an INOUT argument\u2014we use its value and modify it","*\/","static void iAcceptAndMerge(char * portName, MPI_Comm * pComm) {","MPI_Comm tmp;","\/* Accept the incoming connection *\/","mpiAssert(MPI_Comm_accept(portName, MPI_INFO_NULL, 0, *pComm, &tmp),\n\n","\/* Merge the communicators *\/","mpiAssert(MPI_Intercomm_merge(tmp, 0, pComm),\n\n","\/* Free the temporary communicator *\/","mpiAssert(MPI_Comm_free(&tmp), MPIGATEWAY_OPENPORTFAILED);","}","Each follower worker is told by the job manager  (or some other 3party communication mechanism) the port description that the lead worker  received in return from the call to MPI_Openport. The followers  and  call iClientConn with this information, which first calls MPI_Comm_connect to connect to the lead worker  (steps  and ). Once connected to the lead worker , the follower then calls iAcceptAndMerge along with the lead worker to accept the connections from the other followers until all are connected (steps  and ). Each follower calculates the current size of the collaboration, and the expected total size in order to work out how many times they must call iAcceptAndMerge. The region  indicates the current collaboration. The following is exemplary code for iClientConn.","static void iClientConn(int nrhs, const mxArray *prhs[ ]) {","char * portName;","int numClients, i, rank, size;","MPI_Comm tmp, comm;","iNameAndNumberHelper(nrhs, prhs, &portName, &numClients);","\/* Open a connection *\/","mpiAssert(MPI_Comm_connect(portName, MPI_INFO_NULL, 0,","MPI_COMM_WORLD, &comm),\n\n","mpiAssert(MPI_Intercomm_merge(comm, 1, &tmp),\n\n","comm=tmp;","\/* Check that we can call size and rank *\/","mpiAssert(MPI_Comm_size(comm, &size),\n\n","mpiAssert(MPI_Comm_rank(comm, &rank),\n\n","\/* If we're waiting for other people to connect, then we need to call","iAcceptAndMerge the same number of times as the lead worker *\/","for(i=rank+1; i<=numClients; i++) {","iAcceptAndMerge(portName, &comm);","}","\/* Have finished with portName allocated by mxArrayToString, so free here *\/","mxFree(portName);","\/* Set up communicators correctly *\/","iFixUpCommunicators(comm);","}","With the interface function calls  invoked by the technical computing workers A, B and C in the collaboration , the technical computing workers A, B and C can dynamically establish a communication channel  with the other technical computing workers A, B and C, and hence form the collaboration  (step ). Those of skill in the art will appreciate that the interface function calls  can be provided on the workstations A, B and C, or at a location on the network  that can be accessed by the technical computing workers A, B and C.","The illustrative embodiment also enables technical computing workers in the collaboration  to leave the collaboration.  is a flow chart showing an exemplary operation for technical computing workers to leave the collaboration. When a job has been performed by a collaboration, the workers in the collaboration close down the communication channel together. The workers are then free to be re-assigned for other collaborations. (In particular, a worker that was once the lead worker need not be the lead worker in a future collaboration). Assuming that the technical computing workers A, B and C have executed a job and are leaving the collaboration, the technical computing workers A, B and C invoke an interface function call (MPI_Finalize) for disconnecting the communication channel with the other technical computing workers A, B and C in the collaboration (step ). The technical computing workers A, B and C close the MPI shared library (step ). When the communication channel  between the technical computing workers A, B and C is disconnected, the technical computing workers A, B and C are idle (steps -) and independent of the collaboration  and can join a new collaboration at any time.","The illustrative embodiment may provide user APIs that enable a user to launch technical computing workers by specifying additional command-line flags. The first command-line flag may be \u201c-numlabs\u201d which a user can define in order to indicate the desired total number of technical computing workers to be launched. In this case, the user executes a command line as follows.","matlab-numlabs 3",{"@attributes":{"id":"p-0098","num":"0103"},"figref":["FIG. 8","FIG. 6"],"b":["801","802","804","805","803","804","805","806","804","805","808","809","807","810","111"]},"The second command-line flag may be \u201c-ParallelConfig\u201d which allows a user to specify a particular configuration to be used when launching technical computing workers. In this case, the user executes a command line as follows.","matlab-ParallelConfig myConfig",{"@attributes":{"id":"p-0101","num":"0106"},"figref":"FIG. 9","b":["901","902","903","904","905","906","907","908","906","907","909"]},"Although \u201cmpiexec\u201d is specified as the scheduler to launch the additional workers  and  in the illustrative embodiment, the additional technical computing workers  and  may be launched using any scheduler known to the technical computing client. In the case where the technical computing client uses \u201cmpiexec\u201d to launch the additional technical computing workers, these additional technical computing workers may automatically form a collaboration  amongst themselves. However, the call to iClientConn may still allow them to connect together with the first technical computing worker to form an overall collaboration. The operations of the other steps  and  are the same as described above with reference to .","The illustrative embodiment may also provide additional user APIs that enables a user to use a different size of collaborations so that the technical computing workers all leave the parallel collaboration, as shown in . In this case, the user may execute a command line as follows:","startParallelSession(\u2018numlabs\u2019, 3); or","startParallelSession(\u2018ParallelConfig\u2019, \u2018myConfig\u2019).","With the execution of this command line, the technical computing workers may exit the collaboration if they are no longer required. In some instances, such as when a technical computing worker is attached to a job manager, the worker may not leave the collaboration. The user may then continue to re-launch technical computing workers with a different effective \u201c-numlabs\u201d or \u201c-ParallelConfig\u201d setting.","Many alterations and modifications may be made by those having ordinary skill in the art without departing from the spirit and scope of the invention. Therefore, it must be expressly understood that the illustrated embodiments have been shown only for the purposes of example and should not be taken as limiting the invention, which is defined by the following claims. These claims are to be read as including what they set forth literally and also those equivalent elements which are insubstantially different, even though not identical in other respects to what is shown and described in the above illustrations."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing and other objects, aspects, features, and advantages of the invention will become more apparent and may be better understood by referring to the following description taken in conjunction with the accompanying drawings, in which:",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
