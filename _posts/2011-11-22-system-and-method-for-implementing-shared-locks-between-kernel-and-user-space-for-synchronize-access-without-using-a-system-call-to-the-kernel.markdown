---
title: System and method for implementing shared locks between kernel and user space for synchronize access without using a system call to the kernel
abstract: An apparatus comprising one or more processors configured to implement a plurality of operations for an operating system (OS) platform including a kernel and a user application, one or more shared resource blocks by the kernel and the user application, and one or more shared locks by the kernel and the user application corresponding to the shared resource blocks, wherein the user application is configured to synchronize accesses to the shared resource blocks between a user thread and a kernel thread by directly accessing the locks without using a system call to the kernel.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09128786&OS=09128786&RS=09128786
owner: Futurewei Technologies, Inc.
number: 09128786
owner_city: Plano
owner_country: US
publication_date: 20111122
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","STATEMENT REGARDING FEDERALLY SPONSORED RESEARCH OR DEVELOPMENT","REFERENCE TO A MICROFICHE APPENDIX","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Not applicable.","Not applicable.","Not applicable.","Some current Operating System (OS) platforms, such as used in computation devices and network components, allow sharing computing\/networking resources (e.g., memory, processor usage, bandwidth, etc.) between a kernel space and a user space. The kernel corresponds to a component of the OS that bridges between applications (software) and the actual data processing implemented at the hardware level. The kernel's responsibilities include managing the system's resources, such as communications between hardware and software components. Typically, the kernel provides the lowest-level abstraction layer for the resources (e.g., for processors and input\/output (I\/O) devices), which the application software needs to control to perform its function. The kernel typically makes these resources available to application processes through inter-process communication mechanisms and system calls. The kernel space comprises the tasks, operations, and associated resources used by the kernel. The user space comprises the tasks, operations, and associated resources used by the application or software.","In one embodiment, the disclosure includes an apparatus comprising one or more processors configured to implement a plurality of operations for an operating system (OS) platform including a kernel and a user application, one or more shared resource blocks by the kernel and the user application, and one or more shared locks by the kernel and the user application corresponding to the shared resource blocks, wherein the user application is configured to synchronize accesses to the shared resource blocks between a user thread and a kernel thread by directly accessing the locks without using a system call to the kernel.","In another embodiment, the disclosure includes a shared memory block, and a network component comprising a processor for an OS platform configured to receive a request from a first OS thread that operates on the processor to access the shared memory block for a plurality of OS threads, and to allow the first OS thread to lock and access the shared memory block if the shared memory block is not locked by a second OS thread or if a time limit for a lock by the second OS thread is expired.","In a third aspect, the disclosure includes a method implemented by a processor that implements an OS platform including a plurality of threads including application threads and kernel threads, comprising setting a lock for a target memory block by a first thread the lock is not set by another thread, receiving from an OS kernel by the first thread information about allowed operations and time limit for the lock, accessing by the first thread a map of the target memory block, and releasing by the first thread the lock on the target memory block if a terminate call is received by the first thread from a higher priority thread or if operations on the target memory block by the first thread are completed.","These and other features will be more clearly understood from the following detailed description taken in conjunction with the accompanying drawings and claims.","It should be understood at the outset that although an illustrative implementation of one or more embodiments are provided below, the disclosed systems and\/or methods may be implemented using any number of techniques, whether currently known or in existence. The disclosure should in no way be limited to the illustrative implementations, drawings, and techniques illustrated below, including the exemplary designs and implementations illustrated and described herein, but may be modified within the scope of the appended claims along with their full scope of equivalents.","In typical OS platforms, resources are shared between the user space and the kernel space using locks. The locks are implemented in the kernel space to guard or reserve resources for the kernel and prevent the user space from accessing the locked resources. If a resource is not locked (e.g., by the kernel), then the user space can access that resource. To lock resources, the user thread sends lock operation requests using system calls. This lock scheme could result in bottlenecks, e.g., for relatively large quantities of lock operation requests and system calls, which can be detrimental to high performance systems.","Real time system such as router OS platforms may require relatively high performance infrastructure support and relatively high system overhead. When performance is critical, e.g., in a zero-copy socket, the system buffers may not be copied from and to the kernel. Instead, the buffers may be shared between the user space and the kernel space. In this case, improving the lock mechanism for the shared resource (e.g., buffer or memory) may substantially improve system performance. Disclosed herein is a system and method for managing and handling kernel-user shared locks to improve memory or resource sharing and protection between the user space and the kernel space. The kernel-user shared locks may be managed and operated to reduce communications cost between the user space and the kernel space and boost system performance. Unlike typical schemes that are based on using system calls provided by the kernel, the disclosed system and method may allow user applications (user space) to directly set the kernel-user shared locks to access blocks of memory (or similar resources) that are shared between the user space and the kernel space. The kernel-user shared locks may allow user applications to directly lock and unlock the shared locks without system calls to synchronize the accesses to blocks of shared memory between the user space and kernel space. The details of implementing the kernel-user shared locks are described in detail below.",{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1","b":["100","100"]},"The kernel-user shared locks system  may comprise a kernel-user shared memory or memory block , which may be accessed by a kernel producer thread , a kernel consumer thread , a user producer thread , and a user consumer thread . The kernel-user shared memory  may comprise a send buffer , a receive block , a first lock (Lock1) control block  associated with the send buffer , and a second lock (Lock2) control block  associated with the receive buffer . The kernel producer thread  may be part of the kernel space that is configured to access the receive buffer  to place data. The user consumer thread  may be part of the user space (or application) that is configured to access the receive buffer  to receive the placed data. The user producer thread  may be part of the user space that is configured to access the send buffer  to place data. The kernel consumer thread  may be part of the kernel space that is configured to access the send buffer  to obtain the placed data.","The kernel producer thread  and the user consumer thread  may check the Lock2 control block  before attempting to access the receive buffer . If the Lock2 control block  is not locked or a lock time for the Lock2 control block  is expired, then the kernel producer thread  or the user consumer thread  may lock the Lock2 control block  and then access the receive buffer . Similarly, the user producer thread  and the kernel consumer thread  may check the Lock1 control block  before attempting to access the send buffer . If the Lock1 control block  is not locked or a lock time for the Lock1 control block  is expired, then the user producer thread  or the kernel consumer thread  may lock the Lock1 control block  and then access the send buffer . For instance, the Lock1 control block  and the Lock2 control block  may be memory components that comprise data structures, such as flags, that may be set to place a lock or unset to remove the lock.","The kernel-user shared lock system  may be advantageous in protecting data structures that behave in a producer-consumer fashion. The content of a kernel socket buffer may be typically copied from or to user memory space. If the buffers are shared between user space and kernel space, the shared locks may be used to protect the shared data structures. A user thread or process may correspond to the user producer thread  on the send buffer  or the user consumer thread  on the receive buffer . A kernel thread may correspond to the kernel producer thread  on the receive buffer  or the kernel consumer thread  on the send buffer . A user thread may hold the shared lock for a maximum period of time, which may be determined at the lock creation and may run to completion until the lock is released. The user thread's priority may vary according to priority inheritance (hierarchy) settings.","A user space application programming interface (API) (or code) may be used (e.g., by the user producer thread  or the user consumer thread ) to initialize a lock (e.g., for the Lock1 control block  or the Lock2 control block ). During the initialization, a portion of the kernel-user shared memory  (e.g., the send buffer  or the receive buffer ) may be created and mapped into user memory space. When the lock is initialized, the user application (e.g., the user producer thread  or the user consumer thread ) may get a contract from the kernel specifying the operations that the application can perform on the lock and\/or how long the application can hold the lock. If the lock is held longer than the specified time limit, the user process may be killed by the kernel (e.g., by the kernel consumer thread  or the kernel producer thread ).","When the user applications or the kernel try to acquire or release the lock, the acquire\/release operation may be done directly without invoking a system call, unlike typical shared lock schemes. When a user application holds a lock, the user application may run to completion until the lock is released, but the user application may still be subject to preemption if the system allows it. For instance, the kernel may kill the user application and release the lock at any time if needed. The different threads (kernel and user threads) may be categorized so that some categories of threads (e.g., kernel threads) have higher precedence in acquiring the lock than other categories of threads (e.g., user threads). Priority inversion may be addressed by priority inheritance settings, which may allow, for example, the priority of a user thread to be as high as that of a kernel thread. Priority inversion is a problematic scenario in scheduling when a higher priority task is indirectly preempted by a lower priority task effectively \u201cinverting\u201d the relative priorities of the two tasks. This violates the priority model that high priority tasks can only be prevented from running by higher priority tasks and briefly by low priority tasks which will quickly complete their use of a resource shared by the high and low priority tasks.",{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 2","b":["200","100","200","106","108","200","210","106","122","112","108","124","114","210","200","210","200","220"]},"At block , a lock may be set for the target memory block. The user thread may set the lock when the lock is not set, e.g., by another user thread or the kernel, on the target memory block. At block , information about allowed operations and\/or time limit for the lock may be received from the kernel. The user thread may receive such data from the kernel, and may set a timer accordingly for accessing and operating on the target memory block. At block , the target memory block may be accessed. The user thread may map the target memory block to the user space and then access the mapped memory data, e.g., to perform a read operation, write operation, or other types of operations.","At block , the user thread may determine whether a terminate call has been received or the operation on the target memory block been completed. If the user thread receives a kill or terminate call from the kernel or from any thread that has higher priority than the user thread, or if the user thread operation is completed, then the method  may proceed to block . Otherwise, the method  may return to block  and continue accessing and operating on the target memory block until the condition in block  becomes true. At block , the lock on the target memory block may be released. Thus, the user thread may not have anymore access to the shared memory block and may terminate or halt operation. The method  may then end.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 3","b":["300","100","300","102","104","300","310","102","124","114","104","122","112","310","300","330","300","320"]},"At block , the kernel thread may determine whether a time limit for the lock has expired. If the condition in block  is true, then the method  may proceed to block . Otherwise, the method  may return to block  (i.e., begin again) to verify after some time if the lock is still set. At block , the lock on the target memory block may be terminated, e.g., by the kernel thread. At block , a lock may be set for the target memory block, e.g., by the kernel thread. At block , the target memory block may be accessed, e.g., by the kernel thread to perform a write operation, read operation, or other types of operations. At block , the kernel thread may determine whether the operation on the target memory block is completed. If the kernel thread operation is completed, then the method  may proceed to block . Otherwise, the method  may return to block  and continue accessing and operating on the target memory block until the condition in block  becomes true. At block , the lock on the target memory block may be released. Thus, the target memory block may become available to other threads. The method  may then end.","In some embodiments, a higher priority (user) thread may implement similar steps as in the method  to lock\/access a target memory block that may be shared with a lower (user) thread. For instance, the higher thread may terminate the lock of the lower thread and then lock and access the target memory block. The higher thread may then release the lock when the thread operation is completed. A lower thread may not have the right to terminate a lock set by a higher thread, but may wait until the lock is terminated by the operating thread. The kernel may have the highest priority to terminate locks and accessing shared memory blocks. Further, different kernel threads and\/or user threads may be assigned different priorities. The locking\/termination mechanisms in the methods  and  may be implemented without the need to send or initiate system calls in the kernel.",{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 4","b":["400","400","400","410","412","400","420","412","420","440","420","200","300","420","400","430","432"]},"The components and\/or methods described above may be implemented on any general-purpose network component, such as a computer or network component with sufficient processing power, memory resources, and network throughput capability to handle the necessary workload placed upon it.  illustrates a typical, general-purpose network component  suitable for implementing one or more embodiments of the components disclosed herein. The network component  includes a processor  (which may be referred to as a central processor unit or CPU) that is in communication with memory devices including secondary storage , read only memory (ROM) , random access memory (RAM) , input\/output (I\/O) devices , and network connectivity devices . The processor  may be implemented as one or more CPU chips, or may be part of one or more application specific integrated circuits (ASICs).","The secondary storage  is typically comprised of one or more disk drives or tape drives and is used for non-volatile storage of data and as an over-flow data storage device if RAM  is not large enough to hold all working data. Secondary storage  may be used to store programs that are loaded into RAM  when such programs are selected for execution. The ROM  is used to store instructions and perhaps data that are read during program execution. ROM  is a non-volatile memory device that typically has a small memory capacity relative to the larger memory capacity of secondary storage . The RAM  is used to store volatile data and perhaps to store instructions. Access to both ROM  and RAM  is typically faster than to secondary storage .","At least one embodiment is disclosed and variations, combinations, and\/or modifications of the embodiment(s) and\/or features of the embodiment(s) made by a person having ordinary skill in the art are within the scope of the disclosure. Alternative embodiments that result from combining, integrating, and\/or omitting features of the embodiment(s) are also within the scope of the disclosure. Where numerical ranges or limitations are expressly stated, such express ranges or limitations should be understood to include iterative ranges or limitations of like magnitude falling within the expressly stated ranges or limitations (e.g., from about 1 to about 10 includes, 2, 3, 4, etc.; greater than 0.10 includes 0.11, 0.12, 0.13, etc.). For example, whenever a numerical range with a lower limit, R, and an upper limit, R, is disclosed, any number falling within the range is specifically disclosed. In particular, the following numbers within the range are specifically disclosed: R=R+k*(R\u2212R), wherein k is a variable ranging from 1 percent to 100 percent with a 1 percent increment, i.e., k is 1 percent, 2 percent, 3 percent, 4 percent, 7 percent, . . . , 70 percent, 71 percent, 72 percent, . . . , 97 percent, 96 percent, 97 percent, 98 percent, 99 percent, or 100 percent. Moreover, any numerical range defined by two R numbers as defined in the above is also specifically disclosed. Use of the term \u201coptionally\u201d with respect to any element of a claim means that the element is required, or alternatively, the element is not required, both alternatives being within the scope of the claim. Use of broader terms such as comprises, includes, and having should be understood to provide support for narrower terms such as consisting of, consisting essentially of, and comprised substantially of. Accordingly, the scope of protection is not limited by the description set out above but is defined by the claims that follow, that scope including all equivalents of the subject matter of the claims. Each and every claim is incorporated as further disclosure into the specification and the claims are embodiment(s) of the present disclosure. The discussion of a reference in the disclosure is not an admission that it is prior art, especially any reference that has a publication date after the priority date of this application. The disclosure of all patents, patent applications, and publications cited in the disclosure are hereby incorporated by reference, to the extent that they provide exemplary, procedural, or other details supplementary to the disclosure.","While several embodiments have been provided in the present disclosure, it should be understood that the disclosed systems and methods might be embodied in many other specific forms without departing from the spirit or scope of the present disclosure. The present examples are to be considered as illustrative and not restrictive, and the intention is not to be limited to the details given herein. For example, the various elements or components may be combined or integrated in another system or certain features may be omitted, or not implemented.","In addition, techniques, systems, subsystems, and methods described and illustrated in the various embodiments as discrete or separate may be combined or integrated with other systems, modules, techniques, or methods without departing from the scope of the present disclosure. Other items shown or discussed as coupled or directly coupled or communicating with each other may be indirectly coupled or communicating through some interface, device, or intermediate component whether electrically, mechanically, or otherwise. Other examples of changes, substitutions, and alterations are ascertainable by one skilled in the art and could be made without departing from the spirit and scope disclosed herein."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["For a more complete understanding of this disclosure, reference is now made to the following brief description, taken in connection with the accompanying drawings and detailed description, wherein like reference numerals represent like parts.",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
