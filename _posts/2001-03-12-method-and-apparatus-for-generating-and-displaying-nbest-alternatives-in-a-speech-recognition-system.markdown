---
title: Method and apparatus for generating and displaying N-best alternatives in a speech recognition system
abstract: The present invention is directed to a method and apparatus for generating alternatives to words indicative of recognized speech. A reference path of recognized words is generated, based upon input speech data. An operator selection input is received and is indicative of a selected portion of the recognized speech, for which alternatives are to be generated. Boundary conditions for alternatives to be generated are calculated based upon bounds of a reference subpath corresponding to the selected portion of the recognized speech. Alternate subpaths satisfying the boundary conditions are constructed from a hypothesis store which corresponds to the input speech data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06856956&OS=06856956&RS=06856956
owner: Microsoft Corporation
number: 06856956
owner_city: Redmond
owner_country: US
publication_date: 20010312
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["The present application is based on and claims the benefit of U.S. provisional patent application Ser. No. 60\/219,861, filed Jul. 20, 2000, now abandoned, the content of which is hereby incorporated by reference in its entirety.","The present invention deals with speech recognition engines. More specifically, the present invention deals with providing a user with alternatives to the speech recognition output provided by the engine.","Speech recognition engines receive speech data indicative of words spoken by a user. The speech data is provided to a decoder for recognition. The decoder accesses a plurality of models, such as acoustic models and language models, and identifies a word, or a sequence of words, from the speech data input to the engine.","However, even the most advanced real-time continuous speech recognition engines currently available can not correctly determine 100% of what a speaker has uttered. Therefore, it is not uncommon for a user to wish to change or correct a recognition result provided by an engine. Instead of forcing the speaker to re-utter the mis-recognized phrase, it is often more efficient to provide the speaker with additional possible interpretations of the utterance, since there is a reasonable chance that what the user actually said was one of the alternate interpretations provided by the decoder.","In the past, when the user highlighted recognized text to be corrected (or otherwise indicated a portion of the recognized text which needed to be changed), the engine provided a number of alternate suggestions to the user. However, these alternate suggestions were not always the best suggestions, based upon scores generated by the speech recognition engine. Instead, the alternatives provided were often simply a fixed, predetermined number, of alternatives that the engine was required to provide to the application. Such alternatives did not utilize information that hie engine held regarding the acoustic confidence and probabilities of word combinations.","Similarly, in prior engines, if a document was dictated, for example, by the user, and was saved for later editing, it was very cumbersome for all of the alternatives to be maintained such that they could be displayed to the user at a later time. Further, in order to present the best alternatives to the user, it is necessary for scores to be computed which correspond to the alternatives. Therefore, it would have been very cumbersome with prior systems to attempt to calculate scores for all possible alternatives, such that those alternatives and scores could be saved, and so that the user could retrieve them during a later editing process. In fact, the complexity of this problem, as measured by the number of potential candidates for the N-Best alternatives, increases exponentially as the duration of time for which alternates are computed increases.","The present invention is directed to a method and apparatus for generating alternatives to words indicative of recognized speech. A reference path of recognized words is generated, based upon input speech data. An operator selection input is received and is indicative of a selected portion of the recognized speech, for which alternatives are to be generated. Boundary conditions for alternatives to be generated are calculated based upon bounds of a reference subpath corresponding to the selected portion of the recognized speech. Alternate subpaths satisfying the boundary conditions are constructed from a hypothesis store which corresponds to the input speech data.","In one embodiment, the boundary conditions are calculated by identifying beginning and ending boundary conditions which correspond, respectively, to a beginning time in the reference path of a first boundary word that precedes the selected portion of the recognized speech and an ending time in the reference path of a second boundary word that follows the selected portion of the recognized speech. Also, in one embodiment, the hypothesis store is a lattice indicative of entries for a plurality of alternate words corresponding to utterances in the input speech data. Each entry illustratively includes a lexical word, a beginning time in the input speech data corresponding to the lexical word and an ending time in the speech data corresponding to the lexical word. The alternate subpaths are constructed by first obtaining from the hypothesis lattice instances of the first boundary word that satisfy the beginning boundary condition. The alternative subpaths are further constructed by concatenating to each of the instances of the first boundary word a string of one or more additional words, wherein the string of additional words satisfy the ending boundary condition.","In accordance with one embodiment, up to a predetermined number X of hypothesis alternative subpaths are constructed. They are called \u201chypothesis\u201d alternative subpaths because it is not yet known whether they will indeed be the alternate subpaths actually maintained. Each of those subpaths is assigned a score which is updated as the hypothesis alternative subpath is constructed. Only the hypothesis alternate subpaths having the top X scores are maintained. In one embodiment, the subpaths are represented by entries in priority queues which are sorted based on score such that only a portion of the subpaths contained in the priority queues are presented to the user. As the subpaths are constructed, their scores are continuously updated and sorted such that the engine is never considering more than a predetermined maximum number of subpaths.","In accordance with another embodiment, the hypothesis lattice is stored along with the application for which the speech recognition is being performed. Then, when a user Later provides a user selection input indicative of a portion of the reference speech path to be corrected, the hypothesis lattice is retrieved and the engine constructs alternative subpaths to replace portions of the referenced speech path based on the entries in the hypothesis lattice.","FIG.  and the related discussion are intended to provide a brief, general description of a suitable computing environment in which the invention may be implemented. Although not required, the invention will be described, at least in part, in the general context of computer-executable instructions, such as program modules, being executed by a personal computer. Generally, program modules include routine programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. Moreover, those skilled in the art will appreciate that the invention may be practiced with other computer system configurations, including hand-held devices, multiprocessor systems, microprocessor-based or programmable consumer electronics, network PCs, minicomputers, mainframe computers, and the like. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote memory storage devices.","With reference to , an exemplary system for implementing the invention includes a general purpose computing device in the form of a conventional personal computer , including a processing unit (CPU) , a system memory , and a system bus  that couples various system components including the system memory  to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. The system memory  includes read only memory (ROM)  and random access memory (RAM) . A basic input\/output (BIOS) , containing the basic routine that helps to transfer information between elements within the personal computer , such as during start-up, is stored in ROM . The personal computer  further includes a hard disk drive  for reading from and writing to a hard disk (not shown), a magnetic disk drive  for reading from or writing to removable magnetic disk , and an optical disk drive  for reading from or writing to a removable optical disk  such as a CD ROM or other optical media. The hard disk drive , magnetic disk drive , and optical disk drive  are connected to the system bus  by a hard disk drive interface , magnetic disk drive interface , and an optical drive interface , respectively. The drives and the associated computer-readable media provide nonvolatile storage of computer readable instructions, data structures, program modules and other data for the personal computer .","Although the exemplary environment described herein employs the hard disk, the removable magnetic disk  and the removable optical disk , it should be appreciated by those skilled in the art that other types of computer readable media which can store data that is accessible by a computer, such as magnetic cassettes, flash memory cards, digital video disks, Bernoulli cartridges, random access memories (RAMs) read only memory (ROM), and the like, may also be used in the exemplary operating environment.","A number of program modules may be stored on the hard disk, magnetic disk , optical disk , ROM  or RAM , including an operating system , one or more application programs , other program modules , and program data . A user may enter commands and information into the personal computer  through local input devices such as a keyboard , pointing device  and a microphone . Other input devices (not shown) may include a joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a serial port interface  that is coupled to the system bus , but may be connected by other interfaces, such as a sound card, a parallel port, a game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video adapter . In addition to the monitor , personal computers may typically include other peripheral output devices, such as a speaker  and printers (not shown).","The personal computer  may operate in a networked environment using logic connections to one or more remote computers, such as a remote computer . The remote computer  may be another personal computer, a hand-held device, a server, a router, a network PC, a peer device or other network node, and typically includes many or all of the elements described above relative to the personal computer , although only a memory storage device  has been illustrated in FIG. . The logic connections depicted in  include a local area network (LAN)  and a wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer network Intranets, and the Internet.","When used in a LAN networking environment, the personal computer  is connected to the local area network  through a network interface or adapter . When used in a WAN networking environment, the personal computer  typically includes a modem  or other means for establishing communications over the wide area network , such as the Internet. The modem , which may be internal or external, is connected to the system bus  via the serial port interface . In a network environment, program modules depicted relative to the personal computer , or portions thereof, may be stored in the remote memory storage devices. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used. For example, a wireless communication link may be established between one or more portions of the network.","Although  shows an exemplary environment, the present invention is not limited to a digital-computing environment. In particular, the present invention can be operated on analog devices or mixed signal (analog and digital) devices. Furthermore, the present invention can be implemented on a single integrated circuit, for example, in small vocabulary implementations.",{"@attributes":{"id":"P-00027","num":"00027"},"figref":["FIG. 2","FIG. 1","FIG. 2"],"b":["100","102","102"]},"The digital data is provided to a feature extractor  in speech recognition (SR) engine . Feature extractor  extracts a feature  from the digital signal. Some examples of feature extraction modules include modules for performing Linear Predictive Coding (LPC), LPC derived cepstrum, Perceptive Linear Prediction (PLP), Auditory model feature extraction, and Mel-Frequency Cepstrum Coefficients (MFCC) feature extraction. Note that the invention is not limited to these feature extraction modules and that other modules may be used within the context of the present invention.","The feature extraction module  receives the stream of digital values and produces a stream of feature vectors  that are each associated with a frame of the input signal. In many speech embodiments, the frames are 20 milliseconds in length and the centers of the frames are separated by 10 milliseconds, although this is mentioned for exemplary purposes only.","The stream of feature vectors  produced by the extraction module  is provided to a decoder , which accesses lexicon , language model , and acoustic model  and identifies a most likely sequence of patterns based on the stream of feature vectors.","In one illustrative embodiment, acoustic model  is based on a Hidden Markov Model consisting of a set of states, with each frame of the input matched to one frame of the input signal. Each state has an associated set of probability distributions that describe the likelihood of an input feature vector matching a particular state. The model also includes probabilities for transitioning between two neighboring model states as well as allowed transitions between states for particular pattern units. The size of the pattern units can be different for different embodiments of the present invention. For example, for speech recognition embodiments where the pattern units are linguistic units, the pattern units may be senones, phonemes, diphones, triphones, syllables, or even whole words.","Lexicon  illustratively consists of a list of words or labels that identify the patterns to be recognized. Such a lexicon may comprise linguistic words or syllables.","Language model  provides a set of likelihoods that a particular pattern or sequence of patterns will appear in the environment of interest. For example, language model  provides a set of likelihoods that a particular word or sequence of words will appear in a particular language. In one illustrative speech embodiment, the language model is based on a text database such as the North American Business News (NAB), which is described in greater detail in a publication entitled CSR-III Text Language Model, University of Penn., 1994. The language model may be a context-free grammar or a statistical n-gram model such as a trigram. In one embodiment, the language model is a compact trigram model that determines the probability of a sequence of patterns based on the combined probabilities of three-pattern segments of the sequence. For example, the trigram model is based on the combined probabilities of three-word segments.","The language model  may also provide a statistical probability of any sequence of letters. In one illustrative embodiment, a letter trigram language model is used which provides the probability of any three-letter sequence. However, any other letter language model which provides a statistical estimate of the letter probability can be used, or such a model can be omitted.","In performing speech recognition, based on the acoustic model, the language models, and the lexicon, decoder  identifies a most likely sequence of patterns from all possible pattern sequences. The most likely sequence of patterns or words is referred to herein as the reference paths. Decoder  also identifies a plurality of hypothesis patterns that are less likely sequences, but may also be the correct recognized speech.","The reference path and the other most probable sequences of patterns (the other hypotheses) can be provided as a result lattice  to an optional confidence measure module. The confidence measure module identifies which patterns are most likely to have been improperly identified by the recognizer. The confidence measure module then provides, at its output, the sequences of hypothesis patterns along with identifiers indicating which patterns may have been improperly identified. Those skilled in the art will recognize that such a confidence measure module is riot necessary for the practice of the present invention.","In any case, a reference path and a result lattice (or hypothesis lattice)  are eventually provided to speech application programming interfaces (SAPI)  which provides the result lattice in a desired format, to application program . The result lattice illustratively includes entries which have a lexical word, a beginning time and ending time in the recognized speech for that lexical word and the acoustic score for that lexical word. An example to such a lattice is discussed in greater detail below. In one illustrative embodiment, application program  is a word processing or dictation program for generating a document.","User interface  includes an optional display  (such as a monitor) to display the words as they are spoken. User interface  also includes other user input devices which can be used to provide signals to the remainder of the speech recognition system, either directly, or through SAPI . As will be discussed below, such input signals configure the speech recognition system to generate alternatives to selected portions of the reference path.",{"@attributes":{"id":"P-00039","num":"00039"},"figref":"FIG. 2","b":["103","124","124","101","120","124","124","117","116","110","124"]},"By N-Best, it is meant an integer number N of the best alternatives to the selected text, as indicated by an N-Best score computed for the various alternatives represented in hypothesis lattice . Generator  provides the N-Best alternatives  to the user, or application , through SAPI . The user then may select one of the N-Best alternatives , such as through a point and click device or other user input mechanism. It should be noted that the user may also choose to have the system enter another mode of operation, such as to allow the user to re-utter the phrase.","In addition, it should be noted that the reference path , along with the hypothesis lattice , can be provided to application , and stored therewith for later editing. In that case, when the user wishes to edit the recognized speech, the user simply re-launches application . This causes application  to reinitialize the hypothesis lattice . The reference path is provided to the user and, when the user wishes to correct a portion of the reference path, the user selects or highlights a portion of the reference path as indicated above. In that instance, the hypothesis lattice  is provided back to the N-Best alternative subpath generator  either directly, or through the SAPI component  and decoder . N-Best alternative subpath generator  then simply generates the same N-Best alternatives in the same manner as indicated above. This process is described in greater detail below.",{"@attributes":{"id":"P-00042","num":"00042"},"figref":["FIG. 3A","FIG. 3A"],"b":["124","124","200","202","204","206","208","210","212"]},{"@attributes":{"id":"P-00043","num":"00043"},"figref":"FIG. 3B","b":"210"},{"@attributes":{"id":"P-00044","num":"00044"},"figref":["FIGS. 4A and 4B","FIGS. 4A and 4B","FIGS. 2 and 3A"],"b":["124","106","120","106","105","104","250","4","106","117","116","252","117","116","120","101","254","120","256"]},"When the user eventually wishes to correct the recognized speech provided by decoder , the user launches application . This is indicated by block . Of course, application  carries with it the recognized speech (including the reference path) and the hypothesis lattice . This is indicated by block  in FIG. A. The reference path (recognized speech) and hypothesis lattice  are again provided to SR engine  so the alternatives can be generated during correction of the recognized speech. This is indicated by block  in FIG. A.","It should be noted that storing and re-launching application  is purely optional. If the user wishes to edit the recognized speech immediately, the user certainly need not store application .  simply includes those steps to indicate that, in an illustrative embodiment, the hypothesis lattice is stored along with the application  such that it can be retrieved when the application is re-launched and the user wishes to edit the recognized speech.","In any case, once the user decides to edit the recognized speech, the user provides a user input to SR engine  indicative of user selected text to be corrected. As discussed with respect to , this user input can simply be formed by the user highlighting text or a phrase to be corrected using a point and click device, using voice commands, using a computer keyboard, or using any other suitable user input device which provides an indication of text or recognized speech to be corrected. This is indicated by block  in FIG. B.",{"@attributes":{"id":"P-00048","num":"00048"},"figref":"FIG. 3A","b":["202","124","117","200"]},"For purposes of illustration, assume that the user or speaker has uttered the phrase \u201cone to three\u201d, but the SR engine  has mis-recognized this utterance as \u201cone two three\u201d. In this case, a hypothesis lattice  may look like the following (bearing in mind that an actual hypothesis lattice would have far more word hypotheses, and this illustration has been simplified for purposes of illustration only):",{"@attributes":{"id":"P-d0e2467","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"49pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}},{"entry":[{},{},{},{},"Acoustic"]},{"entry":["#","Lexical Word","Start Time","End Time","Score"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"49pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","One","0","1000","100"]},{"entry":["2","One","0","1200","\u200280"]},{"entry":["3","Won","0","1000","\u200250"]},{"entry":["4","To","1000","2000","100"]},{"entry":["5","Too","1000","2000","\u200250"]},{"entry":["6","Two","1000","2000","140"]},{"entry":["7","Two","1000","2000","\u200280"]},{"entry":["8","To","1200","2000","140"]},{"entry":["9","Three","2000","3000","100"]},{"entry":["10\u2002","Tree","2000","3000","\u200260"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"It can be seen that the hypothesis lattice includes, in the left most column a hypothesis indicator number, and following that, the lexical word which has been hypothesized along with a starting time the word recognition began, an ending time that the word recognition ended, and an acoustic score from acoustic model  indicative of the acoustic score associated with that particular recognition result. For purposes of this example, assume that the original cognition (or reference path) output by engine  responds to the hypothesis path number 1-6-9 with a total acoustic score of 340. This sequence of word hypotheses will be referred to as the \u201cbest path\u201d or \u201creference path\u201d.","The next best original recognition corresponds to the path represented by hypotheses 2-8-9, with a total acoustic score of 320. It should be noted that path 1-4-9 will also result in the word sequence \u201cone to three\u201d but has a lower acoustic score of 300.","The hypothesis lattice having been computed, along with the best path or reference path, the user is provided with the reference path as being indicative of recognized speech. Once the user receives a display of the reference path, the user will ask for alternates for the second word, since it was mis-recognized. This is received by path extender  in generator . In response, boundary locator  determines appropriate end points for an alternative path through the hypothesis lattice illustrated in Table 1. In doing so, boundary locator  first finds beginning boundary conditions as illustrated in block  in FIG. B and then finds ending boundary conditions as illustrated in block  in FIG. B.","The beginning and ending boundary conditions define words in the hypothesis lattice which can be used as alternates to the word or phrase selected by the user. Thus, these boundary conditions are effectively used to filter the hypothesis lattice for various combinations of words in the hypothesis lattice which can be presented to the user as the N-Best alternatives for the highlighted text.","Path extender  then utilizes score computation component , queues  and  and CARC array  to construct the alternate subpaths (as alternatives for the portion of the reference path highlighted by the user) by concatenating words in the hypothesis lattice  so that the entire concatenation satisfies the beginning and ending boundary conditions. This is indicated by block  in FIG. B and is described in greater detail in .","Once the alternative subpaths have been constructed, they are ranked by score. This is indicated by block  in FIG. B. The top-N subpaths are presented to the user. This is indicated by block . In performing this step, output component  obtains the top-N alternatives and provides them, for example, through SAPI component , to the user interface or application (or to the user interface through the application).",{"@attributes":{"id":"P-00056","num":"00056"},"figref":"FIG. 5","b":["200","116"]},"That being the case, boundary locator  finds, in the hypothesis lattice the particular instance of the word preceding the user-selected text in the reference path. For example, since the reference path which was provided to the user included hypothesis 6 which was preceded by hypothesis 1, the lexical word \u201cone\u201d in hypothesis 1 is located in the hypothesis lattice. The beginning time (which happens to be start time 0) of that instance of the word in the hypothesis lattice is noted as the beginning boundary time. Locating the particular instance of the word preceding the highlighted text and its beginning time are indicated by blocks  and  in FIG. .","Since the user did not highlight (or select) the word \u201cone\u201d in the reference path that word must be correct. Therefore, boundary locator  identifies the boundary conditions such that the first word in the alternative phrase must start with the lexical word \u201cone\u201d. Boundary locator  also sets as one of the beginning boundary conditions that any instance of the word \u201cone\u201d must have the same start time or beginning time as the particular instance of the word \u201cone\u201d which was provided in the reference path (e.g., starting time 0). Therefore, in the result lattice indicated in Table 1, both instances of the lexical word \u201cone\u201d (i.e., hypotheses 1 and 2) satisfy the beginning boundary conditions since they are both the lexical word \u201cone\u201d and since they both start at time 0. Setting the beginning boundary conditions is indicated by block  in FIG. .",{"@attributes":{"id":"P-00059","num":"00059"},"figref":"FIG. 6","b":["200","268","4","200","284","6"]},"The ending time of this instance of the word following the highlighted text is noted as the ending boundary time. This is indicated by block . Since the ending time of hypothesis number 8 is 3000, one of the ending boundary conditions for all alternatives presented to the user requires that the alternative path end at the time 3000.","Boundary locator  then sets the ending boundary conditions to include that the last word in every alternative subpath must be the lexical word \u201cthree\u201d and it must have an ending time of 3000. These constitute the ending boundary conditions. This is indicated by block  in FIG. .",{"@attributes":{"id":"P-00062","num":"00062"},"figref":"FIGS. 7A and 7B","b":["202","116","202"]},"In any case, path expander  searches through hypotheses lattice  for words which satisfy the beginning boundary conditions. In doing this, path expander  will first come across hypothesis 1 in hypothesis lattice . Since this was the beginning of the reference path actually provided to the user, this will of course satisfy the boundary conditions. Selecting from the hypothesis lattice an instance of a beginning word that satisfies the beginning boundary conditions is indicated by block  in FIG. A.","A score is computed for this hypothesis alternate subpath as indicated by block . This score can be computed in any number of suitable ways, and one illustrative way is described later with respect to FIG. .","It is then determined whether queue  is full. This is indicated by block . If not, the current hypothesis (corresponding to hypothesis 1 from the hypothesis lattice, in this case) is simply added to queue , along with its score. This is indicated by block . However, if the queue is full of hypotheses, then the queue is sorted by score. This is indicated by block . If the score computed for the current hypothesis (computed at block ) is greater than the lowest score in queue , as determined at block , then the lowest hypothesis in queue  is deleted from queue  as indicated by block , and the current hypothesis is added to queue . If, at block , it is determined that the current score is not greater than the lowest score in queue , then the current hypothesis is simply discarded, as illustrated by block .","CARC array  is an optional data structure used to construct and track extended hypothesis subpaths. Operation of CARC array  is discussed in greater detail below.","Path extender  then determines whether there are additional instances of the beginning word in the hypothesis lattice which must be considered. This is indicated by block . In the present example, there is an additional instance of the beginning word. For example, the second hypothesis in the hypothesis lattice of Table 1 also corresponds to the lexical word \u201cone\u201d. The second hypothesis also has a starting time of 0 in the reference path. Therefore, the second hypothesis in the hypothesis lattice of Table 1 satisfies the beginning boundary conditions. This is determined at block , and a score is computed for the second hypothesis. Since there is currently only one entry in queue , the queue is not full so the second hypothesis, along with its score, is added to queue .","It is then determined whether there are even more instances of the beginning word in the hypothesis lattice which satisfy the beginning boundary conditions and must be considered, at block . Since there are no more instances of the lexical word \u201cone\u201d in the hypothesis lattice which begin at the starting time of 0, the answer at block  is no. At this point, the first queue  illustratively looks as shown in Table 2.",{"@attributes":{"id":"P-d0e3451","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":[{},"End","Acoustic","Language","Estimated","Total"]},{"entry":["Path","Time","Score","Score","Score","Score"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","1000","100","100","400","600"]},{"entry":["2","1200","\u200280","100","360","540"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}}}},"The scores illustrated in Table 2 are computed as shown in greater detail in FIG. . For now, suffice it to say that the scores have an actual component and an estimated component The actual component is the known score, which has been computed for each word in the hypothesis constructed to his point. The actual score is comprised of the actual acoustic score and the actual language model score. The estimated score is an approximation of the score which will be computed for this hypothesis subpath in the future, as the hypothesis subpath is filled out.","It should be noted, at this point, that path extender  illustratively treats queues  and  as sort-on-demand priority queues, which means that they are fixed in size, and that the contents are not sorted until the queue becomes full, or until a sort request has specifically been made. When the queue is full and an item must be added, then the item in the queue with the lowest score is dropped, assuming the new item under analysis has a higher score.","It should also be noted that at this point the hypotheses in queue  starting with hypothesis 1 look to be more promising than those starting with path 2. Therefore, if the priority queue could only hold a single entry, path 2 would be dropped from the queue at this point and would never be discovered as the beginning of the true best alternative path. It is for this reason that the priority queue size is illustratively kept reasonably high. It is believed based on empirical results that a factor of 100 is more than adequate. For example, a queue which maintains 1000 entries to determine the ten best alternatives has more than ample room to substantially ensure that the ten best alternatives will actually be computed and maintained for presentation to the user.","Once all of the hypotheses associated with the beginning word have been identified and placed in queue , other words from hypothesis lattice  are concatenated to those beginning words in order to continue constructing the alternate hypothesis subpaths for presentation to the user.","Therefore, as illustrated in , path extender  selects an entry in the first queue . This is indicated by block  in FIG. B. Path extender  then examines hypothesis lattice  and chooses a next word from the hypothesis lattice that has a starting time which is coincident with the ending time of the preceding word in the entry selected from the queue  and does not violate the ending conditions. This is indicated by block .","For example, at block , path extender  selects the first entry (i.e., the first hypothesis alternative subpath) from the first queue , illustrated in Table 2. Since that hypothesis has an ending time at 1000, the next word in the hypothesis lattice, which is chosen by path extender , must have a beginning time of 1000. In addition, that next word must not violate the ending boundary conditions. It can be seen that hypotheses 4, 5, 6 and 7 will all extend hypothesis 1, since all have a starting time of 1000 and an ending time which does not violate the ending boundary conditions. However, hypotheses 6 and 7 correspond to the lexical word which has been identified by the user as being wrong. Therefore, they are not considered.","Thus, path extender  first chooses hypothesis 4 and concatenates that word to the previous word to extend the selected hypothesis alternate subpath and thus create a new alternate hypothesis. This is indicated by block  in FIG. B.","A score for this new hypothesis is also computed and it is determined whether the score is high enough to be placed in the second queue . Computation of the score is indicated by block  and determining whether that score is sufficient to be placed in the second queue  is indicated by blocks -. For example, if the second queue  is not full, as indicated by block , then the new hypothesis alternate subpath is simply added to the second queue as indicated by block . However, if at block , the second queue is full, then that queue is sorted by score as indicated by block . If the score of the new hypothesis alternate subpath is greater than the lowest score in the second queue , then the hypothesis with the lowest score in the second queue  is deleted as indicated by blocks  and . The new extended subpath is then simply added to queue  as indicated by block . However, if, at block , the score of the new hypothesis subpath is not greater than the lowest score in queue , then the new subpath is discarded as indicated by block .","It is then determined whether the selected hypothesis subpath from the first queue  can be extended using a different next word. This is indicated by block . It can be seen that the first hypothesis can be extended by both hypotheses 4 and 5 in the hypothesis lattice. Therefore, both of those words are concatenated to the word in hypothesis 1 in order to construct hypothesis alternate subpaths.","Those are the only two second words that can be concatenated to the first word corresponding to hypothesis 1 in the hypothesis lattice of table 1. Therefore, processing moves from block  to  where it is determined whether more entries (i.e., hypothesis alternative subpaths) in the first queue need to be extended. In this case, of course, hypothesis 2 in Table 2 must also be extended. Hypothesis 8 from the hypothesis lattice shown in Table 1 can be used to extend hypothesis 2 since hypothesis 2 has an ending time of 1200 and since hypothesis 8 has a beginning time of 1200. Therefore, this extended path is pushed on to the second queue  along with its score. At this point, the second queue  looks as follows:",{"@attributes":{"id":"P-d0e3973","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 3"},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":[{},"End","Acoustic","Language","Estimated","Total"]},{"entry":["Path","Time","Score","Score","Score","Score"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1-4","2000","100 + 100","100 + 120","200","620"]},{"entry":["1-5","2000","100 + 50","100 + 80","200","530"]},{"entry":["2-8","2000","\u200280 + 140","100 + 120","200","640"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}}}},"Since all the paths in queue  have been extended, processing moves to block  where it is determined whether all of the hypothesis alternative subpaths have been fully constructed as far as they can be up to this point. In other words, it is determined whether the entries in queue  (i.e., the hypothesis alternative subpaths) have seen constructed such that they satisfy the ending boundary conditions. If not, this means that additional extensions are possible before the subpaths are fully constructed. Path extender  switches the identities of priority queues  and . This is indicated by block . Processing then reverts to blocks -.","Therefore, path extender  selects an entry from the first queue (now queue ). Path extender  chooses a next word from the hypothesis lattice that has a starting time coincident with the ending time of the preceding word in the hypothesis alternative subpath of the selected entry and does not violate the ending conditions. Therefore, path extender  chooses the hypothesis 1-4 from queue  (represented by Table 3) and looks for additional words in the hypothesis lattice which have a beginning time of 2000 and which do not violate the ending condition. The only word in the hypothesis lattice of the present example which meets these conditions is hypothesis 9 which corresponds to the lexical word \u201cthree\u201d that has a beginning time of 2000 and an ending time of 3000. That hypothesis is thus concatenated to the hypothesis 1-4 from queue , a score is computed for the total hypothesis 1-4-9, and it is placed in queue  (in accordance with block  of , since the second queue, now queue  was not full).","Because this is the only hypothesis from the hypothesis lattice that can be used to extend the hypothesis 1-4 from Table 3, and since there are more entries (i.e., hypothesis alternate subpaths) in queue  to be considered, processing reverts back to block . Therefore, path extender  selects the next entry in the first queue (now queue ) as path 1-5, and determines whether that path can be extended using other words in the hypothesis lattice. Again, the only word from the hypothesis lattice that can be used to extend hypothesis 1-5 is hypothesis 9 since it corresponds to the lexical word \u201cthree\u201d and since it has a beginning time of 2000 and an ending time of 3000. Therefore, the word is concatenated to the hypothesis 1-5 to form the hypothesis 1-5-9, a score is computed for that path, and the hypothesis and its score are placed in queue .","Path extender  then selects the next hypothesis 2-8 from queue  (as indicated in Table 3). The only word from the hypothesis lattice that can be used to extend hypothesis path 2-8 is, again, hypothesis 9, which corresponds to the lexical word \u201cthree\u201d and has a beginning time of 2000 and an ending time of 3000. This hypothesis has a score computed for it and is placed in priority queue .","At this point, all of the hypothesis alternative subpaths from queue  (and illustrated in Table 3) have been considered and extended to their full extent. They can be extended no more, and still satisfy the ending boundary conditions. Therefore processing moves from block  in  to block . Queue  now looks as follows:",{"@attributes":{"id":"P-d0e4406","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"5","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"21pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 4"},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":[{},"End","Acoustic","Language","Estimated","Total"]},{"entry":["Path","Time","Score","Score","Score","Score"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1-4-9","3000","100 + 100 + 100","100 + 120 + 60","0","580"]},{"entry":["1-5-9","3000","100 + 50 + 100","100 + 80 + 60","0","490"]},{"entry":["2-8-9","3000","\u200280 + 140 + 100","100 + 120 + 60","0","600"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}}}},"In block , all paths which satisfy the beginning and ending boundary conditions have been considered, and those associated with the top scores have been retained in priority queues  and .","In accordance with one illustrative embodiment of the present invention, output component  determines whether the number of alternative subpaths in the output queue meet a predetermined minimum number of alternates. For example, if the present invention is required to provide 10 alternative subpaths each time a user selects text in the reference path to be corrected, output component  examines the output queue to determine whether 10 alternatives are contained in the output queue. If not, output component  provides a signal indicative thereof to boundary locator  and path extender . Boundary locator  then expands the boundary conditions such that more alternatives can be computed.","For example, assume that the entire sentence which the user has uttered is \u201cShe examined references one to three in the bibliography.\u201d In this example, the word \u201cto\u201d was incorrectly recognized as \u201ctwo\u201d. The user has thus only highlighted the word \u201ctwo\u201d for correction. Therefore, in accordance with a first illustrative embodiment of the present invention, the boundary conditions are set based only on a single preceding word and a single subsequent word. However, since those boundary conditions only yielded a number of alternatives less than ten, boundary locator  expands the boundary conditions. In one illustrative embodiment, boundary locator  expands either the beginning or the ending boundary condition to coincide with an additional word on either side of the text selected by the user (i.e., the beginning boundary will be moved to the word \u201creferences\u201d instead of \u201cone\u201d or the ending boundary will be moved to the word \u201cin\u201d instead of \u201cthree\u201d). In accordance with another embodiment, boundary locator  expands both the beginning and ending boundary conditions to include an additional word. Expanding the boundary conditions is indicated by block  in FIG. B. Once the boundary conditions have been expanded, processing reverts back to block  in  where the hypothesis alternative subpaths are again constructed as described above.","Once a sufficient number of hypothesis alternative subpaths have been constructed, as determined at block ; the last queue which is used to contain the hypothesis alternate subpaths is sorted according to score. This is indicated by block . Thus, that queue will now contain a sufficient number of alternatives, arranged in order of score, for presentation to the user.","As one additional and optional step, output component  can provide the N-Best alternatives to an optional inverse text normalization component which performs inverse text normalization (ITN) on the N-Best alternatives. This process can be done in any known way, and converts phrases such as \u201cthree fifteen p.m.\u201d to \u201c3:15 p.m.\u201d. In the above example, at the discretion of the ITN processor, the phrase \u201cone to three\u201d may be converted to \u201c1-3\u201d. This is indicated by block  in FIG. B. Finally, the top N alternative subpaths are presented to the user. This is indicated by block .",{"@attributes":{"id":"P-00089","num":"00089"},"figref":"FIG. 8","b":["206","208"]},"f(t) is the total score; and","g(t) is the known score at time t, and h(t) is the estimated score at time t.","In other words:","f(t) g(t)+h(t), where","g(t)=the sum of acoustic and language model scores up to time t, and","h(t)=a linear fraction of the optimal score for the remaining time.","The known score g(t) is simply the sum of the acoustic and language model scores. In terms of determining the rank of paths, the score is illustratively computed as the sum of the acoustic scores, plus language model scores. The acoustic score is simply the score assigned by the suitable acoustic model. The language model score can be the unigram probability which is the probability of a word being present in speech. It could also be an n-gram probability which is the probability of a word, given a particular set of n\u22121 words preceding it. It could also be a combination of such scores. For the same sequence of words, the language model score will be the same. For purposes of this example, we are assuming that the total score for the best path, or reference path is 600.","The actual score for an alternate subpath under construction as calculated by summing those two scores (acoustic and language model scores) as illustrated by block  in FIG. . The estimated score is calculated by taking a portion of the alternative subpath remaining to be calculated times the total score for the reference subpath. This is indicated by block . These two scores are added (the actual and estimated scores) to obtain the final score as indicated by block .","Reverting again to the above example, the estimated score is calculated as follows: \n\n\nIn this way, all actual and estimated scores are calculated. Of course, other suitable techniques for estimating the score for the remaining path can be used as well.\n",{"@attributes":{"id":"P-00100","num":"00100"},"figref":"FIG. 3B","b":["210","206","208","210","3","210","210","204","110"]},"In the embodiment in which CARC array  is used. Priority queues  and  identify the hypothesis path by simply containing a pointer into the CARC array and a score associated with that path. By accessing the position pointed to in the CARC array , and following the back pointer path through CARC array , all words which have been concatenated to construct that hypothesis entered in the queue can be located. In addition, the acoustic score for each word can be obtained by indexing into the word hypothesis lattice, and the language model score for each word can be computed based upon the dictionary word indices contained in the CARC objects associated with each word.","Therefore, when a new word is to be concatenated to a hypothesis to form a new hypothesis, the new score for that hypothesis can be calculated by simply tracing back through the CARC array  and obtaining the scores for all of the elements in the hypothesis.","It should also be noted that the priority queues can be thought of as two linked lists, one containing active items and the other containing inactive items. Unlike a typical implementation where each node is allocated on a heap individually, the object in accordance with the present invention instead has an array of elements with pointers to within the array. This obviates the frequent allocations and de-allocations required in usual queue implementations. Since the queue size is predetermined, the heap activity and fragmentation is reduced over conventional techniques.","Another feature of the present invention should be mentioned as well. When the user selects one of the alternates from the N-best alternatives presented to the user, the application can optionally indicate to SR engine  the alternative which was selected by the user. Based on the selected alternative, the engine  is illustratively configured to modify language model , acoustic model  and\/or its other model subsystems so the same misrecognition is less likely to occur in the future. Similarly, even if the user chooses to re-utter the utterance, SR engine  can still learn from the misrecognition. For example, if the user chooses to re-utter the utterance, application  will first invoke generator  to obtain the N-best alternatives for the original utterance. SR engine  then receives the re-utterance and provides the reference path to application  for the re-utterance. The application  then illustratively determines whether the reference path for the re-utterance corresponds to one of the alternatives for the original utterance. If so, application  provides this information to SR engine  which, again, modifies its model subsystems.","It should also be noted that the present invention can be utilized by storing received audio information and invoking decoder  at a later time. The N-best alternatives can be computed at that time. However, this tends to consume more memory than simply storing the hypothesis lattice.","It can thus be seen that the present invention provides significant advantages over prior art systems. For example, with the present invention, the N-Best alternatives need not even be computed until the user selects text to be corrected. In that case, the present system simply accesses the word hypothesis lattice, and begins constructing alternative subpaths using the priority queues and CARC array illustrated in FIG. A. The hypothesis lattice is accessed using boundary conditions as a filter to increase efficiency. Also only a predetermined number of paths are ever considered at the same time (i.e., the predetermined number being set by the size of the priority queues). This renders the computation of the N-Best alternatives even more efficient and can be done substantially on-the-fly.","Similarly, applications can persist the hypothesis lattice such that alternates can be requested at an arbitrary point in the future. This allows a user who dictate a document and have the document proofread by another person, on another machine, or simply at a later time.","Although the present invention has been described with reference to preferred embodiments, workers skilled in the art will recognize that changes may be made in form and detail without departing from the spirit and scope of the invention."],"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE ILLUSTRATIVE EMBODIMENTS"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"P-00012","num":"00012"},"figref":"FIG. 1"},{"@attributes":{"id":"P-00013","num":"00013"},"figref":"FIG. 2"},{"@attributes":{"id":"P-00014","num":"00014"},"figref":"FIG. 3A"},{"@attributes":{"id":"P-00015","num":"00015"},"figref":"FIG. 3B"},{"@attributes":{"id":"P-00016","num":"00016"},"figref":"FIGS. 4A and 4B"},{"@attributes":{"id":"P-00017","num":"00017"},"figref":"FIGS. 5 and 6"},{"@attributes":{"id":"P-00018","num":"00018"},"figref":"FIGS. 7A and 7B"},{"@attributes":{"id":"P-00019","num":"00019"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
