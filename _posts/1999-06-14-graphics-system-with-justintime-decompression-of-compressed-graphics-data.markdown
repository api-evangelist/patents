---
title: Graphics system with just-in-time decompression of compressed graphics data
abstract: A graphics system and method for increasing efficiency of decompressing blocks of compressed geometry data and reducing redundant transformation and lighting calculations is disclosed. Multiple decompression pipelines are used to increases the decompression speed. A control unit receives blocks of compressed geometry data information and selectively routes them to a plurality of decompression pipelines. Each decompression pipeline is configured to decompress the blocks into a set of vertices. The reduction in redundant calculations is accomplished by delaying the formation of geometric primitives until after transformation and lighting has been performed on the vertices. Transformation and/or lighting are performed independently on a vertex-by-vertex basis without reference to which geometric primitives the vertices belong to. After transformation and or lighting, geometric primitives may be formed utilizing previously generated connectivity information. The connectivity information may include mesh buffer references, vertex tags, or other types of information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07071935&OS=07071935&RS=07071935
owner: Sun Microsystems, Inc.
number: 07071935
owner_city: Santa Clara
owner_country: US
publication_date: 19990614
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","DESCRIPTION OF THE RELATED ART","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF SEVERAL EMBODIMENTS","ALTERNATE EMBODIMENT\u2014FIG. ","INDUSTRIAL APPLICABILITY"],"p":["The present invention relates to computer graphics systems, and more particularly, to decompressing and rendering compressed three-dimensional geometry data.","In recent years, demand for high performance graphics systems that can render complex three-dimensional (3D) objects and scenes has increased substantially. This increase is at least in part due to new applications such as computer-generated animation for motion pictures, virtual reality simulators\/trainers, and interactive computer games. These new applications place tremendous demands upon graphics systems. One area in which particularly high demands are placed on graphics systems is bandwidth. This is because 3D graphics data may be several orders of magnitude larger than comparable 2D graphics data. For example, simple 2D graphics data may simply include color information for each pixel displayed. In contrast, 3D graphics data may include x,y,z position information, normal information, color information, transparency information, texture map information, reflectivity information, and additional information. This information is collectively referred to herein as \u201cvertex component information\u201d.","A number of different techniques have been proposed to reduce the bandwidth requirements of 3D graphics data. One such technique is known as geometry compression. One type of geometry compression is described in detail in U.S. Pat. No. 5,793,371, issued on Aug. 11, 1998, entitled \u201cMethod and Apparatus for Geometric Compression of Three-Dimensional Graphics Data\u201d by Michael F. Deering, which is incorporated herein by reference in its entirety. Generally speaking, geometry compression relies upon reusing vertices (among other techniques) to reduce the size of the 3D graphics data. To describe a 3D object, a number of points (called vertices) are specified. Each vertex may have a number of attributes associated with it. For example, each vertex may have color information associated with it. Other attribute that may be associated with vertices are texture map coordinates, normals, color, and transparency information. For example, if a texture of marble is texture-mapped onto a sphere, each vertex on the sphere may have a texture map coordinate specifying how the texture should be applied (i.e., which part of the sample texture should be mapped to that particular vertex). A normal is a vector from the vertex that is perpendicular to the surface of the object at the vertex. This is illustrated in the 3D object of . The 3D object may be represented by a number of vertices (represented as dots in the figure). Normals for the object are represented by arrows that extend perpendicularly from the object's surface at each vertex point.","Normals are vectors or directions in three-dimensional space. In the context of 3D graphics, normals (also called surface normals) may each indicate the local orientation of the surface of a 3D graphics object. Since the starting point of the vector is known from the xyz coordinates of the vertex, the normal may be specified with an x-component, a y-component, and a z-component (referred to as Nx, Ny, and Nz, respectively). In some embodiments, these components may be specified relative to the vertex. This embodiment is illustrated in . However, other forms for specifying normals are also possible. Furthermore, in some implementations the normal components are themselves normalized. A normalized normal is one in which the sum of the squares of Nx, Ny, and Nz equals a constant one.","In 3D graphics, vertices are typically grouped together to form polygons such as triangles, as shown in . By definition, a triangle has three vertices. However, many times triangles share vertices. In , vertices -- form a first triangle and vertices -- form a second triangle. Thus, vertices  and  are shared between the two triangles. 3D objects may be represented by specifying a number of triangles. This is shown in .","However, specifying all of the information associated with each vertex (e.g., xyz location, color, normal, etc.) every time a vertex is referenced as part of a triangle is inefficient. Instead, the information about a vertex can be stored (e.g., when it is first transmitted) for later use. Then, when the vertex is needed again for another triangle, the vertex may be read from storage instead of having to be re-transmitted. The vertex information may be stored in a \u201cmesh buffer\u201d and then reused. This may advantageously reduce the amount of information that must be transmitted and may thus save bandwidth. This is illustrated in .","To efficiently reuse vertices, the triangles may be organized into a mesh (e.g., a predetermined number of neighboring vertices. The mesh may then be encoded as one or more \u201ctriangle-strips\u201d. For example, in  of the application, the triangle strip may start with the following triangles: ,,; ,,; ,,; ,,; ,,; ,,; et seq.","As this pattern shows, once the triangle strip is started many subsequent triangles may be specified using only a single new vertex. For example, after triangle ,, has been constructed, triangle ,, may be constructed using only one new vertex (i.e., vertex ). Thus, each vertex in the triangle strip may describe from \u2153 to one triangle. For example, in the list above, vertex  describes \u2153 of triangle ,,. Vertex  describes one triangle ,,. In some cases, a vertex may even describe two or even more triangles.","While a number of different formats are possible, one type of generalized triangle strip may be defined as follows (encoding the 3D object from ):\n\n","In the notation above, R is a restart tag (indicating that a new mesh is beginning), O denotes replace oldest, and M denotes replace middle. The operation of this type of generalized triangle strip is illustrated in .","In some embodiments, the terms \u201coldest\u201d and \u201cmiddle\u201d may be visualized as representing three registers that are used in forming triangles from the triangle strip representation. The sample encoding above is merely one nomenclature that may be used to represent how the vertices of the mesh are being encoded. Different implementations may use other nomenclatures. The example nomenclature uses letters (O and M) to indicate which vertex should be discarded from the three registers when forming a new triangle. O indicates the oldest vertex should be discarded. M indicates the middle vertex should be discarded. R indicates that a section of mesh is being started. This is used to clear the oldest, middle, and newest registers and the mesh buffer, if desired.","While this method reuses vertices, when vertex  is referenced a second time (i.e., by the command O), the vertex is transmitted again. This retransmission of vertices may be reduced or avoided altogether by using a mesh buffer.","Using a similar nomenclature as in the previous example, a generalized triangle mesh utilizing a mesh buffer may be defined as follows (once again encoding the 3D object of ):\n\n","In this implementation, a trailing letter \u201cp\u201d denotes \u201cpush into mesh buffer\u201d. The number following a capital letter is a vertex number, and a negative number is the mesh buffer reference, in which \u201c\u22121\u201d denotes the most recent pushed vertex.","Thus, geometry compression may explicitly push old vertices (e.g., vertices with a trailing letter \u201cp\u201d above) into a mesh buffer. These old vertices may be explicitly referenced when the old vertex is again needed. This approach provides a fine control that supports irregular meshes of nearly any shape. As used herein, the term \u201cmesh buffer\u201d shall refer to this queue, and the expression \u201cgeneralized triangle mesh\u201d will refer to a combination of generalized triangle strips and mesh buffer references.",{"@attributes":{"id":"p-0017","num":"0025"},"figref":"FIGS. 8A\u20138N","b":"3"},"As previously noted, by reducing the size of the 3D graphic data bandwidth may be saved. For example, when programmers are creating a 3D virtual object to be used in a simulation, they may execute a compression program to determine how best to compress the 3D object. The compression program may tessellate or divide the surface of the object into a plurality of vertices, e.g., a NURBs (Non-Uniform Rational B-spline) object. The compression program may then divide the vertices into groups of generalized triangle meshes as described above. These meshes may then be compressed and encoded using a similar process to that described above. The compressed data may then be stored (e.g., on a CD-ROM or DVD-ROM) and\/or transmitted (e.g., on the Internet). The bandwidth savings may also apply to buses used for transmission of the 3D geometry data within the graphics system itself.",{"@attributes":{"id":"p-0019","num":"0027"},"figref":"FIG. 9","b":["20","10"]},"Generally, compressed 3D geometry data is conveyed to graphics system  on input bus . Geometry decompressor  receives the compressed data and decompresses it. A mesh buffer  may be used to store vertices that will be reused. As previously described, mesh buffer references may be encoded within the compressed data to indicate which vertices will be reused and thus should be stored in the mesh buffer.","Once a geometric primitive such as a triangle is decompressed, it is conveyed to one of a plurality of transform and lighting processors A\u2013N. The transform and lighting processors work independently and in parallel to perform the following functions: (a) transform the vertices forming primitive from their original coordinate reference frame (e.g., object space) into a common reference frame (e.g., world space or screen space); and (b) \u201clight\u201d each vertex by determining which light sources affect each vertex and how much they are affected.","Next, the transformed and lit triangles are conveyed to draw processor , which is configured to render the transformed and lit primitives and apply texture mapping (e.g., from texture map memory ). In some embodiments, textures may instead be applied during the lighting process (collectively referred to as \u201cshading\u201d). In some embodiments, when shading is used only micropolygons are drawn. Draw processor  is configured to rasterize the primitive into frame buffer . In most embodiments, frame buffer  is double buffered, with one buffer being draw into by draw processor  while the second buffer is being read by DACs . DACs  may read frame buffer  asynchronously with respect to draw processor . DACs  form an output video signal that is typically used to drive a display device such as a CRT monitor or LCD panel display.","For the reasons set forth above, the use of geometry compression is particularly advantageous in high performance graphics systems. However, further increases in performance are still demanded by modern applications. Thus, an efficient method for increasing the performance of graphics systems configured to utilize 3D graphics data that has been compressed into generalized triangle mesh format is desired. Furthermore, a graphics system capable of increased performance while utilizing compressed 3D geometry data is also desired.","The problems outlined above may, in part, be solved by a graphics system capable of decompressing data blocks more efficiently. In some embodiments, multiple decompression pipelines (each having one or more decompressors) may be used in parallel to increase efficiency and lessen the load on any one decompressor. In one embodiment, a control unit may be used to selectively assign blocks of compressed vertex information to decompression pipelines. Each pipeline may then decompress the blocks of compressed vertex information. These decompressed blocks of vertex information are then transmitted to transformation and lighting processors (or other processors) by the individual decompression pipelines. In some embodiments, delaying the decompression process until after the graphics data has been divided into blocks and routed to parallel decompression pipelines may improve performance over systems that decompress the data before routing it.","In some embodiments, efficiency may be further increased by delaying the formation of independent primitives until after transformation and\/or lighting has been performed. In this way, vertices that are shared by more than one primitive have the potential to be transformed and lit only once, as opposed to being transformed and lit once for each triangle to which they belong. Transforming and or lighting may thus be performed on an individual vertex basis instead of on a geometric primitive basis. The individually transformed and lit vertices are then assembled into primitives for rendering.","In some embodiments, the graphics system may utilize a transformed vertex cache to store transformed and lit vertices. Each time a particular vertex is needed to form a geometric primitive, the vertex is read from the transformed vertex cache. Each vertex may be accessed using a tag assigned to the vertex during decompression.","In other embodiments, the graphics system may utilize a transformed vertex buffer that is similar to a mesh buffer in function. However, instead of storing vertices generated by the geometry decompressor, the transformed vertex buffer stores transformed and lit vertices. Mesh buffer references may be used by the transformed vertex buffer to determine which transformed and lit vertices should be stored in the transformed vertex buffer.","While the invention is susceptible to various modifications and alternative forms, specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood, however, that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary, the intention is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.","A graphics system according to the present invention may be used to achieve improved performance by reducing redundant processing. Advantageously, compressed geometry data may still be utilized by the system. Before describing the system and related method in detail, the overall environment in which the present invention may be practiced will be described.","Computer Network\u2014",{"@attributes":{"id":"p-0055","num":"0063"},"figref":"FIG. 10","b":["60","70","60","70","60","68","60","62","64","66"]},"Once the compressed 3D geometry data is received by one or more of clients A\u2013C, the data is decompressed, rendered, and then displayed. As indicated in the figure, clients A\u2013C may include computer systems such as personal computers (PCs), laptop computers, network computers (NCs), television sets with \u201cset top\u201d decoder boxes, game boxes, and other electronic devices capable of manipulating and or displaying 3D computer graphics. Other examples include personal digital assistants (PDAs) and virtual reality workstations (e.g., computers having head-mounted displays).","Computer System\u2014",{"@attributes":{"id":"p-0057","num":"0065"},"figref":"FIG. 11","b":"80"},"As shown, the computer system  comprises a system unit  and a video monitor or display device  coupled to the system unit . The display device  may be any of various types of display monitors or devices (e.g., a CRT, LCD, or gas-plasma display). Various input devices may be connected to the computer system, including a keyboard  and\/or a mouse , or other input device (e.g., a trackball, digitizer, tablet, six-degree of freedom input device, head tracker, eye tracker, data glove, body sensors, etc.). Application software may be executed by the computer system  to display 3-D graphical objects on display device . As described further below, the 3-D graphics system in computer system  includes a super-sampled sample buffer with a programmable real-time sample-to-pixel calculation unit to improve the quality and realism of images displayed on display device .","Computer System Block Diagram\u2014",{"@attributes":{"id":"p-0059","num":"0067"},"figref":["FIG. 12","FIG. 11"],"b":["80","90","94","94","92","94"]},"Host processor  may comprise one or more processors of varying types, e.g., microprocessors, multi-processors and CPUs. The system memory  may comprise any combination of different types of memory subsystems, including random access memories, (e.g., Static Random Access Memories or \u201cSRAMs\u201d, Synchronous Dynamic Random Access Memories or \u201cSDRAMs\u201d, and Rambus Dynamic Access Memories or \u201cRDRAM\u201d, among others) and mass storage devices. The system bus or host bus  may comprise one or more communication or host computer buses (for communication between host processors, CPUs, and memory subsystems) as well as specialized subsystem buses.","A 3-D graphics system or graphics system  according to the present invention is coupled to the high-speed bus . The 3-D graphics system  may be coupled to the bus  by, for example, a crossbar switch or other bus connectivity logic. It is assumed that various other peripheral devices, or other buses, may be connected to the high-speed bus . It is noted that the 3-D graphics system may be coupled to one or more of the buses in computer system  and\/or may be coupled to various types of buses. In addition, the 3D graphics system may be coupled to a communication port and thereby directly receive graphics data from an external source, e.g., the Internet or a network. As shown in the figure, display device  is connected to the 3-D graphics system  comprised in the computer system .","Host CPU  may transfer information to and from the graphics system  according to a programmed input\/output (I\/O) protocol over host bus . Alternately, graphics system  may access the memory subsystem  according to a direct memory access (DMA) protocol or through intelligent bus mastering.","A graphics application program conforming to an application programming interface (API) such as OpenGL\u2122 or Java 3D\u2122 may execute on host CPU  and generate commands and data that define a geometric primitive (graphics data) such as a polygon for output on display device . As defined by the particular graphics interface used, these primitives may have separate color properties for the front and back surfaces. Host processor  may transfer these graphics data to memory subsystem . Thereafter, the host processor  may operate to transfer the graphics data to the graphics system  over the host bus . In another embodiment, the graphics system  may read in geometry data arrays over the host bus  using DMA access cycles. In yet another embodiment, the graphics system  may be coupled to the system memory  through a direct port, such as the Advanced Graphics Port (AGP) promulgated by Intel Corporation.","The graphics system may receive graphics data from any of various sources, including the host CPU  and\/or the system memory , other memory, or from an external source such as a network, e.g., the Internet, or from a broadcast medium, e.g., television, or from other sources.","As will be described below, graphics system  may be configured to delay geometric primitive assembly so as to reduce or eliminate redundant vertex processing. Note while graphics system  is depicted as part of computer system , graphics system  may also be configured as a stand-alone device (e.g., with its own built-in display). Graphics system  may also be configured as a single chip device or as part of a system-on-a-chip or a multi-chip module.","Graphics System\u2014",{"@attributes":{"id":"p-0066","num":"0074"},"figref":["FIG. 13","FIG. 15"],"b":["100","100","10","12","14","12","12","22"]},"The individual object-space vertices are distributed (e.g., in a load-balancing manner) to transform\/lighting processors A\u2013N. The transform\/lighting processors A\u2013N transform the object-space vertices to world space or screen space coordinates, and then perform lighting calculations. The transformed and lit vertices are then conveyed to set up\/draw processor .","Set up\/draw processor  is configured to receive both the transformed and lit vertices from processors A\u2013N and the connectivity information from geometry decompressor . Based on the connectivity information, set up\/draw processor  is configured to assemble the transformed and lit vertices into geometric primitives. In the embodiment shown in the figure, a transformed vertex buffer  may be used by set up\/draw processor  to assemble the geometric primitives (e.g., using registers ). Assembly of geometric primitives may be accomplished in a similar manner to that used by geometry decompressor  in . However, instead of using a mesh buffer, set up\/draw processor  may utilize transformed vertex buffer  to store the transformed and lit vertices according to the connectivity information from decompressor . As previously noted, in some embodiments the connectivity information may include mesh buffer references from the compressed 3D geometry data. These mesh buffer references may be used to selectively push and pop transformed and lit vertices onto transformed vertex buffer . In this embodiment, transformed vertex buffer  may be configured as a stack that is accessible using top-of-stack relative addressing (e.g., as shown in ).","As previously noted, by transforming and lighting vertices individually, redundant transforming and lighting of shared vertices may be reduced. For example, in previous systems if a first triangle having vertices -- and a second triangle having vertices -- were formed by decompressor , transform and lighting processor A may have received the first triangle and processor B may have received the second triangle. Each processor would have then performed transformation and lighting calculations on each of its triangle's three vertices. Thus processor A would have transformed and lit vertices , , and , while processor B would have transformed and lit vertices , , and . As this example illustrated, vertices , and  are transformed and lit twice.","In contrast, in the embodiment illustrated in the figure, vertices \u2013 could have been routed to processor A, while vertices \u2013 could have been routed to processor B. Thus duplicative transformation and lighting of repeated vertices may be reduced or eliminated. This is possible because in most cases vertices may be treated as independent points on an object's surface. Which vertices neighbor each other is typically irrelevant for coordinate transformation calculations and lighting calculations.",{"@attributes":{"id":"p-0071","num":"0079"},"figref":"FIG. 14","b":["100","22","110"]},"As shown in the figure, decompressor  is configured to receive and decompress compressed 3D geometry data into vertices. However, decompressor  is also configured to assign a tag to each decompressed vertex. The decompressed vertices are then routed with their tags to transform and lighting processors A\u2013N. Decompressor  is also configured to generate connectivity information using the vertex tags. As in the previous embodiment, the connectivity information is provided to set up\/draw processor .","Set-up\/draw processor  is configured to receive the transformed and lit vertices (and their associated tags) and store them into transformed vertex cache  and tag array , respectively. Depending upon the configuration, transformed vertex cache  may be direct mapped, set-associative, or fully associative. Set up\/draw processor  then assembles geometric primitives based on the connectivity information provided by decompressor . In one embodiment, the connectivity information may comprise a sequences of tags. These tags may be used by set up\/draw processor  to read the transformed and lit vertices out of cache  (using tag array ) and into register . As in the previous embodiment, when a primitive is formed in registers , it is then rendered (i.e., drawn) into frame buffer . As with the previous embodiment, the amount of redundant processing performed on shared\/reused vertices may be reduced. Depending upon the configuration and the size of transformed vertex cache , this embodiment may allow reuse of vertices beyond a particular mesh (e.g., beyond the boundaries of a single triangle mesh).","Note that while the figures show registers  with storage for only three vertices per primitive, other configurations are also possible (e.g., four or more vertices for polygons, two vertices for lines, or one vertex for dots). Further note that while graphics system  is shown as receiving compressed 3D geometry data, other types of data may also be received and used. For example, decompressor  may be configured to receive uncompressed 3D geometry data in some embodiments. The 3D graphics data may include data in a number of different formats. For example, three dimensional objects that are part of the scene may be represented as volumes, surfaces, or 3D objects that have been tessellated into a plurality of polygons (e.g., triangles or quadrilaterals). The 3D graphics data may also include objects modeled with NURBs (non-uniform rational B-splines), volume elements, subdivision surfaces, meshes and other techniques. The 3D data may be generated by computer animators, by 3D scanning devices, 3D cameras, 3D digitizers, or other techniques. Depending upon the format in which the 3D graphics data is received, it may be manipulated before being transformed into a plurality of vertices.","In this case decompressor  acts more like a connectivity information generator by generating the vertex tags and corresponding connectivity information for the vertices instead of actually decompressing the data. In other embodiments the data may be compressed using non-geometric methods (e.g., numerical compression such as LZW compression). While the bandwidth reduction benefits may not be fully realized in such an embodiment, graphics system  may nevertheless be able to reduce the amount of redundant transformation and lighting that is performed on shared\/reused vertices","To allow decompressor\/connectivity information generator  to efficiently generate the connectivity information, in one embodiment connectivity information generator  may be configured with an untransformed vertex cache  and corresponding tag array . As decompressor\/connectivity information generator  receives data, it may assign tags and then store the vertices and their corresponding tags to untransformed vertex cache  and tag array , respectively. Decompressor\/generator  may then examine vertices as they are received. If a corresponding entry is already in untransformed vertex cache , then the vertex has already been transformed and lit and should be stored in transformed vertex cache . Thus, decompressor\/generator  may convey the tag to set up-draw processor  without having the vertex re-transformed. If transformed vertex cache  does not have a copy of the transformed vertex, this may be signaled back to decompressor\/generator  and decompressor\/generator  may convey the untransformed vertex to one of transform and lighting processors A\u2013N.","The size of caches  and  may vary depending upon the organization of the input graphics data. For example, if the graphics data is highly organized (e.g., into generalized meshes), a smaller cache may contain enough storage to be effective. If however, the graphics data contains random vertices, then a larger cache may be more effective in reducing redundant transform and lighting calculations.","While each embodiment may include different information with vertices stored in transformed vertex buffer  (or transformed vertex cache ), a partial list of information that may be included with some or all of the vertices follows: vertex position (e.g., x,y,z coordinate in world space or screen space), texture mapping coordinates (e.g., 2D coordinates, 3D coordinates, multiple texture map coordinates, 4D coordinates), color (e.g., red, green, and blue components), transparency information (e.g., an alpha component), normal information (e.g., Nx, Ny, Nz), lighting information, displacement map information, reflectivity information, bump map information, blur information, an intensity and brightness information, and other control information.","Note in some embodiments there may be multiple set up\/draw processors (e.g., one for each transform and lighting processor or one for every two transform and lighting processors) and multiple decompressor units. These embodiments will be described in greater detail below (see discussion of ). However, the transformation calculations performed by transform and lighting processors A\u2013N will be described first, as will a method for implementing the previously described embodiments.","Transformation\u2014",{"@attributes":{"id":"p-0080","num":"0088"},"figref":"FIG. 15A","b":["150","140","150","140"]},{"@attributes":{"id":"p-0081","num":"0089"},"figref":["FIG. 15B","FIG. 15A"],"b":["150","142","142","142","150","142","140","142"]},{"@attributes":{"id":"p-0082","num":"0090"},"figref":["FIG. 15C","FIG. 15A"],"b":["150","144","144","140","150","142","142","144","18"]},"Method For Reducing Redundant Transformation\/Lighting\u2014",{"@attributes":{"id":"p-0083","num":"0091"},"figref":"FIG. 16"},"First, the geometry data is received by the graphics system (step ). Next, the geometry data is decompressed into individual vertices and corresponding connectivity information is generated (step ). As noted above, in some embodiments the geometric data need not be compressed when received by the graphics system. The connectivity information may include mesh buffer-type references, vertex tags, or other schemes for indicating which vertices should be combined to form geometric primitives.","Next, the vertices are distributed to transformation\/lighting processors (step ). In the preferred embodiment, there are multiple transformation and lighting processors configured to work independently and in parallel. The vertices may distributed according to known load balancing techniques to maximize throughput for each processor. Depending upon the implementation, separate processors may handle transformation and lighting. Alternative embodiments may combine transformation, lighting, and texturing in a process called shading. In some embodiments, the graphics system may be configured to perform only transformation (step ) before assembling the vertices into geometric primitives. In other embodiments, the graphics system may perform both transformation and lighting (step ) before assembling the vertices into geometric primitives. The vertices are assembled into geometric primitives using the previously generated connectivity information, regardless of whether both transformation and lighting are performed or just transformation (step ).","Next, the geometric primitives are rendered into a sample or frame buffer (step ). A sample buffer takes the place of a traditional frame buffer by storing samples in lieu of pixels. The samples are then filtered to form a final pixel value. Use of a sample buffer allows super-sampling, in which the total number of samples is greater than the total number of pixels. Super-sampling has a number of benefits, including a more realistic picture and the capability to perform on-the-fly anti-aliasing. More information on super-sampling is presented in the U.S. patent application Ser. No. 09\/251,449, entitled \u201cA Graphics System With Programmable Sample Positions\u201d by Michael F. Deering, David Naegle, and Scott Nelson, filed on Feb. 17, 1999. This application is hereby incorporated by reference in its entirety.","Note that the flowchart depicted in the figure is meant for explanatory purposes and is not meant to be limiting. In some embodiments, the steps may be performed in a different order, in parallel, or some steps may be eliminated (e.g., step  or step ). Additional steps may also be performed. For example, multiple transformation steps  may be performed to translate the vertices from object space to world space and from world space to screen space. Furthermore, multiple iterations through lighting step  may be performed if multiple light sources are activated. Other graphics processes may also be performed (e.g., texture mapping, bump mapping, displacement mapping, shadowing, specular highlighting, fogging, etc.).","Multiple Graphics Subsystems\u2014",{"@attributes":{"id":"p-0088","num":"0096"},"figref":["FIG. 17","FIG. 12"],"b":["100","100","190","208","90","12","12","18","18"]},"Once the vertices are transformed and lit, they are conveyed to set up\/draw units A\u2013N. In this embodiment, each set up\/draw unit A\u2013N has its own transformed vertex buffer A\u2013N and its own set of oldest-middle-newest registers A\u2013N. These may function similarly to those described in connection with  above. FIFO (First-In First-Out) memories may be utilized in the pipelines (e.g., between control unit  and decompression units A\u2013N) to buffer the data being distributed by control unit .","To control the transform and lighting process and the set up\/draw process, compressed graphics data  may include predefined control information. Some of this control information may be utilized during the decompression process. For example, compressed graphics data  may include control information indicating the type of compression used or specific information about the particular mesh that is compressed. One such type of control information may be an indication of the color depth being used in the particular mesh. Another type of control information may be an indication as to whether color information is specified for each vertex (i.e., a bundle color bit) or whether color information is defined separately (e.g., one global color for all vertices in the mesh). Other control information (e.g., transparency or alpha information) may also be embedded in the compressed geometry data.","The control information may set the \u201cstate\u201d of a state machine within one or more of decompressors A\u2013N, transform\/lighting processors A\u2013N, and\/or set up\/draw processors A\u2013N. In some embodiments, the control information may be designated as either \u201cglobal\u201d or \u201clocal\u201d control (or state) information. The control information is global if it is intended to affect the state of all decompressors A\u2013N, all transform\/lighting processors A\u2013N, or all set up\/draw processors A\u2013N in graphics system . Conversely, if the control information is intended to only affect the state of a single decompressor, transform\/lighting unit, or set up\/draw unit, then the control information is local. Control unit  may be configured to detect whether the control information embedded in the stream of compressed geometry data is global or local, and then route the control information accordingly. For example, if a certain set of control information is global, then control unit  may be configured to send copies of the control information to each decompression\/render pipeline in graphics system . If control unit  determines that the control information is local, control unit  conveys the control information to a single decompression\/render pipeline along with the vertex or vertices that are associated with the control information.","For example, control unit  may receive a stream of compressed graphics data  that begins with a global set color instruction. Control unit  may then convey this global control information to each of decompressors A\u2013N. Then control unit  may pass compressed vertices in round-robin fashion to decompressors A\u2013N. After each vertex is decompressed, each vertex is assigned the global color. If control unit  then detects a second global set color instruction with a new color, control unit  again sends copies of the instruction to each decompressor, which proceed to assign the new color to all vertices they receive after the global change color instruction.","In some embodiments, control unit  may be configured to invalidate the contents of transformed vertex buffers A\u2013N in response to detecting a global control instruction. This may prevent a vertex that is reused with different colors from being rendered more than once with the same color. Note, while color and transparency are used in the examples above, other types of local and control information are also possible and contemplated. In some embodiments, the designation of whether the state\/control information is global or local may be accomplished through the use of a unicast\/multicast bit within compressed graphics data , as described in greater detail below.","Unicast\/Multicast\u2014",{"@attributes":{"id":"p-0094","num":"0102"},"figref":"FIG. 18","b":["208","208","200","202","204","206","202","204","200","204","206","204","204","206","206","204","204","206","202"]},"Data portions  may store compressed geometry data corresponding to predetermined mesh size. For example, data portions may be configured to each store compressed geometry information corresponding to a 16\u00d716 mesh of vertices. as previously noted, each vertex may comprise varying amounts of information, including xyz position, color information, normal information, texture mapping information, and other vertex component information.","Using data sequence , control unit  (see ) may be configured to efficiently route each block according to multicast bits  and length indicators A. Length indicators  enable control unit  to determine block boundaries. For each block received by control unit , the corresponding multicast bit  directs control unit  to convey a block to a single decompression\/render pipeline (unicast) or all decompression\/render pipelines (multicast). For unicast blocks, control unit  may be configured to route the block to the decompression\/render pipeline with the least processing backlog (e.g., to the pipeline that most likely is available). While this configuration provides a great deal of flexibility, in some embodiments certain restrictions may be placed upon the format of data sequence  to simplify the hardware of control unit  and graphics system  (e.g., by reducing or eliminating the need of independent decompress\/render pipelines having to communicate and\/or coordinate with each other).","One such restriction is that only state information may be stored in the data portion  of a block  that is multicast. Without this restriction, multiple pipelines may spend time decompressing and rendering the same geometry data. Instead, multicast blocks are limited to having \u201cstate\u201d information. As used herein state information means information that is being set solely for use with future vertices. As previously noted, some state information (e.g., color and normal information) may be set for a particular vertex of mesh and then reused from one vertex to the next. If all vertices in a particular mesh have the same color, then the color information may be sent once (e.g., with a Java 3D\u2122 compressed geometry setColor instruction) as state information and then reused by some or all of the vertices in the following block or blocks. Other state information may include transparency information and normal information. Depending upon the configuration, other types of state information may also be specified. Thus, a multicast block may serve to reset all decompression\/rendering pipelines to a predetermined state. This may be useful when control unit  receives blocks that begin a new 3D object. While information stored in the mesh buffer is also state information, as previously noted each block may be forced not to rely on any previously entered mesh buffer information.","Similarly, if a block is designated as a unicast block, to reduce interdependence between the decompress\/render pipelines, the block may be limited to geometry information rather than \u201cstate\u201d information. As used herein geometry information means any information that does not carry forward from one block to another. For example, mesh buffer contents, vertex position information, and color information may all be considered geometry information (depending upon the exact implementation of graphics system ).","Another possible restriction that may be used to prevent any vertices within a block from relying upon any previous information supplied in a previous block is to require that the first vertex of each block be accompanied by a restart tag. As previously explained in the background section, a restart tag is a tag that indicates that a new mesh is starting. The restart tag may be used to indicate to the set up\/draw processor that all previous entries in registers  and or transformed vertex memory  should be invalidated (within the corresponding decompression\/render pipeline).","The use of delta encoding or delta\u2014delta encoding of vertex component information may also be restricted. For example, some embodiments of graphics system  may be configured to encode the color of a second vertex as an offset relative to a first vertex. Similarly, the position of second vertex may be specified as an offset relative to first vertex. This type of delta or delta delta encoding is useful because in many cases neighboring vertices may have similar attributes. For example, neighboring vertices will typically have xyz position coordinates that are relatively similar. Thus, instead of specifying an entire position for the second vertex (e.g., 32-bits each for x, y, and z) a simple offset (e.g., 8-bits each for x, y, and z) may be used. However, this type of decoding may complicate control unit . For this reasons, some embodiments of graphics system  may force the first vertex in a block to be explicit (e.g., 32-bits of position information for each x, y, and z). Delta encoding may thus be limited to vertices occurring after the first vertex in each block. Similarly, Delta-delta encoding may be limited to vertices occurring after the second vertex in each block. Depending upon the compressed data and the exact implementation of the graphics system, this restriction may not be terribly burdensome because vertices from different blocks (i.e., different meshes) may have greater likelihood of having less in common than vertices from the same block\/mesh.","Still another such restriction is that vertices in a particular data portion  may not use mesh buffer state information from a previous block. This restriction promotes the independence of each block and may free control unit  from having to route the blocks in a particular manner.","One option for implementing graphics system  is to guarantee that any multicast block will be seen by every decompress\/render pipeline before any subsequent blocks in data sequence . For example, if block A is first block in data sequence , the data may be encoded such that block B is a multicast block. If so, then block C may be encoded to rely upon the state-setting information contained in block B. This optional restriction may once again simplify control unit . To implement this restriction, each decompress\/render pipeline may be limited to executing that blocks that it receives in an \u201cin-order\u201d fashion. For example, if each pipeline has a buffer to store pending blocks, the pipeline may be forced to read from the buffer in a FIFO manner. Out-of-order processing within a particular pipeline would not be allowed in this embodiment.","Similarly, some embodiments of graphics system  may guarantee that any blocks preceding a multicast block will be executed before the multicast block is executed (within a particular pipeline). This may be implemented in the same manner described above (i.e., by forcing each pipeline to execute blocks it receives in the order in which they are received).","Depending upon the implementation and the amount of complexity within control unit  that is acceptable, restrictions are also possible on other types of state information. Examples include limitations on the block-to-block propagation of color information (e.g., set by Java 3D setColor instructions), bundling information (e.g., set by Java 3D bundling instructions), or Huffman table settings. In some embodiments, the geometry compression used may rely upon programmable Huffman tables for decompression. The tables may be loaded by Java 3D setTable instructions. After the decompression table is set, each following vertex and or primitive may be decoded utilizing the table.","The aforementioned restrictions may be programmed into a geometry compression program (or dedicated geometry compression hardware) that follows the restrictions when creating the compressed 3D geometry data. Similarly, the requirements above may be programmed into a load-timer verifier that is run as part of the decompression process. Before decompression begins, the load-time verifier may examine the data to determine which, if any of the requirements have been violated.","Graphics system  may be optimized to support a particular set of compression requirement. However, if data that does not comply with the particular compression requirements is received, in some embodiments graphics system  may still be configured to decompress the data (albeit at a less than optimal rate). For example, in a worst-case scenario all of the blocks may be routed in-order to a single decompress\/render pipeline. While slow, this method may still allow accurate decompression and rendering of some types of compressed 3D geometry data that fail to meet all of the restrictions.","Live-Dead Analysis\u2014","During the compression process, the compression program\/hardware may be configured to perform a live-dead analysis to ensure that the geometry is compressed correctly. This may also be performed in a verifier (i.e., a program that checks the compressed geometry data for compliance with a standard or predefined set of rules). The verifier may be run at compression-time and or at load time. The use of live-dead analysis may allow the compressor to achieve greater compression ratios. In some embodiments, particularly if there are a large number of decompress\/render pipelines, the unicast\/multicast implementation described above may reduce efficiency to some extent. For example, if one out of every five blocks is a multicast block, and if there are six decompress\/render pipelines, then some pipelines may spend an undesirable amount of time processing multicast blocks. To address this, the compressor or verifier may be configured to determine whether a particular pipeline needs to see a particular multicast block. In some embodiments, this information may be encoded as a set of \u201clive-dead\u201d bits (e.g., at the beginning of each block in addition to the multicast bit). Control unit  may be configured to detect these live-dead bits for each block and then route the blocks accordingly. In other embodiments, the compressor may be configured to rearrange and or change global instructions to local instructions.","For example, if a global color change to red is followed by two vertices and then a global color change to green, then the global color change to red may be changed to two local color changes to red (i.e., one for each vertex following the global color change to red). Since the global color change to green follows so closely, local color changes will be more efficient in systems with more than two decompression\/render pipelines.",{"@attributes":{"id":"p-0109","num":"0117"},"figref":["FIGS. 19A\u2013C","FIG. 19A"],"b":["240","242","242","242","244","240","244","242"]},"In many embodiments, however, the geometry may be compressed independent of the target hardware's exact configuration. For example, the compression program may be unaware of the number of decompress\/render pipelines present in the target hardware. The number of pipelines may vary from system to system depending upon their configuration. Thus, to ensure that multicast block  executes correctly (i.e., has the proper state information), unicast block B returns the altered state information back to its original state. This is useful in embodiments in which there are multiple decompress\/render pipelines, each operating independently and each having its own internal copy of the state information. Thus one pipeline may temporarily operate using different state information. When a particular piece of state information will be relied upon by future blocks, that state information is considered to be \u201clive\u201d state information. However, once a particular setting of state information is no longer needed, it is considered \u201cdead\u201d. Dead state information may be changed by subsequent unicast or multicast blocks without having to return the state information back to its original state.",{"@attributes":{"id":"p-0111","num":"0119"},"figref":"FIG. 19B","b":["240","242","242","240"]},"In contrast,  illustrates how moving the state-setting instruction into the unicast instructions prevents the pipelines that execute unicast blocks D\u2013E from having to execute the unnecessary state-setting instruction. By performing live-dead analysis, the compressed geometry data may thus be further optimized.","Encoding of Live-Dead Bits\u2014",{"@attributes":{"id":"p-0113","num":"0121"},"figref":"FIGS. 20A\u2013B"},{"@attributes":{"id":"p-0114","num":"0122"},"figref":"FIG. 20A","b":"208","sub":["1","1","2","2","1 ","1 ","0 ","2"]},"As also indicted in the figure, in this embodiment the body of the first and last instruction of each block may be defined to be variable-length no-op instructions (i.e., Band B). This may allow certain control information to be embedded within the block without sacrificing backward compatibility. For example, some load-time verifier programs may be configured to implement live\/dead encoding as discussed above. The live\/dead encoding may then be embedded within the variable length no-ops. However, if a graphics system only has one decompress\/render pipeline or for some other reasons does not support live\/dead encoding, then the graphics system may be configured to ignore the no-op instruction. In some embodiments, the final header portions Hmay also be packed with live\/dead encoding information and or additional control information.",{"@attributes":{"id":"p-0116","num":"0124"},"figref":["FIG. 20B","FIG. 20A"],"sub":["1 ","0 ","2","1 ","1"]},"The first and last body of each block may be predefined to have a particular set of fields. For example, the first body portion (B) of each block may be defined to begin with a fixed-length field  that indicates the length of the body portion (e.g., in bits, bytes or words). Multicast\/unicast bit  may be defined to follow field . Next, block length information field  may follow. After the first body portion, a fixed or variable number of header-body pairs may follow. As previously noted, the final header and or final body portion may also be defined to indicate a variable or fixed length no-op and may be used to store certain control information.","In some embodiments, state information may be defined as information that is not associated with a particular vertex or set of vertices (e.g., state information that affects all following vertices in the block). For example, the previously described global color change instruction is not associated with a particular vertex and would thus be considered to be a state changing instruction. Thus, color information can be either state information (e.g., global) or non-state information (also referred to herein as geometry information or per-vertex information). A number of different rules may be applied during the compression and or decompression process to simplify the live-dead analysis for state information. For example, in some embodiments a restriction may be imposed that prohibits certain or all state information (e.g., the contents of the transformed vertex memory) from being shared between blocks. Thus a block may not rely on state information set by a previous block. In other embodiments, however, state information may be shared.","Note the example encodings illustrated in the figures are for explanatory purposes only and are not meant to be limiting. Other encodings and configurations are possible and contemplated, depending upon the exact implementation. For example, multicast\/unicast bit  may be defined as the first field in the first body portion of each block. Furthermore, in some embodiments the header-body pairs may be contiguous instead of being separated. The final body portion (or the second to last, etc.) may be defined to contain a particular instruction that indicates the end of the block is approaching.","A graphics system and method have been disclosed. The features described above may be used individually or in combination and may be realized in software, hardware, or a combination thereof. The system and method may be utilized in a number of different products, including computer systems, graphics accelerator cards, game consoles, set top boxes, portable or hand-held electronic devices, graphics display devices, system on a chip applications, and in other types of electronic devices.","Although the system and method of the present invention has been described in connection with the described embodiments, they are not intended to be limited to the specific forms set forth herein. On the contrary, they are intended to cover such alternatives, modifications, and equivalents as can be reasonably included within the spirit and scope of the invention as defined by the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0028","num":"0036"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0029","num":"0037"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0030","num":"0038"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0031","num":"0039"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0032","num":"0040"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0033","num":"0041"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0034","num":"0042"},"figref":"FIGS. 7A\u2013H"},{"@attributes":{"id":"p-0035","num":"0043"},"figref":"FIGS. 8A\u2013N"},{"@attributes":{"id":"p-0036","num":"0044"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0037","num":"0045"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0038","num":"0046"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0039","num":"0047"},"figref":["FIG. 12","FIG. 11"]},{"@attributes":{"id":"p-0040","num":"0048"},"figref":["FIG. 13","FIG. 12"]},{"@attributes":{"id":"p-0041","num":"0049"},"figref":["FIG. 14","FIG. 12"]},{"@attributes":{"id":"p-0042","num":"0050"},"figref":"FIG. 15A"},{"@attributes":{"id":"p-0043","num":"0051"},"figref":"FIG. 15B"},{"@attributes":{"id":"p-0044","num":"0052"},"figref":"FIG. 15C"},{"@attributes":{"id":"p-0045","num":"0053"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0046","num":"0054"},"figref":["FIG. 17","FIG. 12"]},{"@attributes":{"id":"p-0047","num":"0055"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0048","num":"0056"},"figref":"FIG. 19A"},{"@attributes":{"id":"p-0049","num":"0057"},"figref":"FIG. 19B"},{"@attributes":{"id":"p-0050","num":"0058"},"figref":"FIG. 19C","b":"242"},{"@attributes":{"id":"p-0051","num":"0059"},"figref":"FIG. 20A"},{"@attributes":{"id":"p-0052","num":"0060"},"figref":["FIG. 20B","FIG. 20A"]}]},"DETDESC":[{},{}]}
