---
title: Providing shared memory in a distributed computing system
abstract: A distributed computing system includes a plurality of processors and shared memory service entities executable on the processors. Each of the shared memory service entities is associated with a local shared memory buffer. A producer is associated with a particular shared memory service entity, and the producer provides data that is stored in the local shared memory buffer associated with the particular shared memory service entity. The shared memory service entities propagate content of the local shared memory buffers into a global shared memory, wherein propagation of content of the local shared memory buffers to the global shared memory is performed using a procedure that relaxes guarantees of consistency between the global shared memory and the local shared memory buffers.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08024529&OS=08024529&RS=08024529
owner: Hewlett-Packard Development Company, L.P.
number: 08024529
owner_city: Houston
owner_country: US
publication_date: 20090528
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","DETAILED DESCRIPTION"],"p":["A distributed computing environment includes a number of computing nodes, where each computing node can include one or more processors on which software modules execute. Data produced by some of the software modules can be retrieved by other software modules in the distributed computing environment.","To improve performance in the distributed computing environment, a shared memory can be implemented, where data produced by software modules can be stored for retrieval by other software modules. However, conventional shared memory architectures have various issues, including relatively high cost and\/or inability to scale efficiently as the size of the computing environment is increased.","A distributed computing environment or system typically includes a number of computing nodes. More generally, a \u201cdistributing computing environment\u201d refers to any environment that has multiple processors on which software processes are executable. Examples of software processes include producers and consumers, where producers produce data for consumption by the consumers. To improve performance and simplify programming in a distributed computing environment, a shared memory can be provided as a means of sharing data between producers and consumers. Producers can store data into the shared memory, and consumers can retrieve data from the shared memory. As used here, the term \u201cmemory\u201d refers to dynamic RAM (random access memory) or a semiconductor storage device (such as a solid-state SSD device), and\/or any other type of storage.","Conventionally, a shared memory architecture can be hardware-based or software-based. One example of a hardware-based shared memory architecture is the Non-Uniform Memory Access (NUMA) architecture, which employs specialized hardware to support a shared memory in the distributed computing environment. Although hardware-based shared memory architectures provide relatively high performance, they tend to be relatively expensive.","Another type of shared memory architecture is a conventional symmetrical multiprocessor shared memory architecture. Although a symmetrical multiprocessor shared memory architecture may be more cost-effective than the hardware-based shared memory architecture discussed above, such an architecture may not scale efficiently as additional entities (e.g. producers and\/or consumers) are added to the distributed computing environment.","In accordance with some embodiments, a software-based loosely coupled shared memory architecture is provided that employs shared memory services that cooperate within the distributed computing environment to provide a shared memory. Producers and consumers in the distributed computing environment are able to access (write or read) the shared memory using the such shared memory services. A \u201cshared memory service\u201d is a software entity that is executable on processors in the distributed computing environment. In the ensuing discussion, such entities are referred to as \u201cshared memory service entities.\u201d","A collective of the shared memory service entities provides an abstraction of the shared memory to the producers and consumers of the distributed computing environment. A producer or consumer can register with the corresponding local shared memory service entity, which allows the producer or consumer to access the shared memory. A producer provides data to be written to the global shared memory, which a consumer retrieves from the global shared memory. Note that a process can be both a producer and a consumer.","The shared memory service entities are each associated with a local shared memory buffer, which is a region of memory in a computing node on which the corresponding shared memory service entity is provided. The shared memory service entities are defined to be part of a collective such that the content of the local shared memory buffers is propagated to a global shared memory on an intermittent basis. Intermittently propagating content of local shared memory buffers to the global shared memory refers to propagation that can be performed periodically, on-demand, or based on other events.","The propagation of the content of the local shared memory buffers to the global shared memory is performed using a procedure that relaxes guarantees of consistency between the global shared memory and the local shared memory buffers. The synchronization of the content of the local shared memory buffers with the global shared memory is performed on a gradual basis such that at any given point in time, it is possible that data in at least one of the local shared memory buffers may be inconsistent with data in the global shared memory. Thus, consumers of the content of the global shared memory may retrieve data that may be inconsistent with corresponding data that may have been recently updated in one of the local shared memory buffers (such as due to a write operation that has not yet been propagated to the global shared memory). The relaxation of guarantees of consistency allows for a more efficient shared memory architecture that scales more easily and that does not consume large amounts of processing bandwidth of the distributed computing environment. The synchronization of content of local shared memory buffers with the global shared memory can be performed as a background process, such that other software processes in the distributed computing environment have higher priority access of computing resources. By performing the synchronization in the background, consumers will not be blocked until synchronization is completed. This can enhance performance in a distributed environment with a relatively large number of producers and consumers.",{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 1","FIG. 1","FIG. 1"],"b":["100","1","100","2","100","100","1","100","2","100","102","102","104","102","104","102","112","102"],"sub":["\u2014","\u2014"],"i":["n","n "]},"On an intermittent basis, the content of the local LGSM buffers  in the LGSM services _, _, . . . is propagated to a global LGSM buffer  (which is the global shared memory discussed above). In the embodiment of , a copy of the global LGSM buffer  is associated with each LGSM service _, _, . . . . In the implementation of , each LGSM service  is associated with a global LGSM buffer  that contains an aggregation of all local LGSM buffers . The LGSM services  are able to communicate with each other over a network .",{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 1","FIG. 1","FIG. 1"],"b":["108","106","108","110","108","114","114","110","108","100","1","100","2","100"],"sub":"\u2014","i":"n"},"In one embodiment, the LGSM services _, _, . . . can employ collective operations associated with the Message Passing Interface (MPI), which is a specification for an application programming interface (API) that allows the LGSM services to communicate with each other. In such implementation, the collective of the LGSM services _, _, . . . is an MPI collective, which is a set of replicated MPI processes that are synchronized by the MPI infrastructure such that their respective memories are consistent. In one example, MPI collective operations that can be used include MPI_Gather or MPI_Allgather operations. The MPI_Gather operation is used to gather data associated with a group of software processes, while MPI_Allgather operation is used to gather data associated with all software processes. More generally, a \u201cgather\u201d operation refers to a pull-type operation in which consumers pull data from producers through the global shared memory.","Alternatively, if the producers and consumers are implemented with the same (common) executable code image, then MPI_Scatter operation can be used, which scatters the data from the producer's memory to the set of relevant consumers' memories in one step (as discussed with respect to  below). Producers and consumers being implemented with the same executable code image means that the producers and consumers are created using the same software code. The specification that MPI_Scatter can only be used with producers and consumers that execute the same executable code image is provided by the MPI specifications\u2014note, however, that other RDMA IPC paradigms can provide the equivalent of MPI_Scatter to be used even if producers and consumers do not execute the same executable code image. During execution, whether such software code behaves as a producer or a consumer is based on a configurable setting that causes different parts of the software code to be executed (where one part performs tasks of a producer while another part performs tasks of a consumer). A scatter operation, such as an MPI_Scatter operation, causes data from a producer to be propagated (scattered) to a set of consumers (note that different portions of the data from the producer can be sent to different consumers in the set).","If the producers and consumers are implemented with different executable code images, then the MPI_Scatter operation cannot be used; instead, the MPI_Gather operation discussed above can be used.","In one specific implementation, the link  between the LGSM services _, _, . . . is MPI over Infiniband (which is a switched fabric communications link). In other implementations, the link  can be any RDMA (Remote Direct Memory Access)-based link. RDMA allows data on one computing node to move to another computing node without involving the operating systems of the computing nodes. Thus, synchronization of data between the LGSM buffers  and the global LGSM buffer  can be performed at a low level, on a gradual basis, that does not consume too much processing resource in computing nodes of the distributed computing environment.","Once a producer  or consumer  registers with its respective LGSM service, a unique name (e.g., handle) of the LGSM service is returned to the producer or consumer. In subsequent operations, the producer and consumer will refer to the LGSM service by the unique name.","Each producer  and consumer  writes to and reads from, respectively, its respective local memory buffer ( or ) once the producer and consumer have linked the local memory buffer to the LGSM service. Each producer  writes its individual data to its local memory buffer , which is provided to the LGSM service, while each consumer  is able to read the aggregation of all of the producers' data through the global LGSM buffer .","In some embodiments, data produced by the producers  and stored in their local memory buffers  can be propagated to the corresponding LGSM service every predefined fixed time interval. Consumers  can be updated periodically or on demand. The propagation of data between a producer or consumer and an LGSM service can also employ MPI operations.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 2","FIG. 2"],"b":["200","1","200","2","200","204"],"sub":"\u2014","i":"n"},"Each of the nodes _, _, . . . includes producers  that are executable on corresponding CPUs . Although  shows one producer executable on one CPU, it is noted that there can be multiple producers executable on a CPU.","The CPUs  are connected to storage media  in the corresponding computing node. In addition, each of the computing nodes _, _, . . . includes a corresponding LGSM service _, _, . . . In the example of , there is one LGSM service per computing node. In a different implementation, some of the computing nodes can be implemented without an LGSM service.","Each computing node _, _, . . . also includes a network interface  to allow the computing node to communicate over an interconnect network , such as a local area network (LAN), a wide area network (WAN), the Internet, and so forth.","Another computing node is also connected to the interconnect network . The computing node includes consumers  executable on corresponding CPUs , which are connected to storage media . The computing node also includes an LGSM service to which the consumers  are registered. The computing node includes a network interface  to communicate over the interconnect network .","In one exemplary application of the distributed environment shown in , the producers  can be statistics collectors that collect statistics regarding the computing nodes _, _, . . . or statistics about data stored in such computing nodes. The statistics provided by such producers  are propagated to the global LGSM buffer  through the local memory buffers  of the producers and the local LGSM buffers  (). The local memory buffers , local LGSM buffer , and global LGSM buffer  can be stored in the storage media  of the computing nodes.","In this exemplary application, the consumers  can be workload managers that decide how workloads in the distributing computing environment are to be assigned to corresponding computing nodes. The workloads can be workloads associated with database queries or other types of workloads. The workload managers can decide whether or not to allow an incoming workload to be executed immediately, or to queue the incoming workload for later execution, which can be decided based on the priority of the incoming workload and the current resource utilization of the distributed computing environment. To make the decisions regarding assignment of incoming workloads, the workload managers (consumers ) has to be able to access statistics provided by the statistics collectors (producers ) using the global LGSM buffer .","As shown in , the number of network connections between consumers and producers is relatively small. For each producer, there is one connection to the corresponding local LGSM service entity. Similarly, for each consumer, there is one connection between the consumer and the LGSM service. Thus, given M producers and N consumers, there will be M+N connections. In contrast, using traditional point-to-point IPC (inter-process communication) will involve M\u00d7N IPC connections between producers and consumers to allow for proper data sharing between producers and consumers, which increases complexity of the IPC connections management (i.e., setting up and releasing these connections), and reduces the ability to scale efficiently as new producers and\/or consumers are added.",{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIG. 3","FIG. 3","FIG. 3","FIG. 3"],"b":["310","308","310","302","306","302","306","310"]},"The disk processes  retrieve data from the storage devices  and provide the data to the first layer of executor server processes . The first layer of executor server processes  then provides a first set of database operators. The results provided by the first layer of executor server processes  are then provided to the second layer of executor server processes  through connections .  also shows an application process  that can request transactions to be performed by the executor server processes , , and the disk processes . For example, the application process  can be a database management application.","In the example in , the second layer of executor server processes  can be considered to be consumers, while the first layer  of executor server processes can be considered to be producers. Conventionally, assuming that there are N executor server processes in the layer , and M executor server processes in the layer , M\u00d7N connections  between the executor server processes  and  would have to be provided. However, according to an embodiment, the M\u00d7N connections  can be replaced with an LGSM architecture  similar to that shown in  and would employ only (M+N) IPC connections.",{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 4","b":["400","100","102","108","400","402","102","108","100"]},"Examples of API routines  and the API  that can be invoked by the producer  include the following. An LGSM_open( ) routine can be invoked by the producer  to establish a connection (e.g., an MPI connection) with the LGSM service . An LGSM_add( ) routine can be invoked to register the producer  with the LGSM service . An LGSM_put( ) routine can be called by the producer  to copy the local memory buffer  () of the producer  to the local LGSM buffer  (). An LGSM_drop( ) routine can be called by the producer  to un-register the producer from the LGSM service. An LGSM_close( ) routine can be used to close the connection with the LGSM service.","The consumer  can also call the LGSM_open( ) routine to establish a connection with the LGSM service . Moreover, the consumer  can call an LGSM_IOCTL( ) routine to refresh or set a local context. The local context can be set by the consumer  to identify a subset of the producers  from which the consumer is interested in obtaining data. Such a subset can be identified in the context. Refreshing the local context will allow added or dropped producers of the subset to be identified.","An LGSM_get( ) routine is called by the consumer  to retrieve data from the global LGSM buffer . The LGSM_close( ) routine can be called by the consumer  to close a connection with the LGSM service.","Although specific API routines that have been identified above, it is noted that such routines are provided for purposes of example only. In other implementations, other or additional API routines can be used.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 5","FIG. 5","FIG. 1","FIG. 1"],"b":["100","102","108","502","104","102","112","104","112"]},"Another task performed by the LGSM service  is the propagation (at ) of the content of its local LGSM buffer  to the global LGSM buffer . This can be performed on a periodic basis, such as by using an MPI operation (e.g., MPI_Gather, MPI_Allgather). The propagation of content of local LGSM buffers  to the global LGSM buffer  can be performed once every predefined time interval, where the time interval is configurable to different values. By using MPI operations, the synchronization of data between the local LGSM buffers  and the global LGSM buffer  is performed at a low level using RDMA operations that involve controllers (such as controllers of the network interfaces  of the computing nodes in ). The actual transfer of data between the local LGSM buffers  and the global LGSM buffer  does not involve the operating systems  of the computing nodes, which reduce consumption of processing resources during the synchronization process.","In response to requests from a consumer  (or periodically), the LGSM service  can copy (at ) data from the global LGSM buffer  to the local memory buffer  () of the consumer . For example, this can be in response to the MPI_Get( ) routine invoked by the consumer .","In another embodiment, if the producers  and consumers  of the distributed computing environment are implemented with the same executable code image, then an MPI_Scatter operation can be employed to propagate data of a producer to a set of consumers (where the set of consumers can be all consumers in the distributed computing environment or some subset of consumers who have indicated an interest in data output by the producer).","As shown in , a producer  invokes (at ) a scatter operation, such as an MPI_Scatter operation. The invoked scatter operation causes data in the local memory buffer  of the producer  to be scattered (at ) to the set of consumers . Scattering of the data of the producer  is performed by propagating the data through connections provided between the producer \/consumers  and the LGSM services, as discussed above. Note that even with the scatter operation, there can be the possibility of a consumer reading un-synchronized data since the propagation of the data of the producer between the local shared memory buffers  of the LGSM services  is performed as a background process to the global shared memory.","By employing the shared memory paradigm according to some embodiments, a more efficient communication or sharing paradigm is provided in a distributed computing environment. The LGSM services of the shared memory paradigm provides an abstraction that effectively decouples producers from consumers, which allows for easier scaling as producers and consumers are added or dropped.","The LGSM shared memory paradigm according to some embodiments allows data to be exchanged without using global semaphores or mutexes (which are mechanisms for preventing concurrent access of a common resource). In some embodiments, local serialization can be enforced by using local synchronization features provided by MPI. Thus, the local LGSM buffer can be accessed by producers and the LGSM service without employing a global semaphore or mutex. Similarly, the global LGSM buffer can be accessed by a collective operation and by a consumer without employing a global semaphore or mutex. As a result, a consumer can efficiently retrieve data from the local copy of the global LGSM buffer into the local memory buffer of the consumer.","Also, since there is a local connection between each producer or consumer and the respective LGSM service, the LGSM service can detect failure of the producer or consumer and can easily perform cleanup operations should a producer or consumer fail. When the failed producer or consumer later comes back up, the producer or consumer can simply perform another registration operation.","Instructions of software described above (including the producers , consumers , and LGSM services  of ) are loaded for execution on a processor (such as one or more CPUs  in ). The processor includes microprocessors, microcontrollers, processor modules or subsystems (including one or more microprocessors or microcontrollers), or other control or computing devices. As used here, a \u201cprocessor\u201d can refer to a single component or to plural components (whether software or hardware).","Data and instructions (of the software) are stored in respective storage devices, which are implemented as one or more computer-readable or computer-usable storage media. The storage media include different forms of memory including semiconductor memory devices such as dynamic or static random access memories (DRAMs or SRAMs), erasable and programmable read-only memories (EPROMs), electrically erasable and programmable read-only memories (EEPROMs) and flash memories; magnetic disks such as fixed, floppy and removable disks; other magnetic media including tape; and optical media such as compact disks (CDs) or digital video disks (DVDs). Note that the instructions of the software discussed above can be provided on one computer-readable or computer-usable storage medium, or alternatively, can be provided on multiple computer-readable or computer-usable storage media distributed in a large system having possibly plural nodes. Such computer-readable or computer-usable storage medium or media is (are) considered to be part of an article (or article of manufacture). An article or article of manufacture can refer to any manufactured single component or multiple components.","In the foregoing description, numerous details are set forth to provide an understanding of the present invention. However, it will be understood by those skilled in the art that the present invention may be practiced without these details. While the invention has been disclosed with respect to a limited number of embodiments, those skilled in the art will appreciate numerous modifications and variations therefrom. It is intended that the appended claims cover such modifications and variations as fall within the true spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Some embodiments of the invention are described with respect to the following figures:",{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
