---
title: Reinforced clustering of multi-type data objects for search term suggestion
abstract: Systems and methods for related term suggestion are described. In one aspect, relationships among respective ones of two or more multi-type data objects are identified. The respective ones of the multi-type data objects include at least one object of a first type and at least one object of a second type that is different from the first type. The multi-type data objects are iteratively clustered in view of respective ones of the relationships to generate reinforced clusters.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07689585&OS=07689585&RS=07689585
owner: Microsoft Corporation
number: 07689585
owner_city: Redmond
owner_country: US
publication_date: 20040415
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Classification of Low FOO Terms","CONCLUSION"],"p":["This patent application is related to the following patent applications, each of which are commonly assigned to assignee of this application, and hereby incorporated by reference:\n\n","This disclosure relates to data mining, and more particularly to clustering of heterogeneous objects to enhance systems and methods for search term suggestion.","A keyword or phrase is a word or set of terms submitted by a Web surfer to a search engine when searching for a related Web page\/site on the World Wide Web (WWW). Search engines determine the relevancy of a Web site based on the keywords and keyword phrases that appear on the page\/site. Since a significant percentage of Web site traffic results from use of search engines, Web site promoters know that proper keyword\/phrase selection is vital to increasing site traffic to obtain desired site exposure. Techniques to identify keywords relevant to a Web site for search engine result optimization include, for example, evaluation by a human being of Web site content and purpose to identify relevant keyword(s). This evaluation may include the use of a keyword popularity tool. Such tools determine how many people submitted a particular keyword or phrase including the keyword to a search engine. Keywords relevant to the Web site and determined to be used more often in generating search queries are generally selected for search engine result optimization with respect to the Web site.","After identifying a set of keywords for search engine result optimization of the Web site, a promoter may desire to advance a Web site to a higher position in the search engine's results (as compared to displayed positions of other Web site search engine results). To this end, the promoter bids on the keyword(s) to indicate how much the promoter will pay each time a Web surfer clicks on the promoter's listings associated with the keyword(s). In other words, keyword bids are pay-per-click bids. The larger the amount of the keyword bid as compared to other bids for the same keyword, the higher (more prominently with respect to significance) the search engine will display the associated Web site in search results based on the keyword.","Conventional systems and techniques to identify bid term(s) relevant to Web site content typically use clustering algorithms to partition a set of objects into groups, or clusters in such a way that objects from the same cluster are similar and objects from different clusters are dissimilar. Such clustering approaches assume that data objects to be clustered are independent and of identical class, and are often modeled by a fixed-length vector of feature\/attribute values. In the recent surge of data mining research, this classical problem has been re-examined in the context of large databases. However, homogeneity of data objects to be clustered seems still the basic assumption, even though some emerging applications, such as Web mining and collaborative filtering, propose challenges to such an assumption. In such applications, data objects are of different types and are highly interrelated. Unfortunately, even though objects distributed across heterogeneous object types may be highly interrelated, conventional clustering operations typically cluster respective object types individually and without consideration of any interrelated aspects of different object types.","One reason for this is because relationships between data objects of different type are often sparse and difficult to identify. Another reason is because representation of any such relationships with a static fixed-length value vector attached to respective objects, wherein the vector represents both object attributes and attributes of a related object of a different type, would create object attribute\/feature vectors with a very high dimensionality (feature space). Such high dimensionality is not desirable because the data will be far apart from each other in the feature space, and efficient models cannot be sufficiently trained with such a sparse amount of data in small regions.","Accordingly, better clustering techniques to identify and group related objects (e.g., terms) in view of relationships across heterogeneous data objects would be useful. These clustering techniques could be used, for example, to provide systems and methods that identify term(s) for search engine optimization and term bidding, and thereby provide both with a substantially higher probability of identifying relevant term(s).","Systems and methods for related term suggestion are described. In one aspect, intra-layer and\/or inter-layer relationships among respective ones of two or more multi-type data objects are identified. The respective ones of the multi-type data objects include at least one object of a first type and at least one object of a second type that is different from the first type. The multi-type data objects are iteratively clustered in view of respective ones of the relationships to generate reinforced clusters.","Overview",{"@attributes":{"id":"p-0019","num":"0020"},"figref":"FIG. 1","b":["100","100","102","102","1","102","102"],"sub":["1 ","j ","1 ","k "]},"In this implementation, for example:\n\n","Lines\/links extending between a pair of data objects represent respective mined relationships determined to exist between the respective data objects. In certain embodiments of clustering, the lines\/links are referred to as \u201cedges\u201d. The generalized term line or link is used in this disclosure to describe links, edges, or any connector of one object to another object that describes a relationship between the objects. Link direction (as provided by the arrowheads indicating that a relationship between data objects) may be directed in either direction as a function the participating objects attributes. The links are considered illustrative and not limiting in scope. Certain links in a Web environment such as represented by framework  may be more appropriately directed in one direction, and the direction of the arrowhead typically will not affect the following described reinforced clustering operations.","Links between object pairs can be classified as being intralayer or interlayer links. An intralayer link is illustrative of an identified relationship between different objects of the same type. As such intralayer links  connect objects within a same layer . For instance, solid line  between a respective pair of data objects represents an intralayer link. In this example, an intralayer link extends from a Web page object uto another Web page object u, and represents relation(s) between different Web pages.","An inter-layer link describes relationships between data objects of different types. Since interlayer links extend between respective ones of a pair of heterogeneous objects, each of the participating pair of data objects is shown on a different respective data object\/node set layer . As shown in , any line connecting a pair of objects that is not a solid line is an interlayer link. E.g., link  is indicative of a reference (e.g., a hyperlink) from a first of a pair of objects to a second of the pair of objects, link\/line  is indicative of an issue shared\/referenced (e.g., subject matter) from a first of a pair of objects to a second of the pair of objects, link\/line  is indicative of a browse link from a first of a pair of objects to a second of the pair of objects. In another example, a link may extend from a user object wto a search query object pand to a Web page object u, and represent the user submitting a query that returns a Web page selected a relevant by the user.","In the example of , and as shown by respective ones of the intra and interlayer links, the different objects types (p, u, w, . . . ) are related. For example, a user (represented by objects w) issues queries (objects p); the user browses web pages (objects u) returned by a search engine responsive to receipt of the issued queries; and each search query (object p) references one or more respective Web pages (objects u). In view of this, when Web user information is clustered, Web page(s) a user has browsed and queries used to obtain the respective Web page(s) should have more similarity and tend to be clustered together in the clustering process. Similarly, when clustering Web pages, it should also be taken into consideration how the Web pages are used by users and referenced by respective search queries. To address this, as described below, a reinforced clustering algorithm clusters such heterogeneous data objects as a function of mined relationships between respective ones of the data objects.","One aspect of this disclosure is based on an intrinsic mutual relation, wherein objects being clustered are provided with links to other objects. Certain ones of the links (and the objects to which those links connect) that connect to each object can be weighted with different importance to reflect their relevance to that object. For example, objects of the same types as those being clustered can be provided with greater importance than objects of a different type. This disclosure provides a mechanism by which varying levels of importance can be assigned to different objects or different types of objects. This assigning of different levels of importance to different objects (or different types of objects) is referred to herein as clustering with importance. The varying levels of importance of the different objects often results in improved clustering results and effectiveness. These and other aspects of reinforced clustering of multi-type data objects for search term suggestions are now described.","Term(s)\/keyword(s) relevant to a Web site and determined to be used more often in generating search queries by end users are generally selected by Web site promoters\/advertisers for search engine result optimization with respect to the Web site. With this in mind, the following disclosed systems and methods mine multi-type data objects determined to be interrelated to the task at hand, which in this implementation, is search term suggestion. Such multi-type data objects include term(s) of mined historical search queries that have been enhanced with semantic context (e.g., text, URLs, result titles, and short descriptions of each result, etc.) mined from results obtained by submitting the historical queries to a search engine, a set of Web pages selected by a user responsive to a particular historical search query, information specific to the user (e.g., the user's Web site access information, IP address of the machine used to generate the search query, etc.), and\/or types of related data objects.","Similarity between these multi-type data objects is determined as a linear combination of identified and weighted content similarity and calculated inter-object and intra-object relationship similarities. The data objects are assigned different weights by analyzing the link structure derived from the inter-object and intra-type relationships. Thus, the similarity between respective ones of the data objects includes not only the similarity of their own attributes but also the similarity of their relationships.","In view of these calculated multi-type object relationships, a reinforced clustering algorithm iteratively clusters the multi-type data objects as a function of each object's identified inter and intra-object relationship attributes. In this implementation, a modified direct-k-means clustering algorithm is used to determine the cluster centroids by using the weighted sum of the objects in the cluster. This is an iterative process that propagates clustering results to all related data objects by updating their respective relationship attributes. That is, the clustering results of one type of object forms a new feature space, which is then projected and propagated to other related but different types of objects. Then clustering on related types of objects is performed with this updated feature space. This iterative reinforcement process is executed on each object types to merge substantially related cluster nodes to reduce feature space dimensionality, and continued until clustering results across all multi-type objects have converged. This results in reinforced clusters of substantially highly related multi-type data objects.","Responsive to receiving a term from an end-user, the systems and methods compare the term(s) to respective ones of the term(s) in the reinforced clusters based on a term\/query object type. Since the reinforced term clusters include term(s) that are contextually related to one another, when the submitted bid is compared to the terms within the clusters, the term phrase is evaluated in view of any multiple related contexts, or \u201csenses.\u201d Moreover, since each reinforced term cluster is derived from sets of highly related multi-type objects, the algorithm can overcome the flaws of pure content-based method, i.e. efficiently reinforce the semantic relationships between query terms and restrain the impact of noise in the term context. Responsive to comparing the received term to feature spaces of objects in the reinforced clusters, one or more search term suggestions are identified. These search term suggestions are communicated to the end-user.","An Exemplary System","Although not required, the invention is described in the general context of computer-executable instructions (program modules) being executed by a personal computer. Program modules generally include routines, programs, objects, components, data structures, etc., that perform particular tasks or implement particular abstract data types. While the systems and methods are described in the foregoing context, acts and operations described hereinafter may also be implemented in hardware.",{"@attributes":{"id":"p-0031","num":"0036"},"figref":"FIG. 2","b":["200","200","202","204","206","208","206","202","202","210","206","208","204","200","206"]},"EVS  includes a number of computer-program modules to generate suggested term list . The computer-program modules include, for example, search term suggestion (STS) module . In this implementation, and for purposes of discussion and exemplary illustration, the STS module  is described as performing multiple functions such as historical query term mining, Web page retrieval, feature extraction, feature space dimension reduction and normalization, reinforced clustering of multi-type data objects, matching user bid term(s) to contents of reinforced clusters to perform search term suggestion, and term classification. It can be appreciated that respective ones of these operations could be performed by one or more other computer program modules (not shown) in communication with STS module .","Enhancing Mined Historic Search Queries d with Semantic Context","STS module  mines multi-type data objects (MDOs)  determined to be interrelated to the task at hand, which in this implementation, is search term suggestion. Such multi-type data objects  include term(s) of mined historical search queries , which will be enhanced by STS module  with semantic context (e.g., text, URLs, result titles, and short descriptions of each result, etc.) mined from search results obtained by submitting respective ones of the historical queries  to a search engine, and \u201cother MDOs\u201d  such as a set of Web pages selected by a user responsive to a particular historical search query, information specific to the user (e.g., the user's Web site access information, IP address of the machine used to generate the search query, etc.), and\/or types of related multi-type data objects.","In particular, STS module  retrieves a set of historical queries  from query log(s) . The historical queries  include search query terms previously submitted by one or more users to a search engine. STS module  evaluates historical queries  as a function of frequency of occurrence to identify high frequency of occurrence (FOO) search terms  and relatively lower frequency of occurrence search terms . In this implementation, a configurable threshold value is used to determine whether a historical query has a relatively higher or low frequency of occurrence. For example, search query terms in historical queries  that occur at least a threshold number of times are said to have a high frequency of occurrence. Analogously, search query terms in historical queries  that occur less than the threshold number of time are said to have a low frequency of occurrence. For purposes of illustration, such a threshold value is shown as a respective portion of \u201cother data\u201d .","STS module  mines semantic\/contextual meaning high frequency of occurrence query terms  by submitting each query, one-by-one (search query ), to search engine . Responsive to receiving search query , search engine , returns a ranked listing (whose number is configurable) in search result(s)  to STS module . The ranked listing includes URLs, result titles, and short descriptions and\/or contexts of query term related to the submitted search query . The ranked listing is stored in the search results . Such search result retrieval is done for each search query .","STS module  parses Web page Hypertext Markup Language (HTML) to extract the URLs, result titles and short descriptions and\/or contexts of the query term for each query term  from each retrieved search result(s) . The URLs, result titles, short descriptions and\/or contexts of the query term, and the search query  used to obtain the retrieved Search result(s)  are stored by STS module  in a respective record of extracted features .","After parsing search results  for the high frequency of occurrence query terms , STS module  performs text preprocessing operations on extracted features  to generate linguistic tokens (tokenize) from the extracted features into individual keywords. To reduce dimensionality of the tokens, STS module  removes any stop-words (e.g., \u201cthe\u201d, \u201ca\u201d, \u201cis\u201d, etc.) and removes common suffixes to normalize the keywords, for example, using a known Porter stemming algorithm. STS module  arranges the resulting extracted features  into one or more term based multi-type data object (MDO) vectors .","Each term based multi-type data object vector  has dimensions based on term frequency and inverted document frequency (TFIDF) scores. A weight for the ivector's jkeyword is calculated as follows:\n\n\u00d7log()\n\nwherein TFrepresents term frequency (the number of occurrences of keyword j in the irecord), N is the total number of query terms, and DFis the number of records that contain keyword j.\n","Given the vector representation of each query term, a cosine function is used to measure the similarity between a pair of terms (recall that the vectors were normalized):",{"@attributes":{"id":"p-0041","num":"0046"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"sim","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["q","j"]},{"mi":["q","k"]}],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"d"},"mo":"\u2062","mrow":{"msub":[{"mi":"w","mrow":{"mi":["i","j"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mi":"w","mrow":{"mi":["i","k"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":"\u00b7"}}],"mo":"="}}},"br":[{},{},{}],"in-line-formulae":[{},{}],"i":["q",", q","q",", q"],"sub":["j","k","j","k"],"b":["226","210"]},"Mining User Selected Web Page(s) and User Information","To identify a substantially most relevant set of term(s) for search engine result optimization of a Web site (search term suggestion), STS module  mines multi-type data objects  that are different\/heterogeneous than the historical queries . For purposes of discussion, these mined objects are represented as \u201cother MDOs\u201d . In one implementation, \u201cother MDOs\u201d  include, for example, end-user selected Web pages and\/or user specific information, wherein the user is one associated with submitting a historical query  to a search engine . STS module  extracts end-user selected Web pages from query log(s) . The end-user selected Web pages may or may not be sparse, wherein sparse averages, for example, two (2) to three (3) Web pages per historical query . STS module  extracts user specific information from query log(s) , or from other data sources. User specific information includes, for example, Internet Protocol (IP) address of the machine used to submit respective ones of the historical queries , GUID, and\/or Web site access information (e.g., Microsoft's .net Passport information).","Reinforced Multi-Type Data Object Clustering","STS module  fully explores relationships between multi-type interrelated data objects (MDOs ) for clustering analysis. Multi-type data objects  include n different types of objects X, X, . . . , X(e.g., historical queries  and \u201cother MDOs\u201d ). Each type of data object Xis described by a set of features F. Data objects within the same type are interrelated with intra-type relationships RX\u00d7X. Data objects from two different types are related through inter-type relationships RX\u00d7X. To distinguish from the relationships, Fis referred to as content feature of data objects. For a specific object x\u2208X, we use x.Fto represent its content features, and use x.RXand x.RXto denote objects related to it in Xand X, respectively. The problem of clustering multi-type interrelated data objects is to partition each type of objects Xinto Kclusters so that the data objects in each cluster have high similarity, and objects from different clusters are dissimilar.","Considering that an object of multi-type data objects  has both content features and relationships with other object(s) in multi-type data objects , similarity between two objects is determined according to the following:\n\n\u2003\u2003(1)\n\nwhere sis content similarity, sand sare intra-type and inter-type similarities, respectively, \u03b1, \u03b2, and \u03b3 are weights for different similarities with \u03b1+\u03b2+\u03b3=1.\n","From (1), the similarity between two objects is a linear combination of content similarity and relationship similarities. By assigning different values to \u03b1, \u03b2, and \u03b3, STS module  can adjust\/configure the weights of different similarities in the overall similarity. For example, if \u03b1=1, \u03b2=\u03b3=0, similarity between content features is considered. By setting \u03b2=0, STS module  bypasses the effects of intra-type similarity.","Similarity in Equation 1 can be defined using different functions, usually determined by the types of objects and the applications. For example, content similarity between two web-pages could be defined as cosine function x\u2208Xy\u2208x.Rof the two keyword vectors derived from their contents.","A relationship feature of a particular object is represented by an MDO vector  whose entries correspond to its related objects. In one implementation, each entry is a numeric value corresponding to the weight of the relationship. For example, given two object types X={x, x, . . . x}, and Y={y, y, . . . y}, the inter-type relationship vector of object is defined as V=[v, v, . . . , v]where v\u22600 and if, and v=0 otherwise. Then the similarity Son inter-type relationship Rbetween the two objects in X could be also defined as the cosine function of the two vectors.","If objects in Xhave inter-type relationships with multiple data object types, the final inter-type relationship similarity could be the linear combination of all inter-type similarities.","With the defined similarity functions, STS module  identifies intralayer relationships\/links and interlayer links among historical queries  and \u201cother MDOs\u201d . Use of interlayer links in clustering recognizes that clustering of one type of object may be affected by another type of object. For example, clustering of web page objects may be affected by user object configurations, state, and characteristics. Accordingly, these mined intra and interlayer relationships are used to improve cluster quality of interrelated data objects, as described below. Mined inter-layer and intra-layer data object relationships are stored in each object's respective MDO vector .","In one implementation, identified inter-layer links\/relationships represent, for example, one or more of the following:\n\n","In one implementation, identified intra-layer links\/relationships (relationships between objects of a same data type) represent, for example one or more of:\n\n","With respect to links within queries, intralayer relationships indicated by links within queries represent links between an initial historical query  and\/or subsequent query refinements (also represented by respective ones of the historical queries ). In one implementation, such information is extracted from click-thru Web page information retrieved from query log(s) . More particularly, upon determining that initial search query results are not satisfactory, it is estimated that the user will submit one or more refined queries to a search engine  within a configurable amount of time from the time that the initial query was submitted. The configurable amount of time represents a query session. After one or more such search query term refinements, the user may obtains satisfactory search results. For example, consider that a user visits a product support Web site and submits an initial query of \u201ccookie\u201d. Upon determining that the search results are not satisfactory (e.g., too broad), the user may change\/refine terms of the query to \u201cenable cookie\u201d to obtain a more satisfactory search result.","In one implementation, STS module  identifies links within queries by segmenting one or more portions of query log(s)  into respective query sessions. Each query session may include an initial query, one or more query refinements, and possibly one or more Web page click-thru indications. To categorize an initial query and one or more associated query refinements, STS module  calculates term similarity between queries of each query session. Search queries meeting one or ore threshold criteria of similarity are selected for generating the links within queries and corresponding query refinements. In one implementation, query similarity is determined, for instance, using the exemplary operations described above in paragraph.","After mapping relationships among multi-type data objects  as relationship feature modeled in corresponding ones of the MDO vectors , each type of data objects could be clustered individually with conventional clustering techniques (i.e., not using the reinforced clustering operations disclosed herein). However, even though clustering data object individually may at first appear feasible, this technique is substantially limited and problematic. One reason for this is because the number of objects becomes very large, as the size of the feature vector for relationship will be very large. And similarity defined on relationship features, which is based on exact matching of related objects will suffer from the sparseness of non-zero entries. Another reason is because conventional clustering techniques do not consider that relationship(s) among data objects may not be fully reflected in features assigned to data objects, but may only be discovered during the clustering process itself. That is, existing clustering techniques do not consider that clustering operations in turn can provide structuralized information that is useful in reinforcing data in subsequent analysis\/clustering operations.","STS module  addresses these problems\/limitations of conventional clustering techniques at least by propagating clustering results of one data object type to all its related data object types by updating their respective relationship features. That is, STS module  generated reinforced clusters  by aggregating indicated data object relationship(s) to individual multi-type data objects  based on content of the reinforced clusters . For instance, if two candidate nodes exist following the clustering, the closest two candidate nodes can be merged, e.g., by averaging the vector values of the two candidate nodes. This merging allows individual nodes to be combined to reduce the number of nodes that have to be considered As such, dimensionality of the MDO vector(s)  is reduced. Then, STS module  clusters the MDO vector(s) . This process is iteratively performed until clustering results in all object types converge.","The iterative clustering projection technique relies on obtaining clustering information from separate types of objects that are arranged in separate layers, with each layer containing a homogenous type of object. The node information in combination with the link information is used to iteratively project and propagate the clustered results (the clustering algorithm is provided between layers) until the clustering converges. That is, each type of the different kinds of nodes and links are examined to obtain structural information that can be used for clustering. Structural information, for example, can be obtained considering the type of links connecting different data objects (e.g., whether a link is an inter-layer link or an intra-layer link). Iteratively clustering results of one type of object into the clustering results of another type of object can reduce clustering challenges associated with data sparseness. With this iterative projecting, the similarity measure in one layer clustering is calculated on clusters instead of individual groups of clusters of another type.","For example, in view of two object types X={x, x, . . . x}, and Y={y, y, . . . y} to illustrate the process. STS module  first clusters the objects in Y into k clusters, denoted by {C, C, . . . , C} using any traditional clustering method. Recall that an MDO vector , which includes a relationship feature vector of x\u2208X, is originally defined as V=[v, v, . . . , v]with each component corresponding to one object in Y. With clusters in Y, we replace the Vby V\u2032=[v\u2032, v\u2032, . . . , v\u2032]with each component corresponding to one cluster of Y and v\u2032 is non-zero if x.R\u2229C\u2260\u03a6. The numeric value of v\u2032 could be set to |x.R\u2229C|, which represent the number of relationships from object x to objects in cluster C, or other values such as the importance of the associated objects (object importance is described below). Then the clustering of object in X is based on the new inter-type relationship feature. The process will continue by iteratively project the clustering results of one type to another by their inter-layer relationship until converge.","The advantage of the above reinforced clustering algorithm is that the clustering results not only reflect the data distribution from the content, but also reflect the relationships with other data types. It may also solve the data sparseness problem to some extent. Compared to existing clustering approaches which define similarity on fixed feature space, the described systems and methods for reinforced clustering of multi-type data objects updates similarity between two objects during the clustering process to adapt to the new discovered relationship feature space. Furthermore, in one implementation, any traditional clustering algorithm can be embedded into this proposed framework to enhance clustering performance.","Link Analysis and Importance of Objects","For some data objects and applications, multi-type data objects  in the same type may have different importance in the clustering process. Typical examples include Web-page\/user clustering where certain Web pages are more important as they are authoritative pages, and item\/user clustering for collaborative filtering, etc. where some users should be more authoritative in determining the belongingness of items. If we view objects as nodes and view relationship(s) between objects as links, a conventional link analysis method, such as HITS algorithm, is used to calculate the eigen-values of each data object. However, when multiple types of data objects are involved, this method will not work since the importance of different types of objects is not comparable.","To address this problem, the described systems and methods for reinforced clustering of multi-type data objects extend the HITS algorithm as follows. We not only consider the mutual reinforcement of object importance within a type but also the mutual reinforcement between types. Each node is assigned a hub score and an authority score.","For simplicity, we continue to use the case which contains two types of interrelated objects as example to illustrate our proposed algorithm. Given two types of objects X={x, x, . . . x}, Y={y, y, . . . y} and relationships of R, R, Rand Rif directionality is considered. The adjacent matrixes are used to represent the link information. Land Lstand for the adjacent matrixes of link structures within set X and Y, respectively. Land Lstand for the adjacent matrixes of links from objects in X to objects in Y. For example, L(i, j)=1 if there is one link from node xto node y.","There are two levels of calculations: one is that the hub value and authority value of objects from same type reinforce each other by the intra-type relationships; and the other is that the importance of different types of nodes reinforces each other by inter-type relationships. The calculations in this approach are written as follows.",{"@attributes":{"id":"p-0066","num":"0077"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mo":"{","mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mi":"a","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"X"}},{"mrow":[{"mi":"\u03b2","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msubsup":{"mi":["L","X","T"]},"mrow":{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"X"}}},{"mrow":[{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"\u03b2"}},{"mi":"i","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}}],"mo":["\u2062","\u2062"],"msub":{"mi":["L","XY"]}}],"mo":"+"}],"mo":"="}}},{"mtd":{"mrow":{"mrow":[{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"X"}},{"mrow":[{"mi":"\u03b2","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["L","X"]},"mrow":{"mi":"a","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"X"}}},{"mrow":[{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"\u03b2"}},{"mi":"i","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}}],"mo":["\u2062","\u2062"],"msub":{"mi":["L","XY"]}}],"mo":"+"}],"mo":"="}}},{"mtd":{"mrow":{"mrow":[{"mi":"i","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"X"}},{"mrow":[{"mi":"a","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"X"}},{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"X"}}],"mo":"+"}],"mo":"="}}},{"mtd":{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mtd":{"mrow":{"mrow":[{"mi":"a","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}},{"mrow":[{"mi":"\u03b3","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msubsup":{"mi":["L","Y","T"]},"mrow":{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}}},{"mrow":[{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"\u03b3"}},{"mi":"i","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"X"}}],"mo":["\u2062","\u2062"],"msub":{"mi":["L","YX"]}}],"mo":"+"}],"mo":"="}}},{"mtd":{"mrow":{"mrow":[{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}},{"mrow":[{"mi":"\u03b3","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["L","Y"]},"mrow":{"mi":"a","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}}},{"mrow":[{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"\u03b3"}},{"mi":"i","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"X"}}],"mo":["\u2062","\u2062"],"msub":{"mi":["L","YX"]}}],"mo":"+"}],"mo":"="}}},{"mtd":{"mrow":{"mrow":[{"mi":"i","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}},{"mrow":[{"mi":"a","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}},{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}}],"mo":"+"}],"mo":"="}}}]}}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}},"br":{}},"At the beginning of the calculation, all vectors, a(X), h(X), a(Y) and h(Y) are initialized to 1. The hub score and authority score are updated using Equation (2) at each iteration. At the end of each iteration, the vectors will be normalized for the next iteration calculation. This algorithm provides a normalized and uniform importance within each object types and gets more reasonable result by considering the importance of the associated objects of other types through inter-type relationships.","Given the importance score of objects, the described reinforced clustering process is modified to reflect the importance of objects. In this implementation, k-means clustering algorithm is modified to weighted-k-means algorithm. That is, when calculating the cluster centroids, we use the weighted sum of cluster members as the new centroid such that a cluster is biased to those important objects.","In view of the above, STS module  differentiates importance of multi-type data objects based on both inter- and intra-type relationships among the multi-type data objects . This importance is incorporated into the clustering process","Exemplary Processing of a Bid Term","Responsive to receiving the term(s)  from an end-user (e.g., an advertiser, Web site promoter, etc), STS module  compares the term(s)  to respective ones of the terms\/phrases in the reinforced term clusters . Since reinforced term clusters  include terms that are not only contextually related to one another, but also semantically related to one another derived from their interrelationships to webpages and users, the term(s)  is evaluated in view of multiple related and historical contexts, or \u201csenses.\u201d","In one implementation, if STS module  determines that term(s)  matches a term(s) from a reinforced cluster , search term suggestion module  generates suggested term list  from the reinforced cluster . In this implementation, a match may be an exact match or a match with a small number of variations such as singular\/plural forms, misspellings, punctuation marks, etc. The returned list is ordered by a combination of FOO and confidence value.","In one implementation, if a term(s) matches a term from a cluster, the cluster is returned to the end-user in a suggested term list. The suggested term list  includes terms\/phrases determined to be semantically and\/or contextually related to the term(s), respective term(s) to term(s) similarity measurements (confidence values), and respective term(s) frequency of occurrence (FOO). The returned list  is ordered by a combination of FOO and confidence value.","If STS module  determines that term(s)  matches terms in multiple reinforced term clusters , search term suggestion module  generates multiple suggested term lists  from terms in the multiple ones of reinforced term clusters . The lists are ordered by the cluster sizes; and the terms within each list are ordered by a combination of FOO and confidence value.","If no matching clusters are identified, the query term is further matched against expanded clusters generated from query terms with low FOO. In one implementation, query terms with low FOO are clustered by training a classifier (e.g., a K-nearest neighbor classifier) for the reinforced term clusters  generated from the high frequency of occurrence historical query log terms. Historical query terms determined to have low frequency of occurrence are submitted, one-by-one, to the search engine. Features are then extracted from select ones (e.g., a first top-ranked Web page, and\/or so on) of the returned search results. The extracted features are normalized and used to represent the query terms with low FOO. The query terms are then classified into existing clusters to generate expanded clusters based on the trained classifier. The end-user submitted term(s) is then evaluated in view of these expanded clusters to identify and return a suggested term list to the end-user.","When reinforced term clusters  generated from high frequency of occurrence (FOO) query terms  do not include same terms to end-user input term(s) , STS module  generates trained classifier  from reinforced term clusters  generated from high frequency of occurrence (FOO) query log terms . The terms in reinforced term clusters  already have corresponding keyword vectors in a vector space model suitable for classification operations. Additionally, stop-word removal and word stemming (suffix removal) reduced dimensionality of term vectors  (upon which clusters  are based). In one implementation, additional dimensionality reduction techniques, for example, feature selection or re-parameterization, may be employed.","In this implementation, to classify a class-unknown query term , STS module  uses the k-Nearest Neighbor classifier algorithm to find k most similar neighbors in all class-known query terms , relying on their corresponding feature vectors, and uses the a weighted majority of class labels of the neighbors to predict the class of the new query term. Here each query term already in reinforced term clusters  is assigned a label same to their corresponding clusters' label, while each reinforced cluster  is labeled by simple sequence numbers. These neighbors are weighted using the similarity of each neighbor to X, where similarity is measured by Euclidean distance or the cosine value between two vectors. The cosine similarity is as follows:",{"@attributes":{"id":"p-0077","num":"0088"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":"sim","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"X","mo":",","msub":{"mi":["D","j"]}}}},"mo":"=","mfrac":{"mrow":[{"munder":{"mo":"\u2211","mrow":{"msub":{"mi":["t","i"]},"mo":"\u2208","mrow":{"mo":["(",")"],"mrow":{"mi":"x","mo":"\u22c2","msub":{"mi":["D","j"]}}}}},"mo":"\u2062","mrow":{"msub":[{"mi":["x","i"]},{"mi":"d","mrow":{"mi":["i","j"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":"\u00b7"}},{"msub":[{"mrow":{"mo":["\uf605","\uf606"],"mi":"X"},"mn":"2"},{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mi":["D","j"]}},"mn":"2"}],"mo":"\u00b7"}]}}}},"br":{},"sub":["j ","i ","j","i ","i ","ij ","i ","j","2","1","2","3","j","2 ","j"],"sup":["2","2","2"]},{"@attributes":{"id":"p-0078","num":"0089"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"label","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"X"}},{"munder":{"mrow":{"mi":["arg","max"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["l","i"]}},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"munder":{"mo":"\u2211","mrow":{"mrow":{"mi":["All","where"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["D","j"]},"mrow":{"mi":"lable","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["D","j"]}}}},"mo":"=","msub":{"mi":["l","i"]}}},"mo":"\u2062","mrow":{"mi":"sim","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"X","mo":",","msub":{"mi":["D","i"]}}}}}}}],"mo":"="}}}},"In another implementation, a different statistical classification and machine learning technique (e.g., including regression models, Bayesian classifiers, decision trees, neural networks, and support vector machines) other than a nearest-neighbor classification technique is used to generate trained classifier .","STS module  submits low frequency of occurrence (FOO) query terms , one-by-one (via a respective search query ), to search engine . Responsive to receiving search result(s)  associated with a particular search query , and using techniques already described, STS module  extracts features (extracted features ) from one or more retrieved search results  identified by the search result(s) . In this implementation, features are extracted from a first top-ranked Search result(s) . For each retrieved and parsed Search result(s) , STS module  stores the following information in a respective record of extracted features : the URLs, result titles, short descriptions and\/or contexts of the query term, and search query  used to obtain the retrieved Search result(s) . Next, STS module  tokenizes, reduces dimensionality, and normalizes extracted features  derived from low FOO query terms  to generate term vectors . Then, STS module  clusters the query terms into a respective set of term clusters . This clustering operation is performed using trained classifier  (generated from high FOO query terms ).","STS module  evaluates end-user submitted term(s)  in view of these expanded term clusters (generated based on low FOO query terms ) to identify and return one or more suggested term lists  to the end-user. An exemplary such procedure is described above, and in the following section.","An Exemplary Search Term Suggestion List","A suggested term list  includes, for example, term(s) determined to be related to the term(s) , respective term(s) to term(s)  similarity measurements (confidence values), and respective term(s) frequency of occurrence (FOO)\u2014frequency in the historical query log. Techniques for identifying related term(s), generating similarity measurements, and generating FOO values have been described above.","TABLE 1 shows an exemplary suggested term list  of terms determined to be related to term(s)  of \u201cmail.\u201d Terms related to term(s)  are shown in this example in column , titled \u201cSuggested Term.\u201d",{"@attributes":{"id":"p-0084","num":"0095"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"AN EXEMPLARY SUGGESTED TERM LIST FOR"},{"entry":"THE BID TERM \u201cMAIL\u201d"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Suggested Term","Similarity","Frequency","<Context>"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"hotmail","0.246142","93161","online e-"]},{"entry":[{},"yahoo","0.0719463","165722","mail related"]},{"entry":[{},"mail.com","0.352664","1455"]},{"entry":[{},"yahoo mail","0.0720606","39376"]},{"entry":[{},"www.mail.com","0.35367","711"]},{"entry":[{},"email.com","0.484197","225"]},{"entry":[{},"www.hot","0.186565","1579"]},{"entry":[{},"www.msn.com","0.189117","1069"]},{"entry":[{},"mail.yahoo.com","0.0962268","4481"]},{"entry":[{},"free email","0.230611","1189"]},{"entry":[{},"www.aolmail.com","0.150844","654"]},{"entry":[{},"check mail","0.221989","66"]},{"entry":[{},"check email","0.184565","59"]},{"entry":[{},"msn passport","0.12222","55"]},{"entry":[{},"www.webmail.aol.com","0.0200538","108"]},{"entry":[{},"webmail.yahoo.com","0.08789","71"]},{"entry":[{},"free email account","0.0234481","65"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"Suggested term","Similarity","Frequency",{}]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"mail","1","2191","Traditional"]},{"entry":[{},"usps","0.205141","4316","mail related"]},{"entry":[{},"usps.com","0.173754","779"]},{"entry":[{},"united parcel service","0.120837","941"]},{"entry":[{},"postal rates","0.250423","76"]},{"entry":[{},"stamps","0.156702","202"]},{"entry":[{},"stamp collecting","0.143618","152"]},{"entry":[{},"state abbreviations","0.104614","300"]},{"entry":[{},"postal","0.185255","66"]},{"entry":[{},"postage","0.180112","55"]},{"entry":[{},"postage rates","0.172722","51"]},{"entry":[{},"usps zip codes","0.138821","78"]},{"entry":[{},"us postmaster","0.109844","58"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}]}}},"Referring to TABLE 1, note that terms in the suggested term list are mapped to term similarity values (see, column , titled \u201cSimilarity\u201d) and frequency of occurrence scores (see, column , titled \u201cFrequency\u201d). Each term similarity value, calculated as described below in the section titled \u201cTerm Clustering\u201d, provides a similarity measure between a corresponding suggested term (column ) and the term(s) , which is \u201cmail\u201d in this example. Each frequency value, or score, indicates the number of times that the suggested term occurs in the historical query log. The suggested term list is sorted as a function of term similarity, and\/or frequency of occurrence scores as a function of business goals.","Any given term(s)  (e.g., mail, etc.) may have more than a single context within which the bid term may be used. To account for this, STS model  provides an indication in suggested term list  of which suggested terms correspond to which of the multiple contexts of term(s) . For example, referring to TABLE 1, the term(s)  of \u201cmail\u201d has two (2) contexts: (1) traditional off-line mail and (2) online e-mail. Note that a respective list of related terms is shown for each of these two bid term contexts.","Additionally, suggested terms for any term(s)  may be more than synonyms of the bid term. For instance, referring to TABLE 1, the suggested term \u201cusps\u201d is an acronym for an organization that handles mail, not a synonym for the bid term \u201cmail.\u201d However, \u201cusps\u201d is also a term very related to a \u201cmail\u201d bid term, and thus, is shown in the suggested term list . In one implementation, STS model  determines the relationship between a related term R (e.g. \u201cusps\u201d) and a target term T (e.g. \u201cmail\u201d) as a function of the following association rule: itr(T)\u2192itr(R), wherein \u201citr\u201d represents \u201cinterested in\u201d. If a user (advertiser, Web site promoter, and\/or the like) is interested in R, the user will also be interested in T.","An Exemplary Procedure",{"@attributes":{"id":"p-0088","num":"0099"},"figref":["FIG. 3","FIG. 2","FIG. 2"],"b":["300","302","212","216","220","212","216","304","212","222","228","230","306","212","230","232","234","222"]},"At block , STS module  mines \u201cother MDOs\u201d , for example, from query log(s) , Web site user access information, etc. STS module  generated respective MDO vectors  to represent the feature space of the mined \u201cother MDOs\u201d . At block , STS module  identifies intra-object and inter-object relationships\/links between respective ones of the MDOs . At block , STS module  performs reinforced clustering of the MDOs  based on their respective MDO vectors  to generate reinforced clusters . Details of the reinforced clustering of heterogeneous data objects of block  are described in reference to  below. Procedure  continues at block  of  as shown by on-page reference \u201cA\u201d.",{"@attributes":{"id":"p-0090","num":"0101"},"figref":["FIG. 4","FIG. 3","FIG. 2","FIG. 2","FIG. 5"],"b":["300","402","208","212","210","236","208","404","212","236","208","406","212","210","502"]},{"@attributes":{"id":"p-0091","num":"0102"},"figref":["FIG. 5","FIGS. 3 and 4","FIG. 2"],"b":["300","502","212","238","236","222","504","212","224","228","230","506","212","232","230","234"]},"At block , STS module  classifies term vectors  generated from low frequency of occurrence query terms  in view of the trained classifier  to generate respective reinforced term clusters  based on the low frequency of occurrence query terms . At block , STS module  generates a suggested term list  from the keywords\/key phrases from reinforced term clusters  based on the low frequency of occurrence query terms  that are determined to be substantially similar to the term(s) . At block , STS module  sends the suggested term list  to the end-user.",{"@attributes":{"id":"p-0093","num":"0104"},"figref":["FIG. 6","FIG. 3","FIGS. 1 and 2"],"b":["312","310","212","100","100","100"]},"At block , the original framework graph (prior to each clustering iteration) is input. At block , the importance of each node being considered is determined or calculated using equation (2). At block , an arbitrary layer is selected for clustering. At block , nodes in the selected layer are clustered in an appropriate fashion (e.g., according to content features) to generate reinforced cluster . In certain implementations, the nodes can be filtered using a desired filtering algorithm (not shown) to improve the clustering. At block , the nodes of each cluster are merged into one node. For instance, if two candidate nodes exist following the filtering, the closest two candidate nodes can be merged, e.g., by averaging the vector values of the two candidate nodes. This merging allows individual nodes to be combined to reduce the number of nodes that have to be considered. As such, the merging operation can be used to reduce the occurrence of duplicates and near-duplicates. At block , the corresponding links are updated based on the merging in . At block , the clustering algorithm switches to a second layer (from the arbitrarily selected layer) for clustering. The operations of block  continue at block  of , as shown by on-page reference \u201cC.\u201d","Referring to the operations of , note that in the initial clustering pass, only the content features are utilized. Because in most cases the link feature are too sparse in the beginning to be useful for clustering. In subsequent clustering passes, as described below in reference to , content features and link features are combined to enhance the effectiveness of the clustering. By combining the content features and the link features, the weights are specified with different values and the results can be compared, and clustering having an improved accuracy can be provided.",{"@attributes":{"id":"p-0096","num":"0107"},"figref":["FIG. 7","FIGS. 3 and 6"],"b":["312","702","704","706","708","710","712","100"]},"An Exemplary Operating Environment",{"@attributes":{"id":"p-0097","num":"0108"},"figref":["FIG. 8","FIG. 2","FIGS. 3 through 6"],"b":["800","200","800","800","800"]},"The methods and systems described herein are operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well-known computing systems, environments, and\/or configurations that may be suitable for use include, but are not limited to, personal computers, server computers, multiprocessor systems, microprocessor-based systems, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and so on. Compact or subset versions of the framework may also be implemented in clients of limited resources, such as handheld computers, or other computing devices. The invention is practiced in a distributed computing environment where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote memory storage devices.","With reference to , an exemplary system for reinforced clustering of multi-type data objects for search term suggestion includes a general purpose computing device in the form of a computer . The following described aspects of computer  are exemplary implementations of client computing device PSS server  () and\/or client computing device . Components of computer  may include, but are not limited to, processing unit(s) , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example and not limitation, such architectures may include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.","A computer  typically includes a variety of computer-readable media. Computer-readable media can be any available media that can be accessed by computer  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer .","Communication media typically embodies computer-readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism, and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation, communication media includes wired media such as a wired network or a direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer-readable media.","System memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example and not limitation,  illustrates operating system , application programs , other program modules , and program data . In one implementation, wherein computer  is a PSS server . In this scenario, application programs  comprise search term suggestion model . In this same scenario, program data  comprises multi-type data objects , search results , extracted features , MDO vectors , reinforced clusters , trained classifier , and other data .","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media discussed above and illustrated in , provide storage of computer-readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that they are at least different copies.","A user may enter commands and information into the computer  through input devices such as a keyboard  and pointing device , commonly referred to as a mouse, trackball or touch pad. Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus , but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB).","A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . In addition to the monitor, computers may also include other peripheral output devices such as speakers  and printer , which may be connected through an output peripheral interface .","The computer  operates in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and as a function of its particular implementation, may include many or all of the elements described above relative to the computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example and not limitation,  illustrates remote application programs  as residing on memory device . The network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Although the systems and methods for reinforced clustering of multi-type data objects for search term suggestion have been described in language specific to structural features and\/or methodological operations or actions, it is understood that the implementations defined in the appended claims are not necessarily limited to the specific features or actions described. For instance, although the reinforced clustering of multi-type data objects is described in reference to application of search term suggestion, reinforced clustering of multi-type data objects the can be applied to many other types of applications that utilize clustering. Accordingly, the specific features and actions are disclosed as exemplary forms of implementing the claimed subject matter."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["In the figures, the left-most digit of a component reference number identifies the particular figure in which the component first appears.",{"@attributes":{"id":"p-0011","num":"0012"},"figref":"FIG. 1","b":["100","102"]},{"@attributes":{"id":"p-0012","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0015"},"figref":["FIG. 4","FIG. 3"],"b":"300"},{"@attributes":{"id":"p-0015","num":"0016"},"figref":["FIG. 5","FIGS. 3 and 4"],"b":"300"},{"@attributes":{"id":"p-0016","num":"0017"},"figref":["FIG. 6","FIG. 3"],"b":"312"},{"@attributes":{"id":"p-0017","num":"0018"},"figref":["FIG. 7","FIGS. 3 and 6"],"b":"312"},{"@attributes":{"id":"p-0018","num":"0019"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
