---
title: Apparatus and method for detecting false sharing
abstract: A false sharing detecting apparatus for analyzing a multi-thread application, the false sharing detecting apparatus includes an operation set detecting unit configured to detect an operation set having a chance of causing performance degradation due to false sharing, and a probability calculation unit configured to calculate a first probability defined as a probability that the detected operation set is to be executed according to an execution pattern causing performance degradation due to false sharing, and calculate a second probability based on the calculated first probability. The second probability is defined as a probability that performance degradation due to false sharing occurs with respect to an operation included in the detected operation set.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08874856&OS=08874856&RS=08874856
owner: Samsung Electronics Co., Ltd.
number: 08874856
owner_city: Suwon-si
owner_country: KR
publication_date: 20110617
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application claims the benefit under 35 U.S.C. \u00a7119(a) of Korean Patent Application No. 10-2010-0098403, filed on Oct. 8, 2010, the disclosure of which is incorporated by reference in its entirety for all purposes.","1. Field","The following description relates to a technique for detecting false sharing.","2. Description of the Related Art","A symmetric multiprocessor (SMP) includes multiple CPUs or cores each having a local cache guaranteeing cache coherence of the local cache. False sharing is a phenomenon in which an identical data block is cached when threads performed on different CPUs access different memory addresses.","In addition, when a cache line loaded due to false sharing is updated by a thread of one CPU, a memory system of the SMP guaranteeing the cache coherence invalidates a cache line of another CPU which caches the same data block in cooperation with the one CPU. Accordingly, when a thread of the other CPU accesses the cache line of the other CPU again, a data block needs to be reloaded and newly cached and thus the system performance is degraded from the reloading of the data block.","Such false sharing needs to be avoided when developing a multi-thread application designed to run in a multi-core environment. According to an example of a method for detecting false sharing, a performance counter may be used to measure CPU performance. However, this method does not detect potential false sharing before false sharing occurs but instead detects the occurrence of false sharing that has happened by detecting a change in performance resulting from the false sharing. However, in order to detect false sharing during the development stage of multi-thread applications, identification of a chance of false sharing needs to be detected in advance during the development stage.","In one general aspect, a false sharing detecting apparatus for analyzing a multi-thread application, the false sharing detecting apparatus including an operation set detecting unit and a probability calculation unit. The operation set detecting unit is configured to detect an operation set having a chance of causing performance degradation due to false sharing. The probability calculation unit is configured to calculate a first probability defined as a probability that the detected operation set is to be executed according to an execution pattern identified that may cause performance degradation due to false sharing, and to calculate a second probability based on the calculated first probability. The second probability is defined as a probability that performance degradation due to false sharing may occur with respect to an operation included in the detected operation set.","In another general aspect, a false sharing detecting method for analyzing a multi-thread application, the false sharing detecting method includes detecting an operation set having a chance of causing performance degradation due to false sharing is detected and calculating a first probability. The first probability is defined as a probability that the detected operation set is to be executed according to an execution pattern that may cause performance degradation due to false sharing. A second probability is calculated based on the calculated first probability. The second probability is defined as a probability that performance degradation occurs due to false sharing with respect to an operation included in the detected operation set.","Other features will become apparent to those skilled in the art from the following detailed description, which, taken in conjunction with the attached drawings, discloses examples of the invention.","Elements, features, and structures are denoted by the same reference numerals throughout the drawings and the detailed description, and the size and proportions of some elements may be exaggerated in the drawings for clarity and convenience.","The following detailed description is provided to assist the reader in gaining a comprehensive understanding of the methods, apparatuses and\/or systems described herein. Various changes, modifications, and equivalents of the systems, apparatuses and\/or methods described herein will suggest themselves to those of ordinary skill in the art. Descriptions of well-known functions and structures are omitted to enhance clarity and conciseness.","Hereinafter, examples will be described with reference to accompanying drawings in detail.",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1","b":["100","110","110","111","112","111","112","113","114","113","114","111","112"]},"In the multi-core system , when a thread A of the processing core A  accesses an object X  of a memory , a data block  including the object X  is loaded to the cache A . The data block  is stored in cache A  as a cache line -. After the cache line - is loaded to the cache A , if a thread B of the processing core B  accesses an object Y  of the memory , the data block  including the object Y  of the memory  is loaded to the cache B . The data block  is stored in cache B  as a cache line -. In this case, since the cache line - loaded to the cache B  is practically identical to the cache line - loaded to the cache A , when the thread B modifies the object Y of the cache line - loaded to the cache B , the cache line - of the cache A  may be invalidated to guarantee cache coherence. Accordingly, when the thread A of the processing core A  accesses the object X  again, or accesses a predetermined object residing on the same data block , a cache miss may occur and the cache line - may need to be reloaded.","The reloading of the cache line - causes performance degradation. However, the false sharing detecting apparatus  may calculate the probability of performance degradation caused by false sharing when a predetermined operation is executed, and notify a user of the probability of performance degradation due to false sharing. The false sharing detecting apparatus  includes an operation set detecting unit , a probability calculation unit  and a result reporting unit .","The operation set detecting unit  acquires memory access information, and happens-before and parallel relations of executable operations of, for example, a multi-thread application through a memory access and threading application programming interface (API) call trace.","The memory access trace may be implemented using an instrumentation function inserted into a source code or a binary code of, for example, a multi-thread application that is to be executed. The operation set detecting unit  detects operation sets having a probability of causing performance degradation due to false sharing by use of the acquired memory access information, and happens-before and parallel relations.","The detected operation sets may include an operation C representing a read or write operation of a first thread of, for example, a multi-thread application on a first memory object corresponding to a cache line L, an operation I representing a write operation of a second thread with a second memory object that shares the cache line L with the first memory object, and an operation R representing a read or write operation of the first thread that is executed after the operation C on a third object which corresponds to the cache line L and does not overlap with the second memory object.","The probability calculation unit  calculates a first probability defined as a probability that the detected operation set is executed according to an execution pattern that may cause performance degradation due to false sharing. For example, the first probability may be defined as a probability that an operation I is executed between an operation C and an operation R. If the operations C, I and R are executed in the order of operation C, then operation I and then operation R, the cache line L loaded at the operation C is invalidated due to the operation I and the cache line L is reloaded with execution of the operation R, so that performance degradation due to false sharing is caused. However, if the operations C, I and R are executed in the order of operation C, then operation R and then operation I, even if operation R is executed, the cache line L does not need to be reloaded, thereby preventing performance degradation due to false sharing. However, since the detected happens-before and parallel relations of operations are acquired through the memory access and thread API call trace, it is extremely difficult to know the order in which operations are to be executed when a source code or a binary code of, for example, a multi-thread application is executed in practice. Accordingly, the probability calculation unit  calculates the probability that operations are to be executed according to an execution pattern that may cause performance degradation due to false sharing by calculating the first probability for each detected operation set, that is, the probability that the operation I is to be executed between the operation C and the operation R.","In addition, the probability calculation unit  calculates a second probability based on the calculated first probability, in which the second probability is defined as a probability that performance degradation due to false sharing occurs with respect to an operation included in the detected operation set. For example, the second probability may be defined as a probability that a reload for a cache line L occurs when the operation R is executed.","Furthermore, when considered with respect to the operation R, a plurality of operations I causing a reload of the cache line L may be present. Each operation I has a first probability that each operation I is executed according to an execution pattern causing performance degradation due to false sharing. Accordingly, the probability calculation unit  may calculate the second probability by summing in probability the respective first probabilities of the operations I in the detected operation set.","The result report unit  provides a user with a portion of a source code or binary code of, for example, a multi-thread application likely to have performance degradation due to false sharing and the probability that performance degradation occurs within the portion due to false sharing. For example, the result report unit  may display codes associated with the operation R and the calculated second probability in an alignment according to the second probability.",{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 2","FIGS. 1 and 2"],"b":["111","112","1","6","1","4","0","1","1","0"]},"Assumed that X [] and X [] share the same cache line, and the execution order of the operations is A\u2192 . . . \u2192B\u2192B\u2192 . . . \u2192A. In this case, as the operation A is executed, a cache line including X [] is loaded to the cache A . In addition, as the operation B is executed, a cache line including the X [] is loaded to the cache B . Subsequently, if the operation B is executed, data is recorded to X [] in the cache line loaded to the cache B  and the cache line loaded to the cache A  may be invalidated to guarantee cache coherence. Accordingly, when the operation A is executed, the cache line including the X [] may be reloaded to the cache A , thereby causing performance degradation.","The operation set detecting unit  may detect operations having a chance of causing performance degradation due to false sharing in code blocks, for example, operations A, B and A, as shown in .",{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 3"},"As shown in , the access of each operation to the memory objects and happens-before and parallel relations of the respective operations are identified according to the memory access and threading API call trace. For example, the operation A of the thread A is an object accessing the memory object X []. The operation A of the thread A is in a happens-before relation with the operation B of the thread B, and the operations A, A, A and A of the thread A are in a parallel relation with the operations B, B and B of the thread B. The happens-before\/parallel relations between operations may be identified through a vector-clock that has a predetermined dimension and is exchanged between the thread A and the thread B at a threading API call.","The operation set detecting unit  may detect operations having a chance of causing performance degradation due to false sharing, by use of the memory access information and the happens-before\/parallel relation of operations that are recognized through the memory access trace.",{"@attributes":{"id":"p-0039","num":"0038"},"figref":["FIG. 4","FIGS. 1"],"b":["3","4","101"]},"The operation C represents a read operation or a write operation of the first thread on the first memory object corresponding to the cache line L. For example, the operation A, which is a read operation on the memory object X [] corresponding to the cache line L, may correspond with the operation C.","The operation I represents a write operation of the second thread on the second memory object sharing the cache line L with the first memory object. For example, the operation B, which is a write operation on the memory object X [] corresponding to the cache line L, may correspond with the operation I.","The operation R represents a read operation or a write operation of the first thread that is executed after the operation C on a third object which corresponds to the cache line L and does not overlap with the second memory object. For example, the operation A, which is a write operation on the memory object X [] corresponding to the cache line L, may correspond with the operation R.","Accordingly, a set of operations detected by the operation set detecting unit , for example, operations A, B and A may be referred to as a \u201cCIR set.\u201d For the sake of convenience, an example of one CIR set is shown in , but the number of CIR sets detected by the operation set detecting unit is not limited thereto. That is, as shown in , the operation set detecting unit  may detect a plurality of CIR sets satisfying a detection requirement in at least two threads.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 5","FIG. 5"],"b":"101"},"As shown in , if the operation set detecting unit  detects a plurality of CIR sets, the probability calculation unit  may calculate a first probability defined as a probability that each CIR set is to be executed according to an execution pattern causing performance degradation due to false sharing in practice. In addition, the probability calculation unit  calculates a second probability representing the severity of performance degradation due to false sharing, if the detected CIR set has a chance of being executed according to the execution pattern causing performance degradation due to false sharing.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 6","b":["601","602","603"]},"The first probability is calculated as a probability that the operation I is executed between the operation C and the operation R. For example, the first probability is calculated based on the length and number  of operations having a parallel relation with the operation I among operations of the thread A, and the length and number  of operations having a parallel relation with the operation I among operations existing between the operation C and the operation R of the thread A. This is expressed by equation 1.",{"@attributes":{"id":"p-0048","num":"0047"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"C","mo":"\u2192","mrow":{"mi":["I","R"],"mo":"\u2192"}}}},"mo":"=","mfrac":{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mi":["Length","of","operations","between","C","and","R"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]},"mo":","}}},{"mtd":{"mrow":{"mi":["parallel","to","I"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]}}}]},"mrow":{"mi":["Length","of","operations","parallel","to","I"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]}}},{"mo":["(",")"],"mrow":{"mi":["in","Thread","A"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]}}],"mo":","}},{"mrow":{"mo":["[","]"],"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"1"}}}]}}}}},"According to equation 1, if each distance between operations is identical for a thread, the length of operations may be obtained by adding 1 to the number of operations when calculating the first probability.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 7","FIG. 7"]},"When considered with respect to operation R, operation sets C\u2192I\u2192R and C\u2192I\u2032\u2192R are detected as an example of the CIR sets. The first probability P (C\u2192I\u2192R) of the operation set C\u2192I\u2192R and the first probability P (C\u2192I\u2032\u2192R) of the operation set C\u2192I\u2032\u2192R are calculated as 4\/7 and \u2157, respectively, through the above equation 1.","For the thread A and the thread B, the first probability P (C\u2192I\u2192R)= 4\/7 is calculated by use of the length  of operations  having a parallel relationship with the operation I among operations of the thread A and the length  of operations existing between the operation C and the operation R among the operations  of the thread A having a parallel relation with the operation I. For the thread A and the thread B\u2032, the first probability P (C\u2192I\u2032\u2192R)=\u2157 is calculated by use of the length  of operations  having a parallel relation with the operation I\u2032 among operations of the thread A and the length  of operations existing between the operation C and the operation R among the operations  of the thread A having a parallel relation with the operation F.","The second probability may be obtained by summing the calculated probabilities P (C\u2192I\u2192R) and P (C\u2192I\u2032\u2192R) in probability. The summing in probability may not represent a simple summation of probabilities. That is, P (C\u2192I\u2192R) and P (C\u2192I\u2032\u2192R) may not be obtained from independent events, and thus the probability at the operation R in consideration of all operations I (or operations I\u2032) may be obtained by subtracting the probability that all available operations I (or operations I\u2032) are not included between the operation C and the operation R from the total probability of 1. This is expressed by equation 2.",{"@attributes":{"id":"p-0054","num":"0053"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"C","mo":"\u2192","mrow":{"mo":"\u2200","mrow":{"mi":["I","R"],"mo":"\u2192"}}}}},{"mn":"1","mo":"-","mrow":{"munderover":{"mo":"\u220f","mrow":{"mo":"\u2200","mi":"I"},"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"C","mo":"\u2192","mrow":{"mi":["I","R"],"mo":"\u2192"}}}}}}}}],"mo":"="}},{"mrow":{"mo":["[","]"],"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"2"}}}]}}}}},"According to  and equation 2, the second probability may be calculated as 1\u2212(1\u2212( 4\/7))*(1\u2212(\u2157)).",{"@attributes":{"id":"p-0056","num":"0055"},"figref":["FIG. 8","FIG. 8","FIG. 1"]},"First, operation sets are detected (). For example, the operation set detecting unit  may detect a plurality of CIR sets through a memory access trace, for example, as described in .","Thereafter, the first probability is calculated (). The first probability may represent the probability that each detected CIR set is executed according to an execution pattern causing performance degradation due to false sharing. For example, referring to  and equation 1, the probability calculation unit  may calculate the first probability based on the probability that the operation I is executed between the operation C and the operation R.","Then, the second probability is calculated (). The second probability may represent the probability that performance degradation occurs due to false sharing with respect to the operation R of the CIR set. For example, referring to  and equation 2, the probability calculation unit  may calculate the second probability by summing first probabilities in probability.","The result may be reported to a user (). For example, the result report unit  may indicate codes related to the operation R that may cause performance degradation due to false sharing in an alignment according to the calculated second probability.","As described above, according to the false sharing detecting apparatus and method, a portion having a chance of causing performance degradation due to false sharing may be detected during a preliminary execution through a memory access trace, and the severity of the performance degradation caused by the portion may be determined in terms of probability, so that potential performance degradation is preliminarily detected and modified.","The disclosure can also be embodied as computer readable codes on a computer readable recording medium. The computer readable recording medium is any data storage device that is capable of storing data which can be thereafter read by a computer system.","Examples of the computer readable recording medium include read-only memory (ROM), random-access memory (RAM), CD-ROMs, magnetic tapes, floppy disks, optical data storage devices, and carrier waves such as data transmission through the Internet. The computer readable recording medium may also be distributed over network coupled computer systems so that the computer readable code may be stored and executed in a distributed fashion","Also, functional programs, codes, and code segments for accomplishing the present invention can be easily construed by programmers skilled in the art to which the present invention pertains. A number of examples have been described above. Nevertheless, it will be understood that various modifications may be made. For example, suitable results may be achieved if the described techniques are performed in a different order and\/or if components in a described system, architecture, device, or circuit are combined in a different manner and\/or replaced or supplemented by other components or their equivalents. Accordingly, other implementations are within the scope of the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
