---
title: Method and apparatus for detecting prosodic phrase break in a text to speech (TTS) system
abstract: Methods for processing speech data are described herein. In one aspect of the invention, an exemplary method includes receiving a text sentence comprising a plurality of words, each of the plurality of words having a part of speech (POS) tag, generating a POS sequence based on the POS tag of each of the plurality of words, detecting a prosodic phrase break through a recurrent neural network (RNN), based on the POS sequence, and generating a prosodic phrases boundary based on the prosodic phrase break. Other methods and apparatuses are also described.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07136802&OS=07136802&RS=07136802
owner: Intel Corporation
number: 07136802
owner_city: Santa Clara
owner_country: US
publication_date: 20020116
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","DETAILED DESCRIPTION"],"p":["The invention relates to speech recognition. More particularly, the invention relates to prosodic phrase break detection of a limited domain text to speech (TTS) application.","In general, there are three key modules in a text to speech (TTS) system: the text analysis, the prosodic model and the speech synthesis. One of the important stages in the process of turning unmarked text into speech is the assignment of appropriate phrase break boundaries. The phrase break boundaries are important to later modules including accent assignment, duration control and pause insertion. A number of different algorithms have been proposed for such a task, ranging from the simple to the complex. These different algorithms require different information such as part of speech (POS) tags, syntax and even semantic understanding of the text. Obviously these requirements come at different costs and it is important to trade off difficulty in finding particular input features versus accuracy of the model.","Some of the languages, such as Chinese and Japanese, do not have space between the words. The first step of text analysis for such language processing is word segmentation. Because of the difficulty of syntactic parsing for these languages, most of the conventional TTS systems segment the words in the text analysis procedure, and limit the average length of the words after the segmentation at about 1.6 syllables, through the intrinsic properties of the words. Thus a small pause will be inserted every 1.6 syllables during the speech synthesis if there is no other higher level linguistic information, such as prosodic word, prosodic phrase and intonational phrase. As a result, the speech is not fluent enough. Native speakers tend to group words into phrases whose boundaries are marked by duration and intonational cues. Many phonological rules are constrained to operate only within such phrases, usually termed prosodic phrases. Prosodic phrase will help the TTS system produce more fluent speech, while the prosodic structure of the sentence will also help improve the intelligibility and naturalness of the speech. Therefore placing phrase boundaries is very important to ensure a naturally and sounding TTS system. With correct prosodic phrases detected from text, high quality prosodic model can be created and the acoustic parameters can be provided, which include pitch, energy, and duration, for the speech synthesis.","A lot of methods have been introduced to extract prosodic phrase boundaries from English text, such as statistic model, CART (Classification and Regression Tree), FSA (Finite State Automata), MM (Markov Model), and so on. Some approaches use the language information to parse the text, and then map from the syntactic structure to prosodic structure, some methods make use of POS to extract prosodic phrase from the text. However, these methods tend to have limited quality and complex procedures to accomplish their goals. It is desirable to have an improved method and system for detecting prosodic phrase break.","The following description and drawings are illustrative of the invention and are not to be construed as limiting the invention. Numerous specific details are described to provide a thorough understanding of the present invention. However, in certain instances, well-known or conventional details are not described in order to not unnecessarily obscure the present invention in detail.","Methods and apparatus' for prosodic phrase detection of a language are disclosed. The subject of the invention will be described with reference to numerous details set forth below, and the accompanying drawings will illustrate the invention. The following description is illustrative of the invention and is not to be construed as limiting the invention. Numerous specific details are described to derive a thorough understanding of present invention. However, in certain circumstances, well known, or conventional details are not described in order not to obscure the present invention in detail.","Reference throughout this specification to \u201cone embodiment\u201d, \u201can embodiment\u201d, or \u201cpreferred embodiment\u201d indicates that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus, the appearance of the phrase \u201cin one embodiment\u201d, \u201cin an embodiment\u201d, or \u201cin a preferred embodiment\u201d in various places throughout the specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures, or characteristic may be combined in any suitable manner in one or more embodiments.","Unlike most European languages, some languages, such as Mandarin Chinese, use tones for lexical distinction. A tone occurs over the duration of a syllable. There are five main lexical tones that play very important roles in meaning disambiguation.  shows the typical five main lexical tones used in Mandarin. The direct acoustic representative of these tones is the pitch contour variation patterns, as illustrated in . In some cases, one word may have more than one meaning, when the word is associated with different lexical tone. As a result, there could be very large amount of meaning or voice outputs for every single word in Mandarin. Similarly, the voice outputs representing the number could be burdensome, in a text to speech (TTS) application. As the computer system is getting more popular, it is apparent to a person with ordinary skill in the art to use a computer system to implement such application.",{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 2","FIG. 2","FIG. 2"]},"As shown in , the computer system , which is a form of a data processing system, includes a bus  which is coupled to a microprocessor  and a ROM  and volatile RAM  and a non-volatile memory . The microprocessor  is coupled to cache memory  as shown in the example of . The bus  interconnects these various components together and also interconnects these components , , , and  to a display controller and display device  and to peripheral devices such as input\/output (I\/O) devices, which may be mice, keyboards, modems, network interfaces, printers and other devices which are well known in the art. Typically, the input\/output devices  are coupled to the system through input\/output controllers . The volatile RAM  is typically implemented as dynamic RAM (DRAM) which requires power continuously in order to refresh or maintain the data in the memory. The non-volatile memory  is typically a magnetic hard drive, a magnetic optical drive, an optical drive, a DVD RAM, or other type of memory system which maintains data even after power is removed from the system. Typically, the non-volatile memory will also be a random access memory, although this is not required. While  shows that the non-volatile memory is a local device coupled directly to the rest of the components in the data processing system, it will be appreciated that the present invention may utilize a non-volatile memory which is remote from the system, such as a network storage device which is coupled to the data processing system through a network interface such as a modem or Ethernet interface. The bus  may include one or more buses connected to each other through various bridges, controllers, and\/or adapters, as is well-known in the art. In one embodiment, the I\/O controller  includes a USB (Universal Serial Bus) adapter for controlling USB peripherals.",{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 3","b":["300","301","309","309","302","303","304","304","305","305","306","308"]},"The present invention utilizes a recurrent neural network (RNN) to detect a prosodic phrase break.  shows an embodiment of a TTS system with an RNN. A text sentence is inputted to a text processing unit  for text analysis. During the text processing, the sentence may be segmented into a plurality of words. Then the text processing unit assigns a part of speech (POS) tag to each of the words. The tags of the words may be classified into a specific class as discussed above. As a result, a tag sequence corresponding to the words are generated. The tag sequence is then inputted to the recurrent neural network (RNN) . The RNN performs detection of a prosodic phrase break between each of the words. Each of the tags in the tag sequence is sequentially inputted to the RNN. For each inputted tag, a phrase break state is generated from the RNN. The outputted phrase breaks, as well as previously inputted tags are then fed back into the RNN to assist the subsequent prosodic phrase break detection of the subsequent tags of the tag sequence. As a result, a sentence with prosodic phrase break is created. Based on the phrase break detected, the speech features, such as duration, energy, and pitch may be modified. With the phrase break, the length of a word may be longer than a normal one. The sentence with prosodic break is then inputted into the speech processing unit  to perform speech synthesis. As a result, a speech (e.g., voice output) is generated through the speech processing unit .","In general, an RNN is used for analysis temporal classification problems. An RNN consists of a set of units, an example of which is shown in . The unit has a weight associated with each unit. A function of the weights and inputs (e.g., a squashing function applied to the sum of the weight-input products) is then generated as an output. These individual units may be connected together as shown in , with an input layer, output layer, and usually a hidden layer. Typically, the input layer consists of one unit per attribute, and the output layer of one unit per class. The number of the units in the hidden layer is normally arbitrary. Through algorithm such as back propagation, the weights of the neural net can be adjusted so as to produce an output on the appropriate unit when a particular pattern at the input is observed.","A recurrent neural network (RNN) allows for temporal classification, as shown in . Referring to , a context layer is added to the structure, which retains information between observations. At each time step, new inputs are fed into the RNN. The previous contents of the hidden layer are passed into the context layer. These contents then feed back into the hidden layer in the next time step. For a classification, post-processing of the outputs from the RNN is usually performed. For example, when a threshold on the output from one of the nodes is observed, that particular class has been observed.","Before an RNN can be used, it has to be trained. Training the recurrent network is the most computationally difficult process in the development of a system. Once each frame of the training data has been assigned a label, the RNN training is effectively decoupled form the system training. An objective function may be used to ensure that the network input-output mapping satisfies the desired probabilistic interpretation is specified. Training of the recurrent network is performed using gradient methods. Implementation of the gradient parameter search leads to two integral aspect of the RNN training: computation of the gradient and application of the gradient to update the parameters.","Typically, in a Chinese text to speech (TTS) system, there are approximately 2000 sentences (17897 words) in a corpus. The corpus is designed for general purpose, not limited to any specific domains. Typically, ninety percent of the corpus is used to train the RNN, and the remaining ten percent are used for testing purposes. The corpus is labeled with words, POS tags and prosodic phrase boundaries. The words are segmented by a word segment system. The word segment system normally includes more then 130 thousand Chinese words. The word segmentation system may utilize a maximal matching method and linguistic rules to segment words.","In addition, a text analysis includes a lexical analysis procedure. A Markov Model may be implemented in the procedure to tag the POS of the words. In fact, some of the lexical analysis may be combined with the word segmentation processing. There are total twenty-six different tags in the POS tag set. However, it may not be necessary and practical to use all of them to train a model. If all of them are utilized, there will be 26*26*26=17576 possible trigrams, at the same time there are only 17897 words in the corpus. In fact if the corpus were big enough, the words themselves may be used to train the model directly. Therefore, in one embodiment, the tags are classified into eleven classes. In one embodiment, the tag classes include adjective, adverb, noun, verb, number, quantifier, preposition, conjunction, idiom, punctuation, and others. As a result, there are total 11*11*11=1331 kind of trigrams, and it is evident that the classification is accurate and effective.","During the training the prosodic phrase boundaries are labeled. Although it is generally a perception that prosodic phrases have some relationship with syntactic phrases, the two are not isomorphic. If all of the prosodic phrase boundaries are labeled manually, there would be too many syntactic phrases in the training corpus. Therefore a set of rules is applied during the prosodic phrase tagging. In one embodiment, the set of rule may include silence (pause), phrase lengthening and pitch declination. The prosodic phrases are extracted from speech for reference. The result of the prosodic phrase may be examined manually by a user through a user interface. In an alternative embodiment, the examination may be conducted by an application through an application programming interface (API).",{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 6","b":["601","602","603","604","603"]},"Then the system performs prosodic phrasing on the plurality of words with POS tags  and matches with the prosodic phrases from the speech database . The prosodic phrasing processing is typically performed based on a set of rules, such as energy and cross-zero rates, etc. During the processing, the attributes of the objective functions used by the RNN are adjusted. Then the trainer may perform manually checking  to ensure the outputs are satisfied. In one embodiment, the checking may be performed through an application programming interface (API) of an application. If the results are not satisfied (e.g., manually checking fails), the attributes of the objective functions are readjusted and more repeating training are conducted until satisfied results are created. As a result, sentences with prosodic phrase break (e.g., phrase boundaries) are generated.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 7","FIG. 7"],"b":["1","2","3","1","2","3","1","2","1","2","3","3","2","3","1","1","2","2","3","1","1","2","2","3","3","3","3"]},"The inputted POS tags should be orthogonalized into eleven-dimension vectors, thus there is no direct linear relationship among the tags themselves. The break symbols, which represent the state of the break, will be orthogonalized into 2-dimension vectors respectively.","For the subsequent detections, portion of the previous inputted tags and breaks, such as B, T, and T, as well as previously outputted breaks, such as B, are fed back to the RNN with shifts. For example, the next detection for detecting whether there is a phrase break between tag T and the next tag, such as T of the tag sequence, will use previously inputs and outputs. In this case, B, T, B, and T are inputted to the first, second, third, and fourth inputs of the RNN respectively. The next tag on the tag sequence, such as T is retrieved from the tag sequence and inputted to the fifth input of the RNN. As a result, a phrase break B is generated from the RNN. A value of one indicates B is a phrase break and value of zero indicates B is not a phrase break. These processes are repeated until there is no more tag left in the tag sequence.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 8","FIG. 8","FIG. 8"],"b":["1","1","2","2","3","801","1","2","801"]},{"@attributes":{"id":"p-0039","num":"0038"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"X","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mn":"2"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":[{"mi":["a","i"]},{"mi":["B","i"]}],"mo":"\u2062"}}}}},"br":{},"b":["1","2","3","802"],"figref":"FIG. 8"},{"@attributes":{"id":"p-0040","num":"0039"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"Y","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mn":"3"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mo":["(",")"],"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mn":"11"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":[{"mi":["b","ij"]},{"mi":["T","ij"]}],"mo":"\u2062"}}}}}}},"br":[{},{},{}],"sub":["ij ","1","2","i ","ij","1 ","2 "],"b":["3","3","3","3","3","3","3","3"],"in-line-formulae":[{},{}],"i":["c","c"]},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 9"},"Referring to , the system receives  a sentence with part of speech (POS) tags associated with each word of the sentence. The tags of the words in the sentence are then classified  into specific classes. In one embodiment, these classes are among the eleven classes discussed above. Based on the classified tags, a tag sequence is generated . The system retrieves  a next tag from the tag sequence and inputs to the recurrent neural network (RNN) to detect  a prosodic phrase break. As a result, a prosodic break state is generated from the RNN. Then the system checks  whether there are more tags in the tag sequence. If there are more tags in the tag sequence, a next tag will be retrieved from the tag sequence and the newly generated break value, as well as other previously inputs and outputs are fed back to the RNN to detect a prosodic break corresponding to the new input. These processing will be repeated until there are no more tags in the tag sequence. As a result, a sentence with prosodic phrase break is created.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 10","b":["1001","2","3","4","5","1003","1","1003","1002","1","1004","2","1","2","3","1","1","2","1010","1005","3"]},"Next, the parameters are shifted. During the second operation  of RNN , B, T, T and the newly outputted B are inputted to RNN . In addition, the next tag from the tag sequence, T is also inputted to RNN . As a result, B is generated. These processes will be repeated in the operation , with a subsequent tag (e.g., T), until there is no more tag left in the tag sequence. As a result, a sentence with prosodic phrase break  is generated. This sentence will be processed in a subsequent speech processes.","In the foregoing specification, the invention has been described with reference to specific exemplary embodiments thereof. It will be evident that various modifications may be made thereto without departing from the broader spirit and scope of the invention as set forth in the following claims. The specification and drawings are, accordingly, to be regarded in an illustrative sense rather than a restrictive sense."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings in which like references indicate similar elements.",{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5C"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
