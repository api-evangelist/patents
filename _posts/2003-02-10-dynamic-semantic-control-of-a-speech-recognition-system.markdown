---
title: Dynamic semantic control of a speech recognition system
abstract: A method and apparatus are provided for automatically recognizing words of spoken speech using a computer-based speech recognition system according to a dynamic semantic model. In an embodiment, the speech recognition system recognizes speech and generates one or more word strings, each of which is a hypothesis of the speech, and creates and stores a probability value or score for each of the word strings. The word strings are ordered by probability value. The speech recognition system also creates and stores, for each of the word strings, one or more keyword-value pairs that represent semantic elements and semantic values of the semantic elements for the speech that was spoken. One or more dynamic semantic rules are defined that specify how a probability value of a word string should be modified based on information about external conditions, facts, or the environment of the application in relation to the semantic values of that word string. A speech recognition application, upon receiving the keyword-value pairs, instructs the speech recognizer to modify one or more of the probability values, according to the dynamic semantic rules. The dynamic semantic rules are applied to the word strings and the keyword-value pairs. The speech recognizer modifies one or more of the probability values, re-orders the word strings, and returns control to the application. As a result, the speech recognizer may adjust dynamically to a changing likelihood that a speaker uttered a particular utterance, as the application executes, depending on the context of the application and the external factors.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07127393&OS=07127393&RS=07127393
owner: Speech Works International, Inc.
number: 07127393
owner_city: Boston
owner_country: US
publication_date: 20030210
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT","Theory of Operation of Speech Recognition System Using Dynamic Semantic Model","EXAMPLE OF SYSTEM STRUCTURE","Speech Recognition Method Using Dynamic Semantic Model","Hardware Overview"],"p":["This application claims priority to U.S. patent application U.S. Ser. No. 09\/258,012 by Michael Phillips et al. entitled \u201cDYNAMIC SEMANTIC CONTROL OF A SPEECH RECOGNITION SYSTEM\u201d and filed Feb. 25, 1999.","The present invention generally relates to data processing. The invention relates more specifically to speech recognition systems.","Speech recognition systems are specialized computer systems that are configured to process and recognize spoken human speech, and take action or carry out further processing according to the speech that is recognized. Such systems are now widely used in a variety of applications including airline reservations, auto attendants, order entry, etc. Generally the systems comprise either computer hardware or computer software, or a combination.","Speech recognition systems typically operate by receiving an acoustic signal, which is an electronic signal or set of data that represents the acoustic energy received at a transducer from a spoken utterance. The systems then try to find a sequence of text characters (\u201cword string\u201d) which maximizes the following probability:\n\nP(A|W)*P(W)\n","where A means the acoustic signal and W means a given word string. The P(A|W) component is called the acoustic model and P(W) is called the language model.","A speech recognizer may be improved by changing the acoustic model or the language model, or by changing both. The language may be word-based or may have a \u201csemantic model,\u201d which is a particular way to derive P(W).","Typically, language models are trained by obtaining a large number of utterances from the particular application under development, and providing these utterances to a language model training program which produces a word-based language model that can estimate P(W) for any given word string. Examples of these include bigram models, trigram language models, or more generally, n-gram language models.","In a sequence of words in an utterance, W\u2013W, an n-gram language model estimates the probability that the utterance is word j given the previous n\u22121 words. Thus, in a trigram, P(W|utterance) is estimated by P(W|W, W). The n-gram type of language model may be viewed as relatively static with respect to the application environment. For example, static n-gram language models cannot change their behavior based upon the particular application in which the speech recognizer is being used or external factual information about the application. Thus, in this field there is an acute need for an improved speech recognizer that can adapt to the particular application in which it is used.","An n-gram language model, and other word-based language models work well in applications that have a large amount of training utterances and the language model does not change over time. Thus, for applications in which large amounts of training data are not available, or where the underlying language model does change over time, there is a need for an improved speech recognizer that can produce more accurate results by taking into account application-specific information.","Other needs and objects will become apparent from the following detailed description.","The foregoing needs, and other needs and objects that will become apparent from the following description, are achieved by the present invention, which comprises, in one aspect, a method of dynamically modifying one or more probability values associated with word strings recognized by a speech recognizer based on semantic values represented by keyword-value pairs derived from the word strings, comprising the steps of creating and storing one or more rules that define a change in one or more of the probability values when a semantic value matches a pre-determined semantic tag, in which the rules are based on one or more external conditions about the context in which the speech recognizer is used; determining whether one of the conditions currently is true, and if so, modifying one or more of the probability values that match the tag that is associated with the condition that is true.","According to one feature, the speech recognizer delivers the word strings to an application program. The determining step involves determining, in the application program, whether one of the conditions currently is true, and if so, instructing the speech recognizer to modify one or more of the probability values of a word string associated with a semantic value that matches the tag that is associated with the condition that is true.","Another feature involves representing the semantic values as one or more keyword-value pairs that are associated with the word strings recognized by the speech recognizer; delivering the keyword-value pairs to an application program; and determining, in the application program, whether one of the conditions currently is true, and if so, instructing the speech recognizer to modify the probability value of the word strings that are associated with the keyword-value pairs that match the tag that is associated with the condition that is true.","Yet another feature involves delivering the words and semantic values to an application program that is logically coupled to the speech recognizer; creating and storing, in association with the speech recognizer, a function callable by the application program that can modify one or more of the probability values of the word strings associated with semantic values that match the tag that is associated with the condition that is true; determining, in the application program, whether one of the conditions currently is true, and if so, calling the function with parameter values that identify how to modify one or more of the semantic values.","A related feature involves re-ordering the word strings after modifying one or more of the probability values. Another feature is modifying the probability values by multiplying one or more of the probability values by a scaling factor that is associated with the condition that is true.","In another feature, the method involves delivering one or more word-value pairs that include the semantic values to an application program that is logically coupled to the speech recognizer. A function is created and stored, in association with the speech recognizer, which can modify one or more of the probability values of word strings associated with words of word-value pairs that match the tag word that is associated with the condition that is true. It is determined, in the application program, whether one of the conditions currently is true, and if so, calling the function with parameter values that identify how to modify a probability value of a word string associated with the semantic values, including a scaling factor that is associated with the condition that is true. The function may modify a probability value by multiplying the probability value by the scaling factor.","The invention also encompasses a computer-readable medium and apparatus that may be configured to carry out the foregoing steps.","A method and apparatus for speech recognition processing using a dynamic semantic model is described. In the following description, for the purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the present invention. It will be apparent, however, to one skilled in the art that the present invention may be practiced without these specific details. In other instances, well-known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention.","For cases where large amounts of training data are not available, or where the underlying language model does change over time, a speech recognizer may be improved by deriving the model from the meaning of the utterances, rather than only from the word level. Such use of semantic information can greatly improve the accuracy of the language model in these cases.","For example, consider an airline flight reservation system. A customer of the airline telephones a dedicated telephone number that is associated with an interactive voice response (\u201cIVR\u201d) system that includes a speech recognizer. The IVR system prompts the customer to speak the dates on which the customer wishes to travel.","Using a static, word-based language model for recognizing spoken words that represent dates is a fairly weak approach. Such a model would learn that the probability of the user speaking \u201cDecember sixteenth\u201d is similar to the probability of speaking \u201cSeptember fifteenth.\u201d The model also would learn that both of these are somewhat more likely than the probability of the user speaking \u201cthe sixteenth of December,\u201d and much more likely than \u201cSeptember one five\u201d. Thus, a static word-based language model cannot help the speech recognizer resolve confusion between whether a particular utterance represents the word \u201cDecember\u201d or the word \u201cSeptember.\u201d","The airline may know, however, from experience that customers who use the IVR system generally travel within the next few days. So, if the current date is December 14, it is much more likely that a user will speak \u201cDecember sixteenth\u201d than \u201cSeptember fifteenth\u201d. This fact is an example of semantic information that may be used in resolving ambiguities within a recognizer and improving its performance.","The term \u201csemantic model\u201d means that the probability of the word string is based in part on the underlying meaning of the utterance. In the above example, the probability values that a given utterance is \u201cDecember sixteenth\u201d or the \u201cday after tomorrow\u201d will be based both on the probability of the user wanting to travel two days from now and the probability that they will speak it in each of these two ways.","The term \u201cdynamic semantic model\u201d means that the semantic model may cause one or more probability values, each of which is associated with a word string, to change. The change may occur based upon information that describes external events and responses to be taken when the external events occur. A particular change may be determined based on one or more semantic values which represent particular abstract language elements of an utterance, combined with the information that describes external events. In the example above, the semantic model may cause one or more probability values associated with the strings \u201cDecember sixteenth\u201d and \u201cSeptember fifteenth\u201d to change depending on information that identifies the current date.","According to another example embodiment, a semantic model is configured to operate on city name values in a travel system. In this model, City Name is a keyword. The system may create and store, in association with instances of the keyword, one or more values that indicate whether an utterance is a particular city name depending on the area code which the caller is calling from. For example, assume that a speech recognizer receives data identifying the caller, including an area code value that indicates the caller is calling from area code \u201c617\u201d. Further assume that the speech recognizer receives an utterance and generates two word strings that may represent the utterance, namely, \u201cBOSTON\u201d and \u201cAUSTIN\u201d. The speech recognizer also creates and stores a probability value in association with each word string. The probability value indicates the likelihood that the word string is what was actually spoken. The speech recognizer also creates and stores a keyword-value pair associated with each word string. The keyword-value pair of the first word string is (City Name, \u201cBOSTON\u201d). The keyword-value pair for the second word string is (City Name, \u201cAUSTIN\u201d).","As a result, the speech recognizer cannot determine whether it has recognized either \u201cBOSTON\u201d or \u201cAUSTIN\u201d as the City Name value. Since the area code of Boston, Mass. is \u201c617\u201d, it is highly unlikely that the origin city of the caller is AUSTIN and it is also highly unlikely that the destination city of the caller is BOSTON. Thus, based on the area code information and the keyword-value pairs, using a dynamic semantic mechanism, the probability value associated with one word string or the other may be changed, or appropriately weighted.","Another example may involve a semantic model for company names in a stock quote and trading system. Assume that the system has a semantic keyword called Stock, and that a customer or user of the system has a stock portfolio that includes shares of IBM Corporation. Assume further that a hypothetical company called \u201cI-Beam Corporation\u201d is traded on an exchange. In this situation, if the speech recognizer identifies an utterance that could be confused among \u201cIBM\u201d and \u201cI-BEAM,\u201d the semantic model determines that it is far more likely that the utterance is \u201cIBM\u201d because the customer has that stock in their portfolio. Thus, the probability value that is assigned to the two word strings, e.g., \u201cIBM\u201d or \u201cI-BEAM\u201d, depends on the stocks which appear in each user's portfolio.","It has been determined that some applications may realize important benefits from the use of such dynamic semantic models. It has been determined that in some cases there are very significant accuracy gains compared to static word-based language models.","Since most speech recognizers operate fundamentally on word strings and not on semantic information, the dynamic semantic models may be applied as a post-recognition process. For example, the speech recognizer may determine the n-best word strings, and a parser with meaning extraction is applied to convert the n-best word strings to n-best sets of keyword-value pairs. A probability value is stored in association with each of the word strings or each of the keyword-value pairs. The semantic models are applied and used to modify one or more of the probability values, and the n-best sets of keyword-value pairs are re-ordered. Alternatively, the word strings are re-ordered.","In an embodiment, the semantic models may be applied using one or more callbacks. An application that is executing in cooperation with the speech recognizer may use the one or more callbacks to alter the values associated with any keyword based on semantic information that the developer provides.",{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 1","b":["100","2","4","102","2","100","108"]},"The speech recognizer  is coupled to an acoustic model  and a dynamic semantic mechanism . Acoustic model  comprises information that assists speech recognizer  in carrying out speech recognition functions on the signals received from telephone . For example, speech recognizer  uses acoustic model  to determine which phoneme, among a plurality of phonemes, is most likely represented by one or more frames or segments of speech received from telephone . Speech recognizer  may provide as output a set of likely phonemes. Preferably, speech recognizer  also outputs one or more word strings that are the most probable words represented by the phonemes. There may be n word strings and they are normally ordered from best to worst, according to a probability value that is created and stored in association with the word strings. Accordingly, the word strings are called n-best word strings .","Speech recognizer  is also coupled to a dynamic semantic mechanism  which in turn is coupled to and uses data . Dynamic semantic mechanism  assists speech recognizer  in carrying out higher-order speech recognition functions on the signals received from telephone . For example, speech recognizer  uses dynamic semantic mechanism  to determine which words, from among a plurality of words, represent the semantics of the n-best word strings . The dynamic semantic mechanism may be implemented as a function, subroutine, method, or other software process that is callable from application , speech processing modules , or from speech recognizer .","Data  is information about the environment of system  or other external facts or conditions that may affect the output of speech recognizer . In one embodiment, data  may be implemented in the form of a table, list, or other data structure that is stored in non-volatile memory and loaded into main memory when speech recognizer  initializes. The table may store a list of key values that may be matched to utterances of a speaker, and substitute values that are substituted when an utterance matches a key value or is within a range of key values. The table may also store, for each key value, a weight value, a floor value and an offset value that are used to modify the probability value associated with a particular word string among n-best word strings .","The data  may comprise a table of statistical information derived from long use of the application , or may comprise rules or data that is based on such statistical information. For example, when application  is an airline reservation system, it may be found through long use of the application in a real-time environment that customers located within area code \u201c617\u201d (Boston and environs) almost always make flight reservations in which the departing city is Boston. This semantic rule is derived from statistics or log files, stored by the application  when it is executing, that show repeated instances of recognizing \u201cBOSTON\u201d as the departing city when the caller is in area code \u201c617\u201d.","In operation, upon receiving a speech input from telephone , speech recognizer  may create a set of the n-best word strings  that are represented by the speech. Speech recognizer  then applies a parser  to the n-best word strings . Parser  may be a Backus-Naur Form (BNF) type of parser that analyzes the n-best word strings  to determine the linguistic semantics that are represented by the word strings. As a result, parser  creates and stores one or more keyword-value pairs  for each of the word strings.","Each keyword-value pair represents the semantics of one of the n-best word strings . For example, consider an utterance in an airline reservation system in which the speaker says the departure city and arrival city for a flight. One utterance of a speaker might be, \u201cI want to fly from Boston to Denver on March 24.\u201d Speech recognizer  might generate two n-best word strings  from this utterance, namely Word String A=\u201cI want to fly from Boston to Denver on March 24\u201d and Word String B=\u201cI want to fly from Austin to Denver on March 24.\u201d Word String A might have a probability value of \u201c90\u201d and Word String B might have a probability value of \u201c20\u201d, in which a higher value is more probable, on a scale of \u201c0\u201d to \u201c100\u201d. Parser  could create the following keyword-value pairs for Word String A: (FROM-CITY, BOSTON); (TO-CITY, DENVER); (DATE, 24, Mar. 1999). Parser  could create the following keyword-value pairs for Word String B: (FROM-CITY, AUSTIN); (DATE, 24, Mar. 2000).","Preferably, a single probability value is created and stored in association with each of the word strings within the n-best word strings . The probability value represents the likelihood that a particular word string was in fact uttered by the speaker. Alternatively, the system may create and store a probability value for each keyword-value pair that is associated with a word string, and could also combine such probability values into one value for that whole string.","Speech recognizer  may also pass the n-best word strings  to one or more speech processing modules , which are software elements that carry out still higher-order speech processing functions. An example of a commercial product that is suitable for use as speech processing modules  is DialogModules\u2122, commercially available from SpeechWorks International, Inc., of Boston, Mass.","Speech processing modules  cooperate with and may be used by the application  to carry out its logical operations. For example, application  may call one of the speech processing modules to determine whether a speaker using telephone  uttered a \u201cYES\u201d or \u201cNO\u201d response to a particular prompt generated by the application . Details about one embodiment of speech processing modules that interact with an application program are set forth in co-pending U.S. patet application Ser. No. 09\/081,719, filed May 6, 1998, entitled System and Method for Developing Interactive Speech Applications, and naming as inventors Matthew T. Marx, Jerry K. Carter, Michael S. Phillips, Mark A. Holthouse, Stephen D. Seabury, Jose L. Elizondo-Cecenas, and Brett D. Phaneuf.","Since speech recognizer  deals with word strings rather than semantic information, the dynamic semantic models may be applied as a post-process. A callback  is coupled to application  and to speech recognizer  and n-best word strings . Callback  may be implemented in the form of a function call, defined according to an application programming interface (API), that application  may call to alter the probability value of any word string based on its keyword-value pairs and rules data . In one embodiment, the callback is called with parameters that include a keyword, a value, a scaling factor that is used to adjust the probability value of the associated word string, and one or more semantic tags that define when to apply the scaling factor.","Table 1 sets forth an example, in the C programming language, of a function that carries out application of a dynamic semantic model in the context of processing a time value, as well as a callback that may be placed in an application program for accessing the function. The function is named \u201cget_time_lm( )\u201d and the callback is named \u201cTimeLMCallback.\u201d The data structure TIME_LM *tlm contains the language model in the form of a table, and is read in during start-up time.",{"@attributes":{"id":"p-0048","num":"0047"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"287pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"CODE EXAMPLE"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"static int get_time_lm(TIME_LM *tlm, int time_in_minutes)"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"float lm_value;"]},{"entry":[{},"if((time_in_minutes >= 0) && (time_in_minutes < tlm\u2212>num_in_lm)) {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"lm_value = tlm\u2212>lm[time_in_minutes];"]},{"entry":[{},"log_msg(0,3,\u201cSetting time lm to lm[%d] = %8.4f\\n\u201d,time_in_minutes, lm_value);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":"else {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"log_msg(0,3,\u201cSetting time lm to floor = %8.4f\\n\u201d, tlm\u2212>floor);"]},{"entry":[{},"lm_value = tlm\u2212>floor;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":"return (int) (tlm\u2212>weight * (lm_value \u2212 tlm\u2212>offset));"},{"entry":"}"},{"entry":"int TimeLMCallback (const char * parse, int * score, void * data,"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"238pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"ALTsrBNFParseStorage *bnfdata)"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"{"},{"entry":"int time_in_minutes;"},{"entry":"int lm_value;"},{"entry":"TIME_LM * time_lm;"},{"entry":"time_lm = (TIME_LM *) data;"},{"entry":"if(time_lm == NULL) {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"log_msg(0,3,\u201cTime Language Model is NULL in TimeLMCallback\\n\u201d);"]},{"entry":[{},"return 0;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":"time_in_minutes = get_time_in_minutes(parse);"},{"entry":"lm_value = get_time_lm(time_lm, time_in_minutes);"},{"entry":"log_msg(0, 3,\u201cTIME LM :%s time_in_minutes %d LM %d\\n\u201d, parse,"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"time_in_minutes, lm_value);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"*score = lm_value;"]},{"entry":[{},"return 0;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"In this example, each row of the data structure TIME_LM comprises a key value in minutes (num_in_lm), an array of substitute time values, a floor value, a weight value, and an offset value. If the time value in minutes uttered by a speaker matches one of the key values, then the function obtains the corresponding substitute value from the data structure. The substitute value is returned, less the offset and multiplied by the weight value. Otherwise, the function returns the floor value. Thus, a value in a keyword-value pair associated with an uttered time value may be modified by comparing the uttered time value to one or more time values that are expected to be uttered, based on the current application and its context. Alternatively, the probability value of an associated word string may be modified.","In one embodiment, the floor value enables the system to ensure that a semantic value which is unlikely, but still possible, is ascribed a pre-determined minimum probability value that is greater than zero. This prevents unlikely utterances from being undesirably filtered out by the dynamic semantic mechanism. The offset value may enable the system to adjust or move the lowest assigned probability value to any desired value. In effect, use of an offset value moves the range of probability values up or down. In some embodiments, the offset value may be zero and the minimum probability value may be zero.","In still other embodiments, the probability value generated by the dynamic semantic mechanism, or some combination of the weight, offset, and floor values, is combined with an acoustic probability value to yield a final or global probability value.","Generating a probability value may be carried out by taking the logarithm of a root probability value. Thus, the computation for determining a modified probability value from the current probability value associated with a word string may be:\n\nProbability=(log(Current Probability)*Weight)+Offset)>=Floor\n","In any of these embodiments, operation of system  may proceed as follows. A customer or user of system  calls the system. Application  executes and prompts the customer to speak some information. The customer provides a speech signal at telephone , and the signal is communicated over connection  to speech recognizer . Speech recognizer  carries out speech recognition of the signal by using acoustic model  to convert the speech signal into one or more phonemes that are recognized or detected within the signal. Speech recognizer  may then convert the one or more phonemes into the n-best word strings  that may be represented by the phonemes. A probability value is created and stored in association with each of the n-best word strings . The probability value represents the likelihood that a particular word string is what was actually uttered.","Speech recognizer  may then apply parser  to the n-best word strings. The parser  has meaning extraction capabilities. As a result, one or more keyword-value pairs  are created and stored. The keyword-value pairs  represent the semantics of the speaker's utterance. Each keyword is an abstract identifier for some word or language element that has been recognized within the speech signal. Each keyword may be associated with a variable in application . Each value is something that has been recognized as spoken for the associated abstract language element. For example, a keyword could be \u201cFROM-CITY\u201d and an associated value could be \u201cAUSTIN.\u201d","The keyword-value pairs are passed up to speech processing modules , which may carry out logical operations based on the keyword-value pairs. In some cases, the speech processing modules  will pass the keyword-value pairs up to application  for further processing and logical decision-making according to business rules that are embodied in the application.","Application  may instruct speech recognizer  to change one of the probability values that is stored in association with one of the word strings, based on one or more of the keyword-value pairs, and according to the current semantic context and semantic decisions made by the application. For example, consider the above keyword-value pair (FROM-CITY, \u201cAUSTIN\u201d). From other information available to it, the application  may determine that the caller is calling from area code \u201c617\u201d and therefore that it is extremely unlikely that the caller wants to depart from Austin. In response, the application may change the probability value of one of the n-best word strings  that is associated with the keyword-value pair (FROM-CITY, \u201cAUSTIN\u201d) to better reflect the actual semantics of the utterance.","In an embodiment, application  may call a subroutine, method or procedure of speech recognizer  and pass parameters that define how the speech recognizer should change a probability value. Speech recognizer  receives and executes the function call according to the parameter. In response, after changing the probability value, speech recognizer  sorts or re-orders the n-best word strings  pairs to take into account the changed value.","As a result, speech recognizer  adjusts the way it recognizes speech from the customer or user dynamically according to the current semantic context of the application. Accordingly, improved accuracy is achieved in speech recognition.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 2"},"In block , one or more dynamic semantic rules are established. Block  may also involve analyzing statistical information about the actual performance of application , and deriving rules data  based upon log files, statistics files, etc. Thus, rules data  and the rules identified in block  may be derived probabilistically based on statistics tables or performance information from an application.","Alternatively, block  may involve the abstract definition of business rules or semantic rules that change according to the context of the application or according to one or more external factors. An example of a dynamic semantic rule is:","WHEN (AreaCode=617) THEN (DestinationCity!=BOSTON).","In one embodiment, the semantic rules are established by placing, in an application program, one or more calls to a function of the speech recognizer that carries out modifications of probability values of word strings that are associated with keyword-value pairs representing the semantic context of the current application. The semantic rules each include a semantic tag that defines the application context, external conditions, or internal conditions for which a probability value is to be modified. Each semantic tag may be associated with a scaling factor that defines how to change the probability value. Examples of scaling factors include \u201c0.2\u201d, \u201c50%\u201d, etc. The current value is multiplied by the scaling factor to arrive at the modified value. Alternatively, each semantic tag is associated with a substitute value, and the current value is removed and replaced by the substitute value.","In block , one or more logical routines that embody the dynamic semantic rules are created and stored. Block  may involve placing one or more function calls in an application program that operates in coordination with a speech recognizer. Each of the function calls has one or more parameters that implement the dynamic semantic rules. In alternate embodiment, the application may contain all the business logic and processing logic needed to alter the values, without calling back to the speech recognizer.","In block , an utterance is received. The utterance may be received, for example, when a customer or user of a speech recognition system calls the system. The application executes and prompts the customer to speak some information. The customer provides a speech signal at a telephone which is communicated to the speech recognizer.","In block , the speech recognizer carries out speech recognition of the signal by using an acoustic model to convert the speech signal into one or more phonemes. In block , the speech recognizer may convert the one or more phonemes into the n-best word strings that may be represented by the phonemes. Block  may also involve creating and storing a probability value in association with each of the n-best word strings. The probability value indicates the likelihood that the word string is what was actually spoken.","In block , speech recognizer may apply a parser with meaning extraction to the n-best word strings. As a result, one or more keyword-value pairs are created and stored for each of the word strings, as indicated by block . The keyword-value pairs represent abstract language elements and associated values that have been recognized in the speaker's utterance. Optionally, each keyword-value pair may be associated with a keyword probability value that represents a likelihood that the associated value is what was actually spoken for that keyword.","The keyword-value pairs may be passed up to one or more speech processing modules, which may carry out logical operations based on the keyword-value pairs. In some cases, the speech processing modules will pass the keyword-value pairs up to the application for further processing and logical decision-making according to business rules that are embodied in the application.","In block , a dynamic semantic model is applied to the keyword-value pairs. In one embodiment, the application may instruct the speech recognizer to change a probability value of a word string associated with one or more of the keywords, according to the current semantic context and semantic decisions made by the application. Thus, a probability value is modified, as shown in block .","For example, consider the airline reservation system example discussed above. In a function or subroutine, the application may read the current value of the system clock of the computer system on which the application is running. The application thus may determine that the current date is \u201cDecember 2.\u201d If the application then receives word strings and associated keyword-value pairs that include (Current-Month, \u201cSeptember\u201d) and (Current-Month, \u201cDecember\u201d), i.e., one or more ambiguous or confused values, the application may determine that \u201cSeptember\u201d is not likely to be the actual utterance. Stated abstractly, the application could determine that when a hypothesized word is a month that is less than the current month, then the hypothesized word is not likely to be part of the arrival date, so the probability value of its associated word string should be changed or scaled.","In an embodiment, the application may call a subroutine, method or procedure of the speech recognizer and pass parameters that define how the speech recognizer should change the probability value of a word string that is associated with a keyword-value pair. The speech recognizer receives and executes the function call according to the parameter. Execution of the function call may involve examining a current keyword-value pair, comparing it to a table of expected or likely values for that keyword, and modifying the probability value of a word string associated with the current keyword according to a substitute value, a weight, or an offset value. The substitute value, weight, and offset values may be selected in advance by an application developer according to the current context of the application","In block , after changing the value, the speech recognizer sorts or re-orders the word strings to take into account the changed value. The re-ordered word strings may be passed to and used by an application program in carrying out any desired function.","As a result, the speech recognizer recognizes speech from the customer or user, and modifies its output according to the current semantic context of the application.",{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 3","b":["300","300","302","304","302","300","306","302","304","306","304","300","308","302","304","310","302"]},"Computer system  may be coupled via bus  to a display , such as a cathode ray tube (CRT), for displaying information to a computer user. An input device , including alphanumeric and other keys, is coupled to bus  for communicating information and command selections to processor . Another type of user input device is cursor control , such as a mouse, a trackball, or cursor direction keys for communicating direction information and command selections to processor  and for controlling cursor movement on display . This input device typically has two degrees of freedom in two axes, a first axis (e.g., x) and a second axis (e.g., y), that allows the device to specify positions in a plane.","The invention is related to the use of computer system  for speech recognition processing using a dynamic semantic model. According to one embodiment of the invention, speech recognition processing using a dynamic semantic model is provided by computer system  in response to processor  executing one or more sequences of one or more instructions contained in main memory . Such instructions may be read into main memory  from another computer-readable medium, such as storage device . Execution of the sequences of instructions contained in main memory  causes processor  to perform the process steps described herein. In alternative embodiments, hard-wired circuitry may be used in place of or in combination with software instructions to implement the invention. Thus, embodiments of the invention are not limited to any specific combination of hardware circuitry and software.","The term \u201ccomputer-readable medium\u201d as used herein refers to any medium that participates in providing instructions to processor  for execution. Such a medium may take many forms, including but not limited to, non-volatile media, volatile media, and transmission media. Non-volatile media includes, for example, optical or magnetic disks, such as storage device . Volatile media includes dynamic memory, such as main memory . Transmission media includes coaxial cables, copper wire and fiber optics, including the wires that comprise bus . Transmission media can also take the form of acoustic or light waves, such as those generated during radio-wave and infra-red data communications.","Common forms of computer-readable media include, for example, a floppy disk, a flexible disk, hard disk, magnetic tape, or any other magnetic medium, a CD-ROM, any other optical medium, punchcards, papertape, any other physical medium with patterns of holes, a RAM, a PROM, and EPROM, a FLASH-EPROM, any other memory chip or cartridge, a carrier wave as described hereinafter, or any other medium from which a computer can read.","Various forms of computer readable media may be involved in carrying one or more sequences of one or more instructions to processor  for execution. For example, the instructions may initially be carried on a magnetic disk of a remote computer. The remote computer can load the instructions into its dynamic memory and send the instructions over a telephone line using a modem. A modem local to computer system  can receive the data on the telephone line and use an infra-red transmitter to convert the data to an infra-red signal. An infra-red detector can receive the data carried in the infra-red signal and appropriate circuitry can place the data on bus . Bus  carries the data to main memory , from which processor  retrieves and executes the instructions. The instructions received by main memory  may optionally be stored on storage device  either before or after execution by processor .","Computer system  also includes a communication interface  coupled to bus . Communication interface  provides a two-way data communication coupling to a network link  that is connected to a local network . For example, communication interface  may be an integrated services digital network (ISDN) card or a modem to provide a data communication connection to a corresponding type of telephone line. As another example, communication interface  may be a local area network (LAN) card to provide a data communication connection to a compatible LAN. Wireless links may also be implemented. In any such implementation, communication interface  sends and receives electrical, electromagnetic or optical signals that carry digital data streams representing various types of information.","Network link  typically provides data communication through one or more networks to other data devices. For example, network link  may provide a connection through local network  to a host computer  or to data equipment operated by an Internet Service Provider (ISP) . ISP  in turn provides data communication services through the world wide packet data communication network now commonly referred to as the \u201cInternet\u201d . Local network  and Internet  both use electrical, electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on network link  and through communication interface , which carry the digital data to and from computer system , are exemplary forms of carrier waves transporting the information.","Computer system  can send messages and receive data, including program code, through the network(s), network link  and communication interface . In the Internet example, a server  might transmit a requested code for an application program through Internet , ISP , local network  and communication interface . In accordance with the invention, one such downloaded application provides for speech recognition processing using a dynamic semantic model as described herein.","The received code may be executed by processor  as it is received, and\/or stored in storage device , or other non-volatile storage for later execution. In this manner, computer system  may obtain application code in the form of a carrier wave.","The description in this document may be presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. The algorithms descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art.","An algorithm may be generally understood as a self-consistent sequence of steps leading to a desired result. These steps generally require physical manifestation of physical quantities. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared and otherwise manipulated. This document may refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like. However, all of these terms are to be associated with appropriate physical quantities and are merely convenient labels applied to these quantities.","Further, the manipulations performed are often referred to in terms (such as \u201cadding\u201d or \u201ccomparing\u201d) that are commonly associated with mental operations performed by a human operator. No such capability of a human operator is necessary, or desirable in most cases, in any of the operations described herein, unless specifically identified otherwise. The operations are machine operations. Useful machines for performing the operations of the present invention include general-purpose digital computers or other similar devices. This document relates to method of operating a computer in processing electrical or other physical signals to generate other desired physical signals.","One embodiment of the invention is an apparatus for performing these operations. Such an apparatus may be specially constructed for the required purposes or it may comprise a general-purpose digital computer as selectively activated or re-configured by a computer program stored in the computer. The algorithms presented herein are not inherently related to any particular computer or other apparatus. In particular, various general-purpose machines may be used with the teachings herein, or it may prove more convenient to construct more specialized apparatus to perform the required method steps. The required structure for a variety of these machines will appear from the description in this document.","In the foregoing specification, the invention has been described with reference to specific embodiments thereof. The description includes numerous details in order to provide a thorough understanding. These details may be omitted, and various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention. The specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings and in which like reference numerals refer to similar elements and in which:",{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 3"}]},"DETDESC":[{},{}]}
