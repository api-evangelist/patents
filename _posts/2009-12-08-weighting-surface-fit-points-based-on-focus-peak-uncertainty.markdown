---
title: Weighting surface fit points based on focus peak uncertainty
abstract: A machine vision inspection system acquires a plurality of images of a workpiece region of interest at various focus heights, and determines a Z-height (e.g., the best focus height) for the region of interest based on a focus peak determining data set for the region of interest. The focus peak determining data set is derived from the plurality of images. The machine vision inspection system also determines Z-height quality meta-data based on data derived from the plurality of images (e.g., based on the focus peak determining data set), and associates the Z-height quality meta-data with the corresponding Z-heights. The Z-height quality meta-data are usable to establish weighting factors that are used in association with the corresponding best focus Z-heights in subsequent operations that fit a workpiece surface representation to a plurality of the best focus Z-heights.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08581162&OS=08581162&RS=08581162
owner: Mitutoyo Corporation
number: 08581162
owner_city: Kawasaki-shi
owner_country: JP
publication_date: 20091208
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["The present disclosure relates generally to machine vision inspection systems, and more particularly to methods related to precise dimensional inspection using a machine vision system.","Precision machine vision inspection systems (or \u201cvision systems\u201d for short) can be utilized to obtain precise dimensional measurements of inspected objects and to inspect various other object characteristics. Such systems may include a computer, a camera and optical system, and a precision stage that is movable in multiple directions so as to allow the camera to scan the features of a workpiece that is being inspected. One exemplary prior art system that is commercially available is the QUICK VISION\u00ae series of PC-based vision systems and QVPAK\u00ae software available from Mitutoyo America Corporation (MAC), located in Aurora, Ill. The features and operation of the QUICK VISION\u00ae series of vision systems and the QVPAK\u00ae software are generally described, for example, in the 3, published January 2003, and the 3, published September 1996, each of which is hereby incorporated by reference in their entirety. This product, as exemplified by the QV-302 Pro model, for example, is able to use a microscope-type optical system to provide images of a workpiece at various magnifications, and move the stage as necessary to traverse the workpiece surface beyond the limits of any single video image. A single video image typically encompasses only a portion of the workpiece being observed or inspected, given the desired magnification, measurement resolution, and physical size limitations of such systems.","Machine vision inspection systems generally utilize automated video inspection. U.S. Pat. No. 6,542,180, (hereinafter \u201cthe '180 patent\u201d) teaches various aspects of such automated video inspection and is incorporated herein by reference in its entirety. As taught in the '180 patent, automated video inspection metrology instruments generally have a programming capability that allows an automatic inspection event sequence to be defined by the user for each particular workpiece configuration. This can be implemented by text-based programming, for example, or through a recording mode which progressively \u201clearns\u201d the inspection event sequence by storing a sequence of machine control instructions corresponding to a sequence of inspection operations performed by a user, or through a combination of both methods. Such a recording mode is often referred to as \u201clearn mode\u201d or \u201ctraining mode.\u201d Once the inspection event sequence is defined in \u201clearn mode,\u201d such a sequence can then be used to automatically acquire (and additionally analyze or inspect) images of a workpiece during \u201crun mode.\u201d","The machine control instructions including the specific inspection event sequence (i.e., how to acquire each image and how to analyze\/inspect each acquired image) are generally stored as a \u201cpart program\u201d or \u201cworkpiece program\u201d that is specific to the particular workpiece configuration. For example, a part program defines how to acquire each image, such as how to position the camera relative to the workpiece, at what lighting level, at what magnification level, etc. Further, the part program defines how to analyze\/inspect an acquired image, for example, by using one or more video tools such as edge\/boundary detection video tools.","Video tools (or \u201ctools\u201d for short) may be used manually to accomplish manual inspection and\/or machine control operations. Their set-up parameters and operation can also be recorded during learn mode, in order to create automatic inspection programs, or \u201cpart programs.\u201d Set-up parameters may typically be configured using various graphical user interface widgets and\/or menus of the vision inspection system software. Such tools may include, for example, edge\/boundary detection tools, autofocus tools, shape or pattern matching tools, dimension measuring tools, and the like. For example, such tools are routinely used in a variety of commercially available machine vision inspection systems, such as the QUICK VISION\u00ae series of vision systems and the associated QVPAK\u00ae software, discussed above.","Accuracies in the micron or sub-micron range are often desired in such systems. This is particularly challenging with regard to Z-height measurements. Z-height measurements (along the optical axis of the camera system) are generally derived from a \u201cbest focus\u201d position, such as that determined by an autofocus tool. Determining a best focus position is a relatively complex process that generally depends on combining and\/or comparing information derived from multiple images. Thus, the level of precision and reliability achieved for Z-height measurements is often less than that achieved for the X- and Y-measurement axes, where measurements are typically based on feature relationships within a single image.","A particular problem arises when determining a plurality of three-dimensional (3D) data points across the surface of a workpiece, and attempting to use the resulting 3D data points together to determine the shape or profile of the surface. A set of 3D data points may be referred to as \u201cpoint cloud\u201d data. Typically, a curve or surface is fit to the point cloud data. However, the Z-height accuracy and reliability may be poor for at least some of the 3D data points, for a number of reasons. As a first example, when the surface is strongly curved (e.g., the surface of an IC ball grid array solder ball), some parts of the surface are at an extreme angle of incidence, such that they return little light and are underexposed in the autofocus images. As a another example, some parts of the surface may be highly textured, such that they include a range of local Z heights that simply cannot be imaged or \u201cautofocused\u201d with an uncertainty that is less than their Z range. As a result, it is frequently necessary for a surface or curve fitting algorithm to deal with point cloud data that includes poor quality Z-height coordinates.","While there are many known algorithmic approaches for fitting point cloud data that includes poor quality Z-height coordinates, most of them rely simply on some method of weighting and\/or rejected geometric outliers. Defining a geometric outlier is generally based on how far a point deviates from a current best fit curve or surface. There are many approaches to weighting or rejecting point cloud data points based on their distance from a current fit: Tukey's Biweight, Andrew's Sine, Huber, Welsch, Hampel, and others. These are all approaches to minimize the effect that outliers have on the final fit by adjusting the weight of each individual point based on distance from the current fit. In some algorithms, the weighting may be iteratively determined\u2014that is, distance from a first surface determines a first point weighting, then using that point weighting the best fit surface is re-determined, and so on until a stable result is achieved. In some algorithms, the fitted curve or surface may be constrained based on predetermined design information. Certain literature on robust estimation (or fitting) can be found at http:\/\/en.wikipedia.org\/wiki\/Robust_statistics, as well as in U.S. Pre-Grant Publication Nos. 2005\/0216237A1 and 2009\/0103773A1.","However, because they are basically \u201cblind\u201d methods that simply treat geometric data statistically, the foregoing methods are at significant risk for eliminating valid data corresponding to localized defects, or having results influenced in a subtle way by low-reliability data that does not fall outside of predetermined geometric thresholds. Some systems for analyzing machine vision point cloud data simply live with these risks, and\/or perform time-consuming data self-consistency checking and\/or ad-hoc heuristic analysis in addition to simple geometric surface fitting. Other systems allow or require an operator to manually review the point cloud data and\/or fitting results in order to influence the elimination of outliers (e.g., by manual rejection or acceptance, or the like). However, such systems retain a significant possibility for error and\/or are time consuming, or both. The present disclosure is directed to providing systems and methods that overcome the foregoing and other disadvantages.","This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter.","In contrast to known point cloud fitting methods that rely on weighting and\/or rejecting data points based on statistical analysis of geometric data, a system and method are disclosed that associate respective Z-height coordinates with respective Z-height meta-data that is indicative of their quality or uncertainty. In general, such meta-data is referred to here as Z-height quality meta-data, or a Z-height quality metric, regardless of its specific derivation or final form; as long as it qualitatively or quantitatively indicates the relative reliability or uncertainty of a Z-height coordinate. Subsequently, a point cloud fitting method may rely on weighting and\/or rejecting data points based on their Z-height quality meta-data. In some embodiments, a point cloud fitting method may include data point weighting and\/or rejection based on the Z-height quality meta-data in combination with statistical analysis of geometric data.","In accordance with one aspect of the present disclosure, a machine vision inspection system may implement a method that acquires a plurality of images of a defined workpiece region of interest at various focus heights and determines a best focus Z height (e.g., the best focus height) for the defined region of interest based on a focus peak determining data set for the region of interest. The focus peak determining data set is derived from the plurality of images. The machine vision inspection system also determines Z-height quality meta-data for the region of interest based on data derived from the plurality of images (e.g., based on the focus peak determining data set), and associates the Z-height quality meta-data with the corresponding Z height. The Z-height quality meta-data is indicative of the reliability and\/or uncertainty of the corresponding best focus Z height for the region of interest. The Z-height quality meta-data is associated with (e.g., stored and\/or applied in association with) the corresponding best focus Z height such that it is usable to establish a weighting factor that may be used in association with the corresponding best focus Z height in subsequent operations that fit a workpiece surface representation to a plurality of such best focus Z heights.","In various embodiments, determining the Z-height quality meta-data for a focus region of interest may comprise determining a representative noise level indicated by the data used to determine the best focus Z height for that focus region of interest. In some embodiments, determining the Z-height quality meta-data may comprise determining a relationship (e.g., a ratio or a quotient) between a representative peak height indicated by the focus peak determining data set and a representative noise level indicated by the focus peak determining data set. In some embodiments, the Z-height quality meta-data may be expressed in the form of a weighting factor that is directly usable in workpiece surface fitting operations. In some embodiments, that the Z-height quality meta-data may be used to identify invalid best focus Z heights for corresponding focus regions of interest (e.g., by comparing the Z-height quality meta-data to a Z-height quality meta-data threshold value, or identifying statistically determined Z-height quality meta-data outliers).","The best focus Z-height measurements referred to above (along the optical axis and focusing axis of the camera system) may be derived from a \u201cbest focus\u201d position, such as that determined by an autofocus tool or method. In such tools or methods the camera may move through a range of positions along a Z axis (the focusing axis) and capture an image at each position. For each captured image, a focus metric may be calculated based on a region of interest (e.g., a set of pixels) in the image and related to the corresponding position of the camera along the Z axis at the time that the image was captured. This results in focus curve data (which is one type of focus peak determining data set), which may be referred to simply as a \u201cfocus curve\u201d or \u201cautofocus curve.\u201d The peak of the focus curve, which corresponds to the best focus position along the Z axis, is the Z height for the region of interest used to determine the focus curve. The peak of the focus curve may be found by fitting a curve to the focus curve data and estimating the peak of the fitted curve. In some such embodiments, the Z-height quality meta-data (e.g., a Z-height quality metric) referred to above may be determined based on the characteristics of the corresponding focus curve data.","In one implementation, a precision machine vision inspection system may comprises a graphical user interface and an autofocus video tool, and at least at least some of the operations outlined above may be performed automatically as operations associated with the autofocus video tool. The graphical user interface may be configured to allow the user to select an autofocus tool that provides Z-height quality meta-data from a plurality of alternative autofocus tools, and configure the operating parameters of that autofocus video tool. In one embodiment, a multi-point autofocus tool may be so selected and\/or configured, and Z heights and Z-height quality meta-data may be determined for a plurality of focus sub-regions of interest within a global region of interest of the multi-point autofocus tool. In some implementations, the sub-regions of interest have an area that is at most 9\u00d79 pixels, or 7\u00d77 pixels, or less. The present disclosure provides particular advantages in association with Z heights that are based on small focus regions of interest.","It will be appreciated that a fitting procedure that includes weighting factors determined based on Z-height quality meta-data according to this disclosure may in some instances provide relatively small improvements in accuracy (e.g., sub-micron improvements for certain magnifications). However, even small improvements in the accuracy and\/or robustness of such measurement operations are important in numerous applications, while also being difficult to achieve. The present disclosure may achieve such improvements, and may in particular provide advantages when performing surface fitting operations related to inspecting certain surfaces that present difficulties for deriving Z coordinates from autofocus operations.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 1","b":["10","10","12","14","14","16","18","22","24","26","16","10"]},"The vision measuring machine  includes a moveable workpiece stage  and an optical imaging system  which may include a zoom lens or interchangeable lenses. The zoom lens or interchangeable lenses generally provide various magnifications for the images provided by the optical imaging system . The machine vision inspection system  is generally comparable to the QUICK VISION\u00ae series of vision systems and the QVPAK\u00ae software discussed above, and similar state-of-the-art commercially available precision machine vision inspection systems. The machine vision inspection system  is also described in commonly assigned U.S. Pat. No. 7,454,053, and in commonly assigned U.S. patent application Ser. No. 12\/343,383, filed Dec. 23, 2008, now U.S. Pat. No. 8,111,938, issued Feb. 7, 2012, which are each hereby incorporated herein by reference in their entireties. Various aspects of vision measuring machines and control systems are also described in more detail in commonly assigned U.S. Pre-Grant Publication No. 2005\/0031191A1 and U.S. Pat. No. 7,324,682, which are also each hereby incorporated herein by reference in their entireties.",{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 2","b":["120","200","100","120","200","200","205","220","230","240","210","212","210","20","205","260","250","280","286","288","230","205","294"]},"A workpiece  that is to be imaged using the machine vision inspection system  is placed on the workpiece stage . One or more of a stage light , a coaxial light , and a surface light  may emit source light , , or , respectively, to illuminate the workpiece . The source light is reflected or transmitted as workpiece light , which passes through the interchangeable objective lens  and the turret lens assembly  and is gathered by the camera system . The image of the workpiece , captured by the camera system , is output on a signal line  to the control system portion . The light sources , , and  may be connected to the control system portion  through signal lines or busses , , and , respectively. To alter the image magnification, the control system portion  may rotate the turret lens assembly  along axis , to select a turret lens, through a signal line or bus .","In various exemplary embodiments, the optical assembly portion  is movable in the vertical Z-axis direction relative to the workpiece stage  using a controllable motor  that drives an actuator, a connecting cable, or the like, to move the optical assembly portion  along the Z axis to change the focus of the image of the workpiece  captured by the camera system . The term \u201cZ axis,\u201d as used herein, refers to the axis that is intended to be used for focusing the image obtained by the optical assembly portion . The controllable motor , when used, is connected to the input\/output interface  via a signal line .","As shown in , in various exemplary embodiments, the control system portion  includes a controller , an input\/output interface , a memory , a workpiece program generator and executor , and a power supply portion . Each of these components, as well as the additional components described below, may be interconnected by one or more data\/control buses and\/or application programming interfaces, or by direct connections between the various elements.","The input\/output interface  includes an imaging control interface , a motion control interface , a lighting control interface , and a lens control interface . The motion control interface  may include a position control element , and a speed\/acceleration control element . However, it should be appreciated that in various exemplary embodiments, such elements may be merged and\/or indistinguishable. The lighting control interface  includes lighting control elements -, which control, for example, the selection, power, on\/off switch, and strobe pulse timing if applicable, for the various corresponding light sources of the machine vision inspection system .","The memory  includes an image file memory portion , a workpiece program memory portion  that may include one or more part programs, or the like, a 3D data memory portion  which may include a Z-height quality data memory portion , and a video tool portion . The video tool portion  includes representative tool portion (and other analogous video tool portions, not shown), which determines the GUI, image processing operation, etc., for each of the corresponding tools. The video tool portion  also includes a region of interest generator that supports automatic, semi-automatic and\/or manual operations that define various ROIs that are operable in various video tools included in the video tool portion .","The video tool portion  includes the autofocus tools portion , which provides various operations and features related to autofocus operations, as described in greater detail below. In one embodiment, the autofocus tools portion may include an autofocus mode control , autofocus tools , and a Z-height quality determining portion . Briefly, the autofocus tools may perform various operations similarly to known autofocus tools, for example, performing operations in learn mode and run mode such as utilizing a selected lighting level for acquiring a current image stack at various Z heights, generating all or part of a focus curve, and finding its peak as a best focus position. Additional autofocus tool operations which are the subject of this disclosure are described in greater detail below. The autofocus mode control may perform operations, as disclosed herein, to configure the autofocus tools , and\/or the Z heights quality determining portion and\/or autofocus tool modes, depending on which tool or mode is activated.","As will be described in more detail below, the Z-height quality determining portion may operate to determine a Z-height quality metric for a defined region of interest based on a focus peak determining data set for that region of interest. In some embodiments, a region or sub-region of interest may comprise a small set of pixels defined to correspond to, or represent, individual pixel locations. In some embodiments, a Z-height weighting factor may be determined by the Z-height quality determining portion for each region or sub-region of interest, based on the Z-height quality metric. In other embodiments, Z-height weighting factor determination is performed later in association with point cloud processing operation, based on the Z-height quality metrics, by a separate processor or a separation portion of the control system portion . The Z-height quality metrics and\/or Z-height quality weighting factors may be utilized for weighting the corresponding Z coordinates when fitting point cloud data, such that Z coordinates corresponding to low or high Z-height quality metrics receive corresponding low or high weighting in the fitting procedure. This procedure uses meta-data derived based on autofocus image data to overcome several of the disadvantages previously outlined with regard to weighting procedures that rely purely on statistical analysis of geometric data.","Alternative configurations are also possible for the autofocus tools portion . For example, the autofocus tools and Z-height quality determining portion may include partitioned mode control functions such that a separate mode control portion may be omitted. Alternatively, the autofocus tools portion may provide one or more generic autofocus tool elements, and the mode control portion may provide operations that govern the user interface and interrelationships of the generic autofocus tool elements in a manner that depends on which tool behavior is desired. In such a case, the circuits, routines, or applications that provide the operations of the autofocus tools , and\/or the Z-height quality determining portion may be merged and\/or indistinguishable.","In certain implementations, the autofocus mode control may be utilized to implement a Z-height quality metric determining autofocus mode (as opposed to a separate tool). More generally, this disclosure may be implemented in any now known or later-developed form that is operable in conjunction with the machine vision inspection system  to provide the features disclosed herein in relation to the autofocus operations.","In general, the memory portion  stores data usable to operate the vision system components portion  to capture or acquire an image of the workpiece  such that the acquired image of the workpiece  has desired image characteristics. The memory portion  may also store inspection result data, and further may store data usable to operate the machine vision inspection system  to perform various inspection and measurement operations on the acquired images (e.g., implemented, in part, as video tools), either manually or automatically, and to output the results through the input\/output interface . The memory portion  may also contain data defining a graphical user interface operable through the input\/output interface .","The signal lines or busses , , and  of the stage light , the coaxial light , and the surface light , respectively, are all connected to the input\/output interface . The signal line  from the camera system  and the signal line  from the controllable motor  are connected to the input\/output interface . In addition to carrying image data, the signal line  may carry a signal from the controller  that initiates image acquisition.","One or more display devices  and one or more input devices  can also be connected to the input\/output interface . The display devices  and input devices  can be used to display a user interface, which may include various graphical user interface (GUI) features that are usable to perform inspection operations, and\/or to create and\/or modify part programs, to view the images captured by the camera system , and\/or to directly control the vision system components portion . In a fully automated system having a predefined part program (or workpiece program), the display devices  and\/or the input devices  may be omitted.","In various exemplary embodiments, when a user utilizes the machine vision inspection system  to create a part program for the workpiece , the user generates part program instructions either by explicitly coding the instructions automatically, semi-automatically, or manually, using a workpiece programming language, or by generating the instructions by operating the machine vision inspection system  in a learn mode to provide a desired image acquisition training sequence. For example, a training sequence may comprise positioning a workpiece feature in the field of view (FOV), setting light levels, focusing or autofocusing, acquiring an image, and providing an inspection training sequence applied to the image (e.g., using video tools). The learn mode operates such that the sequence(s) are captured and converted to corresponding part program instructions. These instructions, when the part program is executed, will cause the machine vision inspection system to reproduce the trained image acquisition and inspection operation to automatically inspect a workpiece or workpieces matching the workpiece used when creating the part program.","These analysis and inspection methods that are used to inspect features in a workpiece image are typically embodied in various video tools included in the video tool portion  of the memory , including the autofocus tools , which may include and\/or implement the associated operations of the Z-height quality determining portion . Many known video tools, or \u201ctools\u201d for short, are exemplified in commercially available machine vision inspection systems, such as the QUICK VISION\u00ae series of vision systems and the associated QVPAK\u00ae software, discussed above.","Autofocus tools such as tools typically acquire series of images and analyze focus curves as part of a process for determining one or more \u201cbest focus\u201d positions corresponding to the peaks of the focus curves. As will be described in more detail below, by utilizing the methods of the present disclosure which determine Z-height quality metrics (e.g., such as are determined by the Z-height quality determining portion ) and corresponding Z-height quality weighting factors, the accuracy and reliability of shape-fitting algorithms and overall measurement processes are improved.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 3","b":["300","310","310","310"]},"In the embodiment shown in , the focus metric values (that is, the values depicted along the y-axis direction in the graph ) have been normalized so that the maximum value is one. This normalization may be convenient in some embodiments, but may be omitted in other embodiments. In some embodiments, the focus metric values may be based on a calculation of the contrast or sharpness of the region of interest in images included in an autofocus image stack (that is, a set of images focused at various Z heights). The X axis represents the Z heights of the images included in the autofocus image stack, ranging from 0 to 250 microns in this specific example.","It will be appreciated that various data points of the focus curve  include a significant noise component. Therefore, the focus curve is not smooth and the estimated focus peak Zp (e.g., as estimated based on the peak location of a curve such Gaussian curve fit to the focus curve ) should be regarded as relatively uncertain. For example, by inspection of the focus curve  it appears that one may be relatively certain that Zp is accurate within +\/\u221230 microns, but it is quite uncertain that it is accurate within +\/\u22125 microns. It will be appreciated that the uncertainty of Zp could be much greater if the focus curve data were not so densely sampled along the Z-height axis (that is, if relatively few image stack images were widely spaced along the Z axis). Factors that contribute to noisy focus curve data and focus peak or Z height uncertainty may generally include having a small number of pixels in the region of interest, having a very rough or multi-level surface in the region of interest, and\/or poor lighting.","For example, with few pixels in the region of interest (e.g., 36 pixels, or even as few as 9 pixels), light from \u201csurrounding pixels\u201d outside the region of interest may blur into a significant portion of the region of interest, thus \u201ccontaminating\u201d the focus curve for the region of interest. Also, for few pixels in the region of interest along with a very rough surface, the region of interest may actually have no \u201cbest\u201d focus height. In such a case, for random texturing, the noise for each focus curve data point may be approximately inversely proportional to the square root of the number of pixels in the region of interest (e.g., if each portion of the surface that corresponds to a particular pixel is at a different random height). Thus, the focus curve data for a small region of interest may appear particularly noisy. In addition, poor lighting due to poor settings or due to an inherently intractable surface, may result in over or under exposure of pixels in the region of interest, leading to inherently low contrast and poor signal to noise in the focus metrics used for establishing the focus curve.","As will be described in more detail below, in accordance with the present disclosure, a Z-height quality metric or meta-data may be utilized to characterize the relative noise or Z-height uncertainty reflected in a focus peak determining data set (e.g., the focus curve data ) for a region of interest. The Z-height quality metric or meta-data thus tends to indicate the relative reliability or uncertainty associated with a Z-height estimate based on a particular focus peak determining data set for a particular region of interest. Respective Z-height quality weighting factors may be determined based on each respective Z-height quality metric or meta-data, for conveniently and appropriately reflecting the relative reliability or uncertainty of each respective Z-height coordinate used by a point cloud fitting routine.","In one embodiment, the Z-height quality meta-data may be defined as a metric based on a relationship (e.g., a ratio) between a representative focus metric peak height indicated by a focus peak determining data set and a representative noise level or \u201cnoise height\u201d indicated by the focus peak determining data set. For example,  shows a representative focus metric maximum value FMmax (e.g., as established by fitting a curve to the data  and taking its maximum value, or averaging the maximum 10% of the data ), and a focus metric baseline value FMbaseling (e.g., as established by averaging the minimum 40% of the data ). The representative focus metric peak height FMPH may be determined as the difference between FMmax and FMbaseline, in this example.",{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 3","b":["310","310"]},{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIGS. 4A and 4B","FIG. 4A","FIG. 4B","FIG. 4A"],"b":["400","401","402","400","1","2","1","2","401","402","450"],"i":["i","i"]},"Regarding the term \u201cregion of interest,\u201d it should be appreciated that some \u201csingle point\u201d autofocus tools return a single Z height corresponding to an entire region of interest. However, known \u201cmulti-point\u201d type autofocus tools may return multiple Z heights corresponding to individual \u201csub-regions of interest\u201d (e.g., a grid of sub-regions of interest) within a global region of interest defined by the multi-point type autofocus tool. For example, such sub-regions of interest may be manually and\/or automatically defined as centered on each (or most) pixels within the global region of interest. Thus, in some cases, ROI() and ROI() may be regarded as representative sub-regions of interest within a global region of interest.","Both a Z height and a Z-height quality metric may be established according to this disclosure for any defined autofocus region of interest, whether it is a region of interest of a single point autofocus tool or a sub-region of interest within a global region of interest defined by a multi-point autofocus tool. Thus, it will be understood that when the term region of interest is used in relation to establishing a Z height and\/or a Z-height quality metric, that sub-regions of interest (e.g., within a global region of interest defined by a multi-point autofocus tool) may be encompassed within the meaning of that term. To illustrate this point, the regions of interest ROI() and ROI() are shown to be relatively small (e.g., 3\u00d73 pixels), as would be typical of some sub-regions of interest of a multi-point autofocus tool. For example, such a region size may be utilized for determining a focus peak for a single central pixel in each region (or sub-region) of interest, in some embodiments.","As shown in , each of the images image()-image() of the image stack image(i) include the centrally located region of interest ROI() for which the determined focus metric values correspond to the focus metric data points fm(,) on the focus curve . The region of interest ROI() is schematically indicated in  as including a relatively high level of contrast (e.g., in image()), corresponding to the relatively greater focus metric values shown on the focus curve . Similarly, each of the images image()-image() of the image stack image(i) include the peripherally located region of interest ROI() for which the determined focus metric values correspond to the focus metric data points fm(,) on the focus curve . The region of interest ROI() is schematically indicated in  as including a relatively low level of contrast (e.g., in image()), corresponding to the relatively lesser focus metric values shown on the focus curve .","As shown in , each focus metric value fm(,) or fm(,) may be regarded as sampling continuous underlying focus data S or S, respectively. It may be seen in  that the underlying focus data S or S is relatively noisy (e.g., due to the small size of the corresponding regions of interest). However, in the case of the focus curve , due to higher contrast in the corresponding region of interest the focus metric values in the vicinity of the focus curve peak (e.g., near Zp) are relatively large compared to the size of the \u201cnoise component\u201d in the underlying focus data. In contrast, in the case of the focus curve , due to low contrast in the corresponding region of interest, the focus metric values in the vicinity of the focus curve peak (e.g., near Zp) are relatively similar to the size of the \u201cnoise component\u201d in the underlying focus data.","In one specific example, the higher focus metric values indicated in the focus curve  may be due to the surface area in the region of interest ROI() being highly textured and producing high contrast in focused images. In comparison, the lower focus metric values indicated in the focus curve  may be due to the surface area in the region of interest ROI() having little texture and producing little contrast in focused images. In any case, it will be appreciated that because of the low \u201csignal to noise\u201d associated with the lower peak of the focus curve , as compared to relatively high signal to noise associated with the peak of the focus curve , that the estimated Z height of the focus peak Zp of the focus curve  is less reliable or more uncertain than the estimated Z height of the focus peak Zp of the focus curve .","Thus, in accordance with the present disclosure, a lower Z-height quality metric should be determined for the estimated Z height of the focus peak Zp, than for the estimated Z height of the focus peak Zp. As a result, a point cloud fitting algorithm that establishes data point weighting based on Z-height quality metric meta-data may be made to rely more heavily on the estimated Z height of the focus peak Zp, as compared to the estimated Z height of the focus peak Zp, when estimating the shape or location of the surface region . The determination of Z-height quality metrics is described further below.","Autofocus operations associated with determining a Z height for a region of interest have been previously outlined. Briefly summarizing in relation to , a camera may move through a range of Z-height positions Z(i) along a Z axis (the focusing axis) and capture an image(i) at each position. For each captured image(i), a focus metric fm(k,i) may be calculated based on a region or sub-region of interest ROI(k) (e.g., a set of pixels) in the image and related to the corresponding position Z(i) of the camera along the Z axis at the time that the image was captured. This results in focus curve data (e.g., the focus metrics fm(k,i) at the positions Z(i), which is one type of focus peak determining data set), which may be referred to simply as a \u201cfocus curve\u201d or \u201cautofocus curve.\u201d","In one embodiment, the focus metric values may involve a calculation of the contrast or sharpness of the region of interest in the image. In various embodiments, the focus values or curves may be normalized. Various focus metric calculation techniques are described in detail in the incorporated references, and various suitable focus metric functions will also be known to one of ordinary skill in the art.","The Z height (e.g., Zp or Zp) corresponding to the peak of the focus curve, which corresponds to the best focus position along the Z axis, is the Z height for the region of interest used to determine the focus curve. The Z height corresponding to the peak of the focus curve may be found by fitting a curve (e.g., the curve  or ) to the focus curve data (e.g., the data fm(,) or fm(,)) and estimating the location peak of the fitted curve. It will be appreciated that while the image stack image(i) is shown for purposes of illustration as only including eleven images, in an actual embodiment a larger number of images (e.g., 100 or more) may be utilized. Exemplary techniques for the determination and analysis of image stacks and focus curves are taught in U.S. Pat. No. 6,542,180, which is commonly assigned and hereby incorporated herein by reference in its entirety.","As indicated previously, in accordance with the present disclosure, it is desired to assign Z-height quality meta-data indicating higher data reliability or lower uncertainty to Z heights estimated for regions of interest that produce higher focus metric values relative to the underlying noise levels (e.g., the focus curve ), and to assign Z-height quality meta-data indicating lower data reliability or higher uncertainty to Z heights estimated for regions of interest that produce lower focus metric values relative to the underlying noise levels (e.g., the focus curve ). As previously outlined, in some embodiments, the Z-height quality meta-data may be defined as a metric based on a relationship (e.g., a ratio or quotient) between a representative peak height indicated by the focus peak determining data set and a representative noise level or \u201cnoise height\u201d indicated by the focus peak determining data set.","In one embodiment, such a metric may be defined as the ratio of the maximum value of the focus peak determining data set (or a curve fit to the focus peak determining data set) minus a baseline value of the focus peak determining data set (or a curve fit to the focus peak determining data set) divided by an estimated noise value of the focus peak determining data set. In certain implementations, the baseline of the focus peak determining data set may be estimated as its median value, wherein most of the values in that set may be near the baseline and only a relatively small number of values may occur in the region of the focus peak. Such a focus peak determining data set may correspond to an image stack comprising a relatively large number of images (e.g., 100 images) spread over a fairly large Z-height range about the best focus position, for example. In certain implementations, the estimated noise value may be determined as the median absolute difference from the median of the focus peak determining data set. In such a case, the corresponding Z-height quality metric may be determined in some implementations according to:",{"@attributes":{"id":"p-0064","num":"0063"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"ZQM","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},"mo":"=","mfrac":{"mrow":[{"mo":["(",")"],"mrow":{"mrow":[{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"fm","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","i"],"mo":","}}}}},{"mi":"median","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"fm","mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mi":["k","i"],"mo":","}}}}}],"mo":"-"}},{"mi":"median","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mi":"fm","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","i"],"mo":","}}},{"mi":"median","mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mi":"fm","mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mi":["k","i"],"mo":","}}}}}],"mo":"-"}}}}]}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"Eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"1"}}}]}}}}},"where ZQM(k) is the Z-height quality metric for the kth region or sub-region of interest, and fm(k,i) is the focus metric determined based on the kth region of interest in the ith image of the image stack.","For an image stack comprising a relatively large number of images spread over a fairly large Z-height range about the best focus position, large values of ZQM(k) based on Equation 1 reliably indicate a strong focus peak in comparison to the noise level of the underlying data, which produces to a relatively reliable Z-height estimate. Based on this disclosure, one of ordinary skill in the art may determine acceptable alternative ways of estimating a Z-height quality metric to be associated with an estimated Z height determined based on a focus peak determining data set.","For example, the standard deviation of the data set may be used as a measure of the noise in the focus metric signal (used in the denominator of Equation 1), although that measure may be less desirable in certain implementations in that it incorporates both the focus peak and the noise into a single value. Another measure of the noise may be determined by smoothing the focus metric signal (e.g., using a moving average), and then computing the deviation of the raw focus metric signals from the smoothed signal. In this way, the smoothed signal can be used as an approximation to the signal without noise, and then the noise can be estimated. However, in certain implementations, this method may be relatively dependent on the technique that is chosen for smoothing the signal.","Substitutes may be determined for other parts of Equation 1 as well. For example, the maximum value of the focus peak determining data set may be replaced with an average of the highest few values in some embodiments. Similarly, the baseline value of the focus peak determining data set may be replaced with an average of the lowest several values in some embodiments. In other embodiments, the difference between the maximum and baseline values (used in the numerator of Equation 1) may be estimated based on a fit curve (e.g., a Gaussian curve) rather than based on the raw data of the focus peak determining data set. Other variations may be determined by one of ordinary skill in the art, based on the general principles disclosed herein.","Ultimately, it may be desired to weight the Z-height data as it is used in a point cloud fitting method, depending on the estimated reliability of that Z-height data. For example, it may be desired to determine a surface shape conforming to a function Zfit such that the residuals in Equation 2 are approximately minimized:",{"@attributes":{"id":"p-0070","num":"0069"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"residuals","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"n"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mo":"[","mrow":{"mrow":{"mi":"ZWF","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},"mo":"*","msup":{"mrow":{"mo":["[","]"],"mrow":{"mo":["(","]"],"mrow":{"mrow":[{"mi":"Zp","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mi":"Zfit","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":"-"}}},"mn":"2"}}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"Eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"2"}}}]}}}}},"where ZWF(k) is a weighting factor indicating the quality or reliability of the estimated Z height Zp(k) for the kth region of interest of the surface to be fit, and Zfit(k) is the \u201cfit\u201d Z height at the kth region of interest of the surface, as determined based on a candidate surface fitting function Zfit. Of course, it will be appreciated that each region of interest k corresponds to a particular representative (x,y) coordinate location on the surface, and appropriate substitutions of the representative (x,y) coordinates may be made for each value of k that occurs in Equation 2.","In some embodiments and\/or applications, a raw Z-height quality metric ZQM(k) determined as outlined above may vary by several orders of magnitude. If used directly as Z-height quality weighting factors ZWF(k), such disparate weights could introduce unwanted bias into the system and\/or cause some algorithms used to determine a fit function Zfit to become unstable. Thus, in one embodiment, the raw Z-height quality metrics ZQM(k) may be transformed using a hyperbolic tangent function and chosen transformation parameters, as follows:",{"@attributes":{"id":"p-0073","num":"0072"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"ZWF","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mfrac":{"mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mn":"1","mo":"+","mrow":{"mi":"tanh","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"\u03b2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"ZQM","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},"mo":"-","mi":"T"}}}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"Eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"3"}}}]}}}}},"This function smoothly maps raw Z-height quality metric values ZQM(k) in the range from (\u2212\u221e to \u221e) to transformed Z-height quality weighting factors ZWF(k) values in the range (zero to 1). In one specific example implementation, transformation parameter values of T=10 and \u03b2=0.01 were chosen as producing a desirable transformation after experimental trials using data from certain representative surfaces. In one embodiment, the foregoing EQUATION 3 may essentially result in a type of \u201cnormalization.\u201d It will be appreciated that other alternative techniques may also be utilized to ensure that focus peaks with a higher certainty of being accurate are given comparatively higher weights for the fitting algorithm. Also, in certain alternative embodiments, these weighting values may be used in combination with \u201cstandard\u201d statistically-based geometric weighting and outlier methods.","In addition, in some embodiments, thresholding may be applied to completely eliminate Z heights with an associated quality metric below a Z-height quality threshold, and weighting the survivors of the thresholding. For example, in one such embodiment, the value T in Equation 3 is used both as a threshold for ZQM(k) in order to eliminate corresponding data, and as a transformation parameter in Equation 3 for providing transformed Z-height quality weighting factors ZWF(k) for the surviving data. Also, in some embodiments, statistically determined Z-height quality meta-data outliers may be identified and the corresponding best focus Z-height data may be eliminated or otherwise identified as invalid.","It will be appreciated that all of the foregoing equations and values are exemplary only and not limiting. In various embodiments, Z-height quality metrics or meta-data may be expressed and\/or stored in memory in a form that is suitable for use directly as Z-height quality weighting factors in a variety of point cloud fitting algorithms, in which case a weighting factor (e.g., such as that defined by Equation 3) may be regarded as both a weighting factor and as a Z-height quality metric or meta-data. In other embodiments, Z-height quality weighting factors suitable for various point cloud algorithms may be determined by performing secondary or integrated transformation operations on initially determined and\/or stored Z-height quality metrics or meta-data. In still other embodiments, point cloud fitting algorithms may be adapted to provide operations that are compatible with a particular expressed and\/or stored form of Z-height quality metric or meta-data.","In one embodiment, a Z-height quality metric or meta-data may take the form of an estimated uncertainty in the same units of measurement that are used to express the estimated best focus Z height. The main point is that Z-height quality meta-data or a Z-height quality metric are provided that indicate the reliability or uncertainty of corresponding estimated Z heights based on data used to determine that best focus Z height (e.g., a peak focus determining data set), and that the Z-height quality meta-data or metric is made available in a form that can be used for weighting surface fitting residuals used in fitting a surface to the estimated Z heights.",{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 5","b":["500","505"]},"At block , an image stack set of images is defined, comprising image(i) for i=1 to N. The field of view of the image stack set may encompass the set of regions of interest ROI(k), and the Z range of the image stack set generally spans the Z heights that are expected for the set of regions of interest ROI(k). At block , operations to acquire members of the image stack set image(i), at corresponding Z height Z(i), are begun. A Z height Z(i) is the Z height indicated by the machine vision inspection system at the time of acquisition of image(i), and corresponds to the location of a focused object plane for that image, regardless of whether or not a workpiece surface is actually located at that focused object plane.","In some embodiments, it may be advantageous to have the operations of other blocks (e.g., blocks -) executed partially in parallel with block , that is, image analysis operations may begin at any convenient time after one or more regions of one or more initial images have been acquired in order to conserve operation time and\/or memory. Thus, at block , a processing loop for image analysis operations on the first\/next image(i) may begin at any convenient time after one or more regions or sub-regions of the first\/next image(i) have been acquired.","At block , a nested processing loop begins for processing operations related to the first\/next regions of interest ROI(k), for k=1 to P in the current image(i). At block , a focus metric fm(k,i) is determined for the current region of interest ROI(k) in the current image(i), and each such focus metric fm(k,i) and corresponding Z height Z(i) is added to a focus peak determining data set (e.g., a focus curve data set) for the current region of interest ROI(k).","At decision block , a determination is made as to whether there are any more regions of interest ROI(k) to be processed for the current image(i) in the nested processing loop. If so, operation returns to block , otherwise operation continues to decision block .","At decision block , a determination is made whether there is another image(i) to be processed in the processing loop begun at block . If so, operation returns to block , otherwise operation continues to block . In the embodiment shown in , operation continues to block  with a complete focus peak determining data set available for each region of interest ROI(k). However, in other embodiments, the operations of block  may begin for a particular region of interest at any convenient time after a sufficient focus peak determining data set is available for that particular region of interest.","At block , for each region of interest ROI(k) (e.g., for k=1 to P), the best focus Z height Zp(k) is determined (e.g., estimated as outlined previously) for that ROI(k) based on the focus peak determining data set established by the operations of block  for that ROI(k). In some embodiments, each best focus Z height Zp(k) may be stored in the 3D data memory portion .","Operation then continues to block  where, for each region of interest ROI(k) (e.g., for k=1 to P), corresponding Z-height quality meta-data ZQM(k) is determined for that region of interest ROI(k). The Z-height quality meta-data ZQM(k) may take the form of any convenient Z-height quality meta-data or metric that indicates the reliability or uncertainty of the corresponding estimated Z-height Zp(k)), based on data used to determine the best focus Z height Zp(k) for that region of interest ROI(k).","In one embodiment, the Z-height quality meta-data ZQM(k) may advantageously and conveniently be based on the corresponding peak focus determining data set established by the operations at block  for the region of interest ROI(k) (e.g., as outlined with reference to Equations 1 and\/or 3 above). However, it will be appreciated that each peak focus determining data set is ultimately based on the underlying image data included in the image stack referred to above. Thus, in various other embodiments, the Z-height quality meta-data ZQM(k) may be derived from data included in the image stack set for the region of interest ROI(k), or other data derived from that image data.","Various methods of determining Z-height quality meta-data ZQM(k) have been outlined previously (e.g., with reference to Equations 1 and\/or 3 above). In some embodiments, each of the Z-height quality meta-data ZQM(k) may comprise a Z-height weighting factor ZWF(k) determined for that ROI(k) based on the Z-height quality meta-data ZQM(k) determined at block  for that ROI(k) (e.g., as outlined with reference to Equation 3). It will be appreciated based on previous descriptions of Z-height quality meta-data and\/or weighting factors that in some embodiments the Z-height quality meta-data may comprising a form that is directly usable as a weighting factor in subsequent surface fitting operations, and in other embodiments such weighting factor may be established during surface fitting operations based on other forms of stored Z-height quality meta-data.","Operation then continues to block  where for each ROI(k), the Z-height quality meta-data ZQM(k) is associated with the corresponding best focus Z height Zp(k) for that ROI(k) such that the Z-height quality meta-data ZQM(k) are usable to establish Z-height quality weighting factors ZWK(k) that are associated with the corresponding best focus Z heights Zp(k), in subsequent operations that fit a workpiece surface representation to a plurality of the best focus Z heights Zp(k).","For example, in some embodiments, the Z-height quality meta-data ZQM(k) are stored in the Z-height quality data memory portion in association with their corresponding best focus Z heights Zp(k). In other embodiments, the Z-height quality meta-data ZQM(k) are transferred or applied directly to surface representation fitting operations (e.g., two-dimensional \u201cprofile\u201d fitting operations or three-dimensional point cloud fitting operations) in association with their corresponding best focus Z heights Zp(k). As previously indicated, in some embodiments, the Z-height quality meta-data ZQM(k) may comprise or be identical with Z-height quality weighting factors ZWK(k), which may be directly used as weighting factors in subsequent surface representation fitting operations. After block , the routine ends.",{"@attributes":{"id":"p-0090","num":"0089"},"figref":["FIGS. 6A-6D","FIGS. 6A-6D"],"b":["600","610","610","610","610","610","610","610","610","610","600","600"],"i":["a","b","c","d","a","d","b","c","d "]},{"@attributes":{"id":"p-0091","num":"0090"},"figref":["FIG. 6A","FIG. 7"],"b":"610","i":"a "},{"@attributes":{"id":"p-0092","num":"0091"},"figref":"FIG. 6B","b":["610","610"],"i":["b ","b "]},"In various embodiments, the user may accept and\/or select that a default search range be determined and used, or that the search range be based on a nominal (or range midpoint) value entered by the user, or that the search range be based on maximum and minimum values entered by the user. In various embodiments, the autofocus tool may determine a default search range based on operations during manual mode and\/or learn mode set-up of the tool. In any case where the search range is not completely defined by user input, autofocus tool operations may determine the Z-height search range based on the current machine optical configuration (e.g., the current depth of field or magnification), and\/or workpiece information (e.g., expected surface height variations due to fixturing or fabrication variations, or the like) in order to provide an efficient search range that also includes enough range to allow for robust operation with reasonable variations in the region of interest Z heights during measurement and\/or part program execution.",{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIG. 6C","FIG. 6C"],"b":["610","610"],"i":["c ","a"]},"When a \u201cMulti-point\u201d selection is entered, the number of sub-regions and their representative x-y coordinate locations may be determined (relative to the global region of interest location and extents) based on the number of sub-region rows and columns indicated in the \u201cTool Subregions\u201d parameter boxes. The user may also select the \u201cDetermine Z-height Quality Metric,\u201d which will configure the associated autofocus tool or tool mode to implement the operations of the Z-height quality determining portion to determine a Z-height quality metric associated with the best focus Z-height for each region or sub-region (e.g., as outlined with reference to the operations of the routine , in some embodiments.",{"@attributes":{"id":"p-0096","num":"0095"},"figref":["FIG. 6D","FIG. 6D"],"b":["610","610","610"],"i":["d ","c","d "]},"For example, checking the \u201cDetermine Z-Height Weighting Factors from Z-Height Quality\u201d checkbox may implement Equation 3 in some embodiments, and the Z-Height Quality Threshold slider may be used to adjust the parameter \u201cT\u201d, and the Z-Height Weight Factor Strength slider may be used to adjust the parameter \u201c\u03b2\u201d in such embodiments. However, it will be appreciated that the tabbed portions and are exemplary only, and not limiting. More generally, they may be adapted as needed to support any desired implementation that falls within the scope of this disclosure.",{"@attributes":{"id":"p-0098","num":"0097"},"figref":["FIG. 7","FIG. 7"],"b":["700","700","703","710","700","720","740","730","750"]},"The field of view window  includes an exemplary multipoint autofocus tool widget  and a corresponding global region of interest \u2032 defined by the outer boundaries of the widget  and superimposed upon a current workpiece feature  to be inspected. As shown in , the global region of interest \u2032 is subdivided into 10\u00d710 sub-regions of interest SROI(k) (e.g., for k=1 to 100). Each sub-region SROI(k) may be associated with a representative central location (X, Y), and may include an area corresponding to a number of pixel rows and a number of pixel columns. When a best focus Z height Zpis determined based on a sub-region of interest (e.g., as outlined previously), the point cloud element corresponding to that sub-region of interest may be represented by the three-dimensional coordinates (X, Y, Zp).","In various embodiments, the representative locations of the sub-regions may be spaced apart by several pixels or as little as one pixel. Thus, in some such embodiments, the pixel areas used to determine a best focus Z height Zpfor each sub-region may partially overlap one another. In some implementations, the area of each sub-region may be relatively small (e.g., 9\u00d79 pixels, 7\u00d77 pixels, 3\u00d73 pixels, 3\u00d75 pixels, etc.). It will be appreciated that using Z-height quality metrics in a method according to this disclosure is particularly valuable in association with small focus regions of interest, which tend to produce \u201cfocus signals\u201d or focus metrics that may include a relatively large noise component.","In various embodiments, the user may select an autofocus tool or mode that includes determining a Z-height quality metric (or Z-height uncertainty) by selecting the \u201cZ-Uncertainty autofocus tool\u201d button  from a selection bar  that displays various alternative tool and\/or mode selection buttons. The tool selection bar  may indicate that the Z-uncertainty autofocus tool or mode is active via an \u201cactive\u201d box  around the Z-uncertainty autofocus tool or mode button . Upon such a selection, in one embodiment, the user interface may automatically display an autofocus parameter dialog box, such as the previously described parameter dialog box  shown in , for configuring the various parameters of the selected autofocus tool.","In one embodiment, the widget  may be automatically displayed in the user interface to allow a user to graphically define the region of interest \u2032 for that instance of the autofocus tool (e.g., by dragging the square handles located on the border of the widget  using a computer mouse and screen cursor). It will be appreciated that the 10\u00d710 sub-regions shown for the widget  correspond to the particular \u201cMultipoint\u201d parameter settings shown in the tabbed portion in .","It will be appreciated that while the increase in accuracy of the surface shape determined by relying at least partially on the Z-height quality metric operations outlined above may be relatively small in some instances (e.g., sub-micron improvement for certain magnifications), improvements in the robustness or speed of the surface shape determining operations may be significant. Furthermore, even small improvements in the accuracy and\/or robustness of point cloud fitting operations are important in numerous applications and may in particular assist with the measurement of certain pathological surfaces, and in all cases, greater accuracy is generally more desirable when performing precision measurement operations.","While various preferred embodiments have been illustrated and described, numerous variations in the illustrated and described arrangements of features and sequences of operations will be apparent to one skilled in the art based on this disclosure. Thus, it will be appreciated that various changes can be made therein without departing from the spirit and scope of the disclosure."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing aspects and many of the attendant advantages of this disclosure will become more readily appreciated as the same become better understood by reference to the following detailed description, when taken in conjunction with the accompanying drawings, wherein:",{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 4B","FIG. 4A"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIGS. 6A-6D"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
