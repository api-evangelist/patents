---
title: API for launching work on a processor
abstract: One embodiment of the present invention sets forth a technique for launching work on a processor. The method includes the steps of initializing a first state object within a memory region accessible to a program executing on the processor, populating the first state object with data associated with a first workload that is generated by the program, and triggering the processing of the first workload on the processor according to the data within the first state object.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09268601&OS=09268601&RS=09268601
owner: NVIDIA Corporation
number: 09268601
owner_city: Santa Clara
owner_country: US
publication_date: 20110331
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This application claims benefit of United States provisional patent application entitled \u201cCULauncher API for Computer GWC\u201d filed on Apr. 5, 2010 and having a Ser. No. 61\/321,096.","1. Field of the Invention","Embodiments of the present invention relate generally to processor architectures and, more specifically, an application program interface (API) for launching work on a processor.","2. Description of the Related Art","In conventional computer systems, the processing power of a central processing unit (CPU) may be augmented by a co-processor, such as a GPU. GPUs are specialized processors that are configured to efficiently perform graphics processing operations or other operations that would otherwise be performed by the CPU. Some conventional computer systems are configured with a hybrid graphics system that includes, for example, an integrated GPU (iGPU) disposed on the motherboard along with the CPU and a discrete GPU (dGPU) located on an add-in card that is connected to the motherboard via a Peripheral Component Interconnect Express (PCI Express or PCIe) expansion bus and slot.","Typically, in such systems, work on the co-processor can only be launched by the CPU. Such a limitation can result in several inefficiencies. For example, if the co-processor is to execute a series of related tasks, where task B is dependent on the execution of task A, then the CPU will first launch task A on the GPU, wait until task A completes, and then launch task B. In such a scenario, because the CPU has to wait until the GPU indicates that task A has completed and then initiate the execution of task B, many clock cycles are wasted, thus reducing the overall performance of the system.","As the foregoing illustrates, what is needed in the art is an approach for launching work on a processor in a more efficient manner.","One embodiment of the present invention sets forth a method for launching work on a processor. The method includes the steps of initializing a first state object within a memory region accessible to a program executing on the processor, populating the first state object with data associated with a first workload that is generated by the program, and triggering the processing of the first workload on the processor according to the data within the first state object.","One advantage of the disclosed technique is that work can be launched on a processor from within the processor itself, thus eliminating wasted cycles in between the launching of two different tasks.","In the following description, numerous specific details are set forth to provide a more thorough understanding of the present invention. However, it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details. In other instances, well-known features have not been described in order to avoid obscuring the present invention.",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 1","b":["100","100","102","104","106","108","110"]},"The processor  is coupled to the program accessible memory  and the processor driver . In operation, the processor  includes one or more processor cores that each executes a sequence of instructions associated with and\/or transmitted by the various elements of the processing environment , such as the application program . The processor  can be a general purpose processor or a more special purpose processor, such as a graphics processing unit (GPU). The program accessible memory  is a memory space, usually a random access memory (RAM), that temporarily stores data needed to execute instructions within the processor . The data in the program accessible memory  can be set via software programs running within the system  at any given time.","In operation, software programs, such as application program , interact with the processor  via the processor driver . More specifically, the processor driver  transmits commands generated by the application program  to the processor  for execution. In some cases, to initiate execution of a particular workload within the processor , the application program  interfaces with the processor  via the work launching API . The work launching API  interfaces with the processor driver  and allows the application program  to launch workloads for execution on the processor .","To launch a workload, the application program  interacts with different API commands of the work launching API  to (i) allocate memory space in the program accessible memory  for a state object, (ii) store state information needed to execute the workload within the state object and (iii) trigger the execution of the workload. In one embodiment, the same state object may be shared across multiple workloads triggered by the application program  via the work launching API . In an another embodiment, where the processor  is a multi-threaded processor, different threads within the processor  may execute the same workload using different state objects stored within the program accessible memory . In yet another embodiment, a workload that is dependent on a primary workload which is currently being executed by the processor  can be automatically launched for execution within the processor  when the primary workload has been fully executed.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 2","FIG. 1"],"b":["200","100","102","202","204","206"]},"The work launching API  provides functions that can be issued by the application program  for each of the above steps. For creating a state object at step , the work launching API  provides functions for initializing a specified portion of memory within the program accessible memory  that is to be allocated to a state object needed for executing a workload. The state object ,  and  illustrate state objects that have been initialized by the application program . The structure of the state object may be pre-defined or may be dynamic based on a specification provided by the application program . For populating the state object at step , the work launching API  provides functions for setting different pre-determined pieces of state information within the state object. State information can include specifying a number of threads that will be executing the workload, memory management information or texture information in the case of graphics processing. Examples of specific functions providing by the work launching API  for setting state information in the state object are listed below. For triggering the workload execution at step , the work launching API  provides functions for submitting the state object and launching the execution of the workload using the state object within the processor .",{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 3","FIG. 1"]},"The method  begins at step , where the work launching API  receives an instruction from the application program  to initialize a state object within the program accessible memory . The application program , via at least one function provided by the work launching API , specifies a size of memory to be allocated to the state object. In response, at step , the state object specified by the application program  is created within the program accessible memory .","At step , the work launching API  receives state information from the application program  for storing in the state object created at step . The application program , via at least one function provided by the work launching API , specifies the different pieces of state information that are to be set within the state object. In response, at step , the state object is populated with the state information specified by the application program .","At step , the work launching API  receives an indication from the application program  that a workload associated with the state object should be triggered within the processor . At step , the execution of the workload is triggered within the processor .",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 4","b":["400","400","402","404","410","450","460","470"]},"The CPU  connects to the system memory  and the system interface . The CPU  executes programming instructions stored in the system memory , operates on data stored in system memory  and communicates with the GPU  through the system interface , which bridges communication between the CPU  and GPU . In alternate embodiments, the CPU , GPU , system interface , or any combination thereof, may be integrated into a single processing unit. Further, the functionality of GPU  may be included in a chipset or in some other type of special purpose processing unit or co-processor. The system memory  stores programming instructions and data for processing by the CPU . The system memory  typically includes dynamic random access memory (DRAM) configured to either connect directly to the CPU  (as shown) or alternately, via the system interface . The GPU local memory  is any memory space accessible by the GPU  including local memory, system memory, on-chip memories, and peer memory. In some embodiments, the GPU  displays certain graphics images stored in the GPU local memory  on the display .","In one embodiment, the GPU  includes a number M of SPMs (not shown), where M\u22671, each SPM configured to process one or more thread groups. The series of instructions transmitted to a particular GPU  constitutes a thread, as previously defined herein, and the collection of a certain number of concurrently executing threads across the parallel processing engines (not shown) within an SPM is referred to herein as a \u201cwarp\u201d or \u201cthread group.\u201d As used herein, a \u201cthread group\u201d refers to a group of threads concurrently executing the same program on different input data, with one thread of the group being assigned to a different processing engine within an SPM. A thread group may include fewer threads than the number of processing engines within the SPM, in which case some processing engines will be idle during cycles when that thread group is being processed. A thread group may also include more threads than the number of processing engines within the SPM, in which case processing will take place over consecutive clock cycles. Since each SPM can support up to G thread groups concurrently, it follows that up to G*M thread groups can be executing in GPU  at any given time.","Additionally, a plurality of related thread groups may be active (in different phases of execution) at the same time within an SPM. This collection of thread groups is referred to herein as a \u201ccooperative thread array\u201d (\u201cCTA\u201d) or \u201cthread array.\u201d The size of a particular CTA is equal to m*k, where k is the number of concurrently executing threads in a thread group and is typically an integer multiple of the number of parallel processing engines within the SPM, and m is the number of thread groups simultaneously active within the SPM. The size of a CTA is generally determined by the programmer and the amount of hardware resources, such as memory or registers, available to the CTA.","The system memory  includes an application program , application data , the work launching API , a GPU driver  and GPU driver data . The application program  generates calls to a the work launching API  as previously described in order to create state objects within the GPU local memory  and trigger the execution of workloads on the GPU  using those state objects.","Table 1 includes a list of functions provided by the work launching API  for creating and populating state objects as well as triggering the execution of workloads on the processor .",{"@attributes":{"id":"p-0033","num":"0032"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"119pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"77pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["FUNCTION NAME","INPUTS","DESCRIPTION"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Create State Object Function",{},{}]},{"entry":["launcherInitialize","launcher: Launcher","Initializes a state"]},{"entry":[{},"memory to initialize.","object."]},{"entry":[{},"func: Device-side",{}]},{"entry":[{},"function for the",{}]},{"entry":[{},"launcher, or NULL.",{}]},{"entry":["Populate State Object Functions",{},{}]},{"entry":["launcherSetCtaWidth","launcher: Handle to","Set the width of each"]},{"entry":[{},"initialized launcher.","CTA in threads, must"]},{"entry":[{},"ctaWidth: Width of the","be >0, default is zero."]},{"entry":[{},"CTA.",{}]},{"entry":["launcherSetCtaHeight","launcher: Handle to","Set the height of each"]},{"entry":[{},"initialized launcher.","CTA in threads, must"]},{"entry":[{},"ctaHeight: Height of the","be >0, default is zero."]},{"entry":[{},"CTA.",{}]},{"entry":["launcherSetCtaDepth","launcher: Handle to","Set the depth of each"]},{"entry":[{},"initialized launcher.","CTA in threads, must"]},{"entry":[{},"ctaDepth: Depth of the","be >0, default is zero."]},{"entry":[{},"CTA.",{}]},{"entry":["launcherSetGridWidth","launcher: Handle to","Set the width of the"]},{"entry":[{},"initialized launcher.","grid in CTAs, default is"]},{"entry":[{},"gridWith: Width of the","zero."]},{"entry":[{},"grid.",{}]},{"entry":["launcherSetGridHeight","launcher: Handle to","Set the height of the"]},{"entry":[{},"initialized launcher.","grid in CTAs, default is"]},{"entry":[{},"gridHeight: Height of","zero."]},{"entry":[{},"the grid.",{}]},{"entry":["launcherSetSharedMemorySize","launcher: Handle to","Sets the size in bytes"]},{"entry":[{},"initialized launcher.","of the dynamic shared"]},{"entry":[{},"memSize: Size of","memory used by the"]},{"entry":[{},"shared memory.","launched CTAs."]},{"entry":["launcherSetRegisterCount","launcher: Handle to","Overrides the"]},{"entry":[{},"initialized launcher.","compiler-generated"]},{"entry":[{},"regCount: Count of","register count for the"]},{"entry":[{},"registers.","launched CTAs."]},{"entry":["launcherSetL1Configuration","launcher: Handle to","Sets the L1 Cache-"]},{"entry":[{},"initialized launcher.","shared memory"]},{"entry":[{},"I1Config: Particular L1","configuration required"]},{"entry":[{},"condifguration.","by the launched CTAs."]},{"entry":["launcherSetInvalidateTextureCache","launcher: Handle to","If true, invalidate the"]},{"entry":[{},"initialized launcher.","texture cache (in the"]},{"entry":[{},"bool: invalidate.","GPU memory) prior to"]},{"entry":[{},{},"launching work. False"]},{"entry":[{},{},"by default."]},{"entry":["launcherSetInvalidateShaderCache","launcher: Handle to","If true, invalidate the"]},{"entry":[{},"initialized launcher.","shader cache (in the"]},{"entry":[{},"bool: invalidate.","GPU memory) prior to"]},{"entry":[{},{},"launching work. False"]},{"entry":[{},{},"by default."]},{"entry":["launcherSetInvalidateConstantCache","launcher: Handle to","If true, invalidate the"]},{"entry":[{},"initialized launcher.","constant cache (in the"]},{"entry":[{},"bool: invalidate.","GPU memory) prior to"]},{"entry":[{},{},"launching work. False"]},{"entry":[{},{},"by default."]},{"entry":["launcherSetParameterBuffer","launcher: Handle to","Sets the pointer to a"]},{"entry":[{},"initialized launcher.","parameter buffer"]},{"entry":[{},"dParameterBuffer:","containing the data for"]},{"entry":[{},"pointer to parameter","the parameters in the"]},{"entry":[{},"buffer.","kernel signature."]},{"entry":["launcherSetExtraParameterBuffer","launcher: Handle to","Sets the pointer to an"]},{"entry":[{},"initialized launcher.","additional memory"]},{"entry":[{},"dExtraParameterBuffer:","buffer that the user"]},{"entry":[{},"pointer to extra","can read from in the"]},{"entry":[{},"parameter buffer.","launched task."]},{"entry":["launcherSetAtCtaExitCallback","launcher: Handle to","Support to launch"]},{"entry":[{},"initialized launcher.","grids of work directly"]},{"entry":[{},"cbLauncher: Handle to","at CTA exit without"]},{"entry":[{},"initialized callback","explicitly going through"]},{"entry":[{},"launcher.","the command buffer."]},{"entry":[{},"cbParams: Pointer to",{}]},{"entry":[{},"callback parameters.",{}]},{"entry":["launcherSetAtGridExitCallback","launcher: Handle to","Support to launch"]},{"entry":[{},"initialized launcher.","grids of work directly"]},{"entry":[{},"cbLauncher: Handle to","at grid exit without"]},{"entry":[{},"initialized callback","explicitly going through"]},{"entry":[{},"launcher.","the command buffer."]},{"entry":[{},"cbParams: Pointer to",{}]},{"entry":[{},"callback parameters.",{}]},{"entry":["launcherSetQueueBuffer","launcher: Handle to","Specify queue storage"]},{"entry":[{},"initialized launcher.","for queue-based"]},{"entry":[{},"dQueueBuffer: pointer","launchers. Each"]},{"entry":[{},"to queue buffer.","element in the queue"]},{"entry":[{},{},"contains the varying"]},{"entry":[{},{},"arguments to a CTA."]},{"entry":["launcherSetQueueElementCount","launcher: Handle to","Specify the number of"]},{"entry":[{},"initialized launcher.","elements in the queue"]},{"entry":[{},"queueElementCount:","associated with the"]},{"entry":[{},"Number of CTA","launcher."]},{"entry":[{},"elements in the queue",{}]},{"entry":[{},"storage array",{}]},{"entry":["launcherSetQueueElementSize","launcher: Handle to","Specify the size of"]},{"entry":[{},"initialized launcher.","each element in the"]},{"entry":[{},"queueElementSize:","queue associated with"]},{"entry":[{},"Size of each CTA","the launcher."]},{"entry":[{},"element in the queue",{}]},{"entry":[{},"storage array",{}]},{"entry":["launcherSetLogicalSmDisabledMask","launcher: Handle to","Sets a mask that"]},{"entry":[{},"initialized launcher.","determines the set of"]},{"entry":[{},"smMask: A mask that","logical SM indices to"]},{"entry":[{},"determines the set of","which CTAs can be"]},{"entry":[{},"logical SM indices to","launched."]},{"entry":[{},"which CTAs can be",{}]},{"entry":[{},"launched.",{}]},{"entry":["launcherSetPriority","launcher: Handle to","Sets the priority level"]},{"entry":[{},"initialized launcher.","of this launcher."]},{"entry":[{},"priority: Priority of the",{}]},{"entry":[{},"launcher having a",{}]},{"entry":[{},"value between 0 and a",{}]},{"entry":[{},"pre-determined value.",{}]},{"entry":["launcherSetAddToHeadOfPriorityLevel","launcher: Handle to","If true, the scheduler"]},{"entry":[{},"initialized launcher.","will add the launcher"]},{"entry":[{},"b: Boolean indicating","to the head of the"]},{"entry":[{},"whether the priority of","\u2018priority level\u2019 set with"]},{"entry":[{},"the launcher should be","launcherSetPriority,"]},{"entry":[{},"considered.","otherwise the launcher"]},{"entry":[{},{},"is added to the tail."]},{"entry":["Trigger Execution Functions",{},{}]},{"entry":["launcherFinalize","launcher: Handle to","Notify GPU that the"]},{"entry":[{},"initialized launcher.","state object is"]},{"entry":[{},{},"configured and ready"]},{"entry":[{},{},"for work."]},{"entry":["launcherReset","launcher: Handle to","Reset a state object to"]},{"entry":[{},"initialized launcher.","allow its reuse."]},{"entry":["launcherSubmitGrid","launcher: Handle to","Launch a grid of work"]},{"entry":[{},"initialized launcher.","with grid"]},{"entry":[{},{},"width * height * depth"]},{"entry":[{},{},"CTAs for the specified"]},{"entry":[{},{},"launcher."]},{"entry":["launcherSubmitGridCommands","launcher: Handle to","Writes into the given"]},{"entry":[{},"initialized launcher.","buffer the GPU"]},{"entry":[{},"dstCmdBufSeg:","commands required to"]},{"entry":[{},"Destination command","launch a grid of work"]},{"entry":[{},"buffer segment.","for the previously"]},{"entry":[{},{},"configured state"]},{"entry":[{},{},"object."]},{"entry":["launcherSubmitQueueElements","launcher: Handle to","Launch CTAs for a"]},{"entry":[{},"initialized launcher.","queue-based launcher"]},{"entry":[{},"elementStart: Element","using elements stored"]},{"entry":[{},"index of first CTA to","in the associated"]},{"entry":[{},"launch.","dQueueBuffer storage."]},{"entry":[{},"elementCount: Number",{}]},{"entry":[{},"of element CTAs to",{}]},{"entry":[{},"launch.",{}]},{"entry":["launcherInvalidateInstructionCache","launcher: Handle to","If true, invalidate the"]},{"entry":[{},"initialized launcher.","instruction cache prior"]},{"entry":[{},"b: Boolean indicating","to launching work."]},{"entry":[{},"whether instruction",{}]},{"entry":[{},"cache should be",{}]},{"entry":[{},"invalidated before the",{}]},{"entry":[{},"work is launched."]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"While the forgoing is directed to embodiments of the present invention, other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example, aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program(s) of the program product define functions of the embodiments (including the methods described herein) and can be contained on a variety of computer-readable storage media. Illustrative computer-readable storage media include, but are not limited to: (i) non-writable storage media (e.g., read-only memory devices within a computer such as CD-ROM disks readable by a CD-ROM drive, flash memory, ROM chips or any type of solid-state non-volatile semiconductor memory) on which information is permanently stored; and (ii) writable storage media (e.g., floppy disks within a diskette drive or hard-disk drive or any type of solid-state random-access semiconductor memory) on which alterable information is stored. Such computer-readable storage media, when carrying computer-readable instructions that direct the functions of the present invention, are embodiments of the present invention.","In view of the foregoing, the scope of the present invention is determined by the claims that follow."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["So that the manner in which the above recited features of the present invention can be understood in detail, a more particular description of the invention, briefly summarized above, may be had by reference to embodiments, some of which are illustrated in the appended drawings. It is to be noted, however, that the appended drawings illustrate only typical embodiments of this invention and are therefore not to be considered limiting of its scope, for the invention may admit to other equally effective embodiments.",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
