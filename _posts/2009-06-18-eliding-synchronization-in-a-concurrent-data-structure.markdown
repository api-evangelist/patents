---
title: Eliding synchronization in a concurrent data structure
abstract: A concurrent data structure allows synchronization to be elided for read accesses. Processing resources that remove one or more elements of the concurrent data structure are allowed to delete the elements only after all other processing resources have reached a safe point. Each processing resource maintains an indicator that indicates whether the processing resource has reached as safe point (i.e., will not access the concurrent data structure). When the indicators indicate that all processing resources have reached a safe point, elements of the data structure may be deleted.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09384063&OS=09384063&RS=09384063
owner: Microsoft Technology Licensing, LLC
number: 09384063
owner_city: Redmond
owner_country: US
publication_date: 20090618
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Processes executed in a computer system may be configured to execute different parts of the process concurrently. Where these different parts of the process may access the same data concurrently, the accesses to the data are typically synchronized. For example, when an execution context (e.g., a thread, fiber, or child process) of a process accesses data, it generally invokes a lock or other synchronization technique to ensure that no other execution context of the process performs a conflicting access to the data. The synchronization prevents data from being corrupted but adds processing overhead to each data access and may serialize the access to the data by different execution contexts. This serialization may inhibit the performance and scalability of a process, particularly where there are many independent processing resources that execute execution contexts.","A process may wish to perform concurrent operations on a collective set of data. In doing so, different execution contexts of the process may add data to or remove data from the collective set of data in an arbitrary order. The process may wish to remove elements of the set of data at some point in the execution. While various synchronization mechanisms may be used to allow elements of the set of data to be removed, the synchronization mechanisms may inhibit the performance and scalability of the process.","This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.","A concurrent data structure allows synchronization to be elided for read accesses. Processing resources that remove one or more elements of the concurrent data structure are allowed to delete the elements only after all other processing resources have reached a safe point. Each processing resource maintains an indicator that indicates whether the processing resource has reached as safe point (i.e., will not access the concurrent data structure). When the indicators indicate that all processing resources have reached a safe point, elements of the data structure may be deleted.","In the following Detailed Description, reference is made to the accompanying drawings, which form a part hereof, and in which is shown, by way of illustration, specific embodiments in which the invention may be practiced. In this regard, directional terminology, such as \u201ctop,\u201d \u201cbottom,\u201d \u201cfront,\u201d \u201cback,\u201d \u201cleading,\u201d \u201ctrailing,\u201d etc., is used with reference to the orientation of the Figure(s) being described. Because components of embodiments can be positioned in a number of different orientations, the directional terminology is used for purposes of illustration and is in no way limiting. It is to be understood that other embodiments may be utilized and structural or logical changes may be made without departing from the scope of the present invention. The following detailed description, therefore, is not to be taken in a limiting sense, and the scope of the present invention is defined by the appended claims.","It is to be understood that the features of the various exemplary embodiments described herein may be combined with each other, unless specifically noted otherwise.",{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1","b":["46","22","12","10","22","46"]},"Runtime environment  represents a runtime mode of operation in a computer system, such as a computer system  shown in  and described in additional detail below, where the computer system is executing instructions. The computer system generates runtime environment  from a runtime platform such as a runtime platform  shown in  and described in additional detail below.","Runtime environment  includes an least one invoked process , a resource management layer , and a set of hardware threads ()-(M), where M is an integer that is greater than or equal to one and denotes the Mth hardware thread (M). Runtime environment  allows tasks from process  to be executed, along with tasks from any other processes that co-exist with process  (not shown), using an operating system (OS) such as an OS  shown in  and described in additional detail below, resource management layer , and hardware threads ()-(M). Runtime environment  operates in conjunction with the OS and\/or resource management layer  to allow process  to obtain processor and other resources of the computer system (e.g., hardware threads ()-(M)).","Runtime environment  includes a scheduler function that generates scheduler . In one embodiment, the scheduler function is implemented as a scheduler application programming interface (API). In other embodiments, the scheduler function may be implemented using other suitable programming constructs. When invoked, the scheduler function creates scheduler  in process  where scheduler  operates to schedule tasks of process  for execution by one or more hardware threads ()-(M). Runtime environment  may exploit fine grained concurrency that application or library developers express in their programs (e.g., process ) using accompanying tools that are aware of the facilities that the scheduler function provides.","Process  includes an allocation of processing and other resources that hosts one or more execution contexts (viz., threads, fibers, or child processes). Process  obtains access to the processing and other resources in the computer system (e.g., hardware threads ()-(M)) from the OS and\/or resource management layer . Process  causes tasks to be executed using the processing and other resources.","Process  generates work in tasks of variable length where each task is associated with an execution context in scheduler . Each task includes a sequence of instructions that perform a unit of work when executed by the computer system. Each execution context forms a thread, fiber, or child process that executes associated tasks on allocated processing resources. Each execution context includes program state and machine state information. Execution contexts may terminate when there are no more tasks left to execute. For each task, runtime environment  and\/or process  either assign the task to scheduler  to be scheduled for execution or otherwise cause the task to be executed without using scheduler .","Process  may be configured to operate in a computer system based on any suitable execution model, such as a stack model or an interpreter model, and may represent any suitable type of code, such as an application, a library function, or an operating system service. Process  has a program state and machine state associated with a set of allocated resources that include a defined memory address space. Process  executes autonomously or substantially autonomously from any co-existing processes in runtime environment . Accordingly, process  does not adversely alter the program state of co-existing processes or the machine state of any resources allocated to co-existing processes. Similarly, co-existing processes do not adversely alter the program state of process  or the machine state of any resources allocated to process .","Resource management layer  allocates processing resources to process  by assigning one or more hardware threads  to process . Resource management layer  exists separately from the OS in the embodiment of . In other embodiments, resource management layer  or some or all of the functions thereof may be included in the OS.","Hardware threads  reside in execution cores of a set or one or more processor packages (e.g., processor packages  shown in  and described in additional detail below) of the computer system. Each hardware thread  is configured to execute instructions independently or substantially independently from the other execution cores and includes a machine state. Hardware threads  may be included in a single processor package or may be distributed across multiple processor packages. Each execution core in a processor package may include one or more hardware threads .","Process  implicitly or explicitly causes scheduler  to be created via the scheduler function provided by runtime environment . Scheduler instance  may be implicitly created when process  uses APIs available in the computer system or programming language features. In response to the API or programming language features, runtime environment  creates scheduler  with a default policy. To explicitly create a scheduler , process  may invoke the scheduler function provided by runtime environment  and specify one or more policies for scheduler .","Scheduler  interacts with resource management layer  to negotiate processing and other resources of the computer system in a manner that is transparent to process . Resource management layer  allocates hardware threads  to scheduler  based on supply and demand and any policies of scheduler .","In the embodiment shown in , scheduler  manages the processing resources by creating virtual processors  that form an abstraction of underlying hardware threads . Scheduler  includes a set of virtual processors ()-(N) where N is an integer greater than or equal to one and denotes the Nth virtual processor (N). Scheduler  multiplexes virtual processors  onto hardware threads  by mapping each virtual processor  to a hardware thread . Scheduler  may map more than one virtual processor  onto a particular hardware thread  but maps only one hardware thread  to each virtual processor . In other embodiments, scheduler  manages processing resources in other suitable ways to cause instructions of process  to be executed by hardware threads .","The set of execution contexts in scheduler  includes a set of execution contexts ()-(N) with respective, associated tasks ()-(N) that are being executed by respective virtual processors ()-(N) and, at any point during the execution of process , a set of zero or more runnable execution contexts  and a set of zero or more blocked (i.e., wait-dependent) execution contexts . Each execution context , , and  includes state information that indicates whether an execution context , , or  is executing, runnable (e.g., in response to becoming unblocked or added to scheduler ), or blocked. Execution contexts  that are executing have been attached to a virtual processor  and are currently executing. Execution contexts  that are runnable include an associated task  and are ready to be executed by an available virtual processor . Execution contexts  that are blocked also include an associated task  and are waiting for data, a message, or an event that is being generated by another execution context  or will be generated by another execution context  or .","Each execution context  executing on a virtual processor  may generate, in the course of its execution, additional tasks , which are organized in any suitable way (e.g., added to work queues (not shown in )). Work may be created by using either application programming interfaces (APIs) provided by runtime environment  or programming language features and corresponding tools in one embodiment. When processing resources are available to scheduler , tasks are assigned to execution contexts  or  that execute them to completion on virtual processors  before picking up new tasks. An execution context  executing on a virtual processor  may also unblock other execution contexts  by generating data, a message, or an event that will be used by other execution contexts .","Each task in scheduler  may be realized (e.g., realized tasks  and ), which indicates that an execution context  or  has been or will be attached to the task and the task is ready to execute. Realized tasks typically include light-weight tasks and agents and may be associated with an execution context  or  just before executing or in advance of execution. A task that is not realized is termed unrealized. Unrealized tasks (e.g., tasks ) may be created as child tasks generated by the execution of parent tasks and may be generated by parallel constructs (e.g., parallel or parallel for). Scheduler  may be organized into a synchronized collection (e.g., a stack and\/or a queue) for logically independent tasks with execution contexts (i.e., realized tasks) along with a list of workstealing queues for dependent tasks (i.e., unrealized tasks).","Prior to executing tasks, scheduler  obtains execution contexts , , and  from runtime environment , resource management layer , or the operating system. Available virtual processors  locate and execute execution contexts  to begin executing tasks. Virtual processors  become available again in response to an execution context  completing, blocking, or otherwise being interrupted (e.g., explicit yielding or forced preemption). When virtual processors  become available, the available virtual processor  may switch to a runnable execution context  to execute an associated task . The available virtual processor  may also execute a next task  or  as a continuation on a current execution context  if the previous task  executed by the current execution context  completed.","Scheduler  searches for a runnable execution context , a realized task , or an unrealized task  to attach to the available virtual processor  for execution in any suitable way. For example, scheduler  may search for a runnable execution context  to execute before searching for a realized task  or an unrealized task  to execute. Scheduler  continues attaching execution contexts  to available virtual processors  for execution until all tasks and execution contexts  of scheduler  have been executed. In other embodiments, runnable execution contexts  and realized tasks  may be merged into single concept from the perspective of schedulers .","Runtime environment  is configured to use a concurrent data structure  that allows synchronization to be elided for read accesses.  is a block diagram illustrating an embodiment of concurrent data structure . Concurrent data structure  includes a doubly linked list of arrays ()-(P) (referred to as a list array ) where P is an integer that is greater than or equal to one and denotes the Pth array (P). Each array  includes a corresponding set of elements  (e.g., elements ()()-()(Q) in array () where Q is an integer that is greater than or equal to one and denotes the Qth element (Q)). In one embodiment, each array  in the set of arrays has a number of elements  that is equal to a number of bits of a machine word of the computer system (e.g., Q is equal to 32 or 64 for each array ) to allow fast bit arithmetic to be used for array accesses. In other embodiments, each array  includes other suitable numbers of elements .","Runtime environment  includes a concurrent data structure function that generates concurrent data structure  using any suitable programming constructs. In one embodiment, the concurrent data structure function is invoked within runtime environment  to create concurrent data structures  that manage the operation of schedulers . In other embodiments, the concurrent data structure function may be exposed as an application programming interface (API) to allow process  and\/or scheduler  to create and use concurrent data structures .","Concurrent data structure  allows each processing resource (e.g., virtual processors ) to concurrently access elements . The processing resources may read any element  without synchronization but are allowed to delete one or more elements  of the concurrent data structure  only after all other processing resources have reached a safe point. As shown in , each virtual processor  maintains an indicator  that indicates whether a corresponding virtual processor  has reached as safe point with respect to the data structure  or a previous version thereof. A safe point is a point of execution of the virtual processor  where the virtual processor  will not access concurrent data structure  or a previous version thereof. When all indicators ()-(N) indicate that all virtual processors  have reached a safe point, an execution context  executing on virtual processor  may delete one or more elements  of concurrent data structure .","Runtime environment  may create list array  with any suitable predefined or programmatically selected number and\/or sizes of arrays . Once created, an execution context  inserts elements  into list array . A free element list  stores a set of zero or more elements  that were previously used in list array  along with corresponding safe indicator  for each element  in the set. Each safe indicator  indicates whether a corresponding element  in free element list  is safe to delete and\/or reuse. If free element list  includes an element  that is safe to reuse, then execution context  performs an atomic compare and swap (CAS) operation on the element  to remove the element  from free element list  and performs a CAS operation to insert to the element  into list array . If free element list  does not include an element  that is safe to reuse (i.e., free element list  is empty or none of the elements  in free element list  are safe to reuse), then execution context  performs a CAS operation to insert an element  into the array  at the end of list array  if that array  is not full. If all arrays  are full, runtime environment  adds a new array  to list array  and performs a CAS operation to insert an element  into the new array  in list array .","After elements  are inserted in list array , execution contexts  performs read accesses to the elements  without synchronization and performs write operations to the elements  using CAS or other suitable operations. An execution context  accesses an array index  using an index to locate the array  that includes the element  and uses a sub-index to locate element  in the array . For embodiments that use 64 elements  in each array , the index of the array  that includes the element  may be identified by right shifting the address by six places and the sub-index may identified as the first six bits in the address.","To delete an element  from list array , an execution context  performs a CAS operation to move the element  from list array  to free element list  and sets the corresponding safe indicator  to indicate that the element  is not safe to be deleted. Before changing the safe indicator  to indicate that the element  is safe to delete, the execution context  ensures that all virtual processors  have reached a safe point with respect to data structure  using indicators . In some embodiments, elements  in free element list  may be reused in list array  prior to becoming safe to delete.","In one embodiment, an execution context  sets all indicators  of all virtual processors  to a first value (e.g., clears a bit indicator on each virtual processor ) when an element  is moved from list array  to free element list . Each virtual processor  sets its corresponding indicator  to a second value that differs from the first value (e.g., sets the bit indicator on each virtual processor ) when that virtual processor  can ensure that it will not execute an execution context  that accesses concurrent data structure . When all indicators  have been set to the second value, the execution context  determines that a safe point has been reached and changes the safe indicator  to indicate that the element  is safe to delete. The execution context  may delete the element  or allow the element  to remain in free element list  for reuse.","In another embodiment, scheduler  or each concurrent data structure  includes a data version  and a commit version  that are accessible by each virtual processor  as shown in . Execution contexts  use data version  and commit version  along with indicators  to determine whether a safe point has been reached. In addition, the execution context  sets the corresponding safe indicator  to indicate that the element  is not safe to be deleted by storing an incremented data version  as the safe indicator  when an element  is moved from list array  to free element list .","Data version  and commit version  are initialized to be equal to one another and equal each indicator . Periodically (e.g., when free element list  becomes full) or each time that an execution context  moves an element  from list array  to free element list , execution context  increments data version .","Any time that an execution context  executing on a virtual processor  reaches a safe point, the execution context  sets the indicator  of the virtual processor  to be equal to the data version  and attempts to commit the current or an intermediate data version. If the indicators  in each virtual processor  are greater than the current commit version , then the execution context  commits the current or an intermediate data version by storing the lowest value of the set of all indicators  as commit version .","In addition to committing a data version to commit version , the execution context  sets any safe indicators  with values less than or equal to the committed data version to indicate that the corresponding elements  are safe to delete. The execution context  may delete the element or elements  that are safe to delete or allow the element or elements  to remain in free element list  for reuse.","In one embodiment, each virtual processor  sets its corresponding indicator  to indicate that a safe point has been reached in a dispatch loop that dispatches execution contexts  of scheduler  to execute tasks of process  for execution. In this embodiment, the dispatch loop distinguishes between executing tasks that implement scheduling functions of scheduler  and tasks of process . After executing tasks that implement scheduling functions, the dispatch loop knows that concurrent data structures  used by the scheduling functions will not be accessed by the virtual processor  while the virtual processor  is executing tasks of process . Accordingly, the dispatch loop sets the indicator  upon initiating the execution of tasks of process  in this embodiment. In other embodiments, each virtual processor  may sets its corresponding indicator  using other suitable criteria that indicate that a previous version of concurrent data structure  will not be accessed by the virtual processor .","To remove an array  from list array , the runtime environment  moves the array to a list  of arrays  to be deleted with synchronization. Before removing array  from list , the execution context  ensures that all virtual processors  have reached a safe point using indicators  as described above. After determining that no virtual processors  will access concurrent data structure , the execution context  removes array  from list .","In one embodiment, process  (shown in ) organizes tasks into one or more schedule groups  (shown in ) and presents schedule groups  to scheduler  as shown in . In other embodiments, process  organizes tasks into collections for each virtual processor  of scheduler  in other suitable ways.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 4","b":["90","22","90","92","93","94","96","92","38","22","38","92","93","39","38","22","93","22","12","94","96","98","34","96","96","42","34","38"]},"Using the embodiment of , scheduler  may first search for unblocked execution contexts  in the runnables collection  of each schedule group  in scheduler . Scheduler  may then search for realized tasks in the realized task collection  of all schedule groups  before searching for unrealized tasks in the workstealing queues  of the schedule groups .","In one embodiment, a virtual processor  that becomes available may attempt to locate a runnable execution context  in the runnables collection  or a realized task  in the realized task collection  in the schedule group  from which the available virtual processor  most recently obtained a runnable execution context  (i.e., the current schedule group ). The available virtual processor  may then attempt to locate a runnable execution context  in the runnables collections  or a realized task  in the realized task collection  in the remaining schedule groups  of scheduler  in a round-robin or other suitable order. If no runnable execution context  is found, then the available virtual processor  may then attempt to locate an unrealized task  in the workstealing queues  of the current schedule group  before searching the workstealing queues  in the remaining schedule groups  in a round-robin or other suitable order.","In one embodiment, runtime environment  creates concurrent data structures  to manage schedule groups . Runtime environment  also creates concurrent data structures  to manage local collections of tasks for each virtual processor . Additional details of local collections of tasks for each virtual processor  may be found in co-pending U.S. patent application Ser. No. 12\/121,789, filed on May 16, 2008, and entitled LOCAL COLLECTIONS OF TASKS IN A SCHEDULER which is incorporated by reference herein. In addition, runtime environment  creates concurrent data structures  to manage scheduling collections of tasks for scheduling nodes (not shown). Additional details of scheduling collections of tasks for scheduling nodes may be found in co-pending U.S. patent application Ser. No. 12\/121,794, filed on May 16, 2008, and entitled SCHEDULING COLLECTIONS IN A SCHEDULER which is incorporated by reference herein.","In other embodiments, schedule groups  contain other suitable numbers, types, and\/or configurations of task collections.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 5","b":["100","10","46"]},"Computer system  includes one or more processor packages , a memory system , zero or more input\/output devices , zero or more display devices , zero or more peripheral devices , and zero or more network devices . Processor packages , memory system , input\/output devices , display devices , peripheral devices , and network devices  communicate using a set of interconnections  that includes any suitable type, number, and configuration of controllers, buses, interfaces, and\/or other wired or wireless connections.","Computer system  represents any suitable processing device configured for a general purpose or a specific purpose. Examples of computer system  include a server, a personal computer, a laptop computer, a tablet computer, a personal digital assistant (PDA), a mobile telephone, and an audio\/video device. The components of computer system  (i.e., processor packages , memory system , input\/output devices , display devices , peripheral devices , network devices , and interconnections ) may be contained in a common housing (not shown) or in any suitable number of separate housings (not shown).","Processor packages  include hardware threads ()-(M). Each processor package  may include hardware threads  with the same or different architectures and\/or instruction sets. For example, hardware threads  may include any combination of in-order execution cores, superscalar execution cores, and GPGPU execution cores. Each hardware thread  in processor packages  is configured to access and execute instructions stored in memory system . The instructions may include a basic input output system (BIOS) or firmware (not shown), OS , a runtime platform , applications , and resource management layer  (also shown in ). Each hardware thread  may execute the instructions in conjunction with or in response to information received from input\/output devices , display devices , peripheral devices , and\/or network devices .","Computer system  boots and executes OS . OS  includes instructions executable by hardware threads  to manage the components of computer system  and provide a set of functions that allow applications  to access and use the components. In one embodiment, OS  is the Windows operating system. In other embodiments, OS  is another operating system suitable for use with computer system .","Resource management layer  includes instructions that are executable in conjunction with OS  to allocate resources of computer system  including hardware threads  as described above with reference to . Resource management layer  may be included in computer system  as a library of functions available to one or more applications  or as an integrated part of OS .","Runtime platform  includes instructions that are executable in conjunction with OS  and resource management layer  to generate runtime environment  and provide runtime functions to applications . These runtime functions include a scheduler function as described in additional detail above with reference to . The runtime functions may be included in computer system  as part of an application , as a library of functions available to one or more applications , or as an integrated part of OS  and\/or resource management layer .","Each application  includes instructions that are executable in conjunction with OS , resource management layer , and\/or runtime platform  to cause desired operations to be performed by computer system . Each application  represents one or more processes, such as process  as described above, that may execute with scheduler  as provided by runtime platform .","Memory system  includes any suitable type, number, and configuration of volatile or non-volatile storage devices configured to store instructions and data. Memory system  may include any suitable cache hierarchy, be configured as a shared or distributed memory system, and may embody a locality scheme such as a non-uniform memory access (NUMA) scheme. In addition, memory system  may be configured as a single instruction stream multiple different memory store (SIMD) system, a multiple instruction stream multiple different memory store (MIMD) system, or a computer cluster coupled through a messaging protocol such as concurrent read, concurrent write (CRCW), concurrent read, exclusive write (CREW), or parallel random access machine (PRAM).","The storage devices of memory system  represent computer readable storage media that store computer-executable instructions including OS , resource management layer , runtime platform , and applications . The instructions are executable by computer system to perform the functions and methods of OS , resource management layer , runtime platform , and applications  described herein. Examples of storage devices in memory system  include hard disk drives, random access memory (RAM), read only memory (ROM), flash memory drives and cards, and magnetic and optical disks.","Memory system  stores instructions and data received from processor packages , input\/output devices , display devices , peripheral devices , and network devices . Memory system  provides stored instructions and data to processor packages , input\/output devices , display devices , peripheral devices , and network devices .","Input\/output devices  include any suitable type, number, and configuration of input\/output devices configured to input instructions or data from a user to computer system  and output instructions or data from computer system  to the user. Examples of input\/output devices  include a keyboard, a mouse, a touchpad, a touchscreen, buttons, dials, knobs, and switches.","Display devices  include any suitable type, number, and configuration of display devices configured to output textual and\/or graphical information to a user of computer system . Examples of display devices  include a monitor, a display screen, and a projector.","Peripheral devices  include any suitable type, number, and configuration of peripheral devices configured to operate with one or more other components in computer system  to perform general or specific processing functions.","Network devices  include any suitable type, number, and configuration of network devices configured to allow computer system  to communicate across one or more networks (not shown). Network devices  may operate according to any suitable networking protocol and\/or configuration to allow information to be transmitted by computer system  to a network or received by computer system  from a network.","Although specific embodiments have been illustrated and described herein, it will be appreciated by those of ordinary skill in the art that a variety of alternate and\/or equivalent implementations may be substituted for the specific embodiments shown and described without departing from the scope of the present invention. This application is intended to cover any adaptations or variations of the specific embodiments discussed herein. Therefore, it is intended that this invention be limited only by the claims and the equivalents thereof."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings are included to provide a further understanding of embodiments and are incorporated in and constitute a part of this specification. The drawings illustrate embodiments and together with the description serve to explain principles of embodiments. Other embodiments and many of the intended advantages of embodiments will be readily appreciated as they become better understood by reference to the following detailed description. The elements of the drawings are not necessarily to scale relative to each other. Like reference numerals designate corresponding similar parts.",{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 5","b":"46"}]},"DETDESC":[{},{}]}
