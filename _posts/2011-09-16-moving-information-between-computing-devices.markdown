---
title: Moving information between computing devices
abstract: A computer-implemented method for moving information between computing devices includes capturing a digital image of a display of a first computing device using a camera of a second computing device, transmitting, to the first computing device, data that corresponds to the digital image; analyzing the transmitted data on the first computing device to determine whether the digital image matches a current display of the first computing device, and using the analysis to cause one of the first or second computing devices to invoke an application and match a state of an application that is executing on the other of the first or second computing devices.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08805089&OS=08805089&RS=08805089
owner: Google Inc.
number: 08805089
owner_city: Mountain View
owner_country: US
publication_date: 20110916
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application claims priority under 35 U.S.C. \u00a7119(e)(1), to U.S. Provisional Application Ser. No. 61\/384,075, filed on Sep. 17, 2010, the entire contents of which are incorporated herein.","This document relates to systems and techniques for moving data from one computing device to one or more other computing devices.","Many people now own a number of different computers, from a desktop or laptop computer at work or home, to a tablet or slate for reviewing digital content, to a smartphone for mobile computing and communications. Computer users transition frequently between these devices, for example, leaving their personal computer in their office during lunch and carrying their smartphone with them.","At times, a computer user may want to move information from one device onto another device. For example, a computer user may employ the power and convenience of her desktop computer to type in the address of an upcoming travel destination and to get directions to the destination. To make the information mobile, the user can print the directions and carry them along on the trip. The user may also take a picture of the desktop computer's screen, and look at the image of the map captured in the picture as need be on her mobile device display. Alternatively, the user could copy a Uniform Resource Locator (URL) for a map from a browser, paste the URL into an email to himself or herself, send the email, and then open the email with his or her mobile device and select the hyperlink for the URL.","This document describes systems and techniques that provide mechanisms for moving information conveniently between computing devices. The information may be the current state of an application on a first computer, so that the state can be duplicated automatically on a second computer. In one such example, a user who wants to duplicate or approximate a part of a state of another computer may capture an image of the display of the other computer, such as by using a camera on her smartphone. For example, the user may have employed her desktop computer to generate driving directions from her own office to an office of a colleague, and may want a corresponding mapping application to open on her smartphone so that she can carry the directions with her during her drive to the colleague's office. The techniques described here may cause the captured image to be sent to each of the other active (logged in) devices that are assigned to the user, and those devices may compare the image to their respective current displays (because one of them will be displaying the original display that is in the captured image) in order to determine if they are the intended target of the information sharing request. The device that determines it is the target may then converse with the relevant application to obtain information about the state of the application, such as a Uniform Resource Identifier (URI) from a web browser or other forms of information that may be defined by an application programming interface (API) for the system. Such information may then be sent back to the smartphone, which may then cause a corresponding application to be made active and to match the state of the application on the computer. In one implementation, this process is known as deep shooting, or \u201cDeep Shot,\u201d because it allows the initiating or initial device to obtain, not only the image, but also the underlying state data so that it can open an actual functioning application with which the user can interact.","An inverse procedure may be used to post state information from the device that has a camera to another device. In particular, the initiating device (e.g., a smartphone) may capture an image of the target device, and may send that image to all devices that are logged into the user's account (or that are otherwise related to each other in some defined manner). The initiating device may include, along with the image, information about its own state, such as a URI of an application that is the current focus of the initiating device (and it may overlay an image of the application on the image from the camera when the user is taking the picture, so as to clarify for the user the information that will be sent to the other devices). Each of the other devices may then determine whether they are the device in the image, and the device that determines it is the device in the image may launch the relevant application that is identified in the additional information from the initiating device, and may set the state of that application to the state identified in the additional information. Such an implementation may be referred to as \u201cdeep posting,\u201d in contrast to the \u201cdeep shooting\u201d of the first example.","Referring to the mapping example, the user can capture an image of the user's desktop computer and may send that image from the user's smartphone to the desktop computer (and to other devices that belong to the user and are logged in) along with state information from the smartphone browser. The desktop computer can then determine that it is shown in the image and can open its corresponding application and provide it with the received state information. Where the application is a browser, the information may simply be a URI in the address bar of the browser, though additional information may be obtained from the browser when the URI does not fully describe the state of the application (e.g., when various AJAX techniques are used by the application).","Such identification of an executing application and state of the application may be carried out in one example, using text messaging techniques that permit TCP\/IP communications between devices over the internet, while permitting relatively long message and rich content to be sent. One such example is the Extensible Messaging and Presence Protocol (XMPP), which has been implemented commercially as the Jabber product.","In other instances, image analysis can be used to identify the state of a device whose display has been captured in a digital image, such as by identifying text in an image using optical character recognition. For example, if a user captures an image of a map, the names of the towns that are displayed on the map may be identified, and those names may be used to identify the state of the application, such as by providing the names as search query terms for returning an area on the map. Subsequent steps may be taken to make a tighter match for the state of the application, such as by comparing a generated map to the image to make the zoom level proper. Image features in the image may also be compared with image features stored for a polarity of displays of computer applications.","In certain instances, the techniques discussed here can provide one or more advantages. For example, a user of a computing device can use her existing knowledge for operating a camera on the computer (which she may operate every day) to acquire an image of another computer. She can then coordinate or synchronize her smartphone to her computer or another person's computer automatically (though the synchronizing may be delayed, such as by the target computer sending a URI in a text message that the initial user must select in order to activate the captured state from the other computer). As a result, a user can share states between different ones of her computing devices or devices of other uses, and can then interact fully with the computer applications starting from those shared states. As a result, a user may have an improved experience in sharing information between computing devices.","In one implementation, a computer-implemented method for moving information between computing devices is disclosed. The method includes capturing a digital image of a display of a first computing device using a camera of a second computing device, transmitting, to the first computing device, data that corresponds to the digital image, analyzing the transmitted data on the first computing device to determine whether the digital image matches a current display of the first computing device, and using the analysis to cause one of the first or second computing devices to invoke an application and match a state of an application that is executing on the other of the first or second computing devices. The second computing device can provide, to the first computing device and with the digital image, state information about an application executing on the second computing device. Also, the second computing device can launch the application in a state that corresponds to the state information after determining that the digital image shows a current display of the first computing device.","In some aspects, the first computing device can determine whether it is shown in the digital image. Also, the first computing device can receive the digital image from the second computing device, and provide, in a responsive message to the second computing device, identification of an application running on the first computing device and a state of the application. Analyzing the transmitted data on the first computing device can include comparing a feature set from the transmitted data to a feature set from a current screen shot of the first computing device. The method can also include automatically transmitting the data that corresponds to the digital image to all devices that are registered with a messaging system to the user of the first computing device.","In another implementation, a computer-implemented method for moving information between computing devices is disclosed that includes obtaining a digital image of a display screen of a first computing device that is displaying a first application having a first state, where the digital image was acquired by a second computing device, analyzing the digital image to identify aspects of the display screen from the digital image and encoding those aspects as one or more parameters, identifying a currently operating application on the first computing device or on the second computing device, and a current state of the application, and providing data for causing the identified application to be activated on the other computing device on which the application was not operating, and for causing the application on the other computing device to enter a state that corresponds to identified current state. The digital image can be sent from the second computing device to the first computing device, and the second computing device can perform the analyzing of the digital image. The first computing device can also identify a currently operating application on the first computing device and provide an identifier for the application and a current state of the application to the first computing device. Also, the computing device can analyze the digital image to determine whether the first computing device is shown in the digital image. The first computing device can additionally activate the application based on a determination that the first computing device is shown in the digital image, and use state information received from the second computing device to establish a state of the activated application.","In some aspects, the first computing device can decline to activate an application on the first computing device based on a determination that the first computing device is not shown in the digital image. Also, analyzing the image can include determining whether a portion of the image matches a current video display of the first or second computing devices.","In some aspects, analyzing the digital image can include using optical character recognition to identify words, and identifying a currently operating application by using the words to select an application from multiple possible applications. Analyzing the digital image can include performing feature analysis on the digital image and comparing results of the feature analysis to results of feature analysis previously performed on images of known computer applications, where identifying a currently operating application comprises identifying a particular application that corresponds to a match in feature analysis results. In addition, providing data for causing the second computer to automatically display the first application in the first state can include sending a URI to the second computer, the URI corresponding to the first application and the first state. Moreover, the state can include a state of the first computing device accessing a hosted document stored at a computer server system, and providing the data for causing the identified application to be activated can include providing data that causes the second computing device to open an instance of the hosted document.","In yet another implementation, a computer-implemented system for moving information between computing devices is disclosed. The system includes a first computing device arranged to present one or more applications, each having a current state, on a display screen, a second computing device having a digital camera capable of capturing an image of the first computing device, and messaging interfaces on the first computing device and the second computing device to communicate messages through a network and central messaging service between the devices. One or more of the first and second computing devices is programmed, alone or in combination, to obtain data corresponding to a digital image of the display screen captured by the camera, to analyze the data to identify aspects of the display screen from the digital image, and to encode those aspects as one or more parameters, to identify a currently operating application on the first computing device or on the second computing device, and a current state of the application, and to provide data for causing the identified application to be activated on the other computing device on which the application was not operating, and for causing the application on the other computing device to enter a state that corresponds to identified current state.","The details of one or more embodiments are set forth in the accompanying drawings and the description below. Other features and advantages will be apparent from the description, drawings, and claims.","Like reference symbols in the various drawings indicate like elements.","This document describes systems and techniques for capturing information about a current state of one computer and providing it so that a second computer can take the same or a similar state, along with other mechanisms for sharing information between computers using image capture techniques. In the examples discussed here, a camera on a computing device, initiating device or initial computer (e.g., a smartphone), can be used to capture an image of a display screen of another computer or target computer. That image may then be analyzed in order to identify what is occurring on the target computer, and to generate information that may be provided to the initial computer so that the state of the initial computer may match the state of the target computer in the picture. Such a match may be a total match, such as by determining all relevant state variables for the target computer, and emulating those variables on the initial computer. The match may also be an approximate match, such as where the target computer displays an area on a mapping application that substantially overlaps with the area in the captured image, but that may be moved somewhat or zoomed differently. The match may also be an associative match so that the state is modified to match a relative context of the second computer. For example, if a target computer has a document open and a first user of the target computer is editing the document, the initial computer may open the document simultaneously, but may display a cursor for a second user, displaying the cursor at a different location in the document. Thus, the state on the initial computer is similar to the state on the target computer in that both users are viewing the same document, but the state on the initial computer is different from the state on the target computer in that the view on each computer is customized for each of the users.","The following description discusses an example use case of the techniques here, and then discusses particular technical mechanisms for carrying out the use case and other such use cases.  show a smartphone  capturing state information from a monitor of a desktop computer. In general, the figures show a use case of passing the state of a mapping application from a desktop computer to a smartphone, as mentioned above.","In , a user is holding her smartphone  in her right hand and aiming it at a computer monitor  (or display device) of her computer  (e.g., a desktop computer). The user may have employed a web browser (shown by a browser tab ) on her computer  to navigate to a geographic area on a map, such as the location of a business meeting. She may have chosen to use the computer  because of its relatively large monitor and flexible input mechanisms (e.g., a mouse, touch input, and the like). However, she may not be able to bring her computer  with her in her car, and she may need to consult the map as she drives. As a result, she has a desire to get the map information from her computer  to her smartphone . (A smartphone includes a computer, but the smartphone  is referenced separately from the particular computer  here to distinguish, in this example, the one computer of the user (the desktop computer) from the other (the smartphone).)","In this example, the screen of the smartphone  is showing a user interface for a standard camera application that may be included with the smartphone  when it is first provided to the user. In this example, the user has just captured an image of part of the map displayed on the computer monitor . The display of the smartphone  thus shows a subset of the map  that is displayed on the computer monitor .",{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 1B","FIG. 1B"],"b":["108","108","108","108","108","110","108","112","102","108","108","108","100","100","108","100","108","108","100","100","100","102","100","102","100"]},{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 2A","FIGS. 1A and 1B","FIG. 2A"],"b":["200","200","200","202","200","204","208","206","204","208"]},"The server system  may implement a standard instant messaging (IM) system that includes a cross-device information exchange system like PIE. The use of an IM architecture for the information sharing may be beneficial in certain implementations by (1) allowing the computers ,  to communicate with each other without knowing the other's IP address; (2) providing persistent connections for sending and receiving messages in real-time, so as to avoid certain problems with Network Address Translations (NATs) and firewalls; (3) providing immediate messaging so that the computer  can receive a message immediately after the computer  captures an image of the display of computer ; and (4) as the standard instant messaging systems can be fairly mature, well-developed, and well-documented systems, existing libraries and other elements may be used, the system can be modified and improved by many programmers, and the system can be implemented using existing hardware and software, by administrators who already understand such systems.","The particular messaging in one implementation is the Extensible Messaging and Presence Protocol (XMPP) system, which has been implemented commercially as the Jabber product. Such a product permits a single user to log on simultaneously from multiple \u201cresources,\u201d or devices. The user account and resource is identified in communications by the following addressing scheme: \u201cuser@server\/resource\u201d. Thus, a user can establish each of her devices initially with a single user name, and can avoid having to add all of her devices into a contact list manually. In addition, XMPP messages can be relatively large (compared, e.g., to SMS text messages), so that richer content, such as JPEG or other formatted digital images, may be sent using the protocol.","The computers ,  each have programs installed and configured by the user to perform the state matching discussed above (e.g., via deep shooting or deep posting). The particular components in an example implementation are discussed in detail with respect to . In general, the applications may be the same on both computers , , though certain components may be used only on the computer that has image capture capabilities. The applications may be programmed to capture an image, to post the image to a corresponding computer, and to launch an application that corresponds to an application on the other computer in response to a return communication from the other computer.","On the opposite side of an interaction, a target computer may include components for dispatching a received request from the initial computer that captured the image so as to determine whether the image matches the current display of the target computer. The determination is then used for identifying relevant state information of the target computer if there is a match, and for communicating the state information of the target computer back to the initial computer.","A particular information sharing process is shown by the flow arrows in . The process begins when a user logs in to server system  with computer  (arrow ) and thus establishes its presence in the system  and opens a persistent communication channel. At a same, earlier, or later time, the user may log in with computer  (arrow ). The authentication process may cause a level of trust to be formed between the computers , , in that the computers may respond automatically in response to requests from other similarly-authenticated devices because the devices are known to be authenticated to the same user. Although only two computers ,  are shown here for clarity, a user could log in with three or more different devices at the same time (e.g., a plurality of desktop computers, a tablet, a gaming console, and a smartphone). The relevant communications shown here may then be spread by the server system  to each of the similarly-authenticated devices.","Such communications may also occur between devices that are assigned to different users. For example, users may arrange themselves into groups with other users who they trust (e.g., others in their department at work) and the system  may be programmed to automatically pass messages of the type discussed here among the users. In some implementations, the trust may be limited so that a receiving user's device may generate a signal that a relevant communication has been received, and may ask the receiving user to confirm that she is willing to share information about the state of her computer (where the message can provide the identity of the requesting user and identify the information that is to be passed back to the requesting user). Thus, for example, two users who are colleagues and in a room together may have a first user capture an image of the second user's computer display, which will cause the second user's computer to request confirmation from the first user in order to share state information. In some implementations, the trust can be established at run-time, such as by having the target computer post a message for its user when a request for information from another device arrives, where the message can include an identity of the requesting user and also identify the information that will be sent to the requesting user, so that the target user can permit or deny access to the information. In such a situation, for example, the requesting user may have had to identify a test messaging address for the target user manually.","After the computers ,  have logged into the system , the computers ,  may wait for the system  to cause a sharing of information. However, using the text message protocols discussed here, the computers ,  may stay alert for communications from other such computers. A particular information sharing session begins in the example shown in  when computer  is used to capture an image of the display on computer . In this example, a photo of three people can be displayed in a photo management application, including a hosted application, on the monitor of computer . The computer  is shown as having captured at least a portion of that image, passing the image along with other relevant information for the information sharing process to the text message server system  (arrow ). Such a transmission can cause server system  to provide a message to all other devices that are pre-authenticated with the computer . As noted above, such devices may include all devices currently logged into the same user account, devices in a defined group, or other organizations of devices. In this example, the one other device shown that is pre-authenticated with the computer  is the computer , though the same user may have other devices that are pre-authenticated with the computer  that are not shown here.","The computer  can perform the image capture using an application that is specifically directed to the information sharing processes described here. The image capture can be performed via an extension to a native cameraphone system, or can be incorporated into the basic cameraphone functionality. In some examples, the functionality may be one option in a menu of options for sharing a captured image (where the other options can include emailing the image, posting the image to a social networking site, and the like). In some implementations, a device may automatically check whenever an image is captured to determine if the image shows a computer display, and if it does, the functionality discussed here may be instigated automatically.","Returning to the information flow of , the computer  receives the message from computer  and begins a process of checking its own status against the information in the message (arrow ). In particular, a computer  may take a screenshot of its own screen and compare that screenshot to the image received from computer . In one example, the image is encoded in a BASE64 format, and may be decoded using computer vision algorithms such as speeded-up robust features (SURF) or scale-invariant feature transform (SIFT). SURF is a visual features-based algorithm that is robust against scaling and rotation. SURF may be used in a process to detect the key points on a screenshot that is taken on computer  and on the image received from computer , respectively. In addition, SURF may be used in a process to locate the region that the first user captured with the camera of computer , by pairing each key point in a screenshot with each key point of the picture. Once the computer  has identified a matched region on the screen, it may obtain the X, Y coordinates of the corners of the region and the central point of the region and provide that information to the front-most application running on the computer  in that region.","The application may then respond with a message that provides information about its current state. In some implementations, the applications on computer  may be programmed by their developers to perform such actions using an application programming interface (API). In other examples, the application may be a browser that may have been provided with an extension for performing such actions. The information provided by the application may, in some implementations, include a URI that describes the current state of the application. Once the information is gathered, as shown by the information flow (arrow ), the computer  may pass back to the requesting computer , through the server system , information that describes its current state, such as a URI.","Although not shown in this figure, other devices registered with the system  to the same user may have also received the message and acted in a similar manner. In particular, those devices may have received the image, compared it to a screenshot of their current displays, determined that they were not the target of the communication and stayed quiet, or returned respective messages to the computer  that indicated they did not have a match and would not be providing current state information for themselves.","The URI or other form of information that describes the state of the application on the computer  is passed back by way of a corresponding text message to the computer  (arrow ). The computer  may then interpret the received information to launch appropriate applications or make an appropriate application the focus of the computer , and may transition the application into a state that matches the state of the corresponding application on the computer . For example, the computer  may pass a received URI as an address to a browser running on the computer .","In a similar example that involves deep posting from the computer  to the computer  (as compared to deep shooting to obtain information from the computer  to the computer ), a user of the computer  may affirmatively push the state of the computer  out to the computer . As one example, a user may have started editing a document on computer  (e.g., her smartphone) while walking to her office, and may want to complete the editing of the document on her computer  (e.g., a desktop computer). In this example, the user may invoke an information sharing application, which may cause the camera on the computer  to be activated, and also overlay the current view of the camera with the user's current display on the computer . The user may then aim the camera at the computer  and capture an image of the computer . The computer  may then submit a text message in a manner that is similar to that discussed above but with an indication that the computer  is attempting to share its own state with another computer, and with information that describes that current state. The computer  may then receive the message and may perform image matching as described above for deep shooting. For deep posting, however, the computer  determines whether it is the computer to which the user intends the post to be directed. If the computer  determines from the matching that it is the target computer, it may launch or make active an appropriate application or applications, and may set the state of those applications according to the information it received in the text message from computer . In the example above, the computer  may launch a hosted word processing system and may open the same document that the user was editing on the computer , so that the user may continue the editing process easily and seamlessly.","Thus in this manner, the techniques described here may provide, in some implementations, convenient and intuitive mechanism for sharing or synchronizing information between computers that are in visual proximity to each other. Users of such computers are aware of the camera functionality on their computers and may thus invoke the information sharing processes described here. In addition, an information sharing may occur over standard TCP\/IP and text messaging functionality. In general, this functionally can be available and activated at all times on most computers. The process may be implemented in most existing systems with little disruption and can be used intuitively by users of those systems.",{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 2B","FIG. 2B","FIG. 2B"],"b":["220","222","220","220","220","220","220","220","220"]},"In the example of , the mobile device A and the desktop computer B include multiple component types, for example, a shooter, a poster, a dispatcher, launchers, and applications. The shooter component and the poster component can operate on a device that captures images (e.g., a mobile device). The dispatcher component can operate on target devices or computers that share information in deep shots or accept posts from deep posting. The launchers can operate on a device that captures images as well as a target device. When operating on the mobile device A, a launcher  launches mobile applications to present the information that is captured by deep shooting. When operating on the desktop computer B, a launcher  causes desktop applications to present the information that was posted by deep posting.","The particular messages exchanged between and among the components may be structured and encoded in the JavaScript Object Notation (JSON) format. In other words, on top of XMPP, the body of the messages between the XMPP server and the components connected to it are encoded in JSON. The messages on top of WebSocket between the dispatcher and the applications may also be in JSON. WebSocket is a protocol that supports full-duplex and bi-directional communication over a TCP socket. WebSocket is currently being standardized by the Internet Engineering Task Force (IETF) and the World Wide Web Consortium (W3C). In general, many web browsers support the protocol, and many desktop applications can support the protocol because of the use of TCP sockets, where WebSocket can be an extension of TCP sockets with a HTTP-like handshake protocol.","In operation, every time each of applications A-N and , where the applications A-N and  support deep shooting, is launched, the launched application registers itself to a dispatcher  though a WebSocket connection on a TCP port . A registration process starts after the standard WebSocket handshaking. The launched application sends out a line \u201creg APP_NAME\u201d that ends with a carriage return, line feed (CRLF) terminator, where APP_NAME is the name of the launched application. If the dispatcher  accepts the registration of the launched application, the dispatcher  returns \u201cok\u201d with a CRLF. If the dispatcher  does not accept the registration, the dispatcher  returns a message indicating the reason and closes the connection. To support deep posting, an application can optionally send an \u201caccept URI_SCHEME\u201d command, which indicates what types of URI schemes the application accepts. For example, an email client can register \u201cmailto:\u201d, and a web browser can register \u201chttp:\u201d and \u201chttps:\u201d. Once the registration is completed, this WebSocket connection can be kept persistent until the application is closed, so that, for example, the dispatcher can proactively notify an application when a request is coming. Particular processes using the components of system  are discussed in .",{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 3B"},"The processes for both  are described, with further reference to the system  in ","Referring to  and , a user initially captures a picture (image) using a shooter , where the picture is directed to show a display of the desktop computer B (box ). Once a user uses the shooter  to take a picture of a region of interest on a computer monitor included with the desktop computer B, an XMPP message with a subject \u201cdeepshot.req\u201d is sent by the capturing computer (e.g., the mobile device A) (box ). The sending of this message indicates a deep shooting request is then broadcasted to each device that is currently logged in for the user (box ). The message in one example can include one pair of key-values (e.g., content, and the picture encoded as a BASE64 string taken by the user).","The dispatcher  running on the desktop computer B receives the \u201cdeepshot.req\u201d message (box ). The desktop computer B takes a screenshot of the display of the desktop computer B (box ). The dispatcher  then decodes the received BASE64 message, and compares the decoded picture against the screenshot using SURF or a similar algorithm (box ). When the dispatcher  has found a matched region in the screenshot, it determines the x-y coordinates of the corners of the matched region and the central point of the matched region, and also determines which application on the desktop computer B is the front most application (box ).","The dispatcher  in this example is designed as a daemon that can continuously run as a background application on a computing device. The dispatcher  has the user's credential, so the dispatcher  can connect to the XMPP server all the time. Therefore, the availability of a computing device can be obtained from the XMPP server from any other computing device. When the dispatcher  has made the determinations described above, the dispatcher  uses the already-open WebSocket connection with each running and participating application (applications A to N and ) to provide a JSON request to the relevant applications A-N and  that include two pairs of key-values which can be coordinates (e.g., corners and a list of four pairs of x-y coordinates, and center and one pair of x-y coordinates), where the coordinates are relative to the upper-left corner of the dispatched window.","The application then determines its state in any relevant manner and returns its state information to the dispatcher (box ). Such information may be, for example, a URI in a current web browser address box. Other similar information may be provided by other applications. In some examples, the response from the application can include at least one pair of key-values (e.g., a URI, which represents the state of the application). Applications can create their own URIs making the URIs compatible with public standards (e.g., http:,tel:, geo:, etc.). In some cases, an application can attach offline resources or files. Each attached resource or file can be stored in a JSON structure with two pairs of key-values (e.g., (1) a name, which is the file name, and (2) a content, which is the BASE64-encoded content of the file). The attachments can be stored in a JSON array identified by the key \u201cfiles\u201d in the reply message.","A web browser on the desktop computer B may present a special type of application. The web browser may be provided with a web dispatcher extension  or plug in, so that the browser may participate in the processes described. All of the applications may run in the browser, without the authors of those applications having to explicitly support each process. The web dispatcher extension  acts as a second level dispatcher, routing messages from the dispatcher  to the appropriate web page in a web browser and sending reply messages back to the dispatcher . The web dispatcher extension  provides a JavaScript callback function (e.g., DeepShot.addListener(listener)) to all web pages, so that web developers may hook their internal data to the shooting and posting processes described here.","The web dispatcher extension  also can be a default responder for web applications that may not explicitly support the processes described here. If the web dispatcher extension  receives a request to obtain data from a site that does not register itself using the callback function, it can return a URL for the site as a default response. The URL on the address bar can map to the state of the current web application. However, some AJAX applications may not have this property, or they may decide to hide their real URL. To address this issue, the web dispatcher extension  can proactively extract information from web pages by injecting content scripts. As a browser extension, the web dispatcher extension  can be capable of injecting a variety of content into a web page. Therefore, the web dispatcher extension  can inject a piece of JavaScript that calls the callback function DeepShot.addListener into a web page to extract the web page's internal information. For example, a mapping application may not show the URL to the current region of the map on the address bar. To get the real URL that represents the current state (the current region of the map), the web dispatcher extension  can inject a content script that calls \u201cdocument.getElementById(\u2018link\u2019).href\u201d to obtain the real URL stored in the document object module (DOM) element with the id \u201clink\u201d. Using this content script provides a user the ability to use deep shooting to open a map displaying on her computer in one step.","Upon receiving a response from one of the applications A-N and , the dispatcher  may create a new XMPP message with a subject \u201cdeepshot.resp\u201d, which represents a response message. The body part of the response message is the reply from the application, which is a JSON encoded string. The dispatcher may also insert two new pairs of key values into a message (e.g., (1) a title, which indicates the name of the application, which may be stored and used to search or browse the history of deep shooting, and (2) a thumbnail, which is the BASE64-encoded thumbnail of the matched region of the screenshot, which can also be stored in a log and used to browse a history of deep shooting by a user). The dispatcher  then returns the constructed message that includes state information (box ) to the mobile device A via the XMPP server  (box ). The mobile device A (the capturing computer) receives and processes the message (box ).","When the relevant information has been extracted from the message, the information may then be provided to the launcher . The launcher  may be monitoring for the receipt of a message with such a name since it sent out the initial message to the desktop computer B. When a message with that subject arrives, the launcher  decodes the body of the message encoded in JSON and writes all attachments to the storage on the mobile device A. The launcher A opens an appropriate application that handles the type of URI included in the reply from the desktop computer B and passes the response to the application in order to restore the task on the desktop computer B (box ). Once an application is successfully launched, the process of deep shooting is completed.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 3B","b":["224","224","220","224","220"]},"The process in  starts when an application that is programmed to seek deep posting provides a posting request to the system of a device having a camera (box ). Once the poster  receives a posting request from an application, the poster  opens a camera application and overlaps the screenshot of the application on the viewfinder of the camera so that a user can see the targeting device and the information to post at the same time (box ). After the user has aligned the view of the image she would like to capture within the viewfinder of the camera, the user can indicate capturing of the image (e.g., press a button). As a result of the user input, a JPEG image is captured and the image is encoded into a BASE64 string. The captured, encoded image is then inserted into the JSON structure from the posting request with the key content (box ). The poster  can create an XMPP message with a subject \u201cdeeppost.req\u201d, with the entire JSON string as its body. The poster  can then send this XMPP message to all relevant devices (e.g., all devices currently logged into a user's account) in a manner similar to that for deep shooting (box ).","The XMPP server  then broadcasts the message to all such devices (box ), which receive the message (box ) by way of each of their respective dispatchers. For example, the XMPP server  broadcasts the message to the desktop computer B, which receives the message by way of the dispatcher . Each respective device can then run the computer vision process discussed above for deep shooting to match the picture taken by the user (the captured image) against the particular device's screenshot (boxes , ). For example, the desktop computer B runs a computer vision process in order to determine if the picture taken by the user matches a screenshot of the display of the desktop computer B. If no match is found, the dispatcher  replies to the server system with a \u201cno match\u201d message (box , ), the server system forwards the message back to the capturing computer (e.g., the mobile device A) (box ). The capturing computer (e.g., the mobile device A) processes the \u201cno match\u201d messages (box ). If the dispatcher  determines that there is a match, the dispatcher  sends the request to the launcher  (box ).","As discussed above, each of the applications A-N and  can register the types of URI schemes it supports. The launcher  can use this information to launch an appropriate one on of the applications A-N and  for the URI or other state information received from the capturing computer (e.g., the mobile device A) (box ). Each of the applications A-N and  may register multiple URI schemes. In addition, multiple applications can handle a URI scheme. If multiple applications can accept a URI scheme, in some cases, the launcher  can open a dialog to ask the user to select an application. In other cases, if multiple applications can accept a URI scheme, the launcher  can launch a default application that can be selected prior to launching.",{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 4","b":["400","400","400","402"]},"Machine vision techniques are used to identify aspects of the image that may be relevant and to encode parameters that represent those aspects of the image (step ). In examples similar to those discussed above, the aspects may include portions of the image that match an image taken of a screenshot for the computer that was the target of the first image. The parameters may include coordinates on the display of the second or target device corresponding to a topmost application, and a descriptor for communicating with the application.","The parameters are used to identify the application and the state of the application (step ). For example, the application name may be used to contact the application, which may identify its own state such as by returning a value of a URI that is currently associated with the application.","In another example, machine vision may be used to identify words on the display, and to thereby infer what application is in the image and the state of that application. As one example, machine vision may be performed on a title bar of an application or an address bar in a browser application. Also, other words on a display may be used to further indicate the state of the application. As one example, where text in an address bar indicates that the application is a web browser running a web-based mapping application, other text on the display may be used to determine the geographic area to which the mapping application was directed.","Data is provided for causing a second computing device (that is different that the computing device that was the target of initial data capture) to automatically display the relevant application in the determined state (step ). In the main examples discussed above, such a step may be carried out by having the application on the target device provide its state information to another component that prepares a text message to be sent back to the initiating device, where the text message can further include information that identifies the application and the state. In the other example described, where optical character recognition is used, the text that is identified may be organized by the application running on the initiating device. The organization of the text may be such as to result in text that can be used to submit a search query to a remote search engine, or to construct a URL in another manner. For example, the identification of a mapping application from text in a title bar or an address box may be used to identify a domain for building a URL, and text on the map may be used to identify arguments to be submitted to the domain.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIGS. 5A-5C","b":["502","504","506"]},"In some examples, a deep shooting prototype was implemented to support both deep shooting and deep posting. The mobile device side was implemented using JAVA on a smartphone. On the other side (e.g., the computer side), the dispatcher and the launcher were implemented in Python on a laptop computer. An XMPP server was set up using Jabber on Linux. The default configuration of Jabber has a limit on the size of messages it can handle. To allow the potential large size of the content transferred in the system in the messages, the message size limitation was disabled. Apart from that change, the code of Jabber was not modified.","In other examples, in order to minimize the effort to support deep shooting for application developers, a Java library was developed that implements the dispatcher, an application communication process, and hides the WebSocket connection inside the library. The library has a DeepShot class that has one public method void add Listener(Listener listener, String app_name, String[ ] accepted_uris) for applications to register themselves to listen to deep shot requests.","In more examples, a default responder was implemented in a dispatcher (e.g, dispatcher  as shown with reference to ) to handle the case where the target application does not support deep shooting. In addition, an extension for a web browser was implemented to support URL migration for web applications and also to support proactive content extraction by injecting content scripts.","Referring to , a default responder (e.g., implemented in the dispatcher ) can provide useful information when replying to a target application (e.g., one of the applications A-N on the mobile device A) if the targeting application has not registered with the dispatcher (e.g., dispatcher ). In some cases, a default response from the default responder may not be opened directly by the applications A-N as in the case of normal responses, however, the goal is to seamlessly migrate the information showing on a computing device (e.g., the display of the desktop computer B) to a mobile device (e.g., mobile device A). To achieve this goal, the screenshot of the entire display screen of the computing device (e.g., the display of the desktop computer B) is transferred to the mobile device A along with the coordinates of the matched region. Therefore, a user can see a clear version of the image of the display of the desktop computer B without noise and distortion that may be caused by the use of a separate physical camera to capture the image of the screen in a picture. The user can pan and zoom the screen to see more details or other areas not in the original picture. In addition, when the dispatcher  captures the screenshot, the dispatcher  can also detect clickable URLs and other interesting information (e.g. phone numbers or addresses) using, for example, an accessibility API of an operating system. This information in the form of metadata can be transferred along with the screenshot. The user can select (using an input device included on the computing device) a URL in the screenshot to launch a browser or can select a phone number in the screenshot in order to dial the number directly.","To support web applications, a web dispatcher extension or web dispatcher, was created as a web browser extension. The web dispatcher can have three main functionalities. First, the web dispatcher can act as a second level dispatcher, routing messages from a first level dispatcher to the appropriate web page in a browser and sending reply messages back to the second level dispatcher. The web dispatcher can also provide a JavaScript callback function \u201cDeepShot.addListener(listener)\u201d to all web pages, allowing web developers to simply hook their internal data on Deep Shot. Second, the web dispatcher can be a default responder for all web applications that do not support Deep Shot. If the web dispatcher gets a request to ask for data from a site that does not register itself via the callback function, the web dispatcher can simply return the URL to the site as a default response. The URL on the address bar can map to the state of the current web application. However, some AJAX applications do not have this property or hide their real URL. Fortunately, the last functionality of the web dispatcher can deal with this issue. Third, the web dispatcher can proactively extract information from web pages by injecting content scripts. As a browser extension, the web dispatcher can be capable of injecting any content into any web pages. Therefore, a piece of JavaScript that calls \u201cDeepShot.addListener\u201d can be injected into a web page to extract its internal information proactively even though the original web developers may not have planned to support Deep Shot. For example, a maps application may not show the URL to the current region of the map on the address bar. In order to obtain the actual URL that represents the current state, a content script that calls \u201cdocument.getElementById(\u2018link\u2019).href\u201d can be injected in order to obtain the actual URL stored in the DOM element with the id \u201clink\u201d. With this script, a user can use deep shooting to open any map displayed on their computer.","The developed system was evaluated to explore whether using a camera to locate a region on a monitor is feasible or not in terms of speed and accuracy. The first experiment tested system speed and the second tested the accuracy of the image matching techniques.","Experiment 1","A MacBook Pro 15\u2033 computer with a high-resolution 1680\u00d71050 monitor was used as the target device, and a Nexus One smartphone running Android 2.2 was used as the capturing device. The capturing device was held by a man at a distance between 20 cm to 40 cm from the display, and a pitch angle between \u00b120 degrees so that around \u2153 of the screen could be seen through the viewfinder.","Four types of targeting applications (GOOGLE STREETVIEW photos, text from YELP.COM, long articles with little information from CNN.COM and Maps from GOOGLE MAPS) were examined and three pictures were taken using deep shooting for each application. The procedure involved: 1) taking a 512\u00d7384 picture; 2) sending this picture via a XMPP server to the targeting device; 3) once the picture arrived, the targeting device took a screen shot of the entire screen (1680\u00d71050) and resized it to 840\u00d75254) the targeting device extracted SURF features from the picture and the screenshot, and then matched the features using the process described above; 5) the system combined the information returned by the targeting application (i.e. a URL in this experiment) and a thumbnail of the matched region, and then sent the message via the XMPP server back to the capturing device; 6) once the capturing device received the reply, it saved the attached thumbnail and opened the URL using an appropriate application.","In the total twelve trials (three pictures for four applications), the average time of the whole procedure was 7.74 seconds (SD 0.30 seconds), which is an acceptable amount of time. Examining each step, the network transmission occupied about 50% of the total time, while the other processing time took 34% on the targeting device and 16% on the capturing device. The duration of the transmission time was dependent on the process of attaching one picture and one thumbnail in the messages and the subsequent routing of the messages to an external server. Therefore, the transmission time may be reduced by not transmitting pictures and not passing to a third party.","Experiment 2","A MacBook Pro 15\u2033 computer monitor was used with adjustable tilt and pitch angle for the screen. There were four settings of the pitch angle for the screen: 70\u00b0, 90\u00b0, 110\u00b0, and 130\u00b0. The laptop showed a GOOGLE CHROME full-screen browser with a web page of a popular local restaurant (from YELP.COM) consisting of texts and images. A Nexus One smartphone including a camera was tied to an L-square ruler that was perpendicular to the floor. The height of the camera, measured from the surface of the laptop to the center of the camera lens, was fixed to 19 cm while the pitch angle was 90\u00b0 or 110\u00b0, and 14.5 cm while the pitch angle was 70\u00b0 or 130\u00b0. These height settings allowed the camera to focus around the same target, the name of the restaurant, on the screen. Finally, the phone was set in front of the screen with a distance, which was measured from the screen shaft to the camera lens, from 5 cm to 50 cm. For each pitch angle, five pictures were taken for every 5 cm between 5 cm and 50 cm for a total of 200 pictures.","The techniques described above were used to match each picture against the screen display on the laptop. If the center of the matched region overlapped the expected region on the screen, the match was considered successful.  illustrates a graph of a number of trial pictures taken with respect to pitch angle and distance between the camera and the screen.  shows the number of successful matches for each distance setting , while each bar indicates the total number of matches for the four pitch angles -","The results show that the matching process is improved if the camera is parallel to the monitor and the distance between the camera and the monitor is in a range between 10 cm and 40 cm. This range can cover a small region that can include, for example, the name of a restaurant and its basic information. Even if the camera is tilted by 20 degrees toward or away from the monitor, the camera to monitor distance range may be about 30 cm.","Below are a number of information sharing scenarios or use cases.","Scenario 1: Taking Information to go (Desktops to Mobiles)","This type of scenario motivated the development of deep shooting. People usually work on desktop computers or laptops at work or home. Before moving to another place, they may look up the information related to that place on the computers. However, people forget things quickly. They usually need to write down the information on a piece of paper or look up the same information over again on the mobile phones when they are moving. In this kind of scenario, people can take the information with them using deep shooting. For example, people can carry a piece of a map or the information of a next meeting place so they do not need to look up the same information again.","Scenario 2: Sharing the Content or the State Generated on Mobiles to Desktops (Mobiles to Desktops)","People can generate information (e.g. photos, contacts, or unfinished readings) on mobile devices. People can use particular software to synchronize a mobile device with a desktop device. In some cases, a cable and a full synchronizing process may be needed in order to display a single photo on a large display or to open a web page on the desktop device that is already opened on the mobile device. Deep posting can be a less cumbersome way to share this type of information between mobile devices and desktops.","Scenario 3: Using Mobiles as Temporary Storage (Desktops to Desktops Via Mobiles)","USB sticks (USB flash drives) can be used to share files among computers. People can save the information they need to share as files, copy the files onto the USB stick, and then take the USB stick to another computer. In this type of scenario, deep shooting can be used to extract information automatically from an application running on a computer (e.g., a desktop computer) to a mobile device. The mobile device can be taken to another place, and then the user can post the extracted information to another computer (e.g., another desktop computer) with deep posting.","Scenario 4: Sharing the Content or the State on One Mobile Device with Another Mobile (Mobiles to Mobiles)","Information can be shared between multiple personal mobile devices. In addition, information can be shared from one person's mobile device to another person's mobile device. For example, bumping is a synchronous gesture to connect two mobile devices. Although the current Deep Shot framework does not support communication between multiple users' devices, deep shooting and deep posting can be used to locate another device belonging to a user. In addition, deep shooting and deep posting can be used to locate the region of information to share between multiple users. For example, a user can take a picture of a contact displayed on another person's mobile device with deep shooting using his or her mobile device, and then the contact information can be automatically transferred to the user's mobile device.","Scenario 5: Continued Videogame Game Play","The techniques discussed here may be used to provide continuous game play of a video game by a single player, such as through a long-running game campaign. When the player is at home, he can play on a full-featured gaming console. When he goes to work, he can pause the gameplay and take a picture of his television screen with a smartphone. The console may then receive the image, determine that it is the relevant recipient, and send game status information to the smartphone. The user may then pick up the game on the smartphone where he left off, though at lower resolution and perhaps with certain additional limits on the gameplay functionality. The user can perform the inverse process when he returns home.",{"@attributes":{"id":"p-0098","num":"0097"},"figref":"FIG. 7","b":["700","750","700","750"]},"Computing device  includes a processor , memory , a storage device , a high-speed interface  connecting to memory  and high-speed expansion ports , and a low speed interface  connecting to low speed bus  and storage device . Each of the components , , , , , and , are interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate. The processor  can process instructions for execution within the computing device , including instructions stored in the memory  or on the storage device  to display graphical information for a GUI on an external input\/output device, such as display  coupled to high speed interface . In other implementations, multiple processors and\/or multiple buses may be used, as appropriate, along with multiple memories and types of memory. Also, multiple computing devices  may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).","The memory  stores information within the computing device . In one implementation, the memory  is a computer-readable medium. In one implementation, the memory  is a volatile memory unit or units. In another implementation, the memory  is a non-volatile memory unit or units.","The storage device  is capable of providing mass storage for the computing device . In one implementation, the storage device  is a computer-readable medium. In various different implementations, the storage device  may be a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations. In one implementation, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as the memory , the storage device , or memory on processor .","The high speed controller  manages bandwidth-intensive operations for the computing device , while the low speed controller  manages lower bandwidth-intensive operations. Such allocation of duties is exemplary only. In one implementation, the high-speed controller  is coupled to memory , display  (e.g., through a graphics processor or accelerator), and to high-speed expansion ports , which may accept various expansion cards (not shown). In the implementation, low-speed controller  is coupled to storage device  and low-speed expansion port . The low-speed expansion port, which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input\/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.","The computing device  may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server , or multiple times in a group of such servers. It may also be implemented as part of a rack server system . In addition, it may be implemented in a personal computer such as a laptop computer . Alternatively, components from computing device  may be combined with other components in a mobile device (not shown), such as device . Each of such devices may contain one or more of computing device , , and an entire system may be made up of multiple computing devices ,  communicating with each other.","Computing device  includes a processor , memory , an input\/output device such as a display , a communication interface , and a transceiver , among other components. The device  may also be provided with a storage device, such as a microdrive or other device, to provide additional storage. Each of the components , , , , , and , are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.","The processor  can process instructions for execution within the computing device , including instructions stored in the memory . The processor may also include separate analog and digital processors. The processor may provide, for example, for coordination of the other components of the device , such as control of user interfaces, applications run by device , and wireless communication by device .","Processor  may communicate with a user through control interface  and display interface  coupled to a display . The display  may be, for example, a TFT LCD (Thin-Film-Transistor Liquid Crystal Display) or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology. The display interface  may comprise appropriate circuitry for driving the display  to present graphical and other information to a user. The control interface  may receive commands from a user and convert them for submission to the processor . In addition, an external interface  may be provide in communication with processor , so as to enable near area communication of device  with other devices. External interface  may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interface may also be used.","The memory  stores information within the computing device . The memory  can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units. Expansion memory  may also be provided and connected to device  through expansion interface , which may include, for example, a SIMM (Single In Line Memory Module) card interface. Such expansion memory  may provide extra storage space for device , or may also store applications or other information for device . Specifically, expansion memory  may include instructions to carry out or supplement the processes described above, and may include secure information also. Thus, for example, expansion memory  may be provide as a security module for device , and may be programmed with instructions that permit secure use of device . In addition, secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.","The memory may include for example, flash memory and\/or NVRAM memory, as discussed below. In one implementation, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as the memory , expansion memory , memory on processor , or a propagated signal that may be received, for example, over transceiver  or external interface .","Device  may communicate wirelessly through communication interface , which may include digital signal processing circuitry where necessary. Communication interface  may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver . In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS (Global Positioning System) receiver module  may provide additional navigation- and location-related wireless data to device , which may be used as appropriate by applications running on device .","Device  may also communication audibly using audio codec , which may receive spoken information from a user and convert it to usable digital information. Audio codex  may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device .","The computing device  may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone . It may also be implemented as part of a smartphone , personal digital assistant, or other similar mobile device.","Various implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and\/or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and\/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.","These computer programs (also known as programs, software, software applications or code) include machine instructions for a programmable processor, and can be implemented in a high-level procedural and\/or object-oriented programming language, and\/or in assembly\/machine language. As used herein, the terms \u201cmachine-readable medium\u201d \u201ccomputer-readable medium\u201d refers to any computer program product, apparatus and\/or device (e.g., magnetic discs, optical disks, memory, Programmable Logic Devices (PLDs)) used to provide machine instructions and\/or data to a programmable processor, including a machine-readable medium that receives machine instructions as a machine-readable signal. The term \u201cmachine-readable signal\u201d refers to any signal used to provide machine instructions and\/or data to a programmable processor.","To provide for interaction with a user, the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.","The systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (\u201cLAN\u201d), a wide area network (\u201cWAN\u201d), and the Internet.","The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.","A number of implementations have been described. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. For example, various forms of the flows shown above may be used, with steps re-ordered, added, or removed. Also, although several applications of the certification systems and methods have been described, it should be recognized that numerous other applications are contemplated. Accordingly, other implementations are within the scope of the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF DRAWINGS","p":[{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIGS. 1A and 1B"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 2B"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIGS. 3A and 3B"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIGS. 5A-5C"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
