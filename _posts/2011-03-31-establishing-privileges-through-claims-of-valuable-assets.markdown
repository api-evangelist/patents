---
title: Establishing privileges through claims of valuable assets
abstract: A service accessible by a set of entities may be provided to each entity at a different service level (e.g., with a different set of privileges) based on the privilege level of the entity. However, many users may attempt to perform malicious activities through the service, and may do so with impunity if the penalties of detection are inconsequential. Instead, privilege levels of entities may be established based on the claims of assets having identifiable value. Such claims may be established by submitting an asset identifier to the service, such as proof of a software license identified by the submission of a license key purchased at a substantial cost. The penalties of malicious activities performed by such users may include the invalidation of such asset identifiers. Establishing the privilege levels of respective entities in this manner raises the penalties, and hence the deterrence, of attempted malicious use of the service.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08931056&OS=08931056&RS=08931056
owner: Microsoft Corporation
number: 08931056
owner_city: Redmond
owner_country: US
publication_date: 20110331
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Within the field of computing, many scenarios involve a set of entities having a privilege level. As a first example, a service may be provided to a set of users, each of which has established a privilege level with the service, and the service may provide to each user a different level of service associated with the privilege level of the user (e.g., in a file-sharing service, a user with a higher privilege level may be allocated a larger amount of storage space, and\/or may be granted more extensive access privileges, than a user with a lower privilege level). As a second example, a service may be provided to a set of devices (e.g., a cellular communications network configured to provide communication services to a set of wireless devices), and each device may be associated with a different privilege level (e.g., a first set of high-privilege-level devices provided to users directly by the provider of the service; a second set of privilege-trust-level devices provided to users by companies affiliated with the provider of the service; and a third set of low-privilege-level devices provided to users by unknown companies). Devices with lower privilege levels may be more likely to have been altered and\/or used to access the service in unauthorized ways; therefore, higher levels of service may be provided to devices having higher privilege levels than devices having lower privilege levels.","A particular scenario wherein such techniques may be utilized involves the detection and obstruction of attempt to utilize a service in order to achieve a malicious result, such as accessing an account of another entity (e.g., accessing a bank account in order to steal funds, or accessing a web account of a webserver in order to insert advertisements), sending unsolicited bulk email messages (\u201cspam\u201d) or performing a distributed denial-of-service (\u201cDDoS\u201d) attack on a target. In order to achieve these results on a wide scale, the instigators of such attempts may utilize automated processes, such as brute-force algorithms that attempt to identify security vulnerabilities in services or to guess the identity credentials (such as user ID and password) of the accounts of various individuals. The administrators of such services may utilize various techniques to verify that an entity requesting access to the service is a human and not an automated process. As one such technique, a \u201ccaptcha\u201d mechanism may be utilized, wherein an image is generated and presented that is difficult for an automated process to interpret, but that is comparatively easy for a human to interpret (e.g., text presented in a distorted manner on a noisy background). The service may be provided to the entity only after presenting a correct identification of the content of the image.","Within these and other scenarios, many techniques may be used to identify and update the privilege level associated with a particular entity. For example, different levels of identity verification may be utilized to establish the identity of a user or device with a higher degree of confidence (e.g., requesting and verifying increasingly personal, private, sensitive, and\/or extensive levels of information about the user, or inspecting the components of a device with finer granularity). For example, in order to verify the identity of the entity with a higher degree of confidence, captcha techniques may present a more lengthy or more complex captcha, or may inspect the response of the entity with a higher degree of precision. The privilege level of the entity may be established according to the confidence established in the entity, and may be used in various ways (e.g., to determine the degree of service provided to the entity).","This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.","In order to establish a privilege level of an entity, a service may examine, test, and verify many types of information about the entity. In particular, it may be advantageous to establish the identity of an entity based on an association of the entity with assets having a real-world cost and value. For example, when a user requests to create an account with a service, the service may request the user to identify one or more purchased items, e.g., receipts of items purchased in retail stores. The level of privileges (and possibly service) associated with the user may therefore be selected based on the total value (and possibly reliability) of the identified assets. This technique may be particularly difficult for malicious users to circumvent. For example, an automated algorithm may be unable to register many accounts in an automated manner, because the availability of such assets that may be identified to the service may be limited.","Accordingly, it may be advantageous to configure a service to establish and update the privilege levels of various entities based on the assets associated with various entities, and the total value of such assets. For example, the assets may comprise software licenses of various software products, each of which may be identified according to an asset identifier (e.g., a license key or a registration number) that has been purchased in exchange for a particular value (e.g., the license cost of the asset identifier). The service may request the entity to identify a set of such asset identifiers, may verify each asset identifier, and may set the privilege level of the entity according to the number and value of the identified assets. The service may then use the identified privilege level of the entity in various ways, e.g., to select a quality level of the service provided to the entity. The use of such techniques to establish the privilege level of an entity may be particularly difficult to circumvent, and may therefore present a more reliable privilege level of the entity than may be identified by alternative techniques.","To the accomplishment of the foregoing and related ends, the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects, advantages, and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.","The claimed subject matter is now described with reference to the drawings, wherein like reference numerals are used to refer to like elements throughout. In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident, however, that the claimed subject matter may be practiced without these specific details. In other instances, structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.","Within the field of computing, many scenarios involve a representation of a set of entities (such as users or devices) where each entity is associated with a level of privileges. This level of privileges may be set according to various factors, e.g., the confidence in the security of the entity (such as a security clearance level of a user, or the strength of the security and integrity mechanisms implemented on a device) and\/or the confidence in the authentication of the entity (such as the strength of the security mechanisms guaranteeing that communications received from an entity were authored by that entity, and were not forged or tampered with by another entity).","The levels of privileges may be used by the service in many ways. As one example, a service may be provided to a set of entities, such as an email service configured to receive, store, and send email messages on behalf of such entities; a file service configured to receive, store, and send files to such entities; and an application service configured to install and maintain applications stored on devices (where either the devices or the users of such devices are identified as entities). The entities utilizing a service are attributed different levels of privileges, and the service may be configured to provide different levels of service on behalf of such entities. For example, in a file service, an entity with a higher privilege level may be permitted to store more and\/or larger files, to share such files with more users, and\/or to download more files shared by other users than an entity with a lower privilege level.","One scenario where such techniques may be particularly advantageous comprises the defense of a service against misuse. In many contemporary scenarios, a malicious user may attempt to misuse a service in various ways. As a first example, an email service may be configured to send messages to other users, and a malicious user may seek to send bulk unsolicited email messages (\u201cspam\u201d) to other users through the email service. As a second example, a chat service may allow users to exchange chat messages, and a malicious user may seek to send messages comprising advertisements to other users. As a third example, a file service may allow users to store files, and a malicious user may seek to store the assets involved in malicious activity, such as executable binaries that may be invoked to execute a distributed denial-of-service (DDoS) attack on a targeted server, tools used to co-opt other servers (such as rootkits and bot software), or illegal objects (such as copies of copyrighted works that are to be shared with other users). In each of these examples, the user may seek to create an account with the service through which the malicious activity may be performed. Moreover, the service monitors and reviews the activities of various accounts and shuts down accounts that are misused, but the malicious user may endeavor to circumvent these security measures by automatically registering a larger number of accounts than may be monitored by the service. In this manner, malicious users are frequently able to establish and continue the misuse of the service despite careful policing of account activities.","Additional security measures have been implemented to discourage or diminish the automatic registration and use of accounts on various services. As one such example, \u201creverse Turing tests\u201d are often utilized to verify that an entity requesting a secured activity of the service, such as registering an account or downloading a file, is a human and not an automated process. Techniques directed to this example include \u201ccaptcha\u201d technology, wherein the service generates and presents to the entity a media object containing a signal that is obscured by noise, such as an image including words presented on a cluttered background or an audio recording including spoken words with considerable background noise. Because the sensory processing systems of humans are considerably more proficient at extracting such signals from noise than contemporary automated processes, the service may conclude that entities that correctly identify the signal of the \u201ccaptcha\u201d are humans and may perform the requested services. In this manner, the service may perform such secured activities only in response to requests from humans, and may therefore discourage the invocation of the activities by automated processes that may misuse the service.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1","b":["10","12","14","10","12","16","16","28","12","18","16","16","18","18","20","12","16","20","16","16","28","16","28","12","20","18","22","12","16","16","20","12","22","16","20","12","22","16","12","12"]},"As further illustrated in the exemplary scenario  of , the service  may establish and adjust the privilege levels  of various user accounts  based on various activities performed by the represented entities . As a first example, the service  may present a captcha  in order to verify that each entity  is a human and not an automated process. This captcha  may be presented when an entity  requests to perform a secured activity, such as the creation of a new user account  for the entity . For example, when a first entity  (comprising a human) requests to create a user account , the service  may generate a captcha  and send it to the first entity  with a request to identify a signal presented in the captcha  (e.g., the human-readable words presented against the noisy background). When the first entity  provides a response  that correctly identifies the signal (e.g., the readable words) of the captcha , the service  may determine that the first entity  is a human, and may assign high privilege level  to the user account  of the first entity . By contrast, when a second entity  (comprising an automated process) requests to create a user account , the service  may send the same captcha  to the second entity , but upon receiving a response  that incorrectly identifies the readable text (e.g., identifying characters that are often incorrectly identified as readable text by conventional optical character recognition (OCR) technologies), the service  may determine that the second entity  is an automated process, and may assign a low privilege level  to the user account  of the second entity  (or may simply refuse to create a user account  for the second entity ). Moreover, the service  may continue to monitor the activities of the entities  and may accordingly adjust the privilege levels  of the user accounts . For example, when a third entity  having a high privilege level  requests to perform a malicious activity , the service  may reduce the privilege level  of the user account  of the third entity , and may therefore reduce the set of privileges  extended to the third entity .","While the exemplary scenario  of  presents some advantages of captcha techniques, some disadvantages and limitations of captcha techniques may limit the effectiveness thereof in securing the service . As a first example, captcha techniques may present many false positives (incorrectly identifying humans as automated processes) and false negatives (incorrectly identifying automated processes as humans). Such inaccuracies may become more prevalent as malicious users become more adept at designing automated processes that correctly answer captchas, such as utilizing increasingly sophisticated optical character recognition (OCR) and speech recognition technologies. As a second example, humans may find captchas to be irritating, particularly as the difficulty of captchas increases to thwart increasingly sophisticated automated processes. As a third example, captchas are ineffective at discouraging malicious activities performed by humans, and \u201cmechanical Turk\u201d solutions (utilizing humans to answer such challenges correctly) to captchas may permit malicious users to circumvent the security measures of such services.","In view of these limitations, the development of alternative techniques for securing the use of services  may be advantageous. It may be appreciated that in such scenarios, malicious users are able to utilize such techniques as the widespread automation of user account registration because the costs of failure are insignificant. That is, the cost to a malicious user of a failed attempt to misuse a service  is trivial, and even if only a small percentage of such attempts succeed, the value of the successful attempts outweighs the cost of the unsuccessful attempts. As one exemplary scenario where this value proposition affects the tactics utilized by malicious users, unsolicited bulk email messages (\u201cspam\u201d) that are broadcast to users typically achieve a very low response rate (such as click-throughs to advertised websites)\u2014often below one response per 10,000,000 messages sent\u2014but the collective value of the responses may considerably exceed the trivial cost of sending all of the messages, resulting in a very profitable misuse of email services. Therefore, tactics that may be effective at reducing misuse of a service involve increasing the cost of a failed attempt to a non-trivial level. For example, opponents of spam email messages occasionally propose a small per-message cost (such as $0.01) of sending email messages, which may not significantly impact the senders of legitimate email messages, but which may render the sending of spam highly unprofitable. However, solutions that directly attribute a cost to the secured activity may undesirably penalize entities that legitimately perform a large number of secured activities (e.g., a per-message fee may significantly impact the sender of a widely popular electronic newsletter).","In view of these characteristics, the techniques presented herein involve associating a privilege level  with an entity  with one or more assets of value. For example, when an entity  requests to generate a user account , a service  may request the entity  to identify one or more assets having an identifiable value, such as purchases of goods or services or ownership of objects or real estate. Such identification may be asserted by the entity  in various ways, e.g., by providing proof of a financial transaction (such as a copy of a receipt) or an identifier of ownership of the asset. The service  may then assign a privilege level  to the entity  according to the assets claimed by the entity . As one such example, the privilege level  assigned to the entity  may be proportional to the total value of the assets claimed by the entity  (e.g., claims of low-value assets may result in a small elevation of the privilege level  of the entity , while claims of high-value assets may result in a large elevation of the privilege level  of the entity ). If the entity  later performs a malicious activity  that diminishes the privilege level  of the entity  (or even results in a revocation of the user account  of the entity ), the service may also invalidate the claimed assets. This invalidation may simply involve a refusal to associate such assets with other entities , or may further have an impact on the claimed asset; e.g., if the asset has been purchased from the service , the asset may be cancelled or diminished. In this manner, an entity that performs a malicious activity  may suffer a significant loss of value with respect to the claimed assets, thereby increasing the costs of malicious activities  (particularly in comparison with contemporary techniques that involve a trivial penalty for such malicious activities ). Moreover, because the presented assets have been purchased by respective entities  in separate transactions (unrelated to the performance of the secured activities), the per-activity cost of performing the secured activities is not directly assessed to the entities , and does not unduly impact entities  that perform a large number of legitimate activities.",{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 2","b":["30","20","16","32","34","30","12","14","16","12","16","22","20","18","16","20","16","32","30","32","16","32","16","32","34","34","34","16","18","12","12","20","16","22","14","16","18","12","20","18","36","32","16","34","12","16","36","16","36","32","20","18","16","20","34","32","16","36","32","12","20","18","16","20","16","22","14","16","36","32","34","12","16","16","16","22","14"]},"In this manner, and in accordance with the techniques presented herein, the exemplary scenario  enables an assignment of privilege levels  of various entities  utilizing a service  according to the value  of respective assets  asserted by the entities . Because each user account  is now associated with valuable assets, the entities  are discouraged from performing malicious activities , because the service  may respond by penalizing the entity  with respect to those valuable assets . The penalty may simply involve restricting user accounts  associated with the assets , and\/or refusing to register additional user accounts  with the assets . However, more stringent penalties may also be enforced; e.g., the service  may be able to invalidate the asset identifiers  of the assets  (e.g., invalidating the license of the software product purchased by the entity ), and\/or may be able to identify the individual who has attempted to perform a malicious activity  based on the asset  (e.g., identifying an individual who has performed an illegal activity through the service  based on a credit card used to purchase the asset  claimed by the entity ). Moreover, an entity  intending to perform a malicious activity  may be deterred by the threat of invalidation of the assets , and attempts to perform malicious activities  may therefore be rendered unprofitable or not worthwhile.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 3","b":["40","20","16","40","40","42","44","46","20","16","16","48","20","16","16","36","32","16","50","36","32","36","52","20","16","40","20","16","32","34","54"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 4","FIG. 3"],"b":["66","60","20","16","32","34","66","62","64","62","64","66","66","68","20","16","66","70","74","16","20","16","74","66","72","16","36","32","16","36","32","36","20","16","34","32","66","20","16","32"]},"Still another embodiment involves a computer-readable medium comprising processor-executable instructions configured to apply the techniques presented herein. Such computer-readable media may include, e.g., computer-readable storage media involving a tangible device, such as a memory semiconductor (e.g., a semiconductor utilizing static random access memory (SRAM), dynamic random access memory (DRAM), and\/or synchronous dynamic random access memory (SDRAM) technologies), a platter of a hard disk drive, a flash memory device, or a magnetic or optical disc (such as a CD-R, DVD-R, or floppy disc), encoding a set of computer-readable instructions that, when executed by a processor of a device, cause the device to implement the techniques presented herein. Such computer-readable media may also include (as a class of technologies that are distinct from computer-readable storage media) various types of communications media, such as a signal that may be propagated through various physical phenomena (e.g., an electromagnetic signal, a sound wave signal, or an optical signal) and in various wired scenarios (e.g., via an Ethernet or fiber optic cable) and\/or wireless scenarios (e.g., a wireless local area network (WLAN) such as WiFi, a personal area network (PAN) such as Bluetooth, or a cellular or radio network), and which encodes a set of computer-readable instructions that, when executed by a processor of a device, cause the device to implement the techniques presented herein.","An exemplary computer-readable medium that may be devised in these ways is illustrated in , wherein the implementation  comprises a computer-readable medium  (e.g., a CD-R, DVD-R, or a platter of a hard disk drive), on which is encoded computer-readable data . This computer-readable data  in turn comprises a set of computer instructions  configured to operate according to the principles set forth herein. In one such embodiment, the processor-executable instructions  may be configured to perform a method of assigning privilege levels to entities, such as the exemplary method  of . In another such embodiment, the processor-executable instructions  may be configured to implement a system for assigning privilege levels to entities, such as the exemplary system  of . Some embodiments of this computer-readable medium may comprise a non-transitory computer-readable storage medium (e.g., a hard disk drive, an optical disc, or a flash memory device) that is configured to store processor-executable instructions configured in this manner. Many such computer-readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.","The techniques discussed herein may be devised with variations in many aspects, and some variations may present additional advantages and\/or reduce disadvantages with respect to other variations of these and other techniques. Moreover, some variations may be implemented in combination, and some combinations may feature additional advantages and\/or reduced disadvantages through synergistic cooperation. The variations may be incorporated in various embodiments (e.g., the exemplary method  of  and the exemplary system  of ) to confer individual and\/or synergistic advantages upon such embodiments.","A first aspect that may vary among embodiments of these techniques relates to the scenarios wherein such techniques may be utilized. As a first example, these techniques may be utilized to establish privilege levels  of many types of entities , such as individuals, groups of individuals, organizations, corporations, devices, and automated processes. As a second example of this first aspect, many types of privilege levels may be established (e.g., discrete levels, ratings, or scores), and such privilege levels  may be based on many types of information (e.g., the history, number, and types of activities  undertaken by the entity , and the reputation of the entity  among other entities ). As a third example of this first aspect, the privilege level  may be used to establish many criteria of a service provided to respective entities , such as the amount of data that may be exchanged between the entity  and the service (e.g., a maximum volume of data that may be stored by a file service on behalf of an entity ), the number and types of requests that may be made by the entity  of the service (e.g., the number and types of email messages that may be sent on behalf of an entity  by an email service in a particular period), and the privileges of the entity  within the service to perform certain types of activities  (e.g., read and\/or write access extended to the entity  to particular portions of a file system stored by a file service). As one such example, the entity  may be provided a service having a service quality associated with a privilege level  (e.g., a resolution or framerate provided for a video streaming service, or an audio quality provided for a voice-over-IP (VOIP) telephony service), and the service may be provided to any particular entity  with a service quality associated with the privilege level  of the entity .","As a fourth example of this first aspect, many types of assets  may be claimed by respective entities , such as goods purchased at a retail or online store, services purchased from a service provider, and goods or services acquired by the entity  from other entities  at an identifiable cost). It may be appreciated that, in some scenarios, the cost of the assets  claimed by such entities  may significantly relate to the advantages of the techniques presented herein. For example, these techniques may be utilized to discourage entities  from performing malicious activities  by associating a detection of such malicious activities  by the service with an impact on the claimed assets , such as the inability to claim such assets  for use with other accounts established by the same or another entity . In particular, if the asset  comprises a license purchased at an identifiable cost for access to a software asset (such as an account purchased for an online service or a permission to play an online game), the response to the detection of the malicious activity  may involve restricting, suspending, and\/or invalidating the license, thereby imposing a non-trivial penalty on the entity  performing the malicious activity . Moreover, the risks of incurring such penalties may significantly deter entities  from attempting such malicious activities . In such scenarios, it may be appreciated that the magnitude of the punitive and\/or deterrent effect is related to the identifiable cost of the asset ; e.g., assets  that are available at a low or free cost may impose little or no punitive and\/or deterrent effect, but assets  that are only available at a significant cost may impose a correspondingly significant effect on entities  who may otherwise attempt or perform malicious activities . Thus, if the asset  is purchased by the entity  at an asset cost, an embodiment of these techniques may be configured to raise the privilege level  of the entity  proportional to the asset cost of the asset . For example, an entity  that wishes to gain a significant increase in privilege level  (and a corresponding increase in the service quality of a service provided to the entity ) may claim one or several assets  of high value as collateral provided in exchange for the high privilege level .","As a fifth variation of this first aspect, the verification of the asset claim to the asset  may arise within many aspects of a service. As a first such variation, the claim of one or more assets  may be established as a condition of providing the service to an entity . Alternatively, the service may initially be provided at a low service quality to an (unprivileged) entity , but the entity  may secure a higher service quality by claiming one or more assets . As a second alternative, the claim of one or more assets  may be provided as one of several mechanisms for securing a higher privilege level . For example, the service may permit an entity  to achieve a higher privilege level  in many ways, including the completion of one or more alternative verification techniques (e.g., one or more captchas ), the claim of one or more assets , or simply by interacting with the service in a non-malicious manner for an extended period of time. The provision of alternative mechanisms for establishing and raising the privilege level  of the entity  may be appealing to entities  utilizing the service. Those of ordinary skill in the art may devise many scenarios wherein the techniques presented herein may be advantageously utilized.","A second aspect that may vary among embodiments of these techniques relates to the manner of verifying an asset  claimed by an entity . As a first example, the entity  may submit evidence of a financial or other type of transaction, such as a receipt. An embodiment of these techniques may verify the evidence (e.g., by contacting another entity  involved in the transaction, such as another party involved in the transaction or a bank through which payment was processed), and, upon verifying the evidence, may increase the privilege level  of the entity . As a second example of this second aspect, the entity  may have an account associated with various assets  (e.g., a credit card through which various transactions have been processed, or a purchase account through which purchases of one or more assets  have been made), and may claim the associated assets  simply by demonstrating ownership of the specified account.","As a third example of this second aspect, an entity may claim an asset  by tendering an identifier of the transaction. In particular, where the asset  comprises a software license of a software asset, the asset identifier  of the asset  may comprise a software license certificate representing the software license of the software asset. The software license certificate may comprise a certificate that has been cryptographically signed by the issuer of software licenses to the software asset, or may comprise a license key that the entity  may provide to an installed copy of the software asset in order to demonstrate proof of licensing. In these and other scenarios, the software license certificate may be verifiable by a software licensing service, and an embodiment may verify the asset identifier  by sending it to the software licensing service, and receiving from the software licensing service a verification of the software license certificate.","In some scenarios where an entity  may frequently submit requests for activities  for which a privilege level  is to be verified, an embodiment of these techniques may repeatedly verify the asset identifiers  of assets  claimed by the entity . However, such repeated verification may be unduly resource-intensive (e.g., imposing a complex verification process involving a significant expenditure of computing resources, and\/or imposing an undesirable delay upon the completion of the activity ). Alternatively or additionally, in some scenarios, a first device or service may be configured to verify claimed assets  while a second device or service may be configured to perform requested activities  (based on a previously verified privilege level  of the entity  requesting the activity ). In still other scenarios, a service configured to verify assets  and\/or perform requested activities  may be configured to operate in a stateless manner. For example, instead of locally storing information identifying the privilege levels  of respective entities , the service may send information to the entity  identifying its privilege level ; and when the entity  later requests to perform an activity , the service may request and receive from the entity  the information identifying its privilege level , and may examine the information in order to determine the privilege level  of the entity  while evaluating whether to perform the requested activity .","In view of these considerations, some embodiments of these techniques may utilize verification tickets, comprising a temporary identifier of a verified asset identifier  that may be stored on a device of the entity . When the entity  claims an asset , the embodiment may verify the asset , and may then generate and send to the entity  a verification ticket that identifies the asset claimed by the entity  and\/or the privilege level  of the entity  associated with the claimed asset . The verification ticket may be generated, e.g., as a cookie stored within a web browser of a device of the entity , and may include a cryptographic signature of the generating service (in order to verify authenticity and an absence of tampering with the contents of the verification ticket by the entity ). The service may subsequently verify an asset identifier of the entity , and\/or identify a privilege level  of the entity  (e.g., while evaluating a request from the entity  to perform a requested activity ), by requesting, receiving, and examining the verification ticket stored by the entity . In this manner, the embodiment may utilize verification tickets to facilitate the verification of the privilege levels  of respective entities .",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 6","b":["90","94","20","16","90","92","20","16","36","32","16","16","32","34","16","32","36","92","36","16","94","20","16","32","94","92","94","92","94","16","94","16","74","96","94","74","96","16","74","94","20","16","94","20","16","92","36","20","96","94","16","74","20","92","96","20","16"]},"In some scenarios, verification tickets  may be generated without restrictions; e.g., a verification ticket  generated by a server may simply comprise an identification of an asset  claimed by an entity , and possibly also the privilege level  assigned to the entity  as a result of the claimed asset . However, in other scenarios, verification tickets  may be generated with one or more verification ticket restrictions that limit the use of the verification ticket  in one or more ways. Such verification ticket restrictions may be selected from a verification ticket restriction set, including a verification ticket duration restriction that limits the period of time when the verification ticket  is valid (e.g., a verification ticket  that is valid for two weeks from the date of generation); a verification ticket device restriction that limits the device(s) of the entity  from which the verification ticket  may be validly submitted (e.g., a verification ticket  that is only valid if submitted to the service from a particular device); a verification ticket entity restriction that limits the entities  who may validly submit the verification ticket ; and a verification ticket use count restriction that limits the number of valid uses of the verification ticket  (e.g., a verification ticket  that is only valid to indicate the privilege level  of the entity  for one hundred uses). If the verification ticket restriction is violated (e.g., if the verification ticket duration restriction of the verification ticket  expires, or if the verification ticket  is transferred to a device that is not valid according to a verification ticket device restriction of the verification ticket ), the device storing the verification ticket  and\/or a service that subsequently receives the verification ticket  may invalidate the verification ticket  (e.g., by either disposing of the verification ticket , and\/or by recording an identifier of the verification ticket  in a list of invalid verification tickets  that are not to be accepted). Alternatively or additionally, if a service receives a verification ticket  that violates one or more verification ticket restrictions, the service may reexamine the claim of the entity  to the asset(s)  for which the verification ticket  was originally generated (e.g., re-requesting the software licensing certificate from the entity , or examining a database of asset claims to determine whether the claim of the entity  to the asset  is still valid), and, if such claims are still valid, may generate and send to the entity  an updated verification ticket  having renewed verification ticket restrictions. Such reexamination and reissue of tickets may be advantageous, e.g., for allowing verification tickets  granting higher privilege levels  to be revoked, such as in the case of an abused asset identifier .","An exemplary scenario utilizing such techniques involves a restriction of verification tickets  to one or more devices, such as the devices operated by a particular entity . This verification ticket restriction may be achieved, e.g., by specifying within the verification ticket  a device identifier of a device that may validly submit the verification ticket  with a request to perform an activity . When an entity  submits a request from a particular device to a service to perform an activity , the device may be configured to send its device identifier, which the service may compare with the device identifiers indicated by the verification ticket , and may perform the activity  only if the device identifier of the device is specified by the verification ticket . This restriction may reduce the abuse of verification tickets  transferred from an authorized device to an unauthorized device. Additionally, one or more devices may be configured to store a non-verification ticket, which may represent a withholding of verification of any asset identifiers  of any assets  that may be received from the device; and a service may be configured to, upon receiving a non-verification ticket from a device, refuse to verify any asset identifiers  of any assets  received from the device. This technique may be advantageous, e.g., for devices that are used by many users (such as devices that are frequently lent to members of the public, or public terminals available in libraries and community centers) that are not to be utilized to request activities involving a privilege level from any service. Such devices may be effectively blacklisted by the services, and may not participate in activities involving a privilege level . Those of ordinary skill in the art may devise many ways of verifying claims of assets  submitted by entities  in accordance with the techniques presented herein.","A third aspect that may vary among embodiments of these techniques relates to actions that a service may perform upon detecting a malicious activity  of an entity . Such actions may relate to the entity  or the devices operated thereby; to the privilege level  assigned to the entity , to the asset identifiers  and\/or verification tickets  of assets  claimed by the entity ; and\/or to the actual assets  claims by the entity .","As a first example of this third aspect, an embodiment of these techniques may be configured to, upon detecting an abuse of an asset , invalidate an asset identifier  of the asset . For example, if a software product is used by an entity  in a malicious manner, or if the software product is traded by an entity  in a manner that is inconsistent with a software license to the software product (e.g., a copyright violation), a license key assigned for the software product to the entity  may be invalidated. Such invalidation may result in a negation of the claim to the asset  by the entity , and a negation of the increase in the privilege level  of the entity  previously secured by the claim to the asset . Alternatively or additionally, such invalidation may also result in an inability of the entity  to utilize the asset  (e.g., an invalidation of the software license to the entity , resulting in an inability to run the software product on any devices operated by the entity ). As one such example, an asset  may only be validly claimed by a small number of entities  (e.g., one), and attempts by several entities  to claim the asset  may result in an invalidation of the asset identifier  of the asset . This mechanism may be implemented, e.g., as an asset verification count limit that may be associated with the asset identifier  (such as a maximum number of entities  who may claim the asset ) and an asset verification count that is incremented upon receiving each claim to the asset . An incrementing of the asset verification count above the asset verification count limit may be construed as an abuse of the asset  (e.g., a possible indicator of a license violation), and may result in an invalidation of the asset identifier  (e.g., the license key issued with the software license).","As a further example of this first example of this third aspect, respective verifications of an asset identifier  may be associated with a particular device operated by an entity  (e.g., verification tickets may include a verification ticket device restriction that indicates the device identifiers of devices that have claimed the asset identifier ). For example, an entity  may be permitted to claim an asset  on a particular number of devices operated by the entity . If the asset verification count is incremented above the asset verification account limit, the service may present to the entity  a list of devices associated with the asset identifier  (e.g., the devices from which the asset identifier  has been claimed), and the entity  may be permitted to select a device to be dissociated from the asset identifier . If the entity  selects a device to be dissociated, the service may receive the selected device, dissociate the selected device from the asset identifier , decrement the asset verification count of the asset identifier , and reverse the raising of the privilege level of the entity that had been awarded in response to the entity's claim of the asset identifier . If the selected device subsequently submits the same asset identifier , the service may refuse to verify the asset identifier  on behalf of the selected device. In this manner, entities  may be permitted to dissociate devices from which an asset  has previously been claimed, thereby preserving the claims to the asset  by the other devices.","As a second example of this third aspect, an embodiment of these techniques may apply an action responsive to a detected abuse of an asset  to each of several entities  that are associated with the asset identifier . For example, if four entities  attempt to claim an asset  that may be validly claimed only by one entity  (e.g., a possible copyright violation of a software license that is extended only to one entity  and\/or device), it may be presumed that all of the entities  attempting to claim the asset  are potentially involved in the abuse, and the effects thereof may be imputed to all four entities , e.g., by reducing the privilege level  of each entity . Conversely, if a privilege level  of an entity  is adjusted to a lower privilege level based on an activity  performed by the entity  (e.g., an attempt to perform a malicious activity ), an embodiment of these techniques may identify all of the asset identifiers  of all assets  that have been claimed by the entity , and may invalidate all of the asset identifiers  associated with the entity . Those of ordinary skill in the art may devise many such actions that may be taken in response to a detected abuse of an asset  while implementing the techniques presented herein.","Although the subject matter has been described in language specific to structural features and\/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as example forms of implementing the claims.","As used in this application, the terms \u201ccomponent,\u201d \u201cmodule,\u201d \u201csystem\u201d, \u201cinterface\u201d, and the like are generally intended to refer to a computer-related entity, either hardware, a combination of hardware and software, software, or software in execution. For example, a component may be, but is not limited to being, a process running on a processor, a processor, an object, an executable, a thread of execution, a program, and\/or a computer. By way of illustration, both an application running on a controller and the controller can be a component. One or more components may reside within a process and\/or thread of execution and a component may be localized on one computer and\/or distributed between two or more computers.","Furthermore, the claimed subject matter may be implemented as a method, apparatus, or article of manufacture using standard programming and\/or engineering techniques to produce software, firmware, hardware, or any combination thereof to control a computer to implement the disclosed subject matter. The term \u201carticle of manufacture\u201d as used herein is intended to encompass a computer program accessible from any computer-readable device, carrier, or media. Of course, those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 7","FIG. 7"]},"Although not required, embodiments are described in the general context of \u201ccomputer readable instructions\u201d being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media (discussed below). Computer readable instructions may be implemented as program modules, such as functions, objects, Application Programming Interfaces (APIs), data structures, and the like, that perform particular tasks or implement particular abstract data types. Typically, the functionality of the computer readable instructions may be combined or distributed as desired in various environments.",{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIG. 7","FIG. 7"],"b":["100","102","102","106","108","108","104"]},"In other embodiments, device  may include additional features and\/or functionality. For example, device  may also include additional storage (e.g., removable and\/or non-removable) including, but not limited to, magnetic storage, optical storage, and the like. Such additional storage is illustrated in  by storage . In one embodiment, computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage  may also store other computer readable instructions to implement an operating system, an application program, and the like. Computer readable instructions may be loaded in memory  for execution by processing unit , for example.","The term \u201ccomputer readable media\u201d as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory  and storage  are examples of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, Digital Versatile Disks (DVDs) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .","Device  may also include communication connection(s)  that allows device  to communicate with other devices. Communication connection(s)  may include, but is not limited to, a modem, a Network Interface Card (NIC), an integrated network interface, a radio frequency transmitter\/receiver, an infrared port, a USB connection, or other interfaces for connecting computing device  to other computing devices. Communication connection(s)  may include a wired connection or a wireless connection. Communication connection(s)  may transmit and\/or receive communication media.","The term \u201ccomputer readable media\u201d may include communication media. Communication media typically embodies computer readable instructions or other data in a \u201cmodulated data signal\u201d such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.","Device  may include input device(s)  such as keyboard, mouse, pen, voice input device, touch input device, infrared cameras, video input devices, and\/or any other input device. Output device(s)  such as one or more displays, speakers, printers, and\/or any other output device may also be included in device . Input device(s)  and output device(s)  may be connected to device  via a wired connection, wireless connection, or any combination thereof. In one embodiment, an input device or an output device from another computing device may be used as input device(s)  or output device(s)  for computing device .","Components of computing device  may be connected by various interconnects, such as a bus. Such interconnects may include a Peripheral Component Interconnect (PCI), such as PCI Express, a Universal Serial Bus (USB), firewire (IEEE 1394), an optical bus structure, and the like. In another embodiment, components of computing device  may be interconnected by a network. For example, memory  may be comprised of multiple physical memory units located in different physical locations interconnected by a network.","Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example, a computing device  accessible via network  may store computer readable instructions to implement one or more embodiments provided herein. Computing device  may access computing device  and download a part or all of the computer readable instructions for execution. Alternatively, computing device  may download pieces of the computer readable instructions, as needed, or some instructions may be executed at computing device  and some at computing device .","Various operations of embodiments are provided herein. In one embodiment, one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media, which if executed by a computing device, will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further, it will be understood that not all operations are necessarily present in each embodiment provided herein.","Moreover, the word \u201cexemplary\u201d is used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as \u201cexemplary\u201d is not necessarily to be construed as advantageous over other aspects or designs. Rather, use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application, the term \u201cor\u201d is intended to mean an inclusive \u201cor\u201d rather than an exclusive \u201cor\u201d. That is, unless specified otherwise, or clear from context, \u201cX employs A or B\u201d is intended to mean any of the natural inclusive permutations. That is, if X employs A; X employs B; or X employs both A and B, then \u201cX employs A or B\u201d is satisfied under any of the foregoing instances. In addition, the articles \u201ca\u201d and \u201can\u201d as used in this application and the appended claims may generally be construed to mean \u201cone or more\u201d unless specified otherwise or clear from context to be directed to a singular form.","Also, although the disclosure has been shown and described with respect to one or more implementations, equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components (e.g., elements, resources, etc.), the terms used to describe such components are intended to correspond, unless otherwise indicated, to any component which performs the specified function of the described component (e.g., that is functionally equivalent), even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition, while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations, such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore, to the extent that the terms \u201cincludes\u201d, \u201chaving\u201d, \u201chas\u201d, \u201cwith\u201d, or variants thereof are used in either the detailed description or the claims, such terms are intended to be inclusive in a manner similar to the term \u201ccomprising.\u201d"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
