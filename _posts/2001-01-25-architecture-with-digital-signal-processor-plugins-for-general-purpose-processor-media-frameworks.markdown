---
title: Architecture with digital signal processor plug-ins for general purpose processor media frameworks
abstract: A plug-and-play architecture including an extension of a general purpose processor media framework for adjoining DSP processing power.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07080386&OS=07080386&RS=07080386
owner: Texas Instruments Incorporated
number: 07080386
owner_city: Dallas
owner_country: US
publication_date: 20010125
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["This application claims priority from provisional application Ser. No. 60\/177,941, filed Jan. 25, 2000.","The invention relates to media applications, and more particularly to systems and methods extending time-based media applications on a general purpose processor to a combination of a general purpose processor plus a digital signal processor.","Java Media Framework (JMF) is an application programming interface (API) for incorporating time-based media into Java applications and applets. Time-based media include audio clips, music synthesizer files, movie clips, and so forth. The JMF 2.0 API enables programmers to develop Java programs that present time-based media plus support for capturing and storing media data, controlling processing of media data streams, and defines a plug-in API that enables advanced developers to more easily customize and extend JMF functionality.","However, time-based media frequently require significant processing power (such as encoding\/decoding MPEG video) and must adhere to real-time deadlines. And attempts to incorporate adjunct processors, such as digital signal processors (DSP) to provide supplemental processing power have led to complex and difficult to program systems.","The present invention provides an architecture with DSP plug-ins for general purpose processor media frameworks to take advantage of one or more DSPs communicating with the general purpose processor to provide adjunct processing power.","Overview","The preferred embodiment systems include a hardware system composed of a general purpose processor (GPP), a digital signal processor (DSP), and connecting hardware such as shared memory or bus plus a software system extending a media framework of the GPP to provide DSP processor support for applications.  illustrates a preferred embodiment extending Java Media Framework 2.0 including GPP (such as a MIPS core)  with GPP operating system (such as Windows CE or VxWorks)  and media framework JMF 2.0  and Java media applications  together with DSP (such as a C6000 core) , DSP real-time operating system , DSP framework , bridge  for communication between the GPP and DSP portions, DSP plug-ins  for JMF  and corresponding DSP algorithms  plus DSP plug-in interface  extending JMF , and drivers  in operating system  for communication.","The DSP portion extends the GPP portion (GPP , OS , JMF , and application ) and permits application  to easily incorporate objects which involve DSP media processing such as MPEG decoding. Indeed, the DSP portion extension constitutes an instance of a plug-and-play architecture that is \u201csoftware pin compatible\u201d with a media framework.  shows the instantiation of the architecture for solving the problem of obtaining decreased-cost, guaranteed-quality-of-service high-performance implementation of media frameworks for JMF 2.0 by plugging in DSP media components. Analogous instantiations adapt to media frameworks such as DirectShow and Be Media Kit.","Plug-in interface  provide a compliant extension to JMF and a media service and application programming interface (API) to plugging in DSP media components .","DSP framework  for DSP codecs (DSP algorithms)  allows DSP codec developers to plug-in optimized encoders, decoders, multiplexers, demultiplexers, and so forth for DSP processing. DSP framework  provides a consistent environment between a host GPP and codecs running on one or more DSPs connected to the host GPP. This environment provides for codecs to access input data, generate output data, and receive event synchronization that schedules runtime of the codec on the DSP.  illustrates exemplary data flow using three DSP codecs (a,b,c) with corresponding plug-ins (A,B,C) for the GPP media framework. The framework requires that the codecs  are written to a specific DSP interface standard (e.g., XDAIS) which matches the DSP framework interface .","DSP framework  also provides a quality-of-service (QOS) manager that will determine which codecs in the DSP will run based on a dynamically changeable user defined priority list and within in a user defined time period. The QOS manager informs the user on a per input data frame basis if DSP processing bandwidth has been exceeded for that time period.","Multiplexing channel drivers in the operating systems on both DSP and GPP sides of bridge  transfer data between the two processors.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIGS. 10","FIG. 10","FIG. 10"],"i":["a","b ","a ","b "],"b":"10"},"The following sections have more details of the operation of the various elements of the architecture.","DSP System Framework","DSP System Framework  provides an environment in which several DSP algorithms  can operate as an integrated system. A DSP Algorithm Interconnection Standard (DAIS)-compliant DSP algorithm requires data input and output and a synchronization signal to tell it when there is sufficient data ready for processing. Ideally the algorithm is set to run when there has been one complete frame of data received which when processed will provide one complete frame of output; see  illustrating the functionality.","DSP System Framework  requires an information database on each Task (Algorithm) and a mechanism to do Task scheduling. The DSP system Resource Manager Server (DRMS) fulfills this function; see . The first responsibility of the DRMS is to manage an information database maintained for use by the framework. Each task is required to perform a registry process on initialization. The second responsibility of the DRMS is task scheduling, this is done implicitly because each task schedules its own execution separately by synchronizing on data input to the task.","Each Algorithm has to be integrated into the DSP system framework before it can be used. An Algorithm has to be DAIS-compliant, which means that the input and output buffer sizes and locations are defined prior to invocation. An algorithm can have parameters required at runtime and a pointer to the runtime parameters is passed on each invocation of the algorithm. These parameters will be made into a command passing structure described later on.","When a task initializes it must register itself in the DRM database (registry) before any data processing can begin. The information that DRM maintains on each task is used by the Framework to perform housekeeping functions and allow a globally controlled place to hold task information so that the framework and other tasks have access to it.","Each Task manages itself by scheduling execution only after a full data frame has been received of data to be processed. The DSP System is a \u201cpushed\u201d data type system, which means data is sent to the DSP system without being directly requested. So the DSP system must be capable of processing data faster than the incoming data rate because the DSP System Framework does not allow for queuing of data to tasks. The Algorithms running in the DSP are DAIS-compliant and are not concerned with how the data is gathered, only that input data is presented to the Algorithm all at once as a complete frame of data. The task shall not be involved in the gathering of input data that is handled by the DSP system framework and the DRMS.","Requirements for DSP System Resource Manager Server:",{"@attributes":{"id":"p-0028","num":"0000"},"ul":{"@attributes":{"id":"ul0001","list-style":"none"},"li":{"@attributes":{"id":"ul0001-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0002","list-style":"none"},"li":["1. Must get algorithm to process entire frame and not be switched once or twice before processing a frame (high overhead of switching in data overlay of algorithm).","2. Schedule tasks only after complete input data frame is ready","3. Maintain task database for use by framework:\n        \n        "]}}}},"Each Algorithm in the DSP System is required to be DAIS-compliant. This requires that the Algorithms be presented their data in Frame buffers. The data for the Frame buffers must either come from local peripheral devices located in the DSP system or from a virtual device represented by a buffer located locally within the physical boundaries of the DSP system. Typically the DSP system will be a sub-system that is interfaced to a General Purpose Processor (GPP) which is given the role of supervisor or Host processor. The DSP and Host systems are interfaced together using perhaps shared memory or a bus type interface. This abstraction is referred to as the DSP Bridge\/Link. On this link will be a driver to manage the movement of data across the link. When the DSP system is implemented as part of a larger system, data will predominantly enter and leave the DSP system through the Host\/DSP Bridge.","The connection between the Host and DSP task is statically defined at build time of the DSP and Host systems. Alternative preferred embodiments of the DSP framework allow for a dynamic task create and destroy. Each task on the DSP will have two simplex channels using a stream I\/O of the DSP OS with the Host thread\/task that it is serving. These two channels are for receiving commands from the host for each frame of data received and to return status signals after each frame of data has been processed. Data will be passed between the Host and DSP in complete buffers representing one complete frame of data (input and output frame). Since there is only one buffer in each direction a DMA utility of the bridge driver will use to transport the data frame in both directions. See .","For preferred embodiment DSP systems which are defined as static in the number of tasks, there is no need to create and destroy tasks, therefore there does not need to be an active portion of DRMS to initiate tasks. Therefore there is no need to have a dynamic centralized provider for server functions. Alternative preferred embodiments require the ability to create and destroy tasks and therefore will need an active DRMS to handle these requests.","Summary of events between a Host system and the DSP system:","1. Algorithm initializes and registers itself with the DRMS.","2. Algorithm sends a status message on a predefined channel to the Host that indicates the DSP system is ready to process data. Contained in the message from the DSP system is a pointer in DSP memory of where to put the input data frame.","3. Algorithm blocks (waits) for a command from host specifying what to do.","4. Data is being transferred in the background from host to specified data buffer on the DSP system while the task is blocked.","5. Host sends a message to blocked task on DSP system to decode a frame of size \u201cy\u201d.","6. Task unblocks and sends a message to host to send next frame to a different input buffer. Task then processes data in current received buffer.","7. Host now starts to transfer block of data to next Task input buffer in the background of DSP processing.","8. After completing the processing of input data frame the Task now sends a message to the Host that processing of input frame has finished and is of size \u201cz\u201d and where the output frame is in the DSP system as well.","9. Host receives message from DSP that processing is complete, initiates receiving of data from processed buffer in the background of DSP processing.","10. Repeat steps 3\u20139 for each subsequent frame; see .","The first steps have already been described in that when the task initializes it must register itself with DRMS. This initialization defines the task first, then the amount of memory needed by the task for on-chip workspace memory (algorithm data overlay\/stack) inside the DSP.","When the system is operational the Host will be sending commands (encode, decode, etc.) to the task on the DSP system. These commands will give parameters to the DSP task, commands etc. on what to do with the received data frame. Typically this will be the same command over and over with perhaps the parameters sent along with command varying from frame to frame such as received frame size. The command serves another purpose as well and that is as a synchronization mechanism. The DSP in turn will need to communicate results or statuses after each completed output data frame. The Algorithm implementers and the system integrators during the algorithm integration process define all message structures and values that will be passed when the system is operational. This message passing is required because task synchronization or task scheduling depends on it, but the design is left completely open to implementers and integrators to decide what values are to be passed.","After the Task has completed the registration process, the DSP system sends a message to the Host processor on a pre-defined channel set up statically at build time to signal that the task is ready for data. In this message will be a pointer for the Host system to put the input data frame. The integration process defines what this buffer size should be.","The DSP Task blocks on waiting for a message from Host thread\/task that it is connected with. When the DSP Bridge delivers the message to the DSP System the Task is unblocked and readied to run. When the DSP task gains control from the DSP OS it examines the command received from the host and starts processing the data in the receive buffer frame based on this command. Note the implementers of the DSP task and the accompanying Host task\/thread define the commands that work between the Host Application and the DSP task.","The data frame is transferred to the DSP from the Host using the DMA utility of the host based link driver. This transfer will take place in the background of the DSP system. After the DSP system specifies the buffer the host will place and remove all data in the input and output frames. See .","Once the host has completed placing the input data frame into the buffer in the DSP system, the host will send a message across the DSP Bridge to the DSP system. This command indicates the input data frame is now ready for processing, included in the message is the size of the data frame sent.",{"@attributes":{"id":"p-0048","num":"0051"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"command"]},{"entry":[{},"size of frame"]},{"entry":[{},"address of buffer frame"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"When the DSP task receives the message it will be unblocked or readied to run by the OS. The DSP task will start to process the frame, the task will run until the frame is completely processed (correctly or with error) and the output frame is ready for transfer back to the host. Once all the output data is in the output frame the DSP task sends a message to the host that indicates completion of the frame processing. Contained within that message is buffer pointer in the DSP system that is ready to receive the next frame of input data for the DSP task.","Note that the DSP system relies on the Host processor not to overrun the DSP system with unbalanced requests. The data should be sent to the DSP in matched sets or at least symmetrical sets.","The host receives the completion message with the next input buffer address for the DSP task will now start to do two back ground moves of data. First is to recover the processed frame of data and the next is to send the next frame of input data to the buffer indicated by the DSP task. This is the end of the processing loop that processes the data, the host and DSP task will now repeat these steps until there is no more data to process.","GPP Media Framework System","The GPP media framework (JMF 2.0) extension by the DSPPlugin interface is analogous to the JMF Plug-In API in that it allows plug-ins to be accessed by application programs.","Class DSPPlugIn",{"@attributes":{"id":"p-0053","num":"0056"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"java.lang.Object"]},{"entry":[{},{"sup":"\u2009\u2003"}]},{"entry":[{},{"sup":"\u2003"}]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"ul":{"@attributes":{"id":"ul0004","list-style":"none"},"li":["All Implemented Interfaces:\n    \n    ","public abstract class DSPPlugIn","extends java.lang.Object","implements javax.media.PlugIn"]}},"Implementors of DSPPlugIns will extend this class. DSPPlugIns use the resources of the DSPSystem to process media frames.","Implementors of a particular DSPPlugIn (e.g. com.ti.media.codec.video.mpeg) will typically provide a no-argument constructor that calls the superclass base constructor with the appropriate input\/output Format arguments. A base implementation of a PlugIn is provided that has input_format.length input tracks and output_format.length output tracks. For example, a Codec that extends this class can define its process method:\n\n","A Format might have data type DSPSystem.internalArray which means that the input or output's data remains internal to the DSPSystem. It can only be connected to an input or output of another DSPPlugIn.",{"@attributes":{"id":"p-0057","num":"0070"},"figref":"FIG. 7"},"Fields inherited from interface javax.media.PlugIn:\n\n","This is the base DSPPlugIn constructor, and provides the connection with the resources of the DSPSystem. A base implemention of a Plugin connected to the DSPSystem is provided that matches in input and output Formats. For example, an H.263 codec can be defined extension of DSPPlugIn that is",{"@attributes":{"id":"p-0060","num":"0079"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"package com.ti.media.codec.video.h263;"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"public class DSPDecoder {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"static final VideoFormat[] inputs ="]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"{ new VideoFormat(VideoFormat.H263, ...) };"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"static final VideoFormat[] outputs ="]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"{ new VideoFormat(VideoFormat.YUV, ...) };"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"public DSPDecoder() {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"super(inputs, output);"]},{"entry":[{},"..."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{},"ul":{"@attributes":{"id":"ul0011","list-style":"none"},"li":["getNumberInputTracks","protected int getNumberInputTracks( )"]}},"Return the number of input tracks going into this DSPPlugIn.\n\n","Return the number of output tracks going into this DSPPlugIn.\n\n","Input a buffer from an input track for processing.\n\n","Output a buffer to an output track. This will block until a buffer is ready. It could be the case that the buffer's data remains DSPSystem.internalArray, if that is the data type of the format for this track.\n\n","Send a message packaged as a byte array. The implemetation of controls of an extension of DSPPlugIn can call this based on a system dependent protocol.\n\n","Returns the maximum processing time needed for processing inputs to outputs.\n\n","Returns the average processing time needed for processing inputs to outputs.\n\n",{"@attributes":{"id":"p-0068","num":"0107"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"java.lang.Object"]},{"entry":[{},"\u2002|"]},{"entry":[{},"\u2002+--com.ti.media.dsp.DSPSystem"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"ul":{"@attributes":{"id":"ul0022","list-style":"none"},"li":["public final class DSPSystem","extends java.lang.Object","The DSPSystem provides for loading DSP programs which provide DSPPlugins.\n\nField Details\n","internalArray","static java.lang.Class internalArray"]}},"A Buffer with have this datatype for its data if the frame is internel to the DSPSystem.","getData( )will return null.","Method Details",{"@attributes":{"id":"p-0071","num":"0000"},"ul":{"@attributes":{"id":"ul0023","list-style":"none"},"li":["load","static void load(java.lang.String[ ] filename)","Methods inherited from class java.lang.Object","clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait\n\nDSP Plug-in Interface\n"]}},"The DSP Plug-in Interface (DPI)  provides an application programmer interface to DSP media processing units for high performance media processing. The DPI API specification is described below as both a \u201cnative\u201d C API and a Java API \u201cwrapper\u201d for the developer of JMF PlugIns. A DSPPlugIn provides the base class. DPI can also be used to provide DSP media components for other frameworks, such as Microsoft Corporation's DirectShow.",{"@attributes":{"id":"p-0073","num":"0120"},"figref":"FIG. 8"},"DPI Datatypes","A set of primitive datatypes:\n\n","These types are defined in dpi.h.","A set of constructed datatypes:\n\n","The encoding string holds an identifier for the encoding format. The dataType defines the type of array of data in the data buffers on the media track with this format. The attributes data object holds the parameters needed for this media format; the datatypes of the parameters may need to be cast to the appropriate type. For example, an audio format may have the following attributes\n\n","A DPI_Buffer is a container for a chunk of media data as it movers form one processing stage to the next. The datatype of the buffer is provided by format\u2192dataType. If the datatype of a buffer is one of the DPI_DATATYPE_DSP types, then this means the actual data is held in DSP internal memory and is not available for processing unless provided by another plug-in down the chain that returns a non-DSP datatype. In the case of a DPI_DATATYPE_DSP type, this means that the chunk member of the buffer's data is NULL.  shows a dataflow where the data chunks remain in DSP memory.\n\n","A generalized plug-in datatype provides for an arbitrary number input and out tracks (media dataflows). Specific plug-ins, such as JMF Demultiplexer, Codec, Effect, Renderer, Multiplexer will have a fixed number of input\/output tracks. For example, a Codec has a single input and a single output track. In this version of DPI, a DSP plug-in only supports a single format on each input and output track.","DPI Constants","A set of constants defining the buffer datatypes and processing results.\n\n","A set of constants for flags on DPI_Buffers.\n\n","Produces a buffer for an output track. Return code is one of the DPI_BUFFER_constants.\n\n","A control interface to a plug-in, where a data block input is sent to the plug-in, and the result is copied to output. This can be used to implement a gain control on an audio plug-in, for example.\n\n","A Java API to DPI is provided in the com.ti.media.dpi package, which consists of the following classes:\n\n","DSPFormat extends javax.media.Format by adding additional datatypes for buffers whose data chunk is stored on the DSP, as well as a generic attributes property which represents the attributes as a byte array. The interpretation of the attributes is based on the encoding. A JMF format can be mapped to a DSPFormat by copying its attributes into a byte array:\n\n","DSPPlugin is an abstract class that provides the native implementation for a JMF PlugIn. This abstract class can be extended to make a concrete Plugin. A constructor is provided which creates a plug-in based on a vector of input formats and a vector of output formats, one for each media track. The lengths of the two vectors specifies the number of input and output media tracks that this plug-in is connected to. The instance methods open( ), close( ), and reset( ) are PlugIn methods. The connect( ) method connects the output track outTrackID to the input track inTrackID of next_plugin. The result of this is that the DSP memory data will remain on the DSP. The process( ) and read( ) methods are used to process a buffer from an input track and read a buffer from an output track respectively. In particular, read( ) will block until data is ready. If setTransferHandler( ) is called with a DSPTransferHandler transferhandler, then when data is ready to be read on output track trackID, transferHandler.transfer(this, trackID) is called. Finally, control( ) is used to pass an arbitray control message input to the plug-in, and the response is copied to output.","com.ti.media.dpi.DSPTransferHandler",{"@attributes":{"id":"p-0087","num":"0000"},"ul":{"@attributes":{"id":"ul0034","list-style":"none"},"li":["public interface DSPTransferHandler {","public void transfer(DSPPlugIn plugin, int trackID);","}"]}},"When a buffer is ready to be read on an output track trackID of a DSPPlugIn, the transfer( ) method is called on the DSPTransferHandler instance that is attached to it."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The drawings are heuristic for clarity.",{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIGS. 2\u20134"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIGS. 5\u20136"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIGS. 10","i":["a","b "],"b":"10"}]},"DETDESC":[{},{}]}
