---
title: Method and system for efficiently transferring a self-defined non-contiguous message in a one-sided communication model
abstract: A method and system for transferring noncontiguous messages group including assembling a set of data into a series of transmission packets, packaging a description of the layout of the transmission packets into description packets and then places each description packet into a local buffer while maintaining a count of the number of description packets, transfers each description packet into a transmit buffer for transmission to at least one receiving node, identifies the data packets, and forwards each data packet to the transmit buffer for transmission to the at least one receiving node. The receiving node receives the transmission packets, identifies each packet as a description packet or data packet, places the description packets in a local buffer for storage until the description is complete, places each description packet into a user data buffer, stores data packets in a local queue until the description is complete, then transfers the data packets to the user buffer.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07454491&OS=07454491&RS=07454491
owner: International Business Machines Corporation
number: 07454491
owner_city: Armonk
owner_country: US
publication_date: 20041014
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED ART","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This application is related to the commonly owned, co-pending, prior U.S. patent application Ser. No. 09\/517,167, entitled \u201cData Gather\/Scatter Machine,\u201d filed on Mar. 2, 2000, and the commonly owned U.S. Pat. No. 6,389,478, entitled \u201cEfficient Non-Contiguous Vector and Strided Data Transfer in One Sided Communication or Multiprocessor Computers,\u201d both of which the entire contents are herein incorporated by reference in their entirety.","The invention relates to multiprocessor computers and, more particularly, to efficiently transferring self-defined, non-contiguous messages in a one-sided communication model.","Message Passing Interface (\u201cMPI\u201d) defines a standard application programming interface (\u201cAPI\u201d) for using several processes at one time to solve a single large problem, or a \u201cjob,\u201d on a multiprocessor and often multi-node computer (i.e., commonly one process per CPU across 1 or more multi CPU nodes). Each job can include multiple processes. A process can also commonly be referred to as a task. Each process or task can compute independently except when it needs to exchange data with another task. The program passes the data from one task to another as a \u201cmessage.\u201d Examples of multiprocessor computers are, e.g., an IBM eServer Cluster 1600 available from IBM Corporation, Armonk, N.Y., and supercomputers available from Cray, Silicon Graphics, Hewlett Packard and the like.","The most commonly used portions of the MPI standard use a two sided protocol. A message transfer occurs in a two sided protocol when a task one initiates a send request and another task initiates a receive request. No data transfer occurs until both the sending and receiving tasks have made a call into the API. Often it is convenient to implement a two sided protocol with a one sided protocol. For example, IBM offers a library implementing the MPI API which in turn is implemented using the one sided LAPI (Low level API) programming model. In the one sided programming model, the sender may initiate data transfer even if the receiving task has not made a call requesting data transfer.","Data transfer in parallel programming applications can involve contiguous or non-contiguous data structures.  illustrates the simplest form of data transfer: the transfer of a message from a contiguous data structure  in an originating task  to another contiguous data structure  in a target task .  depicts the more complex scenario of transferring a message contained in a non-contiguous data structure  in the originating task  to another non-contiguous data structure  in the target task . It is also sometimes necessary to transfer from a contiguous data structure to a non-contiguous structure and vice-versa.","Transferring a message from a source  to a destination  based on a non-contiguous data structure presents significant challenges in cases where the network adapter is incapable of directly handling non-contiguous data structures. It is more difficult to transfer such a message in a one-sided model because the target data structure is provided in the original side. A one-sided communication is a communication where the receiver is not expecting or waiting to receive the data communications. U.S. Pat. No. 6,389,478, \u201cEfficient Non-contiguous Vector and Strided Data Transfer in One-sided Communication on Multiprocessor Computers,\u201d describes a mechanism to transfer vector type non-contiguous data in one-sided communication model, which is hereby incorporated by reference in its entirety. In that invention, as shown in , data is transferred in such a way that each packet  contains description(s)  of the data structure and data block(s) .","This prior art mechanism requires a whole description of the user data structure and the data contained within the structure in a non-contiguous message to be transferred from the send side to the target side. However, there are cases when a block by block description of the data is longer than data itself. For example, a four byte data block needs two values in its description (e.g. its address and its length). Thus, the total number of bytes transferred (including data and the description of the data structure) in this method could be significantly larger than the data bytes transferred.","Another commonly owned prior art invention, U.S. patent application Ser. No. 09\/517,167, entitled \u201cData Gather\/Scatter Machine,\u201d describes a method of constructing a compact data description and packing\/unpacking data from\/to non-contiguous data structure to\/from contiguous data structure based on the description, which is hereby incorporated by reference in its entirety. A Data Gather\/Scatter Program (\u201cDGSP\u201d) is a message level description that potentially eliminates unnecessary individual data block descriptions. However the original DGSP and Data Gather\/Scatter Machine (\u201cDGSM\u201d) concept does not handle any communication protocol problems. Using a DGSP description of non-contiguous data can improve the efficiency of non-contiguous message transfer by reducing overhead of transmitting the target data description. However, there are still problems in transferring data in this manner, such as:\n\n","Therefore, a need exists to overcome the problems with the prior art as described above.","Briefly, in accordance with preferred embodiments of the present invention, disclosed is a system, method, and computer program product transferring noncontiguous messages across a distributed computing environment containing a plurality of processing nodes coupled together over a network. The method, on a sending node, groups a set of data to be transferred into a series of transmission packets, packages a description of the layout of the set of data into a group of one or more description packets, and places each of the description packets into a transmit buffer while maintaining a count of the total number of description packets placed in the buffer. Each description packets in the transmit buffer is transmitted to at least one receiving node, identifies each of the transmission packets representing data packets, and forwards each of the data packets to the transmit buffer for transmission to the at least one receiving node.","An embodiment of the present invention, while packaging the description of the layout of the set of data into description packets is accomplished by packaging a destination data gather scattering program (DGSP).","An embodiment of the present invention, while packaging the description of the layout of the set of data into description packets further includes packaging a source data gather scattering program (DGSP) as well.","An embodiment of the present invention, while grouping a set of data to be transferred into a series of transmission packets includes grouping the set of data compatible with LAPI. Further the transmission packets include both LAPI active message and a LAPI passive message.","An embodiment of the present invention, while grouping a set of data to be transferred into a series of transmission packets includes transmitting the number of the data packets transmitted.","From the point of view of the receiving node, the method includes receiving a series of transmission packets representing a set of data which is transferred from at least one sending node and identifying each of the transmission packets as either a description packet or a data packet. The method assembles each description packet which represents a layout of the set of data to be received while counting the total number of description packages received. The method also places each data packet in the user data buffer only if all the description packets corresponding to the data packets have been previously assembled. An embodiment of the present invention includes assembling each description packet which represents a layout of the set of data to be received using a metadata unpacking routine using a source data gather scatter program (DGSP)","An embodiment of the present invention, includes packaging the description of the layout of the set of data into description packets into a destination data gather scattering program (DGSP) on the receiving node to transfer the data packets to the at least one target task.","An embodiment of the present invention, includes placing the data packet in a local buffer if all the description packets corresponding to the data packets are not yet assembled.","An embodiment of the present invention includes placing the data packet in a local buffer if all the description packets corresponding to the data packets are not yet assembled and then transferred to the user buffer when the destination DGSP is ready.","An embodiment of the present invention includes receiving the set of data to be compatible with LAPI.","An embodiment of the present invention includes one of a LAPI active message and a LAPI passive message.","An exemplary embodiment of the invention is discussed in detail below. While specific implementations are discussed, it should be understood that this is done for illustration purposes only. A person skilled in the relevant art will recognize that other components and configurations may be used without parting from the spirit and scope of the invention.","Overview of the Invention:","An embodiment of the present invention contains a number of unique features and advantages to overcome the problems identified in the prior art to more efficiently transfer messages between non-contiguous data structures in one-sided communication models. To solve the poor pipelining problem, an embodiment of this invention uses an \u201ceager mode sending\u201d method. In this method, the sender starts to send data right alter sending data description and does not need to stall and wait for the acknowledgement from target side indicating the data description has arrived. Since the sender pipelines the sending of the data description and the data by not waiting for complete acknowledgment of the data description packets before sending the data, there is possibility that some data packets arrive earlier than all data description packets.","To handle data packets that arrive before all the message data description packets have been received, an exemplary embodiment of the present invention sets up an early arrival queue of scratch buffers to temporarily store the contents of these data packets. Because any data packet that arrives in the receive FIFO and is presented to the next higher layer packet must either be processed or discarded, the data packets that arrive before the corresponding description packets are copied to scratch buffers in the early arrival queue until the complete description is available (i.e., all message description packets have arrived at the target).","An embodiment of the present invention uses two values to decide if the message is complete: (i) the number of pending description packets and (ii) the number of pending data packets. The two values provide more flexibility in the system than prior art methods since one total number of packets is not sufficient to decide the completion of data description, data blocks and the whole message (which includes the data description and data blocks).","Exemplary Distributed Computing Environment","In one embodiment, the mechanisms of the present invention are incorporated and used in a distributed computing environment, such as the one depicted in . An exemplary distributed computing environment  includes, for instance, a plurality of frames  coupled to one another via a plurality of LAN gates . Frames  and LAN gates  are described in detail below.","In one example, distributed computing environment  includes eight (8) frames, each of which includes a plurality of Systematic Multi Processor (SMP) nodes . Since a SMP (Symmetric Multi Processor) node normally runs all Central Processing Units (CPUs) under a single OSI (Open System Interconnect), the terms OSI and SMP can be considered interchangeable in this discussion. In one instance, each frame includes sixteen (16) processing nodes. Each processing node is, for instance, a RS\/6000 (or RISC System\/6000) computer running AIX, a UNIX based operating system. Each processing node within a frame is coupled to the other processing nodes of the frame via, for example, an internal LAN connection. Additionally, each frame is coupled to the other frames via LAN gates .","As an example, each LAN gate  includes either an RS\/6000 computer, any computer network connection to the LAN, or a network router. However, these are only examples. It will be apparent to those skilled in the relevant art that there are other types of LAN gates, and that other mechanisms can also be used to couple the frames to one another.","In addition to the above, the distributed computing environment of  is only one example. It is possible to have more or less than eight frames, or more or less than sixteen nodes per frame. Further, the processing nodes do not have to be RS\/6000 computers running AIX. Some or all of the processing nodes can include different types of computers and\/or different operating systems. All of these variations are considered to be part of the claimed invention.","Transferring Non-Contiguous Data",{"@attributes":{"id":"p-0041","num":"0044"},"figref":"FIG. 5","b":["501","507","503","505","507","512","512","508","509","518","518","512","508","507","513","506","503","510","508","520","520","504","526","528","530","516","509","519","512","510","512","510","532","509","522","512","510","532","521","512","510","505","511","502","510","532","524","532","510","516","521","512","510","505","524","510","524","503"]},"It is important to note that even though the example implemention shows description and data packets as strictkly separate packets, it is within the true scope and spirit of the present to include the start of the data in the packet containing the end of the description.",{"@attributes":{"id":"p-0043","num":"0046"},"figref":"FIG. 6","b":["602","501","604","606","507","608","512","509","508","507","509","518","508","610","513","506","503","504","501","503","504","510","508","508","612","510","520"]},"Referring now to , the method on a receiving node begins at step  by determining that a new packet is arriving, at step . The metadata unpackaging routine  at step  checks the two bits in the flag field of the LAPI packet header of the incoming packet to determine whether the packet is a description packet  or a data packet . If the packet is a description packet , the unpackaging routine  at step , checks to see if the description packet counter  has been set and sets the description packet counter , at step , according to information contained in the packet header. Otherwise, if the description packet counter  has previously been set, the routine decrements the description counter  at step , and unpacks the contents of the description packet  received in the receiving buffer  to reconstruct the destination DGSP  on the receiving node at step . Then, the unpackaging routine  checks at step , to see if the description is complete (description counter=0). If the description is incomplete, the method returns to step  to receive the next packet. If the description is complete, the unpackaging routine  checks, at step , to see if there are any data packets  in the temporary local buffer  (also referred to as \u201cearly queue\u201d). If there is no data in the local buffer , the method returns to step  to receive the next packet. However, if there are data packets  in the local buffer , the unpackaging routine  calls the DGSM  at step , which uses the destination DGSP  to transfer the data packets  stored in the temporary local buffer  to a user buffer  in the target task . The unpackaging routine  adjusts the value of the data packet counter  by the amount of data packets  transferred from the local buffer  at step . From there, the method checks to see if the data is complete (all data packets received and data counter=0) at step . If the data is incomplete, the method returns to step  to await the next packet. If the data is complete, the process ends.","However, if the incoming packet, at step , is a data packet  (i.e. not a description packet), the unpackaging routine  checks to see if the description is complete at step  (i.e. the destination DGSP  has been completely assembled and the description counter=0). If the description is complete at step , the unpackaging routine  calls the DGSM , which uses the destination DGSP  to transfer the data packet  received in the receiver buffer  to the user buffer  in the target task . The unpackaging routine  then decrements the data counter  at step . Next, the method checks to see if the data is complete (all data packets received and data counter =0), at step . If the data is incomplete, the method returns to step  to await the next packet. If the data is complete, the process ends.","If at step , the description is not complete, the unpackaging routine  checks to see if the temporary local buffer  is full at step , and providing there is sufficient available space, stores the data packet  into the temporary local buffer  at step , until such time as the destination DGSP  is ready to complete the transfer to the user buffer . The method then returns to step  to await the next packet. In the event that the temporary local buffer  is full, the data must be discarded at step , and it will be necessary to retransmit in order to receive the message in its entirety.","In addition to the above procedure, the receiving node sends an acknowledgement back to the transmitting node for each packet received. If the transmitting node does not receive acknowledgement of each packet within a predetermined amount of time, the message, or the missing portion of the message, is retransmitted.","One embodiment of the present invention uses a passive message model in which the target side reception, caching, interpretation and finally disposal of the message description that controls data scatter is handled by a communication library without explicit involvement of the target side application code. However, an extension of this implementation is to apply this new method to active message communication in which some application code is also run at message arrival. Any message level data layout description (a DGSP in this case but any other form of message level data description as well) does not only provide the target data layout needed by the communication library in distributing the data, it also encodes the information determined by the side that originated the message of which parts of the target data structure will be updated by the incoming message. This information is potentially useful at the target when the target does not have its own knowledge of which parts of the data structure the just arriving message will affect. The application's purpose in sending data to some target is so the data can be incorporated in the ongoing work of the target. To take advantage of the arrived data, the target requires some way of knowing the bounds of the data that has arrived. In some cases, this knowledge of message layout is built into the application code and it is enough for the target side to know data has arrived. In such cases, the passive message approach is sufficient. In other cases, the target side may not have such knowledge built in.","In general, an active message technique which runs a user header handler at the arrival of the first packet is a known technique which allows the application to capture information about the message to guide the incorporation of that message into the ongoing computation of the application or other activities. The planned extension of this invention will have the communication library cache the DGSP in more persistent storage and pass a handle for that cached DGSP to the user header handler as a parameter. The header handler of the application, in one embodiment, records the handle and instruct the communication library to preserve the target data structure description for future use by the application. When the application comes to the point of needing to discern what parts of the target data structure has been modified by the message the cached description can be accessed and analyzed by the application, using the handle to access the preserved DGSP. The information remains available to the application for as long as it is needed and then can be disposed by an application call a FREE(handle) routine advising the communication library it may now discard the DGSP.","In an example embodiment of the present invention, the platform is any computer capable of running multiple processes in which each process runs with its own address space but under a single OSI. The OSI supports mapping of address ranges between distinct address spaces, and can be run to exploit multiple processors which may not have access to a single common address space. It will be apparent to those skilled in the art that implementation is not limited to such an exemplary platform.","While various embodiments of the present invention have been described above, it should be understood that they have been presented by way of example only, and not limitation. Thus, the breadth and scope of the present invention should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing and other features and advantages of the invention will be apparent from the following, more particular description of an exemplary embodiment of the invention, as illustrated in the accompanying drawings, in which:",{"@attributes":{"id":"p-0023","num":"0026"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0024","num":"0027"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0025","num":"0028"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0026","num":"0029"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0027","num":"0030"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0028","num":"0031"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0029","num":"0032"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
