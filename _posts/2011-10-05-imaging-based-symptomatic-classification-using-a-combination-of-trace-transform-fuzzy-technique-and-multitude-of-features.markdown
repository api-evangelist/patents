---
title: Imaging based symptomatic classification using a combination of trace transform, fuzzy technique and multitude of features
abstract: Characterization of carotid atherosclerosis and classification of plaque into symptomatic or asymptomatic and risk score estimation are of clinical value. A statistical system is described for symptomatic versus asymptomatic plaque automated classification of carotid ultrasound images and cardiovascular risk score computation. The technique is applicable for the following types of modalities for carotids: 2D Ultrasound, 3D Ultrasound, CT, MR. Wall region is segmented and features are extracted consisting of type 1 combination consisting of: (a) Higher Order Spectra; (b) Discrete Wavelet Transform (DWT); (c) Texture and (d) Wall Variability; type 2 combination consisting of: (a) Local Binary Pattern; (b) Law's Mask Energy and (c) Wall Variability and type 3 combination: (a) Trace Transform; (b) Fuzzy Grayscale Level Co-occurrence Matrix and (c) Wall Variability. These features are trained using a training classifier on training images and the coefficients are applied to on-line test patient images. The system yields the cardiovascular risk score value using the feature combinations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08532360&OS=08532360&RS=08532360
owner: Atheropoint LLC
number: 08532360
owner_city: Roseville
owner_country: US
publication_date: 20111005
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["PRIORITY APPLICATIONS","TECHNICAL FIELD","BACKGROUND","SUMMARY OF THE VARIOUS EMBODIMENTS","DETAILED DESCRIPTION"],"p":["This is a continuation-in-part patent application of co-pending patent application Ser. No. 12\/799,177; filed Apr. 20, 2010 by the same applicant. This is also a continuation-in-part patent application of patent application Ser. No. 12\/802,431; filed Jun. 7, 2010 now U.S. Pat. No. 8,313,437 by the same applicant. This is also a continuation-in-part patent application of co-pending patent application Ser. No. 12\/896,875; filed Oct. 2, 2010 by the same applicant. This is also a continuation-in-part patent application of co-pending patent application Ser. No. 12\/960,491; filed Dec. 4, 2010 by the same applicant. This is also a continuation-in-part patent application of co-pending patent application Ser. No. 13\/053,971; filed Mar. 22, 2011 by the same applicant. This is also a continuation-in-part patent application of co-pending patent application Ser. No. 13\/077,631; filed Mar. 31, 2011 by the same applicant. This is also a continuation-in-part patent application of co-pending patent application Ser. No. 13\/107,935; filed May 15, 2011 by the same applicant. This is also a continuation-in-part patent application of co-pending patent application Ser. No. 13\/219,695; filed Aug. 28, 2011 by the same applicant. This present patent application draws priority from the referenced co-pending patent applications. The entire disclosures of the referenced co-pending patent applications are considered part of the disclosure of the present application and are hereby incorporated by reference herein in its entirety.","This patent application relates to methods and systems for use with data processing, data storage, and imaging systems, according to one embodiment, and more specifically, for medical image processing.","Atherosclerosis (or arteriosclerotic vascular disease) is a condition in which an artery wall thickens as a result of deposition of materials such as cholesterol, fat, and other substances resulting in the formation of hard structures called plaques. Formation of plaques makes the arteries stiff and narrow (stenosis), thereby restricting blood supply to the involved organs. Such restricted blood supply would damage the organ, and eventually lead to its failure. Pieces of plaque can also break away and move from the affected artery to smaller blood vessels, block these vessels completely, and consequently, result in tissue damage and death (embolization). This embolization process is one of the causes of heart attack and stroke. Recent statistics from the World Health Organization indicate that such cardiovascular diseases (CVDs) are the world's largest killers, resulting in 17.1 million deaths a year. Estimates indicate that by 2030, almost 23.6 million people will die from CVDs, mainly from heart disease and stroke. The earliest risk indicator of a possible CVD is the presence of atherosclerosis. Early detection of atherosclerosis and adequate treatment and lifestyle changes would enable the patient to prevent the onset of a CVD. Unfortunately, atherosclerosis is a chronic disease that remains asymptomatic for decades. Therefore, development of techniques that detect the presence of plaque at its earliest stages is of paramount importance.","Owing to its anatomical position and its relatively large diameter, the Common Carotid Artery (CCA) is the preferred artery for routine clinical examination to detect the presence of plaque and to study its characteristics. The examination is mostly carried out using non-invasive carotid artery ultrasound, which is a cost-effective and relatively fast imaging technique that does not use ionising radiation. However, ultrasound technique is operator dependent, and hence, the interpretation is subjective. Moreover, even though studies show that ultrasonographic B-mode characterization of plaque morphology is useful in assessing the vulnerability of atherosclerotic lesions, a confident and reproducible classification of dangerous plaques and its risk score from this plaque is still not available. Also, the correlation between ultrasonographic findings and the histological findings of carotid plaques is often poor. These limitations are due to the low image resolution and artifacts associated with ultrasound imaging. Thus, Computer Aided Diagnostic (CAD) techniques that adequately pre-process the ultrasound images before extracting discriminating features for further classification and giving a risk score would improve the correlation between ultrasound based results and histological results of carotid plaques.","Once plaque is detected, the treatment options to unblock the stenosis include Carotid Artery Stenting (CAS) and Carotid Endarterectomy (CEA). CAS is a non-invasive procedure that uses a catheter to correct stenosis, whereas CEA is a surgical procedure. It has been shown that CEA reduces the risk of ipsilateral stroke. In a clinical trial named CREST, both CAS and CEA were compared on the collective incidence of any stroke, any heart attack or death. The study concluded that there was a higher risk of stroke with CAS and a higher risk of myocardial infarction with CEA. This conclusion indicates that there is a considerable risk for the patient undergoing either of these procedures. Therefore, characterization of the patient as symptomatic or asymptomatic based on the wall plaque morphology would enable the vascular surgeons to decide whether the patient needs such risky procedures. This is because studies have shown that only symptomatic patients were found to have more frequent plaque rupture that cause life-threatening embolization. Plaque rupture was seen in 74% of symptomatic plaques and in only 32% of plaques from asymptomatic patients.","Thus, the development of an efficient completely automated CAD technique that not only detects plaque but also classifies it into symptomatic and asymptomatic while giving a cardiovascular risk score would immensely assist the doctors in managing atherosclerosis.","Atherosclerosis is a degenerative disease of the arteries that results in the formation of plaques, and consequent narrowing of blood vessels (stenosis). Characterization of carotid atherosclerosis and classification of plaque into symptomatic or asymptomatic along with the risk score estimation are key steps necessary for allowing the vascular surgeons to decide if the patient has to definitely undergo risky treatment procedures that are needed to unblock the stenosis. This application describes a (a) Computer Aided Diagnostic (CAD) technique for symptomatic versus asymptomatic plaque automated classification of carotid ultrasound images and (b) presents a cardiovascular risk score computation in longitudinal 2D Ultrasound, cross-sectional MR, CT and 3D Ultrasound and 3D IVUS. We show this for Ultrasound, CT and MR modalities and extendable to 3D Carotid Ultrasound and 3D IVUS.","The on-line system consists of Atherosclerotic Wall Region estimation using AtheroEdge\u2122 (for longitudinal Ultrasound) or Athero-CTView\u2122 (for CT) or Athero-MRView (for MR) and extendable to 3D carotid Ultrasound or 3D IVUS. This grayscale Wall Region is then fed to a feature extraction processor which computes: (a) Higher Order Spectra-based features; (b) Discrete Wavelet Tansform (DWT)-based features; (c) Texture-based features and (d) Wall Variability. The output of the Feature Processor is fed to the Classifier which is trained off-line from the Database of similar Atherosclerotic Wall Region images. The off-line Classifier is trained from the significant features from (a) Higher Order Spectra; (b) Discrete Wavelet Transform (DWT); (c) Texture and (d) Wall Variability, selected using t-test. Symptomatic ground truth information about the training patients is drawn from cross modality imaging such as CT or MR or longitudinal Ultrasound or 3D ultrasound or 3D IVUS in the form of 0 or 1 (1 for symptomatic). Support Vector Machine (SVM) or similar classifier (such as KNN, PNN or Decision Tree or Adaboost) supervised classifier of varying kernel functions is used off-line for training. The obtained training parameters are then used to evaluate the test set. One can then achieve high accuracy with the radial basis function kernel and the one with a polynomial kernel of order two. The system also yields the risk score value on the basis of the wall features. The proposed technique demonstrates that plaque classification between symptomatic vs. asymptomatic could be achieved with a completely automated CAD tool with a significant accuracy. Performance of the system can be evaluated by computing the accuracy, sensitivity, specificity, and Positive Predictive Value (PPV). Hence, such a tool would prove to be a valuable inclusion in the current treatment planning protocol by vascular surgeons.","Most of the existing plaque classification CAD tools rely on human intervention to manually segment the plaque in the ultrasound images before features are extracted and processed. It is known that manual segmentation needs well trained experts in the field, and the results may be different from expert to expert. Generally, patients are considered symptomatic if they had experienced Amaurosis Fugax (AF), Transient Ischemic Attack (TIA), or focal transitory, reversible or established neurological symptoms in the ipsilateral carotid territory in the previous six months. However, in this application, in order to make the proposed technique independent of the previous history of the patients, the ground truth of whether the plaque is symptomatic or asymptomatic is obtained by studying the cross modality (other than ultrasound) such as Computer Tomography (CT) or MRI or 3D Ultrasound or 3D IVUS and their results are obtained from the patients. Patients without any history of recent neurologic symptoms or with nonspecific symptoms such as dizziness and vertigo were considered asymptomatic.","As described herein for various example embodiments, the embodiments can support and effect the following features:\n\n","The system of an example embodiment uses Coarse to Fine Resolution Processing: Previous art has focused on methods for either classification of media layer or finding the MA edges in the manual designated ROI. Since it is manual ROI, it is time consuming and non-practical for clinical applications, we have developed a new method which is fast, accurate, reliable and very practical for IMT measurement for ultrasound carotids, brachial, femoral and aortic blood vessels. Since the manual methods are time consuming and requires a lot of training, this applications is a two step stage process: (a) automated artery recognition and (b) automated calibration (segmentation) which finds the LIMA borders more accurately which is then used for Atherosclerotic Wall Region computation. The automated recognition process is hard given the Jugular vein in the neighborhood. Our concept is to recognize the artery in a smaller image with a high speed (so-called coarse resolution) and spot the artery out in longitudinal ultrasound images. The spotted artery can then be seen in the tine resolution or high resolution. This will allow processing the pixels in the correct region of interest. The statistics of the neighboring pixels will not affect the region of interest, which is where the accurate LIMA borders need to be determined. Normally, arteries are about 10 mm wide while the media thickness is about 1 mm wide. It is also known from our experience that the image resolution is about 15 pixels per mm. If we can bring the original resolution to a coarse resolution by one step down sample, we can bring the media layer to about 8 pixels per mm. Further, if this coarse resolution is down sampled by another half, then one can bring the image resolution from 8 pixels per mm to 4 pixels per mm. Thus, if the coarse resolution of the arterial ultrasound vessels has a medial thickness of 4 pixels per mm, one can easily detect such edges by convolving the higher order derivatives of Gaussian kernel with the coarse resolution image. Thus the new concept here to compute Atherosclerotic Wall Region is to automatically detect the arterial wall edges by down sampling the image and convolving the coarse images to higher order derivatives of Gaussian kernels. This allows the media layer to be automatically determined, thus generating the Atherosclerotic Wall Region which is then used for grayscale feature identification such as: FIOS-Bispectrum Phase Entropy, DWT features like vertical and horizontal and energy component (from decomposition directions corresponding to 0\u00b0 (horizontal, Dh), 90\u00b0 (vertical, Dv) and 45\u00b0 or 135\u00b0 (diagonal, Dd) orientation were taken using DWT features), Texture Features and Wall Variability.","In another methodology, Atherosclerotic Wall Region which is then used for grayscale feature identification such as Local Binary Pattern (LBP) and Laws Mask Energy (LME) and Wall Variability.","Such an approach for automated media layer detection from fine to coarse resolution will further improve the region of interest determination. The art of changing the fine to coarse resolution has been popular in computer vision sciences. There are several methods available to converting the image from high resolution to coarse resolution. One of them is wavelet-based method where wavelets are being applied for down sampling the image to half Another method can be hierarchical down sampling method using Peter Burt's algorithm. Thus the first advantage of the current system is automated recognition of the artery at coarse resolution and then using the MA border for visualization and recognition at the fine resolution (up-sampled resolution). This multi-resolution approach for Atherosclerotic Wall Region computation has several advantages to it:\n\n","In prior art, we have seen that the speckle reduction has been used for removing speckles in the ultrasound images. Though speckle reduction is common in ultrasound imaging, but the way speckle reduction is used here is very conservative. The idea here is to find out where the LIMA borders are using automated recognition system and then apply the local statistical speckle reduction filter in specific set of pixels which come under the LIMA band or media layer. Such a strategy allows multiple advantages:\n\n","Extracting LIMA borders in presence of Calcium Shadow: Calcium is an important component of the media layer. It is not exactly known how the calcium is formed, but it is said that calcium accumulates in the plaques. During the beginning of Atherosclerosis disease, the arterial wall creates a chemical signal that causes a certain type of WBC (white blood cells) such as monocytes and T cells that attaches the arterial wall. These cells then move into the wall of the artery. These T cells or monocyles are then transformed into foam cells, which collect cholesterol and other fatty materials and trigger the growth of the muscle cells (which are smooth in nature) in the artery. Over time, it is these fat-laden foam cells that accumulate into plaque covered with a fibrous cap. Over time, the calcium accumulates in the plaque. Often times, the calcium is seen in the near wall (proximal wall) of the carotid artery or aortic arteries. This causes the shadow cone formation in the distal wall (far wall). As a result the LI boundaries (for Atherosclerotic Wall Region computation) are over computed from its actual layer. The shadow causes the LI lining over the actual LI boundary. As a result, the LI-MA distances are over computed in the shadow zone. Because of this, the Atherosclerotic Wall Region formation is over computed in these cases. This application particularly takes care of Atherosclerotic Wall Region computation during the shadow cone formation. We will see how the actual LI boundaries are recovered if calcium is present causing the shadow cone. As a result, the Atherosclerotic Wall Region computation has the following advantages when using shadow cones (a) Accurate Atherosclerotic Wall Region computation in real time when the calcium is present in the proximal wall (near wall) causing the shadow cone formation; (b) The system allows computing the Atherosclerotic Wall Region in both cases: (a) when calcium is present and when calcium is not present.","In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the various embodiments. It will he evident, however, to one of ordinary skill in the art that the various embodiments may be practiced without these specific details.","Description of the CVRS Estimation","This section presents (a) how the plaque in the Atherosclerotic Wall Region can be classified into symptomatic vs. asymptomatic patient and (b) Cardiovascular Risk Score (CVRS) estimation.","The concept of this application lines in modeling the vessel wall region to classify the patient plaque and coming out with the cardiovascular risk score. The modeling of the vessel wall requires non-linear processing of the plaque in the vessel wall, especially the media layer. The non-linear process requires computing the features of the plaque which presents the symptomatic information and asymptomatic information. These features are characteristics of the plaque in the vessel wall such as: (a) Higher Order Spectra; (b) Discrete Wavelet Transform (DWT); (c) Texture and (d) Wall Variability. In another methodology used here is to compute the grayscale features in the Atherosclerotic Wall Region such as: Local Binary Pattern (LBP) and Laws Mask Energy (LME) and Wall Variability.","One way to classify the wall plaque is to train a system with a similar kind of features and use this trained system to identify if it can recognize a similar featured vessel and give a cardiovascular risk score. This recognition can be considered on a test ultrasound image scan having the vessel wall. This protocol can be the testing protocol on a new incoming test patient. Thus the combination of training and testing can assist in the classification of symptomatic and asymptomatic carotid vessel wall. The training system can be called as an off-line system while the testing system can be called as an on-line system. Since the training and testing systems are applied in the region-of-interest (ROI) or Guidance Zone (GZ) where the features are supposed to be extracted. Thus the region of interest can be considered as an Atherosclerotic Wall Region (AWR) and plays a critical role in development of an invention where the plaque wall features are extracted for training and the parameters computed during the training system can then be applied to the test image. The concept involves feature selection using t-test. Another novel concept is to use cross-modality information for the learning process during the training system. This means even if the symptomatic vs. asymptomatic classification system and cardiovascular risk score estimation system works for the ultrasound vascular wall, the system allows getting its training attributes from the cross-modality and it can be ultrasound, MR or CT or 3D carotid ultrasound or 3D IVUS. This idea brings a greater flexibility for development of the training system for Symptomatic vs. Asymptomatic (SymVsAsym) Classification and cardiovascular risk score (CVRS) estimation.","Since this is a vascular wall based system, it therefore requires that the far wall of the vessel wall in the longitudinal ultrasound or the region of interest or guidance zone be accurately and automatically developed. Thus an accurate determination of the media wall thickness and the grayscale region needs to be determined and analyzed. One way is to get the accurate vessel far wall is to get the initma media thickness (IMT) thickness accurately. The IMTs are normally 1 mm in thickness, which nearly corresponds to approximately 15 pixels on the screen or display. IMT estimation having a value close to 1 mm is a very challenging task in ultrasound images due to large number of variabilities such as: poor contrast, orientation of the vessels, varying thickness, sudden fading of the contrast due to change in tissue density, presence of various plaque components in the intima wall such as lipids, calcium, hemorrhage, etc. Under normal resolutions, a one mm thick media thickness is difficult to estimate using stand-alone image processing techniques. Over and above, the image processing algorithms face an even tighter challenge due to the presence of speckle distribution. The speckle distribution is different in nature from these interfaces. This is because of the structural information change between intima, media and adventitia layers of the vessel wall. As a result, the sound reflection from different cellular structures is different. The variability in tissue structure\u2014all that happens in one mm of the vessel wall\u2014brings fuzziness in the intensity distribution of the vessel wall. Under histology, media and adventitia walls are clearly visible and one can observe even their thicknesses. This one mm zone is hard to discern in a normal resolution image of 256\u00d7256 pixels in a region of interest (ROI) or in a higher resolution image of 512\u00d7512 pixels in a region of interest (ROI). One needs a high resolution image to process and identify the intensity gradient change in ultrasound images from lumen to intima and media to adventitia layers. The ultrasound image resolution may not be strong enough like MRI or computerized axial tomography (CAT or CT) images, which can be meaningful for soft tissue structural information display.","Thus, an on-line system can consist of Atherosclerotic Wall Region estimation using AtheroEdge\u2122 for longitudinal Ultrasound or Athero-CTView\u2122 for CT or Athero-MRView from MR. AtheroEdge\u2122 is a boundary estimation system for LI and MA borders for the ultrasound longitudinal blood vessel image such as Carotid, Brachial, Femoral or Aorta. Athero-CTView\u2122 is a boundary estimation system for computing the lumen and outer wall borders from the CT slices of the carotid artery. Similarly, Athero-MRView is the boundary estimation system for computing the lumen and outer wall borders from the MR carotid slices. Similarly, AtheroEdge3D is the boundary estimation system for computing the lumen and outer wall borders from the 3D carotid ultrasound slices.","Atherosclerotic Wall Region (AWR) is the region between LI and MA borders in the ultrasound image for the blood vessel. For CT or MR or 3D Carotid Ultrasound or 3D IVUS, the Atherosclerotic Wall Region (AWR) is considered to be the grayscale region between the lumen border and outer wall of the carotid artery.","This grayscale Atherosclerotic Wall Region (AWR) is then fed to a feature extraction processor which computes: (a) Higher Order Spectra; (b) Discrete Wavelet Transform (DWT); (c) Texture and (d) Wall Variability.","In another methodology used here is to compute the grayscale features in the Atherosclerotic Wall Region such as: Local Binary Pattern (LBP) and Laws Mask Energy (LME) and Wall Variability.","The output of the Feature Processor is fed to the Classifier which is trained off-line from the Database of similar Atherosclerotic Wall Region images. The off-line Classifier is trained from the significant features from (a) Higher Order Spectra; (b) Discrete Wavelet Transform (DWT); (c) Texture and (d) Wall Variability, selected using t-test. Symptomatic ground truth information about the training patients is drawn from cross modality imaging such as CT or MR or 3D Carotid Ultrasound or 3d IVUS in the form of 0 or 1. Support Vector Machine (SVM) supervised classifier of varying kernel functions is used off-line for training. Those skilled in the art can use: Radial Basis Probabilistic Neural Network (RBPNN), Nearest Neighbor (KNN) classifier, Decision Trees (DT), Adaboost Classifier, or of similar kind. The obtained training parameters are then used to evaluate the test set. The highest accuracy close to 90% was registered by the SVM classifier with the radial basis function kernel and the one with a polynomial kernel of order two. The system also yields the risk score value on the basis of the four set of wall features. The proposed technique demonstrates that plaque classification between symptomatic vs. asymptomatic could be achieved with a completely automated data mining CAD tool with a significant accuracy. Performance of the system is evaluated by computing the accuracy, sensitivity, specificity, and Positive Predictive Value (PPV).","Atherosclerotic Wall Region (AWR) Computation:","In the longitudinal ultrasound image, the CCA (lumen) appears as a region of low intensity between two layers of high intensity, namely, the Near Adventitia (ADN) and Far Adventitia (ADF). The Intima-Media Thickness (IMT) of the CCA is the most commonly used measure for atherosclerosis monitoring, and is defined as the distance between the Lumen-Intima (LI) and Media-Adventitia (MA) interfaces. Manual Atherosclerotic Wall Region (AWR) and measurement of IMT from B-mode images is time consuming, subjective, and difficult. In the past two decades, several CAD tools, both fully automated and semi-automated, have been developed. Typically, in CAD tools for IMT measurement, the calculation of Atherosclerotic Wall Region (AWR) computation and IMT measurement involves the following two steps.\n\n","Several algorithms in the literature for the automated segmentation of the CCA (image gradients and edge detection based and parametric deformable models based) rely on user interaction in Step 1 described above. Therefore, complete automation cannot he achieved and also inter-observer variability prevails.","A completely automated procedure for carotid layers extraction called CALEX (Completely Automated Layers Extraction; F. Molinari, G. Zeng, and J. S. Suri, An integrated approach to computer-based automated tracing and its validation for 200 common carotid arterial wall ultrasound images: A new technique, J Ultras Med, 29, (2010), 399-418) was developed. In another automated technique called CULEX (Completely User-independent Layers Extraction, S. Delsanto, F. Molinari, P. Giustetto, W. Liboni, S. Badalamenti, and J. S. Suri, Characterization of a Completely User-Independent Algorithm for Carotid Artery Segmentation in 2-D Ultrasound Images, Instrumentation and Measurement, IEEE Transactions on, 56(4), (2007), 1265-1274) demonstrated the usage of local statistics, signal analysis, and fuzzy-based classification for IMT measurement and subsequently for plaque delineation.","Another recent technique called CAMES (Completely Automated Multiresolution Edge Snapper; F. Molinari, C. Loizou, G. Zeng, C. Pattichis, D. Chandrashekar, M. Pantziaris, W. Liboni, A. Nicolaides, and J. Suri, -(CAMES)\u2014A New Technique for an Accurate Carotid Ultrasound IMT Measurement and its Validation on a Multi-Institutional Database, in SPIE Medical Imaging Conference. 2011: Lake Buena Vista (Orlando), Fla., USA) was developed, that measures the segmentation of LI and MA borders and IMT measurement by utilizing the morphological properties of the CCA. Herein, for Step 1, we first down-sample the original image (multi-resolution approach) and then capture the (near adventitia border) ADN and far adventitia borders (ADF) edges using derivative of Gaussian Kernel with known a priori scale, and finally up-sample the determined ADF profile in order to determine the Region Of Interest (ROI) for Step 2. In Step 2, only the ROI was considered, and the First Order Absolute Moment (FOAM) operator was used to enhance the intensity edges (guided by the multiresolution approach in stage 1), and finally, the LI and MA borders were heuristically determined in this ROI. CAMES is a revolutionary technique as it is the first technique to automatically recognize the CA. This method showed 100% accuracy in artery recognition process. Since our aim is to develop a completely automated Atherosclerotic Wall Region (AWR), CAMES was one of the preferred choice for CCA segmentation and subsequent LI and MA border determination. The system consists of an on-line system where the wall region is automatically segmented from the given set of images from database based on multi-resolution approach. The segmentation output gives LI and MA borders and the grayscale region between this the LI and MA borders constitute the Atherosclerotic Wall Region. This is called the Guidance Zone (GZ).","This grayscale information (or guidance zone, GZ) is modeled as non-linear information by taking the Radon Transform of the grayscale wall region and then computing the Normalized Bispectral Entropy and Normalized Squared Bispectral Entropy. The DWT features are computed as vertical and horizontal and energy component, in four decomposition directions corresponding to 0\u00b0 (horizontal, Dh), 90\u00b0 (vertical, Dv) and 45\u00b0 or 135\u00b0 (diagonal, Dd) orientation were taken. Texture features are also computed (symmetry and state of disorderness entropy). Finally, the vessel wall variability is computed due to presence of plaque is computed.","Once the LIMA borders are determined, one can get the Atherosclerotic Wall Region (AWR) and is ready for on-line processing of the patient's image. If the system is for CT, instead of LIMA borders, we have lumen border and outer wall border of the carotid artery. If the SysVsAsym Classification system is for MR, the protocol will compute the lumen and outer wall borders. If it is 3D Carotid Ultrasound, we have lumen border and outer wall border of the carotid artery in ultrasound cross-sectional slices. The region between the lumen and outer walls for MR or CT or 3D Ultrasound will constitute carotid artery wall thickness (CAWT). The Atherosclerotic Wall Region grayscale image is fed for feature extraction process which consists on (a) Normalized Bispectral Entropy, (b) Normalized Bispectral Squared Entropy; (c) Average Dh, Average Dv, Energy (from DWT coefficients); (d) Texture symmetry and Entropy; (e) Wall Variability.","HOS Feature:","Higher Order Spectra or polyspectra allow one to study the non-linear behavior of a process. Higher order statistics denote higher order moments (order greater than two) and non-linear combinations of higher order moments, called the higher order cumulants. In the case of a Gaussian process, all cumulant moments of order greater than two are zero. Hence, such cumulants can be used to evaluate how much a process deviates from Gaussian behavior. One of the most commonly used HOS parameter is the bispectrum. The bispectrum is the spectrum of the third order cumulant, and is a complex valued function of two frequencies given by\n\n()=()()*()]\u2003\u2003(1)\n","where X(f) is the Fourier transform of the signal studied. As per the equation, the bispectrum is the product of the three Fourier coefficients. The function exhibits symmetry, and is computed in the non-redundant\/principal domain region \u03a9 as shown in .","Principal domain region (\u03a9) used for the computation of the bispectrum for real signals.","The bispectrum phase entropy obtained from the bispectrum is used as one of the features in this application. This entropy is defined as:","Bispectrum Phase Entropy:\n\nePRes=\u03a3(\u03c8)log (\u03c8)\u2003\u2003(2)\n\nwhere\n\n(\u03c8)=\u03a3(\u03c6(())\u2208 \u03c8)\u2003\u2003(3)\n\n\u03c8={\u03c6|\u2212\u03c0+22\u03c0(1)\/\n\n0,11\u2003\u2003(4)\n\nwhere L is the number of points within the region \u03a9, \u03c6 is the phase angle of the bispectrum, and l(.) is an indicator function which gives a value of 1 when the phase angle is within the range depicted by \u03c8in equation (4).\n","In order to calculate the bispectrum, and hence, the phase entropy, the pre-processed ultrasound Atherosclerotic Wall Region images were first subjected to Radon transform. This transform computes line integrals along many parallel paths in the Atherosclerotic Wall Region image from different angles \u03b8 by rotating the image around its centre. Such a transformation projects the intensity of the pixels along these lines into points in the resultant transformed signal. Thus, Radon transform converts an Atherosclerotic Wall Region image into a one-dimensional signal at various angles. In this patent application, we calculated the Radon transformed signals for every 10 step size and then determined the phase entropy of these signals. Those skilled in the art can change the step size to higher and lower numbers. The system computes two bi-spectral entropies from the Radon transformed signals. These entropies are defined as follows.","Normalized Bi-spectral Entropy (e1Res):",{"@attributes":{"id":"p-0083","num":"0118"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":["e","Res"],"mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"},{"mo":"-","mrow":{"msub":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":[{"mi":["p","i"]},{"mi":["p","i"]}],"mo":["\u2062","\u2062","\u2062"],"mi":"log","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":"="},"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}},"mi":"where"}},{"mrow":{"mo":["(",")"],"mn":"5"}}]},{"mtd":[{"mrow":{"msub":{"mi":["p","i"]},"mo":"=","mfrac":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"mi":"B","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"f","mn":"1"},{"mi":"f","mn":"2"}],"mo":","}}}},{"msub":{"mo":"\u2211","mi":"\u03a9"},"mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"B","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"f","mn":"1"},{"mi":"f","mn":"2"}],"mo":","}}}}}]}}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}]}}},"br":{}},{"@attributes":{"id":"p-0084","num":"0119"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":["e","Res"],"mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"},{"mo":"-","mrow":{"msub":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":[{"mi":["p","n"]},{"mi":["p","n"]}],"mo":["\u2062","\u2062","\u2062"],"mi":"log","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":"="},"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}},"mi":"where"}},{"mrow":{"mo":["(",")"],"mn":"7"}}]},{"mtd":[{"mrow":{"msub":{"mi":["p","n"]},"mo":"=","mfrac":{"msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"B","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"f","mn":"1"},{"mi":"f","mn":"2"}],"mo":","}}}},"mn":"2"},"mrow":{"msub":{"mo":"\u2211","mi":"\u03a9"},"mo":"\u2062","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"B","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"f","mn":"1"},{"mi":"f","mn":"2"}],"mo":","}}}},"mn":"2"}}}}},{"mrow":{"mo":["(",")"],"mn":"8"}}]}]}}},"br":{}},"Discrete Wavelet Transform (DWT) is a transform that captures both the time and frequency information of the signal. DWT analyzes the atherosclerotic wall region image by decomposing it into coarse approximation via low-pass filtering and into detail information via high-pass filtering. Such decomposition is done recursively on the low-pass approximation coefficients obtained at each level, until the necessary iterations are reached.","Let each atherosclerotic wall region image he represented as a p\u00d7q grayscale matrix I[i,j], where each element of the matrix represents the grayscale intensity of one pixel of the image. Each non-border pixel has eight adjacent neighboring pixel intensities. These eight neighbors can be used to traverse through the matrix. The resultant 2D-DWT coefficients will be the same irrespective of whether the matrix is traversed right to left or left to right. Hence, it is sufficient that we consider four decomposition directions corresponding to 0\u00b0 (horizontal, Dh), 90\u00b0 (vertical, Dv) and 45\u00b0 or 135\u00b0 (diagonal, Dd) orientation. The decomposition structure for one level is illustrated in the diagram below. I is the image, g[n] and h[n] are the low-pass and high-pass filters, respectively and A is the approximation coefficients. In this work, the results from level 1 were found to yield significant features.  shows the 2D DWT decomposition. 2ds1 indicates that rows are down sampled by 2 and columns by 1. 1ds2 indicates that rows are down sampled by 1 and columns by 2. \u2018\u00d7\u2019 operator indicates convolution operation.","As is evident from diagram above, the first level of decomposition results in four coefficient matrices, namely, A, Dh, Dv, and Dd. Since the number of elements in these matrices is high, and since we only need a single number as a representative feature, we employed averaging methods to determine such single-valued features. The following are the definitions of the three features that were determined using the DWT coefficients.",{"@attributes":{"id":"p-0088","num":"0123"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":["Average","Dh"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mn":"1"},{"mfrac":{"mn":"1","mrow":{"mi":["p","q"],"mo":"\u00d7"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"x","mo":"=","mrow":{"mo":["\u2329","\u232a"],"mi":"p"}}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"y","mo":"=","mrow":{"mo":["\u2329","\u232a"],"mi":"q"}}},"mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"Dh","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"9"}}]},{"mtd":[{"mrow":{"mrow":[{"mi":["Average","Dv"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mn":"1"},{"mfrac":{"mn":"1","mrow":{"mi":["p","q"],"mo":"\u00d7"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"x","mo":"=","mrow":{"mo":["\u2329","\u232a"],"mi":"p"}}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"y","mo":"=","mrow":{"mo":["\u2329","\u232a"],"mi":"q"}}},"mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"Dv","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"10"}}]},{"mtd":[{"mrow":{"mi":"Energy","mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"msup":[{"mi":"p","mn":"2"},{"mi":"q","mn":"2"}],"mo":"\u00d7"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"x","mo":"=","mrow":{"mo":["\u2329","\u232a"],"mi":"p"}}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"y","mo":"=","mrow":{"mo":["\u2329","\u232a"],"mi":"q"}}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":"Dv","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},"mn":"2"}}}}}},{"mrow":{"mo":["(",")"],"mn":"11"}}]}]}}}},"Equations (9) and (10) calculate averages of the corresponding intensity values, whereas equation (11) is an averaging of the energy of the intensity values.","Texture Feature:","The texture of an image is characterized by the regular repletion of patterns in the image. There are several approaches to analyzing the textural properties, and in this work, we studied the statistical textural features that are based on the relationship and distribution of pixel intensities. Consider \u03c6(i) as the number of pixels with intensity value i, i ranging from 1 to n. Let A be the area of the Atherosclerotic wall region image. The probability of intensity i in the image is given by:",{"@attributes":{"id":"p-0091","num":"0126"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":"=","mfrac":{"mrow":{"mi":"\u03c6","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mi":"A"}}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}},"br":{}},{"@attributes":{"id":"p-0092","num":"0127"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"Deviation","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["i","\u03bc"],"mo":"-"}},"mn":"2"},"mo":"\u2062","mrow":{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}}}}},{"mrow":{"mo":["(",")"],"mn":"13"}}]}}}},"br":{}},"Next, two matrices, namely, the Gray Level Co-occurrence Matrix (GLCM) and the Run Length Matrix were determined based on the pixel intensities, and features were extracted from these matrices. They are defined as follows.","Gray Level Co-occurrence Matrix:","The GLCM of an image I of size m\u00d7n is given by",{"@attributes":{"id":"p-0095","num":"0130"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["C","d"]},"mo":"=","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mo":["{","}"],"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mi":["p","q"],"mo":","}},{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mrow":[{"mi":"p","mo":"+","mrow":{"mi":["\u0394","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mi":"q","mo":"+","mrow":{"mi":["\u0394","y"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":","}},{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["p","q"],"mo":","}}}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":":"}},"mo":"=","mi":"i"}],"mo":[",",","]}}},{"mtd":{"mrow":{"mrow":{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"p","mo":"+","mrow":{"mi":["\u0394","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mi":"q","mo":"+","mrow":{"mi":["\u0394","y"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":","}}},"mo":"=","mi":"j"}}}]}}}}},{"mrow":{"mo":["(",")"],"mn":"14"}}]}}}},"br":{}},{"@attributes":{"id":"p-0096","num":"0131"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},"mo":"=","mfrac":{"mrow":[{"msub":{"mi":["C","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"msub":{"mo":"\u2211","mrow":{"mo":["\u2329","\u232a"],"mi":"i"}},"mo":"\u2062","mrow":{"msub":{"mo":"\u2211","mrow":{"mo":["\u2329","\u232a"],"mi":"j"}},"mo":"\u2062","mrow":{"msub":{"mi":["C","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}]}}},{"mrow":{"mo":["(",")"],"mn":"15"}}]}}}},"br":{}},{"@attributes":{"id":"p-0097","num":"0132"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"Symmetry","mo":"=","mrow":{"mn":"1","mo":"-","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"mo":"\u2009","mrow":{"msub":{"mo":"\uf603","mi":"c"},"mo":["\u2062","\uf604"],"mrow":{"mrow":[{"msub":{"mi":["C","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"mmultiscripts":{"mi":["C","d","c"],"none":[{},{}],"mprescripts":{}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["j","i"],"mo":","}}}],"mo":"-"}}}}}}}},{"mrow":{"mo":["(",")"],"mn":"16"}}]},{"mtd":[{"mrow":{"mi":"Entropy","mo":"=","mrow":{"mo":"-","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"mi":"ln","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}],"mo":"\u00d7"}}}}}},{"mrow":{"mo":["(",")"],"mn":"17"}}]}]}}}},"Entropy, which denotes the degree of disorder in an image, will have high value if the elements in the GLCM are the same.","Run Length Matrix:","The run length matrix Pconsists of all the elements where the intensity value i has the run length j continuous in direction \u03b8. Typically values of \u03b8 are 0\u00b0, 45\u00b0, 90\u00b0, or 135\u00b0. The feature called Run Length Non-uniformity (RLnU) is then determined as follows.",{"@attributes":{"id":"p-0100","num":"0135"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["R","Ln","U"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]},{"munder":{"mo":"\u2211","mrow":{"mo":["\u2329","\u232a"],"mi":"j"}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"munder":{"mo":"\u2211","mrow":{"mo":["\u2329","\u232a"],"mi":"i"}},"mo":"\u2062","mrow":{"msub":{"mi":["P","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}},"mn":"2"}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"18"}}]}}}},"br":[{},{}]},"A circular neighborhood is considered around a pixel. \u2018P\u2019 points are chosen on the circumference of the circle with radius \u2018R\u2019 such that they are all equidistant from the center pixel. The gray values at points on the circular neighborhood that do not coincide exactly with pixel locations are estimated by interpolation. These points are then converted into a circular bit-stream of 0 s and 1 s according to whether the gray value of the point is less than or greater than the gray value of the center pixel. If the number of bit-transitions in the circular bit-stream is less than or equal to 2, the center pixel is labeled as uniform. A look up table is generally used to compute the bit-transitions to reduce computational complexity. Uniform LBP was then defined in the following manner.  showing the circularly symmetric neighbor sets for different P and R [2].",{"@attributes":{"id":"p-0102","num":"0137"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":"LBP","mrow":{"mi":["P","R"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mo":"{","mrow":{"mrow":[{"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"p","mo":"=","mn":"0"},{"mi":"p","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mi":"s","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["g","p"]},{"mi":["g","c"]}],"mo":"-"}}}},"mo":","}},{"mrow":{"mrow":{"mi":"U","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},"mo":"\u2264","mn":"2"}}]},{"mtd":[{"mrow":{"mrow":{"mi":"P","mo":"+","mn":"1"},"mo":","}},{"mi":"otherwise"}]}]},"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}},"mrow":{"mi":"s","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}},{"mo":"{","mtable":{"mtr":[{"mtd":{"mrow":{"mn":"1","mo":",","mrow":{"mi":"x","mo":">","mn":"0"}}}},{"mtd":{"mrow":{"mn":"0","mo":",","mrow":{"mi":"x","mo":"\u2264","mn":"0."}}}}]}}],"mo":"="}}],"mo":"="}}}},"gis the gray value of the center voxel and gis the gray value of its neighbors. U(x) is the uniformity function calculated using the method described above. Multi-Scale analysis of the image using LBP is done by choosing circles with various radii around the center pixels and thus constructing separate LBP image for each scale. For our work, energy and entropy of the LBP image, constructed over different scales are then used as feature descriptors (see ).","Law's Mask Energy (LME) Feature","The Laws mask has evolved with the idea of representing image features without referring to the frequency domain [1]. The idea of inferring as what looks like where, instead of the conventional what happens where, is the essence of using this approach as a conjunction to the human visual perception [2]. Laws empirically determined that several masks of appropriate sizes were very informative for discriminating between different kinds of texture [3]. Originally, he classified samples based on expected values of variance-like square measures of these convolutions, called texture energy measures [3]. The texture energy measure is quantified using the three masks L3=[1, 2, 1], E3=[\u22121, 0, 1], and S3=[\u22121, 2,\u22121], for level, edge, and spot detection respectively. The appropriate convolution of these masks yield nine different combination of 3\u00d73 masks, of which we use the eight zero-sum masks. The image under inspection is filtered using these eight masks, and their energies are computed and used as the feature descriptor [2].","Trace Transform (TT) Feature","Trace transform is a generalized approach to the Radon transform, and consists of tracing an image with straight lines along which certain functional of the image function. The purpose of a functional is to characterize a function by a number. Different functionals are used for representation of rotation, translation and scaling invariant features of an image, construction of features that may correlate well with the visual texture (A. Kadyrov, and M. Petrou, \u201cThe trace transform and its applications,\u201d , vol. 23, no. 8, pp. 811-828, August 2001). Let the studied image be scanned with lines in all directions. Let A be the set of all these lines. The Trace transform can then be defined as a function g defined on \u0394 with the help of T which is some functional of the image function of variable t. T is called the trace functional. In order to define a triple feature, two more functionals designated by letters P and \u03a6 are defined. P, called the diametrical functional, is a functional of the Trace transform function when it is considered as a function of the length of the normal to the line only. \u03a6, called the circus functional, is a functional operating on the orientation variable, after the previous two operations (use of T and P) have been performed. Thus, the triple feature can be defined as\n\n\u03a0()=\u03a6(((())))\u2003\u2003(TT-1)\n\n","Gray Level Co-occurrence Matrix (GLCM) represents second-order texture moments, and it is made up of the frequency of appearance of a gray level in a specified linear relationship with another gray level within the neighborhood of interest. The Fuzzy GLCM (FGLCM) [24] of an image I of size L\u00d7L is given by:\n\n()=[]\u2003\u2003(F-4)\n\n",{"@attributes":{"id":"p-0107","num":"0146"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":"Energy","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["E","fuzzy"]}},{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","msup":{"mrow":{"mo":["[","]"],"mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}},"mn":"2"}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"5"}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"Contrast","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["C","fuzzy"]}},{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":"-"}},"mn":"2"},"mo":"\u2062","mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"6"}}}]},{"mtd":[{"mrow":{"mi":"Homogeneity","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["G","fuzzy"]},"mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mfrac":{"mrow":[{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},{"mn":"1","mo":"+","msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":"-"}},"mn":"2"}}]}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"7"}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"Entropy","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["H","fuzzy"]}},{"mo":"-","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"mrow":[{"mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},"mo":"\u00b7","mi":"ln"},{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"8"}}}]},{"mtd":[{"mrow":{"mrow":{"mrow":{"mi":"Correlation","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["Corr","fuzzy"]}},"mo":"=","mfrac":{"mrow":[{"mrow":[{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"mo":["[","]"],"mrow":{"msub":{"mi":["mnF","d"]},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}},{"msub":[{"mi":["\u03bc","m"]},{"mi":["\u03bc","u"]}],"mo":"\u2062"}],"mo":"-"},{"msub":[{"mi":["\u03c3","m"]},{"mi":["\u03c3","n"]}],"mo":"\u2062"}]}},"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}},"mi":"where"}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"9"}}}]},{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["\u03bc","m"]},"mo":"=","mrow":{"mo":"\u2211","mrow":{"mi":"m","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}},{"msubsup":{"mi":["\u03c3","m"],"mn":"2"},"mo":"=","mrow":{"mrow":{"mo":"\u2211","mrow":{"msup":{"mi":"m","mn":"2"},"mo":"\u2062","mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}},"mo":"-","msubsup":{"mi":["\u03bc","m"],"mn":"2"}}}],"mo":","}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"10"}}}]},{"mtd":[{"mrow":{"mrow":[{"mrow":[{"msub":{"mi":["\u03bc","m"]},"mo":"=","mrow":{"mo":"\u2211","mrow":{"mi":"n","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}},{"msubsup":{"mi":["\u03c3","n"],"mn":"2"},"mo":"=","mrow":{"mrow":{"mo":"\u2211","mrow":{"msup":{"mi":"n","mn":"2"},"mo":"\u2062","mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}},"mo":"-","msubsup":{"mi":["\u03bc","n"],"mn":"2"}}}],"mo":","},{"mrow":[{"mi":"Moments","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"msub":{"mi":"M","mn":"1"}},{"mi":"and","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"msub":{"mi":"M","mn":"4"},"mo":":"}}],"mo":[",",",",","],"msub":[{"mi":"M","mn":"2"},{"mi":"M","mn":"3"}]}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"11"}}}]},{"mtd":[{"mrow":{"msubsup":{"mi":["M","fuzzy","g"]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":"-"}},"mi":"g"},"mo":"\u2062","mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"12"}}}]}]}}},"ul":{"@attributes":{"id":"ul0012","list-style":"none"},"li":{"@attributes":{"id":"ul0012-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0013","list-style":"none"},"li":"The similarity between two pixels that are (\u0394m,\u0394n) apart is measured by the homogeneity feature. On the contrary, the local variation between those two pixels is captured by the contrast feature. The denseness and the degree of disorder in an image are measured by energy and entropy features. The entropy feature will have a maximum value when all elements of the co-occurrence matrix are the same. Difference statistics is defined as \u201cthe distribution of the probability that the gray-level difference is k between the points separated by \u03b4 in an image\u201d (F. Tomita and S. Tsuji, . Kluwer Academic Publishers, Boston, 1990). The difference statistics vector being a subset of the fuzzy co-occurrence matrix can be obtained from FGLCM as:"}}}},{"@attributes":{"id":"p-0108","num":"0148"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"munder":{"mrow":[{"munder":[{"mo":"\u2211","mi":"m"},{"mo":"\u2211","mi":"n"}],"mo":"\u2062"},{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":["m","n"],"mo":"-"}},"mo":"=","mi":"k"}]},"mo":"\u2062","mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"13"}}}]}}}},"br":{},"i":"Pattern Recogn., vol. "},{"@attributes":{"id":"p-0109","num":"0149"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["Angular","Second","Moment"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["ASM","diff"]}},{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"-","mn":"0"},{"mi":"c","mo":"-","mn":"1"}]},"mo":"\u2062","msup":{"mrow":{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},"mn":"2"}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"14"}}}]}}}},"ul":{"@attributes":{"id":"ul0014","list-style":"none"},"li":{"@attributes":{"id":"ul0014-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0015","list-style":"none"},"li":"When the F(k) values are very similar or close, ASM is small. ASM is large when certain values are high and others are low."}}}},{"@attributes":{"id":"p-0110","num":"0151"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"Mean","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["\u03bc","diff"]}},{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"-","mn":"0"},{"mi":"c","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"msub":{"mi":["kF","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"15"}}}]}}}},"ul":{"@attributes":{"id":"ul0016","list-style":"none"},"li":{"@attributes":{"id":"ul0016-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0017","list-style":"none"},"li":"When F(k) values are concentrated near the origin, mean is small and mean is large when they are far from the origin."}}}},{"@attributes":{"id":"p-0111","num":"0153"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"Contrast","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["C","diff"]}},{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"-","mn":"1"},{"mi":"c","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"msup":{"mi":"k","mn":"2"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"16"}}}]}}}},"ul":{"@attributes":{"id":"ul0018","list-style":"none"},"li":{"@attributes":{"id":"ul0018-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0019","list-style":"none"},"li":"Contrast is also known as the second moment of F(its moment of inertia about the origin)."}}}},{"@attributes":{"id":"p-0112","num":"0155"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"Entropy","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["H","diff"]}},{"mo":"-","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"-","mn":"0"},{"mi":"c","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":["\u2062","\u2062","\u2062"],"mi":"log","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"17"}}}]}}}},"ul":{"@attributes":{"id":"ul0020","list-style":"none"},"li":{"@attributes":{"id":"ul0020-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0021","list-style":"none"},"li":["Entropy is smallest when F(k) values are unequal, and largest when F(k) values are equal. Entropy is directly proportional to unpredictability.","The above mentioned features were calculated for \u03b4=(0, 1), (1, 1), and (1, 0), and the total mean values for the four features were taken.","The FGLCM contains information about the positions of pixels having similar gray level values, and hence, the features in Eqns. (F-5 to F-12) quantify this information. However, the difference statistics based features (Eqns. F-13 to Eqns. F-17)) are derived from the vector based on absolute differences between pairs of gray levels. Even though the definitions of features like contrast (Eq. (F-6) and Eq. (F-16)) and entropy (Eq. (F-8) and Eq. (F-17)) are similar, they are calculated on different matrices\/vectors that quantify the texture of the image in different ways.\n\nFuzzy Run Length Matrix (FRLM)\n"]}}}},"The run length matrix, F(m,n) consists of the number of elements where gray level value i has the run length j continuous in direction \u03b8. Often the direction \u03b8 is set as 0\u00b0, 45\u00b0, 90\u00b0, and 135\u00b0 (M. M. Galloway, \u201cTexture analysis using gray level run lengths,\u201d , vol. 4, no. 2, pp. 172-179, 1975 and K. V. Ramana and B. Ramamoorthy, \u201cStatistical methods to compare the texture features of machined surfaces,\u201d , vol. 29, pp. 1447-1459, 1996). The features listed below were calculated for analysis and classification:","Fuzzy Short Run Emphasis:",{"@attributes":{"id":"p-0114","num":"0160"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["SRE","fuzzy"]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"mfrac":{"mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},"msup":{"mi":"n","mn":"2"}},"mo":"\/","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"18"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0115","num":"0161"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["LRE","fuzzy"]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msup":{"mi":"n","mn":"2"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}],"mo":"\/"}}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"19"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0116","num":"0162"},"maths":{"@attributes":{"id":"MATH-US-00019","num":"00019"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["GLNU","fuzzy"]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["{","}"],"mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}},"mn":"2"},"mo":"\/","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"20"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0117","num":"0163"},"maths":{"@attributes":{"id":"MATH-US-00020","num":"00020"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["RLNU","fuzzy"]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["{","}"],"mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}},"mn":"2"},"mo":"\/","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"21"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0118","num":"0164"},"maths":{"@attributes":{"id":"MATH-US-00021","num":"00021"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["RP","fuzzy"]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":["F","q"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},"mo":"\/","mi":"A"}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"22"}}}]}}}},"ul":{"@attributes":{"id":"ul0022","list-style":"none"},"li":{"@attributes":{"id":"ul0022-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0023","list-style":"none"},"li":"where A is the area of the image of interest.\n\nWall Variability (WV):\n"}}}},"This is computed by measuring the standard deviation of the IMT from the longitudinal ultrasound image. As mentioned in the previous section, AtheroEdge\u2122 algorithm was employed to determine the LI and MA borders. In order to calculate the distance between LI and MA borders (IMT), the Polyline Distance Measure (PDM) was used. PDM is based on vector calculus, and in this method, we measure the distance of each vertex of one boundary to the segments of the second boundary.\n\n",{"@attributes":{"id":"p-0120","num":"0168"},"maths":{"@attributes":{"id":"MATH-US-00022","num":"00022"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["v","s"],"mo":","}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"msub":{"mi":"d","mo":"\u22a5"}},{"mrow":{"mn":["0","1"],"mo":["\u2264","\u2264"],"mi":"\u03bb"}}]},{"mtd":[{"mrow":{"mi":"min","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"d","mn":"1"},{"mi":"d","mn":"2"}],"mo":","}}}},{"mrow":{"mrow":[{"mi":"\u03bb","mo":"<","mn":"0"},{"mi":"\u03bb","mo":">","mn":"1"}],"mo":","}}]}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"19"}}]}}}},"br":{},"sub":["1 ","2 ","1 "]},"The polyline distance from vertex v to the boundary Bcan be defined as",{"@attributes":{"id":"p-0122","num":"0170"},"maths":{"@attributes":{"id":"MATH-US-00023","num":"00023"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"v","mo":",","msub":{"mi":"B","mn":"2"}}}},{"munder":{"mi":"min","mrow":{"mi":"v","mo":"\u2208","msub":{"mi":"B","mn":"2"}}},"mo":"\u2062","mrow":{"mrow":{"mo":["{","}"],"mrow":{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["v","s"],"mo":","}}}},"mo":"."}}],"mo":"="}}},"br":{},"sub":["1 ","2 ","1 ","2"]},{"@attributes":{"id":"p-0123","num":"0171"},"maths":{"@attributes":{"id":"MATH-US-00024","num":"00024"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mi":"v","mo":"\u2208","msub":{"mi":"B","mn":"1"}}},"mo":"\u2062","mrow":{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"v","mo":",","msub":{"mi":"B","mn":"2"}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"20"}}]}}}},"br":{},"sub":["2","1","2 ","1"]},{"@attributes":{"id":"p-0124","num":"0172"},"maths":{"@attributes":{"id":"MATH-US-00025","num":"00025"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}},"mo":"=","mfrac":{"mrow":[{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}},{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"2"},{"mi":"B","mn":"1"}],"mo":","}}}],"mo":"+"},{"mo":["(",")"],"mrow":{"mrow":[{"mi":["#","of","vertices","of"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":"B","mn":"1"}},{"mi":["#","of","vertices","of"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":"B","mn":"2"}}],"mo":"+"}}]}}},{"mrow":{"mn":"21","mo":")"}}]}}}},"br":{},"sub":["1 ","2 ","1","2"]},{"@attributes":{"id":"p-0125","num":"0173"},"maths":{"@attributes":{"id":"MATH-US-00026","num":"00026"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msup":{"mi":"\u03c3","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mi":"v","mo":"\u2208","msub":{"mi":"B","mn":"1"}}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"v","mo":",","msub":{"mi":"B","mn":"2"}}}},{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}}],"mo":"-"}},"mn":"2"}}],"mo":"="}},{"mrow":{"mo":"(","mn":"22"}}]},{"mtd":[{"mrow":{"mrow":[{"msup":{"mi":"\u03c3","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"2"},{"mi":"B","mn":"1"}],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mi":"v","mo":"\u2208","msub":{"mi":"B","mn":"2"}}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"v","mo":",","msub":{"mi":"B","mn":"1"}}}},{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"2"},{"mi":"B","mn":"1"}],"mo":","}}}],"mo":"-"}},"mn":"2"}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"23"}}]}]}}},"br":{},"sub":"poly "},{"@attributes":{"id":"p-0126","num":"0174"},"maths":{"@attributes":{"id":"MATH-US-00027","num":"00027"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["IMTV","poly"]},"mo":"=","msqrt":{"mfrac":{"mrow":[{"mrow":[{"msup":{"mi":"\u03c3","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}},{"msup":{"mi":"\u03c3","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"2"},{"mi":"B","mn":"1"}],"mo":","}}}],"mo":"+"},{"mrow":[{"mi":["#","vertices","of"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":"B","mn":"1"}},{"mi":["#","vertices","of"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":"B","mn":"2"}}],"mo":"+"}]}}}},{"mrow":{"mo":["(",")"],"mn":"24"}}]}}}}},"The key advantage of using PDM over other IMT measurement techniques is that the measured distance is robust because it is independent of the number of points on each boundary. More details on the centerline vs. polyline will be discussed ahead. This variability is the wall thickness variability in MR or CT or 3D carotid Ultrasound or 3D IVUS.","In the various embodiments described herein, a CAD system for symptomatic vs. Asymptomatic patient image classification and computing the cardiovascular risk score based on the grayscale features of atherosclerotic wall. The image classification is a training-based system using cross-modality a priori knowledge binary information for training the classifier off-line. The on-line system consists of Atherosclerotic Wall Region estimation using AtheroEdge\u2122 for longitudinal Ultrasound (or Athero-CTView\u2122 for CT) or (Athero-MRView for MR) or AtheroEdge3D (for 3D carotid Ultrasound). This grayscale Wall Region is then fed to a feature extraction processor which computes features using: (a) Higher Order Spectra; (b) Discrete Wavelet Transform (DWT); (c) Texture and (d) Wall Variability. In another methodology used here is to compute the grayscale features in the Atherosclerotic Wall Region such as: Local Binary Pattern (LBP) and Laws Mask Energy (LME) and Wall Variability.","The output of the Feature Processor is fed to the Classifier which is trained off-line from the database of similar Atherosclerotic Wall Region images. The off-line Classifier is trained from the significant features from (a) Higher Order Spectra; (b) Discrete Wavelet Transform (DWT); (c) Texture and (d) Wall Variability, selected using t-test. Symptomatic ground truth information about the training patients is drawn from cross modality imaging such as CT or MR or 3D carotid ultrasound or 3D IVUS in the form of binary information such as 0 or 1. Support Vector Machine (SVM) supervised classifier of varying kernel functions is used off-line for training. The obtained training parameters are then used to evaluate the test set. The system also yields the risk score value on the basis of the four set of wall features. The proposed technique demonstrates that plaque classification between symptomatic vs. asymptomatic could be achieved with a completely automated CAD tool with a significant accuracy. Performance of the system is evaluated by computing the accuracy, sensitivity, specificity, and Positive Predictive Value (PPV).",{"@attributes":{"id":"p-0130","num":"0178"},"figref":"FIG. 1"},"Thus the overall system (off-line and on-line) is flexible for any of the three imaging modalities: Ultrasound, CT, MR, while the binary information used for training the off-line classifier can be any. The off-line system must be trained on the same system on which the on-line operates, while the binary information used for training the off-line system can be derived from any sources such as longitudinal Ultrasound, or 3D ultrasound or MR or CT.",{"@attributes":{"id":"p-0132","num":"0180"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0133","num":"0181"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0134","num":"0182"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0135","num":"0183"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0136","num":"0184"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0137","num":"0185"},"figref":"FIG. 6B"},{"@attributes":{"id":"p-0138","num":"0186"},"figref":"FIG. 6C"},"On-line HOS Processor:","Higher Order Spectra or polyspectra allow one to study the non-linear behavior of a process. Higher order statistics denote higher order moments (order greater than two) and non-linear combinations of higher order moments, called the higher order cumulants. In the case of a Gaussian process, all cumulant moments of order greater than two are zero. Hence, such cumulants can be used to evaluate how much a process deviates from Gaussian behavior. One of the most commonly used HOS parameter is the bispectrum. The bispectrum is the spectrum of the third order cumulant, and is a complex valued function of two frequencies given by the following equation:\n\n()=()()*()]\u2003\u2003(I)\n\nwhere X(f) is the Fourier transform of the signal studied. As per the equation, the bispectrum is the product of the three Fourier coefficients. The function exhibits symmetry, and is computed in the non-redundant\/principal domain region \u03a9 as shown in .\n","Principal domain region (\u03a9) used for the computation of the bispectrum for real signals.","The bispectrum phase entropy obtained from the bispectrum is used as one of the features in this application. This entropy is defined as:","Bispectrum Phase Entropy:\n\nePRes=\u03a3(\u03c8)log (\u03c8)\u2003\u2003(2)\n\nwhere\n\n(\u03c8)=\u03a3(\u03c6(())\u2208 \u03c8)\u2003\u2003(3)\n\n\u03c8={\u03c6|\u2212\u03c0+22\u03c0(1)\/\n\n0,11\u2003\u2003(4)\n\nwhere L is the number of points within the region \u03a9, \u03c6 is the phase angle of the bispectrum, and l(.) is an indicator function which gives a value of 1 when the phase angle is within the range depicted by \u03c8in equation (4).\n","In order to calculate the bispectrum, and hence, the phase entropy, the pre-processed ultrasound plaque region images were first subjected to Radon transform. This transform computes line integrals along many parallel paths in the image from different angles \u03b8 by rotating the image around its centre. Such a transformation projects the intensity of the pixels along these lines into points in the resultant transformed signal. Thus, Radon transform converts an image into a one-dimensional signal at various angles. In this study, we calculated the Radon transformed signals for every 1\u00b0 step size and then determined the phase entropy of these signals. The system computes two bi-spectral entropies from the Radon transformed signals. These entropies are defined as follows.","Normalized Bi-spectral Entropy (e1Res):",{"@attributes":{"id":"p-0143","num":"0191"},"maths":{"@attributes":{"id":"MATH-US-00028","num":"00028"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":["e","Res"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mn":"1"},{"mo":"-","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":[{"mi":["p","i"]},{"mi":["p","i"]}],"mo":["\u2062","\u2062","\u2062"],"mi":"log","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":"="},"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}},"mi":"where"}},{"mrow":{"mo":["(",")"],"mn":"5"}}]},{"mtd":[{"mrow":{"msub":{"mi":["p","i"]},"mo":"=","mfrac":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"mi":"B","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"f","mn":"1"},{"mi":"f","mn":"2"}],"mo":","}}}},{"munder":{"mo":"\u2211","mi":"\u03a9"},"mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"B","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"f","mn":"1"},{"mi":"f","mn":"2"}],"mo":","}}}}}]}}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}]}}},"br":{}},{"@attributes":{"id":"p-0144","num":"0192"},"maths":{"@attributes":{"id":"MATH-US-00029","num":"00029"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":["e","Res"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mn":"2"},{"mo":"-","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":[{"mi":["p","n"]},{"mi":["p","n"]}],"mo":["\u2062","\u2062","\u2062"],"mi":"log","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":"="},"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}},"mi":"where"}},{"mrow":{"mo":["(",")"],"mn":"7"}}]},{"mtd":[{"mrow":{"msub":{"mi":["p","n"]},"mo":"=","mfrac":{"msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"B","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"f","mn":"1"},{"mi":"f","mn":"2"}],"mo":","}}}},"mn":"2"},"mrow":{"munder":{"mo":"\u2211","mi":"\u03a9"},"mo":"\u2062","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"B","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"f","mn":"1"},{"mi":"f","mn":"2"}],"mo":","}}}},"mn":"2"}}}}},{"mrow":{"mo":["(",")"],"mn":"8"}}]}]}}},"br":{}},"Discrete Wavelet Transform (DWT) is a transform that captures both the time and frequency information of the signal. DWT analyzes the atherosclerotic wall longitudinal ultrasound image (or Atherosclerotic Wall region image of MR, CT, 3D Carotid Ultrasound or 3D IVUS) by decomposing it into coarse approximation via low-pass filtering and into detail information via high-pass filtering. Such decomposition is done recursively on the low-pass approximation coefficients obtained at each level, until the necessary iterations are reached.","Let each atherosclerotic wall region longitudinal image (or Atherosclerotic Wall region image of MR, CT, 3D Carotid Ultrasound or 3D IVUS) be represented as a p\u00d7q grayscale matrix I[i,j], where each element of the matrix represents the grayscale intensity of one pixel of the image. Each non-border pixel has eight adjacent neighboring pixel intensities. These eight neighbors can be used to traverse through the matrix. The resultant 2D-DWT coefficients will be the same irrespective of whether the matrix is traversed right to left or left to right. Hence, it is sufficient that we consider four decomposition directions corresponding to 0\u00b0 (horizontal, Dh), 90\u00b0 (vertical, Dv) and 45\u00b0 or 135\u00b0 (diagonal, Dd) orientation. The decomposition structure for one level is illustrated in the diagram below. I is the image, g[n] and h[n] are the low-pass and high-pass filters, respectively and A is the approximation coefficients. In this work, the results from level I were found to yield significant features.  shows the 2D DWT decomposition. 2ds1 indicates that rows are down sampled by 2 and columns by 1. 1ds2 indicates that rows are down sampled by 1 and columns by 2. \u2018\u00d7\u2019 operator indicates convolution operation.","As is evident from the diagram above, the first level of decomposition results in four coefficient matrices, namely, A, Dh, Dv, and Dd. Since the number of elements in these matrices is high, and since we only need a single number as a representative feature, we employed averaging methods to determine such single-valued features. The following are the definitions of the three features that were determined using the DWT coefficients.",{"@attributes":{"id":"p-0148","num":"0196"},"maths":{"@attributes":{"id":"MATH-US-00030","num":"00030"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":["Average","Dh"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mn":"1"},{"mfrac":{"mn":"1","mrow":{"mi":["p","q"],"mo":"\u00d7"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"x","mo":"=","mrow":{"mo":["<",">"],"mi":"p"}}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"y","mo":"=","mrow":{"mo":["<",">"],"mi":"q"}}},"mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"Dh","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"9"}}]},{"mtd":[{"mrow":{"mrow":[{"mi":["Average","Dv"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mn":"1"},{"mfrac":{"mn":"1","mrow":{"mi":["p","q"],"mo":"\u00d7"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"x","mo":"=","mrow":{"mo":["<",">"],"mi":"p"}}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"y","mo":"=","mrow":{"mo":["<",">"],"mi":"q"}}},"mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"Dv","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"10"}}]},{"mtd":[{"mrow":{"mi":"Energy","mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"msup":[{"mi":"p","mn":"2"},{"mi":"q","mn":"2"}],"mo":"\u00d7"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"x","mo":"=","mrow":{"mo":["<",">"],"mi":"p"}}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"y","mo":"=","mrow":{"mo":["<",">"],"mi":"q"}}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":"Dv","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},"mn":"2"}}}}}},{"mrow":{"mo":["(",")"],"mn":"11"}}]}]}}}},"Equations (9) and (10) calculate averages of the corresponding intensity values, whereas equation (11) is an averaging of the energy of the intensity values. For the Atherosclerotic Wall region image of MR, CT, 3D Carotid Ultrasound or 3D IVUS, same features, Average Dh, Average v and Energy are computed which are then used for classification and risk score estimation.","On-line Texture Processor:","The texture of an image is characterized by the regular repletion of patterns in the image. There are several approaches to analyzing the textural properties, and in this work, we studied the statistical textural features that are based on the relationship and distribution of pixel intensities. Consider \u03c6(i) as the number of pixels with intensity value i, ranging from 1 to n. Let A be the area of the image. The probability of intensity i in the image is given by:",{"@attributes":{"id":"p-0151","num":"0199"},"maths":{"@attributes":{"id":"MATH-US-00031","num":"00031"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mo":"=","mfrac":{"mrow":{"mi":"\u03c6","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},"mi":"A"}}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}},"br":{}},{"@attributes":{"id":"p-0152","num":"0200"},"maths":{"@attributes":{"id":"MATH-US-00032","num":"00032"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"Deviation","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["i","\u03bc"],"mo":"-"}},"mn":"2"},"mo":"\u2062","mrow":{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}}}}},{"mrow":{"mo":["(",")"],"mn":"13"}}]}}}},"br":{}},"Next, two matrices, namely, the Gray Level Co-occurrence Matrix (GLCM) and the Run Length Matrix were determined based on the pixel intensities, and features were extracted from these matrices. They are defined as follows.","Gray Level Co-occurrence Matrix","The GLCM of an image I of size m\u00d7n is given by",{"@attributes":{"id":"p-0154","num":"0202"},"maths":{"@attributes":{"id":"MATH-US-00033","num":"00033"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["C","d"]},"mo":"=","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mo":["{","}"],"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mi":["p","q"],"mo":","}},{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mrow":[{"mi":"p","mo":"+","mrow":{"mi":["\u0394","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mi":"q","mo":"+","mrow":{"mi":["\u0394","y"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":","}},{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["p","q"],"mo":","}}}],"mo":":"},"mo":"=","mi":"i"}],"mo":[",",","]}}},{"mtd":{"mrow":{"mrow":{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"p","mo":"+","mrow":{"mi":["\u0394","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mi":"q","mo":"+","mrow":{"mi":["\u0394","y"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":","}}},"mo":"=","mi":"j"}}}]}}}}},{"mrow":{"mo":["(",")"],"mn":"14"}}]}}}},"br":{}},{"@attributes":{"id":"p-0155","num":"0203"},"maths":{"@attributes":{"id":"MATH-US-00034","num":"00034"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},"mo":"=","mfrac":{"mrow":[{"msub":{"mi":["C","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mo":["\u2329","\u232a"],"mi":"i"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mo":["\u2329","\u232a"],"mi":"j"}},"mo":"\u2062","mrow":{"msub":{"mi":["C","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}]}}},{"mrow":{"mo":["(",")"],"mn":"15"}}]}}}},"br":{}},{"@attributes":{"id":"p-0156","num":"0204"},"maths":{"@attributes":{"id":"MATH-US-00035","num":"00035"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"Symmetry","mo":"=","mrow":{"mn":"1","mo":"-","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"msub":{"mo":"\uf603","mi":"c"},"mo":["\u2062","\uf604"],"mrow":{"mrow":[{"msub":{"mi":["C","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"msub":{"mi":["C","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["j","i"],"mo":","}}}],"mo":["\u2062","\u2062"],"msub":{"mo":"-","mi":"c"}}}}}}}},{"mrow":{"mo":["(",")"],"mn":"16"}}]},{"mtd":[{"mrow":{"mi":"Entropy","mo":"=","mrow":{"mo":"-","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"mi":"ln","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}],"mo":"\u00d7"}}}}}},{"mrow":{"mo":["(",")"],"mn":"17"}}]}]}}}},"Entropy, which denotes the degree of disorder in an image, will have high value if the elements in the GLCM are the same.","Run Length Matrix:","The run length matrix Pconsists of all the elements where the intensity value i has the run length j continuous in direction \u03b8. Typically values of \u03b8 are 0\u00b0, 45\u00b0, 90\u00b0, or 135\u00b0. The feature called Run Length Non-uniformity (RLnU) is then determined as follows.",{"@attributes":{"id":"p-0159","num":"0207"},"maths":{"@attributes":{"id":"MATH-US-00036","num":"00036"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"RLnU","mo":"=","mrow":{"munder":{"mo":"\u2211","mrow":{"mo":["\u2329","\u232a"],"mi":"j"}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"munder":{"mo":"\u2211","mrow":{"mo":["\u2329","\u232a"],"mi":"i"}},"mo":"\u2062","mrow":{"msub":{"mi":["P","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}},"mn":"2"}}}},{"mrow":{"mo":["(",")"],"mn":"18"}}]}}}}},"Since RLnU measures the similarity of the run lengths, its value will be less if the run lengths are uniform throughout the image. For the Atherosclerotic Wall region image of MR, CT, 3D Carotid Ultrasound or 3D IVUS, same features, Symmetry, Entropy, RLnU are estimated from Gray Level Co-occurrence Matrix (GLCM) and the Run Length Matrix. They are based on the pixel intensities computed in the wall region between the lumen border and outer wall border. These texture features are then used for classification and risk score estimation.","LBP Feature","Local Binary Pattern (LBP): Local Binary Pattern (LBP) has been established as a robust and efficient texture descriptor and was first presented by Ojala et al. (1996, 2002). LBP has been successfully applied to a wide range of different applications from texture segmentation (Liao et al. 2009) to face recognition (Zhang et al. 2010). The LBP feature vector, in its simplest form, is determined using the following method.","A circular neighborhood is considered around a pixel. P points are chosen on the circumference of the circle with radius R such that they are all equidistant from the center pixel. The gray values at points on the circular neighborhood that do not coincide exactly with pixel locations are estimated by interpolation. Let gbe the gray value of the centre pixel and g, p=0, . . . , P\u22121, corresponds to the gray values of the P points. These P points are converted into a circular bit-stream of 0s and 1s according to whether the gray value of the pixel is less than or greater than the gray value of the center pixel.  circularly symmetric neighbor sets for different values of P and R.","Ojala et al. (2002) introduced the concept of uniformity in texture analysis. They did so by classifying each pixel as uniform or non-uniform and used the uniform pixels for further computation of texture descriptor. These \u201cuniform\u201d fundamental patterns have a uniform circular structure that contains very few spatial transitions U (number of spatial bitwise 0\/1 transitions), and thus, function as templates for microstructures such as bright spot (U=0), flat area or dark spot (U=8), and edges of varying positive and negative curvature (U=1\u22127). Therefore, a rotation invariant measure called LBPusing uniformity measure U is calculated based on the number of transitions in the neighborhood pattern. Only patterns with U<2 are assigned the LBP code as depicted in equation (3) i.e. if the number of bit-transitions in the circular bit-stream is less than or equal to 2, the centre pixel is labelled as uniform. A look up table is generally used to compute the bit-transitions to reduce computational complexity.",{"@attributes":{"id":"p-0164","num":"0212"},"maths":{"@attributes":{"id":"MATH-US-00037","num":"00037"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"LBP","mrow":{"mi":["P","R"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mo":"{","mrow":{"mrow":[{"mtable":{"mtr":[{"mtd":[{"mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"p","mo":"=","mn":"0"},{"mi":"P","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mi":"s","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["g","p"]},{"mi":["g","c"]}],"mo":"-"}}}}},{"mrow":{"mrow":{"mi":"if","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":"U","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}},"mo":"\u2264","mn":"2"}}]},{"mtd":[{"mrow":{"mi":"P","mo":"+","mn":"1"}},{"mi":"otherwise"}]}]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mtext":{}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"where","mrow":{"mi":"s","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mn":"1","mo":","}},{"mrow":{"mi":"x","mo":"\u2265","mn":"0"}}]},{"mtd":[{"mrow":{"mn":"0","mo":","}},{"mrow":{"mi":"x","mo":"<","mn":"0"}}]}]}}],"mo":"="}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}}},"Multi-scale analysis of the image using LBP is done by choosing circles with various radii around the centre pixels and thus constructing separate LBP image for each scale. In our work, energy and entropy of the LBP image, constructed over different scales (R=1, 2, and 3 with the corresponding pixel count P being 8, 16, and 24, respectively) were used as feature descriptors.","Law's Musk Energy (LME) Feature","Laws mask has evolved with the idea of representing image features without referring to the frequency domain (Gupta and Undrill 1995). The idea of inferring as what looks like where, instead of the conventional what happens where, is the essence of using this approach as a conjunction to the human visual perception (Petrou and Sevilla 1980). Laws empirically determined that several masks of appropriate sizes were very informative for discriminating between different kinds of texture (Laws 1980). Originally, he classified samples based on expected values of variance-like square measures of these convolutions, called texture energy measures (Laws 1980). The texture energy measure is quantified using the three masks L=[1, 2, 1], E=[\u22121, 0, 1], and S=[\u22121, 2, \u22121], for level, edge, and spot detection, respectively. The appropriate convolution of these masks yield nine different combination of 3\u00d73 masks, of which we use the eight zero-sum masks numbered 1 to 8. The image under inspection is filtered using these eight masks, and their energies are computed and used as the feature descriptor (Petrou and Sevilla 1980). A more detailed analysis of applications of Law's texture can be seen in the recent book by Mermehdi et al. (2008).","On Line Trace Transform Processor","Trace transform is a generalized approach to the Radon transform, and consists of tracing an image with straight lines along which certain functional of the image function. The purpose of a functional is to characterize a function by a number. Different functionals are used for representation of rotation, translation and scaling invariant features of an image, construction of features that may correlate well with the visual texture (A. Kadyrov, and M. Petrou, \u201cThe trace transform and its applications,\u201d , vol. 23, no. 8, pp. 811-828, August 2001). Let the studied image be scanned with lines in all directions. Let A be the set of all these lines. The Trace transform can then be defined as a function g defined on A with the help of T which is some functional of the image function of variable t. T is called the trace functional. In order to define a triple feature, two more functionals designated by letters P and \u03a6 are defined. P, called the diametrical functional, is a functional of the Trace transform function when it is considered as a function of the length of the normal to the line only. \u03a6, called the circus functional, is a functional operating on the orientation variable, after the previous two operations (use of T and P) have been performed. Thus, the triple feature can be defined as\n\n\u03a0()=\u03a6(((())))\u2003\u2003(TT-1)\n\n","Gray Level Co-occurrence Matrix (GLCM) represents second-order texture moments, and it is made up of the frequency of appearance of a gray level in a specified linear relationship with another gray level within the neighborhood of interest. The Fuzzy GLCM (FGLCM) [24] of an image I of size L\u00d7L is given by:\n\n()=[]\u2003\u2003(F-4)\n\n",{"@attributes":{"id":"p-0169","num":"0221"},"maths":{"@attributes":{"id":"MATH-US-00038","num":"00038"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":"Energy","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["E","fuzzy"]}},{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","msup":{"mrow":{"mo":["[","]"],"mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}},"mn":"2"}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"5"}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"Contrast","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["C","fuzzy"]}},{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":"-"}},"mn":"2"},"mo":"\u2062","mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"6"}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"Homogeneity","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["G","fuzzy"]}},{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mfrac":{"mrow":[{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},{"mn":"1","mo":"+","msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":"-"}},"mn":"2"}}]}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"7"}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"Entropy","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["H","fuzzy"]}},{"mo":"-","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"mrow":[{"mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},"mo":"\u00b7","mi":"ln"},{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"8"}}}]},{"mtd":[{"mrow":{"mrow":{"mrow":{"mi":"Correlation","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["Corr","fuzzy"]}},"mo":"=","mfrac":{"mrow":[{"mrow":[{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"mo":["[","]"],"mrow":{"msub":{"mi":["mnF","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}},{"msub":[{"mi":["\u03bc","m"]},{"mi":["\u03bc","n"]}],"mo":"\u2062"}],"mo":"-"},{"msub":[{"mi":["\u03c3","m"]},{"mi":["\u03c3","n"]}],"mo":"\u2062"}]}},"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}},"mi":"where"}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"9"}}}]},{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["\u03bc","m"]},"mo":"=","mrow":{"mo":"\u2211","mrow":{"mi":"m","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}},{"msubsup":{"mi":["\u03c3","m"],"mn":"2"},"mo":"=","mrow":{"mrow":{"mo":"\u2211","mrow":{"msup":{"mi":"m","mn":"2"},"mo":"\u2062","mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}},"mo":"-","msubsup":{"mi":["\u03bc","m"],"mn":"2"}}}],"mo":","}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"10"}}}]},{"mtd":[{"mrow":{"mrow":[{"mrow":[{"msub":{"mi":["\u03bc","n"]},"mo":"=","mrow":{"mo":"\u2211","mrow":{"mi":"n","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}},{"msubsup":{"mi":["\u03c3","n"],"mn":"2"},"mo":"=","mrow":{"mrow":{"mo":"\u2211","mrow":{"msup":{"mi":"n","mn":"2"},"mo":"\u2062","mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}},"mo":"-","msubsup":{"mi":["\u03bc","n"],"mn":"2"}}}],"mo":","},{"mrow":[{"mi":"Moments","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"msub":{"mi":"M","mn":"1"}},{"mi":"and","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"}],"msub":{"mi":"M","mn":"4"}}],"mo":[",",",",","],"msub":[{"mi":"M","mn":"2"},{"mi":"M","mn":"3"}]}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"11"}}}]},{"mtd":[{"mrow":{"msubsup":{"mi":["M","fuzzy","g"]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":"-"}},"mi":"g"},"mo":"\u2062","mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"12"}}}]}]}}},"ul":{"@attributes":{"id":"ul0030","list-style":"none"},"li":{"@attributes":{"id":"ul0030-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0031","list-style":"none"},"li":"The similarity between two pixels that are (\u0394m,\u0394n) apart is measured by the homogeneity feature. On the contrary, the local variation between those two pixels is captured by the contrast feature. The denseness and the degree of disorder in an image are measured by energy and entropy features. The entropy feature will have a maximum value when all elements of the co-occurrence matrix are the same. Difference statistics is defined as \u201cthe distribution of the probability that the gray-level difference is k between the points separated by \u03b4 in an image\u201d (F. Tomita and S. Tsuji, . Kluwer Academic Publishers, Boston, 1990). The difference statistics vector being a subset of the fuzzy co-occurrence matrix can be obtained from FGLCM as:"}}}},{"@attributes":{"id":"p-0170","num":"0223"},"maths":{"@attributes":{"id":"MATH-US-00039","num":"00039"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"munder":{"mrow":[{"munder":[{"mo":"\u2211","mi":"m"},{"mo":"\u2211","mi":"n"}],"mo":"\u2062"},{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":["m","n"],"mo":"-"}},"mo":"=","mi":"k"}]},"mo":"\u2062","mrow":{"msub":{"mi":["F","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"13"}}}]}}}},"br":{},"i":"Pattern Recogn."},{"@attributes":{"id":"p-0171","num":"0224"},"maths":{"@attributes":{"id":"MATH-US-00040","num":"00040"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["Angular","Second","Moment"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["ASM","diff"]}},{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"-","mn":"0"},{"mi":"c","mo":"-","mn":"1"}]},"mo":"\u2062","msup":{"mrow":{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},"mn":"2"}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"14"}}}]}}}},"ul":{"@attributes":{"id":"ul0032","list-style":"none"},"li":{"@attributes":{"id":"ul0032-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0033","list-style":"none"},"li":"When the F(k) values are very similar or close, ASM is small. ASM is large when certain values are high and others are low."}}}},{"@attributes":{"id":"p-0172","num":"0226"},"maths":{"@attributes":{"id":"MATH-US-00041","num":"00041"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"Mean","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["\u03bc","diff"]}},{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"-","mn":"0"},{"mi":"c","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"msub":{"mi":["kF","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"15"}}}]}}}},"ul":{"@attributes":{"id":"ul0034","list-style":"none"},"li":{"@attributes":{"id":"ul0034-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0035","list-style":"none"},"li":"When F(k) values are concentrated near the origin, mean is small and mean is large when they are far from the origin."}}}},{"@attributes":{"id":"p-0173","num":"0228"},"maths":{"@attributes":{"id":"MATH-US-00042","num":"00042"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"Contrast","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["C","diff"]}},{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"-","mn":"0"},{"mi":"c","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"msup":{"mi":"k","mn":"2"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"16"}}}]}}}},"ul":{"@attributes":{"id":"ul0036","list-style":"none"},"li":{"@attributes":{"id":"ul0036-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0037","list-style":"none"},"li":"Contrast is also known as the second moment of F(its moment of inertia about the origin)."}}}},{"@attributes":{"id":"p-0174","num":"0230"},"maths":{"@attributes":{"id":"MATH-US-00043","num":"00043"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"Entropy","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["H","diff"]}},{"mo":"-","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"-","mn":"0"},{"mi":"c","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":["\u2062","\u2062","\u2062"],"mi":"log","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"17"}}}]}}}},"ul":{"@attributes":{"id":"ul0038","list-style":"none"},"li":{"@attributes":{"id":"ul0038-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0039","list-style":"none"},"li":["Entropy is smallest when F(k) values are unequal, and largest when F(k) values are equal. Entropy is directly proportional to unpredictability.","The above mentioned features were calculated for \u03b4=(0, 1), (1, 1), and (1, 0), and the total mean values for the four features were taken.","The FGLCM contains information about the positions of pixels having similar gray level values, and hence, the features in Eqns. (F-5 to F-12) quantify this information. However, the difference statistics based features (Eqns. F-13 to Eqns. F-17)) are derived from the vector based on absolute differences between pairs of gray levels. Even though the definitions of features like contrast (Eq. (F-6) and Eq. (F-16)) and entropy (Eq. (F-8) and Eq. (F-17)) are similar, they are calculated on different matrices\/vectors that quantify the texture of the image in different ways.\n\nFuzzy Run Length matrix (FRLM)\n"]}}}},"The run length matrix, F(m,n) consists of the number of elements where gray level value i has the run length j continuous in direction \u03b8. Often the direction \u03b8 is set as 0\u00b0, 45\u00b0, 90\u00b0, and 135\u00b0 (M. M. Galloway, \u201c., vol. 4, no. 2, pp. 172-179, 1975 and K. V. Ramana and B. Ramamoorthy, \u201cStatistical methods to compare the texture features of machined surfaces,\u201d , vol. 29, pp. 1447-1459, 1996). The features listed below were calculated for analysis and classification:","Fuzzy Short Run Emphasis:",{"@attributes":{"id":"p-0176","num":"0235"},"maths":{"@attributes":{"id":"MATH-US-00044","num":"00044"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["SRE","fuzzy"]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"mfrac":{"mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},"msup":{"mi":"n","mn":"2"}},"mo":"\/","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"18"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0177","num":"0236"},"maths":{"@attributes":{"id":"MATH-US-00045","num":"00045"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["LRE","fuzzy"]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msup":{"mi":"n","mn":"2"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}],"mo":"\/"}}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"19"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0178","num":"0237"},"maths":{"@attributes":{"id":"MATH-US-00046","num":"00046"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["G","L","N"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"msub":{"mi":["U","fuzzy"]}},{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["{","}"],"mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}},"mn":"2"},"mo":"\/","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"20"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0179","num":"0238"},"maths":{"@attributes":{"id":"MATH-US-00047","num":"00047"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["R","L","N"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"msub":{"mi":["U","fuzzy"]}},{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["{","}"],"mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}},"mn":"2"},"mo":"\/","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"21"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0180","num":"0239"},"maths":{"@attributes":{"id":"MATH-US-00048","num":"00048"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["RP","fuzzy"]},"mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"m"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":["F","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},"mo":"\/","mi":"A"}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mn":"22"}}}]}}}},"ul":{"@attributes":{"id":"ul0040","list-style":"none"},"li":{"@attributes":{"id":"ul0040-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0041","list-style":"none"},"li":"where A is the area of the image of interest.\n\nOn-line Wall Variability Processor:\n"}}}},"This is computed by measuring the standard deviation of the IMT. As mentioned in the previous sections, AtheroEdge\u2122 algorithm was employed to determine the LI and MA borders. We will discuss the AtheroEdge\u2122 system for non-shadow ultrasound scans and with shadow ultrasound scans. In order to calculate the distance between LI and MA borders (IMT), the Polyline Distance Measure (PDM) was used. PDM is based on vector calculus, and in this method, we measure the distance of each vertex of one boundary to the segments of the second boundary.\n\n",{"@attributes":{"id":"p-0182","num":"0243"},"maths":{"@attributes":{"id":"MATH-US-00049","num":"00049"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["v","s"],"mo":","}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"msub":{"mi":"d","mo":"\u22a5"}},{"mrow":{"mn":["0","1"],"mo":["\u2264","\u2264"],"mi":"\u03bb"}}]},{"mtd":[{"mrow":{"mi":"min","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"d","mn":"1"},{"mi":"d","mn":"2"}],"mo":","}}}},{"mrow":{"mrow":[{"mi":"\u03bb","mo":"<","mn":"0"},{"mi":"\u03bb","mo":">","mn":"1"}],"mo":","}}]}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"19"}}]}}}},"br":{},"sub":["1 ","2 ","1 "]},"The polyline distance from vertex v to the boundary Bcan be defined as",{"@attributes":{"id":"p-0184","num":"0245"},"maths":{"@attributes":{"id":"MATH-US-00050","num":"00050"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"v","mo":",","msub":{"mi":"B","mn":"2"}}}},{"munder":{"mi":"min","mrow":{"mi":"x","mo":"\u2208","msub":{"mi":"B","mn":"2"}}},"mo":"\u2062","mrow":{"mrow":{"mo":["{","}"],"mrow":{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["v","s"],"mo":","}}}},"mo":"."}}],"mo":"="}}},"br":{},"sub":["1 ","2 ","1 ","2"]},{"@attributes":{"id":"p-0185","num":"0246"},"maths":{"@attributes":{"id":"MATH-US-00051","num":"00051"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mi":"v","mo":"\u2208","msub":{"mi":"B","mn":"1"}}},"mo":"\u2062","mrow":{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"v","mo":",","msub":{"mi":"B","mn":"2"}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"20"}}]}}}},"br":{},"sub":["2","1","2 ","1"]},{"@attributes":{"id":"p-0186","num":"0247"},"maths":{"@attributes":{"id":"MATH-US-00052","num":"00052"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}},"mo":"=","mfrac":{"mrow":[{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}},{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"2"},{"mi":"B","mn":"1"}],"mo":","}}}],"mo":"+"},{"mo":["(",")"],"mrow":{"mrow":[{"mi":["#","of","vertices","of"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":"B","mn":"1"}},{"mi":["#","of","vertices","of"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":"B","mn":"2"}}],"mo":"+"}}]}}},{"mrow":{"mo":["(",")"],"mn":"21"}}]}}}},"br":{},"sub":["1 ","2 ","1","2"]},{"@attributes":{"id":"p-0187","num":"0248"},"maths":{"@attributes":{"id":"MATH-US-00053","num":"00053"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msup":{"mi":"\u03c3","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mi":"v","mo":"\u2208","msub":{"mi":"B","mn":"1"}}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"v","mo":",","msub":{"mi":"B","mn":"2"}}}},{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}}],"mo":"-"}},"mn":"2"}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"22"}}]},{"mtd":[{"mrow":{"mrow":[{"msup":{"mi":"\u03c3","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"2"},{"mi":"B","mn":"1"}],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mi":"v","mo":"\u2208","msub":{"mi":"B","mn":"2"}}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"v","mo":",","msub":{"mi":"B","mn":"1"}}}},{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"2"},{"mi":"B","mn":"1"}],"mo":","}}}],"mo":"-"}},"mn":"2"}}],"mo":"="}},{"mrow":{"mrow":[{"mi":["l","l"],"mo":"."},{"mo":["(",")"],"mn":"23"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}}]}]}}},"br":{},"sub":"poly "},{"@attributes":{"id":"p-0188","num":"0249"},"maths":{"@attributes":{"id":"MATH-US-00054","num":"00054"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["IMTV","poly"]},"mo":"=","msqrt":{"mfrac":{"mrow":[{"mrow":[{"msup":{"mi":"\u03c3","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"1"},{"mi":"B","mn":"2"}],"mo":","}}},{"msup":{"mi":"\u03c3","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mn":"2"},{"mi":"B","mn":"1"}],"mo":","}}}],"mo":"+"},{"mrow":[{"mi":["#","vertices","of"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":"B","mn":"1"}},{"mi":["#","vertices","of"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":"B","mn":"2"}}],"mo":"+"}]}}}},{"mrow":{"mo":["(",")"],"mn":"24"}}]}}}},"br":{},"figref":"FIG. 40"},"The key advantage of using PDM over other IMT and variability measurement techniques is that the measured distance is robust because it is independent of the number of points on each boundary.","Feature Selection Process:","Student's t-test is used to assess whether the means of a feature from two classes are significantly different. In order to determine this, initially, the null hypothesis is assumed that the means of the features from the two classes are equal. Then, the t-statistic, which is the ratio of difference between the means of two classes to the standard error between class means, and the corresponding p-value are calculated. The p-value is the probability of rejecting the null hypothesis given that the null hypothesis is true. A low p-value (less than 0.01 or 0.05) indicates rejection of null hypothesis, and therefore, the fact that means are significantly different for the two classes.  (table) presents the significant features obtained for longitudinal carotid artery scan.\n\n",{"@attributes":{"id":"p-0191","num":"0255"},"figref":["FIG. 8","FIG. 3","FIG. 33","FIG. 4","FIG. 5","FIG. 6A","FIG. 6B","FIG. 6C","FIG. 8"]},{"@attributes":{"id":"p-0192","num":"0256"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]},{"entry":[{},"Trg. Pat#"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"9"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"8","colwidth":"28pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"1003","1004","1005","1006","1007","1008","1009","1010"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"8","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"9"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"8","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"9","colwidth":"28pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["GT info","1","1","0","0","0","0","1","1"]},{"entry":{"@attributes":{"namest":"1","nameend":"9","align":"center","rowsep":"1"}}}]}}]}}},"Note that the  is an off-line representative system when applied to the carotid artery. The same system is applicable to brachial, femoral and aortic walls. Also note that the system is applicable to the cross-modality training. This means that the off-line system can be used for Magnetic Resonance arteries or Computer Tomography or 3D carotid Ultrasound or 3D IVUS arteries. The only flexibility this system has that during the training process, the ground truth information can be taken from cross-modalities such as MR, CT or Ultrasound or IVSU images.","Classification Strategy:","Generally, 70% of the available images are used for training and the remaining 30% are used for testing. Those skilled in the art can use lot of different kind of training protocols such as equal partition, different permutation and combination methods and\/or jack knifing, etc. The performance measures are reported based on the results obtained using the test set. These measures, reported using the hold-out technique, are highly dependent on the samples chosen for the training and test sets. In order to obtain more generalized measures, especially for small sample size datasets such as the one in this application, the preferred data re-sampling technique is the k-fold cross validation technique. In this work, we employed three-fold cross validation wherein the dataset is split into three folds. In the first run, two folds are used for training and the remaining one fold is used for testing and for obtaining the performance measures. This procedure is repeated two more times by using a different fold for testing every time. The overall performance measures are the averages of the performance measures obtained in each run. This procedure was stratified, in the sense that, we ensured that the ratio of the samples belonging to the two classes (class distribution) remained the same in every run.",{"@attributes":{"id":"p-0195","num":"0259"},"figref":"FIG. 9","b":["1","2","3","1","2","3","1","2","3","123","1","2","3","123","123"],"sub":["ii","i ","i ","n","n ","n "]},{"@attributes":{"id":"p-0196","num":"0260"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"left"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["Feature","Asymptomatic","Symptomatic","P value"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["e1Res (38 degree)","0.477 \u00b1 6.196E\u221202","0.418 \u00b1 5.834E\u221202","0.0089"]},{"entry":["e1Res (39 degree)","0.470 \u00b1 6.751E\u221202","0.407 \u00b1 6.627E\u221202","0.010"]},{"entry":["e2Res (39 degree)","9.833E\u221202 \u00b1 ","6.132E\u221202 \u00b1 ","0.0085"]},{"entry":[{},"4.172E\u221202","2.396E\u221202",{}]},{"entry":["ePRes (106 degree)","0.843 \u00b1 0.344","1.35 \u00b1 0.602","0.0014"]},{"entry":["ePRes (107 degree)","0.828 \u00b1 0.280","1.18 \u00b1 0.494","0.0061"]},{"entry":["Wall Variability","0.256 \u00b1 0.193","0.484 \u00b1 0.191","0.0017"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}}}},"Using the risk score without wall variability is given as:","Cardiovascular Risk Score=K+e1Res38+e1Res39+e2Res39\u2212ePRes106+ePRes107.",{"@attributes":{"id":"p-0198","num":"0262"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"56pt","align":"center"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"Class","Asymptomatic","Symptomatic","P value"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Risk Score","6.03 \u00b1 0.282","5.71 \u00b1 0.312","0.0034"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"Using the wall variability as a feature, the risk score separation index between the Symptomatic vs. Asymptomatic with all the three grayscale features and wall variability feature included are shown in table as:",{"@attributes":{"id":"p-0200","num":"0264"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"56pt","align":"center"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"Class","Asymptomatic","Symptomatic","P value"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Risk Score","5.77 \u00b1 0.249","5.23 \u00b1 0.449","<0.0001"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"Our protocol when tried on ultrasound plaque data (without wall region) and without wall variability can be seen in the publication (Rajendra U. Acharya & Oliver Faust & A. P. C. Alvin & S. Vinitha Sree & Filippo Molinari & Luca Saba & Andrew Nicolaides & Jasjit S. Suri, Symptomatic vs. Asymptomatic Plaque Classification in Carotid Ultrasound), Journal of Medical Systems, DOI 10.1007\/s10916-010-9645-2. The publication shows the range of SACI (Risk Score) for symptomatic and asymptomatic cases as: 9.26 vs. 6.13 for Symptomatic vs. Asymptomatic.","Different types of risk scores can be obtained depending upon the feature set used.","Border Estimation System in Longitudinal Carotids:",{"@attributes":{"id":"p-0203","num":"0267"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0204","num":"0268"},"figref":["FIG. 11","FIG. 11"]},{"@attributes":{"id":"p-0205","num":"0269"},"maths":{"@attributes":{"id":"MATH-US-00055","num":"00055"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"sin","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"c","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}},{"mfrac":{"mrow":[{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["\u03c0","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},{"mi":["\u03c0","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},"mo":"."}],"mo":"="}}}},"Since the sine function never goes to zero, practical filter can be implemented by taking the sine function and multiplying it by a \u201cwindow\u201d, such as Hamming and Hann, giving an overall filter with finite size. We can define the Lanczos window as a sine function scaled to be wider, and truncated to zero outside of the main lobe. Therefore, Lanczos filter is a sine function multiplied by a Lanczos window. Three lobed Lanczos filter can be defined as",{"@attributes":{"id":"p-0207","num":"0271"},"maths":{"@attributes":{"id":"MATH-US-00056","num":"00056"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"Lanczos","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"3","mrow":{"mo":["(",")"],"mi":"x"}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mfrac":{"mrow":[{"mrow":[{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["\u03c0","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"\u03c0","mo":"\u2062","mfrac":{"mi":"x","mn":"3"}}}}],"mo":"\u2062"},{"mi":"\u03c0","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"x","mo":"\u00b7","msubsup":{"mi":["\u03c0","x"],"mn":"3"}}}]},"mo":","}},{"mrow":{"mrow":{"mi":"if","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["\uf603","\uf604"],"mi":"x"}},"mo":"\u2264","mn":"3"}}]},{"mtd":[{"mrow":{"mn":"0","mo":","}},{"mrow":{"mrow":{"mi":"if","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["\uf603","\uf604"],"mi":"x"}},"mo":">","mn":"3"}}]}]}}],"mo":"="}}}},"Although Lanczos interpolation is slower than other approaches, it can obtain the best interpolation results because Lanczos' method attempts to reconstruct the image by using a series of overlapping sine waves to produce what's called a \u201cbest fit\u201d curve. Those skilled in the art of down sample can also use Wavelet transform filters as they are very useful for multi-resolution analysis. The orthogonal wavelet transform of a signal f can be formulated by",{"@attributes":{"id":"p-0209","num":"0273"},"maths":{"@attributes":{"id":"MATH-US-00057","num":"00057"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mrow":[{"munder":{"mo":"\u2211","mrow":{"mi":["k","z"],"mo":"\u2208"}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["c","j"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":"\u03c6","mrow":{"mi":["j","k"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}],"mo":"\u2062"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"J","mo":"=","mn":"1"},"mi":"J"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":["k","Z"],"mo":"\u2208"}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["d","j"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":"\u03c6","mrow":{"mi":["j","k"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}],"mo":"\u2062"}}}],"mo":"+"}],"mo":"="}}},"br":[{},{},{}],"sub":["j","i","j,k","j,k"],"in-line-formulae":[{},{}],"i":["t","t\u2212k"],"sup":["\u2212j\/2","\u2212j"],"ul":{"@attributes":{"id":"ul0046","list-style":"none"},"li":{"@attributes":{"id":"ul0046-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0047","list-style":"none"},"li":"Bicubic interpolation can also be used as it will estimates the value at a given point in the destination image by an average of 16 pixels surrounding the closest corresponding pixel in the source image. Given a point (x,y) in the destination image and the point (l,k) (the definitions of l and k are same as the bilinear method) in the source image, the formulae of bicubic interpolation is"}}}},{"@attributes":{"id":"p-0210","num":"0275"},"maths":{"@attributes":{"id":"MATH-US-00058","num":"00058"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":[{"mi":"m","mo":"=","mrow":{"mi":"l","mo":"-","mn":"1"}},{"mi":"l","mo":"+","mn":"2"}]},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"n","mo":"=","mrow":{"mi":"k","mo":"-","mn":"1"}},{"mi":"k","mo":"+","mn":"2"}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"g","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},{"mi":"r","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","l"],"mo":["-","-"],"mrow":{"mo":"\u2146","mi":"x"}}}},{"mo":["(",")"],"mrow":{"mrow":{"mo":"\u2146","mi":"y"},"mo":["-","+"],"mi":["n","k"]}}],"mo":["\u00b7","\u00b7"]}}}],"mo":"="},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0211","num":"0276"},"maths":[{"@attributes":{"id":"MATH-US-00059","num":"00059"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mrow":[{"mi":"r","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mfrac":{"mn":["1","6"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"msup":{"mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"x","mo":"+","mn":"2"}}},"mn":"3"},"mo":["-","+","-"],"mrow":[{"mn":"4","mo":"\u2062","msup":{"mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"x","mo":"+","mn":"1"}}},"mn":"3"}},{"mn":"6","mo":"\u2062","msup":{"mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},"mn":"3"}},{"mn":"4","mo":"\u2062","msup":{"mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"x","mo":"-","mn":"1"}}},"mn":"3"}}]}}}],"mo":"="},{"mi":["where","is"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}}],"mo":[",","\u2062"],"mstyle":{"mtext":{}}}}},{"@attributes":{"id":"MATH-US-00059-2","num":"00059.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mi":"x"},{"mrow":{"mi":"x","mo":">","mn":"0"}}]},{"mtd":[{"mn":"0"},{"mrow":{"mi":"x","mo":"\u2264","mn":"0"}}]}]}}],"mo":"="}}}],"br":{},"ul":{"@attributes":{"id":"ul0048","list-style":"none"},"li":{"@attributes":{"id":"ul0048-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0049","list-style":"none"},"li":["Bilinear interpolator can also be used as it is very simple to implement. Mathematically, it is given as: if g represents a source image and f represents a destination image, given a point (x,y) in f, the bilinear method can be presented as:\n\n()=(1)\u00b7(1)\u00b7()+\u00b7(1)\u00b7(1,)+(1)\u00b7(1)+(11),\n","where l=\u2514x\u2518 and k=\u2514y\u2518, and the dx, dy are defined as dx=x\u22121 and dy=y\u2212k respectively. Bilinear interpolation is simple. However it can cause a small decrease in resolution and blurring because of the averaging nature."]}}}},{"@attributes":{"id":"p-0212","num":"0279"},"figref":"FIG. 12","br":[{},{}],"in-line-formulae":[{},{}],"i":["J","=\u012a+k","I","\u2212\u012a"],"sub":["x,y","x,y","x,y","x,y ","x,y ","x,y","x,y "]},{"@attributes":{"id":"p-0213","num":"0280"},"maths":{"@attributes":{"id":"MATH-US-00060","num":"00060"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":"k","mrow":{"mi":["x","y"],"mo":","}},"mo":"=","mfrac":{"msubsup":{"mi":["\u03c3","l"],"mn":"2"},"mrow":{"mrow":{"msup":{"mover":{"mi":["I","_"]},"mn":"2"},"mo":"\u2062","msubsup":{"mi":["\u03c3","l"],"mn":"2"}},"mo":"+","msubsup":{"mi":["\u03c3","n"],"mn":"2"}}}},"mo":","}}},"br":{},"sub":["1","n"],"sup":["2 ","2 "]},"Prior to despeckle filtering, the system crops the image in order to discard the surrounding black frame containing device headers and image\/patient data. For DICOM image, we relied on the data contained in the specific field named SequenceOfUltrasnundRegions, which contains four sub-fields that mark the location of the image containing the ultrasound representation. These fields are named RegionLocation (their specific label is xmin, xmax, ymin and ymax) and they mark the horizontal and vertical extension of the image. The raw B-Mode image is then cropped in order to extract only the portion that contains the carotid morphology. Those skilled in the art of DICOM will know that if the image came in from other formats or if the DICOM tags were not fully formatted, one can adopt a gradient-based procedure. One can compute the horizontal and vertical Sobel gradient of the image. The gradients repeat similar features for the entire rows\/columns without the ultrasound data: they are zero at the beginning and at the end. Hence, the beginning of the image region containing the ultrasound data can be calculated as the first row\/column with gradient different from zero. Similarly, the end of the ultrasound region is computed as the last non-zero row\/column of the gradient.",{"@attributes":{"id":"p-0215","num":"0282"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0216","num":"0283"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0217","num":"0284"},"figref":"FIG. 15"},"Higher order Gaussian derivative filter: The despeckled image is filtered by using a first order derivative of a Gaussian kernel filter. It is possible to observe how the CA walls become enhanced to white. The sigma parameter of the Gaussian derivative kernel was taken equal to 8 pixels, i.e. to the expected dimension of the IMT value. In fact, an average IMT value of say 1 mm corresponds to about 16 pixels in the original image scale and, consequently, to 8 pixels in the down-sampled scale.\n\n",{"@attributes":{"id":"p-0219","num":"0294"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0220","num":"0295"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0221","num":"0296"},"figref":"FIG. 18"},"LIMA Border Estimation for AWR Computation\/Segmentation Stage (Stage II):","Here we use any of the existing methods for computation of the LI and MA borders given the region of interest or Guidance Zone. The following citations can be used for computation of the LI\/MA borders and its corresponding IMT measurement:\n\n",{"@attributes":{"id":"p-0223","num":"0306"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0224","num":"0307"},"figref":"FIG. 20"},"The Calibration process of type II (using Edge Flow Calibration Processor). This shows the domain based calibration process or segmentation processor. The system is divided into three components: (a) Guidance Zone Processor; (b) DoG Filtering Processor; (c) Heuristic Processor. Since the Artery Recognition Processor has identified the adventitia tracing ADF, the calibration needs to be applied in the zone which was initially guided by the Artery Recognition Processor. Since the calibration stage is merely a combination of finding the edges of the LI and MA borders, the importance of guidance zone is very crucial. The Guidance Zone is the key to avoid the false peaks estimation in the calibration phase.","The Guidance Zone is built around the adventitia tracing ADF. The Guidance Zone is a region-of-interest (ROI) around the automatically traced ADF profile, so called the domain region in which segmentation will run. The ROI is designed such that it has the same width as of the ADF curve. This will allow the creation of the largest possible ROI, according to the detected length of the adventitia layer. The height has to be equal to 30 pixels (1.8 mm for images with 16.67 pixels\/mm of density, and 1.875 mm for images with 16 pixels\/mm of density). For each point of the ADF profile we considered as upper limit of the ROI the pixel with a row index of 30 pixels lower, towards the upper edge of the cropped image. Substantially, the bottom limit of the ROI was the ADF curve while the upper limit was ADF shifted by 30 pixels. Those skilled in the art can use the pixel density to compute the height of the ROI given the ADF border.","Edge Flow Magnitude and Edge Flow Direction (stage II):","We use the method developed by W. Y. Ma and B. S. Manjunath (citation: Ma, W. Y. and B. S. Manjunath. 1997. San Juan).","that facilitates the integration of different image attributes into a single framework for boundary detection and is based on the construction of an edge flow vector defined as:\n\n(,\u03b8)=(,\u03b8), (,\u03b8), (,\u03b8+\u03c0)]\u2003\u2003(2)\n\nwhere:\n\n","The final single edge flow vector can be thought of as the combination of edge flows obtained from different types of image attributes. The image attributes that we considered are intensity and texture. In order to calculate the edge energy and the probabilities of forward and backward edge flow direction, a few definitions must first be clarified, specifically the first derivative of Gaussian (GD) and the difference of offset Gaussian (DOOG).","Considering the Gaussian kernel G(x,y), where \u03c3 represents the standard deviation, the first derivative of the Gaussian along the x-axis is given by",{"@attributes":{"id":"p-0231","num":"0317"},"maths":{"@attributes":{"id":"MATH-US-00061","num":"00061"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["GD","\u03c3"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mrow":[{"mo":"-","mrow":{"mo":["(",")"],"mfrac":{"mi":"x","msup":{"mi":"\u03c3","mn":"2"}}}},{"msub":{"mi":["G","\u03c3"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}],"mo":"\u2062"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}},"br":[{},{},{},{},{}],"in-line-formulae":[{},{},{},{},{},{}],"sub":["\u03c3","\u03c3","\u03c3","\u03c3,\u03b8","\u03c3,\u03b8","\u03c3,\u03b8","\u03c3","\u03c3,\u03b8","\u03c3"],"i":["x,y","x,y","G","x+d,y","GD","x,y","GD","x\u2032,y","x,y","x\u2032,y"],"ul":{"@attributes":{"id":"ul0056","list-style":"none"},"li":{"@attributes":{"id":"ul0056-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0057","list-style":"none"},"li":"where: x\u2032=x cos \u03b8+y sin \u03b8, and y\u2032=\u2212x sin \u03b8+y cos \u03b8\n\nIntensity Edge Flow (of Stage II):\n"}}}},"Considering the original image I(x,y) at a certain scale \u03c3, I(x,y) is obtained by smoothing the original image with a Gaussian kernel G(x,y). The edge flow energy E(s,\u03b8) at scale \u03c3, defined to be the magnitude of the gradient of the smoothed image I(x,y) along the orientation \u03b8, can be computed as\n\n(,\u03b8)=|()*|\u2003\u2003(7)\n\nwhere s is the location (x,y). This energy indicates the strength of the intensity changes. The scale parameter is very important in that it controls both the edge energy computation and the local flow direction estimation so that only edges larger than the specified scale are detected.\n","To compute P(s,\u03b8), two possible flow directions (\u03b8 and \u03b8+\u03c0) are considered for each of the edge energies along the orientation \u03b8 at location s. The prediction error toward the surrounding neighbors in these two directions can be computed as:\n\nError(,\u03b8)=|(cos \u03b8, sin \u03b8)\u2212()|=|()*DOOG)|\u2003\u2003(8)\n\nwhere d is the distance of the prediction and it should be proportional to the scale at which the image is being analyzed. The probabilities of edge flow direction are then assigned in proportion to their corresponding prediction errors, due to the fact that a large prediction error in a certain direction implies a higher probability of locating a boundary in that direction:\n",{"@attributes":{"id":"p-0234","num":"0321"},"maths":{"@attributes":{"id":"MATH-US-00062","num":"00062"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","\u03b8"],"mo":","}}},"mo":"=","mfrac":{"mrow":[{"mi":"Error","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","\u03b8"],"mo":","}}},{"mrow":[{"mi":"Error","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","\u03b8"],"mo":","}}},{"mi":"Error","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"s","mo":",","mrow":{"mi":["\u03b8","\u03c0"],"mo":"+"}}}}],"mo":"+"}]}}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}}}}},"Texture Edge Flow: Texture features are extracted from the image based on Gabor decomposition. This is done basically by decomposing the image into multiple oriented spatial frequency channels, and then the channel envelopes (amplitude and phase) and used to form the feature maps.","Given the scale \u03c3, two center frequencies of the Gabor filters (the lowest and the highest) are defined and based on the range of these center frequencies, an appropriate number of Gabor filters g(x,y) is generated. The complex Gabor filtered images are defined as:\n\n()=I*g()=()exp[\u03a6()]\u2003\u2003(10)\n\nwhere 1\u2266i\u2266N, N is the total number of filters and i is the sub band, m(x,y) is the magnitude, and \u03a6(x,y) is the phase. A texture feature vector \u03a8(x,y) can then be formed by taking the amplitude of the filtered output across different filters at the same location (x,y):\n\n\u03a8()=[(),(), . . . , ()]\u2003\u2003(11)\n\nThe change in local texture information can be found using the texture features, thus defining the texture edge energy:\n",{"@attributes":{"id":"p-0237","num":"0324"},"maths":{"@attributes":{"id":"MATH-US-00063","num":"00063"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"E","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","\u03b8"],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mn":"1","mo":["\u2264","\u2264"],"mi":["i","N"]}},"mo":"\u2062","mrow":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"msub":{"mi":["m","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"msub":{"mi":"GD","mrow":{"mi":["\u03c3","\u03b8"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}],"mo":"*"}},"mo":"\u00b7","msub":{"mi":["w","i"]}}}],"mo":"="},{"msub":{"mi":["w","i"]},"mo":"=","mfrac":{"mn":"1","mrow":{"mo":["\uf605","\uf604"],"msub":{"mi":["\u03b1","i"]}}}}],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mtext":{}},{"mtext":{}}],"mi":"where"}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}},"br":{},"sub":"i"},"The direction of the texture edge flow can be estimated similarly to the intensity edge flow, using the prediction error:",{"@attributes":{"id":"p-0239","num":"0326"},"maths":{"@attributes":{"id":"MATH-US-00064","num":"00064"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"Error","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","\u03b8"],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mn":"1","mo":["\u2264","\u2264"],"mi":["i","N"]}},"mo":"\u2062","mrow":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"msub":{"mi":["m","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"msub":{"mi":"DOOG","mrow":{"mi":["\u03c3","\u03b8"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}],"mo":"*"}},"mo":"\u00b7","msub":{"mi":["w","i"]}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"13"}}]}}}},"br":[{},{}]},"For general-purpose boundary detection, the edge flows obtained from the two different types of image attributes can be combined:",{"@attributes":{"id":"p-0241","num":"0328"},"maths":{"@attributes":{"id":"MATH-US-00065","num":"00065"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"E","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","\u03b8"],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mrow":{"mi":"a","mo":"\u2208"},"mo":"=","mi":"A"}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["E","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","\u03b8"],"mo":","}}},{"mi":"w","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"a"}}],"mo":"\u00b7"}}],"mo":"="},{"mrow":{"munder":{"mo":"\u2211","mrow":{"mi":["a","A"],"mo":"\u2208"}},"mo":"\u2062","mrow":{"mi":"w","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"a"}}},"mo":"=","mn":"1"}],"mo":","}},{"mrow":{"mo":["(",")"],"mn":"14"}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","\u03b8"],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mi":["a","A"],"mo":"\u2208"}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["P","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","\u03b8"],"mo":","}}},{"mi":"w","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"a"}}],"mo":"\u00b7"}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"15"}}]}]}}},"br":{},"sub":["a","a","0\u2266\u03b8\u2266\u03c0"]},{"@attributes":{"id":"p-0242","num":"0329"},"maths":{"@attributes":{"id":"MATH-US-00066","num":"00066"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"\u0398","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"s"}},{"mi":"arg","mo":"\u2062","mrow":{"munder":{"mi":["max","\u03b8"]},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"munder":{"mo":"\u2211","mrow":{"mi":"\u03b8","mo":["\u2264","\u2264"],"msup":{"mi":["\u03b8","\u2032"]},"mrow":{"mi":["\u03b8","\u03c0"],"mo":"+"}}},"mo":"\u2062","mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"s","mo":",","msup":{"mi":["\u03b8","\u2032"]}}}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"16"}}]}}}},"br":{}},{"@attributes":{"id":"p-0243","num":"0330"},"maths":{"@attributes":{"id":"MATH-US-00067","num":"00067"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mover":{"mi":"F","mo":"\u27f6"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"s"}},{"munder":{"mo":"\u2211","mrow":{"mrow":[{"mi":"\u0398","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"s"}},{"mrow":{"mi":"\u0398","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"s"}},"mo":"+","mi":"\u03c0"}],"mo":["\u2264","\u2264"],"mi":"\u03b8"}},"mo":"\u2062","mrow":{"mrow":[{"mi":"E","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","\u03b8"],"mo":","}}},{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"j\u03b8"}}],"mo":"\u00b7"}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"17"}}]}}}},"br":[{},{}]},"Once the edge flow {right arrow over (F)}(s) of an image is computed, boundary detection can be performed by iteratively propagating the edge flow and identifying the locations where two opposite direction of flows encounter each other. The local edge flow is then transmitted to its neighbor in the direction of flow if the neighbor also has a similar flow direction. The steps which describe this iterative process are as follows:",{"@attributes":{"id":"p-0245","num":"0332"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["STEP 1:","Set n=0 and {right arrow over (F)}(s) = {right arrow over (F)}(s)"]},{"entry":["STEP 2:","Set the initial edge flow {right arrow over (F)}(s) at time n+1 to zero"]},{"entry":["STEP 3:","At each image location s=(x,y), identify the neighbour s \u2032=(x\u2032,y\u2032)"]},{"entry":[{},"which is in the direction of edge flow {right arrow over (F)}(s)"]},{"entry":["STEP 4:","Propagate the edge flow if {right arrow over (F)}(s\u2032)\u00b7 {right arrow over (F)}(s) > 0"]},{"entry":[{},"\u2003{right arrow over (F)}(s\u2032) = {right arrow over (F)}(s\u2032) + {right arrow over (F)}(s):"]},{"entry":[{},"\u2003otherwise."]},{"entry":[{},"\u2003{right arrow over (F)}(s) = {right arrow over (F)}(s) + {right arrow over (F)}(s)"]},{"entry":["STEP 5:","If nothing has been changed, stop the iteration. Otherwise, set"]},{"entry":[{},"n=n+1 and go to step 2."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"The image boundaries can then be detected once the edge flow propagation reaches a stable set by identifying the locations which have non-zero edge flow coming from two opposing directions. For all of the images, we considered 8 different orientations, starting from 0\u00b0 and going to 315\u00b0 with equal degree intervals in between.","Once the image boundaries are detected, the final image is generated by performing region closing on it to limit the number of disjoint boundaries by searching for the nearest boundary element, which is within the specified search neighborhood at the unconnected ends of the contour. If a boundary element is found, a smooth boundary segment is generated to connect the open contour to another boundary element. The neighborhood search size is taken to be proportional to the length of the contour itself.","This approach of edge detection has some very salient features, including the fact that it uses a predictive coding model for identifying and integrating the different types of image boundaries, the boundary detection is based on flow field propagation and it has very few \u201cfree\u201d parameters that control the segmentation. Because of this, very little parameter tuning or selection is needed and the sole parameter that controls the segmentation is the preferred image scale.","The edge flow algorithm can over-segments in many different points, due partly to the fact that the image can be cropped to contain the entire Guidance Zone Mask and therefore may contain sections of the image that can be found below the ADF profile. Also, while part of the MA and LI edge estimation may be done using the edge flow algorithm, the segmentation cannot yet be considered complete as there are still some missing MA and LI edges and the edges found must be classified as either belonging to the MA profile or the LI profile. This refinement and classification process is done using a strong dependency on the edges found by the edge flow algorithm and via labeling and connectivity, which will be explained in further detail in the next two sections.","Small Edge Objects (stage II):","Secondly, since there can still be small unwanted edge objects around the interested area, small edge objects are defined as those which have an area ratio below a certain limit \u03c6 and are subsequently removed from the image. The area ratio is defined by the following equation:",{"@attributes":{"id":"p-0251","num":"0338"},"maths":{"@attributes":{"id":"MATH-US-00068","num":"00068"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"AreaRatio","mo":"=","mrow":{"mrow":{"mfrac":{"msub":[{"mi":["Area","EdgeObject"]},{"mi":["Area","AllEdgeObjects"]}]},"mo":"\u2264","mi":"\u03d5"},"mo":"\u21d2","mi":"SmallEdgeObject"}}},{"mrow":{"mo":["(",")"],"mn":"18"}}]}}}},"br":{}},"Our experimental data showed that, when \u03c6=0.1 we are successfully able to discard the small edge objects. The MA segment is then first initialized as being the edge object with the highest pixel row index (i.e., the lowest edge object in the image) and its unconnected end points are found as the right top and left top pixels of the edge object (RTMA and LTMA, respectively). The remaining edge objects are then sorted by their mean pixel row index value so as to examine the edge objects starting from those which are lowest in the image and working upwards. The edge objects are then classified by following these steps:\n\n",{"@attributes":{"id":"p-0253","num":"0342"},"maths":{"@attributes":{"id":"MATH-US-00069","num":"00069"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":"LT","msub":{"mi":"x","munder":{"mi":["MA","i"]}}},{"mi":"RT","msub":{"mi":"x","msub":{"mi":["i","MA"]}}}],"mo":"-"}}},{"mrow":{"mo":["(",")"],"mn":"19"}}]}}}},"ul":{"@attributes":{"id":"ul0060","list-style":"none"},"li":{"@attributes":{"id":"ul0060-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0061","list-style":"none"},"li":["3. Calculate the respective row distance in absolute value (|LT\u2212RT|) and column distance (LT\u2212RT) between the correct unconnected end point pair found and determine that the examined edge object can be classified as being part of the MA segment if the following two conditions are met:\n\n||\u2266\u03c3\u2003\u2003(20)\n\n>0 \u2003\u2003(21)\n","where \u03c6 is the maximum row distance acceptable, which we took to be equal to 15. The condition on the column distance is needed to ensure that the edge object considered does not overlap the already existing MA segment, while the condition on the row distance is necessary so as to avoid including edges that are too far above the existing MA segment.","4. Find new unconnected end points of the MA segment.","5. Repeat steps 1-4 until all edge objects have been examined."]}}}},"Once all of the edge objects have been examined, those which are classified as being part of the MA segment are then connected together and regulated using a B-spline to produce the final MA profile.","LI Weak\/Missing Edge Estimation using LI Strong Edge Dependency and Complete MA Edge Dependency (Stage II)","The LI missing edge estimation is completely dependent on the MA profile which is determined in previous stage. In fact, the MA profile is used to create a guidance zone starting from the profile and extending it upwards 50 pixels. This is used so as to find solely the edge objects from the image output of the edge flow algorithm that can be found above (lower row value) the MA profile and that have at least some common support with it","Once this step is done, the following steps are necessary for each of these i edge objects:\n\n","Once all of the edge objects are examined, those found to be part of the LI segment (good edge objects) must be tested to see if the distance between two adjacent edges objects is too vast. This is to avoid connecting two edge objects which are too far from each other, which could have a negative effect on the outcome of the final LI profile.","To do this, the good edge objects are considered by adjacent pairs. The Euclidean distance between the two closest unconnected end points of the pair is calculated and if this distance exceeds a certain limit, the good edge objects are classified as belonging to two different LI segments. If the distance calculated is less than the defined limit, then the pair is classified as belonging to the same LI segment. Once all good edge objects have been examined, the final LI segment is determined by those that are part of the longest LI segment found.","The edge objects that are part of the final LI segment are then connected together and regulated using a B-spline to produce the final LI profile.","AWR Compulsion when the Longitudinal Ultrasound Images have Shadows:","Normally, when then walls do not have the calcium shadows, then the above AWR system be applied.  show the AtheroEdge\u2122 system when there are shadows in the longitudinal carotid ultrasound wall region.  shows the OPD (object process diagram) for the whole system when the shadows are present in the ultrasound scans. The top box shows the interacting system between ultrasound machine, patient and user. This invention is applicable to vascular ultrasound for carotid, brachial, aortic and femoral but not limited to these alone. For carotid, one can use the left and the right scan. When the patient conies in, the system is made to get ready for the ultrasound scan and IMT measurement and AWR computation. Patient is positioned optimally for the best scan and then Gel is applied before vascular scanning. The probe is then skin surfaced for the carotid scan as seen in the . The first sub-system in  shows the patient positioning and vascular scanning system. The input to this block is vascular scan type: carotid, brachial, femoral and aortic, which means these four kinds of arteries, can be used for IMT measurement and AWR computation. The output to the system is the real time ultrasound vascular scan, normally DICOM in format. In the  is also shown that the user completely monitors the system all the time and is in user's control all the time. This allows for perfect synchronization of the patient interface with ultrasound and for the diagnostic IMT measurement and AWR computation. Normally, the vascular screening is done by the vascular surgeon or a neuroradiologist or a sonographer or a cardiologist. They are trained to recognize any calcium present near the proximal wall zone. The diamond box shows if the calcium is present in arterial wall or not. The user such as neuroradiologist or sonographer or cardiologist or vascular surgeon uses his expertise to spot the calcium and its shadow in the proximal (near) end of the arterial wall. Those skilled in the art will note that even though the probe is used longitudinally in B-mode for scanning the arterial wall, one can change the orientation of the probe orthogonal to the blood flow and move the probe linearly along the carotids or brachial or femoral or aortic to get the transverse slices to see the extent (range) of the calcium.","Since the presence of the calcium in longitudinal B-mode scans causes the calcium cone in the ultrasound images, a different processing stage is required before AtheroEdge\u2122 stand alone is applied for IMT measurement and AWR computation. AtheroEdge\u2122 is made to activate if there is no calcium is present while AtheroEdge\u2122 system with calcium correction is made to activate when calcium is spotted in the longitudinal or transverse B-mode images. The output of the AtheroEdge\u2122 (with or without calcium system) is the real time IMT measurement and AWR computation. Note that the user completely monitors the system all the time and is in user's control all the time during the AtheroEdge\u2122 system with calcium and AtheroEdge\u2122 system without calcium.",{"@attributes":{"id":"p-0262","num":"0362"},"figref":["FIG. 22","FIG. 22"]},"Thus we need a method, which can actually compute the IMT values and AWR computation if the user (cardiologist, neuroradiologist, vascular surgeon, sonographer) does not find the calcium shadows. We need a reliable, real time and accurate method for IMT measurement and AWR computation when there is no calcium present. Similarly, we need to find IMT and AWR computation when the calcium is present. When calcium is not present, the IMT computation and AWR computation uses AtheroEdge\u2122 directly, but when calcium is present the system uses AtheroEdge\u2122 in the non-calcium zones and correcting the LI border in the calcium zones and then interpolating with the LI border of the non-calcium zone thereby getting the complete and correct LI borders.",{"@attributes":{"id":"p-0264","num":"0364"},"figref":"FIG. 23"},"These axial slices will show the vessel wall which is circular band in nature. The inner wall shows the lumen region and outer wall is the adventitia walls. Since the application interested in the distal (far) walls in longitudinal B-mode, we look for the vessel wall region in the distal area of the artery. Those skilled in the art of doing 3D ultrasound will notice that the lumen region is dark (black) and the vessel wall (relatively brighter than lumen region), hence the interface region is discernable between lumen and walls. This change in gradient information for the distal (far) wall for that particular slice will allow the user manually or semi-automatically or automatically to estimate the gradient change between the lumen and vessel wall for that orthogonal slice.  shows the circular wall boundaries of the lumen and media-adventitia layers in axial or transverse slices. The point of gradient change between the lumen and vessel wall corresponding to the longitudinal B-mode position of the probe, orthogonal to the arterial axis is the point, which corresponds to the 1.1 border where calcium region was hit. This point is shown as a black circle in the . Those skilled in the art of boundary estimation can use off the shelf snake method or deformable method or edge detection method to find the lumen boundary in the transverse slice of the ultrasound arterial image. The above process of finding the point of intersection of the longitudinal B-mode position to the circular vessel wall in the transverse image is repeated for all the transverse slices where calcium region is identified. The information extracted for the shadow region is stored to be reused because that is the partial information on the LI border. The rest of the information will be extracted from AtheroEdge\u2122 using the longitudinal B-mode vascular ultrasound image.",{"@attributes":{"id":"p-0266","num":"0366"},"figref":["FIG. 24","FIG. 24"]},{"@attributes":{"id":"p-0267","num":"0367"},"figref":["FIG. 25","FIG. 25"]},{"@attributes":{"id":"p-0268","num":"0368"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0269","num":"0369"},"figref":["FIG. 27","FIG. 28"],"ul":{"@attributes":{"id":"ul0064","list-style":"none"},"li":["F. Molinari, G. Zeng, and J. S. Suri. An integrated approach to computer-based automated tracing and its validation for 200 common carotid arterial wall ultrasound images: A new technique, J Ultras Med, 29, (2010), 399-418.","F. Molinari, G. Zeng, and J. S. Suri, Intima-media thickness: setting a standard for completely automated method for ultrasound, IEEE Transaction on Ultrasonics Ferroelectrics and Frequency Control, 57(5), (2010), 1112-1124.","S. Delsanto, F. Molinari, P. Giustetto, W. Liboni, S. Badalamenti, and J. S. Suri, Characterization of a Completely User-Independent Algorithm for Carotid Artery Segmentation in 2-D Ultrasound Images, Instrumentation and Measurement, IEEE Transactions on, 56(4), (2007). 1265-1274.","S. Delsanto, F. Molinari, P. Giustetto, W. Liboni, and S. Badalamenti, CULEX-completely user-independent layers extraction: ultrasonic carotid artery images segmentation, Conf Proc IEEE Eng Med Biol Soc, 6, (2005), 6468-71.","S. Delsanto, F. Molinari, W. Liboni, P. Giustetto, S. Badalamenti, and J. S. Suri, User-independent plaque characterization and accurate IMT measurement of carotid artery wall using ultrasound, Conf Proc IEEE Eng Med Biol Soc, I, (2006), 2404-7.","F. Molinari, S. Delsanto, P. Giustetto, W. Liboni, S. Badalamenti, and J. S. Suri, User-independent plaque segmentation and accurate intima-media thickness measurement of carotid artery wall using ultrasound, in, Number of 111-140 (2008, Artech House, Norwood, Mass. 20081).","F. Molinari, W. Liboni, P. Giustetto, E. Pavanelli, A. Marsico, and J. Suri, Carotid plaque characterization with contrast-enhanced ultrasound imaging and its histological validation, The Journal for Vascular Ultrasound, 34(4), (2010), 1-10.","F. Molinari, C. Loizou, G. Zeng, C. Pattichis, D. Chandrashekar, M. Pantziaris, W. Liboni, A. Nicolaides, and J. Suri, -()\u2014-, in 2011: Lake Buena Vista (Orlando), Fla. USA."]}},{"@attributes":{"id":"p-0270","num":"0378"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0271","num":"0379"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0272","num":"0380"},"figref":"FIG. 31A"},{"@attributes":{"id":"p-0273","num":"0381"},"figref":"FIG. 31B"},{"@attributes":{"id":"p-0274","num":"0382"},"figref":"FIG. 31C"},{"@attributes":{"id":"p-0275","num":"0383"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0276","num":"0384"},"figref":"FIG. 42","sub":["c ","p"]},{"@attributes":{"id":"p-0277","num":"0385"},"figref":"FIG. 43"},{"@attributes":{"id":"p-0278","num":"0386"},"figref":"FIG. 44"},{"@attributes":{"id":"p-0279","num":"0387"},"figref":"FIG. 45","b":["3300","3310","3320","3330","3340","3350"]},{"@attributes":{"id":"p-0280","num":"0388"},"figref":"FIG. 46","b":"2700"},"The example computer system  includes a processor  (e.g., a central processing unit (CPU), a graphics processing unit (GPU), or both), a main memory  and a static memory , which communicate with each other via a bus . The computer system  may further include a video display unit  (e.g., a liquid crystal display (LCD) or a cathode ray tube (CRT)). The computer system  also includes an input device  (e.g., a keyboard), a cursor control device  (e.g., a mouse), a disk drive unit , a signal generation device  (e.g., a speaker) and a network interface device .","The disk drive unit  includes a machine-readable medium  on which is stored one or more sets of instructions (e.g., software ) embodying any one or more of the methodologies or functions described herein. The instructions  may also reside, completely or at least partially, within the main memory , the static memory , and\/or within the processor  during execution thereof by the computer system . The main memory  and the processor  also may constitute machine-readable media. The instructions  may further be transmitted or received over a network  via the network interface device . While the machine-readable medium  is shown in an example embodiment to be a single medium, the term \u201cmachine-readable medium\u201d should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and\/or associated caches and servers) that store the one or more sets of instructions. The term \u201cmachine-readable medium\u201d can also be taken to include any non-transitory medium that is capable of storing, encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the various embodiments, or that is capable of storing, encoding or carrying data structures utilized by or associated with such a set of instructions. The term \u201cmachine-readable medium\u201d can accordingly be taken to include, but not be limited to, solid-state memories, optical media, and magnetic media.","Classification Results for Longitudinal Ultrasound:","The average accuracy, PPV, sensitivity, and specificity values obtained by feeding all the features except the Wall Feature into five different kernel configurations of SVM, KNN, PNN, DT, and Fuzzy classifiers are presented in  (Table). The results obtained using all the significant features including the Wall Feature in the classifiers are presented in  (Table). In both  (table) and  (table), the values indicated are averages obtained in the three folds of testing. TN indicates the number of True Negatives, FN the number of False Negatives, TP the number of True Positives, and FP the number of False Positives. It is evident that the classifiers show improved performance when the Wall Feature is included in the training process. The highest accuracy of 94.4% was registered by the KNN classifier  (table).",{"@attributes":{"id":"p-0284","num":"0392"},"figref":"FIG. 31B"},{"@attributes":{"id":"p-0285","num":"0393"},"figref":"FIG. 31C"},"For the Wall-dataset with features of FD, LBP, LME, IMTV, the optimal classifier would either be the KNN or the RBPNN as both registered high values for accuracy (89.5%), sensitivity (89.6%) and specificity (88.9%) ().","Atheromatic Wall Index Using the Features (LBP+LME+IMTV)","The Atheromatic\u2122 is calculated using Equation shown below. The range of this index for both the symptomatic and asymptomatic classes is presented in  (table) and the corresponding box plot is shown in .  shows the Mean\u00b1Standard Deviation of the Atheromatric\u2122 for both asymptomatic and symptomatic classes. Again, this wall index (using combination 2) is also significantly different for the two classes. The symptomatic images have a higher value for this index because they have higher values for the IMTVfeature and LME2 (component on the numerator N of the equation below), and lower values for LBPEne (component on the denominator D of the equation). The value of bias \u03b2 was taken to be 10 and \u03c7 was taken to be 5. This Wall Index may be used by the clinicians for a more objective, real-time, and faster classification of symptomatic vs. asymptomatic plaque walls. This index is single valued index and do not require any subjective interpretation.",{"@attributes":{"id":"p-0288","num":"0396"},"maths":[{"@attributes":{"id":"MATH-US-00070","num":"00070"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"AtheromaticWi","mo":"=","mrow":{"mi":"\u03b2","mo":["\u00d7","\u00d7"],"msub":{"mi":["IMTV","poly"]},"mrow":{"msub":{"mi":"log","mn":"10"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":{"mi":["N","D"]},"mo":"+","mi":"\u03c7"}}}}}}},{"@attributes":{"id":"MATH-US-00070-2","num":"00070.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"N","mo":"=","mrow":{"mi":"LME","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"}}}},{"@attributes":{"id":"MATH-US-00070-3","num":"00070.3"},"math":{"@attributes":{"overflow":"scroll"},"mi":"and"}},{"@attributes":{"id":"MATH-US-00070-4","num":"00070.4"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"D","mo":"=","mrow":{"msub":{"mi":"LBP","mn":"324"},"mo":["\u2062","\u00d7","\u2062","\u2062"],"mi":["Ene","LME"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"8"}}}}],"br":[{},{}],"sub":"324","figref":"FIG. 31B"},"Computed tomography images of the carotid artery provide unique 3D images of the artery and plaque that could be used for calculating percentage stenosis. On using the Atheromatic\u2122 system on images obtained using non-invasive Multi-Detector row CT Angiography (MDCTA) and using the texture-based features and discrete wavelet transform based features, one can use the same paradigm for classification of carotid wall plaque images into symptomatic vs. asymptomatic and computation of the risk score index.","An example of MDCTA symptomatic and asymptomatic wall region is shown in , ,  and .","Example of Texture Features using Gray Level Co-occurrence Matrix (GLCM) and the run length matrix to extract texture features from the segmented images of the carotid artery. The features are briefly described below.","Co-occurrence Matrix: The GLCM of a m\u00d7n image is defined as:",{"@attributes":{"id":"p-0292","num":"0400"},"maths":{"@attributes":{"id":"MATH-US-00071","num":"00071"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["C","d"]},"mo":"=","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mo":["{","}"],"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mi":["p","q"],"mo":","}},{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mrow":[{"mi":"p","mo":"+","mrow":{"mi":["\u0394","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mi":"q","mo":"+","mrow":{"mi":["\u0394","y"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":","}},{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["p","q"],"mo":","}}}],"mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]},"mo":"=","mi":"i"}],"mo":[",",","]}}},{"mtd":{"mrow":{"mrow":{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"p","mo":"+","mrow":{"mi":["\u0394","x"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mi":"q","mo":"+","mrow":{"mi":["\u0394","y"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":","}}},"mo":"=","mi":"j"}}}]}}}}}},"br":{}},{"@attributes":{"id":"p-0293","num":"0401"},"maths":{"@attributes":{"id":"MATH-US-00072","num":"00072"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},"mo":"=","mfrac":{"mrow":[{"msub":{"mi":["C","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mo":["\u2063","\u2063"],"mrow":{"mo":["\u2329","\u232a"],"mi":"i"}}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mo":["\u2329","\u232a"],"mi":"j"}},"mo":"\u2062","mrow":{"msub":{"mi":["C","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}]}}}},"br":{}},{"@attributes":{"id":"p-0294","num":"0402"},"maths":[{"@attributes":{"id":"MATH-US-00073","num":"00073"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"Energy","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msqrt":{"mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","msup":{"mrow":{"mo":["[","]"],"mrow":{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}},"mn":"2"}}}}}}},{"@attributes":{"id":"MATH-US-00073-2","num":"00073.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"Contrast","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":"-"}},"mn":"2"},"mo":"\u2062","mrow":{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}}}}},{"@attributes":{"id":"MATH-US-00073-3","num":"00073.3"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"Homogeneity","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mfrac":{"mrow":[{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"mn":"1","mo":"+","msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":"-"}},"mn":"2"}}]}}}}}},{"@attributes":{"id":"MATH-US-00073-4","num":"00073.4"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"Entropy","mo":"\u2062","mstyle":{"mtext":":"}},{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"mrow":[{"mrow":{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},"mo":"\u00b7","mi":"ln"},{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":["\u2062","-"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}}},{"@attributes":{"id":"MATH-US-00073-5","num":"00073.5"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"Moments","mo":["\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"msub":{"mi":["m","g"]}},{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":"-"}},"mi":"g"},"mo":"\u2062","mrow":{"msub":{"mi":["P","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}}],"mo":"="}}}],"br":{},"sub":["1","2","3","4 "]},{"@attributes":{"id":"p-0295","num":"0403"},"maths":[{"@attributes":{"id":"MATH-US-00074","num":"00074"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":["Angular","Second","Moment"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"=","mn":"0"},{"mi":"n","mo":"-","mn":"1"}]},"mo":"\u2062","msup":{"mrow":{"msub":{"mi":["P","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},"mn":"2"}}}}},{"@attributes":{"id":"MATH-US-00074-2","num":"00074.2"},"math":{"@attributes":{"overflow":"scroll"},"mi":"where"}},{"@attributes":{"id":"MATH-US-00074-3","num":"00074.3"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["P","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"msub":{"mi":["C","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}],"mo":"="}}}],"br":{}},"Run Length Matrix: The run length matrix P[24] contains all the elements where the gray level intensity i has the run length j continuous in direction \u03b8. The direction \u03b8 is set as 0\u00b0, 45\u00b0, 90\u00b0, or 135\u00b0. In this work, we calculated the following features based on P.",{"@attributes":{"id":"p-0297","num":"0405"},"maths":[{"@attributes":{"id":"MATH-US-00075","num":"00075"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":["Short","run","emphasis"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"mfrac":{"mrow":{"msub":{"mi":["P","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},"msup":{"mi":"j","mn":"2"}},"mo":"\/","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"msub":{"mi":["P","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}}}}}}},{"@attributes":{"id":"MATH-US-00075-2","num":"00075.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":["Long","run","emphasis"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"msup":{"mi":"j","mn":"2"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["p","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"msub":{"mi":["P","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}],"mo":"\/"}}}}}}},{"@attributes":{"id":"MATH-US-00075-3","num":"00075.3"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":["Gray","level","non","uniformity"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":"-"},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["{","}"],"mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"msub":{"mi":["P","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}},"mn":"2"},"mo":"\/","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"msub":{"mi":["P","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}}}}}},{"@attributes":{"id":"MATH-US-00075-4","num":"00075.4"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":["Run","length","non","uniformity"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":"-"},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["{","}"],"mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"msub":{"mi":["P","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}},"mn":"2"},"mo":"\/","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"msub":{"mi":["P","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}}}}}}}}},{"@attributes":{"id":"MATH-US-00075-5","num":"00075.5"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":["Run","percentage"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"j"},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":["P","\u03b8"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},"mo":"\/","mi":"A"}}}}}}],"br":{}},"DWT feature for MDCTA data set: As discussed in Ultrasound above, Discrete Wavelet Transform (DWT) is a transform that captures both the time and frequency information of the image. When two-dimensional DWT is applied to CT\/MR images, it decomposes the image into coarse approximation coefficients using low-pass filters and finer detail coefficients using high-pass filters. This decomposition is done iteratively on the low-pass approximation coefficients obtained at each level, until the necessary iterations are reached.  shows the pass band structure for a 2D sub-band transform at three levels. We used Daubechies (Db) 8 as the mother wavelet in this work. Specifically, LL coefficients are obtained when Low Pass Filtering (LPF) is applied on both rows and columns in the image. HL coefficients (vertical details) are obtained when LPF is applied on rows, and High Pass Filtering (HPF) is applied on columns. LH coefficients (horizontal details) are the result of applying HPF on rows and LPF on columns. When both the rows and columns are filtered using HPF, we get the diagonal or detail coefficients HH. Further decompositions are done on the LL sub-band to obtain the next coarser scale of wavelet coefficients. All the elements within the individual rows of the matrix containing the coefficients are added, and the elements of the resulting vector are squared before adding to form a scalar value. Subsequently, this value is normalized by dividing it by the number of rows and columns of the original matrix.  also shows the resultant features A, H, H, V, V, D, Di.e. HH, after the above described process, results in feature D, and so on.","Significant features from MDCTA were then used to train and test a Support Vector Machine (SVM) classifier shown in the table below:",{"@attributes":{"id":"p-0300","num":"0408"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"left"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["Feature","Symptomatic","Asymptomatic","p-value"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Entropy","1.78 \u00b1 0.267","1.55 \u00b1 0.134","<0.0001"]},{"entry":["Angular2ndMoment","3.469E+06 \u00b1 ","3.926E+06 \u00b1 ","<0.0001"]},{"entry":[{},"3.599E+05","1.749E+05",{}]},{"entry":["ShortRunEmphasis (0\u00b0)","0.769 \u00b1 ","0.733 \u00b1 ","<0.0001"]},{"entry":[{},"2.506E\u221202","3.491E\u221202",{}]},{"entry":["D","4.752E\u221203 \u00b1 ","3.717E\u221203 \u00b1 ","<0.0001"]},{"entry":[{},"1.002E\u221203","5.210E\u221204"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}}}},"Sample results shows the Accuracy results when Atheromatic\u2122 system when applied to MDCTA:",{"@attributes":{"id":"p-0302","num":"0410"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"9"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"8","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"9","colwidth":"35pt","align":"center"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"9","align":"center","rowsep":"1"}}},{"entry":["Kernel",{},{},{},{},"Accuracy","PPV","Sensitivity","Specificity"]},{"entry":["Types","TN","FN","TP","FP","(%)","(%)","(%)","(%)"]},{"entry":{"@attributes":{"namest":"1","nameend":"9","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"9"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"21pt","align":"char","char":"."}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"7","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"8","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"9","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Linear","49","9","51","11","83.9","85.7","85.6","82.2"]},{"entry":"Kernel"},{"entry":["Poly","49","9","51","11","83.6","85.7","85","82.2"]},{"entry":"Kernel,"},{"entry":"O = 1"},{"entry":["Poly","49","2","58","11","88.9","85.4","96.7","81.1"]},{"entry":"Kernel,"},{"entry":"O = 2"},{"entry":["Poly","51","3","57","9","90","87.2","95.6","84.4"]},{"entry":"Kernel,"},{"entry":"O = 3"},{"entry":["RBF","48","3","57","12","87.2","84.3","95","79.4"]},{"entry":"Kernel"},{"entry":{"@attributes":{"namest":"1","nameend":"9","align":"center","rowsep":"1"}}}]}}]}}},"The best classification results (in terms of accuracy, sensitivity, and specificity) were obtained using the SVM classifier with a polynomial kernel of order 3. TN represents the True Negatives, FN, the False Negatives, TP, the True Positives, and FP, the False Positives. The highest accuracy presented by the proposed technique for plaque categorization was 90% recorded by the SVM classifier with the polynomial kernel of order 3. Even though the highest sensitivity of 96.7% was recorded by the polynomial kernel of order 2, its specificity is very low (81.1%). Such an imbalance in sensitivity and specificity values indicates that the classifier has more capability of classifying only one class correctly than the other. Hence, an optimal classifier should give equally high values for accuracy, sensitivity, and specificity, and therefore, based on the results, the polynomial kernel of order 3 was chosen as the most optimal SVM configuration for this particular work.","Cardiovascular Risk Score (CVRS) or INDEX when using MDCTA can be shown using the features: Entropy, Angular2ndMoment, ShortRunEmphasis (0\u00b0), D:",{"@attributes":{"id":"p-0305","num":"0413"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"maths":{"@attributes":{"id":"MATH-US-00076","num":"00076"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"CVRS","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"MDCTA"}},{"mn":"3","mo":"\u00d7","mrow":{"mo":["(",")"],"mrow":{"mi":"Entropy","mo":"-","mfrac":{"mrow":{"msub":{"mi":"log","mn":"10"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Angular2ndMoment","ShortRunEmphasis"],"mo":["\u2062","\u00d7","\u2062","\u00d7"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"msub":{"mi":"D","mn":"1"}}}},"mn":"10"}}}}],"mo":"="}}}}},{"entry":{}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Symptomatic","Asymptomatic","p-value"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["CVRS (MDCTA)","4.10 \u00b1 0.786","3.43 \u00b1 0.406","<0.0001"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}]}}},"The MDCTA images of plaques provide the clinician information about the plaque size and plaque composition. However, classification of CT carotid plaques into asymptomatic and symptomatic will add value to the MDCTA modality as such a classification will aid the vascular surgeons in making clearer decisions about whether a patient needs risky treatment or not. Plaque classification is a difficult problem and has now been demonstrated for both ultrasound and MDCTA modalities, though more cost effective in ultrasound. Our preliminary results of classifying CT plaque images into symptomatic and asymptomatic are quite promising. The SVM classifier with a polynomial kernel of order 3 presented the highest accuracy of 90%, sensitivity of 95.6%, and specificity of 84.4%. CVRS (MDCTA) also give a unique risk scoe that uses significant features. This CVRS (MDCTA) can be effectively used for monitoring the change in features, and well demonstrated solid tool for plaque characterization.",{"@attributes":{"id":"p-0307","num":"0415"},"figref":"FIG. 42","b":["3300","3310","3312","3314","3316","3318"]},{"@attributes":{"id":"p-0308","num":"0416"},"figref":"FIG. 43","b":"2700"},"The example computer system  includes a processor  (e.g., a central processing unit (CPU), a graphics processing unit (GPU), or both), a main memory  and a static memory , which communicate with each other via a bus . The computer system  may further include a video display unit  (e.g., a liquid crystal display (LCD) or a cathode ray tube (CRT)). The computer system  also includes an input device  (e.g., a keyboard), a cursor control device  (e.g., a mouse), a disk drive unit , a signal generation device  (e.g., a speaker) and a network interface device .","The disk drive unit  includes a machine-readable medium  on which is stored one or more sets of instructions (e.g., software ) embodying any one or more of the methodologies or functions described herein. The instructions  may also reside, completely or at least partially, within the main memory , the static memory , and\/or within the processor  during execution thereof by the computer system . The main memory  and the processor  also may constitute machine-readable media. The instructions  may further be transmitted or received over a network  via the network interface device . While the machine-readable medium  is shown in an example embodiment to be a single medium, the term \u201cmachine-readable medium\u201d should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and\/or associated caches and servers) that store the one or more sets of instructions. The term \u201cmachine-readable medium\u201d can also be taken to include any non-transitory medium that is capable of storing, encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the various embodiments, or that is capable of storing, encoding or carrying data structures utilized by or associated with such a set of instructions. The term \u201cmachine-readable medium\u201d can accordingly be taken to include, but not be limited to, solid-state memories, optical media, and magnetic media.","The Abstract of the Disclosure is provided to comply with 37 C.F.R. \u00a71.72(b), requiring an abstract that will allow the reader to quickly ascertain the nature of the technical disclosure. It is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition, in the foregoing Detailed Description, it can be seen that various features are grouped together in a single embodiment for the purpose of streamlining the disclosure. This method of disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather, as the following claims reflect, inventive subject matter lies in less than all features of a single disclosed embodiment. Thus the following claims are hereby incorporated into the Detailed Description, with each claim standing on its own as a separate embodiment."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0017","num":"0050"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0018","num":"0051"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0019","num":"0052"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0020","num":"0053"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0021","num":"0054"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0022","num":"0055"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0023","num":"0056"},"figref":"FIG. 6B"},{"@attributes":{"id":"p-0024","num":"0057"},"figref":"FIG. 6C"},{"@attributes":{"id":"p-0025","num":"0058"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0026","num":"0059"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0027","num":"0060"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0028","num":"0061"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0029","num":"0062"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0030","num":"0063"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0031","num":"0064"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0032","num":"0065"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0033","num":"0066"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0034","num":"0067"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0035","num":"0068"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0036","num":"0069"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0037","num":"0070"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0038","num":"0071"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0039","num":"0072"},"figref":["FIG. 21A","FIG. 21B"]},{"@attributes":{"id":"p-0040","num":"0073"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0041","num":"0074"},"figref":["FIG. 23","FIG. 23"]},{"@attributes":{"id":"p-0042","num":"0075"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0043","num":"0076"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0044","num":"0077"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0045","num":"0078"},"figref":["FIG. 27","FIG. 28"]},{"@attributes":{"id":"p-0046","num":"0079"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0047","num":"0080"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0048","num":"0081"},"figref":"FIGS. 31A","b":["31","31"]},{"@attributes":{"id":"p-0049","num":"0082"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0050","num":"0083"},"figref":"FIG. 33"},{"@attributes":{"id":"p-0051","num":"0084"},"figref":"FIGS. 34","b":["35","36","37"]},{"@attributes":{"id":"p-0052","num":"0085"},"figref":"FIG. 38"},{"@attributes":{"id":"p-0053","num":"0086"},"figref":"FIG. 39"},{"@attributes":{"id":"p-0054","num":"0087"},"figref":"FIG. 40"},{"@attributes":{"id":"p-0055","num":"0088"},"figref":"FIG. 41"},{"@attributes":{"id":"p-0056","num":"0089"},"figref":"FIG. 42"},{"@attributes":{"id":"p-0057","num":"0090"},"figref":"FIG. 43"},{"@attributes":{"id":"p-0058","num":"0091"},"figref":"FIG. 44"},{"@attributes":{"id":"p-0059","num":"0092"},"figref":"FIG. 45"},{"@attributes":{"id":"p-0060","num":"0093"},"figref":"FIG. 46"}]},"DETDESC":[{},{}]}
