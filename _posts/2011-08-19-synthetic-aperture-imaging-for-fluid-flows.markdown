---
title: Synthetic aperture imaging for fluid flows
abstract: A synthetic aperture three-dimensional fluid flow imaging apparatus is provided. The apparatus includes a plurality of cameras. At least two of the cameras are oriented to view a volume along mutually non-parallel directions. The cameras are connected to a programmable computer. The computer captures images from the cameras to generate three dimensional intensity fields. The computer can refocus the images on at least one refocus plane to generate reconstructed three dimensional intensity fields on a plane within the volume. Intensity field cross-correlation is performed on the reconstructed three dimensional intensity fields to extract velocity fields within the volume. The velocity fields represent velocities of objects or fluid phases within the volume. These velocity fields can be recorded for later use.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08922636&OS=08922636&RS=08922636
owner: The United States of America as represented by the Secretary of the Navy
number: 08922636
owner_city: Washington
owner_country: US
publication_date: 20110819
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["This application claims the benefit of U.S. Provisional Application No. 61\/375,510, filed Aug. 20, 2010 and which is entitled SYNTHETIC APERTURE PARTICLE IMAGE VELOCIMETRY by JESSE L. BELDEN, TADD T. TRUSCOTT and ALEXANDRA H. TECHET.","The invention described herein may be manufactured and used by or for the Government of the United States of America for Governmental purposes without the payment of any royalties thereon or therefor.","None.","(1) Field of the Invention","The invention relates to systems and methods for measuring particle velocities in general and particularly to systems and methods that employ synthetic aperture methods to measure particle velocities.","(2) Description of the Prior Art","Efforts for resolving three-dimensional velocity fields are justified by the need to experimentally resolve flows that are highly three-dimensional and to validate numerical simulations of complex flows. The ability to spatio-temporally resolve flow features from small to large scales in arbitrarily large volumes is the goal of any three dimensional particle image velocimetry system. Of course, there have been many roadblocks to achieving all of these goals with a single system, and compromises must be made. Two-dimensional particle image velocimetry (2D PIV) is the most pervasive method for resolving velocity fields, thus it is not surprising that recent efforts to resolve three dimensional flow fields have extended many of the fundamentals of two dimensional particle image velocimetry to the third dimension.","Several methods exist for resolving three dimensional particle fields, or any three dimensional scenes for that matter, but the methods of data acquisition seem to fall into three broad categories: multiple-viewpoints, holography and internal optics alteration.","One of the earliest, but still frequently utilized, methods for three dimensional particle image velocimetry is two camera stereoscopic particle image velocimetry, which is primarily used to resolve the third component of velocity within a thin light sheet. A three dimensional particle tracking velocimetry (PTV) method is known which resolves the location of individual particles imaged by two, three or four cameras in a stereoscopic configuration. They report measurements in a large volume (e.g. 200\u00d7160\u00d750 mm), but with very low seeding density (\u22481000 particles). Through precise calibration and knowledge of the imaging geometry, the particle field can be reconstructed. More recently, improvements to PTV methods have been made. In general, low seeding density is a typical limitation of PTV, yielding low spatial resolution in the vector fields.","Another technique which makes use of multiple viewpoints is defocusing digital particle image velocimetry (DDPIV). In theory, DDPIV capitalizes on the defocus blur of particles by placing an aperture with a defined pattern (usually pinholes arranged as an equilateral triangle) before the lens, which is a form of coded aperture imaging. The spread between three points generated by imaging a single particle corresponds to the distance from the camera along the Z dimension. In practice, the spread between particles is achieved using three off-axis pinhole cameras which causes a single point in space to appear at separate locations relative to the sensor of each camera. The images from all three camera sensors are superimposed onto a common coordinate system, an algorithm searches for patterns which form an equilateral triangle, and based on size and location of the triangle the three dimensional spatial coordinates of the point can be resolved. A main limitation of this technique appears to be seeding density, because the equilateral triangles formed by individual particles must be resolved to reconstruct the particle field. Simulations with seeding density of 0.038 particles per pixel (ppp) in a volume size of 100\u00d7100\u00d7100 mmhave been reported, and experiments with seeding density of 0.034 ppp in a volume size of 150\u00d7150\u00d7150 mm. The technique has also been efficiently implemented with a single camera using an aperture with color-coded pinholes, to measure velocity fields in a buoyancy driven flow in a 3.35\u00d72.5\u00d71.5 mmvolume with seeding density\u22480.001 ppp.","Tomographic-PIV also uses multiple viewpoints (usually 3-6 cameras) to obtain three dimensional velocity fields. Optical tomography reconstructs a three dimensional intensity field from the images on a finite number of cameras. The intensity fields are then subjected to three dimensional particle image velocimetry cross-correlation analysis. The seeding density for tomographic-PIV seems to be the largest attainable of the existing techniques. Simulations show volumetric reconstruction with seeding density of 0.05 ppp, and recent tomographic-PIV experiments typically have seeding density in the range of 0.02-0.08 ppp. The viewable depth of volumes in tomographic-PIV is typically three to five times smaller than the in-plane dimensions.","Holographic PIV (HPIV) is a technique in which the three-dimensional location of particles in a volume is deduced from the interference pattern of the light waves emanating from particles and the coherent reference wave that is incident upon the field. The nature of the interference pattern is used to back out information about the phase of light diffracted from objects in the volume, which is related to the distance of the objects from the sensor (i.e. depth in the volume). Holographic PIV makes use of this principle to image particle-laden volumes of fluids, and extract information about location of particles in the volume. In holography, the size of the observable volume is ultimately limited by the size and spatial resolution of the recording device. Very high resolution measurements of turbulent flow in a square duct using film-based HPIV have been reported, where particles were seeded to a reported density of 1-8 particles\/mmin a volume measuring 46.6\u00d746.6\u00d742.25 mm. Although film has much better resolution and is larger than digital recording sensors, difficulties of film based holographic PIV have been extensively cited, which have likely prevented the method from being widely utilized. In contrast, digital Holographic PIV is more readily usable, but is often limited to small volumes and low seeding density. A digital hybrid HPIV method has been implemented which allows for measurement in volumes with larger depth, but the size of the in-plane dimensions are limited by the physical size of the digital sensor, and seeding density remains low. Recent results of measurements in a turbulent boundary layer with increased seeding density (0.014 ppp) in a volume measuring 1.5\u00d72.5\u00d71.5 mmhave been presented.","Also known in the prior art is Stroke, U.S. Pat. No. 3,785,262, which is said to disclose a method and apparatus for synthesizing large-aperture optics by exposure of a single photographic plate either successively or simultaneously through small-aperture optics. The technique represents the extension of the \u201csynthetic-aperture radio telescope\u201d principle to the optical domain by the relatively simple photographic synthesis of a \u201chigh-resolution\u201d image in a single photograph, exposed either successively through sets of small \u201clow-resolution\u201d apertures successively placed to generate the spatial frequency components of the desired large aperture, or exposed simultaneously through a set of small \u201clow-resolution\u201d apertures having such optical characteristics and being so arranged as to generate the spatial frequency components of the desired large aperture.","Also known in the prior art is Kirk, U.S. Pat. No. 5,379,133, which is said to disclose an apparatus, a system, and a method wherein a synthetic aperture based sequence of image samples are generated with respect to a subject to be stereoscopically imaged. These sample images are presented to the spaced inputs of a holographic integrated combiner screen to be presented at an output aperture in laterally spaced mutual positioning. That spacing is selected, in one aspect, as one-half of the interpupillary distance of human eyes and thus binocular stereoscopic viewing at the aperture is achieved. The combiner screen may be utilized in conjunction with a holographic optical image combiner architecture which additionally employs a lens assembly such as a projecting lens to generate multi-zone outputs, each zone of which may be presented for stereoscopic viewing at a discrete viewing station. Correction for chromatic aberration of the holographic optical components is described.","Also known in the prior art is Adrian et al., U.S. Pat. No. 5,548,419, which is said to disclose a holographic particle image velocimeter that employs stereoscopic recording of particle images, taken from two different perspectives and at two distinct points in time for each perspective, on a single holographic film plate. The different perspectives are provided by two optical assemblies, each including a collecting lens, a prism and a focusing lens. Collimated laser energy is pulsed through a fluid stream, with elements carried in the stream scattering light, some of which is collected by each collecting lens. The respective focusing lenses are configured to form images of the scattered light near the holographic plate. The particle images stored on the plate are reconstructed using the same optical assemblies employed in recording, by transferring the film plate and optical assemblies as a single integral unit to a reconstruction site. At the reconstruction site, reconstruction beams, phase conjugates of the reference beams used in recording the image, are directed to the plate, then selectively through either one of the optical assemblies, to form an image reflecting the chosen perspective at the two points in time.","Also known in the prior art is Raffel et al., U.S. Pat. No. 5,610,703, which is said to disclose a digital particle image velocimetry (DPIV) method for contactless measurement of three dimensional flow velocities comprising the steps of seeding a flow with tracer particles; repeatedly illuminating a plane-like interrogation volume of the seeded flow; projecting the repeatedly illuminated interrogation volume onto at least a photo sensor in a projection direction for recording pictures of the illuminated interrogation volume; and determining the three dimensional flow velocities from the pictures of the repeatedly illuminated interrogation volume recorded by the photo sensor. The plane-like interrogation volume of the invention comprises at least two partial volumes positioned parallel to each other with regard to the projection direction. The step of repeatedly illuminating the interrogation volume comprises the step of illuminating the partial volumes in such a way that the pictures of different partial volumes are distinguishable from each other. The step of determining the three dimensional flow velocities of the flow comprises the steps of calculating a local autocorrelation function of a double exposed picture of the same partial volume, or calculating a local cross-correlation function between two separate pictures of the same partial volume, calculating a local cross-correlation function between two pictures of two different partial volumes, determining the sign of the out-of-plane component of the local flow velocities by using the location of a peak of the local cross-correlation function between the two pictures of the two different partial volumes, and determining the magnitude of the out-of-plane component of the local flow velocities by using the peak heights of peaks of both local correlation functions.","Also known in the prior art is McDowell et al., U.S. Pat. No. 5,905,568, which is said to disclose a system and a method for measuring three-dimensional velocities at a plurality of points in a fluid employing at least two cameras, positioned approximately perpendicular to one another. The cameras are calibrated to accurately represent image coordinates in world coordinate system. The two-dimensional views of the cameras are recorded for image processing and centroid coordinate determination. Any overlapping particle clusters are decomposed into constituent centroids. The tracer particles are tracked on a two-dimensional basis and then stereo matched to obtain three-dimensional locations of the particles as a function of time so that velocities can be measured therefrom. The stereo imaging velocimetry technique of the present invention provides a full-field, quantitative, three-dimensional map of any optically transparent fluid which is seeded with tracer particles.","Also known in the prior art is Meng et al., U.S. Pat. No. 6,496,262, which is said to disclose a holographic particle image velocimetry (HPIV) system that employs holograms of two time-separated particle fields, illuminated by separate reference beams on a single recording medium. 90-degree scattering is utilized for the object wave, in order to improve Numerical Aperture and resolve the third dimension of the hologram. The proposed HPIV system then uses substantially the same optical geometry for the reconstruction process. A CCD camera is utilized to extract particle subimages, thin slice by thin slice, and a centroid-finding algorithm is applied to extract centroid locations for each volume. The concise cross correlation (CCC) algorithm for extracting velocity vector fields from the centroid data is an important enabling feature of the proposed system. Correlations are calculated between subsets of centroids representing the images or cubes, and velocity vectors are computed from the individual correlations. Higher spatial resolution can also be obtained by pairing particle centroids individually.","Also known in the prior art is Schaller, U.S. Pat. No. 6,525,822, which is said to disclose a three-dimensional particle image velocimetry method, in which a stream system containing light-scattering particles is exposed continuously over a certain period or at least two discrete points in time using a laser light sheet, and a hologram is produced and evaluated. Increased accuracy in determining velocity is achieved by evaluating the hologram with regard to its phase information interferometrically by using a reconstruction wave and superimposing a reference wave.","Also known in the prior art is Japanese patent application publication JP2006058321A1, which is said to disclose a three-dimensional confocal microscopic system designed such that images used for micro PIV are acquired at the same focusing position by using accurate position information from an actuator. The three-dimensional confocal microscopic system includes: a confocal scanner for acquiring the slice images of a micro conduit as confocal images via a microscope; a video camera for outputting the image data of the confocal images; an actuator for moving the focusing position of the objective lens of the microscope in the direction of its optical axis; a control section for generating a scanning waveform signal for scanning the objective lens in the direction of the optical axis via the actuator; and an image processing section for calculating the speed of a fluid in the micro conduit on the basis of at least the two image data acquired by the video camera. Based upon a position signal output from the actuator, the system acquires at least the two images in a prescribed position in the micro conduit.","There is a need for improved particle image velocimetry in three dimensions.","A primary objective of the present invention is to provide a synthetic aperture particle three-dimensional image velocimetry apparatus having at least one refocus plane.","It is also a primary objective of the present invention to provide synthetic aperture three-dimensional (3D) imaging for fluid flows.","It is also an objective of the present invention to produce a synthetic aperture three dimensional imaging apparatus having a plurality of cameras.","It is yet another objective of the present invention to provide apparatus for imaging multiple phase fluid flows.","According to one aspect, the invention features a synthetic aperture particle three-dimensional (3D) image velocimetry apparatus. The apparatus comprises a plurality of image recording devices. At least two of said plurality of image recording devices are oriented so as to view a volume to be imaged along mutually non-parallel directions. A data processing apparatus based on a general purpose programmable computer is configured to operate under control of a set of instructions recorded on a machine readable medium. When operating under control of said set of instructions, said data processing apparatus is configured to perform the steps of: capturing a plurality of images using said at least two image recording devices oriented along mutually non-parallel directions to generate three dimensional intensity fields; refocusing said plurality of images on at least one refocus plane in the field of view of each image recording device to generate reconstructed three dimensional intensity fields on a plane placed at a location within said volume to be imaged. performing intensity field cross-correlation on said reconstructed three dimensional intensity fields to extract therefrom velocity fields within said volume to be imaged, said velocity fields representing velocities of objects or fluid phases within the volume to be imaged; and recording said velocity fields for later use.","In one embodiment, the image recording devices are cameras.","In another embodiment, the plurality of image recording devices are controlled by said general purpose programmable computer when operating under control of said set of instructions recorded on said machine readable medium.","In yet another embodiment, the synthetic aperture particle three dimensional image velocimetry apparatus further comprises an illumination source configured to illuminate at least a portion of said volume within said volume to be imaged.","In still another embodiment, wherein said illumination source is a laser.","In a further embodiment, a plurality of images captured simultaneously is used to derive said velocity fields within said volume to be imaged.","In yet a further embodiment, said data processing apparatus is configured to perform a preprocess step prior to the refocusing step.","According to another aspect, the invention relates to a method of providing synthetic aperture particle three-dimensional (3D) image velocimetry data. The method comprises the steps of: capturing a plurality of images using a plurality of image recording devices, at least two of said plurality of image recording devices oriented so as to view a region of interest along mutually non-parallel directions to generate three dimensional intensity fields; refocusing said plurality of images on at least one refocus planes in the field of view of each image recording device to generate reconstructed three dimensional intensity fields on a plane placed at a location within the imaged volume using a data processing apparatus based on a general purpose programmable computer, said data processing apparatus operating under control of a set of instructions recorded on a machine readable medium; performing intensity field cross-correlation on said reconstructed three dimensional intensity fields to extract velocity fields therefrom; and recording said velocity fields for later use.","In one embodiment, the method further comprises a preprocess step prior to the refocusing step.","In another embodiment, the preprocess step comprises the steps of: subtracting a sliding minimum value having a window size; convolving image data with a 3\u00d73 Gaussian kernel; equalizing histograms to a histogram of said image with the highest contrast; increasing said contrast by trimming a bottom range and a top range of intensity values; and subtracting a sliding minimum value having a window size.","In yet another embodiment said bottom range and said top range of intensity values are 0.1% of said intensity values.","The foregoing and other objects, aspects, features, and advantages of the invention will become more apparent from the following description and from the claims.","We present a new method for resolving three-dimensional (3D) fluid velocity fields using a technique called synthetic aperture particle image velocimetry (SAPIV). By fusing methods from the imaging community pertaining to light field imaging with concepts that drive experimental fluid mechanics, SAPIV overcomes many of the inherent challenges of three dimensional particle image velocimetry (3D PIV). This method offers the ability to digitally refocus a three dimensional flow field at arbitrary focal planes throughout a volume. The viewable out-of-plane dimension (Z) can be on the same order as the viewable in-plane dimensions (X-Y), and these dimensions can be scaled from tens to hundreds of millimeters. Furthermore, digital refocusing provides the ability to \u201csee-through\u201d partial occlusions, enabling measurements in densely seeded volumes. The advantages are achieved using a camera array (typically at least 5 cameras) to image the seeded fluid volume. The theoretical limits on refocused plane spacing and viewable depth are derived and explored as a function of camera optics and spacing of the array. A geometric optics model and simulated PIV images are used to investigate system performance for various camera layouts, measurement volume sizes and seeding density; performance is quantified by the ability to reconstruct the three dimensional intensity field, and resolve three dimensional vector fields in densely seeded simulated flows. SAPIV shows the ability to reconstruct fields with high seeding density and large volume size. Finally, results from an experimental implementation of SAPIV using a low cost 8-camera array to study a vortex ring in a 65\u00d740\u00d732 mmvolume are presented. The three dimensional particle image velocimetry results are compared with two dimensional particle image velocimetry data to demonstrate the capability of the 3D SAPIV technique.","The technique described herein falls into the multiple-viewpoint category, and makes use of an algorithm known as \u201csynthetic aperture refocusing\u201d to examine the imaged volume. Herein, we focus on the application of the principles of synthetic aperture imaging to develop a measurement system for resolving three-dimensional fluid velocity fields. The system performance is evaluated theoretically and numerically. The practical utility of SAPIV is demonstrated through an experimental study of a canonical vortex ring.","The synthetic aperture PIV technique is implemented using an array of synchronized charge coupled device cameras distributed such that the fields of view overlap. Images are recombined in software using a refocusing algorithm. The result is sharply focused particles in the plane of interest (high intensity), whereas particles out-of-plane appear blurred (low intensity). Due to the multiple camera viewpoints and the effective reduction of signal strength of out-of-plane particles in image recombination, particles that would otherwise be occluded can in fact be seen. The three dimensional intensity field of particle-laden flows can be reconstructed by refocusing throughout the entire volume and thresholding out particles with lower intensities. Typical three dimensional particle image velocimetry techniques can then be applied to the intensity fields to extract velocity data. This technique enables larger volumes to be resolved with greater seeding density, yielding higher spatial resolution than prior three dimensional particle image velocimetry methods. Additionally, the algorithms are simple and robust and build on established image processing techniques. Results of simulated particle fields show the ability to reconstruct three dimensional volumes with seeding densities of 0.17 ppp (6.73 particles\/mm) when the ratio of X-Y to Z dimension is 5:1 (50\u00d750\u00d710 mmvolume), and 0.05 ppp (1.07 particles\/mm) when the ratio of X-Y to Z dimension is 4:3 (40\u00d740\u00d730 mmvolume). A vortex ring flow field is imposed on each of these simulated volumes, and three dimensional particle image velocimetry analysis yields highly-resolved vector fields.","Results are presented from an experimental implementation of SAPIV using a custom built camera array to study a vortex ring in a 65\u00d740\u00d732 mmvolume. Design considerations for experimental 3D SAPIV implementation are discussed throughout the description. The experimental data presented are benchmarked with two dimensional particle image velocimetry, and demonstrate the ability of SAPIV to resolve three dimensional flow fields, providing a useful and flexible tool for making three dimensional particle image velocimetry measurements.","Synthetic aperture PIV is based on the concept of light field imaging, which involves sampling a large number of light rays from a scene to allow for scene reparameterization. In practice, one method used by researchers in the imaging community for sampling a large number of rays is to use a camera array. It is believed that the novelty of the approach presented herein is the application of the reparameterization methods to three dimensional particle image velocimetry, and the development of the technique into a measurement system, including the generation of algorithms to reconstruct three dimensional particle intensity fields from the refocused images. The technique is broken down into sequential components as described below.","Image capture is performed using an array of cameras typically arranged in a multi-baseline stereo configuration, which view the scene from different viewpoints. The cameras can be placed at arbitrary locations and angles as long as the desired refocused planes are in the field of view (FOV) of each camera. The depth of field of each camera is large enough such that the entire volume of interest is in focus. The multiple viewpoints array captures many more light rays than can be seen with one camera (i.e. light field imaging).","In synthetic aperture techniques, images captured by an array of cameras each with large depths of field are post-processed to generate one image with a narrow depth of field on a specific focal plane. Through synthetic aperture refocusing, further post-processing allows the location of the focal plane to be arbitrarily placed within the imaged volume. This technique provides many desirable implications for three dimensional particle image velocimetry; namely, a particle-laden volume can be captured at one instant in time and synthetic aperture refocusing allows for the reconstruction of particles at known depths throughout the volume post capture.","In general, the post-processing for synthetic aperture refocusing involves projecting all images onto a focal surface (planar or otherwise) in the scene on which the geometry is known, averaging the projected images to generate one image, and repeating for an arbitrary number of focal planes. The working principle of the synthetic aperture technique is demonstrated with a simplified example.  provides a diagram of the case where two cameras  and  view the same portion of a reference plane . Each camera has a lens and and a detector and . Camera  has a lens center of projection Cwhich is positioned at X axis location X, and camera  has a lens center of projection Cwhich is positioned at X axis location X. Particles A and B are in an imaged volume within the field of view of cameras  and . The image from particle A follows rays Aand A. The image from particle B follows rays Band B. Detectors or image sensors and are parallel to each other and the camera centers of projection Cand Clie on the same plane . The geometric imaging optics are described by four parameters: the focal length (f) of lenses and ; distances from the lenses and to the front of the imaged volume (s); distance from lenses and to image plane (s) and magnification (M(Z)=\u2212s\/(s+Z)). Also, the focal length is related to sand sthrough the imaging condition: 1\/f=1\/s+1\/s.","If the images from each camera are mapped to the reference plane , and then all images (now in reference plane coordinates) are averaged, the particle A will be in sharp focus in the averaged image. However, particles at different depths or distances such as particle B on secondary plane  will appear out of focus because of the parallax between camera centers of projection Cand C. In the average of the reference plane  aligned images, the images of particle B from the two cameras will appear at the points  and  where rays Band Bin  intersect reference plane , which are separated by \u0394. By adding more cameras, mapping images to the reference plane and averaging, the signal of particle A will grow increasingly larger than that of the off-plane particles.","The concept is shown schematically in three dimensions in , which shows image capture by a nine camera array  from a measurement volume . Particle A is on plane A, and particle B is plane B. Planes A and B are different planes in measurement volume . A typical image from a camera is shown at . These images are subsequently refocused on two planes  and . Plane  is refocused to the measurement volume  plane A having particle A, and plane  is refocused to the measurement volume  plane B having particle B. By positioning the cameras on a sufficiently large baseline (larger separation between camera centers of projection), some of the cameras can see particles which are occluded in other images. Therefore, the partially occluded particles retain a high signal in the refocused image.","The goal of the synthetic aperture PIV technique is to reconstruct three dimensional particle intensity fields which are suitable for cross-correlation based three dimensional particle image velocimetry processing. The starting point for volume reconstruction is the implementation of the synthetic aperture algorithm to generate refocused images on planes throughout the volume. Thereafter, the actual particle field must be extracted from the refocused images and organized into a volume with quantifiable locations.","To implement synthetic aperture refocusing, relationships between the image coordinates and focal planes in world coordinates must be established (i.e., a set of mapping functions). In the simulations presented herein, cameras are represented with a pinhole model, and the mapping functions can be generated by an algorithm known in the art. This algorithm is suitable for pinhole cameras with no image distortion and no changes in optical media in the line of sight (e.g. air-glass-water transition). In practice, mapping functions that can account for distortion and changes in optical media can be generated by more sophisticated calibration techniques, as is done for the experiment discussed below. For example, a planar calibration grid can be placed at several planes throughout the volume to generate mapping functions, and error in these functions is reduced using a volume self-calibration technique. The map-shift-average algorithm represents the most basic that is used in synthetic aperture refocusing, but it is helpful in describing the technique and is also implemented in the simulations presented below.","The first step in the map-shift-average algorithm is to align all images on a reference plane. The reference plane is an actual plane in the view of the cameras which, in practice, is defined using a planar calibration grid. Images are aligned on the reference plane by applying a homography which, is a central projection mapping between two planes given by\n\nbx\u2032=Hx\u2003\u2003(1A)\n",{"@attributes":{"id":"p-0077","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"b","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mi":["x","\u2032"]}}}},{"mtd":{"mrow":{"mi":"b","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mi":["y","\u2032"]}}}},{"mtd":{"mi":"b"}}]}},"mi":"i"},"mo":"=","mrow":{"msub":[{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"msub":{"mi":"h","mn":"11"}},{"msub":{"mi":"h","mn":"12"}},{"msub":{"mi":"h","mn":"13"}}]},{"mtd":[{"msub":{"mi":"h","mn":"21"}},{"msub":{"mi":"h","mn":"22"}},{"msub":{"mi":"h","mn":"23"}}]},{"mtd":[{"msub":{"mi":"h","mn":"31"}},{"msub":{"mi":"h","mn":"32"}},{"msub":{"mi":"h","mn":"33"}}]}]}},"mi":"i"},{"mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mi":"x"}},{"mtd":{"mi":"y"}},{"mtd":{"mn":"1"}}]}},"mi":"i"}],"mo":"\u2062"}}},{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"\u2062","mi":"B"}}}]}}}},"br":{},"sub":["33","i","RP",{"sub2":"i"}]},"Light field imaging with camera arrays offers the ability to refocus on arbitrarily shaped focal surfaces. For the simulations herein, we restrict the situation to refocusing on fronto-parallel planes where the raw images are captured with a camera array where all camera centers of projection lie on the same plane. For this restricted case, the mapping that must be applied to refocus on each fronto-parallel plane is simply a shift of the reference-plane aligned images by an amount proportional to the relative camera locations. The coordinates of image points on the new focal plane are given by",{"@attributes":{"id":"p-0079","num":"0078"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"msup":{"mi":["x","\u2033"]}}},{"mtd":{"msup":{"mi":["y","\u2033"]}}},{"mtd":{"mn":"1"}}]}},"mi":"i"},"mo":"=","mrow":{"msub":[{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"0"},{"mrow":{"msub":[{"mi":["\u03bc","k"]},{"mi":"X","msub":{"mi":["C","i"]}}],"mo":["\u2062","\u2062","\u2062"],"mi":"\u0394","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]},{"mtd":[{"mn":"0"},{"mn":"1"},{"mrow":{"msub":[{"mi":["\u03bc","k"]},{"mi":"Y","msub":{"mi":["C","i"]}}],"mo":["\u2062","\u2062","\u2062"],"mi":"\u0394","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"}]}]}},"mi":"i"},{"mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"msup":{"mi":["x","\u2032"]}}},{"mtd":{"msup":{"mi":["y","\u2032"]}}},{"mtd":{"mn":"1"}}]}},"mi":"i"}],"mo":"\u2062"}}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}},"br":{},"sub":["k ","C",{"sub2":"i "},"C",{"sub2":"i "},"FP",{"sub2":"ki"}]},"In the final step in the refocusing algorithm, the mapped and shifted images (now all aligned on the kth focal plane) are averaged. The resultant image is referred to as the refocused image, and is given by",{"@attributes":{"id":"p-0081","num":"0080"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":"I","mrow":{"mi":"S","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["A","k"]}}},"mo":"=","mrow":{"mfrac":{"mn":"1","mi":"N"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","msub":{"mi":"I","mrow":{"mi":"F","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":"P","mrow":{"mi":["k","i"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}}}}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}},"br":{}},"Theoretical analysis of the focal plane spacing and viewable depth is presented using the two camera model shown in , A, B, C and D. Here, we define the focal plane spacing, \u03b4Z, as the distance between planes throughout the measurement volume, where Z is the distance from the front of the measurement volume to a given plane. The viewable depth is the total depth dimension (Z) of the measurement volume. The simple two camera model is sufficiently general to establish the theoretical limits of the system, and the results can be applied to design and predict the performance of various arrangements. A full scale simulated model is implemented hereinafter to examine the effects of parameters not considered in this theoretical treatment, such as particle seeding density, number of cameras and mapping error.","To examine the effect of camera layout on focal plane spacing, we start by considering the relationship between points in physical space and the images of these points. The coordinates of a general point, A (see ), projected onto the imaging plane of one of the cameras is given by",{"@attributes":{"id":"p-0084","num":"0083"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["x","A"]},"mo":"=","mrow":{"mrow":{"mrow":[{"mo":["[","]"],"mfrac":{"mrow":[{"mo":"-","msub":{"mi":["s","i"]}},{"msub":[{"mi":["s","o"]},{"mi":["Z","A"]}],"mo":"+"}]}},{"mo":["(",")"],"mrow":{"msub":[{"mi":["X","A"]},{"mi":["X","C"]}],"mo":"-"}}],"mo":"\u2062"},"mo":"-","msub":{"mi":["d","C"]}}}},{"mrow":{"mo":["(",")"],"mn":"4"}}]}}}},"br":{},"sub":["A ","A ","C ","C "]},{"@attributes":{"id":"p-0085","num":"0084"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":["\u03b4","X"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"=","mfrac":{"mrow":[{"mo":"-","mi":"p"},{"mi":"M","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Z"}}]}}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}}}},"br":{}},"As described earlier, the first step in the reconstruction is to align the images on a reference plane. In , reference plane  is chosen (arbitrarily) to be the plane in physical space on which point A lies. In , the image sensors and are shown with the centers aligned along the z-axes of the local image coordinates.  shows the image sensors and shifted to align the images on reference plane . This requires a shift of the image sensor (or equivalently, the digital image) of camera  by an amount equal to s=x\u2212x(the disparity of the images of point A) in the negative x-direction of the camera  coordinate system. Since point B does not lie on the reference plane, s=x\u2212xdoes not equal s, and thus points at different depths are disambiguated.  shows the shifting and addition of multiple image sensors , , , and to give refocused image .","The focal plane spacing, \u03b4Z, is dictated by the image plane shift required to refocus on another plane. To move from the reference plane to the secondary plane shown in the model, the image plane must be shifted by an amount equal to s\u2212s, which is given by",{"@attributes":{"id":"p-0088","num":"0087"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":[{"mi":["s","A"]},{"mi":["s","B"]}],"mo":"-"},{"mi":"\u0394","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["X","C"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mfrac":[{"mrow":[{"mo":"-","msub":{"mi":["s","i"]}},{"msub":[{"mi":["s","o"]},{"mi":["Z","B"]}],"mo":"+"}]},{"mrow":[{"mo":"-","msub":{"mi":["s","i"]}},{"msub":[{"mi":["s","o"]},{"mi":["Z","A"]}],"mo":"+"}]}],"mo":"-"}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}}}},"br":{},"sub":["C","C2","C1 ","A","B","A","B"]},{"@attributes":{"id":"p-0089","num":"0088"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"\u0394","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["X","C"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mfrac":{"mrow":[{"mo":"-","msub":{"mi":["s","i"]}},{"mrow":[{"mo":["(",")"],"mrow":{"msub":{"mi":["s","o"]},"mo":"+","mi":"Z"}},{"mi":["\u03b4","Z"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}],"mo":"+"}]},"mo":"-","mrow":{"mi":"M","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Z"}}}}}},"mo":"=","mi":"p"}},{"mrow":{"mo":["(",")"],"mn":"7"}}]}}}}},"Solving Equation 7 for \u03b4Z gives",{"@attributes":{"id":"p-0091","num":"0090"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["\u03b4","Z"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mo":"-","mrow":{"msub":{"mi":["s","i"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mfrac":[{"mrow":[{"mi":"\u0394","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["X","C"]}},{"mi":"p","mo":"+","mrow":{"mi":"\u0394","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["X","C"]},"mo":"\u00b7","mrow":{"mi":"M","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Z"}}}}}]},{"mn":"1","mrow":{"mi":"M","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Z"}}}],"mo":"-"}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"8"}}]}}}}},"Dividing the top and bottom of the first term in the bracket by 1\/syields",{"@attributes":{"id":"p-0093","num":"0092"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["\u03b4","Z"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mo":"-","mrow":{"msub":{"mi":["s","i"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mfrac":[{"mrow":[{"mo":["(",")"],"mfrac":{"mrow":{"mi":"\u0394","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["X","C"]}},"msub":{"mi":["s","o"]}}},{"mfrac":{"mi":"p","msub":{"mi":["s","o"]}},"mo":"+","mrow":{"mrow":[{"mo":["(",")"],"mfrac":{"mrow":{"mi":"\u0394","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["X","C"]}},"msub":{"mi":["s","o"]}}},{"mi":"M","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Z"}}],"mo":"\u00b7"}}]},{"mn":"1","mrow":{"mi":"M","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Z"}}}],"mo":"-"}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}}}}},"Equation 9 contains the convenient geometric parameter,",{"@attributes":{"id":"p-0095","num":"0094"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mrow":{"mi":"\u0394","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["X","C"]}},"msub":{"mi":["s","o"]}},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0096","num":"0095"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"D","mo":"\u2261","mrow":{"mfrac":{"mrow":{"mi":"\u0394","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["X","C"]}},"msub":{"mi":["s","o"]}},"mo":"."}}}},"br":{}},{"@attributes":{"id":"p-0097","num":"0096"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":[{"mrow":[{"mi":["\u03b4","Z"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":["\u03b4","X"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mrow":[{"mfrac":[{"mn":"1","mi":"D"},{"mi":"Z","mrow":{"mi":"D","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["s","o"]}}}],"mo":"+"},{"mn":"1","mo":"-","mfrac":{"mrow":[{"mi":["\u03b4","X"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":"D","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["s","o"]}}]}}]}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"10"}}]}}}}},"For typical PIV applications, it is reasonable to assume \u03b4X=Ds; applying this approximation yields",{"@attributes":{"id":"p-0099","num":"0098"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":{"mrow":[{"mi":["\u03b4","Z"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":["\u03b4","X"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},"mo":"\u2245","mrow":{"mfrac":[{"mn":"1","mi":"D"},{"mi":"Z","mrow":{"mi":"D","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["s","o"]}}}],"mo":"+"}}},{"mrow":{"mo":["(",")"],"mn":"11"}}]}}}}},"Therefore, the ratio \u03b4Z\/\u03b4X is a linear function of Z with intercept defined by the camera baseline and slope defined by the camera baseline and the imaging system optics. The depth of field in the reconstructed volume is directly related to \u03b4Z\/\u03b4X. When \u03b4Z\/\u03b4X is small, the camera lines of sight are at large angles to one another, and the physical depth over which particles are in focus is small (small depth of field). Conversely, larger \u03b4Z\/\u03b4X leads to a larger depth of field, which is manifested as reconstructed particles which are elongated in Z.","In theory, the overall viewable range in X, Y and Z is limited only by the field of view (FOV) and depth of field (DOF) of a single camera of the array. In reality, images from the outer cameras of the array must be shifted with respect to the central camera image to refocus at different depths. The outer edges of the refocused images have a lower signal-to-noise ratio than regions where all images contribute to the average. This effective limitation on the field of view can be characterized by the number of image shifts required to refocus through an entire volume, which is given by",{"@attributes":{"id":"p-0102","num":"0101"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"N","mo":"=","mfrac":{"msub":{"mi":["Z","o"]},"mrow":{"mi":["\u03b4","Z"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}},"br":{},"sub":"o "},"Once the refocused images have been generated, the images must be processed to extract the particles in the plane of interest from the blurred, lower intensity background. (The blurred lower intensity background represents particles on other planes.)  shows a zoomed view (250\u00d7250 pixels) of simulated image from the central camera of the array and  shows a refocused image from the 50\u00d750\u00d710 mmvolume simulation which will be described in detail hereinafter. The refocused image has a higher background \u201cnoise\u201d level than the raw image or a typical two dimensional particle image velocimetry image due to the averaging of multiple images, however the \u201cnoise\u201d is probabilistic. If we consider the intensity fields of the N images aligned on a given focal plane to be independent and identically distributed random variables, I, I, . . . , I, with means \u03bc and standard deviations \u03c3, then the central limit theorem states that the distribution of the average of the random variables will be Gaussian with mean \u03bc and standard deviation of \u03c3\/\u221a{square root over (N)}. Therefore, the intensity distribution of a refocused image (which is an average of the focal plane aligned images) can be modeled as Gaussian.  shows the intensity histogram for a reference plane-aligned image from one camera of the array and the histogram for the refocused image in  is shown in . Clearly, the distribution of intensity for the single camera image is not Gaussian, but the shape of the distribution of the refocused image follows a Gaussian distribution quite well, as indicated by the model fit. As more particles are added, the mean of the individual images becomes larger, and thus the mean of the refocused image becomes larger. Plane of interest particles appear with high intensity values, and are thus outliers with respect to the distribution of the refocused image. Intensity thresholding can be applied to retain plane of interest particles and eliminate background \u201cnoise\u201d caused by other planes from the images. It was found that a threshold value around three standard deviations above the mean intensity of each refocused image yielded acceptable reconstruction.  shows the refocused image from  now thresholded to reveal the particles in the plane of interest. By refocusing throughout the volume and thresholding the refocused images, the three-dimensional intensity field is reconstructed. By detecting the outliers in the refocused images, the true particle plane of interest can be reconstructed, attesting to the simplicity of the SAPIV technique.","A 5\u00d75 camera array model is simulated to investigate the system performance as a function of particle seeding density, size of measurement volume and error in the mapping function. The effect of array layout and camera number on reconstruction performance is also investigated by changing the spacing between cameras and removing certain cameras from the array, respectively. Cameras are arranged with centers of projection on the same plane and equal spacing along X and Y between all camera centers of projection (unless otherwise noted). In order to overlap the fields of view, the cameras are angled such that the ray passing through the center of the measurement volume intersects the center of the image sensor. For this arrangement, the map-shift-average algorithm applies. The perspective due to the angling of the cameras is compensated for when the reference plane homographies are applied to the images.","The ability of the system to resolve the particle field in four different measurement volume sizes is examined. The volume sizes (X\u00d7Y\u00d7Z) are 50\u00d750\u00d710 mm, 40\u00d740\u00d730 mm, 50\u00d750\u00d750 mmand 100\u00d7100\u00d7100 mm. For each volume, the system performance is evaluated for several different camera baselines, D, and for each camera baseline the particle seeding density is varied. For all simulations presented herein, the cameras are modeled with 85 mm focal length lenses and the imaging sensors are 1000 pixels\u00d71000 pixels with a pixel pitch of 10 \u03bcm. For the 100\u00d7100\u00d7100 mmvolume, the initial magnification is set to M (Z=0)=\u22120.1 and for the other three volumes the magnification is M (Z=0)=\u22120.2.","Reference plane homographies are calculated for each camera from calibration images of known points on several Z planes with the central camera of the array as the reference camera. The camera positions relative to the central camera are established using a calibration method known in the art. The calibration images are used to establish the shift required to refocus at each depth in order to define the conversion between voxels and physical units in the Z dimension. Herein, we define a voxel as having the dimensions of a pixel in X and Y, and dimension equal to the focal plane spacing in Z. Because integer pixel shifts are used in the map-shift-average algorithm, a given calibration depth may not correspond exactly to any of the refocused images. Therefore, the actual voxel to Z calibration is approximated by fitting a gaussian curve to the summed intensity from refocused images surrounding each calibration plane and finding the voxel corresponding to the peak of the fit.","Particles are randomly seeded within the volume and imaged using the camera array. Once the image plane coordinates of a point are known, a realistic model of the intensity distribution must be applied. A standard method of simulated image generation is to apply a Gaussian intensity profile. The distribution is applied to each camera image for each pixel location, which forms an image similar to the one presented in .","After simulated images have been formed by each camera, the map-shift-average algorithm, followed by intensity thresholding and three-dimensional field reconstruction, is carried out for each numerical experiment. In order to quantify how well the intensity field is reconstructed, a known measure of reconstruction quality, Q, is applied here:",{"@attributes":{"id":"p-0109","num":"0108"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"Q","mo":"=","mfrac":{"mrow":{"munder":{"mo":"\u2211","mrow":{"mi":["X","Y","Z"],"mo":[",",","]}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["E","r"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["X","Y","Z"],"mo":[",",","]}}},{"msub":{"mi":["E","s"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["X","Y","Z"],"mo":[",",","]}}}],"mo":"\u00b7"}},"msqrt":{"mrow":{"munder":{"mo":"\u2211","mrow":{"mi":["X","Y","Z"],"mo":[",",","]}},"mo":"\u2062","mrow":{"mrow":[{"msubsup":{"mi":["E","r"],"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["X","Y","Z"],"mo":[",",","]}}},{"munder":{"mo":"\u2211","mrow":{"mi":["X","Y","Z"],"mo":[",",","]}},"mo":"\u2062","mrow":{"msubsup":{"mi":["E","s"],"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["X","Y","Z"],"mo":[",",","]}}}}],"mo":"\u00b7"}}}}}},{"mrow":{"mo":["(",")"],"mn":"13"}}]}}}},"br":{},"sub":["r ","s "]},"Baseline spacing affects the Z dimension of the voxels such that they represent larger physical sizes than the X-Y dimensions, therefore the intensity distribution in the synthesized field is scaled in Z in voxel space such that in physical space the intensity distribution is spherically symmetric. This ensures that a perfectly reconstructed particle would yield a Q value of 1 when compared to the synthesized field.","The value of Q is calculated for each numerical experiment conducted, and we use the requirement of Q\u22670.75 for the reconstruction to be considered adequate. In all cases other than the 40\u00d740\u00d730 mmmeasurement volume, the outer  edge pixels were cropped prior to calculating Q because of the effective loss in field of view as described earlier (in the 40\u00d740\u00d730 mm, the images do not fill the entire image sensor and thus the outer pixels of the reconstructed images contain no particles). , B and C present the reconstruction quality as a function of particle seeding density for various camera baselines in each volume. The number of seeded particles, maximum particle seeding density (C) and number of particles per pixel (ppp) in each case are summarized in Table 1. To find the maximum seeding density, simple linear interpolation of the data was used to find the seeding density corresponding to Q=0.75.",{"@attributes":{"id":"p-0112","num":"0111"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"28pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}},{"entry":[{},{},{},{},"C","Part.\/",{}]},{"entry":["Measurement",{},{},{},"(part.\/","pixel",{}]},{"entry":["Volume (mm)","D","\u03b4X","\u03b4Z\/\u03b4X","mm)","(ppp)","# part."]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"7","colwidth":"28pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"0.2","0.05","5.00",">10",">0.25",">250000"]},{"entry":["50 \u00d7 50 \u00d7 10","0.4","0.05","2.5","6.73","0.17","168150"]},{"entry":[{},"0.5","0.05","2","3.34","0.08","83464"]},{"entry":[{},"0.5","0.05","2.00","5.29","0.13","132230"]},{"entry":[{},"(uneven)",{},{},{},{},{}]},{"entry":["40 \u00d7 40 \u00d7 30","0.4 ","0.05","2.51","1.07","0.05","51179"]},{"entry":[{},"(uneven)",{},{},{},{},{}]},{"entry":[{},"0.1","0.05","10.24","0.70","0.09","87573"]},{"entry":["50 \u00d7 50 \u00d7 50","0.2","0.05","5.13","0.42","0.05","52072"]},{"entry":[{},"0.4","0.05","2.56","0.14","0.02","17282"]},{"entry":[{},"0.11","0.1","9.40","0.16","0.16","164200"]},{"entry":["100 \u00d7 100 \u00d7 100","0.21","0.1","4.70","0.10","0.10","96149"]},{"entry":[{},"0.32","0.1","3.13","0.05","0.05","51854"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}}]}}},"In the case of the 50\u00d750\u00d710 mmmeasurement volume, the reconstruction quality falls off with increasing seeding density, and also decreases with increasing camera baselines. For larger seeding density, the reduction in reconstruction quality is expected; the occurrence of off-plane particle overlap is increased, and the overall signal-to-noise ratio decreases in the refocused images. The reason for reduced reconstruction quality with increasing baseline is less obvious. Investigation of the data reveals that the reason for the degradation in reconstruction quality with increasing baseline is due to the more extreme warping of the particle images imposed by the homography which maps images to the reference plane. The particles become elongated in the mapped image which raises the background noise in the refocused images. This may be mitigated by placing the outer cameras of the array a normalized distance D\/2 from the inner cameras (which determine the focal plane spacing of the system and would still be placed a normalized distance D from the central camera) but requires interpolation when shifting images from the outer cameras of the array. This has been implemented in the case labeled D=0.5 uneven spacing, and indeed the reconstruction quality is improved for the same seeding density. For this configuration, the achievable seeding density is C=5.29 part.\/mmand the resultant particles per pixel is 0.13.","Simulations in the 50\u00d750\u00d750 mmvolume show a similar trend as for the 50\u00d750\u00d710 mmvolume, with Q decreasing with increasing C more rapidly for a larger camera baseline. However, the achievable seeding density is lower than for the volume with smaller depth (e.g. C=0.4 part.\/mmfor D=0.2). The reasons for the lower seeding density and the lower actual number of particles that can be seeded as compared to the 50\u00d750\u00d710 mmvolume are four-fold. First, the larger depth of field of each camera requires a larger f-number which increases the particle image diameter. This results in a larger mean intensity in the refocused image. Second, the depth of the volume creates more likelihood of particle overlap on each simulated image, which can, in a sense, decrease the dynamic range of the system by increasing the likelihood of saturated pixels. Third, the larger depth creates a higher likelihood of overlapping of many different out-of-focus particles in the refocused images. These false particles may be retained in the thresholding if enough images overlap. Finally, the limitation on the field of view imposed by the image shift contributes to the loss in reconstruction quality because some images contribute zero values to the average toward the outer regions of the refocused images, thus particles in the plane of interest have a lower intensity value. This can be mitigated by averaging only the portions of the image which are known to contribute to the refocused image, but that technique has not been implemented here. Tuning the camera array and reconstruction algorithms to enable more seeding in the very large volumes is the subject of ongoing work. By decreasing the dimensions of the volume somewhat, more particles can be seeded, even in volumes where the Z dimension approaches that of the X-Y dimensions, and all are relatively large. Simulations in the 40\u00d740\u00d730 mmvolume are carried out at only one array configuration\u2014D=0.4 uneven spacing\u2014and it was found that a seeding density of C=1.07 part.\/mmcorresponding to 0.05 particles per pixel could be achieved. As shown the Section titled Synthetic three dimensional Flow Fields, this seeding density allows three dimensional particle image velocimetry measurements to be made in this volume with reasonable spatial resolution.","Finally, the camera magnifications are reduced to accommodate the large 100\u00d7100\u00d7100 mmmeasurement volume. The trend for reconstruction quality as a function of seeding density and baseline is similar to that observed for the other volumes studied. The total number of particles that can be seeded is, however, larger than for the 50\u00d750\u00d750 mmvolume for comparable camera baselines. Thus, trading off X-Y resolution allows for more particles to be seeded even with increasing depth dimension. Overall, these results indicate that the synthetic aperture PIV technique is capable of imaging extremely densely seeded volumes where the depth dimension is somewhat reduced, and still quite densely seeded volumes when the Z dimension approaches that of the X-Y dimensions.","The effect of camera number on reconstruction quality is investigated in the 50\u00d750\u00d710 mmvolume by using only some of the cameras in the array.  shows Q as a function of camera number with seeding densities of 2, 3 and 5 part.\/mm. Clearly, the reconstruction quality reaches a point of diminishing returns as more cameras are added, and the most efficient number of cameras seems to be in the range of 10-15.","Two synthetic flow fields are simulated to assess the ability of the synthetic aperture PIV method in reconstructing three dimensional intensity fields that are suitable for cross-correlation based three dimensional particle image velocimetry analysis. In each simulation, the fluid motion is prescribed by the same equation for a vortex ring as known in the art, where the velocity magnitude is given by",{"@attributes":{"id":"p-0118","num":"0117"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mo":["\uf603","\uf604"],"mi":"V"},{"mfrac":{"mrow":{"mn":"8","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mi":["K","R"]},"mi":"l"},"mo":"\u2062","msup":{"mi":"\u2147","mrow":{"mo":"-","mfrac":{"mi":["R","l"]}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"14"}}]}}}},"br":{},"sup":["3 ","3"]},"Since the reconstructed volumes are intensity fields, a cross-correlation based PIV calculation is suitable for calculating vector fields. Many different cross-correlation techniques are know in the art. In the present study, we have adapted an open-source two dimensional particle image velocimetry code, matPIV, for three dimensional functionality. Other PIV calculation programs could be used for this purpose. A multipass algorithm with a final interrogation volume containing 32\u00d732\u00d716 voxels and 75% overlap generates 327448 vectors (122\u00d7122\u00d722 vectors). The Z dimension of the interrogation volumes in voxel units is half that of the X-Y dimension because the focal plane spacing is twice the pixel size for this camera configuration. Each interrogation volume contains approximately 20 particles, based on the gross particle seeding density.",{"@attributes":{"id":"p-0120","num":"0119"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0121","num":"0120"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"mrow":[{"mi":["\u03b4","Z"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":["\u03b4","X"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}}},"br":{},"figref":"FIG. 8B"},"To quantitatively evaluate the performance, both the reconstructed three dimensional intensity fields and the synthesized three dimensional intensity fields are processed using the three dimensional adaptation of matPIV, and each is compared to the exact velocity field. The error is defined as the difference between the processed and exact field at every vector location. By comparing the PIV results for both fields, error due to the PIV algorithm itself can be identified. Both the synthesized and reconstructed volumes are processed using exactly the same window sizes, PIV code and filtering routines. We will refer to the vector fields resulting from PIV processing of the reconstructed three dimensional intensity fields and the synthetic three dimensional intensity fields as the reconstructed vector field, and synthesized vector field, respectively.","Error can be computed for each vector component for the reconstructed vector field. This calculation indicates that most of the error is due to the PIV algorithm itself, and a much smaller percentage is due to the actual intensity field reconstruction. This is not surprising since the three dimensional particle image velocimetry algorithm is not very sophisticated, and we would expect a reduction in error magnitude with a more advanced three dimensional particle image velocimetry algorithm.","In the second simulated flow, a vortex ring of the same size is oriented with the central axis of the toroid parallel to the X-axis, such that the ring spans deeper into the flow in the Z dimension. The 5\u00d75 model camera array is used with spacing D=0.4 (uneven spacing, see Table 1) and the magnification is set to M(Z=0)=\u221202. The maximum displacement in the flow field is 0.37 mm which corresponds to 7.3 voxels in X and Y and 2.9 voxels in Z. A particle seeding density of C=1 part\/(mm)in a 40\u00d740\u00d730 mmvolume results in a distribution of 48,000 particles (resulting in Q=0.75). The lower seeding density requires larger interrogation volume sizes in order to contain an appropriate number of particles, therefore a final interrogation volume containing 60\u00d760\u00d724 voxels is used with each containing 27 particles based on the seeding density. Using 50% overlap in the multipass three dimensional particle image velocimetry calculation yields 18,432 vectors (32\u00d732\u00d718), which includes the imaged area that contained no seeding particles (with a magnification of \u22120.2, images of the seeded volume did not span the entire imaging sensor).","To illustrate the capabilities of the SAPIV technique in practice, a canonical three dimensional flow field is captured experimentally using an array of eight cameras. Instantaneous 3D-3C SAPIV and classic two dimensional particle image velocimetry velocity data of a piston-generated vortex ring are acquired for comparison. A diagram of the experimental setup is given in .","The experiment is conducted in a glass tank  filled with fluid  and seeded with neutrally buoyant particles . A cylindrical piston-driven vortex ring generator  is mounted in the center of the tank . In this embodiment water was used as fluid . A camera array  is oriented to image tank  from the side. Camera array  has nine cameras  mounted on a common frame . Cameras  are angled in order to overlap the fields of view. As shown previously, reconstruction quality reaches a point of diminishing returns as more cameras  are added, and that the most efficient number of cameras is in the range of 10-15, as shown in .","In this embodiment, cameras  in array  are capable of capturing 1024\u00d7768 pixels, 8 bit, monochromatic images at 10 frames per second. The cameras are connected to a single computer  which records the data. Classic PIV frame straddling timing is used to obtain appropriate image pair time spacing. A pulsed laser  joined to a beam expander  is used to illuminate the particle volume. A timing box  synchronizes the cameras  and laser .","In use, piston  produces a vortex ring  in fluid . Vortex ring  causes movement of particles . Particles  are illuminated at intervals by beam  from beam expander . Simultaneously, as triggered by timing box , Camera array  records images from illuminated particles . Recorded images are provided to computer  for processing.","To achieve proper focus in synthetic aperture images, accurate mapping between image and world coordinates is required. The mapping is found by imaging a precision machined calibration plate traversed through the target volume with Z location increments of 2 mm. Since the SAPIV technique involves reprojecting the images onto several planes throughout the volume, a suitable coordinate system must be established on the calibration plate. Here, we use the average calibration in pixels\/mm from the center camera image of the plate at the Z location farthest from the cameras to convert the reference geometry of the calibration plate from mm to pixels. Second-order polynomial fits are used to map image coordinates to reference coordinates on each Z calibration plane, and linear interpolation is used to find the polynomial fits on Z planes between each calibration plane. This approach follows that of prior Tomographic-PIV studies where polynomial fits are used to deal with the distortion introduced when imaging through an air-glass-water transition. The error in the mapping functions should be less than 0.45 pixels for adequate reconstruction in SAPIV. Volume self-calibration is not implemented in the present experiment, yet reconstruction still yields a volume which is suitable for three dimensional particle image velocimetry. Implementing volume self-calibration will improve greatly the particle yield rate in the reconstruction.","The synthetic aperture images are formed with focal plane spacing of 0.2 mm in Z. Theoretically, the number of focal planes that can be generated within an illuminated volume is infinite, but the information on each plane will not necessarily be unique, as the sharpness of a refocused object is determined by the degree to which mapped images of the object overlap. For example, it is possible to generate focal planes very close to each other by shifting all images by a very small amount. However, if the shift size is much smaller than the refocused object, the two refocused images will be essentially indistinguishable, in which case the information is redundant. Therefore, focal plane spacing (which determines voxel size) should be made large enough so as not to retain redundant information. The depth over which objects are in focus can be controlled by changing the camera baseline, D; for the present experiment, D=0.2. Ultimately, smaller focal plane spacing should yield better resolution in the Z dimension of the reconstructed fields, and thus the vector fields. The influence of focal plane spacing and camera baseline on the accuracy and resolution of three dimensional particle image velocimetry vector fields is the subject of ongoing work.","Other volumetric PIV studies have discussed the need for image preprocessing to deal with non-uniformities in laser profiles and pulse intensities, as well as to remove background noise. Prior to refocusing, images are subjected preprocessing. A sliding minimum was subtracted from the images with a window size of 10 pixels. The image was convolved with a 3\u00d73 Gaussian kernel. The histograms of the images were equalized to the histogram of the image with the highest contrast. The contrast of each image was increased by trimming the bottom and top 0.1% of intensity values. Finally the step of subtracting a sliding minimum was conducted again.","After preprocessing, the images are mapped to each plane throughout the volume, averaged to form the synthetic refocused image, and thresholded to retain particles to generate an intensity volume for each time instant. Because the mapping functions are not simple linear homographies, interpolation is required to re-project the images; here, a bilinear interpolation is used.  shows a preprocessed image from the array.  shows a synthetic aperture refocused image at one depth.  shows a thresholded image at the same depth.","Once reconstructed, the intensity volumes are ready for cross-correlation based three dimensional particle image velocimetry analysis; the adapted version of matPIV is again employed. A multi-pass algorithm with one pass at an initial interrogation volume size of 128\u00d7128\u00d764 voxels and two passes at an final interrogation volume size of 64\u00d764\u00d732 voxels and 50% overlap generates a 23\u00d731\u00d711 vector field. Each 64\u00d764\u00d732 voxels interrogation volume contains approximately 15 particles. The resultant vector field resolution is 2.1 mm in X and Y and 3.2 mm in Z. Post-processing consists of a filter based on signal-to-noise ratio of the cross-correlation peak, a global filter which removes vectors five standard deviations above the mean of all vectors, and a local filter which removes vectors which deviate by more than three standard deviations from the median of a 3\u00d73\u00d73 vector window. The filtered field is interpolated using linear interpolation and smoothed with a 3\u00d73\u00d73 gaussian filter. At this point some mention should be made of the overall processing time. The time required to reconstruct the two volumes used to generate the three dimensional vector field is 18% of the time required for the three dimensional particle image velocimetry processing of the fields. Therefore, the limiting time factor in processing is the three dimensional particle image velocimetry analysis, which demonstrates the relative efficiency of the synthetic aperture refocusing technique.","Experimental results for the instantaneous three dimensional velocity data of the vortex ring are shown in FIG. A; the resultant three dimensional vector field and an iso-vorticity contour (magnitude 9 s) are plotted at one time instant. For ease of comparison between the 3D SAPIV and two dimensional particle image velocimetry data, we normalize all lengths by the orifice diameter (D=30 mm), as known in the art. The origin of the X-Y-Z global coordinate system is placed approximately at the center of the outlet orifice of the vortex generator, with Y positive up and Z decreasing in the direction away from the cameras. In  the ring has propagated to a distance Y\/D\u22483.72 below the orifice outlet. Every vector in Z is plotted and every second vector is plotted in X and Y directions. The measured SAPIV volume is only limited by the volume which is illuminated by the laser. The iso-vorticity contour shows an incomplete ring, due to the fact that the ring is not centered in the laser volume and part of the ring is outside of the illuminated region. Cross sectional slices of vorticity, with planes at Z\/D=0.003 and X\/D=0, are plotted in . As expected, isolated regions of vorticity are located where the ring passes through the planar cut in the three dimensional volume. The vorticity magnitude on the X-Z slice is slightly lower than for the X-Y, which is likely due to the lower resolution of the vector field in the Z-dimension. By locating the peaks in the normal vorticity component in each core cross-section on the plane passing through Z\/D=0.003, the normalized diameter of the vortex is found to be D\/D=0.77.","Finally, to serve as another quantitative measure for benchmarking the 3D SAPIV system the circulation, \u0393, is calculated on a variety of planes. The circulation is calculated by taking the line integral of velocity around a rectangular contour on a particular plane. Here, we calculate the circulation in two dimensional data, as well as on several planes for three dimensional data, using rectangular contours of increasing size to encompass up to one half of any two dimensional slice (i.e., encompassing one vortex core). Each contour is centered around the location of maximum surface-normal vorticity on the plane under consideration. The inset of  shows the location and angle of each plane on which circulation is computed. For the three dimensional data, nine planes are chosen with angles varying between 0\u00b0-180\u00b0, as well as one additional plane located at Z\/D=0.11, on which the circulation is calculated for both cuts through the vortex ring core.  shows the circulation plotted against area enclosed by the integration contour for each plane.","For a symmetric vortex ring, the circulation on half of any one plane containing the axis passing through the ring center should be constant. From , it can be seen that the magnitude of circulation remains relatively constant regardless of plane angle, for a given integration contour size. The maximum difference in peak circulation is 2.69 cm\/s (13.5% of maximum) for the angled planes. On the plane passing through Z\/D=0.11, as well as for the two dimensional data (laser plane at Z\/D=0.15), the peak circulation is reached at a smaller integration contour size than for the planes passing through the central ring axis, because the bisected cross-sections are offset from the center of the ring. Nonetheless, the maximum circulation magnitude on the offset planes for both the two dimensional and three dimensional data is within 7% of the maximum found on the planes which pass approximately through the central axis of the ring.","The quantitative agreement between the 3D SAPIV data and the 2DPIV data confirms the viability of the SAPIV technique for making accurate measurements in three dimensional volumes. Although the simulations show the ability to reconstruct very densely seeded fields, the seeding density was kept rather low (0.026 ppp in the raw images) in this experiment to ensure proper reconstruction. However, it is expected that increased seeding density can be achieved in practice.","Synthetic aperture PIV offers a method for imaging complex three dimensional flow-fields with high seeding densities or significant phase differences and partial occlusions. SAPIV draws on the concept of light field imaging, which involves sampling and encoding many rays from a three dimensional scene, and is practically implemented with an array of cameras. Recombining the camera array images using synthetic aperture refocusing provides many desirable capabilities for three dimensional fluid flow measurement; namely, the ability to digitally refocus on isolated planes post-capture, to effectively \u201csee-through\u201d partial occlusions by exploiting the multiple camera viewpoints and to capture volumetric information at a single time instant. We expect the capabilities of the synthetic aperture system to be flexible enough to measure in other flow environments, such as multi-phase and bubbly flows or flows with partial obstructions.","Simulations showed that a single array arrangement allowed for measurement within volumes with depth ranging from 10 mm to 50 mm. Altering the optics on the cameras enables further scalability of the measurement range, as was shown in the simulation of the 100\u00d7100\u00d7100 mmvolume. In this manner, the behavior of the camera array is similar to the behavior of a single-lens camera: we have control over the viewable depth for a given magnification and can change the field of view by changing the magnification. Two simulated flow fields demonstrated the performance of the technique in resolving vector fields with high resolution and in a relatively large volume. The focal plane spacing of the system in the Z dimension, which is related to the depth of field, was theoretically derived for the simple model of two coplanar image sensors. The observed focal plane spacing in the simulations agreed extremely well with that predicted by the theory, despite the fact that the camera image sensors in the simulated model were not coplanar (the cameras were angled). This shows that the concise theory derived is an accurate and useful tool for predicting the depth of field of the refocused images as a function of camera baseline and optics.","The results of the three dimensional particle image velocimetry experiment indicate that SAPIV is a viable technique for efficiently and accurately resolving a range of three dimensional flow fields. In practice, the hardware implementation successfully captured an instantaneous three dimensional velocity vector field for a vortex ring, with only eight cameras, in a volume with an aspect ratio (Z:X-Y) that is comparable to some of the largest found in the literature. three dimensional SAPIV results compared well with the two dimensional particle image velocimetry experimental data for a similar vortex ring. The signal-to-noise ratio of plane of interest particles for each of the simulated cases was much lower than for the SAPIV experiment, indicating that seeding density can be greatly increased in future experimental studies, which will allow for increased vector resolution.","All data processing was performed on a commercially available personal computer. Reconstruction and three dimensional particle image velocimetry analysis was implemented in Matlab\u00ae; however, other available software could be used. However, the computation time to implement the map-shift-average algorithm, refocus and threshold the images, and assemble them into the reconstructed volume for two timesteps in the simulated 40\u00d740\u00d730 mmvolume required 15% of the time taken to compute the vector fields with 3 passes and 50% overlap (40 minutes to reconstruct the two timesteps, and 223 minutes to perform the PIV processing). For the SAPIV experiment, the time required to reconstruct the two volumes used to generate the three dimensional vector field (62 minutes) was 18% of the time required for the three dimensional particle image velocimetry processing of the fields (414 minutes). This attests to the relative simplicity of the refocusing algorithm. Therefore, the actual three dimensional particle image velocimetry calculations will dominate the computation time for synthetic aperture PIV.","It is believed that volume self-calibration can improve the image reconstruction quality and allow for increased seeding densities. The ability of the SAPIV technique to reconstruct the intensity fields without the use of volume self-calibration in the present study underscores the capability of the method. In addition, increasing the camera baseline spacing is expected to increase Z resolution. By increasing the baseline, the depth-of-field can be reduced allowing for more distinction between particles in the Z direction, which we expect will yield higher resolution in Z.","Synthetic Aperture PIV (SAPIV) provides a method for 3D-3C, quantitative flow velocimetry, which offers the ability to reconstruct very dense flow fields in relatively large volumes for a wide range of applications.",{"@attributes":{"id":"p-0144","num":"0143"},"figref":"FIG. 13","b":["100","110","100","112","112","114","110","100","110","100","118","110","110","120","122","114","118","110","124","124","114","126","126"]},"A computer  is provided for controlling and collecting data from the apparatus. Computer  can be joined to light source  in order to control actuation and strobing. Array  is joined to computer  in order to control and coordinate array  and to receive data from array . Computer  is joined to a storage device  and to a display device . Display device  allows direct user control of the apparatus. Display  can also allow direct viewing of data from array. Computer  can process the data as described in the preceding text or can communicate the data for further processing.","Although the theoretical description given herein is thought to be correct, the operation of the devices described and claimed herein does not depend upon the accuracy or validity of the theoretical description. That is, later theoretical developments that may explain the observed results on a basis different from the theory presented herein will not detract from the inventions described herein.","Any patent, patent application, or publication identified in the specification is hereby incorporated by reference herein in its entirety. Any material, or portion thereof, that is said to be incorporated by reference herein, but which conflicts with existing definitions, statements, or other disclosure material explicitly set forth herein is only incorporated to the extent that no conflict arises between that incorporated material and the present disclosure material. In the event of a conflict, the conflict is to be resolved in favor of the present disclosure as the preferred disclosure.","It will be understood that many additional changes in the details, materials, steps and arrangement of parts, which have been herein described and illustrated in order to explain the nature of the invention, may be made by those skilled in the art within the principle and scope of the invention as expressed in the appended claims."],"GOVINT":[{},{}],"heading":["STATEMENT OF GOVERNMENT INTEREST","CROSS REFERENCE TO OTHER PATENT APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The objects and features of the invention can be better understood with reference to the drawings described below, and the claims. The drawings are not necessarily to scale, emphasis instead generally being placed upon illustrating the principles of the invention. In the drawings, like numerals are used to indicate like parts throughout the various views.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 2B","b":"2"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 2C"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 2D"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 4B"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 5","FIG. 3B"]},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 6A","sup":["3","3 "]},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 6B","sup":["3","3 "]},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 6C","sup":["3","3 "]},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 8A","sup":"3 "},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 8B","sup":"3 "},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 10A"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 10B"},{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 10C"},{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 11A","sup":"\u22121"},{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 11B"},{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
