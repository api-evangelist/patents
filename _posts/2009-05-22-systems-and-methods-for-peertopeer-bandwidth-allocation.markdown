---
title: Systems and methods for peer-to-peer bandwidth allocation
abstract: Apparatus, systems, and methods can operate to provide efficient data transfer in a peer-to-peer network. A list of peer computers can be accessed and sorted by a data exchange metric. A requester peer is selected by traversing the list from a peer computer with a smallest data exchange metric to a peer computer with a largest data exchange metric to identify a peer computer with a pending data block request, the peer computer with the pending data block request being the requester peer and having an associated data exchange metric. A data block is then transmitted to the requester peer and the data exchange metric associated with the requester peer is updated to provide an updated data exchange metric for the requester peer. The list of peer computers can then be resorted. Additional apparatus, systems, and methods are disclosed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09037657&OS=09037657&RS=09037657
owner: The Trustees of Columbia University in the City of New York
number: 09037657
owner_city: New York
owner_country: US
publication_date: 20090522
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED PATENT DOCUMENTS","FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Overview of Fairness in P2P Systems","Example Systems And Methods of Operation","Hardware Platform","Additional Notes"],"p":["This patent application is a nationalization under 35 U.S.C. 371 of PCT\/US2009\/044996, filed May 22, 2009 and published as WO 2010\/077379 A1 on Jul. 8, 2010, which claims the benefit of priority under 35 U.S.C. \u00a7119(e) to U.S. Provisional Patent Application Ser. No. 61\/055,917 filed on May 23, 2008 and entitled \u201cSystems, Methods, and Media for Peer-to-Peer File Sharing\u201d; U.S. Provisional Patent Application Ser. No. 61\/214,107 filed on Apr. 20, 2009 and entitled \u201cFairstream: Improving Peer-to-Peer Streaming Performance Through Fairness\u201d; and U.S. Provisional Patent Application Ser. No. 61\/214,105 filed on Apr. 20, 2009 and entitled \u201cFairtorrent: Bringing Fairness to Peer-to-Peer Systems\u201d, the contents of which applications and publication are incorporated herein by reference in their entirety.","The present application relates generally to computer networking and more particularly, but not by way of limitation, to managing peer-to-peer bandwidth allocation.","Peer-to-Peer (P2P) systems are growing in popularity. These types of systems may be used to share content between hundreds or even thousands of users. Such systems may share static content, such as a music file, or streaming content, such as a video feed. In contrast to a purely centralized distribution model, P2P distribution relies on the cumulative network resources of the peers in the network. In general, peers act as both clients and servers to one another\u2014requesting and receiving data from one peer while serving and transmitting data to another. This cooperation is a fundamental advantage in a P2P system.","One problem that arises in P2P systems is a lack of fairness in bandwidth allocation. That is, some peers do not contribute service commensurate with what they receive, or vice versa. As a result, peers are disincentivized from contributing upload bandwidth and free-riders, those that receive data with little or no reciprocal contributions, become more prevalent. As a result, in limited bandwidth situations, peers throughout the P2P system will observe poor data transmission regardless of the contribution of any given peer. In addition, when the provisioning is low, the client can easily take all of the available upload bandwidth from the users who already contribute a lot, and cripple other network-bound processes running on the users' machines. In the other extreme, if users were allowed to configure their bandwidth contribution, without any incentive mechanism, P2P streaming systems would invite a lot of free-riding and degrade performance even further.","Free-riding, while a problem in P2P file-sharing systems, is even more significant in P2P streaming systems. While in most file-sharing systems users would prefer faster downloads, they may be satisfied with an eventual download completion. In contrast, when a user watches a stream in real-time, any drop in the download rate results in missed packets and decreased quality of the stream. Thus, for a system without an incentive mechanism, an increase in free-riding may result in poor quality for all users.","This application describes systems and methods that provide effective data distribution in a peer-to-peer network and despite the presence of free-riders.","Example 1 describes a computer-implemented method comprising accessing a list of peer computers, the list sorted by a data exchange metric; selecting a requester peer by traversing the list from a peer computer with a smallest data exchange metric to a peer computer with a largest data exchange metric to identify a peer computer with a pending data block request, the peer computer with the pending data block request being the requester peer and having an associated data exchange metric; and transmitting a data block to the requester peer.","In Example 2, the method of Example 1 is optionally performed such that selecting the requester peer comprises determining whether the requester peer is able to receive the data block, and transmitting the data block comprises transmitting the data block to the requester peer when the requester peer is able to receive the data block.","In Example 3, the methods of any one or more of Examples 1 or 2 are optionally performed such that selecting the requester peer comprises maintaining a total amount of received data associated with each peer computer in the list of peer computers; and using the total amount of received data to select among a plurality of peer computers having equal data exchange metrics.","In Example 4, the methods of any one or more of Examples 1-3 are optionally performed such that using the total amount comprises selecting, from the plurality of peer computers having equal data exchange metrics, a peer computer having a largest total amount of transmitted data.","In Example 5, the methods of any one or more of Examples 1-4 are optionally performed such that the data exchange metric represents the difference between bytes sent to a peer computer and bytes received from the peer computer.","In Example 6, the methods of any one or more of Examples 1-5 are optionally performed comprising updating the data exchange metric associated with the requester peer to provide an updated data exchange metric for the requester peer; and resorting the list of peer computers.","In Example 7, the methods of any one or more of Examples 1-6 are optionally performed such that updating the data exchange metric comprises adjusting the data exchange metric by the size of the data block transmitted to the requester peer.","In Example 8, the methods of any one or more of Examples 1-7 are optionally performed such that resorting the list of peer computers comprises removing the requester peer from the list; and inserting the requester peer into the list based on the updated data exchange metric.","In Example 9, the methods of any one or more of Examples 1-8 are optionally performed comprising determining whether the requester peer already has a data block corresponding to the pending data block request; and selecting an alternative data block to transmit to the requester peer when the requester peer already has the data block corresponding to the pending data block request.","In Example 10, the methods of any one or more of Examples 1-9 are optionally performed such that selecting the alternative data block comprises identifying a rare data block.","In Example 11, the methods of any one or more of Examples 1-10 are optionally performed comprising determining whether a playback position of the requester peer is beyond a sequence number of a data block corresponding to the pending data block request; and selecting an alternative data block to transmit to the requester peer when the playback position of the requester peer is beyond the sequence number of the data block corresponding to the pending data block request.","In Example 12, the methods of any one or more of Examples 1-11 are optionally performed such that selecting the alternative data block comprises identifying a rare data block.","Example 13 describes a system comprising a memory; and a control module coupled to the memory, the control module configured to: access a list of peer computers, the list sorted by a data exchange metric; select a requester peer by traversing the list from a peer computer with a smallest data exchange metric to a peer computer with a largest data exchange metric to identify a peer computer with a pending data block request, the peer computer with the pending data block request being the requester peer and having an associated data exchange metric; and transmit a data block to the requester peer.","In Example 14, the system of Example 13 is optionally configured such that the control module is configured to select the requester peer by determining whether the requester peer is able to receive the data block, and transmit the data block by transmitting the data block to the requester peer when the requester peer is able to receive the data block.","In Example 15, the system of any one or more of Examples 13 or 14 are optionally configured such that wherein the control module is configured to select the requester peer by: maintaining a total amount of received data associated with each peer computer in the list of peer computers; and use the total amount of received data to select among a plurality of peer computers having equal data exchange metrics.","In Example 16, the system of any one or more of Examples 13-15 are optionally configured such that the control module is configured to use the total amount by selecting, from the plurality of peer computers having equal data exchange metrics, a peer computer having a largest total amount of transmitted data.","In Example 17, the system of any one or more of Examples 13-16 are optionally configured such that the data exchange metric represents the difference between bytes sent to a peer computer and bytes received from the peer computer.","In Example 18, the system or any one or more of Examples 13-17 are optionally configured such that the control module is configured to: update the data exchange metric associated with the requester peer to provide an updated data exchange metric for the requester peer; and resort the list of peer computers.","In Example 19, the system or any one or more of Examples 13-18 are optionally configured such that the control module is configured to update the data exchange metric by adjusting the data exchange metric by the size of the data block transmitted to the requester peer.","In Example 20, the system of any one or more of Examples 13-19 are optionally configured such that the control module is configured to resort the list of peer computers by: removing the requester peer from the list; and inserting the requester peer into the list based on the updated data exchange metric.","In Example 21, the system of any one or more of Examples 13-20 are optionally configured such that the control module is configured to: determine whether the requester peer already has a data block corresponding to the pending data block request; and select an alternative data block to transmit to the requester peer when the requester peer already has the data block corresponding to the pending data block request, wherein the alternative data block is a rare block.","In Example 22, the system of any one or more of Examples 13-21 are optionally configured such that the control module is configured to: determine whether a playback position of the requester peer is beyond a sequence number of a data block corresponding to the pending data block request; and select an alternative data block to transmit to the requester peer when the playback position of the requester peer is beyond the sequence number of the data block corresponding to the pending data block request, wherein the alternative data block is a rare block.","Example 23 describes a machine-readable medium including instructions, which when executed by a machine, cause the machine to access a list of peer computers, the list sorted by a data exchange metric; select a requester peer by traversing the list from a peer computer with a smallest data exchange metric to a peer computer with a largest data exchange metric to identify a peer computer with a pending data block request, the peer computer with the pending data block request being the requester peer and having an associated data exchange metric; and transmit a data block to the requester peer.","This section is intended to provide an overview of subject matter of the present application. It is not intended to provide an exclusive or exhaustive explanation of the inventive subject matter. The Detailed Description is included to provide further information about the present application.","In the drawings, which are not necessarily drawn to scale, like numerals may describe similar components in different views. Like numerals having different letter suffixes may represent different instances of similar components. The figures illustrate generally, by way of example, but not by way of limitation, various embodiments discussed in the present document.","The usage of Peer-to-Peer (P2P) file-sharing applications on the Internet has experienced explosive growth. Many users and businesses now rely on P2P file-sharing for distributing videos, software, and documents. P2P file-sharing applications are plagued by unfairness in how bandwidth among peers is used and allocated. Peers do not receive service commensurate with what they contribute to the system. Unfairness can cause many performance problems. Peers can be disincentivized from contributing more upload bandwidth. A growing number of free riders, e.g., peers who cap their upload bandwidth to zero or a small value, take as much as possible from the system while contributing little resources. Lack of real-time rewards for contributions can lead to poor performance, particularly in streaming applications.","Fair bandwidth allocation in P2P systems can be difficult to achieve for several reasons. First, bandwidth resources are distributed all over the Internet and belong to, and are controlled by, individual peers, not by a single party. Unlike a router or a server, there is no central entity to control or arbitrate access to resources. Second, the amount of bandwidth resources available is unknown in advance and peers cannot be relied upon to honestly provide their own resources. Third, bandwidth resources can vary over time for several reasons, such as network conditions, peers joining and leaving the system, mobile peers connecting at different access points, and users using available bandwidth for other activities. Finally, it is difficult to design a fair allocation mechanism that is strong enough to withstand attempts by free-riders and strategic peers to manipulate the system.","Several approaches have attempted to address the problem of fair bandwidth exchange. For example, one approach splits a peer's upload bandwidth equally among a subset of neighboring peers and adjusts this subset based on estimates of their bandwidth rates. This approach is referred to as a tit-for-tat (TFT) heuristic. Another approach is block-based TFT used by peers among one another, which augments TFT with hard limits on the amount of data one peer can owe another. In another approach, a peer's upload bandwidth is split among its neighbors in proportion to past estimates of its neighbors' bandwidth contributions.","BitTorrent employs a rate-based tit-for-tat (TFT) heuristic to incentivize peers to upload and to attempt to provide fair exchange of bandwidth between peers. Peers participating in the download of the same target file form a swarm. The target file is conceptually broken up into pieces (typically 256 KB). Peers tell one another which pieces of the target file they already have and request missing pieces from one another. Requests are typically made for 16 KB sub-pieces. Peers that already have the entire file are seeds. Peers that are still downloading pieces of the file are leechers. TFT is used in a swarm to attempt to enable fair bandwidth exchange during the current download of a file. It operates by having each BitTorrent client upload to N other peers in round-robin fashion, where N-k of the peers have provided the best download rate during the most recent time period, and k peers are randomly selected to help discover other peers with similar upload rates. (N is typically between 4 and 10). The set of peers to which a client uploads is periodically changed based on measurements of their download rates. BitTorrent refers to the selection and desel ection of a peer for uploading as unchoking and choking, respectively. These approaches are rate-based and suffer from a fundamental flaw.","Each approach assumes that neighbor peer rates measured over some arbitrary period of time provide accurate capacity estimates and are indicators of future bandwidth contributions. However, in practice, this assumption can be problematic, as both P2P bandwidth availability and consumption can vary substantially over time. This can result in significant problems with such rate-based approaches, including unfairness, potential exploitation by strategic clients, bandwidth underutilization, ad-hoc parameter tuning requirements, and poor performance.","This disclosure presents systems and methods that provide a deficit-based distributed P2P technique that addresses the problem of fair bandwidth exchange in the presence of free-riders and strategic peers.","In an example, peers are accurately rewarded in accordance with their respective contributions. A programmatic element, which can run locally at each peer, can maintain a deficit counter for each neighbor. The deficit counter can represent the difference between bytes sent and bytes received from a neighbor. When a peer is ready to upload a data block, the peer can send the data block to a peer with the largest deficit, that is, the peer to whom it \u201cowes\u201d the most data. Unlike other approaches, examples described herein can use a completely different mechanism that does not rely on express estimates of peer bandwidth. This can help avoid the bandwidth rate estimation problem that can plague other approaches. By selecting the neighbor with the largest deficit as the destination of the next data block, exampled described herein can act to reduce or minimize the difference between bytes sent and bytes received, thereby decreasing or minimizing unfairness at each step. This can result in a higher degree of fairness and performance for each peer that can be closely correlated with its contribution.","Examples of P2P networks described herein provide one or more advantages over other approaches, for example: (1) a P2P network can provide fair bandwidth allocation, e.g., operating only at individual peers, in a distributed manner that does not require any centralized control of peers or other P2P resources; (2) a P2P network can be resilient to strategic clients and free riders as they can choose to upload a block to a peer to whom it \u201cowes\u201d more data; (3) a P2P network can increase or maximize utilization of peers in the network, e.g., a peer can push toward a maximum upload capacity and can still receive a fair amount of bandwidth in return; (4) a P2P network can avoid the long peer discovery of other approaches, and even a high uploading peer can quickly discover a set of neighbors with which it can reach a fair data-exchange rate; (5) a P2P network can avoid a need to measure available download bandwidth, can allocate precise upload or download rates for any peers, or can rely on estimates or advanced knowledge of available bandwidth from users or other peers; (6) a P2P network can provide low variance in download rate, which can be important for streaming applications; (7) a P2P network does not need to have any \u201cmagic\u201d parameters or require tuning, can be convenient to implement, and can be compatible with existing P2P clients, e.g., some examples may be implemented as an extension to existing P2P clients or networks (e.g., as a client in a BitTorrent network).",{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 1","b":["100","100","102","104","102","104","106"]},"When a content server  makes a file available to the peer-to-peer computer network , one or more peer computers  can connect and download at least a portion of the file. Each peer computer  that downloads a part of the file makes that part available to other peer computers  on the peer-to-peer computer network . After a file is fully downloaded to a particular peer computer , that particular peer computer  can become a seed computer and distribute portions of the file to other groups of peer computers . The distributed nature of peer-to-peer file sharing results in a viral data distribution throughout a network of peers. As more peers join the peer-to-peer computer network , they can obtain the file from previously-existing peers that have portions of the file or from peers that have the entire file (i.e., seeds). Peer-to-peer file sharing provides redundancy by reducing dependence on the original content server . In addition, distribution using a peer-to-peer network can increase download performance and reliability.","Some P2P system establish multiple simultaneous network connections with neighboring peers. In an example, a computer peer  in the peer-to-peer computer network  can establish TCP connections with up to 50 neighbors. This is similar to other P2P implementations like Azureus and BitTorrent. However, while Azureus and BitTorrent actively unchoke a limited set of peers at a time, the present system can unchoke any or all of the 50 neighbors that are interested in a peer's data. Referring to the BitTorrent protocol, a leecher Lwill only receive requests from a leecher Lif Lif is interested in some data that Lhas and Lhas unchoked L. BitTorrent and Azureus only unchoke several peers at a time. This mechanism forces higher uploading peers to push at a higher rate to each unchoked peer. This results in allowing higher uploading peers to measure each other's rates and discover one another in a swarm, although such discovery is slow. Unfortunately, this means that low uploading peers can also detect high uploading peers and leech off their bandwidth.","In contrast, in the present system, leecher Lsimply unchokes any neighbor Lthat is interested in L's data. The present system does not need to try to discover like-uploading peers as does BitTorrent. Instead, Lquickly finds enough peers such that the sum of their reciprocation rates is at least as high as L's upload rate and Lcan adapt to their rates. For example, in the present system, a high-capacity leecher surrounded by many low-capacity leechers can quickly adapt to exchange data at their respective rates. A lecher Lcan end up exchanging at different rates with different peers.","A computer peer  can begin by moving along its randomly ordered list of peers and sending a block to each peer it has unchoked. As soon as one reciprocates, the computer peer  can send the reciprocating peer more blocks to match its rate. Peers can automatically attempt to increase or maximize reciprocation to one another by probing each other with more blocks. A high uploader can adapt quickly whether or not surrounded by other peers by running the systems and methods described herein.","In the peer-to-peer computer network  illustrated in , when several requesting peer computers  request data blocks from a responding peer computer , the responding peer computer  can use a deficit-based reply policy to determine which order to reply to the pending requests. For example, each peer computer  can keep track of its deficit with each neighbor. A deficit can be calculated determining the bytes sent to a particular neighbor minus the bytes receives from that neighbor. To decide which peer to respond to first, the responding peer computer  can select a peer with the largest deficit representing the peer to which the responding peer computer  \u201cowes\u201d the most data. A deficit-based reply policy is resilient to the free rider and strategic peer problems. This can help provide a good quality stream to a peer that contributes bandwidth at above the stream rate. The reply policy can be fully distributed and can be implemented individually at each peer.","In an example, each peer pthat implements such a reply policy can keep track of the deficit dwith each peer p, where drepresents the difference in the total number of bytes that phas sent to pand the bytes that preceived from p. Instead of replying to peers in first-come-first-served order, when phas a number of pending requests it can elect to send the next block to a peer pwith the minimum value d. Thus, peer pcan always seek to select a peer to which it \u201cowes\u201d the most data or conversely, a peer who \u201cowes\u201d it the least.","Upon receiving a block from pj, methods and systems described herein can check whether the block is valid, such as by checking its hash and, if it is a valid block, can increase the deficit dby the size of the block, where dis the deficit with peer p. When pis ready to send another block of data (e.g., either based on its bandwidth capacity or the application upload bandwidth cap set by the user), peer pcan select a peer with the minimum value of dand a pending request. Then pcan send a block to p, and reduce the deficit dby the size of the block. This is further illustrated below in .","Referring now to .  is a flow chart illustrating a method  of selectively transmitting data to a peer computer. At , a list of peer computers is accessed. The list is sorted by a data exchange metric. In an example, the data exchange metric represents the difference between bytes sent to a peer computer and bytes received from the peer computer. The data exchange metrics are measured using actual values with \u201csmallest\u201d and \u201clargest\u201d referring to the relationship of the values on a number line. That is, a data exchange metric with a value of \u221230 is smaller than a data exchange metric with a value of \u22125. Similarly, a data exchange metric with a value of \u22125 is smaller than a data exchange metric of 10. The data exchange metric may be discussed in terms of a \u201cdeficit.\u201d In such a case, a large deficit indicates a small actual value, and a small deficit indicates a large actual value. A negative deficit can be referred to as a surplus. Thus, the data exchange metrics can be referred to in terms of deficits, surpluses, or actual values.",{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 3","b":["300","300"],"sub":"\u2014"},"Referring again to , at , a requester peer is selected by traversing the list from a largest data exchange metric to a smallest data exchange metric. In the example of , PEER8 would be considered first. It is possible that two or more peers have the same data exchange metric. When this situation occurs, one or more mechanisms can be used to resolve priority. For example, a first-in-first-out queue can be maintained such that the first peer to obtain the data exchange metric would have priority against other peers who arrive at the same metric. As another example, a peer can be chosen at random. A random selection is useful when a peer is just beginning transmissions and has little or no history of transactions with adjacent peers. As another example, the amount of transmitted data can be tracked so that the peer with the most data transmitted to the responding peer has priority. The amount of transmitted data can be evaluated over a particular period of time, such that a peer that has transmitted less data but more recently may have a higher priority than a peer that has transmitted more data but farther in the past. Various aging protocols can be used to determine priority in these cases. In addition, the time period can be a moving window of time or a fixed period. For example, transmitted data can be calculated from a starting date and time up to the present time. As another example, transmitted data can be recalculated using a 24-hour moving window.","In another example, the list of peers is not sorted or maintained. Instead, the list can be scanned to determine a requester peer or peers with a lowest data exchange metric. There is a trade off using this mechanism. Instead of resorting the list and then traversing it, which has a logarithmic or loglinear computational cost, a full scan has a linear computational cost.","In an example, among peers with equal values and pending requests for data, the present system can break ties as follows. First, it can select a peer that transmitted the most data to the local peer. This can protect the system against whitewashers\u2014strategic peers that repeatedly enter the system with new identities and no data exchange metric in order to achieve priority queuing. If there is more than one peer with the same data exchange metric, the system can select a peer based on a random ordering of neighbors. An example of a tie-breaking mechanism is illustrated in .",{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 4","b":["204","400"]},"At , the total amount of received data is used to select among peer computers having equal data exchange metrics. In an example, a peer is selected from the peer computers having equal data exchange metrics by determining the peer computer having a largest total amount of transmitted data to the sending peer.","After selecting a requester peer, in an example, it is determining whether the requester peer is able to receive the data block. Peers have a finite data buffer. As such, after selecting a potential peer to transmit a data block to, the transmitting peer can first check to ensure that there is room in the receiving peer's buffer to receive the data block. When there is sufficient room, then the data block is transmitted. When there is insufficient room, in an example, an alternative peer is chosen. This mechanism increases or maximizes the upload bandwidth of the transmitting peer and reduces idle time. In an example, the table  () is referred to again to obtain an alternative peer to send a data block.","After transmitting a data block to a peer, the transmitting peer updates its records.  is a flow chart illustrating a method  of tracking peer computers. At , the data exchange metric associated with the requester peer is updated. In particular, in an example, the peer-to-peer data exchange metric is adjusted by the size of the data block transmitted to the requester peer. In an example, the size in kilobytes is added to the data exchange metric.","At , the list of peer computers is resorted. The list is resorted according to the updated data exchange metric. In an example, the requester peer is removed from the list. Then, after updating the data exchange metric, the requester peer is inserted into the list based on the updated data exchange metric. In an example, changes to data exchange metrics are maintained and the list is resorted periodically. For example, the list can be resorted prior to transmitting a block, but otherwise the data exchange metrics are only updated based on received data blocks. This mechanism can preserve extraneous processing when a peer's upload rate is different from its download rate. For example, when a peer uploads a block at one-fifth the rate that it downloads blocks from other peers, the list can be resorted one-fifth as many times, thus reducing computational overhead while preserving the data exchange-based priority mechanism.","In addition, as the responding peer receives data blocks from other peers in the network, the data exchange metrics are revised to reflect the data received. When the list is resorted, any peers that have sent data may change positions in the list relative to other peers. In an example, the list can be resorted after each update to a peer's data exchange metric (e.g., after receipt of a data block). In another example, the list is resorted at specific times, such as when a transmitting peer is determining a peer to respond to or on a periodic or regular basis. By reducing the number of resorting operations to specific times, additional efficiencies can be gained.","There are several other processes that can be used to streamline and improve the processing of data block requests. For example, while a peer can exist in a sorted list of peers who have transacted with the transmitting peer, there is no guarantee that the peer actually has an outstanding request for data from the transmitting peer or that the data would still be relevant should it be transmitted to the requesting peer. For example, in a streaming application data can become irrelevant when the requesting peer's playback position is beyond the sequence number of the data block that was requested previously in time.",{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 6","b":["500","602"]},"At , when the requester peer al has the data block corresponding to the pending data block request, an alternative data block is selected to transmit. In example, a rare data block is identified to be transmitted. A rare block includes a block that is found on fewer computer peers than other blocks.",{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 7","b":["600","702"]},"At , when the playback position of the requester peer is beyond the sequence number of the data block corresponding to the pending data block request, an alternative data block is selected to transmit. In example, a rare data block is identified to be transmitted.","Referring again to , at , a data block is transmitted to the requester peer selected at .","For streaming applications, an efficient request and buffering policy is important to maintain uninterrupted playback of a data stream. When a peer computer  joins a stream, it can fix its starting position at the highest sequence-numbered block it observes from its neighbors. The new peer computer  can begin buffering at that position. Once the peer computer  accumulates a specified amount (e.g., 90%) of data in a specified length buffer (e.g., a 30-second buffer window), the peer computer  can begin playing the stream.","While playing the stream, the peer computer  can maintain a sliding interest window, which can start at the position of the last-played data block and be sized in relation to the buffer (e.g., a 30-second interest window). The peer computer  can make requests for the missing data blocks inside this interest window. In an example, the computer peer  can randomly request missing blocks from the interest window. This type of request policy can be more fault-tolerant then a rarest-first policy, such as in the presence of free-riders or malicious peers. Using rarest-first, a peer can assume that it can download blocks from its free-riding neighbors and can request other least commonly available blocks. In reality, however, the free-riders' blocks are not available to the peer. Using a random request policy can allow \u201cwell-behaved\u201d peers to avoid this false assumption and can evenly spread out requests for missing blocks.","When in buffering mode, in an example, a computer peer  can request blocks exclusively from the interest window (e.g., inside the buffer), such as to complete buffering as quickly as possible. In an example of this mode, the computer peer  can make multiple requests for each block from its neighbors, while maintaining the same number of outstanding requests for each missing block.","In a playback mode, a computer peer  can also make duplicate requests for the blocks in its interest window. Since the data blocks of a stream has a playback deadline, P2P streaming systems can re-request missing blocks to improve the probability of receiving a given block by its deadline. Another approach, for example, can use a short timeout and can repeat a request for a missing block every few seconds. However, in the presence of peers with variable capacity many of those requests could be going to peers with little or no upload bandwidth (e.g., free-riders). To improve the probability of success, in an example, a computer peer  can send duplicate requests to other computer peers  with low average response times. Response times can be measured as the time between sending a request to a peer and receiving a reply.",{"@attributes":{"id":"p-0084","num":"0083"},"figref":"FIG. 8","b":["800","802"]},"At , when the data block is urgently needed, the data block is repeatedly requested at a request interval. When making a request, the method  can select a peer with the best average response time. In addition, the method  can remove those peers that have another urgent request in its request queue. If the peer is handling a non-urgent request, that request can be preempted, by the urgent request. For example, the replying peer can replace the pending request with the urgent request received from the requester).","In an example, a process can run once a second and to implement the preemptive re-request policy.  is a pseudo code listing of the PR-Rillustrating a method of managing urgent requests. Referring to , the call to GUBcan return the list of blocks in the next half-interest window that have not yet been received. For each such block, the peer can make a preemptive re-request every request_interval seconds. The function SBPcan select the peer with the best average response time that does not have a pending urgent request. The response time can be measured as the time between the request sent and reply received from a peer. The function RFPcan submit a request to peer pwith an indication that the request is urgent. In an example, RFPcan return a code indicating whether the remote peer is able to handle the urgent request. If the remote peer is unable to handle the request, another peer is chosen. In an example, a request-interval of 5 seconds is used and allows a block to be re-requested a few times before its deadline.","While making duplicate requests can increase the probability of receiving a block, it can also end up generating duplicate replies and wasting bandwidth. To reduce the probability of sending a duplicate reply, in an example, the system can use an improved or optimized reply policy.",{"@attributes":{"id":"p-0088","num":"0087"},"figref":["FIG. 10","FIG. 10"],"smallcaps":["ROCEDURE ","END","O","EER ","HOOSE","AREST "],"sub":["j","j ","j ","j","i ","i ","i"]},"This technique can require each peer to advertise its playback position and blocks in its possession. In an example, a peer can send a CURPOS message to its neighbors at regular intervals, such as once per second, to advertise its current position. Also, upon downloading a block, in an example, peers can send a HAVE message to its neighbors to announce the block sequence numbers it currently has.","As long asp, has upload capacity, it is in the interest of the peer to send a more optimal block to pinstead of not sending anything at all. Based on the fairness properties as provided by the systems and methods described herein, such behavior improves the probability of getting more reward from pin the future.","While much of the discussion thus far has focused on peers and clients in the peer-to-peer computer network , content servers  and seeds do not download from peers in a swarm. As such, using data exchange metrics to allocate upload bandwidth from a seed is of limited utility. In an example, the peer-to-peer computer network  can allocate seed bandwidth split evenly among lechers, for example by using a round robin mechanism.","In a streaming peer-to-peer distribution network, similar to the client, a content server  or seed can announce new blocks that it streams via HAVE messages. Like a pull-based design, a content server can passively reply to pull requests from its neighboring peers. A content server  or seed need not use the reply policy used by the peers since it is not trying to compete for user bandwidth. Instead, it can allocate its bandwidth evenly among its neighbors and can serve requests via round-robin.","The content server  or seed need not be completely passive, as it can also have a goal of distributing all of the stream updates to the computer peers. To accomplish this, the content server  or seed can sometimes ignore a client request and can instead reply with a block that has not yet been streamed.",{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIG. 11","FIG. 11"],"smallcaps":["ROCEDURE ","ERVER","EPLY ","BSOLUTE","AREST","LOCK "]},"A Best-Peers technique can be included in the server technique, such as to use the server bandwidth more optimally in the face of free-riders. In an example, if a block b is only sent by the server to free-riders, the block will never be distributed to other peers. Even if the server streams each block to a fixed percentage of randomly selected clients, it may still get unlucky with some blocks and send them exclusively to free-riders. For example, if the server has enough upload capacity to stream each block three times, and there are 112 free-riders among the users, then on average each block has the probability of \u215b of going only to free-riders. Thus, it is expected that sharing users will miss 12.5% of the updates.","More generally, if there is any fraction of free-riders, and the bandwidth of the server is limited, there is a nonzero chance that some blocks will not be distributed outside of free-riders, and thus will not be propagated to other users. This problem can be especially acute in streaming, as compared to file-sharing. In file-sharing, a missing block can eventually be requested from a content server or a seed. However, in streaming each block has a limited window of usefulness. Thus, the problem of effective server-bandwidth allocation in streaming can be important.","In an example, the peer-to-peer computer network  can include a technique called Best-Peers that need not require reputation or any a priori knowledge at the server, and that still can significantly improve the server capacity utilization despite a large fraction of free-riders.","Using this technique, when a peer p, makes a request to the streaming server it includes in its request a set S pof up to k of its best neighbors. These best peers are selected by pas the peers with the best average download response times that pobserves. For a sharing peer, this set would represent peers that are not free-riders and that it is actively downloading data from. When the server replies to pit sends back a block that is specifically missing from the set of p's effective neighbors.","This technique can allow the server to use its bandwidth more effectively. With this technique, the server can be less likely to send duplicate blocks to the sharing peers. Thus, the sharing peers can be more likely to receive all of the blocks in the stream. This is because the server can assess what is missing not only at the requesting peer, but at the whole neighborhood of the peer, and can respond by not sending duplicate blocks to that neighborhood.",{"@attributes":{"id":"p-0100","num":"0099"},"figref":["FIG. 12","FIG. 12"],"smallcaps":["ROCEDURE ","ERVER","EPLY","PT "]},"With this modification, the server does not need to trust the requesting peer. The server can be assured that a sharing peer will want to truthfully report its set S, as it is in the interest of each sharing peer to help the server to distribute more unique blocks to the pool of sharing peers.","Also, it does not matter how the malicious peers may try to sabotage the requests, such as by providing false neighborhood sets or mis-advertising blocks that they do or do not have. It can be assumed that all of the replies by the server to malicious peers are useless and are wasted. Even with that assumption, because a sharing peer only sends the set of its \u201cbest\u201d peers (e.g., peers with whom it is actively exchanging data and from whom it observes best response times), the server can only use the provided best peers to determine a more unique block in the peer's neighborhood.","Note that this technique is not a reputation-based technique and can be more resistant to malicious peers misrepresenting other peers' reputation. In an example of this approach, the server does not use the information from one peer's reply to another. It can directly use the information from pto reply to p.","The server may not be neighbors with some or all of the peers in the set Sand thus may not know what blocks they are missing. As a hint to the server, pcan add a set of blocks missing among her k best peers. It can be more optimal for the server to make the decision about the missing block because it can delay making that decision until reply time and thus avoid sending a duplicate if the requested block already arrived in the neighborhood of p. However, the peer pcan be configured for that case as well, such as by sending frequent preemptive re-requests to the server with more up-to-date information until the server replies.","In an example, the peer-to-peer computer network  can use a 16 KB block size. This is consistent with the unit of playback in other platforms. The peer-to-peer computer network  need not break this block into smaller transmission units; the peer-to-peer computer network  system can incur smaller overhead due to HAVE messages exchanged between neighbors. The peer-to-peer computer network  can allow each peer to connect to 50 neighbors selected at random. Especially in the presence of free-riders and malicious peers, the larger neighborhood size can allow a peer to discover other sharing neighbors more quickly. In an example, each peer can queue at most one request to each peer. In this example, a peer does not need to \u201cwait\u201d on more than one request toward a slow or free-riding peer.",{"@attributes":{"id":"p-0106","num":"0105"},"figref":"FIG. 13","b":"1300"},"Thus, other embodiments can be realized. For example, an article of manufacture, such as a computer, a memory system, a magnetic or optical disk, some other storage device, and\/or any type of electronic device or system can include one or more processors  coupled to a machine-readable medium  such as a memory (e.g., removable storage media, as well as any memory including an electrical, optical, or electromagnetic conductor) having instructions  stored thereon (e.g., computer program instructions), which when executed by the one or more processors  result in performing any of the actions described with respect to the methods above.","The machine  can take the form of a computer system having a processor  coupled to a number of components directly, and\/or using a bus . Such components can include main memory , static or non-volatile memory , a mass storage device , and a signal generation device  (e.g., a speaker). Other components coupled to the processor  can include an output device , such as a video display, an input device , such as a keyboard, and a user interface navigation device , such as a mouse. A network interface device  to couple the processor  and other components to a network  can also be coupled to the bus . The instructions  can further be transmitted or received over the network  via the network interface device  utilizing any one of a number of well-known transfer protocols (e.g., HTTP). Any of these elements coupled to the bus  can be absent, present singly, or present in plural numbers, depending on the specific embodiment to be realized.","The processor , the memories , , and the storage device  can each include instructions  which, when executed, cause the machine  to perform any one or more of the methods described herein. In alternative embodiments, the machine  operates as a standalone device or can be connected (e.g., networked) to other machines. In a networked environment, the machine  can operate in the capacity of a server or a client machine in server-client network environment, or as a peer machine in a peer-to-peer (or distributed) network environment. The machine  can be a personal computer (PC), a tablet PC, a set-top box (STB), a Personal Digital Assistant (PDA), a cellular telephone, a web appliance, a network router, switch or bridge, or any machine capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that machine. Further, while only a single machine  is illustrated, the term \u201cmachine\u201d shall also be taken to include any collection of machines that individually or jointly execute a set (or multiple sets) of instructions to perform any one or more of the methodologies discussed herein.","While the machine-readable medium  is shown as a single medium, the term \u201cmachine-readable medium\u201d should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and\/or associated caches and servers, and or a variety of storage media, such as the processor  registers, memories , , and the storage device ) that store the one or more sets of instructions . The term \u201cmachine-readable medium\u201d shall also be taken to include any medium that is capable of storing, encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present invention, or that is capable of storing, encoding or carrying data structures utilized by or associated with such a set of instructions. The term \u201cmachine-readable medium\u201d shall accordingly be taken to include, but not be limited to tangible media, such as solid-state memories, optical, and magnetic media.","The above Detailed Description includes references to the accompanying drawings, which form a part of the detailed description. The drawings show, by way of illustration, specific embodiments in which the invention can be practiced. These embodiments are also referred to herein as \u201cexamples.\u201d All publications, patents, and patent documents referred to in this document are incorporated by reference herein in their entirety, as though individually incorporated by reference. In the event of inconsistent usages between this document and those documents so incorporated by reference, the usage in the incorporated reference(s) should be considered supplementary to that of this document; for irreconcilable inconsistencies, the usage in this document controls.","In this document, the terms \u201ca\u201d or \u201can\u201d are used, as is common in patent documents, to include one or more than one, independent of any other instances or usages of \u201cat least one\u201d or \u201cone or more.\u201d In this document, the term \u201cor\u201d is used to refer to a nonexclusive or, such that \u201cA or B\u201d includes \u201cA but not B,\u201d \u201cB but not A,\u201d and \u201cA and B,\u201d unless otherwise indicated. In the appended claims, the terms \u201cincluding\u201d and \u201cin which\u201d are used as the plain-English equivalents of the respective terms \u201ccomprising\u201d and \u201cwherein.\u201d Also, in the following claims, the terms \u201cincluding\u201d and \u201ccomprising\u201d are open-ended, that is, a system, device, article, or process that includes elements in addition to those listed after such a term in a claim are still deemed to fall within the scope of that claim. Moreover, in the following claims, the terms \u201cfirst,\u201d \u201csecond,\u201d and \u201cthird,\u201d etc. are used merely as labels, and are not intended to impose numerical requirements on their objects.","Method examples described herein can be machine or computer-implemented at least in part. Some examples can include a computer-readable medium or machine-readable medium encoded with instructions operable to configure an electronic device to perform methods as described in the above examples. An implementation of such methods can include code, such as microcode, assembly language code, a higher-level language code, or the like. Such code can include computer readable instructions for performing various methods. The code can form portions of computer program products. Further, the code can be tangibly stored on one or more volatile or non-volatile computer-readable media during execution or at other times. These computer-readable media can include, but are not limited to, hard disks, removable magnetic disks, removable optical disks (e.g., compact disks and digital video disks), magnetic cassettes, memory cards or sticks, random access memories (RAMs), read only memories (ROMs), and the like.","Such embodiments of the inventive subject matter can be referred to herein, individually and\/or collectively, by the term \u201cinvention\u201d merely for convenience and without intending to voluntarily limit the scope of this application to any single invention or inventive concept if more than one is in fact disclosed. Thus, although specific embodiments have been illustrated and described herein, it should be appreciated that any arrangement calculated to achieve the same purpose can be substituted for the specific embodiments shown. This disclosure is intended to cover any and all adaptations or variations of various embodiments. Accordingly, the specification and drawings are to be regarded in an illustrative rather than a restrictive sense. Combinations of the above embodiments, and other embodiments not specifically described herein, will be apparent to those of ordinary skill in the art upon reviewing the above description. This Detailed Description, therefore, is not to be taken in a limiting sense, and the scope of various embodiments is defined only by the appended claims, along with the full range of equivalents to which such claims are entitled. This method of disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather, as the following claims reflect, inventive subject matter lies in less than all features of a single disclosed embodiment. Thus the following claims are hereby incorporated into the Detailed Description, with each claim standing on its own as a separate embodiment.","The Abstract of the Disclosure is provided to comply with 37 C.F.R. \u00a71.72(b), requiring an abstract that will allow the reader to quickly ascertain the nature of the technical disclosure. It is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF DRAWINGS","p":["Some embodiments are illustrated by way of example and not limitation in the figures of the accompanying drawings in which:",{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 6","b":"500"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 9","smallcaps":["ROCEDURE ","E","EQUEST "]},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 10","smallcaps":["ROCEDURE ","END","O","EER "]},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 11","smallcaps":["ROCEDURE ","ERVER","EPLY "]},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 12","smallcaps":["ROCEDURE ","ERVER","EPLY","PT "]},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
