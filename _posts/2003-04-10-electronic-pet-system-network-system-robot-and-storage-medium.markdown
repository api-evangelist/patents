---
title: Electronic pet system, network system, robot, and storage medium
abstract: A virtual electronic pet and a pet-type robot that changes emotional state and instinct state according to surrounding information and internal information. The electronic pet behaves according to the emotional state and the instinct state. Transmission/reception of the internal state of the electronic pet (pet characteristic information) is made possible among the virtual electronic pet, the pet-type robot, and a personal computer. Thus, the action of the electronic pet is implemented by each device in accordance with the internal state of the electronic pet affected by other equipment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07089083&OS=07089083&RS=07089083
owner: Sony Corporation
number: 07089083
owner_city: Tokyo
owner_country: JP
publication_date: 20030410
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["This is a divisional application of Ser. No. 09\/720,760, now U.S. Pat. No. 6,560,511, filed Mar. 12, 2001, which is a 371 of PCT\/JPO0\/02856, filed 28 Apr. 2000.","This invention relates to an electronic pet system, a network system, a robot, and a storage medium, and particularly to an electronic pet system, a network system, a robot, and a storage medium which enable realization of an electronic pet in various types of devices.","Recently, so-called electronic pet devices (or breeding simulation game machines) have been popular because of the easiness in comparison with breeding of real animals as pets.","In an electronic pet device, an object of a virtual living body is displayed as an electronic pet and a keeper (user of the electronic pet device) is notified of the state of the electronic pet such as the degree of starvation (hunger) or fatigue by an image or a sound. The keeper (user) feeds or plays with the electronic pet by operating the electronic pet device in accordance with the state of the electronic pet. Thus, the electronic pet has its state (state of the electronic pet) changed on the basis of the keeper's actions and is thus bred. The electronic pet grows with the lapse of time and therefore the state of the electronic pet is also changed with the lapse of time.","Meanwhile, since the electronic pet device only displays the electronic pet on the display screen, the displayed electronic pet is a so-called virtual existence.","In the case where the electronic pet is realized by means of, for example, a robot, which exists as a substance, the robot as the electronic pet actually exists in the real world. In such a case, with respect to the robot as the electronic pet, the keeper (user) will have a feeling closer to the feeling in the case of actually breeding a pet, than with the electronic pet displayed in the electronic pet device.","However, in the case where the electronic pet is realized by means of a robot, it is inconvenient to carry the robot in traveling or the like. Therefore, it is more convenient if the electronic pet can be realized as an actually existing robot in a certain case and can be realized as a virtual existence in a portable electronic pet device in another case.","Since the electronic pet realized in the conventional electronic pet device generally has its state changed in accordance with an input from the user or with the lapse of time and thus takes an action, it lacks reality in comparison with the case of breeding a real animal as a pet.","Specifically, for example, in the case where a dog as a real animal is bred as a pet, when the dog wants the keeper to play with him, the dog barks or wags his tail to draw the keeper's attention. In this case, if the keeper keeps ignoring, the dog gets tired and stops barking or wagging his tail and then takes an action such as falling asleep. The real pet animal may be in high spirits after sleeping.","On the other hand, the electronic pet realized in the conventional electronic pet device (for example, an electronic pet dog) continues barking or wagging its tail when wanting the keeper to play, or stops such an action due to the lapse of time. Unlike the real pet animal (for example, a dog), the electronic pet does not get tired and fall asleep through barking or wagging its tail. That is, in the electronic pet realized in the conventional electronic pet device, the state of the electronic pet is not changed in accordance with the action of the electronic pet itself, and therefore does not take any action in accordance with such a change of the state due to the action of the electronic pet itself. For these reasons, it is demanded to provide an electronic pet with more reality.","In view of the foregoing status of the art, it is an object of the present invention to provide an electronic pet system, a network system, a robot, and a storage medium which enable realization of an electronic pet with more reality in various types of devices.","Specifically, an electronic pet system according to the present invention has an information processing device and a robot. The information processing device has transmission\/reception means capable of transmitting and receiving the internal state of an electronic pet, which is changed in accordance with input information and is information for causing the electronic pet to act, and image display means, and carries out processing for implementing the electronic pet by the image display means. The robot has transmission\/reception means capable of transmitting and receiving the internal state of the electronic pet, which is changed in accordance with input information and is information for causing the electronic pet to act, and a motion section for moving in the real world, and controls the motion section to carry out processing for implementing the electronic pet as an existence in the real world.","With such an electronic pet system, the internal state of the electronic pet is changed in accordance with input information and transmission\/reception of the internal state is carried out between the information processing device and the robot which cause the electronic pet to act on the basis of the internal state. The information processing device acts on the basis of the internal state sent from the robot, and the robot acts on the basis of the internal state sent from the information processing device.","Also, an electronic pet system according to the present invention has an information processing device and a robot. The information processing device has radio transmission\/reception means capable of radio-transmitting and receiving the internal state of an electronic pet, which is changed in accordance with input information and is information for causing the electronic pet to act, and image display means, and carries out processing for implementing the electronic pet by the image display means. The robot has radio transmission\/reception means capable of radio-transmitting and receiving the internal state of the electronic pet, which is changed in accordance with input information and is information for causing the electronic pet to act, and a motion section for moving in the real world, and controls the motion section to carry out processing for implementing the electronic pet as an existence in the real world.","With such an electronic pet system, the internal state of the electronic pet is changed in accordance with input information and radio transmission\/reception of the internal state is carried out between the information processing device and the robot which cause the electronic pet to act on the basis of the internal state. The information processing device acts on the basis of the internal state sent from the robot, and the robot acts on the basis of the internal state sent from the information processing device.","A network system according to the present invention has one or more implementation devices and a server device. The implementation device has transmission\/reception means capable of transmitting and receiving the internal state of a living body object, which is changed in accordance with input information and is information for causing the living body object to act, and the identification information of the living body object, thus implementing the living body object. The server device has management means for managing the internal state of the living body object and the identification information of the living body object, and transmission\/reception means capable of transmitting\/receiving at least the internal state and the identification information. The implementation devices and the server device are connected with each other via a network.","With such a network system, the living body object in the implementation device has its internal state and identification information managed by the server device.","Also, a network system according to the present invention has an implementation device and an information processing device. The implementation device has transmission\/reception means capable of transmitting and receiving the internal state of a living body object, which is changed in accordance with input information and is information for causing the living body object to act, thus implementing the living body object. The information processing device has transmission\/reception means capable of transmitting and receiving the internal state of the living body object, controls the action of the living body object acting in a virtual world on the basis of the internal state of the living body object, and carries out processing for displaying at least the virtual world and the living body object.","With such a network system, the internal state of the living body object in the implementation device, which is changed in accordance with input information and is information for causing occurrence of an action, is transferred to the information processing device, which carries out processing for displaying at least the virtual world and the living body object.","A robot according to the present invention is adapted for storing the internal state of a living body object, which is changed in accordance with input information and is information for causing the living body object to act, and for controlling a motion section to carry out processing for implementing the living body object as an existence in the real world. The robot transfers at least the internal state to an information processing device, which controls the action of a living body object acting in a virtual world on the basis of the internal state of the living body object in the robot and carries out processing for displaying at least the virtual world and the living body object.","Such a robot transfers the internal state, which is changed in accordance with input information and is information for causing occurrence of an action, to the information processing device, which carries out processing for displaying at least the virtual world and the living body object.","A storage medium according to the present invention is adapted for storing data usable in an information processing device and can be inserted to\/ejected from a slot provided in the information processing device. The storage medium has indication means for indicating an accurate loading position when loaded in the slot of the information processing device.","Thus, the user loads the storage medium into the slot of the information processing device with reference to the indication means.","Preferred embodiments of the present invention will now be described in detail with reference to the drawings.",{"@attributes":{"id":"p-0079","num":"0078"},"figref":"FIG. 1"},"The electronic pet system has an individual information storage section  and a body section , as shown in .","For example, an animal as a living body is considered to be made up of the flesh and the soul residing in the flesh and controlling the psychological function. The individual information storage section  of the electronic pet system is equivalent to such a soul of the animal and is constituted as hardware in the electronic pet. The body section  is equivalent to such a flesh and is constituted as software in the electronic pet.","Specifically, the individual information storage section , which expresses the characteristics (emotions and physical characteristics) of the electronic pet, can be said to function as the soul of the electronic pet. The body section , which expresses the actions of the electronic pets, can be said to function for implementing the substantial or virtual flesh of the electronic pet and representing the real actions with the substantial or virtual flesh. The actions of the body section  are carried out on the basis of the characteristics of the electronic pet held by the individual information storage section . Therefore, the individual information storage section  can be said to be the core of the electronic pet.","The individual information storage section  can be extracted from the body section  and can also be provided (to reside) in other body sections , , . . . . In this case, the body section  in which the individual information storage section  is not provided does not function as an electronic pet. The electronic pet of this case is in a so-called cast-off state.","On the other hand, the other body sections in which the individual information storage section  is provided starts to function as electronic pets having the original characteristics. That is, the soul of the electronic pet can switch from one flesh to another.",{"@attributes":{"id":"p-0085","num":"0084"},"figref":["FIG. 2","FIG. 1"]},"The individual information storage section  of  is expressed by, for example, an IC (integrated circuit) card . The IC card  contains a stamp flash memory or the like and stores the quantity of characteristics of instincts and emotions of the electronic pet and the constitutional information of the body section as will be described later (hereinafter referred to as pet characteristic information).","The body section  of  is realized by, for example, a virtual electronic pet device  or a pet-type robot . The virtual electronic pet device  is constituted by a portable information processing device for carrying out processing for displaying a virtual electronic pet, and has a slot A for loading the IC card  therein. The pet-type robot  is a robot having the shape of an electronic pet and also has a slot A for loading the IC card  therein. Although a quadrupedal robot is used as an example of the pet-type robot in the embodiments of the present invention, the form of the robot is not particularly limited and various arbitrary forms can be employed such as a bipedal robot, a robot having wings, a robot having wheels, a robot with no limb, and combination or modification of various parts. The present invention is applicable to robots of various forms.","Both the virtual electronic pet device  and the pet-type robot  are devices which function as the body section of the electronic pet and do not take any action by themselves. Specifically, as the IC card  is loaded therein, the virtual electronic pet device  and the pet-type robot  function as electronic pets. In the case of the virtual electronic pet device , an electronic pet is displayed on its monitor and the electronic pet displayed on the monitor takes an action based on the pet characteristic information stored in the IC card . Similarly, the pet-type robot  takes an action based on the pet characteristic information stored on the IC card .","With such an electronic pet system, the user at home can enjoy the feeling close to the feeling of actually keeping a pet by loading the IC card  into the slot A of the pet-type robot . When the user goes on a trip, the user can easily carry the electronic pet to the destination by detaching the IC card  from the pet-type robot  and loading the IC card  into the virtual electronic pet device .",{"@attributes":{"id":"p-0090","num":"0089"},"figref":["FIG. 3","FIG. 1"],"b":["2","2","22","23"]},"An I\/F (interface)  is equivalent to the slot A of the virtual electronic pet device  or the slot A of the pet-type robot  of , and functions as an interface for transmission of data between the individual information storage section  and the body section . Specifically, the I\/F  reads out information (pet characteristic information) expressing the characteristics of instincts and emotions of the electronic pet and the structure of the body section and supplies the information to an internal state calculation section . The I\/F  also writes the information obtained as a result of predetermined calculation at the internal state calculation section  to the individual information storage section  and updates the storage contents.","To the internal state calculation section , inputs from an external input section  and a time input section  are supplied as well as the pet characteristic information from the I\/F  as described above. Moreover, specific actions of the electronic pet obtained by an action conversion section  are fed back to the internal state calculation section . The internal state calculation section  drives emotion and instinct models stored in a model storage section  in accordance with the input from the I\/F , the external input section , the time input section , or the action conversion section , and updates the internal state of the electronic pet. The internal state of the electronic pet relates to the information of emotions and instincts included in the pet characteristic information from the I\/F , as will be described later, and the updated internal state is written to the individual information storage section  via the I\/F . The internal state calculation section  also decides a motion (conceptual motion) to be made by the electronic pet, and outputs a command (motion command) instructing the execution of that motion (conceptual motion) to the action conversion section , which carries out control to output the real action.","The external input section  supplies stimuli given by the user or from the external environment to the internal state calculation section .","In the case where the body section  is the virtual electronic pet device , the external input section  is constituted by a keyboard (or switches and buttons), a microphone, and a voice recognition device. The external input section  changes an operation or a speech made by the user for taking care of the electronic pet, into an electric signal, and supplies the electric signal to the internal state calculation section .","On the other hand, in the case where the body section  is the pet-type robot , the external input section  is constituted by a keyboard, a microphone, a voice recognition device, a photoelectric conversion element, an image recognition device, and a sensor (e.g., a temperature sensor). The external input section  changes an operation or a speech made by the user for taking care of the electronic pet, into an electric signal, and supplies the electric signal to the internal state calculation section . The external input section  also supplies information about surrounding objects and temperature to the internal state calculation section .","The time input section  keeps time (including the year, month and day) and supplies the time (current time) to the internal state calculation section .","The model storage section  stores models of emotions and instincts (emotion\/instinct models) of the electronic pet. As the emotions of the electronic pet, for example, joy, sadness, anger, surprise, fear, and hatred are set, and the model storage section  stores a model of these emotions (e.g., computational formulas for finding parameters expressing these emotions). As the instincts of the electronic pet, for example, movement instinct, love instinct, recharge instinct, and search instinct are set, and the model storage section  stores a model of these instincts. The internal state of the electronic pet is constituted by the state of emotion and the state of instinct.","The body section  has the emotion and instinct models of the same structure, irrespective of whether it is the virtual electronic pet device  or the pet-type robot . Thus, even when the IC card  is exchanged between the virtual electronic pet device  and the pet-type robot , the characteristics and actions of the electronic pet are not changed to those of different electronic pets.","The action conversion section  converts a conceptual motion command from the internal state calculation section  to a command (action command) instructing a specific action (such as an action, motion, or posture). The action conversion section  supplies the command to an output section  and also supplies the command to the internal state calculation section  as a feedback.","The output section  makes an output in accordance with the action command from the action conversion section . Specifically, the output section  causes the electronic pet to take the action in accordance with the action command from the action conversion section .","In the case where the body section  is the virtual electronic pet device , the output section  is constituted by a monitor, a voice synthesizer (e.g., a rule-based voice synthesizer), and a speaker. Thus, the output of the output section  changes the display of the electronic pet and outputs a voice.","On the other hand, in the case where the body section  is the pet-type robot , the output section  is constituted by motion sections such as motors for driving members corresponding to the limbs, trunk, head and tail, and a voice synthesizer and a speaker. Thus, the output of the output section  rotates a predetermined motor and outputs a voice.","The structure of the virtual electronic pet device  and the pet-type robot  will be described using a more specific example.  shows an exemplary hardware structure of the virtual electronic pet device .","A CPU (central processing unit)  is adapted for carrying out various types of processing in accordance with a program stored in a ROM (read only memory) . A timer circuit A counts a clock, not shown, and generates a timer interruption for every predetermined unit time (e.g., 100 ms) to the CPU  on the basis of the count value.","The ROM  stores a program to be executed by the CPU  and data necessary for the execution of the program. A RAM (random access memory)  stores data necessary for the operation of the CPU .","An I\/F  functions as an interface between the CPU  on one hand and an A\/D converter , an operation section , an IC card connector , a D\/A converter  and a liquid crystal controller  on the other.","Of the above-mentioned sections, the CPU , the ROM , the RAM  and the I\/F  are interconnected via a bus (address bus or data bus).","A microphone  converts a sound inputted thereto (e.g., a whistle sound or the like) to an audio signal as an analog electric signal and supplies the audio signal to the A\/D converter . The A\/D converter  carries out A\/D conversion of the analog audio signal from the microphone and outputs the resultant digital audio signal to the CPU  via the I\/F .","In the case where the CPU  has thus received the audio signal, the CPU  carries out linear prediction analysis of the audio signal so as to extract the characteristics quantity, and carries out voice recognition based on an HMM (hidden Markov model) method. A program to be executed by the CPU  for voice recognition and word models as the objects of voice recognition are stored, for example, in the ROM . In this case, as the word models to be the objects of voice recognition, particularly the words models used by the keeper to talk to the pet are stored. The words to be stored include \u201cHey\u201d, \u201cGood boy\u201d, \u201cGood morning\u201d, \u201cGood night\u201d, \u201cPaw\u201d, \u201cSit\u201d, \u201cWhat are you doing?\u201d and the like.","The method of acoustic analysis is not limited to the linear prediction analysis, and the method of voice recognition is not limited to the HMM method.","The operation section  is constituted by various buttons and keys and supplies a signal corresponding to the operation from the user to the CPU  via the I\/F . Thus, the CPU  can recognize the buttons and keys operated by the user. The operation section  has buttons for providing various inputs to the electronic pets such as a \u201cscold\u201d button, which is operated for scolding the electronic pet, a \u201cpraise\u201d button, which is operated for praising the electronic pet, a \u201cgreeting\u201d button corresponding to saying \u201cGood morning\u201d or \u201cGood night\u201d, and a \u201cpaw\u201d button and a \u201csit\u201d button, which are operated for instructing the electronic pet to raise the paw or to sit as a performance.","The IC card connector  is provided in the slot A of the virtual electronic pet device  (), and is adapted for electrically connecting the IC card  with the CPU  via the I\/F  when the IC card  is loaded in the slot A. In this case, the CPU  reads data from and writes data to the IC card  via the I\/F  and the IC card connector . The CPU  can also detect the loading of the IC card .","The D\/A converter  carries out D\/A conversion of the digital audio signal supplied from the CPU  via the I\/F  and supplies the resultant analog audio signal to a speaker . The speaker  contains an amplifier to amplify the audio signal from the D\/A converter  and to output the amplified audio signal. The CPU  generates a voice of the electronic pet or other necessary sounds by voice synthesis, if necessary, and outputs the synthesized sound to the D\/A converter  via the I\/F . A program for carrying out voice synthesis and data necessary for voice synthesis are stored, for example, in the ROM .","The liquid crystal controller  is controlled by the CPU  via the I\/F  and displays various images (e.g., an image of the electronic pet) and characters on a liquid crystal display section . The liquid crystal display section  displays images and characters under the control of the liquid crystal controller . The ROM  stores a program for displaying images and characters on the liquid crystal display section  by controlling the liquid crystal controller , and the CPU  executes this program, thus displaying images and characters on the liquid crystal display section .","The foregoing is the exemplary hardware structure of the virtual electronic pet device . An exemplary hardware structure of the pet-type robot  will now be described. The exemplary hardware structure of the pet-type robot  is as shown in .","In , the portions corresponding to those of the virtual electronic pet device  of  are denoted by the same numerals. Specifically, the pet-type robot  has basically the same structure as the virtual electronic pet device , except for a motor  and a driving mechanism  provided in place of the liquid crystal controller  and the liquid crystal display section .","The motor  is controlled by the CPU  via the I\/F  and is adapted for driving the driving mechanism . The driving mechanism  constitutes, for example, the head, limbs, trunk or tail as moving parts of the pet-type robot  and is driven by the motor .","The I\/F  and the IC card connector  of  correspond to the I\/F  of , and the CPU  and the ROM  of  correspond to the internal state calculation section  and the action conversion section  of . The microphone , the A\/D converter  and the operation section  of  correspond to the external input section  of . The timer circuit A of  corresponds to the time input section  of , and the ROM  of  corresponds to the model storage section  of . Moreover, the D\/A converter  and the speaker  of , the liquid crystal controller  and the liquid crystal display section  of , or the motor  and the driving mechanism  of  correspond to the output section  of .","The pet-type robot  will be described further in detail. The overall shape (appearance) of the pet-type robot  is constituted by coupling a head portion  corresponding to the head, a trunk portion  corresponding to the trunk, limb portions A, B, C and D corresponding to the four limbs, and a tail portion  corresponding to the tail, as shown in . The pet-type robot  of such a structure moves the head portion , the limb portions A to D, and the tail portion  with respect to the trunk portion , thus moving like a real quadrupedal animal. The pet-type robot  has the slot for loading the IC card , though not shown.","On the head portion , an image recognition section  made up of a CCD (charge coupled device) camera corresponding to the eyes for picking up an image, a microphone  corresponding to the ears for picking up a sound, and a speaker  corresponding to the mouth for generating a sound are attached at predetermined positions, as shown in . Also, on the head portion , a remote controller receiving section  for receiving a command transmitted from the user via a remote controller (not shown), a touch sensor  for detecting the tough by the user's hand or the like, and a LED (light-emitting diode)  made up of light-emitting means are attached.","On the trunk portion , a battery  is attached at a position corresponding to the abdomen, and an electronic circuit (not shown) for controlling the operation of the entire pet-type robot  is housed inside the trunk portion .","Joint portions of the limb portions A to D, coupling portions between the limb portions A to D and the trunk portion , a coupling portion between the trunk portion  and the head portion , and a coupling portion between the trunk portion  and the tail portion  are coupled by their respective actuators A to N and are driven under the control of the electronic circuit housed inside the trunk portion . By thus driving the actuators A to N, the pet-type robot  moves like a real quadrupedal animal, for example, shakes the head portion  vertically and horizontally, wags the tail portion , and moves the limb portions A to D to walk or run.","Such a pet-type robot  changes the internal state such as emotions and instincts on the basis of input information like circumferential information and internal information (e.g., information of the remaining capacity of the battery). The internal state is stored on the IC card .","The pet-type robot  controls the motion sections such as the head portion , the trunk portion , the limb portions A to D and the tail portion  (which are moved by the actuators A to N) on the basis of the changed internal state, and thus realizes the electronic pet in the real world. The circuit structure of such a pet-type robot  will now be described in detail with reference to .","The head portion  has a command receiving section  made up of the microphone  and the remote controller receiving section , an external sensor  made up of the image recognition section  and the tough sensor , the speaker , and the LED . The trunk section  has the battery , and also has therein a controller  for controlling the operation of the entire pet-type robot , and an internal sensor  made up of a battery sensor  for detecting the remaining capacity of the battery  and a heat sensor  for detecting the heat generated within the pet-type robot . Moreover, the actuators A to N are provided at predetermined positions in the pet-type robot .","The command receiving section  is adapted for receiving commands given to the pet-type robot  from the user such as \u201cWalk\u201d, \u201cDown\u201d, and \u201cChase the ball\u201d, and is constituted by the microphone  and the remote controller receiving section .","The remote controller receiving section  receives a desired command inputted by the user operating the remote controller (not shown). For example, the transmission of a command from the remote controller is carried out using an infrared ray. The remote controller receiving section  receives this infrared ray to generate a received signal SA and sends it to the controller .","The remote controller is not limited to the one using infrared rays but may also be adapted for giving a command to the pet-type robot  by using the musical scale. In such a case, the pet-type robot  carries out processing corresponding to the musical scale from the remote controller inputted from the microphone .","When the user generates a voice in accordance with a desired command, the microphone  picks up the voice generated by the user to generate an audio signal SB and sends it to the controller .","The command receiving section  thus generates a command signal S made up of the received signal SA and the audio signal SB in accordance with the command given to the pet-type robot  from the user, and supplies the command signal S to the controller .","The touch sensor  of the external sensor  is adapted for detecting the approach from the user to the pet-type robot , for example, \u201cpat\u201d, \u201cslap\u201d and the like. For example, when the user touches the touch sensor  and takes a desired manner of approach, the touch sensor  generates a touch detection signal SA corresponding to that approach and sends it to the controller .","The image recognition section  of the external sensor  is adapted for detecting the environment information around the pet-type robot  such as \u201cdark\u201d or \u201cthere is my favorite toy\u201d, or the motion of other robot devices such as \u201canother robot is running\u201d, as a result of identifying the environment around the pet-type robot . This image recognition section  sends an image signal SB obtained as a result of picking up the image of the surroundings, to the controller .","The external sensor  thus generates an external information signal S made up of the touch detection signal SA and the image signal SB in accordance with the external information provided from outside the pet-type robot , and sends the external information signal S to the controller .","The internal sensor  is adapted for detecting the internal information of the pet-type robot  itself, for example, \u201cI'm hungry\u201d, which means the battery capacity is lowered, \u201cI have a fever\u201d and the like. The internal sensor  is constituted by the battery sensor  and the heat sensor .","The battery sensor  is adapted for detecting the remaining capacity of the battery , which supplies the power to each circuit of the pet-type robot . This battery sensor  sends a battery capacity detection signal SA as a result of detection to the controller .","The heat sensor  is adapted for detecting the heat within the pet-type robot . This heat sensor  sends a heat detection signal SB as a result of detection to the controller .","The internal sensor  thus generates an internal information signal S made up of the battery capacity detection signal SA and the heat detection signal SB in accordance with the internal information of the pet-type robot , and sends it to the controller .","The image recognition , the microphone , the remote controller receiving section , the touch sensor  and the like shown in  correspond to the external input section  shown in . The actuators A to N shown in  correspond to the output section  shown in . As a matter of course, the constituent parts that are not shown in  but shown in  or  may also be provided as the constituent parts of the pet-type robot  of . For example, the constituent part such as the time input section  may be provided.","The controller  generates control signals SA to SN for driving the actuators A to N on the basis of the input information, that is, the command signal S supplied from the command receiving section , the external information signal S supplied from the external sensor  and the internal information signal S supplied from the internal sensor , and sends these control signals to drive the actuators A to N, thus operating the pet-type robot .","The controller  generates an audio signal S or a light-emitting signal  to be outputted to the outside, if necessary, and outputs the audio signal S to the outside via the speaker  or sends the light-emitting signal S to the LED  to carry out desired light-emitting output (e.g., flashing or changing the color), thus notifying the user of the necessary information. For example, by the light-emitting output, the controller  notifies the user of the emotion of the electronic pet. An image display section for displaying an image can be provided in place of the LED . Thus, it is possible to notify the user of the necessary information like the emotion by displaying a desired image. The processing at the controller  will now be described in detail.","The controller  carries out software-like data processing on the command signal S supplied from the command receiving section , the external information signal S supplied from the external sensor  and the internal information signal S supplied from the internal sensor  on the basis of a program stored in advance in a predetermined storage area, and supplies control signals S obtained as a result to the actuators A to N. The actuators A to N operate on the basis of the control signals SA, SB, . . . , SN.","As shown in , the contents of the data processing at the controller  are functionally classified into an emotion\/instinct model section  as emotion\/instinct model change means, an action decision mechanism section  as motion decision means, a posture transition mechanism section  as posture transition means, and a control mechanism section . The command signal S, the external information signal S and the internal information signal S supplied from outside are inputted to the emotion\/instinct model section  and the action decision mechanism section . These sections roughly function as follows.","The emotion\/instinct model section  decides the state of emotions and instincts on the basis of the command signal S, the external information signal S and the internal information signal S. The action decision mechanism section  decides the next motion (action) on the basis of the emotion\/instinct state information S obtained by the emotion\/instinct model section  in addition to the command signal S, the external information signal S and the internal information signal S, and the posture transition mechanism section  on the subsequent stage makes a posture transition plan for shifting to the next motion (action) decided by the action decision mechanism section . The information of the motion (action) decided by the action decision mechanism section  is fed back to the emotion\/instinct model section , and the emotion\/instinct model section  decides the state of emotions and instincts with reference to the decided motion (action). That is, the emotion\/instinct model section  decides the instinct and emotion also with reference to the motion (action) result.","The control mechanism section  controls each motion section in accordance with the posture transition information S sent on the basis of the posture transition plan from the posture transition mechanism section , then actually shifts the posture, and then actually carries out the next motion (action) decided by the action decision mechanism section .","That is, using the above-described controller , the pet-type robot  decides the next motion (action) on the basis of the emotions and instincts, then makes the transition plan for realizing the posture to enable execution of such a motion (action), then shifts the posture on the basis of the transition plan, and actually executes the motion (action) decided on the basis of such emotions and instincts.","The function of the model storage section  for emotions and instincts and the internal state calculation section  shown in  is realized by the emotion\/instinct model section  shown in , and the function of the action conversion section  shown in  is realized by the action decision mechanism section , the posture transition mechanism section  and the control mechanism section  shown in . The constituent parts of the above-described controller  will now be described.","The emotion\/instinct model section  generally has a group of emotions  constituting the emotion model, and a group of instincts  constituting the instinct model prepared as a model with different attributes from those of the emotion model, as shown in .","In this case, the emotion model is a model which is constituted by emotion parameters having certain values and adapted for expressing the emotion prescribed for the robot device by means of a motion corresponding to the values of the emotion parameters.","The emotion parameters have their values increased or decreased mainly in accordance with an external input signal (circumferential information or external element) indicating \u201cbeing slapped\u201d or \u201cbeing scolded\u201d detected by a sensor like a pressure sensor or a visual sensor. Of course, in some cases, the emotion parameters may be changed in accordance with an internal input signal (internal information or internal element) such as the remaining capacity of the battery or the temperature within the body. Also, the emotion parameters are changed simply with the lapse of time.","The instinct model is a model which is constituted by instinct parameters having certain values and adapted for expressing the instinct (desire) prescribed for the robot device by means of a motion corresponding to the values of the instinct parameters. The instinct parameters have their values increased or decreased mainly in accordance with an internal input signal indicating \u201cI want to move\u201d based on the action record or \u201cI need recharge (I'm hungry)\u201d based on the remaining capacity of the battery. Of course, similar to the emotion parameters, the instinct parameters may be changed in accordance with an external input signal. Also, the instinct parameters are changed simply with the lapse of time.","The emotion model and the instinct model are constituted by a plurality of types of models having the same attributes, respectively. Specifically, the group of emotions  has emotion units A to F as independent emotion models having the same attribute, and the group of instincts  has instinct units A to D as independent instinct models having the same attribute.","The group of emotions  has the emotion unit A expressing the emotion of \u201cjoy\u201d, the emotion unit B expressing the emotion of \u201csadness\u201d, the emotion unit C expressing the emotion of \u201canger\u201d, the emotion unit E expressing the emotion of \u201csurprise\u201d, and the emotion unit F expressing the emotion of \u201chatred\u201d.","The group of instincts  has the instinct unit A expressing the \u201cmovement instinct\u201d, the instinct unit B expressing the \u201clove instinct\u201d, the instinct unit C expressing the \u201crecharge instinct\u201d, and the instinct unit D expressing the \u201csearch instinct\u201d.","With respect to the emotion units A to F, the degree of the emotion is expressed by the strength (emotion parameter) of, for example, 0 to 100, and the strength of the emotion is changed every moment on the basis of the supplied command signal S, external information signal S and internal information signal S. Thus, the emotion\/instinct model  expresses the state of the emotion of the pet-type robot  by combining the strengths of the emotion units A to F which are changed every moment, and thus forms a model of emotional changes along the time.","Moreover, desired emotion units affect each other to change the strength. For example, the emotion units are coupled in a mutually suppressive manner or in a mutually stimulative manner so as to affect each other, thus changing the strength.","Specifically, as shown in , if the emotion unit A of \u201cjoy\u201d and the emotion unit B of \u201csadness\u201d are coupled in a mutually suppressive manner, when the pet-type robot is praised by the user, the strength of the emotion unit A of \u201cjoy\u201d is increased, and the strength of the emotion unit B of \u201csadness\u201d is reduced in accordance with the increase in the strength of the emotion unit A of \u201cjoy\u201d even though the input information S to S for changing the strength of the emotion unit B of \u201csadness\u201d is not supplied. Similarly, when the strength of the emotion unit B of \u201csadness\u201d is increased, the strength of the emotion unit A of \u201cjoy\u201d is reduced in accordance with the increase in the strength of the emotion unit B of \u201csadness\u201d.","If the emotion unit B of \u201csadness\u201d and the emotion unit C of \u201canger\u201d are coupled in a mutually stimulative manner, when the pet-type robot is slapped by the user, the strength of the emotion unit C of \u201canger\u201d is increased, and the strength of the emotion unit B of \u201csadness\u201d is increased in accordance with the increase in the strength of the emotion unit C of \u201canger\u201d even though the input information S to S for changing the strength of the emotion unit B of \u201csadness\u201d is not supplied. Similarly, when the strength of the emotion unit B of \u201csadness\u201d is increased, the strength of the emotion unit C of \u201canger\u201d is increased in accordance with the increase in the strength of the emotion unit B of \u201csadness\u201d.","As the desired emotion units thus affect each other to change the strength, a change of the strength of one of the coupled emotion units leads to a change of the strength of the other emotion unit, thus realizing the pet-type robot  having natural emotions.","With respect to the emotion units A to D, similar to the emotion units A to F, the degree of the instinct is expressed by the strength (instinct parameter) of, for example, 0 to 100, and the strength of the instinct is changed every moment on the basis of the supplied command signal S, external information signal S and internal information signal S. Thus, the emotion\/instinct model  expresses the state of the instinct of the pet-type robot  by combining the strengths of the instinct units A to D which are changed every moment, and thus forms a model of instinct changes along the time.","Moreover, similar to the case of coupling the emotion units, desired instinct units affect each other to change the strength. For example, the instinct units are coupled in a mutually suppressive manner or in a mutually stimulative manner so as to affect each other, thus changing the strength. Thus, when the strength of one of the coupled instinct units is changed, the strength of the other instinct unit is changed accordingly, and the pet-type robot  having natural instincts is realized.","Furthermore, the units of the group of emotions  and the group of instincts  affect each other to change the strength. For example, changes of the strength of the instinct unit B expressing \u201clove instinct\u201d and the instinct unit C expressing \u201crecharge instinct\u201d of the group of instincts  affect changes of the strength of the emotion unit B expressing \u201csadness\u201d and the emotion unit C expressing \u201canger\u201d of the group of emotions . Thus, if the \u201clove instinct\u201d is satisfied, the emotion of \u201canger\u201d and the emotion of \u201csadness\u201d are suppressed, and if the \u201crecharge instinct\u201d is not satisfied, the emotion of \u201canger\u201d and the emotion of \u201csadness\u201d are increased. With such interaction between emotions and instincts, it is possible to express the state where emotions and instincts affect one another complicatedly.","As is described above, the emotion\/instinct model section  changes the strength of the emotion units A to F and the instinct units A to D, using the input information S to S consisting of the command signal S, the external information signal S and the internal information signal S, or the interaction between the emotion units of the group of emotions , the interaction between the instinct units of the group of instincts , and the interaction between the units of the group of emotions  and the group of instincts .","The emotion\/instinct model section  decides the state of the emotion by combining the changed strengths of the emotion units A to F, and decides the state of the instinct by combining the changed strengths of the instinct units A to D. The emotion\/instinct model section  then sends the decided state of the emotion and the decide state of the instinct as emotion\/instinct state information S to the action decision mechanism section .","The emotion\/instinct model section  is supplied with action information S indicating the contents of the current or past action of the pet-type robot  itself from the action decision mechanism section  on the subsequent stage. For example, in the case where an action of walking is decided by the action decision mechanism section , which will be described later, the action information S indicating that the pet-type robot \u201chas walked for a long time\u201d is supplied.","By thus feeding back the action information S, different emotion\/instinct state information S can be generated in accordance with the action of the pet-type robot  indicated by the action information S, even though the same input information S to S is provided. Specifically, with the following structure, the action information S that is fed back is referred to in deciding the state of the emotion and the state of the instinct.","As shown in , in the emotion\/instinct model section , strength increase\/decrease means A to C for generating strength information SA to SC for increasing\/decreasing the strengths of the emotion units A to C on the basis of the action information S indicating the action of the pet-type robot  and the input information S to S are provided on the stage prior to the emotion units A to C, and the strengths of the emotion units A to C are increased\/decreased in accordance with the strength information SA to SC outputted from the strength increase\/decrease means A to C.","For example, when the pet-type robot greets the user and is patted on the head by the user, that is, when the action information S indicating that the pet-type robot has greeted and the input information S to S indicating that the pet-type robot is patted on the head are supplied to the strength increase\/decrease means A, the emotion\/instinct model section  increases the strength of the emotion unit A of \u201cjoy\u201d. On the other hand, when the pet-type robot which is carrying out a certain task is patted on the head, that is, when the action information S indicating that the pet-type robot is carrying out a task and the input information S to S indicating that the pet-type robot is patted on the head are supplied to the strength increase\/decrease means A, the emotion\/instinct model section  does not change the strength of the emotion unit A of \u201cjoy\u201d. The strength increase\/decrease means A is constituted, for example, as a function or a table for generating the strength information SA to SC on the basis of the action information S and the input information S to S. The other strength increase\/decrease means B and C are similarly constituted.","Thus, since the emotion\/instinct model section  has the strength increase\/decrease means A to C and decides the strengths of the emotion units A to C with reference to not only the input information S to S but also the action information S indicating the current or past action of the pet-type robot , it is possible to avoid occurrence of an unnatural emotion such that the strength of the emotion unit A of \u201cjoy\u201d is increased when the user pats the pet-type robot on the head with a mischievous intention while the pet-type robot is carrying out a certain task. Similarly, the emotion\/instinct model section  also increases or decreases the strengths of the instinct units A to C on the basis of the input information S to S and the action information S supplied thereto.","In the present embodiment, the strength increase\/decrease means A to C are provided for the emotion units A to C of \u201cjoy\u201d, \u201csadness\u201d and \u201canger\u201d. However, it is a matter of course that the present invention is not limited to such a structure and that strength increase\/decrease means can also be provided for the other emotion units D to F of \u201csurprise\u201d, \u201cfear\u201d and \u201chatred\u201d.","As is described above, when the input information S to S and the action information S are inputted, the strength increase\/decrease means A to C generate and output the strength information SA to SC in accordance with a predetermined parameter. Therefore, by varying the value the parameter for each pet-type robot , the individuality such as being quick-tempered or cheerful can be provided for the robot.","The processing at the action decision mechanism section  will now be described. Specifically, the action decision mechanism section  decides the next motion (action) on the basis of various types of information in cooperation with a selection module  shown in . The action decision mechanism section  is supplied with information S consisting of the command signal S, the external information signal S, the internal information signal S, the emotion\/instinct state information S and the action information S, as shown in , and decides the next motion (action) on the basis of this information S.","The action decision mechanism section  holds a plurality of action models such as \u201cthe first action model (action model 1)\u201d, \u201cthe second action model (action model 2)\u201d, \u201cthe third action model (action model 3)\u201d, \u201cthe fourth action model (action model 4)\u201d, . . . , \u201cthe n-th action model (action model n, where n is an integer)\u201d, as shown in . For example, the action models are models for deciding the action in each scene such as \u201cthe case where the remaining capacity of the battery is reduced\u201d, \u201cthe case of recovering from falling\u201d, \u201cthe case of avoiding an obstacle\u201d, and \u201cthe case where a ball is detected\u201d. That is, when certain information is inputted, an action model (or a plurality of action models) specified for the input information reacts to it and the action model that has thus reacted decides the next action.","Then, the results of decision by the first to n-th action models on the basis of the information S are outputted to selection module .","As a technique for deciding the next action, the first to n-th action models use an algorithm which is called a finite probability automaton for deciding the transition that should be made from one node (state) NODE to NODEn to another node NODE to NODEn as shown in  in terms of the probability on the basis of the transition probabilities P to Pn set for arcs ARC to ARCn connecting the respective nodes NODE to NODEn.","Specifically, the first to n-th action models have a state transition table  as shown in  for each of the nodes NODE to NODEn, corresponding to the node NODE to NODEn constituting the action models themselves.","In the state transition table , input events (recognition result) as the transition conditions in the nodes NODE to NODEn are listed in a preferential order in the row of \u201cname of input event\u201d, and further conditions with respect to the transition conditions are described in the columns corresponding to the rows of \u201cname of data\u201d and \u201crange of data\u201d.","In the node NODE shown in the state transition table  of , the conditions for transition to another node include that when the recognition result (information S) to the effect that \u201ca ball is detected (BALL)\u201d is provided, the \u201csize (SIZE)\u201d of the ball provided together with the recognition result or as the recognition result is within the range of \u201c0 to 1000\u201d, or that when the recognition result to the effect that \u201can obstacle is detected (OBSTACLE)\u201d is provided, the \u201cdistance (DISTANCE)\u201d to the obstacle provided together with the recognition result is within the range of \u201c0 to 100\u201d.","In this node NODE, the node as the destination of transition is selected also with reference to whether the strength of a desired unit exceeds a predetermined threshold value or not, of the strengths of the emotion units A to F and the instinct units A to D indicated by the emotion\/instinct state information S supplied as the recognition result (information S) from the emotion\/instinct model section . Thus, even when the same command signal S is inputted, transition to different nodes is made depending on the strengths of the emotion units A to F and the instinct units A to D.","In this node NODE, even in the case where there is no input of the recognition result (information S), transition to another node can be made when the parameter value of any of \u201cjoy (JOY)\u201d, \u201csurprise (SURPRISE)\u201d and \u201csadness (SADNESS)\u201d held by the emotion models is within the range of \u201c50 to 100\u201d, of the parameter values of the emotions and instincts held by the emotion\/instinct model section .","In the state transition table , the names of nodes to which transition from the node NODE to NODEn can be made are listed in the column of \u201ctransition destination node\u201d in the section of \u201cprobability of transition to another node\u201d, and the probabilities of transition to another node NODE to NODEn that can be made when all the conditions described in the rows of \u201cname of input event\u201d, \u201cname of data\u201d and \u201crange of data\u201d are met are described in the corresponding spaces within the section of \u201cprobability of transition to another node\u201d. Also, the actions to be outputted in transition to the nodes NODE to NODEn are described in the row of \u201coutput action\u201d in the section of \u201cprobability of transition to another node\u201d. The sum of the probabilities described in the respective rows in the section of \u201cprobability of transition to another node\u201d is 100 [%]. The probability of transition may be changed. For example, the probability of transition is changed by the learning function. Thus, the pet-type robot  changes the probability of transition in accordance with the result of learning and therefore obtains individuality with respect to the decision of the action. For example, the probability of transition, which is the characteristic of the pet-type robot , is stored as the pet characteristic information into the individual information storage section  (IC card ).","In the node NODE shown in the state transition table  of , for example, when the recognition result (information S) to the effect that \u201cthe ball is detected (BALL)\u201d and that the \u201csize (SIZE)\u201d of the ball is within the range of \u201c0 to 100\u201d is provided, transition to \u201cnode NODE (node )\u201d can be made with the probability of \u201c30%\u201d, and then the action of \u201cACTION1\u201d is outputted.","With such action models, for example, when it is detected on the basis of the supplied external information S that the palm is presented in front of the pet-type robot, and it is detected on the basis of the emotion\/instinct state information S that the strength of the motion unit C of \u201canger\u201d is not higher than a predetermined threshold value, and it is detected on the basis of the internal information signal S that \u201cthe pet-type robot is not hungry\u201d, that is, the voltage of the battery is not lower than a predetermined threshold value, the action for making the motion of \u201cgiving the paw\u201d is decided in response to the presentation of the palm in front of the pet-type robot.","On the other hand, when it is detected that the palm is presented in front of the pet-type robot, and that the strength of the emotion unit C of \u201canger\u201d is not higher than the predetermined threshold value, and that \u201cthe pet-type robot is hungry\u201d, that is, the voltage of the battery is less than the predetermined threshold value, the action for making the motion of \u201clicking the palm\u201d is decided.","Alternatively, when it is detected that the palm is presented in front of the pet-type robot, and that the strength of the emotion unit C of \u201canger\u201d is equal to or higher than the predetermined threshold value, the action of making the motion of \u201cturning away\u201d is decided irrespective of whether \u201cthe pet-type robot is not hungry\u201d, that is, whether the voltage of the battery is not lower than the predetermined threshold value.","The first to n-th action models are constituted in such a manner that a number of nodes NODE to NODEn described as the state transition table  are connected. Thus, when the recognition result (information S) is provided, the next action is decided in terms of the probability by using the state transition table of the corresponding node NODE to NODEn, and the result of decision is outputted to the selection module .","The selection module  selects the action outputted from the action model of the predetermined high priority, of the actions outputted from the first to n-th action models, and outputs the information of the selected action as action command information S to the posture transition mechanism section . For example, the action models described on the lower side in  are of higher priority.","The selection module  also outputs the result of selection as the action information S to the emotion\/instinct model section  and the action decision mechanism section . For example, the selection module  raises a flag on the decided action and outputs its information as the action information S and the action command information S to the action decision mechanism section  and the posture transition mechanism section .","The action decision mechanism section  decides the action on the basis of the action information S as well as the external information (the command signal S and the external information signal S) S and the internal information (the internal information signal S and the emotion\/instinct state information S) S, and thus can decide the next action in consideration of the previous action.","The emotion\/instinct model section  changes the state of the emotion and the state of the instinct on the basis of the action information S as well as the same information S to S (consisting of the command signal S, the external information S and the internal information signal S) as described above. Thus, the emotion\/instinct model section  can generate different emotion\/instinct state information S even when the same information S to S is provided, as described above.","Since the contents of the information S to S vary in accordance with the timing of being inputted to the emotion\/instinct model section  and the action decision mechanism section , the information S to S is inputted to both the emotion\/instinct model section  and the action decision mechanism section .","For example, when the external information signal S to the effect that \u201cthe pet-type robot is patted on the head\u201d is supplied, the controller  causes the emotion\/instinct model section  to generate the emotion\/instinct state information S indicating \u201cjoy\u201d and to supply this emotion\/instinct state information S to the action decision mechanism section . In this state, if the external information signal S indicating that \u201cthe palm is in front of the pet-type robot\u201d is supplied, the action decision mechanism  decides the action of \u201cgiving the paw with joy\u201d on the basis of the emotion\/instinct state information S indicating \u201cjoy\u201d and the external information signal S to the effect that \u201cthe palm is in front of the pet-type robot\u201d.","By the above-described various types of means, the action command information S is decided by the action decision mechanism section  and the selection module , that is, the action is decided as a concept. The decided action information command information S is inputted to the posture transition mechanism section .","The posture transition mechanism section  generates information for shifting to the target posture or the target motion.","As described above, the pet-type robot  causes the action decision mechanism section  to decide the next action to be taken. However, the current action and the next action are not necessarily realized in the same posture or motion. That is, there is considered a case where the current action is realized in a \u201clying posture\u201d and where the next action is realized in a \u201cstanding posture\u201d. In such a case, the transition from the \u201clying posture\u201d to the \u201cstanding posture\u201d must be made in order to carry out the next action. The posture transition mechanism section  is adapted for carrying out such transition of the posture or motion.","Specifically, the posture transition mechanism section  generates the posture transition information S for shifting the current posture or motion to the next posture or motion (the target posture or the target motion, or the posture or motion for realizing the next action) on the basis of the action command information S supplied from the action decision mechanism section , and sends the posture transition information S to the control mechanism section , as shown in . For example, the posture to which transition can be made from the current posture is decided in accordance with the physical shape of the pet-type robot  such as the shapes of the trunk and limbs, the weight and the coupling state of the respective parts, and the mechanism of the actuators A to N for the directions and angles of bending of the joints. The posture transition information S is the information for realizing transition in consideration of such shape and mechanism.","On the basis of the posture transition information S thus sent from the posture transition mechanism section , the control mechanism section  actually operates the pet-type robot .","The posture transition mechanism section  has registered therein in advance the posture to which transition can be made by the pet-type robot  and the motion in making the transition, and holds such information as a graph. The posture transition mechanism section  sends the action command information S, supplied from the action decision mechanism section , to the control mechanism section  as the posture transition information S. The control mechanism section  operates in accordance with the posture transition information S so as to shift to the target posture or the target motion. The processing at the posture transition mechanism section  will now be described in detail.","For example, there is a case where the pet-type robot  cannot directly shift to the posture in accordance with the contents of the command (action command information S). The postures of the pet-type robot  are classified into postures to which direct transition can be made from the current posture, and postures to which transition can be made not directly but via a certain motion or posture.","The quadrupedal pet-type robot  can directly shift from the sprawling state to the state of getting down, but cannot directly shift to the standing posture and needs to make two stages of motions, that is, drawing the limbs back toward the trunk so as to take the lying posture and then standing up. There is also a posture that cannot be taken safely. For example, the quadrupedal pet-type robot  will fall down if it tries to raise the forelimbs up in the standing posture. Alternatively, when a command having the contents of \u201cfluttering the limbs\u201d, which can be done only in the sitting posture, is sent in the case where the current posture is the sprawling posture (or lying posture), the transition from the lying posture to the sitting posture and the motion of fluttering the limbs are carried out and the pet-type robot  may lose its balance and fall down.","Therefore, when the action command information S supplied from the action decision mechanism section  indicates the posture to which direct transition can be made, the posture transition mechanism section  sends the action command information S as it is, as the posture transition information S to the control mechanism section . On the other hand, when the action command information S indicates the posture to which direct transition cannot be made, the posture transition mechanism section  generates the posture transition information S for shifting to the target posture (posture instructed by the action command information S) via another posture or motion that can be taken, and sends this posture transition information S to the control mechanism section . Thus, the pet-type robot  can avoid any impossible attempt to take a posture to which transition cannot be made or any risk of falling down. Also, the preparation of a plurality of motions to reach the target posture or motion leads to the abundance of expressions.","The pet-type robot  is adapted for representing the action of the electronic pet in the real world. Thus, it is essential to consider the current posture or the like when making transition to the target motion or posture, as described above. It is also essential to consider the conflict of resources, which will be described later. Meanwhile, such consideration is not required in the virtual electronic pet device  adapted for representing the action of the electronic pet in the virtual world (on the screen).","Specifically, the posture transition mechanism section  holds a graph having registered therein the posture and motion that can be taken by the pet-type robot  and constituted by the posture and the motion for shifting the posture. The posture transition mechanism section  then searches for a path from the current posture to the target posture or the target motion on the graph on the basis of the action command information S as the command information, and causes the pet-type robot to move in accordance with the search result, thus shifting from the current posture to the target posture or the target motion. That is, the posture transition mechanism section  registers in advance the postures that can be taken by the pet-type robot , and also records the connection between two postures which allow transition. The posture transition mechanism section  thus makes transition to the target posture or motion on the basis of the graph and the action command information S outputted from the action decision mechanism section .","Specifically, as the above-described graph, the posture transition mechanism section  uses an algorithm called a directed graph  as shown in . The directed graph  is constituted by coupling a node indicating the posture that can be taken by the pet-type robot , a directed arc (motion arc) for connecting two postures (nodes) which allow transition, and depending on the case, a motion arc for returning from one node to this one node, that is, a self-motion arc indicating the motion completed within one node. That is, the posture transition mechanism section  holds the directed graph  constituted by the node as the information indicating the posture (standstill posture) of the pet-type robot , and the directed arc and the self-motion arc as the information indicating the motion of the pet-type robot . The posture transition mechanism section  then regards the posture as point information and regards the information of the motion (or action) as directed line information.","In this case, there may be a plurality of directed arcs or self-motion arcs. That is, a plurality of arcs may be provided between the nodes (postures) which allow transition, and a plurality of self-motion arcs may be coupled in one node.","When the action command information S is supplied from the action decision mechanism section , the posture transition mechanism section  searches for a path from the current node to the next node along the direction of the directed arc so as to connect the node corresponding to the current posture and the node corresponding to the next posture to be taken indicated by the action command information S, and sequentially records the nodes located on the path thus searched for, thereby making the plan of posture transition. Hereinafter, the search for the target node (node instructed by the command) or the target arc (arc instructed by the command) from the current posture is referred to as path search. In this case, the target arc may be a directed arc or may be a self-motion arc. For example, in the case where a self-motion arc is the target arc, a self-motion is the target (instructed), that is, for example, a predetermined performance (motion) is instructed.","On the basis of the posture transition plan to reach the target posture (node) or the target motion (directed arc or self-motion arc) obtained by path search, the posture transition mechanism section  outputs a control command (posture transition information S) for transition to the control mechanism section  on the subsequent stage.","For example, as shown in , when the action command information S representing \u201cSit\u201d is supplied in the case where the current posture is at the node DN indicating the posture of \u201cgetting down\u201d, direct transition from the node ND indicating the posture of \u201cgetting down\u201d to the node ND indicating the posture of \u201csitting\u201d is possible since the directed arc a exists from the node ND to the node ND. Thus, the posture transition mechanism section  provides the posture transition information S having the contents of \u201cSit\u201d to the control mechanism section .","On the other hand, when the action command information S representing \u201cWalk\u201d is supplied in the case where the current posture is at the node ND indicating the posture of \u201cgetting down\u201d, since direct transition from \u201cgetting down\u201d to \u201cwalking\u201d is not possible, a posture transition plan is made by searching for a path to reach the node ND indicating the posture of \u201cwalking\u201d from the node ND indicating the posture of \u201cgetting down\u201d. That is, a posture transition plan is made such as to select the node ND indicating the posture of \u201cstanding\u201d via the directed arc a from the node ND indicating the posture of \u201cgetting down\u201d and then to reach the node ND indicating the posture of \u201cwalking\u201d via the directed arc a from the node ND indicating the posture of \u201cstanding\u201d. As a result of such a posture transition plan, the posture transition mechanism section  outputs the posture transition information S having the contents of \u201cStand\u201d and then outputs the posture transition information S having the contents of \u201cWalk\u201d, to the control mechanism section .","The pet-type robot  is capable of separately operating the individual constituent parts. That is, commands can be executed with respect to each of the constituent parts. Such constituent parts of the robot device  (whole body) may be generally the head portion , the limb portions , and the tail portion , as shown in .","In the pet-type robot  thus constituted, the tail portion  and the head portion  can be operated separately. That is, these portions can be operated separately since there is no conflict of resources. On the other hand, the whole body of the pet-type robot  and the head portion  cannot be operated separately. That is, the whole body and the head portion cannot be operated separately since there is a conflict of resources. For example, while a command for the motion of the whole body including the motion of the head portion  is executed, a command for the head portion  cannot be executed. It is possible for the pet-type robot to wag the tail portion  while shaking the head portion , but it is impossible to shake the head portion  while doing a certain performance using the whole body. The occurrence of such a conflict of resources is a problem proper to the pet-type robot , which constitutes the electronic pet in the real world.","The following table shows exemplary combinations of parts which cause and do not cause a conflict of resources with respect to the action command information S sent from the action decision mechanism section .",{"@attributes":{"id":"p-0212","num":"0211"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"left"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Combination of Parts","Conflict of Resources"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Head, Tail","No"]},{"entry":[{},"Head, Whole Body","Yes"]},{"entry":[{},"Limbs, Whole Body","Yes"]},{"entry":[{},"Head, Limbs, Tail","No"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"In the case where the commands which cause a conflict of resources is thus supplied, either the command for the motion of the whole body  or the command for the motion of the head portion  must be executed preferentially. The processing for dealing with such commands will now be described.","In the case of preferentially executing one of the commands because there is a conflict of resources, for example, in the case of completing the motion of the whole body  and then executing the command for the head portion , the motion of the head portion  is started in the last posture which is reached as a result of the motion of the whole body . However, the last posture after the motion of the whole body  is not necessarily a posture suitable for starting a motion such as shaking the head portion . If the motion of the head portion  is started when the last posture after the motion of the whole body  is not a posture suitable for starting the motion of the head portion , that is, when the postures between which transition is made are discontinuous due to the different commands, the head portion  may move abruptly, thus generating an unnatural motion. This problem is caused in the case where the transition from the current posture (or motion) to the target posture (or motion) extends over the whole body and the individual constituent parts of the pet-type robot  and where a network (graph) including the node and arc constituted for controlling the whole body of the pet-type robot  and networks (graphs) including the node and arc constituted for controlling the individual constituent parts of the pet-type robot  are separately constituted without having any relation with each other.","The unnatural motion, generated by the pet-type robot  due to the discontinuity of the postures between which transition is made, is eliminated by making a posture transition plan so as to smoothly connecting the transition motions on the graph. Specifically, a basic posture shared on the graphs of the whole body and the constituent parts is employed to make the posture transition plan.","Information of a network used for the posture transition plan of the pet-type robot  will be described hereinafter with reference to the case where it is constituted by the information (graph) of the network of the whole body and the information (graphs) of the networks of the individual constituent parts, as shown in . For example, the information used for the posture transition plan consisting of the information (graph) of the network of the whole body and the information (graphs) of the networks of the individual constituent parts is constituted within the posture transition mechanism section , as shown in .","The basic posture is a posture to which transition is temporarily made in order to shift the state between the motion of the whole body and the motion of each constituent part. The basic posture may be, for example, a sitting posture as shown in . The procedure for smoothly connecting the transition motions in the case where the sitting posture is employed as the basic posture will now be described.","Specifically, it is the case where the current posture is understood as the posture NDa on the graph of the whole body and where a motion a of the head portion is to be executed as a target motion, as shown in .","On the graph of the whole body, a directed arc a for shifting the posture of the whole body of the pet-type robot  from the current posture NDa to a basic posture NDab is selected. In the case where the whole body is in the basic posture, the state (node) of the basic posture is also grasped on the graphs of the head portion, the limb portions, and the tail portion.","On the graph of the head portion, an optimum directed arc a from the state of a basic posture NDhb is selected, and a path to reach the target motion (self-motion arc) a of the head portion  is decided.","In accordance with such procedure, the selection of the transition path (posture transition plan) so as to smoothly connects the motions of the whole body and each constituent part is carried out on the graph of the whole body and the graph of the head portion. Then, the posture transition mechanism section  outputs the posture transition information S to the control mechanism section  on the basis of the posture transition plan.","In the above-described example, the motions are smoothly connected the motion of the whole body to the motion of each constituent part. An example in which the motions are smoothly connected from the motion of each constituent part to the motion of the whole body will now be described. Specifically, it is the case where the posture of the head portion  is grasped as a posture NDh on the graph of the head portion while the posture of the limb portion  is grasped as a posture NDf on the graph of the limb portion and where a motion a of the whole body is to be executed as a target motion, as shown in .","On the graph of the head portion, a directed arc a for shifting the posture of the head portion  from the current posture NDh to a basic posture NDAB is selected. On the graph of the limb portion, directed arcs a and a for shifting the posture of the limb portion  from the current posture NDf to a basic posture NDfb via a posture NDf are selected. It is assumed that the tail portion  is originally in its basic posture. In the case where the respective constituent parts are thus in the basic postures, the basic posture is also grasped on the graph of the whole body.","On the graph of the whole body, an optimum directed arc a from the state of the basic posture NDhb is selected and a path to reach the target motion (self-motion arc) a of the whole body is decided.","For example, the motion of each constituent part may be executed simultaneously with the motion of another constituent part in the transition to the basic posture, and the motions of the respective constituent parts may be executed with some limitations. For example, certain timing for carrying out the motion may be provided.","Specifically, if a command for the motion of the whole body  is given while the pet-type robot is doing a certain performance with its head portion , transition of the head portion  to the basic posture NDhb cannot be made since the pet-type robot is doing a performance with the head portion . Therefore, the limb portion  is first set in the state of the basic posture NDfb and then the head portion  on completion of the performance is shifted to the state of the basic posture NDhb.","The individual constituent parts can also be moved in consideration of the balance of the posture of the whole body . For example, if the head portion  and the limb portion  are simultaneously shifted, or if the head portion  is first shifted to the state of the basic posture NDhb, the pet-type robot  loses its balance and falls down. In such a case, the limb portion  is first set to the state of the basic posture NDfb and then the head portion  is shifted to the state of the basic posture NDhb.","By thus making the posture transition plan which allows temporary transition to the basic posture, the motions can be smoothly connected.","The posture transition mechanism section  searches for an optimum path to the target posture or motion indicated by the command so as to make the posture transition plan on the basis of the action command information S sent from the action decision mechanism section , and outputs the posture transition information S to the control mechanism section  in accordance with the posture transition plan, as described above.","Thus, the pet-type robot  can avoid any impossible attempt to take a posture to which transition cannot be made or any risk of falling down. Also, the preparation of a plurality of motions to reach the target posture or motion leads to the abundance of expressions.","The control mechanism section  generates a control signal S for driving the actuators A to N on the basis of the posture transition information S, as shown in , and sends the control signal S to the actuators A to N so as to drive the actuators A to N, thus causing the pet-type robot  to make a desired motion.","Specifically, in the case where the transition of the posture or motion is necessary for taking the next action, the control mechanism section  controls the actuators A to N on the basis of the posture transition information S in accordance with the posture transition plan sent from the posture transition mechanism section , thus shifting the pet-type robot  to a desired posture or motion. Then, the control mechanism section  controls the actuators A to N on the basis of the subsequently supplied information of the action selected by the selection module , thus causing the pet-type robot  to carry out the selected action, for example, a performance.","In the case where the transition of the posture or motion is not necessary for taking the next action, the control mechanism section  controls the actuators A to N on the basis of the subsequently supplied information of the action selected by the selection module , thus causing the pet-type robot  to carry out the selected action (e.g., a performance), without carrying out the transition of the posture or motion.","The specific structure of the pet-type robot  is described above. Such a pet-type robot  can change the state of the emotion and the state of the instinct using the emotion models and the instinct models on the basis of the external information (environment or external elements) or the internal information (internal elements) and can act in accordance with the state of the emotion and the state of the instinct.","Thus, since parameters corresponding to the emotion and instinct of the electronic pet are contained in the pet-type robot , a short-tempered electronic pet or a crybaby electronic pet can be realized. It is thus possible to cause the electronic pet to take an action in consideration of such an emotion or action, and to change the emotion in accordance with the action carried out by the electronic pet itself. Specifically, when the electronic pet is hungry and thus has the emotion of anger at a high level, it is possible to cause the electronic pet to take an action like crying or falling asleep and to sooth the increased emotion of anger in accordance with that action. Thus, an electronic pet with more reality is realized.","In the embodiment, the structure shown in  is employed as the specific structure of the pet-type robot . However, it is a matter of course that the structure shown in  can be applied to the virtual electronic pet device . For example, in the case where the structure is applied to the virtual electronic pet device , an equivalent technique is employed for inappropriate portions, thus realizing the virtual electronic pet device  as shown in . For example, in the virtual electronic pet device , since the motion section (actuators A to N) is not required, it is changed to an output to the image display section, thus realizing the virtual electronic pet device . In the virtual electronic pet device , the mechanism for making the posture transition plan or for solving the conflict of resources is not required, either.","Thus, in the virtual world (on the display image), an electronic pet which changes the state of the emotion and the state of the instinct on the basis of the external or internal information and acts in accordance with the state of the emotion or the state of the instinct can be realized similarly.","In the electronic pet system, as described above, an electronic pet which stores the pet characteristic information in the individual information storage section  (IC card ) and has the emotion or instinct based on the stored pet characteristic information is realized.","For example, in the case where the virtual electronic pet device  or the pet-type robot  is constituted as described above, the pet characteristic information stored in the individual information storage section  (IC card ) may be the emotion parameters and the instinct parameters decided by the above-described emotion models and the instinct models. In this case, the emotion parameters and the instinct parameters are stored in the individual information storage section , as shown in .","As the pet characteristic information, the transition probability in deciding actions can also be stored in the individual information storage section .","As described with reference to , using the finite probability automaton, actions are decided in terms of the probability on the basis of the transition probabilities P to Pn which are set for respective arcs ARC to ARCn connecting the respective nodes NODE to NODEn and indicating to which node NODE to NODEn the transition should be made from one node (state) NODE to NODEn, and these transition probabilities P to Pn can also be stored in the individual information storage section . The transition probabilities P to Pn can be changed in accordance with the state of the emotion, the state of the instinct, or learning. Therefore, the individuality of the electronic pet can be realized by storing the transition probabilities.","The pet characteristic information stored in the individual information storage section  is not limited to the above-described example.","For example, the name of the electronic pet, the name of the owner (the name of the keeper (user)), the time of growth, the number of remaining metempsychoses, and the species may also be employed. The time of growth is the elapsed time from the birth of the electronic pet up to the present. The electronic pet (its soul) comes back to life after death, and the number of remaining metempsychoses is the information indicating the number of remaining times for coming back to life. Specifically, it is the number of times for reset. The species is the information indicating the kind of the electronic pet such as dogs, cats, or birds. The kind of the electronic pet need not necessarily be an existent animal.","The pet characteristic information may also be learning information. The learning information is the information related to whether the electronic pet can do a predetermined performance or not. That is, the electronic pet is enabled to learn several types of performances and the learning information indicates whether the electronic pet can do each type of performance.","In the present embodiment, since the internal information is stored on the IC card  that can be inserted to and ejected from the virtual electronic pet device  or the pet-type robot , the electronic pet can be enjoyed in a form suitable for the user's environment.","In the present embodiment, the IC card  is loaded in the virtual electronic pet device  or the pet-type robot  so as to cause the virtual electronic pet device  or the pet-type robot  to function as the electronic pet. However, the IC card  can also be loaded into a typical computer or the like, and it is thus possible to cause the computer to function as the electronic pet.","In the present embodiment, the present invention is described with respect to the electronic pet. However, the present invention can also be applied to other living objects than the electronic pet (e.g., plant object or the like).","Moreover, in the present embodiment, the pet characteristic information is stored on the IC card. However, as the storage means for storing the pet characteristic information, portable storage means that can be inserted to and ejected from the device can be employed, such as a memory card, an optical card, a magneto-optical disc, and a magnetic disk.","In addition, in the present embodiment, the individual information storage section  storing the pet characteristic information can be inserted to and ejected from the body section . However, it is also possible to provide a memory (built-in storage medium or storage unit) that can be inserted to and ejected from the body section  and to store the pet characteristic information into that memory. In this case, the individual information storage section  and the body section  transmits the pet characteristic information by using various types of communication means, for example, a communication cable, radio transmission, or infrared rays.","In the virtual electronic pet device , the electronic pet is a virtual existence displayed on the monitor and therefore its appearance is easily changed. However, it is difficult for the pet-type robot  to change its appearance. Therefore, in the pet-type robot , the information related to the appearance, of the pet characteristic information, is basically ignored. When the species of the pet characteristic information indicates birds in the case where the pet-type robot  is in the shape of a dog, it is possible to cause the pet-type robot  to request a change of parts for those of a bird (for example, by means of a synthetic voice).","A specific example of the IC card that can be inserted and ejected, used in the above-described first embodiment, is shown in . IC cards of various shapes are currently standardized and the present invention is applicable to any of such IC cards. In the present embodiment, a stick-shaped IC card is employed, for example.","The stick-shaped IC card can be inserted and ejected, as described above. When the user inserts the stick-shaped IC card into the slot A of the pet-type robot  or the slot A of the virtual electronic pet device , the user will be at a loss for determining how deep the user can insert the IC card. That is, when loading the IC card into the slot A of the pet-type robot  or the slot A of the virtual electronic pet device , it is convenient if the user can feel the loading by a loading sound (a clicking sound or the like) or if the pet-type robot  or the virtual electronic pet device  has an IC card lock\/ejection function. However, if the user cannot feel the loading or if the lock\/ejection function is provided, the user might break the IC card by forcibly inserting the IC card into the slot, or cannot carry out transmission\/reception of data because of insufficient insertion of the IC card.","Thus, in the present embodiment, color discrimination for indicating a predetermined insertion position is carried out on an IC card , as shown in . Specifically, as the color of a portion  which should be out of the slot and the color of a portion  which should be inserted and kept in the slot are made different (color discrimination is made), the user can visually recognize the state of the accurately loaded IC card when the IC card  is inserted in the slot A of the pet-type robot  or the slot A of the virtual electronic pet device . Although  shows an example in which color discrimination is made on a label  attached to the body of the IC card , color discrimination may also be made on the body of the IC card  itself. In the present invention, the colors of the portions  and  for color discrimination are not particularly limited, and arbitrary colors can be used.","Although color discrimination is made on the IC card  in the example of , it is also possible to provide an arrow mark  as shown in , together with or in place of the color discrimination on the IC card .  shows an example in which the color of a portion  to be out of the slot and the color of a portion  to be inserted and kept in the slot are made different similarly to the example of  and in which the arrow mark  is added to the portion  which should be out of the slot. By thus providing the arrow mark , the user not only can accurately load the IC card  into the slot but also can easily recognize the loading direction of the IC card . Although  shows the example in which color discrimination is made on the label  attached to the body of the IC card  and in which the arrow mark  is added to the label , the arrow mark  may also be provided on the body of the IC card  itself.","As a still another example, it is possible to provide a line  indicating the boundary position as shown in , together with or in place of the color discrimination.  shows an example in which the color of a portion  to be out of the slot and the color of a portion  to be inserted and kept in the slot are made different similarly to the example of  and in which the line  is added at the boundary position between the portion  to be out of the slot and the portion  to be kept in the slot. By thus providing the line , the user can accurately load the IC card  into the slot. Although  shows the example in which color discrimination is made on the label  attached to the body of the IC card  and in which the line  is added to the label , the line  may also be provided on the body of the IC card  itself.",{"@attributes":{"id":"p-0256","num":"0255"},"figref":"FIG. 25","b":["131","23","22"]},{"@attributes":{"id":"p-0257","num":"0256"},"figref":["FIG. 26","FIG. 26","FIG. 22"],"b":["132","131","132","134","131","133"]},{"@attributes":{"id":"p-0258","num":"0257"},"figref":["FIG. 27A","FIGS. 22 to 24","FIG. 27B","FIG. 26"],"b":["131","131","137","23","23","22","22","138","132","134","131"]},"A second embodiment of the present invention will now be described.","In the first embodiment, storage of the individual information storage section  (pet characteristic information of the electronic pet) in a storage medium such as an IC card that can be inserted and ejected is enabled, and insertion\/ejection of the IC card to\/from the slot A of the virtual electronic pet device  or the slot A of the pet-type robot  is enabled, thus enabling transfer of the pet characteristic information between the virtual electronic pet device  and the pet-type robot . In the second embodiment, however, transfer of the pet characteristic information is enabled by communication without using an IC card.",{"@attributes":{"id":"p-0261","num":"0260"},"figref":"FIG. 28"},"A virtual electronic pet device  shown in  is basically the same as the above-described virtual electronic pet device , and a pet-type robot  shown in  is basically the same as the above-described pet-type robot . In the second embodiment, however, both the virtual electronic pet device  and the pet-type robot  have a communication processing section which enables replacement of the pet characteristic information of the above-described individual information storage section  by communication. The pet characteristic information communicated via the communication processing section can be stored onto an IC card as described above and can also be stored into data storage sections  and  which are internally provided. (In , it is shown that they are outside of the virtual electronic pet device  and the pet-type robot , respectively, but they are actually provided therein.) In the second embodiment, the pet characteristic information is stored into the internally provided data storage sections.","In the example of connection shown in , the virtual electronic pet device  and the pet-type robot  are connected to a personal computer , and the personal computer  is connected a network such as the Internet . Meanwhile, it is also possible to directly connect the virtual electronic pet device  to the pet-type robot  without using the personal computer , or to directly connect them to the Internet  without using the personal computer . Moreover, in the second embodiment, it is possible to connect the virtual electronic pet devices  to each other or the pet-type robots  to each other.","The electronic pet can be expressed not only by the virtual electronic pet device  or the pet-type robot  but also on the personal computer . In this case, by installing an application program for realizing the above-described electronic pet on the personal computer  and starting the application program for the electronic pet, it becomes possible to keep the electronic pet on the personal computer . Therefore, also the pet characteristic information of the electronic pet is stored into the personal computer .","In the second embodiment, as the connection form in the case of transmitting and receiving the pet characteristic information between the virtual electronic pet device  and the pet-type robot , various forms of connection can be considered such as connection via a cable, connection via radio transmission, and connection by infrared rays. The present invention is applicable to any connection form including such connection via a cable, radio transmission, and infrared rays.",{"@attributes":{"id":"p-0266","num":"0265"},"figref":["FIG. 29","FIGS. 3","FIG. 29","FIG. 29"],"b":["204","204","5","7"]},"In , a RAM  corresponds to the RAM  of , and a processing unit  corresponds to the CPU  of .","The communication processing section  of the pet-type robot  shown in  has an infrared (IrDa) transmission\/reception section , a serial port section , and a radio transmission\/reception section , as communication means connected to the outside (e.g., the virtual electronic pet device, the personal computer, or the Internet) for transmitting and receiving the pet characteristic information. These communication means are connected to a communication control section .","The communication control section  is controlled by the processing unit  corresponding to the CPU  of , and operates in accordance with a communication clock from a clock generation section , thus transmitting and receiving data in accordance with a communication protocol corresponding to the connection form of the communication means.","The data to be transmitted is read out from the RAM  under the control of the processing unit , then temporarily stored in a transmitted data storage section  as a transmission buffer, and then transmitted from the communication means via the communication control section . The data received by the communication means is temporarily stored in a received data storage section  as a reception buffer via the communication control section  and then sent to the RAM .",{"@attributes":{"id":"p-0271","num":"0270"},"figref":"FIG. 30"},"A virtual electronic pet device  shown in  has a monitor  for displaying the electronic pet, a speaker  for outputting a voice, a microphone  for picking up a voice, operation buttons  for the user to input various operations to the device , LEDs (light-emitting diodes)  which are lit in accordance with the operated buttons, and a talk switch  for instructing analysis of the voice picked up from the microphone  as described above.","The virtual electronic pet device  as shown in  has an internal hardware structure as shown in . The structure shown in  has basically the same function as the structure of , but a communication interface  is provided as the structure to enable communication of the pet characteristic information as in the second embodiment.","In , a processing unit  is adapted for carrying out various types of processing in accordance with programs stored in a ROM . The ROM  stores programs to be executed by the processing unit  and data necessary for executing the programs. A RAM  stores data necessary for the operation of the processing unit .","The communication interface  functions as an interface corresponding to the communication means and the communication control section  shown in .","The microphone  converts a voice inputted thereto to an audio signal as an analog electric signal and supplies the audio signal to an A\/D converter . The A\/D converter  performs A\/D conversion on the analog audio signal from the microphone  and outputs a digital audio signal to a voice recognition device .","The voice recognition device  carries out linear prediction analysis of the audio signal inputted thereto so as to extract the characteristic quantity, and carries out voice recognition based on, for example, the HMM method. A program executed by the voice recognition device  for carrying out voice recognition and word models as the objects of voice recognition are stored, for example, in a ROM . In the ROM , particularly the word models used for the keeper to talk to the pet are stored as the word models to be the objects of voice recognition. The method of acoustic analysis is not limited to the linear prediction analysis, and the method of voice recognition is not limited to the HMM method. A RAM  stores data necessary for the operation of the voice recognition device .","A key section corresponds to the operation buttons  and the talk switch  shown in . A signal outputted from the key section ,  as the user operates the key section is inputted to the processing unit . Thus, the processing unit  recognizes the buttons and keys operated by the user. For example, when the operation buttons  in the key section are operated, various types of inputs are provided to the electronic pet in response to the operations. When the talk switch  in the key section is pressed, the processing unit  causes the voice recognition device  to start voice recognition of the voice inputted from the microphone .","A sensor  is a sensor for detecting the state of the external environment such as the sound, light, and temperature. A detection signal from this sensor  is converted to a digital signal by an A\/D converter  and then sent to the processing unit . The processing unit  controls the reaction of the electronic pet on the basis of the detection data obtained from the sensor .","A voice synthesizer  synthesizes a voice to be outputted by the electronic pet under the control of the processing unit . A program for the voice synthesizer  to carry out voice synthesis and data as the basis for voice synthesis are stored, for example, in a ROM . In the ROM , data for synthesizing various types of voices to be outputted by the electronic pet are stored. A ROM  stores data necessary for the operation of the voice synthesizer .","A D\/A converter  performs D\/A conversion on the audio data synthesized by the voice synthesizer  so as to generate an analog audio signal, and supplies the analog audio signal to the speaker . The speaker  includes an amplifier so as to amplify the audio signal from the D\/A converter  and then outputs the amplified audio signal.","A liquid crystal display (LCD) section  includes a liquid crystal controller which is controlled by the processing unit  and displays various images (e.g., images of the electronic pet) and characters.",{"@attributes":{"id":"p-0283","num":"0282"},"figref":"FIG. 32","b":["220","204","220","204"]},"In , a CPU  of the virtual electronic pet device  corresponds to the processing unit  of , a RAM  corresponds to the RAM  of , and a ROM  corresponds to the ROM  of . An image controller  corresponds to the liquid crystal controller included in the liquid crystal display section  of . A data storage section  stores the pet characteristic information. The pet characteristic information is transmitted to and received from the pet-type robot  via the USB cable connected to a USB port .","A CPU  of the pet-type robot  corresponds to the processing unit  of , a RAM  corresponds to the RAM  of , and a ROM  corresponds to the ROM  of . A mechanical controller  controls the driving mechanism  of  under the control of the CPU . A data storage section  stores the pet characteristic information. The pet characteristic information is transmitted to and received from the virtual electronic pet device  via the USB cable connected to a USB port .",{"@attributes":{"id":"p-0286","num":"0285"},"figref":["FIG. 33","FIG. 33","FIG. 32"],"b":["220","204","220","204"]},"In the example of , an infrared transmission\/reception section  of the virtual electronic pet device  is provided in the communication interface  of . The pet characteristic information is transmitted and received between the infrared transmission\/reception section  and an infrared transmission\/reception section  of the pet-type robot .","The infrared transmission\/reception section  of the pet-type robot  corresponds to the infrared transmission\/reception section  shown in . The pet characteristic information is transmitted and received between the infrared transmission\/reception section  and the virtual electronic pet device .",{"@attributes":{"id":"p-0289","num":"0288"},"figref":["FIG. 34","FIG. 34","FIG. 32"],"b":["220","204","220","204"]},"In the example of , a radio transmission\/reception section  of the virtual electronic pet device  is provided in the communication interface  of . The pet characteristic information is transmitted and received between the radio transmission\/reception section  and a radio transmission\/reception section  of the pet-type robot .","The radio transmission\/reception section  of the pet-type robot  corresponds to the radio transmission\/reception section  shown in . The pet characteristic information is transmitted and received between the radio transmission\/reception section  and the radio transmission\/reception section  of the virtual electronic pet device .","Specifically, as the radio transmission\/reception section  of the pet-type robot  and the radio transmission\/reception section  of the virtual electronic pet device , Bluetooth modules  and  can be used, respectively, as shown in .","The Bluetooth is a radio interface using ISM (industrial Scientific Medical) band of 2.4 GHz which does not require permission as the carrier frequency. The Bluetooth modules  and  employ this Bluetooth radio interface. The schematic structure of the Bluetooth will be described as follows.","The Bluetooth uses a spread spectrum technique in accordance with a frequency hopping system. It uses 79 channels each having a width of 1 MHZ and capable of switching the channel 1600 times per second at the maximum. Thus, interference with other radio communications is prevented. Carrier sense is not carried out since hopping is switched to high-speed hopping.","The maximum data transmission speed is 1 Mbits\/sec. The multiplexing method for packets can deal with both TDD (time division duplex) circuit switching and packet switching. While asynchronous transmission is carried out, a maximum of three audio channels each having 64 kbits\/sec can be secured simultaneously.","The Bluetooth-compatible equipments are classified into a \u201cmaster\u201d for deciding the frequency hopping pattern and a maximum of seven \u201cslaves\u201d accompanying the master. A sub-net constituted by the master and several slaves is called \u201cpico-net\u201d. Since the master can be a slave of the pico-net, it is possible to form a network by sequentially connecting pico-nets. For example, such a network structure is called stacker net. In the pico-net or the stacker net, communications and the state of equipments are managed using an 8-bit MAC address.","The Bluetooth equipment deals with several modes of different dissipation powers, depending on the state of participation in the communication. By fragmenting the mode in the specification, the dissipation power is reduced.","The link between the master and the slaves is set by the Bluetooth as follows. First, the master transmits \u201cInquiry\u201d, which is a message including a key for connection or the like, at an interval of 625 \u03bcs. On the slave side, since the channel is constantly switched in accordance with the hopping pattern, synchronization is made approximately in two seconds. Thus, the master recognizes the slave, and the slave obtains 3-bit \u201cActive member address\u201d and enters the pico-net. \u201cActive member address\u201d is address information of 3 bits allocated to the equipment which communicates with the master. As this \u201cActive member address\u201d is allocated, the pico-net is formed.","After that, the master sends a \u201cPage\u201d message to the slave. The slave the operates in the hopping pattern decided by the master.","After that, authentication is carried out. An encryption key used for authentication is produced by the exclusive OR of a random number generated by the master and the MAC address of the slave. On completion of the authentication, a dedicated key is provided to simplify the subsequent processing. Then, transmission and reception of data is started.","The foregoing is the schematic structure of the Bluetooth. The pet-type robot  and the virtual electronic pet device  can have the Bluetooth modules  and  employing such Bluetooth radio interfaces, respectively, as the radio transmission\/reception sections.",{"@attributes":{"id":"p-0302","num":"0301"},"figref":["FIG. 36","FIG. 36","FIG. 32"],"b":["201","204","201","204","201","200"]},"In the example of , a CPU  of the personal computer  corresponds to a processor unit, and a ROM , a RAM , and a USB port  are generally provided in the personal computer. A data storage section  corresponds to a hard disk, for example. This personal computer  transfers to the Internet  the pet characteristic information transmitted from the pet-type robot  via the USB cable, and transfers the pet characteristic information received from the Internet  to the pet-type robot  via the USB cable.",{"@attributes":{"id":"p-0304","num":"0303"},"figref":["FIG. 37","FIG. 37","FIGS. 36 and 33"],"b":["201","204","201","204","201","200"]},"In the example of , the personal computer  has an infrared transmission\/reception port , thus transferring to the Internet  the pet characteristic information transmitted from the pet-type robot  by using infrared rays and also transferring the pet characteristic information received via the Internet  to the pet-type robot  by using infrared rays.",{"@attributes":{"id":"p-0306","num":"0305"},"figref":["FIG. 38","FIG. 38","FIGS. 36 and 34"],"b":["201","204","201","204","201","200"]},"In the example of , the personal computer  has a radio transmission\/reception section , thus transferring to the Internet  the pet characteristic information transmitted from the pet-type robot  by using radio waves and also transferring the pet characteristic information received via the Internet  to the pet-type robot  by using radio waves. Specifically, as the radio transmission\/reception section  of the pet-type robot  and the radio transmission\/reception section  of the virtual electronic pet device , Bluetooth modules  and  can be used, respectively, as shown in . The modules  and  employ Bluetooth radio interfaces, as described above.",{"@attributes":{"id":"p-0308","num":"0307"},"figref":["FIG. 40","FIG. 40"]},"In , a connection request is issued, for example, from the pet-type robot. Specifically, the pet-type robot first transmits a connection request signal to the virtual electronic pet device (expressed as a portable electronic pet in ), as indicated by TR in . In this case, the connection request is issued from the pet-type robot for the following reason. That is, if the connection request can be issued both from the pet-type robot and the virtual electronic pet device, a switch for determining which side should issue the connection request must be provided both in the pet-type robot and in the virtual electronic pet device, and particularly, providing such a switch in the pet-type robot is not desired in view of the design (i.e., it is desired that various switches are provided in a robot as a pet). However, the present invention is not limited to this example. The connection request can also be issued from the side of the virtual electronic pet device, and can be issued either from the pet-type robot or from the virtual electronic pet device.","Therefore, in the present embodiment, since it is decided to issue the connection request from the pet-type robot, the switch is not required.","In this case, the connection request signal transmitted from the pet-type robot includes an ownership flag (Own_flg), which is a flag indicating which of the pet-type robot and the virtual electronic pet device has the right of ownership of the pet characteristic information (that is, a flag indicating which of the pet-type robot and the virtual electronic pet device the soul resides in). In the present embodiment, the right of ownership of the pet characteristic information is not provided when the value of the ownership flag is 0 (Own_flg=0), and the right of ownership of the pet characteristic information is provided when the value of the ownership flag is 1 (Own_flg=1). In the example of , as an initial state, the value of the ownership flag of the pet-type robot is 0 (Own_flg=0) and the value of the ownership flag of the virtual electronic pet device is 1 (Own_flg=1).","On receiving the connection request signal, the virtual electronic pet device compares its own ownership flag (Own_flg=1) with the ownership flag (Own_flg=0) included in the received connection request signal. When the value of the ownership flag of the received connection request signal and the value of its own ownership flag are different, the virtual electronic pet device transmits a connection permission signal to the pet-type robot, as indicated by TR in .","On receiving the connection permission signal, the pet-type robot compares its own ownership flag (Own_flg=0) with the ownership flag (Own_flg=1) included in the received connection permission signal. When the value of the ownership flag of the received connection permission signal and the value of its own ownership flag are different, the pet-type robot transmits a data request signal to the virtual electronic pet device, as indicated by TR in .","On receiving the data request signal, the virtual electronic pet device transmits the pet characteristic information stored therein to the pet-type robot, as indicated by TR in .","On receiving all the necessary pet characteristic information, the pet-type robot transmits a reception completion signal to the virtual electronic pet device, as indicated by TR in , and changes the value of its own ownership flag to 1 (Own_flg=1).","On receiving the reception completion signal from the pet-type robot, the virtual electronic pet device changes the value of its own ownership flag to 0 (Own_flg=0). In the above-described manner, the flow in the case of transferring the pet characteristic information from the virtual electronic pet device to the pet-type robot is completed. Thus, it is considered that the individual information storage section has been shifted to the pet-type robot.",{"@attributes":{"id":"p-0317","num":"0316"},"figref":["FIG. 41","FIG. 41"]},"In , first, the pet-type robot transmits a connection request signal including the ownership flag to the virtual electronic pet device (expressed as a portable electronic pet in ), as indicated by TR in . The value of the ownership flag in this case is 1 (Own_flg=1).","On receiving the connection request signal, the virtual electronic pet device compares its own ownership flag (Own_flg=0) with the ownership flag (Own_flg=1) included in the received connection request signal. When the value of the ownership flag of the received connection request signal and the value of its own ownership flag are different, the virtual electronic pet device transmits a connection permission signal to the pet-type robot, as indicated by TR in .","On receiving the connection permission signal, the pet-type robot compares its own ownership flag (Own_flg=1) with the ownership flag (Own_flg=0) included in the received connection permission signal. When the value of the ownership flag of the received connection permission signal and the value of the ownership flag are different, the pet-type robot transmits the pet characteristic information stored therein to the virtual electronic pet device, as indicated by TR in .","On receiving all the necessary pet characteristic information, the virtual electronic pet device transmits a reception completion signal to the virtual electronic pet device, as indicated by TR in , and changes the value of its own ownership flag to 1 (Own_flg=1).","On receiving the reception completion signal from the virtual electronic pet device, the pet-type robot changes the value of its own ownership flag to 0 (Own_flg=0). In the above-described manner, the flow in the case of transferring the pet characteristic information from the pet-type robot to the virtual electronic pet device is completed. Thus, it is considered that the individual information storage section has been shifted to the virtual electronic pet device.",{"@attributes":{"id":"p-0323","num":"0322"},"figref":["FIG. 42","FIG. 42"]},"In , first, the pet-type robot transmits a connection request signal including the ownership flag to the virtual electronic pet device (expressed as a portable electronic pet in ), as indicated by TR in . The value of the ownership flag in this case is 0 (Own_flg=0).","On receiving the connection request signal, the virtual electronic pet device compares its own ownership flag (Own_flg=0) with the ownership flag (Own_flg=0) included in the received connection request signal.","In this case, since the value of the ownership flag of the received connection request signal and the value of its own ownership flag are the same, the virtual electronic pet device transmits a reception completion signal to the pet-type robot, as indicated by TR in . On receiving the reception completion signal, the pet-type robot ends the processing.",{"@attributes":{"id":"p-0327","num":"0326"},"figref":"FIG. 43"},"The connection request signal consists of the connection request ID, the number of communication bytes, which the number of bytes used at the time of connection, and the ownership flag (Own_flg) with its additional data, each of the connection request ID, the number of communication bytes and the ownership flag being represented by 4 bytes.","The connection permission signal consists of the connection permission ID, the number of communication bytes, and the ownership flag (Own_flg) with its additional data, each being represented by 4 bytes.","The reception completion signal consists of the reception completion ID, the number of communication bytes, and the ownership flag (Own_flg) with its additional data, each being represented by 4 bytes.","In the above-described embodiment, it is possible to transmit and receive the pet characteristic information of the electronic pet, directly or via the Internet. In the present invention, it is also possible to manage various types of information related to the electronic pet by a predetermined server  via the Internet . Hereinafter, this server is referred to as a pet shared server.",{"@attributes":{"id":"p-0332","num":"0331"},"figref":"FIG. 44","b":["202","201","204","204","260","200"]},"In the case of this network system, the pet shared server  is provided with a data storage section  which has a pet characteristic information storage section  for storing the pet characteristic information and a management information (shared server pet management information) storage section  for electronic pets managed by the pet shared server .",{"@attributes":{"id":"p-0334","num":"0333"},"figref":["FIG. 45","FIG. 45"],"b":["220","204","260","220","204","200"]},"In the example of , since the virtual electronic pet device  and the pet-type robot  can be connected directly to the Internet , the virtual electronic pet device  and the pet-type robot  include modems  and , respectively. Through the modems  and , it is possible to connect to the pet shared server  via the Internet  and to manage various types of data including the pet characteristic information by the pet shared server .","As it is made possible to manage the pet characteristic information of the electronic pet by the pet shared server  via the Internet  as shown in , it is possible to cause the pet shared server  to manage the pet characteristic information of the electronic pet, for example, in the case where the owner is away from home for a business trip, that is, to leave the electronic pet to the pet shared server, and at the destination of the business trip, retrieve and play with the pet characteristic information from the server, as shown in .","Specifically, in the example of , at home before making a business trip, the pet-type robot is first connected to the Internet so as to access the pet shared server, as described in A of . At this point, the value of the ownership flag of the pet-type robot is 1 (Own_flg=1). When the value of the ownership flag is 1, the pet-type robot automatically selects \u201cleaving\u201d for leaving the pet characteristic information to the server. Thus, the pet characteristic information is uploaded from the pet-type robot to the server. Since the individual electronic pets left to the pet shared server must be distinguished, the specific ID and password stored in the ROM of the pet-type robot are simultaneously transferred to the server in the uploading.","Next, at the destination of the business trip, for example, a portable terminal (a portable virtual electronic pet device or personal computer) is connected to the Internet so as to access the pet shared server, as described in B of . At this point, a plurality of menu items are displayed in the image display section of the portable terminal (the image display section of the portable virtual electronic pet device or the monitor of the personal computer). The menu items include \u201cleaving\u201d, \u201creceiving\u201d and so on. In this case, \u201creceiving\u201d is selected. For receiving the electronic pet which the user left, the user enters the ID and password to prevent reception of a wrong electronic pet. After that, the pet characteristic information of the electronic pet left to the pet shared server is downloaded to the portable terminal. Thus, the user can keep the electronic pet on the portable terminal or play with the electronic pet even at the destination of the business trip.","When returning from the destination of the business trip, for example, the portable terminal is connected to the Internet so as to access the pet shared server, as described in C of . Thus, a plurality of menu items are displayed in the image display section of the portable terminal. As the user selects \u201cleaving\u201d of the menu items and enters the ID and password, the pet characteristic information is uploaded from the portable terminal to the server.","After returning home from the business trip, the pet-type robot is connected to the Internet so as access the pet shared server, as described in D of . At this point, the value of the ownership flag of the pet-type robot is 0 (Own_flg=0). When the value of the ownership flag is 0, the pet-type robot automatically selects \u201creceiving\u201d for receiving the pet characteristic information from the server. Thus, the pet characteristic information is downloaded from the server to the pet-type robot.","In the above-described second embodiment, the electronic pet is kept as the electronic pet on the virtual electronic pet device, the pet-type robot, and the personal computer. However, as a third embodiment of the present invention, it is also possible that the pet-type robot plays as an electronic pet  in a virtual world  on the personal computer and that the user himself\/herself enters the virtual world  as an avatar  and plays with his\/her own electronic pet, as shown in . The avatar is the incarnation of the god appearing in the Indian mythology. In the virtual world drawn as two-dimensional or three-dimensional computer graphics, this avatar serves as a character representing the user.","In the present embodiment, it is also possible to let the avatar  of the user and his\/her electronic pet  enter a virtual world  which is constructed on the network and in which another avatar  and his\/her electronic pet  exist, and to let them communicate with each other.","In the example shown in , the virtual electronic pet device  and the pet-type robot  can be connected to the Internet  via the modems  and . However, the means for connection to the Internet is not limited to these modems. For example, connection can be made by Bluetooth modules, which are radio means. In such a case, the pet-type robot  and the virtual electronic pet device  have Bluetooth modules and respectively, as radio transmission\/reception sections, as shown in . Accordingly, Bluetooth modules and are connected to the Internet (e.g., public telephone network) and data transmission\/reception is carried out with the Bluetooth module of the pet-type robot  and the Bluetooth module the virtual electronic pet device . In this case, the Bluetooth modules and employ Bluetooth radio interfaces, as described above.","Hereinafter, the structure and operation will be described which are adapted for realizing the keeping of the electronic pet in a three-dimensional virtual space as in the third embodiment by using the WWW (world wide web) framework for providing various types of information via the Internet, which is a computer network constructed on the global scale, and by using VRML (virtual reality modeling language), which is a description language enabling unified handling of three-dimensional information.","First, prior to the description of the third embodiment of the present invention, VRML will be briefly explained.","VRML is a three-dimensional graphics description language which enables setting of links of hyper texts with respect to an object drawn by description in the three-dimensional space or three-dimensional graphics and which enables sequential access to the WWW server while tracing these links. To display the three-dimensional space described in this VRML, VRML browser has been developed. The details of VRML are described, for example, in Mark Pesce, \u201cVRML: Browsing & Building of Cyerberspace\u201d, 1995, New Readers Publishing, ISBN 1-56205-498-8 (and its Japanese version, translated by Koichi Matsuda, Terutaka Kamachi, Shoichi Takeuchi, Yasuaki Honda, Junichi Rekimoto, Masayuki Ishikawa, Ken Miyashita and Kazuhiro Hara, first edition published on Mar. 25, 1996), and Koichi Matsuda and Yasuaki Honda, \u201cThe Latest Trend of VRML and Cyber-Passage\u201d, bit (Kyoritsu Shuppan), 1996, Vol. 28, No. 7, pp. 29 to 36; No. 8, pp. 57 to 65; No. 9, pp. 29 to 36; and No. 10, pp. 49 to 58. The official complete specification of the Virtual Reality Modeling Language Version 2.0, ISO\/IEC CD 14772, Aug. 4, 1996 is laid open to the public at \u201chttp:\/\/webspace.sgi.com\/moving-words\/spec\/index.html\u201d and its Japanese version is laid open at \u201chttp:\/\/www.webcity.co.jp\/info\/andoh\/VRML\/vrml2.0\/spec-jp\/index.html\u201d. Moreover, as the VRML 2.0 browser and the shared server software, for example, the present Applicant, Sony Corporation has developed and produced \u201cCommunity Place Browser\/Bureau (trademark)\u201d, and its beta version (sample version) can be downloaded from the homepage \u201chttp\/\/vs.sony.co.jp\u201d on the Internet.","In the case of building a three-dimensional virtual space using such VRML 2.0, a VRML file representing desired contents is first prepared in accordance with the corresponding relation (routing) between the graphic data and the script, for example, preparation of the graphic data indicating the shape, motion, and position of an object (model) in the virtual space by using VRML (i.e., preparation of the model), addition, to the model, of a switch (sensor) which generates an event when the user clicks the mouse to point the model in the virtual space displayed on the screen (i.e., addition of the sensor), programming of the script for realizing the event generated in response to the pointing to the sensor (i.e., preparation of the script), and operation with respect to the sensor and starting of the script. (Hereinafter, common nodes such as the graphic data, the script, and the right prescribed in VRML are also referred to as nodes, as a general term.) For example, how to write and sample data of VRML 2.0 are explained at \u201chttp:\/\/www.ses.co.jp\/SES\/STAFF\/kan\/howto\/howto1.html\u201d.","The data of VRML 2.0 is constituted by a node and a field. The field provides a variable to the node and designates the parameter of the node. The field may be omitted. In the case where the field is omitted, a default value is used. As the field, a \u201csingle-value field (SF)\u201d having only a single value or a \u201cmultiple-value field (MF)\u201d may be employed. For the detailed function of the node and the field, \u201cAppendix 1: VRML 2.0 Node List\u201d should be referred to.","In VRML 2.0, a mechanism for realizing autonomic behavior in the VRML virtual space is prescribed. The details of the mechanism for autonomic behavior are disclosed in the paragraph of concepts in the specification 4. of the Virtual Reality Modeling Language Version 2.0, ISO\/IEC CD 14772, Aug. 4, 1996, which is laid open to the public at \u201chttp:\/\/webspace.sgi.com\/moving-worlds\/spec\/part1\/concepts.html\u201d and its Japanese version \u201chttp:\/\/www.webcity.co.jp\/info\/andoh\/VRML\/VRML2.0\/spec-jp\/part1\/concepts.html\u201d. In the paragraph, the key concepts for using the VRML specification are described. General items related to various nodes are described such as the method for coupling a node to a scene graph, the method in which a node generates or receives an event, the method for preparing a node type using a prototype, the method for adding a node type to VRML and exporting it so as to enable use from outside, and the method for incorporating a script operating as a program into the VRML file.",{"@attributes":{"id":"p-0350","num":"0349"},"figref":"FIG. 49"},"The constituent elements denoted by numerals , , and  in  are client PCs, that is, the above-described personal computers in which a VRML browser and a WWW browser are installed and operating. These client PCs are connected to the Internet  via Internet connection service providers , , and .","To a LAN (local area network)  connected to the Internet  via a router , a WWW server , a WLS (world location server) , a pet shared server , AO servers , , a mail server , and a communication server  are connected. In these servers  to , hard disks (HDDs) to are provided, respectively.","The communication server  is connected to a telephone set  and a facsimile  via a public telephone network . The communication server  is also connected to a PHS (personal handyphone system) terminal  via a PHS service provider , and is connected through radio waves to a pager terminal  via a pager service provider .",{"@attributes":{"id":"p-0354","num":"0353"},"figref":["FIG. 50","FIG. 49"],"b":"301"},"In , the client PC  is constituted by a CPU  for controlling each part, an HDD  in which the VRML contents made up of a script program of a virtual life object by VRML 2.0 or Java (trademark) and the user data are stored, a CD-ROM drive  for reading the VRML contents stored on a CD-ROM disc , a ROM  in which BIOS (basic input output systems) and the like are stored, a sound processing circuit  connected with a microphone  and left and right speakers , , a modem  for connecting to the Internet , an I\/O (input\/output) interface  connected with a mouse  and a keyboard , a graphics processing circuit  having a VRAM  provided therein, a CRT monitor , and a RAM . At the time of execution, a WWW browser (e.g., Netscape Navigator (trademark)) operating on an OS (e.g., Windows by Microsoft), an interpreter (e.g., Java interpreter), and a VRML 2.0 browser (e.g., Community place Browser developed by Sony Corporation) are read into the RAM  so as to be executed by the CPU .","In the VRML 2.0 browser, a syntax interpretation library (parser) of VRML (e.g., QvLib developed by Silicon Graphics of the U.S. and made open free of charge), and a software renderer (e.g., RenderWare produced by Criterion Software Ltd. of England) are provided.","The VRML 2.0 browser of this client PC carries out transmission\/reception of various types of data to\/from the WWW browser (e.g., Netscape Navigator) on the basis of NCAPI (Netscape Client Application Programming Interface (trademark)), as shown in .","On receiving the HTML file and the VRML contents (including the VRML file and the script program) from the WWW server  via the Internet , the WWW browser stores these data into the local HDD . The WWW browser processes the HTML file of the received data and displays texts and images on the CRT monitor. On the other hand, the VRML browser processes the VRML file and displays a three-dimensional virtual space on the CRT monitor, and also changes the behavior of the object in the three-dimensional virtual space in accordance with the result of processing of the script program by the interpreter.","Although not shown in the drawing, the other client PCs  and  are constituted similarly to the client PC .","An exemplary operation of the system shown in  will now be described.","First, the procedures from the actual downloading of the VRML contents via the Internet to the provision of a multi-user environment in which a plurality of users share one virtual space will be described with reference to .","As indicated by L in , the homepage of the website providing the VRML contents is first browsed by using the WWW browser. Then, the users of the client PC  and the client PC  download the VRML contents made up of the VRML 2.0 file and the script program (e.g., Java script program) for realizing autonomic behavior in the VRML space, as indicated by L in . Of course, the VRML contents provided on the CD-ROM  may be read by the CD-ROM drive .","Next, as shown in , in the client PC  and the client PC , the VRML browser interprets and executes the VRML 2.0 file, which is downloaded and temporarily stored on the local HDD  of the respectively client PCs. Moreover, the client PC  and the client PC  inquire the WLS  for the URL of the pet shared server  on the basis of the VSCP (virtual society server client protocol), as indicated by L in . In this case, the WLS  notifies the client PC  and the client PC  of the URL of the pet shared server  with reference to a shared server URL management table stored on an HDD as indicated by L in .","Using the URL, the client PC  and the client PC  are connected to the pet shared server , as shown in . Consequently, transmission of a shared message related to the position and motion of a shared 3D (three-dimensional) object is carried out via the pet shared server , as indicated by L in , and transfer of the shared message is carried out, as indicated by L in , thus realizing a multi-user environment.","In the multi-user environment thus realized, when log-in from the client PC , that is, from the user, is made, the pet shared server  transmits the data of the virtual shared world to the client PC  and transfers the data of the virtual life object in the AO server .","On receiving the whole data of the virtual shared world and the data of the object in the virtual shared world, the client PC  records these data onto the internal hard disk or stores them into the internal memory, and then displays the virtual shared world on the monitor screen on the basis of the recorded data.","In the case where the user enters his\/her own avatar  and the electronic pet  into the virtual shared world at the client PC , a call message is transmitted to the AO server  via the pet shared server . The AO server  executes parameter updating processing based on the access event.","As another access event is executed, the operation message is transmitted to the AO server , and the parameter is updated every time an operation event is generated.","For example, every time the parameter is updated, it is transferred to the client PC  and the other client PC  which shares the virtual space, by multi-cast processing of the pet shared server .","In the client PC , the script program in which the processing procedure for controlling the autonomic behavior of the electronic pet is described is executed on the basis of the parameter sent back thereto. The value of the field of each node constituting the three-dimensional object for expressing the electronic pet of the VRML file is changed. The electronic pet on which the changed value of the field is reflected is rendered and displayed on the main window of the VRML browser on the screen of the image display section of the client PC .","The same processing as that of the client PC  is executed in the other client PC  which shares the virtual world. Thus, the electronic pet on which the value of the field changed in accordance with the movement of the electronic pet is reflected is rendered and also displayed on the main window of the VRML browser on the image display section of the other client PC .","For the details of the above-described connection procedure, the Japanese Publication of Unexamined Patent Application No. Hei9-81781 should be referred to.","In the present embodiment, the information providing medium for providing the computer program for executing the above-described processing includes a network transmission medium such as the Internet or a satellite as well as an information recording medium such as a magnetic disk or a CD-ROM."],"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND ART","DISCLOSURE OF THE INVENTION","BEST MODE FOR CARRYING OUT THE INVENTION"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIGS. 18A and 18B"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIGS. 27A and 27B"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 31"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 33"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 34"},{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 35"},{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 36"},{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 37"},{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 38"},{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 39"},{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 40"},{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 41"},{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 42"},{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 43"},{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 44"},{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 45"},{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 46"},{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 47"},{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 48"},{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 49"},{"@attributes":{"id":"p-0074","num":"0073"},"figref":["FIG. 50","FIG. 49"]},{"@attributes":{"id":"p-0075","num":"0074"},"figref":["FIG. 51","FIG. 49"]},{"@attributes":{"id":"p-0076","num":"0075"},"figref":["FIG. 52","FIG. 49"]},{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 53"}]},"DETDESC":[{},{}]}
