---
title: Virtual prosthetic limb system
abstract: A system for configuring a prosthetic limb for use by a living being is provided. The system includes an electronic control unit (ECU) configured to receive a control signal generated in response to a command from the living being and to generate a plurality of virtual bodies on a display including members of a virtual prosthetic limb and at least one virtual object. The ECU is further configured to control movement of at least one member of the virtual limb responsive to the control signal, to determine a contact force between first and second virtual bodies of the plurality of virtual bodies upon engagement between the first and second bodies caused by movement of one of the one member of the virtual limb and the at least one virtual object and to adjust a position of at least one of the first and second bodies responsive to the contact force.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09271660&OS=09271660&RS=09271660
owner: 
number: 09271660
owner_city: 
owner_country: 
publication_date: 20110701
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["This application claims priority to U.S. Provisional Patent Application No. 61\/398,794 filed Jul. 2, 2010, the entire disclosure of which is incorporated herein by reference.","1. Field of the Invention","This invention relates to a virtual prosthetic limb system that can be used to design and evaluate new prosthetic limbs, serve as a platform for control algorithm design and sensor\/signal selection, and train patients to use a given prosthetic limb.","2. Discussion of Related Art","Many individuals in the United States today are living with upper extremity amputations. These amputations most frequently result from trauma and affect young persons, especially for the soldiers wounded in Afghanistan or Iraq. A robotic arm with a fully functioning hand will significantly improve the quality of life for these amputees. Designing a robotic prosthetic arm with an optimal control mechanism that matches an individual's needs with minimum training time requires a lot of time, effort and money. A virtual prosthetic limb system that can simulate any possible design of prosthetic limb in a realistic way will significantly reduce the time, effort and money in developing a new robotic prosthetic limb, will reduce the actual training time for amputees to use the real prosthetic limbs and provide a platform for experimentation with any of a variety of possible control methods. Some research has been reported on creation of a virtual prosthetic arm system. In one such project, Orsborn, et al, (Orsborn, Amy et al, \u201cSimulation of an Above-Elbow Myoelectric Prosthetic Arm for Development of an Implanted Myoelectric Control System\u201d, (http:\/\/www.phys.cwru.edu\/undergrad\/Senior%20Projects\/SeniorProjectPosters\/AmyOrsbornPOSTER.pdf)), developed a basic prosthetic model and the framework required for a multi-component simulator using myoelectric signals. In another related project reported by J. Burck, M. J. Zeher, R. Armiger and J. D. Beaty, entitled \u201cDeveloping the World's Most Advanced Prosthetic Arm Using Model-Based Design\u201d, and published by The Math Works in & , in 2009, they developed a Virtual Integration Environment (VIE) that included a limb simulation environment, constructed using MathWorks tools and Model-Based Design. The VIE allowed users to control the virtual prosthetic arm with different control inputs, e.g., switches or joysticks.","To develop a more advanced virtual prosthetic limb system, the present inventors adopted advanced technologies to, among other things (i) simulate the interactions between and among the virtual prosthetic limb and virtual objects; and (ii) to build a more realistic visualization system; and (iii) to \u201cconnect\u201d the virtual prosthetic limb and the residual limb of a patient in two directions, namely, to change the position of the virtual prosthetic limb according to the movement of the residual arm of a patient, and to provide feedback to the patient according to the events in the virtual space. The inventive virtual prosthetic limb system can be used for designing and evaluating new prosthetic arms, as a platform for control algorithm design and sensor\/signal selection, patient training, and recording limb movements and control signals during clinical investigations for performance analysis. For example, as a design platform it could be used in studying how to connect a robotic prosthetic arm into the nervous system and\/or into the brain (see for example the publications \u201cExtraction algorithms for cortical control of arm prosthetics\u201d by Schwartz, A B, Taylor, D M, Tillery, S I, 11, 701-707 (2001); \u201cCortical control of a prosthetic arm for self-feeding\u201d by Velliste M, Perel S, Spalding M C, Whitford A S, Schwartz A B, , Vol 453 19 Jun. 2008 doi:10.1038; and \u201cUsing virtual reality to test the feasibility of controlling an upper limb FES system directly from multiunit activity in the motor cortex\u201d by Taylor D M, Schwartz A B, In Proceedings of the 6th Annual IFESS Conference: 2001 Jun. 16-20; Cleveland. 2001:132-134, all of which are incorporated by reference hereinto).","The inventors herein have recognized a need for a virtual prosthetic limb system that will minimize and\/or eliminate one or more of the above-identified deficiencies.","The present invention provides a system for configuring a prosthetic limb for use by a living being.","A system in accordance with one embodiment of the invention includes an electronic control unit configured to receive a control signal generated in response to a command from the living being. The control unit is further configured to generate a plurality of virtual bodies on a display including a plurality of members of a virtual prosthetic limb (e.g., fingers, a forearm, etc.) and at least one virtual object. The control unit is further configured to control movement of at least a first member of the plurality of members of the virtual prosthetic limb responsive to the control signal. The control unit is further configured to determine a contact force between first and second virtual bodies of the plurality of virtual bodies upon engagement between the first and second virtual bodies caused by movement of one of the at least a first member of the virtual prosthetic limb and the at least one virtual object. The first and second virtual bodies may comprise, for example, two members of the virtual prosthetic limb, two virtual objects, or a member of the virtual prosthetic limb and a virtual object. The control unit is further configured to adjust a position of at least one of the first and second virtual bodies responsive to the contact force.","A system in accordance with another embodiment of the invention includes an electronic control unit configured to receive a control signal generated in response to a command from the living being. The control signal may be generated through a control interface such as a switch or other conventional input\/output device or through one or more sensors, such as an electrode placed in contact with tissue in the living being. The electronic control unit may be further configured to generate a virtual prosthetic limb and a virtual object on a display and to control movement of the virtual prosthetic limb responsive to the control signal (e.g., to sense movement of the residual limb and move the \u201cattached\u201d virtual prosthetic limb accordingly). The electronic control unit may be further configured to determine a contact force between the virtual prosthetic limb and the virtual object upon engagement of the virtual object by the virtual prosthetic limb. The electronic control unit may be further configured to adjust a position of at least one of the virtual prosthetic limb and the virtual object responsive to the contact force. In another embodiment of the invention, the electronic control unit may be further configured to generate a feedback signal to the living being responsive to engagement of the virtual object by the virtual prosthetic limb or another event in the virtual space.","A system in accordance with the present invention represents an improvement over conventional systems because it can efficiently simulate various designs for prosthetic limbs in a realistic manner. As a result, the system improves the design and evaluation of prosthetic limbs and associated control algorithms and sensor\/signal selection and also provides more efficient training for patients.","These and other advantages of this invention will become apparent to one skilled in the art from the following detailed description and the accompanying drawings illustrating features of this invention by way of example.","Referring now to the drawings wherein like reference numerals are used to identify identical components in the various views,  illustrates a system  for configuring a prosthetic limb for use by a patient  or other living being in accordance with one embodiment of the present invention. It should be understood that the term \u201climb\u201d may refer to an arm, a leg, or any portion of the foregoing. System  may include a display , a recording system , a control interface , and an electronic control unit  in accordance with the present invention.","Display  is provided to display virtual bodies including a virtual prosthetic limb  and its constituent members (e.g., in the case of an arm, limb  may include an elbow joint, forearm, wrist joint, palm, fingers and finger joints) and one or more virtual objects  in order to allow patients  and others to visualize movement of the limb  in response to commands from the patient  and interactions with objects  and between objects  resulting from such movement. Display  may comprise a three-dimensional display. Display  may be a stereoscopic display or an auto-stereoscopic display. In one embodiment of the system stereoscopic 3D visualization of the virtual limb  and objects  is achieved by using the Alienware OptX\u2122 AW2310 23-inch 3D Full HD Widescreen Monitor and NVIDIA GeForce 3D Vision Kit (both are available from Dell Computer, 1 Dell Way Round Rock, Tex.) with a 3D graphics card PNY NVIDIA Quadro FX 580 (available from Amazon.com). ECU  uses the application programming interface OpenGL originally developed by Silicon Graphics, Inc. to generate images of the limb  and objects  for left and right eyes and uses display  to achieve the stereoscopic 3D visualization. The virtual prosthetic limb  and virtual objects  will be rendered in real-time on display . The stereoscopic 3D display  will provide realistic visual sense and will improve the usage of system .","Recording system  is provided to record the positions of the virtual limb  and objects  as well as the set of commands from the subject\/patient , at any given set of times. A set of images of the prosthetic limb  and virtual objects  can be regenerated using the recorded positions of the virtual limb  and virtual objects , for subsequent replaying on display  and\/or computations or other outputs of ECU  for use in, for example, performance analysis. System  may comprise conventional fixed or portable media (e.g., a hard drive, compact disc, digital video disc, flash drive, etc.) and may be located locally or remotely and accessed over a wired or wireless telecommunications network. System  is configured to save and replay all movements of limb  and objects  for performance analysis.","Control interface  is provided to allow transfer of commands from the patient  to ECU  and, in some embodiments, to provide feedback from system  to patient . Interface  may generate control signals reflecting the patient's body movement so as to \u201cattach\u201d the patient's body to the virtual limb  by reflecting movement of the patient's body in the virtual space (e.g., a virtual arm with shoulder joint can be \u201cattached\u201d to the patient's shoulder and any movements (translations and\/or rotations) of the patient's shoulder will move the virtual arm in real-time accordingly). Interface  may also generate control signals used to control movements of the joints that link the segments of the virtual limb (e.g., the elbow joint linking the upper arm and forearm, the wrist joint linking the forearm and hand, and knuckle joints linking finger segments).","In one embodiment of the invention, interface  includes a pair of cameras , , and a plurality of markers  that are affixed to the patient . The patient's body movements, e.g., shoulder movements, are measured in real-time with cameras , , mounted above the patient's shoulder. Cameras , , may be about 400 mm apart with camera  pointing vertically downward and camera  pointing downward at about thirty (30) degrees relative to camera . Three reflective tracking markers  forming a right triangle may be fixed on a 50 mm by 100 mm aluminum sheet (5 mm thick) coated with non-reflective paint. The sheet is mounted on the patient's shoulder in such a way that two of the markers  are in anterior-posterior direction (along the 50 mm side) and two markers  are in lateral-medial direction (along the 100 mm side). To avoid interference from extraneous light (e.g., room light), two infrared LED light sources (not shown) may be used to illuminate the tracking markers  and infrared filters ,  may be used on the cameras , . The real-time tracking marker images captured by the two cameras ,  are processed by ECU  to obtain the patient's shoulder translations and rotations. The processing by triangulation using video cameras and markers is well known in the field (see for example the publication \u201cRepeatability of gait data using a functional hip joint centre and a mean helical knee axis,\u201d by Besier T. F., Sturnieks D. L., Alderson J. A. and Lloyd D. G., 36 (2003), pp. 1159-1168, which is incorporated by reference hereinto). This information is used to determine the virtual prosthetic proximal end location and orientation. It should be understood that the above-described approach can also be used to capture the movements of other body parts, such as the residual limb of an above-elbow amputee. In an alternative embodiment, control interface  may include a position sensor (not shown) affixed to the patient  and a tracking device such as the electromagnetic motion analysis system sold commercially under the trademark \u201cFASTRAK\u201d by Polhemus Inc. of Colchester, Vt. The sensors may be placed on the trunk and residual limb and 3D position coordinates and angles (roll, pitch, and yawl) are measured and transmitted to ECU . The sensor and tracking device may be connected by wires or cables or may exchange data wirelessly through, for example, radiofrequency or infrared transmitters and receivers or the like.","As noted hereinabove, control interface  may also include means for receiving signals used to control joints in limb . In one embodiment of the invention, interface  may include switches  operated by the patient's feet used to control the movements of the joints and various segments connected by those joints in the virtual limb . The patient  can use the switches  to move an individual segment, e.g., rotate the forearm to pour water into a cup, or to move segments in a group, e.g., move hand to a given point in a 3D space, or control fingers to grab or release an object. In an alternative embodiment, interface  includes one or more sensors, such as an accelerometer, attached to patient . In yet another alternative embodiment, one or more electrodes  may be attached to tissue (e.g., muscle or nerve tissue) in the residual limb of the patient. Electrodes  are used to obtain myoelectric signals from a patient and the signals are used to control the movements of the segments of limb . It should be appreciated that a variety of control signals besides those arising from switches  or electromyography (EMG) signals detected by sensors  can be used in the present invention. For example, EEG and direct electrode recording from within the brain, or any combination of the above, are all considered to be within the scope of the present invention.","ECU  provides a means for generating virtual bodies on display  including members of limb  and objects  and for controlling movement of limb  and its members. ECU  further provides a means for determining a contact force between various virtual bodies (e.g. between members of limb , between limb  and an object  or between two objects ) upon engagement between the virtual bodies resulting from movement of one or more members of limb  or one or more virtual objects . ECU  further provides a means for adjusting a position of at least one of the virtual bodies responsive to the contact force. ECU  may comprise a programmable microprocessor or microcontroller or may comprise an application specific integrated circuit (ASIC). ECU  may include a central processing unit (CPU) and an input\/output (I\/O) interface through which ECU  may receive a plurality of input signals including signals generated by control interface  and generate a plurality of output signals including those used to control and\/or provide data to display  and recording system .","In accordance with one embodiment of the present invention, ECU  is configured with appropriate programming instructions or code (i.e., software) to perform several steps in a method for configuring a prosthetic limb  in accordance with the present invention. The method may include the step of receiving one or more control signals generated in response to a command from the patient . These control signals may be generated by control interface  as described hereinabove. The method may continue with the steps of generating a virtual prosthetic limb  (and individual members of limb ) and one or more virtual objects  on display  and controlling movement of members of limb  responsive to the control signals. ECU  may generate limb  and objects  using the application programming interface OpenGL originally developed by Silicon Graphics, Inc. ECU  calculates the translations and rotations of each segment of limb  based on the control signals from interface  and the movements of objects  according to the interaction between limb  and objects  or between multiple objects . The movement of limb  is therefore controlled by the real-time input signals from interface . The patient's body movements will be directly reflected in the virtual prosthetic limb . The joint movements will be controlled in the way as designed, e.g., each individual joint or group of joints will be controlled to realize pre-defined movements.","Referring to , limb  and objects  are defined to include one or more surfaces ,  and a plurality of contact elements ,  having a predetermined relationship (e.g. location) to a given surface , . Each contact element ,  further includes one or more contact nodes , . Contact elements ,  with contact nodes ,  will be used to cover all surfaces ,  that may contact with other surfaces ,  for both virtual limb  and virtual objects . In one embodiment of the invention, three (3) node triangle contact elements are used to represent the surfaces in three-dimensional space. It should be appreciated, however, that different approaches with respect to the specific choice of contact elements ,  can be adopted. For example, in two alternative embodiments, four and eight node quadrilateral contact elements, respectively, are used. It should be appreciated that a variety of shapes and number of nodes ,  for the contact elements ,  should be considered to be within the scope of the present invention. Referring to , two alternative embodiments of contact elements are shown that may reduce computational overhead. In , a linear or line contact element  is placed in the center of a virtual cylindrical object  (which may comprise a portion of a virtual limb  for example) In , a linear or line contact element  is placed in the center of a virtual cylindrical-conical object  (which may comprise a portion of a virtual limb  such as a finger or section of a finger for example). In another alternative embodiment, a single node contact element with a shape of a point is placed in the center of a virtual spherical object and with contact tolerance equal to the radius of the spherical object. This embodiment is useful for significantly reducing cost (in terms of processing time and memory) in processing the interactions between the spherical object and virtual limb  or other virtual objects . The contact elements ,  may have complete or continuous coverage over a given surface or only a portion thereof. Alternatively, the contact elements ,  may not have complete or continuous coverage over a given surface or portion thereof. In such embodiments, contact elements composed of circles, triangles or other shapes (e.g. a point) are relatively sparsely distributed over contact surfaces.","Each contact element ,  may be placed beneath a given surface ,  with an offset (i.e., depth) equal to the contact tolerance of the element , . In one embodiment, it is assumed that the contact elements ,  do not move relative to the original contact surfaces ,  when the contact surfaces ,  deform. It should be appreciated that in the scope of the present invention a variety of tolerances may be used, including a variety of tolerances below a given surface, above a given surface and on a given surface and that, in some embodiments the contact elements ,  can move relative to the original contact surfaces ,  when the contact surfaces deform. In the embodiment of the contact element  shown in , the contact tolerance is equal to the fixed radius r. In , the tolerance varies along the length of element  and is equal to the varying radius r at that point. In the illustrated embodiment, rand rare the radii at the top and bottom of the virtual object , respectively.","The inventive method may further include the step of determining a contact force between a pair of virtual bodies upon engagement between the virtual bodies caused by movement of limb  or one or more virtual objects . In one embodiment of the invention, the contact force between virtual prosthetic limb  (or at least a member thereof) and a virtual object  is determined. Alternatively, it should be understood that the contact force between multiple members of limb  could be determined (e.g., one finger engaging another finger) or between multiple virtual objects could be determined (e.g., a baseball bat swung by the virtual limb hitting a ball). Each contact element ,  has its own contact properties, including contact tolerance, stiffness, maximum allowed force, minimum separation force and coefficient of friction. In one embodiment of the invention, it is assumed that contact properties do not vary within a contact element , . In an alternative embodiment of the invention, contact properties may vary within an element , . The concept of the contact tolerance is introduced by the inventors to effectively process interactions between the virtual bodies such as limb  and virtual objects . In general, the contact tolerance of a contact element ,  is the distance beneath the surface ,  (or relative to the surface , ) at which the contact element ,  is located. With this approach, contact force and displacement of a contact node ,  or contact point can be easily calculated (see description below). For contact stiffness, an elastic force-displacement relationship is used. In some embodiments, a linear elastic relationship F=k\u00d7d, where K is a constant, is used although non-linear relationships may find application in several embodiments in which surfaces have large deformations. In an alternative embodiment of the invention where contact properties vary within an element , , stiffness has a more complicated force-displacement relationship, e.g., different loading-unloading-reloading curves, including creep and stress relaxation, so that more complicated interactions between the virtual limb  and virtual objects  can be simulated (such as squeezing toothpaste).","Referring again to , two surfaces Sand Sare shown with contact points Pand Pbefore contact is established () and after contact is established (). In the illustrated embodiment, contact point Pcomprises contact node . It should be understood, however, that either of contact points Pand Pmay comprise a contact node or another point on surface Sand S, respectively. Tand Tare the contact tolerances of contact points Pand P, respectively. D is the distance between Pand P. In the illustrated embodiment, contact elements ,  are disposed beneath the surfaces ,  at predetermined offsets (i.e., the depths below the surfaces) equal to the contact tolerances for the points P, P, respectively. ECU  may be configured, in determining the contact force, to detect a condition in which a distance between a point Pon a first contact element  of limb  and a point Pon a contact element  of object  is less than a sum of a tolerance of point Pand of a tolerance of point Pand, upon detecting the condition, calculate the contact force responsive to one of the predetermined set of characteristics associated with the contact nodes ,  of the contact elements ,  of limb  and object . In particular, when the distance D between a contact point Pon a surface Sand a contact point Pon another surface Sbecomes less than the summation of the contact tolerances T, Tassociated with the two contact points P, P, contact force may be calculated based on the stiffnesses of the contact points P, P. When two surfaces (e.g. surfaces , ) contact each other, two cases are considered: (1) a contact point P, Pfrom one of the two surfaces ,  contacts a contact point P, Pon the other surface ,  that is within the perimeter of a contact element , ; and (2) a contact point P, Pon one surface ,  contacts a point P, Pon the other surface ,  where one or more contact elements ,  touch. The contact properties of a contact point P, Pfor these two cases are defined as (1) the same as the contact element , , when the contact point P, Pis within the perimeter of the contact element , ; and (2) the same as the contact element ,  or the angular weighted average of all contact elements ,  that touch the point P, P. ECU  may be further configured, in determining the contact force, to determine a direction of the contact force responsive to a position of the points P, Pon the contact elements , . In particular, the direction of the contact force may be defined as the line segment between the two contact points P, P. Friction force associated with the contact force may also be calculated. The contact force, F, is a known function of displacement, and this function is referred to as \u201cstiffness\u201d, denoted by F(d). The contact force is calculated in the following way: the contact force applied on the contact points Pand Pis\n\n()=()\n\nwhere dis the displacement of the contact point Pand F(d) is a known function of d, representing the contact force on contact point Pdue to the displacement d, and the dand F(d) are the displacement and force associated with contact point P. The phrase \u201cdisplacement of a contact point\u201d stands for the normal (i.e., orthogonal) deformation of a contact surface in an area represented by the contact point. The contact forces on each of the two surfaces (which are equal in magnitude and opposite in direction) can be computed as follows. Referring to , by equating d+dto the difference between the summation, T+T, of the contact tolerances of the two contact points P, P, respectively, and the distance, D, between the two contact points P, P, the contact force is obtained by solving the two equations\n\n()=() and \n\nIn most embodiments of the invention, the contact force and displacement of each contact point P, Pare calculated independently of any other contact point P, P. In an alternative embodiment of the invention, the contact force and displacement of a contact point P, Pdepend on the contact force and displacement of one or more other contact points P, P. In yet further alternative embodiments, computational modeling, e.g., the finite element method, boundary element method and\/or finite difference method, are used to calculate the contact forces and deformations of the segments of the virtual limb  and the virtual objects , due to the surface forces (e.g., contact and friction forces) and body forces (e.g., gravity and electromagnetic forces) in the virtual space. Such computational methods are well known in the art; see for example the excellent three books:\n\n","The inventive method may continue with the step of adjusting a position of at least one of the virtual bodies such as prosthetic limb  or virtual object  responsive to the determined contact force. The movements of a virtual movable object  will be determined by the resultant of all forces (and moment of forces) applied on the object  and the mass (and moment of inertia) of the object , as well as the environment simulated, e.g., on the earth, in a weightless space, under water or a hypothetical environment. If a contacting virtual object  is fixed in space, e.g., a virtual workbench, the movements of the virtual limb  or a movable object  will be limited when they contact such a virtual object . A virtual object  with limited movements may become a movable object when the resultant of forces applied on the object  is higher than a threshold level, e.g., picking an apple from a tree. ECU  may be further configured, in adjusting the position of a virtual body such as the virtual prosthetic limb  and\/or virtual object , to limit an amount of an adjustment from a prior position to an amount that is less than a predetermined minimum distance between the contact points P, Pon the virtual bodies. To prevent penetration between two contact elements , , the movements of the virtual limb  and virtual objects  will be achieved by adopting multiple small incremental movements, so that the maximum displacement of all (any) contact elements ,  will be smaller than the minimum contact tolerance of all contact elements ,  before any contact is established. The increments may be reduced further to ensure the maximum displacement will be smaller than the minimum distance between any pair of contact points P, Pafter any contact is established. Surface contact may be checked from both sides of two contact surfaces, i.e., to ensure that contact points P, Pon one contact surface ,  do not penetrate any contact element ,  on another contact surface ,  and vice versa. In yet further embodiments, surface contact is checked asymmetrically; that is, it is only ensured that contact points P, Pon one contact surface ,  do not penetrate any contact element ,  on another contact surface , , but the reverse is not checked. For example, this would be equivalent to ensuring that the contact point Pon the virtual limb  does not penetrate any contact element  on the contact surfaces  of the virtual objects , but that the contact surfaces  of the virtual objects  are not checked to ensure no penetration onto the virtual limb . In one embodiment of the invention, deformations of the virtual limb  and virtual objects  due to contact forces are not reflected by ECU  on display . In an alternative embodiment of the invention, the deformations are reflected on display .","ECU  may be further configured to generate virtual force sensors at various locations on virtual prosthetic limb  (e.g., on the fingers) and to transmit an output signal through an interface to the patient  or others responsive to a contact force determined at the location of a given virtual force sensor. The interface may be a part of, or separate from, interface . Further, although ECU  is used to process signals from the virtual sensors and\/or provide output signals to the interface, it should be understood that the interface could employ a separate electronic control unit to process the signals and provide output signals to the interface such that signal processing for the interface can be designed independent of the other tasks handled by ECU . Forces sensed at the virtual sensor locations may be fed back to the patient  or others with visual and\/or audio output signals. For example, the contact forces calculated by ECU  at the location with virtual force sensors may be displayed on display  or a separate display. ECU  may also generate sounds through an audio interface that mimics expected sounds from the interaction of limb  and objects  (e.g., a hand hitting a table, objects contacting one another, or a can being crushed by a hand). Forces sensed at the virtual sensor, locations may also be fed back to patient  through electro-mechanical feedback mechanisms. For example, ECU  may generate a signal through an electrode coupled to the patient's residual limb, to simulate the interaction in virtual space (e.g., contact of the limb and other objects, inertia force due to limb and object motions, etc.). The output signal may have a predetermined characteristic if the contact force exceeds a predetermined threshold. For example, when the maximum force at a given location becomes higher than a preset level, a visual and\/or audio warning signal may be provided.","In yet another alternative embodiment, the virtual limb  or limbs are used to simulate a person's natural limb or limbs instead of a prosthetic limb. In this embodiment, tracking markers are placed on segments of the natural limb(s) to capture the real-time movements of the interested segments and the captured real-time data is used to control the movements of the virtual limb(s).","While the invention has been shown and described with reference to one or more particular embodiments thereof, it will be understood by those of skill in the art that various changes and modifications can be made without departing from the spirit and scope of the invention."],"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF EMBODIMENTS OF THE INVENTION"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIGS. 2A-B"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIGS. 3A-B"}]},"DETDESC":[{},{}]}
