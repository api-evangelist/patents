---
title: Methods and apparatus for enabling bus connectivity over a data network
abstract: A method and system for interconnecting peripherals, processor nodes, and hardware devices to a data network to produce a network bus providing OS functionality for managing hardware devices connected to the network bus involves defining a network bus driver at each of the processor nodes that couples hardware device drivers to a network hardware abstraction layer of the processor node. The network bus can be constructed to account for the hot-swappable nature of the hardware devices using a device monitoring function, and plug and play functionality for adding and, removing device driver instances. The network bus can be used to provide a distributed processing system by defining a shared memory space at each processor node. Distributed memory pages are provided with bus-network-wide unique memory addresses, and a distributed memory manager is added to ensure consistency of the distributed memory pages, and to provide a library of functions for user mode applications.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07694312&OS=07694312&RS=07694312
owner: Pleora Technologies Inc.
number: 07694312
owner_city: Kanata
owner_country: CA
publication_date: 20040910
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","MICROFICHE APPENDIX","TECHNICAL FIELD","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT","EXAMPLES OF OS IMPLEMENTATIONS"],"p":["This is the first application filed for the present invention.","Not Applicable.","The invention relates in general to data communications and computing, and in particular to methods and apparatus that permits bus connectivity over a data network so that standard network interface cards serve as bus controllers, in order to create a network bus for sharing device connections, management tasks, memory, input\/output operations and processing capabilities among network-connected nodes.","The coupling of processor nodes by data networks to permit the cooperation and sharing of data and resources has long been of recognized value. Distributed processing systems have been developed to harness processing capabilities of many individual processor nodes. Typically, distributed processing systems define each processor node as a client or a server, which runs corresponding software. Distributed applications, i.e. application that run on processor nodes of a distributed processing system, control peripheral devices, and communicate information to remote applications. It is the nature of distributed applications that details of the remote applications are required by the local application. The client\/server approach has well known limitations respecting scalability, i.e., as the number of client processor nodes is increased to satisfy increasing processing load, the server (the center of communications and control) becomes a bottleneck of the system. In order to produce a scalable system, the server's communications bandwidth and processing capability must scale with the number of processor clients.","Remote invocation methods which permit applications to share resources over a network, such as Remote Procedure Call (RPC), have also been proposed. Numerous distributed operating systems (OSs) have been developed to take advantage of the features associated with remote invocation methods to permit direct processor node-to-processor node communication. This method does not inherently rely on a client server architecture, which permits designers to overcome the scalability limitations associated with client server-based systems. Distributed operating systems such as Amoeba, and Cajo rely on RPC.","Because of complexity inherent in some distributed operating systems, such as Amoeba, the costs of developing distributed applications are much higher that when creating comparable non-distributed applications. To date all distributed operating systems rely on an RPC-like communication structure.","The RPC protocol was designed to be implemented on a processor node with general purpose capabilities, and as such is not easily implemented on network-enabled hardware devices that do not have processors.","Both of these prior art methods also require the software developer to specify how each application is to be distributed and how the data is to be shared. A method for building distributed applications as easily as non-distributed applications, is therefore desirable.","Additionally, with a proliferation of network-enabled hardware devices, such as cameras, that do not include native processors, there is a need for processorless devices to be able to communicate with a processor node. In some applications of distributed processing systems, it is cost effective to deploy hardware devices that do not have native processors for certain tasks. Hardware devices, such as cameras, produce volumes of data, and it is cost effective to distribute the processing of this data between a number of different processor nodes. A method is therefore needed to enable communications with processorless hardware devices that is also consistent with communications between multiple processor nodes. A scalable distributed architecture is needed to support the processing of this data.","Accordingly it is clear that there remains a need for improved communications between processor nodes and hardware devices.","It is therefore an object of the invention to provide an improved communications framework that permits processor nodes to selectively leverage operating system capabilities within a network environment.","In accordance with one aspect of the invention a method for enabling bus connectivity to hardware devices interconnected by a data network is provided, where the hardware devices include at least one processor node coupled to the data network by network interface circuitry (NIC). The method involves installing a network bus driver on each processor node connected by the network bus, registering a driver of each NIC with the respective network bus driver, to permit the network bus driver to effect communications with the hardware devices via the data network, and instantiating device drivers on each of the at least one processor node for controlling respective hardware devices through the network bus driver. The network bus driver, NIC driver and device drivers define a bus abstraction layer that permit a network bus to be defined over the data network. The NIC assumes functionality of a bus controller.","Instantiating the device drivers may accommodate a hot-swappable nature of the hardware devices. For example, instantiating the device drivers may involve instantiating drivers for base driver objects that may be added to or removed from the network while the processor node remains connected to the data network, providing a device monitoring function that uses network messaging to detect the connection and disconnection of the hardware devices from the data network, and providing a plug and play functionality for adding and deleting device driver instances in response to the connection and disconnection of the hardware devices.","The method may further provide a device and service connector in communication with the network bus driver at each of the processor nodes, the device and service connector embodied as a plug and play kernel mode device driver. The device and service connector publishes a user mode access interface that permits device and service drivers to access the network bus driver through the device and service connector. The user mode access interface defines a list of functions for an I\/O manager of an operating system of the processor node.","The method may further permit a peripheral device or special application of one of the processor nodes to be bus-connected to the networked devices by providing a user mode software device gateway that uses the published access, interface to permit a driver of the peripheral device (or a special service) to access the network bus driver, or by providing a kernel mode plug and play driver for accessing the network bus driver.","The method may further enable memory sharing and distributed processing among processor nodes connected to the network bus, in which case each of the processor nodes having a same operating system is provided with a distributed memory manager that cooperates with the operating system to define and maintain a shared memory space of distributed memory pages that is consistent with those of the other processor nodes to define a pool of shared objects. The distributed memory manager uses an addressing scheme for uniquely identifying each of the distributed memory pages. And the method further provides a distributed memory driver of the distributed memory manager for effecting communications over the network bus to update pages of the shared memory space in order to maintain the consistency of the data when changes are made at one of the processor nodes.","The addressing scheme is enforced by providing program instructions for each processing unit to maintain a code space of addressable program instructions, the code space definable by a list of operations loaded and unloaded by the processing unit, and by providing program instructions for communicating any change in the code space to the corresponding code spaces of processing units of the same distributed process by adding code space change operations to the operation list.","Preferably the distributed memory manager provided further enables a notification system for permitting shared objects to exchange data.","The method may further permit bus-to-bus bridges for enhanced security, link aggregation for increasing a bandwidth of the network bus, and high availability applications that provide redundancy of processing units.","Further objects of the invention involve a system for embodying the method.","It should be noted that throughout the appended drawings, like features are identified by like reference numerals.","In accordance with the invention a system and method are provided for interconnecting peripherals, processor nodes, and hardware devices via a network bus. The invention provides a network bus that leverages operating system (OS) functionality of processor nodes for managing the hardware devices, and for providing an alternative mechanism for accessing the hardware devices at the processor nodes that avoids delays associated with legacy network subsystems of current OSs. A network bus driver is provided at each of the processor nodes that couples hardware device drivers (and other, preferably plug and play, drivers) to a network hardware abstraction layer of the processor node. By using plug and play hardware device drivers the network bus can be constructed to account for the hot-swappable nature of the hardware devices. Peripherals of the processor nodes can be connected to the network bus by providing a software device gateway between a driver of the peripheral (or other user mode software providing a special service) and the network bus abstraction layer. The sharing of control of certain hardware devices can be enabled\/facilitated by providing a kernel mode shared memory space at each of the processor nodes, the kernel mode shared memory space providing mirror images of parts of the kernel mode of each of the other processor nodes, to permit the sharing of context information related to the hardware devices.","The network bus can be used to produce a distributed processing system by defining a shared user mode memory space at each processor node. Distributed memory pages belonging to a distributed process are provided with network-wide unique memory addresses, and a distributed memory manager is added to ensure consistency of the distributed memory pages, and to provide a library of functions for user mode applications. Mutually exclusive locking of application-defined data structures permit consistency of data. The maintenance of a consistent code space for each processing unit may be provided using an operation list that provides a complete list of the order in which user mode library files are loaded and unloaded from memory into the code space.",{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 1","b":["10","10","12","14"]},"The data network  may be of any known configuration, including those that include multiple subnetworks. As is typical of current data networks, data network  consists of a plurality of interconnected hubs, routers, and\/or switches  (two illustrated) that are interconnected, and connected to the nodes  by data transmission links. The data network , for example may permit transmission of Internet Protocol (IP) packets between the nodes . In accordance with the present invention, the data network  supports a network bus .","Any end-point hardware connected to the data network  (i.e. not a dedicated hub, switch or router ) by network interface equipment (e.g. network interface cards or chips or circuitry (collectively referred to as NICs )) is a node . It is a considerable advantage of the present invention that commonly used NICs (such as commercially available Ethernet cards and integrated circuits) are acceptable, and the data network  can likewise consist of common used network equipment. The present invention permits standard NICs  to serve as bus controllers for the network bus . Each node  will contain a network bus driver to control the interface with the NIC. The network bus driver can be software or hardware based on the resources available on the node .","Each node  is a hardware device , and may further include one or more hardware devices  as respective subsystems. Each hardware device  for the data network  has a respective address and serves as a respective message termination point of the data network . Each message termination point is effected by a NIC  of a node  on which the hardware device  resides, but any hardware device  may or may not be a node . A node  with functional units known as sub-devices provides network bus access to the sub-devices via the node's NIC .","For example, a Node , and a Node  are illustrated. Node  includes a NIC , and two sub-devices (-A, -B) which are hard disk , temperature sensor  and power sensor , which are each hardware devices . Each of the hardware devices  of Node  is a message termination point, and includes a control unit  that provides limited message processing capabilities to effect commands issued to the corresponding hardware (hard disk, sensor, etc.).","Node  has no subdevice. Accordingly Node  includes a NIC  that is dedicated to the (camera) hardware device , which includes an image acquisition unit , for controlling an image sensor . Typically a NIC  used in a node  like Nodes , is a network interface chip, rather than a network interface card. The functioning of such hardware devices  are known in the art and will not be further elaborated.","A node  with processing capability is known as a processor node . Processor nodes  are adapted to access any hardware device  connected to the network bus . Nodes  that are not processor nodes  can be slave devices to processor nodes , as will be well understood by those skilled in the art. As illustrated, typical Processor Nodes , include one (or more) processors  (such as central processing units), memory , and a plurality of peripheral devices, all of which are interconnected by a processor node bus . Processor Node  includes the following peripherals: a universal serial bus (USB) port , and a sound card ; and Processor Node  includes a serial port  peripheral. In accordance with an aspect of the invention, peripheral devices of processor nodes, can be made accessible to the network bus .",{"@attributes":{"id":"p-0067","num":"0066"},"figref":["FIG. 2","FIG. 1","FIG. 2","FIG. 2"],"b":["0","1","30","0","1","40","20","10","40","20"]},"In accordance with some embodiments of the invention, the network bus  provides transparent connections between all hardware devices  enabling the sharing of their respective capabilities. Capabilities include, but are not limited to, processing capacity, memory (including kernel and user space memory), and input and output (I\/O) devices such as a display, a camera, a mouse and a keyboard.","In order to enable the processor nodes  to share user mode memory, a distributed memory driver  is resident on the processor nodes ,. The distributed memory driver  is a part of a distributed memory manager adapted to maintain a pool of distributed memory pages that can be accessed by all of the processor nodes , as is further described below. Accordingly, different threads of one or more user mode applications can be executed by threads of a processing unit at remote processor nodes .","As the term is used herein, a distributed process is a process running on a set of processing units. The address space of the distributed process is separated into three parts that consist of the code space, private data and shared data. Each processing unit of the distributed process is started using the same start image. Each processing unit of a distributed process has an address space which indexes memory such that identical functions of different processing units are located at the same memory address. The addressing space of each processing unit includes a private data space and its main distributed memory pool. The distributed process is associated with an object created in the main distributed memory pool.","The user mode application can start a processing unit and directly give it a task to execute, in which case the processing unit is in a RUNNING state. A processor node  may also be configured to ensure a predefined number of IDLE (i.e. not RUNNING) processing units remain available. The number of processing units to keep available may be configured based CPU usage, for example.","In accordance with some embodiments of this invention, the selection of processing units as needed by a distributed process is made by device drivers and libraries, hidden from the applications themselves. From a running application's perspective the threads that are dispatched remotely are indistinguishable from threads that are dispatched locally. Consequently, application developers, do not need to be concerned with the details of the distributed system. The developer need only determine whether the process may be distributed, without defining a selection algorithm.","As illustrated in , threads of processing units (such as Processing Units ,) may be distributed across the processors  on a thread-by-thread basis. Threads of Processing Unit  are being run on the processors  of Processor Nodes ,, while Processing Unit  remains idle on Processor Node . The processing units can be controlled by any type of operating system (OS) that supports multiple threads, but the threads of a single distributed process must typically be run on processing units controlled by OSs of the same type.","In some embodiments, it is desirable to permit the processing load associated with controlling shared hardware devices  to be shared between processor nodes . If multiple processor nodes  are to serve as masters of a single (slave) hardware device , it may be helpful to share a kernel memory space between the processor nodes  using the distributed memory driver , as is further explained below. The distributed memory space is mapped such that a part of the kernel memory space of each processor node  is mirrored at the other processor nodes  and the user memory space is mapped with non-overlapping address spaces on all processor nodes .","In some embodiments, a reach of the network bus  is extended to include peripheral devices of the processor nodes  (such as the USB port , sound card , and serial bus ). As will be explained further below, the inclusion of peripheral devices on the network bus  is enabled by adding software device gateways , which act as intermediaries between native drivers of the peripheral devices, and the network bus . In order to permit remote processor nodes  to control the peripheral devices, corresponding device drivers  are provided. Specifically both the Processor Nodes , are provisioned with serial port device drivers, sound card device drivers, and USB port device drivers.","It will be appreciated that the processor nodes  that have a processor node bus  that connects its processor  to the peripheral is able to access the peripheral via either the processor node bus  or the network bus , in accordance with one embodiment of the invention. Alternatively, in accordance with another embodiment of the invention, only one of the two buses may be used.","Enabling Bus Connectivity","One aspect of the invention permits processorless hardware devices  to be seen as a physical resource available to all the processor nodes present on the network bus . By configuring the hardware devices  to communicate as if over a bus, for example, a printer can be shared at the network bus level removing the need for network stack processing, which is a burden at high data throughput rates. As will be appreciated by those skilled in the art, typical OSs provide a network subsystem that permits communications according to a predefined protocol that involves numerous checks and intermediate steps that can be dispensed with when communicating with known devices if each device is associated with a respective kernel mode driver, as is further explained below.","If each of the hardware devices  is presented to the operating system as a native device, all security features the OS provides work normally over the network device. For instance, if a mass storage device is connected to processor node  via the network bus , an OS file management subsystem manages the file system and all features provided by the OS are supported.","The bus connectivity shown in FIGS. , is achieved in part using a bus architecture, an overview of which is shown in . Control to this architecture is a network bus driver , an exemplary embodiment of which is described in detail below. The network bus driver  controls the exchange of network messages through a bus adapter driver , which directly controls the NIC . A plurality of plug and play device drivers communicate with the network bus driver  (including device drivers , distributed memory driver , and a software device gateway \u2032). The plug and play device drivers are instantiated for a base OS network subsystem support to allow communications with standard data networking equipment and processes.","Each device driver  controls a corresponding hardware device . The device drivers  are designed to respect the operating system driver architecture enabling full interconnection with the operating system. Consequently the underlying data network connection is hidden the from the overlaying software layers.","In accordance with the illustrated embodiment, each plug and play driver provides one or more end points for communications over the data network , and is therefore associated with one or more sub-device numbers. Sub-device numbers are formed by concatenating a hardware (e.g. MAC) address of the NIC  with a locally unique 16 bit unsigned integer.","It is an advantage of the present invention that it can be deployed over Ethernet protocol networks. Ethernet cards are relatively inexpensive NICs, and Ethernet hubs, switches and routers are also relatively inexpensive. Furthermore, to facilitate access and control of hardware devices  that have limited or no general purpose processing capabilities, the network bus drivers  of respective processor nodes  run relatively low complexity standard protocols such as Ethernet, IP, user datagram protocol (UDP), transport control protocol (TCP), etc.","The network bus driver  maintains an up-to-date list of available hardware devices  in cooperation with a device monitoring function  (DMF) provided in part by the network bus driver , and in part by a device enumerator described further below. The device monitoring function updates a list of available hardware devices  and accesses a plug and play functionality which generally involves detecting newly connected hardware devices, and detecting disconnected (non-responsive) hardware devices. In accordance with the present invention the former is provided by a device enumerator DMF , whereas the latter is provided by the network bus driver  DMF , although it will be appreciated by those of skill in the art that the DMF may be provided cooperatively by both or exclusively by either, and can be effected in numerous ways. Where ever changes in the list of enumerated devices are detected, there must be a link to the plug and play functionality, which is a part of some OSs, but not a part of others. Part of the plug and play functionality involves instantiating device drivers for added hardware devices, and removing the device drivers of disconnected hardware devices.","The device monitoring function uses the presence or absence of network messaging to detect the connection and disconnection of the hardware devices. For example, a combination of message processing techniques and timers for each of the hardware devices  may be used. A timer for a hardware device  is reset every time a packet is received from the hardware device . If the timer reaches a predefined maximum value, the network bus driver  directs the bus adapter driver  to issue a message to the hardware device , in order to verify that the hardware device  remains in an operational state. If no reply to the message is received within an established period of time, the hardware device  is declared \u201cdropped\u201d to the plug and play functionality. Alternatively or additionally, each hardware device could broadcast a \u201ckeep alive\u201d packet before expiry of its timer expires.","The network bus driver  registers three types of plug and play device drivers: slave device drivers, bridge device drivers and a master device drivers. Each slave device driver  (one shown: Device Driver ) is associated with a respective slave hardware device . At least one bridge entity is required (such as the bus adapter driver ) and is associated with (at least one) NIC . There are different plug and play drivers that are of a master device driver type, including software device gateways (such as Software Device Gateway  \u2032), the distributed memory driver , a device and service connector , a legacy network manager .","The bus adapter driver  is a bridge plug and play driver that is associated with instance settings. The network bus driver  registers these instance settings (including network (IP) addresses and a list of hardware device identifiers) that the network bus driver  passes to the OS when loading, or locating, associated device drivers. Accordingly the network bus driver  can switch the NICs and bus adapter driver  used to support the network bus, for example in the event of a failure of the currently used NIC. In this manner, plug and play drivers, such as the legacy network manager, distributed memory driver, device and service connector , etc. can be loaded as the network bus driver  is loaded.","The network bus driver  accesses the NIC via the bus adapter driver . The bus adapter driver  may be a standard off-the-shelf NIC driver, and is loaded as such except that rather than registering with the operating system as a network provider, it registers with the network bus driver . Thereafter the bus adapter driver  forwards received messages to the network bus driver .","The bus adapter driver  further performs two functions, hardware abstraction for the NIC  and bus contention. The first function makes the bus adapter driver  responsible for electrical connection to the particular NIC . The second function is a known medium access control layer function shared between all bus adapter drivers  (and software of the network interface chips) connected to, the data network  to avoid and correct collisions of data.","The bus adapter driver  may be configured to receive or ignore all messages transmitted over the data network ; or it may participate in one or more multicast groups. In addition it may be adapted to change or add a MAC address to the NIC , for example to support link aggregation, as is further described below, or to permit definition of multiple software abstractions of the network bus , as described above.","The legacy network manager  is a native OS driver that connects the bus adapter driver  to the network subsystem  of the OS in the prior art. In the present embodiment the legacy network manager  is retained to facilitate previously existing functionality that relied on the network subsystem. The legacy network manager  is connected to the network bus driver . Unlike the device drivers , it is not associated with a specific hardware device . It provides a network subsystem interface, which performs protocol stack processing in a predefined manner. The OS network interface does not provide the flexibility for using different communications protocols for different messages, and invokes a procedure for handling the messages, which becomes a limitation at high messaging rates. Accordingly, one advantage of the instant embodiment of the invention is that numerous direct interfaces are provided between the user mode applications, and a software abstraction layer of the network bus . Each device driver  is associated with a respective user mode library file that permits installation and configuration of the device driver . The device and service connector library  publishes a general purpose access interface, all of which circumvents the legacy network manager  and the network subsystem .","A sub-device number assigned to the legacy network manager  is that of the network bus driver . The legacy network manager  has no specific setting. All setup information comes from the network subsystem . Because the legacy network manager  is included in the system of the illustrated embodiment, the network itself can also be used for standard network communications that are unrelated to the network bus . That is, the data network  and the NIC  are used as in the prior art and in parallel support the network bus . This minimizes the impact of the network bus architecture on existing applications processor nodes .","Each software device gateway  executes a native process for connecting a local device or service to the network bus . The software device gateway  may be instantiated as user mode program instructions (Software Device Gateway  \u2033) that use the access interface provided by the device and service connector , or may be a kernel mode plug and play driver (Software Device Gateway  \u2032). Communications between remote hardware devices  and a peripheral or service of the processor node  running the software device gateway  is enabled by the software device gateway .","The device and service connector  is a plug and play driver and is associated with a library of user mode program instructions. The library publishes an access interface permitting user mode applications to access the network bus driver  using the device and service connector . The access interface is functionality that permits any number of devices and services with access to the network bus driver . For example the access interface simplifies development of program instructions for instantiating software device gateways (e.g. Software Device Gateway ) and other special applications (e.g. special application ).","Device Enumeration","A device enumerator is also provided to facilitate identification of hardware devices  that are added to the data network , in a manner described below. The device enumerator is embodied as a device enumeration service  which is provided by user mode program instructions that use the access interface.","One device and service connector  runs on, each network bus, and is connected to the corresponding network bus driver . The device and service connector  has the same subs-device number as the network bus driver . The device and service connector  forwards notifications output by the connected services and devices and also sends a notification if the device and service connector  must disconnect, to permit the connected service to disconnect.","In alternate embodiments, a device enumerator is provided as kernel mode program instructions adjunct to the network bus driver , for example, but in the illustrated embodiment, it is embodied as the device enumeration service  provided by a server application consisting of user mode program instructions that use the access interface provided by the device and service connector  for messaging over the network bus . The device enumeration service  is assigned a sub-device number by the device and service connector  at connection time. The sub-device number is a concatenation of the device and service connector  identifier (which is the same as the network bus driver  identifier) and a locally unique 16 bit unsigned integer.","In accordance with one embodiment, the device enumeration service  detects newly added hardware devices  by sending broadcast messages requesting that all hardware devices , including those accessing the network bus  through software device gateways , return respective auto-identification messages that include device information. The device enumeration service  is prompted to begin the enumeration process, for example, at the request of the user mode application, or upon startup. These broadcast messages contain an identifier of the device enumeration service , the NIC's (IP) address and implementation-specific information, as required.","When the device enumerator service  receives an auto-identification message (either in response to a request, or initially sent by the hardware device upon connection) that is not associated with an enumerated device, a new hardware device  is declared. The device enumerator notifies the plug and play functionality of the addition, which then creates an associated base device object for the hardware device . The base device implements a network bus driver-programming interface, for example, as described below in relation to .","If the data network  (like most IP-based packet networks) does not provide guaranteed delivery of messages, validation and retransmission procedures are applied to communications between the device drivers , as required. If the risk of compounded errors associated with a single packet is unacceptable, additional mechanisms (checksums encryption, or higher-level protocols) known in the art can be leveraged. To account for the possibility of lost identification requests, the device enumeration service  sends the broadcast messages multiple times (typically three times), with a predefined delay between each send.","Replies to these identification requests are not broadcast, but rather are sent only to the NIC  (of the processor node  executing the device enumeration service ) and received at the network bus driver , where they are directed to the device and service connector , which conveys a content of each message to the device enumeration service . It should be noted that each hardware device , and each software device gateway connected to the network bus  responds to the identification request, but that a processor node  does not itself respond. The device information includes a network identifier of the responding hardware device , the hardware device identifier, and any other implementation-specific information, as required. The hardware device identifier is a binary string used by the OS and indicates a device type of the responding hardware device .","If the device enumerator  discovers a new hardware device , it notifies a plug and play management function, providing the binary device identification string. In some embodiments, the device enumeration service  supports a filter in the form of a list of hardware devices  and\/or network (IP) addresses and\/or device types to ignore when detecting devices.","Auto-Description on Connection","In accordance with certain embodiments, hardware devices , publish their capabilities on connection. This is done, for example, in a message following the hardware device's connection, or in response to a request for further auto-description. Upon connection, the hardware device  discloses its capabilities in a prescribed format. While in some embodiments this self-description process is not required, it is a preferred aspect of embodiments wherein it is desirable to permit addition of new nodes  with a minimum of revision of the existing processor nodes .","One format that can be employed is extensible markup language (XML), which is a language that can be used to specify an hardware device's capabilities. Unique hardware device features may be defined to permit specification of settings of the hardware device, and environmental and operating conditions, etc. to all members of the distributed architecture. XML is also easily extended to permit the network bus  to support new hardware device types, for example using a generic device driver augmented with feature specifications respecting the particular hardware device .","Beginning with , the remainder of the figures illustrating the invention are made assuming that the data network  conforms with an Ethernet protocol, and accordingly that the NICs are Ethernet cards, the hardware devices  are Ethernet devices, and the network bus driver  is an Ethernet bus driver; although this is not necessary for the application of the invention.",{"@attributes":{"id":"p-0105","num":"0104"},"figref":"FIG. 4","b":["50","100","100"]},"The Ethernet device driver preferably accommodates the \u201chot swappable\u201d nature of every Ethernet device. The Ethernet bus driver helps in this task by notifying other plug and play drivers of Ethernet device connection, and disconnection, and of communication errors. The methods of the IBaseDriver  permit the plug and play drivers to send local notifications to the Ethernet bus driver (such as an ADD_DEVICE message used to instantiate another IBaseDriver ), and to the other plug and play drivers of the software abstraction of the Ethernet bus. In this manner the Ethernet device drivers can be added or removed in response to changes in connected nodes of the Ethernet.","The plug and play drivers use a SubscribeLocalNotification method to subscribe to certain kinds of local notifications (according to a type of notification, a sub-device number, etc.), and may unsubscribe using an UnsubscribeLocalNotification method. In a like manner, the plug and play drivers may subscribe and unsubscribe to messages of a given kind (packet type, protocol, sender, etc.) sent over the Ethernet bus using SubscribePacket and UnsubscribePacket methods.","As explained above, there are three types of IBaseDrivers , and each is associated with a corresponding interface. The IMasterBaseDriver  is an interface for plug and play drivers such as the distributed memory driver , legacy network manager , device and service connector , and any software device gateways . IMasterBaseDriver interfaces include EntityInformation and EthernetInformation attributes, and instances of these interfaces provide corresponding plug and play drivers with methods for sending Ethernet packets, sending IP packets, and sending UDP packets over the Ethernet bus. The master type plug and play drivers are therefore able to effect connections over the Ethernet of a plurality of types, as required.","An IBridgeBaseDriver  interface provides methods for registering another packet forwarder (such as the bus adapter driver , or an aggregator described below), and for forwarding an Ethernet packet received from the Ethernet bus to the plug and play drivers that have subscribed to the packet. The ability to register new packet forwarders enables failover procedures that permit the switching of the Ethernet card while the system is running in a manner that does not impact the local processor node  or the distributed system.","An ISlaveBaseDriver  interface provides methods that permit device drivers  to send Ethernet (or UDP) packets to the (slave) hardware device  over the Ethernet bus. ISlaveBaseDriver  interfaces only provide for communications with the corresponding slave hardware device , whereas the methods of the IMasterBaseDriver  permit transmission of messages to any hardware device  or multicast group thereof.","The Ethernet bus driver is further adapted to invoke packet forwarder interface, packet receiver interface, and notification receiver interface. An IPacketForwarder interface  is created by the bus adapter driver before registration with the Ethernet bus driver. The IPacketForwarder interface  defines a method called by the Ethernet bus driver upon receipt of a message at the Ethernet card, identified by the bus adapter driver .","An IPacketReceiver interface  is instantiated by a plug and play driver prior to subscription to a packet delivery service. The IPacketReceiver interface  provides methods for processing Ethernet,. IP, and UDP packets that are addressed to the Ethernet bus driver. The packet processing methods provide the content of the packets to the Ethernet bus driver to be distributed to all subscribers.","An INotificationReceiver interface  is instantiated by one of the plug and play drivers immediately before subscribing to a packet delivery service that specifies which packets are to be received by the plug and play driver. The plug and play drivers may instantiate as many IPacketReceiver interfaces  and INotificationReceiver interfaces  as needed. A respective IPacketReceiver interface  is required for each protocol stack used to process a packet that is subscribed to, and one or more INotificationReceiver interfaces  are created for each IPacketReceiver interface  to support the subscriptions.","Enabling Memory Distribution","The sharing of memory by the processor nodes  is part of what enables distributed processing. This is enabled by concurrently running a distributed memory manager on each of the processor nodes .","Applications built using the network bus framework are, easier to develop and support than applications developed using prior art systems, because the programmer only needs to understand how to develop multithreaded applications, not distributed applications, in order to create viable distributed applications that run on distributed processors connected to a network bus in accordance with the invention.","For example, if a distributed system graphical user interface (GUI) is limited to a single processor node, only a computational part of an application requires modification for distributed procession, which can be accomplished by taking advantage of the ability of threads to spawn threads from a common thread pool effectively supplied by the processor nodes  connected by the network bus . Accordingly, this bus architecture does not require application programmers to define the control should shift from one processor node to another, which is a significant advantage over the prior art.","As illustrated in , the processor node  is further adapted to invoke and execute processes, both native  and distributed. A native process  is one that is not distributed. A distributed process is one that can connect to one or more processing units , such as Processing Unit . As illustrated, native processes may access device drivers , and may communicate over the data network  using the legacy network manager  and network subsystem . Typically, distributed processes will not access the legacy network manager  or network subsystem , but use a distributed memory manager , which is described in detail below, with reference to .","The distributed memory manager  is defined by user mode and kernel mode program instructions for maintaining a memory space, and is assigned a sub-device number by the network bus driver  when the distributed memory manager  connects to the network bus driver  on start up. The sub-device number is concatenated from the network bus driver identifier and a locally-unique 16-bit unsigned integer, and is compatible with Ethernet device identifiers.","The distributed memory manager  has three components: the distributed memory driver , a distributed memory library  and the distributed memory service . The distributed memory driver  is defined by kernel mode program instructions principally for managing a page table, and passing notifications from kernel mode to user mode, and vice versa. The distributed memory library  includes user mode program instructions called by distributed processes, and the distributed memory service , for example, permits connections to the network bus driver  required to support a shared memory pool.",{"@attributes":{"id":"p-0120","num":"0119"},"figref":"FIG. 5","b":["30","68","62","30","0","1","2","68","0","1"]},"Each processing unit  includes a user mode memory space  which is a virtual addressing space, that includes (an address of) one or more memory pages that contain a global shared memory pool . The processing unit  also includes private memory spaces and a shared kernel mode memory space which is managed independently. As each processing unit  includes pointers to the same memory pages, the content of the global shared memory pool  is the same for each of the processing units . The global shared memory pool  includes a software mechanism for organizing the processing units  that are IDLE to permit efficient selection of an IDLE processing unit , as required.","If a processing unit  is IDLE, like processing unit  residing on processor node , it has not connected to a distributed process , and has no cause to create any additional shared memory pools. A code space , which is an addressing space for executable code, user mode library files, etc. of the processing unit  is also empty except for the start image program instructions as no user mode application program code has been provided to the processing unit .","A processing unit  in a RUNNING state has connected to a distributed process , and has made a separate copy of the executable code executed by the processing unit  in its code space . Each processing unit  connected to a common distributed process  will have a respective copy of the same executable code, but a change to one of these (via a load library\/unload library operation) does not induce and automatic change in that of the other copies, because a separate copy is made.","Each processing unit  in a RUNNING state also has a main shared memory pool  including a page for managing and storing data associated with the distributed process  to which it belongs. It is through the main shared memory page that the processing unit  can access the distributed process  to which it is connected.","As illustrated, the processing unit  may create and connect to additional shared memory pools  (e.g., shared memory pools A,B), which may be created, for example, to expand a memory address space of the processing unit , or to provide sharing of data between different distributed processes , for example. Shared memory pool A may have been created to provide a separate memory pool for a certain set of threads, and is shared by all members of the pool's multicast group (including processor nodes ,). Shared memory pool B is associated with a different multicast group and includes all processor nodes  with processing units  connected to either distributed process  or process .","Some slave hardware devices  cannot be controlled by multiple masters concurrently without running the risk of causing the hardware device  to fail, unless an efficient access protocol that prevents conflicts is implemented. In the illustrated embodiment, the Ethernet device drivers  communicate with other device drivers  associated with the same Ethernet device. The device drivers  always communicate with the associated Ethernet devices and other participating plug and play drivers using the services provided by the distributed memory manager . This is accomplished through the kernel distributed memory space.","In order to effect the sharing of memory required to permit shared control over slave hardware devices, a kernel shared memory pool is effected by mirroring a part of the kernel memory space (i.e. a shared kernel memory space) of each processor unit  at each of the other processor units . The distributed memory service  () begins at start-up of the processor node , by creating a shared kernel memory pool. The device drivers  use the kernel shared memory pool to store shared state information and the connection context.","FIGS. , schematically illustrate a class structure diagram of the distributed memory library , in accordance with an embodiment of the invention. A shared memory pool is identified by an identifier of a multicast group with which the distributed memory pool is associated. Accordingly there is at most one shared memory pool per multicast group.","In order to facilitate the development of efficient distributed processing systems, in addition to the distribution of memory, messaging between distributed copies of the same distributed object may be desired. In accordance with the illustrated embodiment, notifications provide this ability. A notification can be sent to one processor node  (for example a processor node  where a particular processing unit  resides) or to all processor nodes  sharing the specific memory pool. When all processor nodes  must be notified, the notification is sent using the multicast group associated with the memory pool.","In accordance with the illustrated embodiment, notifications sent from a source distributed memory manager  to a destination distributed memory manager  always include the following data:\n\n","If, upon receipt of a notification, the destination distributed memory manager  finds that a notification fails the integrity test (e.g. the checksum fails), the notification is discarded. Accordingly, notifications may not be delivered in this way, or when packets are discarded by network routers, for example. The hardware devices may accordingly implement timeout management and acknowledgement protocols well known in the art, as required.","The distributed memory manager  provides notifications on announcement (i.e. at the beginning of a distributed process), and notifications when the distributed memory manager  stops. When the distributed memory manager  stops, each processing unit , and the distributed memory service , must disconnect.","Each notification is associated with a specific (destination) object in the shared memory pool. The notification message includes the memory address of the destination object. Each shared memory pool contains a Pool object , the class structure of which is shown in . The Pool  is a root object containing information needed to manage the shared memory pool. A special fixed object address is reserved for the Pool object  at each of the distributed memory managers. This special fixed address is necessary since the address range of the main shared memory pool is not known before connection.","The Pool  is a NotificationReceiver object , and as such includes an operator for deleting itself, and two SendNotification methods (i.e. SendNotificationToGroup and SendNotificationToOne methods). As shown in , the NotificationReceiver  is an object  and inherits the delete operator from the object . Similarly the Pool  object inherits new and delete operators. Each NotificationReceiver  has methods for sending notifications to either a particular Ethernet device, or to a predefined multicast group, and further a method for processing a notification. The notifications common to all NotificationReceivers include notifications of the following types: DELETE, DELETE_ACK, and INVALID_OBJECT.  illustrate the processing of notifications of these kinds and schematically shows the delete operator.","The Pool  object defines methods for allocating and releasing memory, locking and unlocking pages or the pool, for processing page faults, and for retrieving private pages. The processing of notifications of the following types: ALREADY_EXIST, CREATED, DEAD, DEAD_ACK, ENTRY, ENTRY_ACK, EXIT, EXIT_ACK, PAGE_LOCK, PAGE_LOCK_ACK, PAGE_REQUEST, PAGE_RESCUE, PAGE_RESCUE_ACK, PAGE_UPDATE, and the local notifications received from KernelPool objects  shown in , via the DriverInterface  of the distributed memory manager , as well as the methods of the Pool object , are schematically shown in FIGS. -,,,.","A Mutex object  is also a NotificationReceiver , and a member of Mutex (mMutex) belongs to the Pool . This means that the Mutex can lock and unlock the Pool object . The Mutex  includes methods for locking and unlocking data structures defined by user mode applications on one or more of the pages, and a ProcessNotification method for receiving LOCK, LOCK_ACK, and RELEASED notifications, as is described below in relation to .","The illustrated embodiment of the distributed memory driver is provisioned with software objects to define Kernel pools. A KernelPool object  is a member of the IMasterBaseDriver interface  created for the distributed memory driver . The KernelPool object  includes a SendLocalNotification method for sending local notifications to the other plug and play drivers connected to the software abstraction of the Ethernet bus, including ALLOCATE, LOCK, PAGE_FAULT, RELEASE and UNLOCK notifications, and respective ACKs for each) Methods are also provided for incrementing and decrementing a reference count, which maintains an counter of the number of instances of the distributed memory manager  that are concurrently running, as each of these is effectively connected to the KernelPool . The KernelPool  further has a method for handling page update requests from the other plug and play drivers. The KernelPool  also has a KernelPoolConnection  which is an object that permits device drivers to connect to the KernelPpool for allocating and releasing memory, and locking and unlocking pages. The KernelPoolConnection  is created by the KernelPool, and retains a pointer to the KernelPool.","The KernelPool object  is associated with a NotificationQueue  which permits the queuing of local notifications received from the other plug and play drivers along with notifications received from the Ethernet bus driver. Each NotificationQueue  effects a first-in first-out (FIFO) buffer for managing notifications addressed to a respective Pool  of a processing unit. The NotificationQueue  is an INotificationReceiver  and as such receives the local notifications.","The KernelPool object  is an IKernelPool interface , and as such inherits methods for allocating and releasing memory of the kernel distributed memory space, and locking and unlocking pages on behalf of respective plug and play drivers, and sending notifications, and subscribing to notifications on behalf of respective plug and play drivers. The methods for allocating and releasing memory, and locking and unlocking pages permit the use of the DriverInterface  to pass the corresponding local notifications up to the respective Pool object  where they are subsequently processed. The methods for subscribing to and sending notifications permit a peripheral device (through its software device gateway ) to exchange notifications with remote distributed memory managers.","A KernelObject  is a primitive of the kernel mode objects, and is instantiated by the IKernelPool interface, but retains a pointer (mIKPool) to its creator. A KernelNotificationReceiver object  is similar to the NotificationReceiver object  of the user mode.",{"@attributes":{"id":"p-0141","num":"0147"},"figref":"FIG. 8","b":"122"},"In step , the distributed memory manager  sends a DELETE notification to the multicast group associated with the object. A thread running the delete operator then sets a timeout timer (for a predetermined time that may be related to the expected round trip messaging time of the Ethernet, and expected processing time of the notifications) and goes to sleep (step ).","The thread may be awoken either by a DELETE_ACK notification report (i.e. a report issued by a thread running a ProcessNotification method upon receipt of a DELETE_ACK notification), or by a timeout of the timer. If the timeout expires before a report is registered, timeout management handling is applied, before the thread returns to step . An example of timeout management handling is described below with reference to .","If a ProcessNotification method returns a (success) report, all of the members have acknowledged the DELETE (i.e. step  of ), in which case the distributed memory manager  deletes the local context of the NotificationReceiver object  (step ), and then deletes the NotificationReceiver  itself (step ).",{"@attributes":{"id":"p-0145","num":"0151"},"figref":"FIG. 9","b":["122","120","128","65","1020","1022","1024"]},"If the notification is of a DELETE_ACK type, the processor node  receiving the acknowledgement (ACK) is the one that sent the DELETE notification. Accordingly the ACK is added to a local list (step ). The local list is then used (step ) to determine if all of the processor nodes  in the multicast group associated with the addressed object have issued corresponding DELETE_ACK notifications. If all of the processor nodes  of the group have acknowledged the deletion, the processor node  and the notification wakes up a sleeping thread (executing the delete operator of ), indicating that the deletion of the object has succeeded (step ). Otherwise the object waits for a next DELETE_ACK notification, and the ProcessNotification is complete.","Finally, if the notification is of an INVALID_OBJECT type, the responding processor node  could not associate a previous notification sent from the NotificationReceiver with the addressed object, and accordingly the sleeping thread (whatever method it was executing) is awoken to generate a report of a fatal error (step ). A fatal error prompts the process running the sleeping thread to abort, terminating all threads and releasing all processing units. It will be noted that while this is a logical possibility for any thread that goes to sleep awaiting a ProcessNotification report, the remainder of the examples in this application will not include such fatal error report handling.","Pool Creation",{"@attributes":{"id":"p-0148","num":"0154"},"figref":"FIG. 10","b":["1040","42","74","68","75","42","1042","1044"]},"The thread of the user mode application connects to the distributed memory driver (step ) via DriverInterface  program instructions (shown in ). The DriverInterface  defines a set of functions accepted by the I\/O manager of the operating system, and includes a ClosePool function, a CreatePool function, and functions for sending local notifications, receiving and sending notifications, and updating pages. The thread issues the CreatePool function command to the distributed memory driver  (step ) to reserve local resources for a shared memory pool including a range of memory addresses for an address space (including the user memory space ) of the shared memory pool, a sub-device number for the Pool, etc., in accordance with parameters specified by the application to prepare for the instantiation of the Pool . If the distributed memory driver  reports an error when attempting to reserve the resources, the attempt fails, and the thread reports an error.","If the distributed memory driver  successfully allocates resources to the new pool, it is determined in step  whether or not the application requires a new Pool object. An application creating an object may require that the Pool be a new object because there is no shared memory pool with sufficient available address space to join, or because a main shared memory pool is required, for example.","If the shared memory pool must be new, a SendNotification function of the Pool object (which has yet to be instantiated) is invoked to send a CREATED notification to the members of the multicast group (step ). The CREATED notification is sent to determine whether the multicast group is already associated with an existing shared memory pool, or the multicast group is available for the user mode application's purposes. The CREATED notification includes relevant pool settings to permit identification of the particular shared memory pool, which has been created, but which has not yet been provided with its main Pool object.","Once the CREATED notification is sent, the thread sets a timer, and goes to sleep (step ). If any member of the group returns an ALREADY_EXIST notification, then the multicast group is already in use by another distributed process, and a ProcessNotification thread reports success to awake the sleeping thread. The thread consequently requests the ClosePool function over a connection to the DriverInterface  to effect the release of the reserved resources (step ), and the process returns to step  to randomly select another group.","If the timer times out before any ALREADY_EXIST notification is received, the native thread repeats steps , . If the timer times out again and no ALREADY_EXIST notification is received, it is assumed that the multicast group is not being used, and accordingly the Pool object is instantiated, a first page of the Pool is created (step ), and the attempt to create a new Pool succeeds.","If, in step  it is found that a new pool is not required, in step , it is determined whether or not the application specified a particular multicast group to be joined. If a shared memory pool of a particular group is to be joined, the SendNotification method is invoked to send an ENTRY notification to the members of the group (step ). The thread then sets the timer and goes to sleep (step ). If the timer times out a first time, the steps of sending the ENTRY notification and going to sleep are repeated. If the timer times out a second time, or an error report awakes the sleeping thread, the ClosePool function is issued to the distributed memory driver (step ), which releases the resources for the shared memory pool, and the attempt to join has failed.","If a report of success from a ProcessNotification method is received before the timer expires (the second time), positive ENTRY_ACK notifications have been received from all of the members of the group which already has a Pool object, and the join attempt succeeds.","If it is found in step  that the application has not specified that any particular group be joined, the group was selected randomly, and the current members of the group are not known to the distributed memory manager . In step  the SendNotificationToGroup method is invoked to send an ENTRY notification to the group, the notification includes pool settings, so that the members of the group can verify that the pool settings are correct (See ).","The thread then sets the timer and waits for a first ENTRY_ACK notification (step ). If a first ENTRY_ACK notification is received, it identifies the members of the group and the process returns to step  to verify that all members are notified of the entry of the member into the shared memory pool. If the thread is awoken by a first timeout, the steps  and  are repeated. If the timeout recurs, the distributed memory manager  is presumed to be the first and only current member of the group, and accordingly the Pool object is instantiated, the first page is created (step ), and the attempt to join or create is successful. If the thread is awoken to an error report the thread advances to step .","Pool Notifications","When either a notification or a local notification is received that identifies a Pool, the ProcessNotification method or the ProcessLocalNotification method of the Pool object is called. Depending on a type of the received notification (determined in step ), the notification is handled according to one of the processes shown in FIGS. ,- are performed.","If the local notification is of either an ALLOCATE type or a RELEASE type, the method invokes the corresponding AllocateMemory, or ReleaseMemory method (step ), which prompts the application of the distributed memory service  for managing the kernel memory space, to effect (if possible) a change in the usage of the kernel mode memory space at the request of the corresponding plug and play driver. At the successful completion of the AllocateMemory\/ReleaseMemory method, the SendLocalNotification method of the corresponding KernelPool is invoked to send the ALLOCATE_MEMORY_ACK or the RELEASE_MEMORY_ACK (step ). The allocation and release of memory is requested by one of the plug and play drivers to request part of the shared kernel memory space.","The ALLOCATE and RELEASE local notifications are sent to the distributed memory driver by a plug and play driver that uses the kernel memory space to share context information regarding respective Ethernet devices. More specifically, the requesting plug and play driver calls the AllocateMemory or ReleaseMemory method of the IKernelPool object, which formulates the ALLOCATE\/RELEASE local notification, pushes the local notification into the NotificationQueue , and waits for an acknowledgement. The ALLOCATE\/RELEASE remains in the NotificationQueue  until the local notification is popped by the user mode Pool. When the local notification is popped, it prompts the execution of the AllocateMemory or the ReleaseMemory method of the Pool (step ).","The ALLOCATE_MEMORY_ACK and the RELEASE_MEMORY_ACK -notifications are only used for managing kernel mode memory spaces. Other similar methods are used by plug and play drivers to lock and unlock pages. The ALLOCATE_MEMORY_ACK, RELEASE_MEMORY_ACK as well as the LOCK_ACK, PAGE_FAULT_ACK and UNLOCK_ACK message types are reserved for local notifications. Accordingly, if one of these types of messages or any other unexpected notification types are received, they are received in error and disregarded without any action taken in response.","If the notification is of an ALREADY_EXIST type, the sleeping-thread is awoken (step ) with a success report (indicating that the thread must attempt to create another pool as shown in ). It is also clear from the foregoing discussion of  that if the notification is of a CREATED type, the Pool object is already created for the multicast group, and accordingly the ALREADY_EXIST notification is issued (step ) in reply.","In order to notify the distributed instances of the shared memory pool, numerous different types of notifications are defined. When a Pool is joined or created, as shown in , CREATED and ENTRY messages are sent, the latter being acknowledged. Before a processing unit severs a connection to the Pool, it issues an EXIT notification to the group and waits for EXIT_ACKs in reply. However, in certain cases the EXIT may not be sent before the connection is severed or the processing unit fails. In such a case it is up to any remaining member of the group to identify the failed (\u201cdead\u201d) member. When a member of the group's processing unit of the Pool is determined to be dead, the determining member issues a DEAD notification to the other members of the multicast group of the Pool. These DEAD notifications are acknowledged with DEAD_ACKs by the other remaining members, as shown in the timeout handling of .","Upon receipt of one of a DEAD_ACK or an EXIT_ACK, the ProcessNotification method adds the respective ACK to a local list of ACKs (step ) relating to the Pool (stored in a private part of the shared memory space of the Pool). It is subsequently determined (step ) whether the local list now includes ACKs from all of the members of the multicast group of the Pool. If the list is complete, in step , the waiting thread is awoken to the report of a success. In either case the processing of the notification is successfully completed.","Upon receipt of a PAGE_LOCK_ACK (see in ) or an ENTRY_ACK (step ), it is determined whether the ACK is positive or negative. If the ACK is positive, the process advances to step . Otherwise, in step , the waiting thread is awoken to a report of an error.","Upon receipt of an ENTRY notification, it is determined whether pool settings included in the ENTRY notification match with those of the Pool locally. If the pool settings do not match, the thread processing the notification sends a negative ENTRY_ACK notification in reply (step ). Otherwise the pool settings match, and a local member list that identifies the members connected to the Pool, is updated to add the joining member (step ) before returning a positive ENTRY_ACK notification in reply (step ). If the NotificationReceiver process is processing a DEAD or EXIT notification, it applies steps , and  as shown, but the updating of the local member list involves deleting the identified member(s).","The plug and play drivers issue LOCK or UNLOCK local notifications in order to write shared state information and the connection context on pages of the shared kernel memory space. Such notifications are passed via the distributed memory driver  to a user mode of the distributed memory manager , which effects the locking or unlocking of the page (step ), and issues a corresponding local notification ACK (via the distributed memory driver ), in response (step ).","The ProcessNotification handling of PAGE_REQUEST notifications is described further below with reference to . The handling PAGE_LOCK notifications follows the process described below in relation to . The ProcessLocalNotification handling of PAGE_FAULT type local notifications are described further below with reference to , respectively.","Handling a PAGE_RESCUE_ACK type notification involves adding the ACK to the local list (step ), and inspecting content of the ACT to determine whether the page data is empty (step ). If the page data is not empty, an old copy of the page is included in the message. This copy is saved (step ) if it is more recent than a currently stored version of the page so when the list is complete the most recent version of the page is stored and identified as readable, to complete the page rescue operation shown as a part of the RetrievePage method of the Pool (see ). Regardless of whether the PAGE_RESCUE_ACK is empty, the thread processing the PAGE_RESCUE_ACK determines whether the local list is now complete (step ). If the list is not complete, the thread reports success, otherwise the thread wakes the sleeping thread to report the success of the PAGE_RESCUE, and the saved version of the page is identified (step ).","If the notification is of a PAGE_RESCUE type, the ProcessNotification handling involves determining whether a local copy of the page identified in the PAGE_RESCUE is recognized (step ), and returns a PAGE_RESCUE_ACK notification. A page will not be recognized by a member if the page was locked when the member joins, and the page is not the subject of a page update before a PAGE_RESCUE notification is received member (step ), and accordingly the member issues a PAGE_RESCUE_ACK notification (indicating that the message was received, and that the member is still operational), but that the PAGE_RESCUE_ACK notification does not contain a copy of the page. All of the other members issue the most recent version of the page available in the PAGE_RESCUE_ACK notification (step ), i.e. the page that it has recently amended, or the page that was most recently received from a PAGE_UPDATE notification, as will be further described below with reference to .","Page Access Control","Most current OSs manage kernel memory spaces on a page basis, and this is how the shared kernel memory spaces of the shared memory address spaces are managed. By default, all pages can be read (but not written to) by any thread. When a thread tries to read\/write to a page, the distributed memory manager  uses the OS's memory management unit to verify if the request is allowed. If the page is writable, the write attempt is effected immediately. If the page is not writable, a processing unit may request a page lock to prevent other threads from accessing the page concurrently, to prevent inconsistent sets of page data being used throughout the network. Methods for attempting to lock and unlock a page are shown in . If a page is initially readable, and the page is requested for a write operation, a page lock is first requested and obtained. If the page is not readable, the distributed memory manager  must retrieve the page first, which may require a rescue of the page if an operation that locked the page has failed. Once the page is locked, the local distributed memory manager  makes the page writable and restarts the sleeping thread.",{"@attributes":{"id":"p-0172","num":"0178"},"figref":["FIG. 12","FIG. 14"],"b":["1130","1132","1130","1134","30"]},"Once the local page lock counter is incremented, it is determined (step ) whether the memory page is writable. If the page is writable, the page is already (effectively) locked by the Pool locally, and the thread running the lock page method returns a success. Otherwise, in step , the thread issues a PAGE_LOCK notification to the Pool's multicast group, to notify the members that the page is write-locked and therefore cannot be read. The PAGE_LOCK notification includes a page index that uniquely identifies the page.  shows how a PAGE_LOCK notification is handled by the other members of the group. In step , the thread sets a timer and goes to sleep. If the thread is awoken by the timeout, timeout handling is applied as shown in , following which the thread returns to step .","If the thread is awoken to the report of an error (because a negative PAGE_LOCK_ACK was received), the thread decrements the local page lock counter (step ), sleeps a random time (step ), and awakes to return to step . Subsequent to step , the local page lock counter is null (unless another thread has locally requested the page concurrently), because if the page is not writable, the local page lock counter was previously null and the incrementing and decrementing cancel each other.","The randomized delay is useful for preventing repeated concurrent lock attempts for a single page. As will be appreciated by those skilled in the art, if two (or more) threads on two different processor nodes  require the same page at a same time, both increment the local page lock counters and accordingly (as will be clear from the flowchart of ) both will deny the other access to the page. If the two threads immediately repeat the request for the same page neither will ever obtain the page. Accordingly, both members decrement the local page lock counter, select a random backoff time, and wait until the expiry of this time before returning to respective steps . The thread that selects the longer time will receive the PAGE_LOCK notification from the other member before returning to step , and because the local page lock counter is decremented to zero, will defer to the thread that selected the shorter time. Other page access contention techniques using priorities etc. can be used in other embodiments.","If the thread is awoken to a report of a successful page lock, the page is updated locally to make the page writable (step ). The thread then invokes the LockPool method of the Pool object (step ) to prevent the deletion of the Pool, when all of the pages are no longer locked, which would be problematic if the page contained updated data that is only locally available. This prevents the loss of data that is otherwise risked because a page does not indicate whether it has been modified since a last PAGE_UPDATE was sent. The LockPage thread then completes, reporting success.",{"@attributes":{"id":"p-0177","num":"0183"},"figref":"FIG. 13","b":["1149","65","65"]},{"@attributes":{"id":"p-0178","num":"0184"},"figref":"FIG. 14","b":["1150","1152"]},"At any point in time a page may be either of two stable states: in the default state (readable but not writable), or may be locked by one of the members, in which case it is writable by the member, but neither readable nor writable by the other members. As each member has it's own state of the page, during transitions the state maintained by the different members is not consistent if a PAGE_UPDATE is not delivered to a current member, or a PAGE_LOCK is not recognized by a current member. The PAGE_LOCK notifications are acknowledged by each of the members of the group, and members joining the group will not have a copy of a non-readable page, and so inconsistency of the second kind is unlikely.","If the page is in the default state, all members should have the page identified as readable, but any member that did not receive the last PAGE_UPDATE will not know that the page is in this state, and accordingly may issue a RetrievePage. In this case, all of the members that did correctly receive the last PAGE_UPDATE (and the member that sent it) will have an up-to-date (readable) copy of the page and all members will issue the PAGE_UPDATE to the Pool that sent the PAGE_REQUEST, but each of these will contain exactly the same page.","If the page is in a locked state (not readable or writable) only one PAGE_UPDATE notification will be received (from the member of the multicast group with the up-to-date copy of the page). Only a member with a lock on the page can return a negative PAGE_UPDATE notification. A negative PAGE_UPDATE notification indicates that a remote thread is modifying the desired page, and accordingly the thread executing the RetrievePage method is forced to wait. In accordance with the present embodiment, the thread sets a timer for a random time (step ) and returns to step  when a timeout occurs. It should be noted that the selection of a random time reduces a likelihood of competing requests repeatedly being issued at substantially the same time.","If the member that previously locked the page returns a positive PAGE_UPDATE notification in step , the thread ends reporting a success, and the up-to-date copy of the page is now accessible.","If the PAGE_REQUEST notification did not arrive at the processor node  where the member resides, or the PAGE_UPDATE notification does not arrive at the distributed memory manager , no response to the PAGE_REQUEST is received. In such an eventuality a retry counter is incremented (step ), and in step  it is determined whether the retry counter has reached a maximum value. If no, the thread returns to step . If the maximum value is reached in step , the thread effects page rescue procedures, which are necessary to prevent the unending retransmission of the PAGE_REQUEST notifications, for example if the member processing unit has terminated in an ungraceful manner.","The page rescue procedures involve multicasting a PAGE_RESCUE notification to the group (step ), and waiting for PAGE_RESCUE_ACK notifications in reply (step ). If the timer times out, the timeout handling is applied as per the steps of , after which the process returns to step . If all current group members return corresponding PAGE_RESCUE_ACK notifications before the timeout, the ACK with the most current content is now readable, and is taken to be the up-to-date copy of the page. The page with the most current content may be identified using a page serial number included in the PAGE_RESCUE_ACK (and the PAGE_UPDATE from which it was originally received).",{"@attributes":{"id":"p-0185","num":"0191"},"figref":"FIG. 15","b":["1170","1172"]},"If the local page lock counter is null, it is determined whether the page is writable, in step . If the page is not writable, it is determined (step ) whether according to the receiving member, the page is readable. If the page is readable, the receiving member has an up-to-date copy of the page, and accordingly a positive PAGE_UPDATE notification is sent in reply to the members of the group (step ), ending the processing of the PAGE_REQUEST notification.","In the illustrated embodiment, the readable page is multicast, so that all of the members independently verify the consistency of the page, and so that members that have newly joined the multicast group are provided with the up-to-date copy of the page. It will be appreciated by those skilled in the art that in other embodiments this response may be unicast so that only the member that sent the PAGE_REQUEST will verify the consistency of the values on copies of the page, and newly added members will have to wait until the next PAGE_UPDATE is sent. This type of implementation decision represents a trade-off between network traffic and notification processing load against the value of newly added members receiving the copy of the readable page.","If the page is not readable at the receiving member, the PAGE_REQUEST notification is discarded as the receiving member does not have an up-to-date copy of the page. In this manner, all of the members with up-to-date copies of the requested page will reply to a PAGE_REQUEST notification, if a LOCK_PAGE notification could have been sent instead, and only the member that most recently locked the page will reply otherwise. In either case the first PAGE_UPDATE notification determines the content of the page or that the page is not available.","If, in step  it is determined that the page is writable, the receiving member updates the page table to make the page no longer writable, but readable (step ), and multicasts to the group a positive PAGE_UPDATE notification (step ) which includes an up-to-date copy of the page. Each member that receives the up-to-date copy records the page, which may have been changed when the page was writable by another member. This dissemination of the updated page facilitates the page rescue process and permits the page to return to the readable default at all member locations.","It should be noted that if a member that sent the PAGE_REQUEST only requires a page for read purposes, a PAGE_REQUEST is all that is sent. However if a page is required for writing purposes, the further steps of locking the page are required, as per . Once the positive PAGE_UPDATE notification is multicast, an UnlockPool method is invoked by the receiving member (step ).",{"@attributes":{"id":"p-0191","num":"0197"},"figref":"FIG. 16","b":["1185","1186"]},"If the PAGE_UPDATE is positive, the recipient may or may not be the member that issued the PAGE_REQUEST, and it may or may not be the first of the PAGE_UPDATE notifications received in response to the PAGE_REQUEST. In accordance with the illustrated embodiment, it is determined whether the page is writable (step ). If the page is writable, there is a fatal error, as the distributed memory manager  sending the PAGE_UPDATE notification should have previously obtained the page for writing purposes and accordingly has (presumably) altered the content of the page, but independently the receiver of the PAGE_UPDATE notification has taken the page to be writable, and has presumably updated the page, which means that neither page is current and it is not clear how to resolve the inconsistency. The possibility of incomplete or incorrect information having been read from and acted upon, or written to the page is detected and a fatal error is reported.","Similarly the page should not be marked as readable, unless the PAGE_REQUEST was sent with reference to a readable page, in which case the page should be identical to that issued in a previous PAGE_UPDATE. If in (step ) it is found that the page is readable, it is determined (step ) whether the data on the readable page matches the content of the page included in the PAGE_UPDATE notification. If the pages match, then the PAGE_UPDATE notification may be the result of multiple PAGE_UPDATE notifications issued in response to a PAGE_REQUEST sent with reference to a readable page, as previously explained, and no error has occurred. Accordingly, if the pages match, the handling of the PAGE_UPDATE is complete. If the pages do not match, a discrepancy is detected that could have led to the incorrect use of stale data from the readable page (which should not have been readable, if the sending party is correct in sending the PAGE_UPDATE). As it cannot be determined whether the page was accessed since the page was or should have been locked, and further it cannot be determined whether any access was relevant to the changed data, a fatal error is reported.","If the page is neither readable nor writable, the PAGE_UPDATE is the first issued in respect of the page with the current up-to-date page data, and the up-to-date copy of the page is stored, and the page table is updated to make the page readable (step ). In step , it is determined whether the receiver is the member that issued the PAGE_REQUEST to which the received PAGE_UPDATE is a response. If the member sent the corresponding PAGE_REQUEST, there will be a corresponding thread running a RequestPage method, and this thread is awoken to the report of a success (step ) before the ProcessNotification thread completes successfully. If there is no corresponding RequestPage method, the page is stored to facilitate future page rescue operations on the page, bringing the processing of the notification to its successful conclusion.",{"@attributes":{"id":"p-0195","num":"0201"},"figref":"FIG. 17","b":["1200","1204","1202"]},"The rule adopted to ensure consistency of the page data used by the members of the multicast group is that no two members can modify a page concurrently. Accordingly if a receiver has incremented its page lock counter, either prior to obtaining a lock on the page (as in step  of ), when a request for the same page is received, the receiver asserts a lock on the page by denying the PAGE_LOCK and sending the negative ACK. If for any reason after the receiver has obtained a lock on the page but before the page is unlocked globally (i.e. when the PAGE_UNLOCK is sent), the sending member has erroneously identified the page as readable, for otherwise it would have sent a PAGE_REQUEST instead of the PAGE_LOCK. As all members (at the time of locking) acknowledged the previous PAGE_LOCK, a PAGE_LOCK is not required for a writable page unless there is a failure of notification processing at one of the two members. Even if the sending member was not connected when the initial PAGE_LOCK was sent, the sending member would not be able to read the locked page and accordingly would not send a PAGE_LOCK. Content of the page is presumed to be stale when the page is locked. But whenever a writable or locked page is identified in a PAGE_LOCK, the receiving member denies the PAGE_LOCK.","If the local page lock counter is 0, and the page is not writable, it is determined (step ) whether the page is readable. If the page is readable, the page table is updated (step ) to make the page unavailable (neither readable nor writable), and in either case the thread sends a positive PAGE_LOCK_ACK notification in reply (step ). The PAGE_LOCK is sent because the sending member believed it to be readable. The page should be readable at the receiver as well, unless the PAGE_LOCK is a retransmission. In anticipation of the page lock by the sender, the receiver ensures that the page is neither readable nor writable as the page will be modified by the sender, so the content of the page cannot be relied upon. It is for this reason that the page is marked as unavailable for both read and write operations.","Page Faults","A page fault is detected by an OS when a thread attempts to read a page that is not available, or to write to a page that is locally write locked. Page faults may be detected during the user mode application execution, and are handled locally to prompt the user mode application to effect the page lock, as described above. However when a plug and play driver executing in the kernel mode attempts to access a page in the kernel mode shared memory space that is not accessible, the distributed memory service needs to be notified of the condition.","Upon detection of a PAGE_FAULT, the plug and play driver issues a PAGE_FAULT local notification to the distributed memory driver , which pushes the local notification into the queue. When the memory manager library retrieves the notification (using the DriverInterface ), it will invoke the ProcessPageFault method of the Pool (step ). The distributed memory driver  acknowledges the PAGE_FAULT local notification in step  once the ProcessPageFault method completes, and the processing of the local notification is complete.","Principal steps of the ProcessPageFault method are schematically illustrated in . In step  a type of the page fault is identified. As previously stated, the page faults may be either of a read or a write type. If the page fault is of a read type, the Pool method for retrieving a page is called (step ), and the processing shown in  is effected, completing the processing of the ProcessPageFault method. The thread running the ProcessLocalNotification of the PAGE_FAULT notification is therefore awakened with the indication of success, prompting the transmission of the acknowledgement of (step , ).","If the page fault is of a write type, the ProcessPageFault method applies the LockPage and then the UnlockPage methods in succession (steps , ). By locking the page the page becomes writable, and by unlocking the page the local page lock counter is decremented so that other distributed memory managers can thereafter obtain access to the page by requesting it. Given that there is no predefined criterion for identifying when to unlock the page once it is locked, the page is unlocked immediately. When the page becomes unlocked, the page remains writable by the local threads, until such time as the page is requested by another member of the group.","Mutex Locking","It is frequently a requirement for programming of distributed applications that mutually exclusive (Mutex) locks be applied to data structures in order to ensure that consistent data is maintained by all members of the group, by permitting only one member to update a page at a time, and by ensuring that while a member is updating an object, no other member relies on the content of the data. It should be noted that while the data structures are stored on the memory pages, there is no correspondence between the locking of pages and the unlocking of pages.","Mutex locks permit the program developer to define Mutex objects  belonging to the Pool . The Mutex objects  permit the program developer to regroup logically related (non-overlapping) sets of data (the data structures) located on the pages. Each Pool  (of both the main shared memory pools  and the additional shared memory pools ) can be associated with respective Mutex objects , and accordingly a Mutex object  can belong to a single processing unit, or can be shared by a number of processing units.","The flow chart shown in  schematically shows steps involved in locking a data structure in accordance with the Lock method of the Mutex object . In step  a local mutex count of the Mutex  is incremented. It is then determined (step ) whether the local mutex count was null. If the local mutex count is now greater than 1, the Mutex  object is already locked, in which case the Lock method is complete.","If the local mutex lock counter is now 1, the local mutex count was previously zero, and no prior lock on the Mutex object was established. Accordingly the Mutex object's SendNotificationToGroup method is invoked to issue a LOCK notification to the multicast group of the Pool object  (step ), and the thread running the Lock method sets a timer, and goes to sleep (step ). If the thread is awoken by timeout, the timeout handling shown in  is applied before returning to step . If the thread is awoken by a ProcessNotification with a report of success, the Mutex lock has been acknowledged by all of the current members of the group, and the method completes successfully.","If the thread awakes to the report of an error, one of the members of the group has refused the Mutex lock., and the thread decrements the local mutex count (step ), effectively clearing the local mutex count. The thread then randomly selects a backoff time and goes to sleep (step ), in order to avoid a lock-step collision of Lock notifications, as previously described. If the thread is awoken by a timeout, or if the thread is awoken by a ProcessNotification successfully reporting a RELEASED notification, the thread returns to step .",{"@attributes":{"id":"p-0207","num":"0213"},"figref":"FIG. 21","b":["128","1300","1302","1304"]},{"@attributes":{"id":"p-0208","num":"0214"},"figref":"FIG. 22","b":["128","1310","1312","1314","1316"]},"If the notification is of a LOCK_ACK type, it is first determined whether the notification is positive or negative (step ). If the ACK is negative, in step , the thread wakes up the thread running the LOCK method (), to report an error. If the ACK is positive, the ACK is added to the local list (step ), and it is determined whether the local list is now complete (step ). If the list is not complete, the ProcessNotification has not yet completed. If the list is complete the thread running the ProcessNotification wakes the thread running the LOCK method to report success (step ).","If the notification is of a RELEASED type, ProcessNotification handling involves determining whether there is any thread waiting for the release of the Mutex object (step ). If there is no thread sleeping in accordance with step  of , the ProcessNotification method completes successfully. Otherwise the thread is awoken to the report of success (step ).","ProcessingUnit Objects",{"@attributes":{"id":"p-0211","num":"0217"},"figref":"FIG. 23","b":["150","65","65"]},"Each processing unit has address space where it keeps its own copy of its executable code; the code space . In each copy, identical functions are located at the same virtual address so that each copy of the code space  has the same content at the same virtual address. Each processing unit of the distributed process is started using the same executable image. Each processing unit further has its own private data addressing space (not shown in ). This private data addressing space contains a local thread stack and a private heap as well as the local list of ACKs relating to the ProcessingUnit. Each processing unit is associated with a ProcessingUnit object  in the user mode memory space  identified as the global shared memory pool .","The ProcessingUnit object  is a ListItem , which in turn is a NotificationReceiver , as shown in , inheriting the corresponding methods and attributes. Every ProcessingUnit is created in a global shared memory pool  that all distributed processes can access. The ProcessingUnit belongs to a member of Mutex, and so can be locked and unlocked by the Mutex. The ProcessingUnit  includes methods for connecting to a process, creating a process, and for resetting itself to go from a RUNNING state to an IDLE state. The ProcessingUnit  also includes a ProcessNotification method for exchanging CONNECTION and CONNECTION_ACK messages as required to support the ConnectProcess methods. The ProcessingUnit  also has a State attribute that is either RUNNING, DISCONNECTING or IDLE. When the ProcessingUnit  is RUNNING, it is not in a ListHead .","The ListHead object  is an object that manages the list mutex. ListItem and ListHead objects are structures provided by operating systems, and commonly included in programming language libraries that may be instantiated to provide queue management for any number of items.","In accordance with the current embodiment of the invention, the ListHead  contains ProcessingUnits  that are in the IDLE state (an IDLE processing unit list), and a ReadWriteMutex object  belongs to the ListHead . The ListHead object  is stored in the global distributed memory space of a ProcessingUnit . The ListHead  provides methods for pushing, and popping items of the IDLE processing unit list and for exchanging notifications and other ITEM_ADDED notifications with the ListHead objects  of the ProcessingUnit at different processor nodes .","The ListHead maintains the IDLE processing unit list in a manner that facilitates the selection of an IDLE processing unit to enlist by distributed processes, if one is available. Depending on implementation, the distributed processes can use thread information to efficiently choose an IDLE processing unit from the global shared memory pool . Such information may be a CPU usage of the processor node , an assigned priority of the processing unit, available physical memory of the processor node , available hardware resources or other criteria defined by the user mode application.  show how ProcessingUnits connect to or create distributed processes.","A ReadWriteMutex object  is an object that controls read and write locks on shared objects (which are defined in the same manner as Mutex objects). In contrast with the mutex  which locks data structures preventing the reading or writing of data on the data structures, the ReadWriteMutex provides a method for read locking, or for write locking. A write ReadWriteMutex lock is equivalent to a mutex lock, and in some embodiments only one of the two is defined.","In the same manner as the Mutex is defined as a part of the Pool, but can equally be instantiated by any other user mode application-defined data structure, and perform the same locking function with respect to that other data structure, the ReadWriteMutex of the ListHead is shown to introduce the ReadWriteMutex but the ReadWriteMutex object can be instantiated for other data structures as well.","Redundancy","When building high availability systems, the presented architecture permits starting processing units in pairs running on separate processor nodes . One more State is defined called STANDBY. The paired processing units are the same part of the same Process. Their code space is kept consistent and both participate in management of shared memory.","The RUNNING processing unit operates normally. The processing unit on standby monitors the RUNNING processing unit by setting its bus adapter driver  to receive all notifications sent to the RUNNING processor node , but does not send ACKs.","All notifications defined herein sent to system level objects (Pool, Thread, Process etc.) of the RUNNING processing unit are received by the STANDBY ProcessingUnit. However it will be appreciated by those skilled in the art that notifications defined by developers of user mode applications will not be monitored in this manner, because there is no logic for handling these notifications. Accordingly user-defined notifications may be ignored by the STANDBY processing unit.","If the running unit fails to acknowledge a notification as expected, the STANDBY ProcessingUnit can switch to a RUNNING state, and restart all threads known to be running on the previously RUNNING ProcessingUnit.","In such high availability embodiments, the application developer ensures that each thread running on such a standby ProcessingUnit can be restarted, for example by tracking various copies of the structures that are marked and resuming thread processing with the copy available before the processing unit failed.","When redundancy is used, the RUNNING ProcessingUnit runs a special thread that parses the page table, and sends a PAGE_UPDATE notification to the group (or alternatively only to the STANDBY ProcessingUnit) whenever it finds an unlocked modified page. This way a risk of losing shared data is minimized. This special thread can be run even if redundancy is not activated to decrease the likelihood of lost data when a processor node  fails, and may be particularly useful when the rate of change of membership in the multicast groups is high.","Pool Locking",{"@attributes":{"id":"p-0225","num":"0231"},"figref":"FIG. 24","b":["120","1340"]},{"@attributes":{"id":"p-0226","num":"0232"},"figref":"FIG. 25","b":["1350","1352"]},"If the pool protection counter is decremented to 0 in step , there is no longer any reason for the Pool to be retained. Accordingly, in step  the thread invokes a method for sending a notification of the EXIT type to the group. The thread (step ) sets a timer and sleeps until the timer expires (in which case the timeout process of  are applied before returning to step ), or a report from a ProcessNotification thread is received. If EXIT_ACKs are received from all of the current members of the group before the timeout, the Pool object is closed (step ), the processing unit state is set to IDLE (step ) by invoking the Reset method of the ProcessingUnit, and the ProcessingUnit is added to the IDLE processing unit list by invoking the PushItem method (see ) of the ListHead object.","ListHead",{"@attributes":{"id":"p-0228","num":"0234"},"figref":["FIG. 26","FIG. 29","FIG. 30"],"b":["154","1380","156","1382","150","1384","1386"]},"If the list is found to be empty in step , the Unlock method of the Mutex object is invoked to release the write lock (step ). Next a timer is set, and the thread running the PopItem method waits for an ITEM_ADDED notification, or for the timer to timeout (step ). In either case, the thread returns to step .",{"@attributes":{"id":"p-0230","num":"0236"},"figref":["FIG. 27","FIG. 26"],"b":["154","1400","1402","1404","1406","1390"]},"As shown in , upon receipt of a notification from a remote process, in step , the thread identifies a type of the notification (which is an ITEM_ADDED type, or a type inherited by the NotificationReceiver , in which case it is handled in the manner described above in relation to ). Upon receipt of an ITEM_ADDED notification, the thread determines whether a thread running the PopItem method is sleeping (step ). If no such thread is found, the process is complete. Otherwise the ITEM_ADDED notification prompts the thread that is processing the notification to wake up each thread running the PopItem method reporting a success (step ).","Read and Write Locking","While the Mutex locking mechanism described above provides sufficient control of data structures in certain embodiments, in other embodiments, it may be desirable to permit read locking as well as write locking. The Mutex locking mechanism is a write lock. Read locks may be required to prevent other members from writing over the data structure but without preventing other members from reading the data structure. Many distributed application routines require one consistent set of values be used throughout the routine. If the values change during execution of the routine the result of the routine may be inaccurate, or the routine may crash. While a write lock could be used, this would preclude other members from reading the object which may not be desirable. Accordingly, the illustrated embodiment further provides ReadLock and WriteLock methods.",{"@attributes":{"id":"p-0233","num":"0239"},"figref":"FIG. 29","b":["156","1430","1432"]},"If the incremented lock count is 1 (step ), it was previously null, and the thread effecting the ReadLock\/WriteLock method must notify the other members of the group of a change in the status by issuing a LOCK notification, by invoking the SendNotificationToGroup method inherited from the NotificationReceiver  (step ). The thread then sets a timer and sleeps (step ) until awoken by the timeout, or a thread running a ProcessNotification routine. If a timeout wakes the thread, timeout handling is applied as shown in . If the thread is awoken by a report of success, the method completes successfully. If a negative LOCK ACK notification is received, one of the other members of the group has denied the read or write lock (see ), and accordingly the thread decrements the appropriate (read or write) local lock counter (step ), and sets a timer for a random back off interval (step ). If the timer times out, or a RELEASE notification is received, the method returns to step .",{"@attributes":{"id":"p-0235","num":"0241"},"figref":"FIG. 30","b":["1450","1452","1454"]},{"@attributes":{"id":"p-0236","num":"0242"},"figref":"FIG. 31","b":["1460","1462","1464"]},"Otherwise, the local write lock counter is null, and it is determined in step  whether the LOCK notification requests a read lock, or a write lock. If a read lock is requested, the request is satisfiable and accordingly the thread sends a unicast reply to the sending member indicating a positive LOCK_ACK (step ). If a write lock is requested, the thread determines whether the local read lock counter is 0 (step ). If the read lock is counter null, no thread currently requires the mutex's data structure, and so the thread sends a positive LOCK_ACK in step . Otherwise the acknowledgement of the write lock would interrupt the read lock of the local user mode application, and must be refused using the messaging step .","Upon receipt of a LOCK_ACK notification, it is determined (step ) whether the ACK is positive or negative. If the ACK is negative, the thread wakes the sleeping thread that executes the ReadLock or WriteLock, indicating an error (step ). If the ACK is positive it is added to the local list (step ), and it is determined if the local list now contains an ACK from each member (step ). If the local list is still incomplete, the method returns a success. If the local list is now complete, the thread wakes up the sleeping thread indicating success (step ), before completing successfully.","Upon receipt of a RELEASE notification, it is determined whether a corresponding thread is sleeping, as per step  of , with respect to the same ReadWriteMutex. If no other thread is sleeping, the method has completed successfully. Otherwise, the sleeping thread is awoken reporting success (step ).","Process and Thread Objects",{"@attributes":{"id":"p-0240","num":"0246"},"figref":["FIG. 32","FIG. 6"],"b":["180","182","122"]},"The Thread  objects include methods for killing, starting, stopping, suspending and waiting (e.g. for a child thread to end) in the execution of the method it invokes. The Thread  further includes a ProcessNotification method for enabling remote threads to exchange KILL, KILL_ACK, RESUME, RESUME_ACK, START, START_ACK, STATE_CHANGED, STOP, STOP_ACK, SUSPEND, and SUSPEND_ACK notifications in accordance with the methods of the Thread. The methods of the Thread  permit any instance of the ProcessingUnit  to which the Thread belongs to start and stop the thread, to suspend and resume the thread, and to kill the Thread, and further permits the Thread to be forced to wait for a Thread to end, for example in accordance with a wait method. The starting and stopping of threads permits threads to perform ongoing processes that may be stopped or started by other threads. The suspending and resuming operations are useful for debugging distributed application code, as is well known in the art. A final method of the Thread permits the Thread to notify (multicast to group) the termination of the thread upon completion, by sending a STATE_CHANGED notification.","The distributed processes are associated with respective Process objects  created in the main shared memory pool . The Process  belongs to a member of Mutex, and so can be locked and unlocked by the Mutex. The Process object  has methods for creating thread objects, enlisting an IDLE processing unit to be added to the Process, and for maintaining consistency between content of the respective code spaces of the Process's ProcessingUnits by loading and freeing user mode library files of the code spaces. The Process  also has a method for aborting itself. Abort is a method invoked by a process when a fatal error is encountered. The abort method prompts the killing of each of the associated threads and the disconnection of the ProcessingUnits from the Process. An UpdateCodeSpace method permits the loading and freeing of the user mode library files in accordance with an operation list, which indexes the complete ordered set of load and unload operations that have taken place at the distributed process's code space. The method for processing notifications inherited from the NotificationReceiver is further adapted to process CODE_SPACE_CHANGE and CODE_SPACE_CHANGE_ACK notifications.",{"@attributes":{"id":"p-0243","num":"0249"},"figref":["FIG. 33","FIG. 26"],"b":["182","1490","154","1492","150","30"]},{"@attributes":{"id":"p-0244","num":"0250"},"figref":"FIG. 34","b":["150","1500"]},"The thread at the effective site of the distributed process running the ConnectProcess method of the selected IDLE ProcessingUnit (but potentially remote from the processor node  of the selected ProcessingUnit), in step , issues a CONNECT notification to the selected ProcessingUnit at the processor node  of the selected ProcessingUnit. As typically is the case, the CONNECT is sent from the effective site of the Process to the processor node  of the selected ProcessingUnit using the SendNotificationToOne method inherited from the NotificationReceiver. In this way the public part of the processing unit (which is available at each processing unit via the global distributed memory pool ), permits the Process to connect to selected ProcessingUnit.","The thread then sets a timer, and goes to sleep (step ). If the thread is awoken by the timer timing out, the timeout handling shown in  is applied, before returning to step . If a positive CONNECT_ACK is received, the thread releases the mutex lock on the ProcessingUnit, and returns success. If a negative CONNECT_ACK is received, the thread advances to step .",{"@attributes":{"id":"p-0247","num":"0253"},"figref":["FIG. 35","FIG. 20","FIG. 9"],"b":["150","1514","1516","1518","1520","1522"]},"Once a Pool object is instantiated for the main distributed memory pool of the processing unit, a Process object is created (step ) using a Constructor method of the Process object, in a manner well known in the art. The Process object is now created and the ProcessingUnit belongs to the Process, but there is nothing for the distributed process to execute. Accordingly in step , the LoadLibrary method of the Process object is invoked. The LoadLibrary method loads, into the code space  of the locked ProcessingUnit, a shared object (in Linux) or a data linked library file (in Windows), or an equivalent software layer element of another operating system used to implement the invention. The LoadLibrary method includes executable code for effecting the execution of the part of the user mode application prompted the construction of the distributed process. If the LoadLibrary method fails, the thread advances to step . Otherwise a main Thread is created for the Process (step ) using the CreateThread method of the Process, and the Start method of the Thread is invoked (step ). The Start method is further described below with reference to . If the start method ends in failure, the thread advances to step , and otherwise the mutex lock on the ProcessingUnit is released (step ), and the thread ends in success.",{"@attributes":{"id":"p-0249","num":"0255"},"figref":"FIG. 36","b":["1550","1552","1554","1556"]},"If in step  it is found that the ProcessingUnit is in an IDLE state, the thread sets the state to RUNNING (step ) and the create Pool process shown in  is performed to attempt to create a new shared memory pool. If the attempt fails (step ), the State of the ProcessingUnit is returned to IDLE (step ), and the thread advances to step . Otherwise, in step , the Process is retrieved using the RetrieveProcess method of the Pool object. Insodoing the connection between the Process and the ProcessingUnit is established.","The UpdateCodeSpace method of the Process is subsequently invoked (step ) to update the code space of the ProcessingUnit, to be the same as the codes spaces of the other ProcessingUnits of the Process to which the ProcessingUnit has connected. If the update code space method is successfully completed, the thread advances to step , otherwise it advances to step .","If the notification received is a CONNECT_ACK, it is received at the effective site of the Process, and the thread determines (step ) whether the CONNECT_ACK is a positive or a negative ACK. If the ACK is positive, the thread reports success to the waiting thread (step ), and if the ACK is negative, the thread reports error to the waiting thread (step ), before ending successfully.",{"@attributes":{"id":"p-0253","num":"0259"},"figref":["FIG. 37","FIG. 20"],"b":["1580","1582","1584"]},"If the load\/free operation is successful, the thread adds the load\/free operation to the operation list of the Process (step ). The operation list permits the Process to indirectly specify content of each bit in the code space to any ProcessingUnit  configured by the same OS, so that addresses of the code spaces of the processing units of the same distributed process are addressable.","In step , the thread invokes the SendNotificationToGroup method of the Process object, to issue a CODE_SPACE_CHANGE notification. The thread then sets a timer, and goes to sleep (step ). If a negative CODE_SPACE_CHANGE_ACK is received, one of the other members of the group has failed to apply the change. Consequently, the mutex lock is released (step ), and the distributed process aborts step . If the thread is awoken by the timer timing out, the timeout handling shown in  is applied before the thread returns to step . If each of the members of the group responds with a positive CODE_SPACE_CHANGE_ACK notification before the timeout, the mutex unlocks the ProcessingUnit (step ) and the method ends in success.",{"@attributes":{"id":"p-0256","num":"0262"},"figref":"FIG. 38","b":["182","1600","1602"]},"If the UpdateCodeSpce method succeeds, the thread effects the sending of a CODE_SPACE_CHANGE_ACK notification of a positive status using the SendNotificationToOne method (step ). Otherwise the UpdateCodeSpce method fails, and the thread sends a negative CODE_SPACE_CHANGE_ACK notification in reply (step ).","If a CODE_SPACE_CHANGE_ACK type notification is received, it is determined in step  whether the ACK is positive, or negative. If the ACK is negative, the thread wakes the sleeping thread, reporting an error (step ). If the ACK is positive, the ACK is added to the local list (step ), and it is determined (step ) whether the list is thereby completed. If the list is not complete, the processing of the notification returns success. Otherwise, in step ) the waiting thread (that is running the LoadLibrary or FreeLibrary method) is awoken with a report of success, and the method ends.","Remote Thread Operations",{"@attributes":{"id":"p-0259","num":"0265"},"figref":"FIG. 39","b":["180","1630","1632","1634","1636"]},"If the notification is an ACK (i.e. a KILL_ACK, RESUME_ACK, START_ACK, or STOP_ACK), it is determined (step ) whether the ACK is positive or negative. If the ACK is positive, the corresponding waiting thread is awoken, and success is reported (step ), and if negative, the corresponding waiting thread is awoken to the report of an error (step ).","If the notification is of a RESUME, or a START, or a SUSPEND type, the thread (of the Thread addressed in the notification) was previously suspended, or not started, or running is resumed (step ), or started (step ), or suspended (step ) by using native OS thread management services. If the resume\/start\/suspend operation successfully completes a positive RESUME_ACK\/START_ACK\/SUSPEND_ACK notification is sent (step \/\/), and if the resume\/start\/suspend operation fails, a negative RESUME_ACK\/START_ACK\/SUSPEND_ACK notification is sent (step \/\/).","The Suspend and Resume methods are used for step-wise debugging user mode applications. The Start and Stop are used to begin and end the thread's execution of program instructions. The Stop permits the ending of a thread in a consistent manner. The thread will continue processing until a consistent state is achieved, and then ends the processing of the program instructions.","Upon receipt of a STOP notification, the ProcessNotification thread sets a thread stop flag (step ), and sets a timer for waiting for the thread to stop (step ). If the thread stops before the timer times out, a positive STOP_ACK notification is sent in reply to the stop (step ). Otherwise, the STOP_ACK notification is negative (step ).","The thread processing a STATE_CHANGED notification determines (step ) whether there is local thread executing a Wait method waiting for the thread (identified in the STATE_CHANGED notification) to complete. The STATE_CHANGED notification is an unacknowledged message that is multicast to the group by a Thread when the corresponding thread has completed the executable program instructions and has no Wait methods sleeping. If there are no threads waiting on the Thread that issued the STATE_CHANGED notification, the ProcessNotification completes successfully. Otherwise the Thread that is sleeping is awoken to a report of success (step ).",{"@attributes":{"id":"p-0265","num":"0271"},"figref":"FIGS. 40-45"},"In analogous steps , ,  and , the (local copy of) user mode application program instructions performed by a thread at a first member of a group determines that a second thread of a ProcessingUnit of the Process needs to be killed, resumed, stopped or suspended, and consequently sends a corresponding notification by invoking the SendNotificationToOne method of the Thread associated with the second thread to send the notification of the required type. It will be noted that the second thread may be the thread itself, may be local to the thread, or may be remotely running on another processor node .","The thread then sets a timer and waits for corresponding ACKs (steps ,,,). If the thread just sent a KILL to itself, the ProcessNotification thread that handles the KILL_ACK will drop it. If the timeout of the timer wakes the thread, the thread applies timeout handling according to the method shown in , and returns to a corresponding step , ,  or . If the thread is awoken to an error report, the method ends in failure, and if awoken to a report of success, the method ends successfully.",{"@attributes":{"id":"p-0268","num":"0274"},"figref":"FIG. 44","b":["1704","74","1706","1704"]},"Principal steps involved in starting a thread remotely are illustrated in . The thread that is started already has a Thread object in the main shared memory pool  (defined by the CreateThread method of the distributed process), but is not running on any of the ProcessingUnits, and has no program instructions to execute. At the outset a start address of the code space at which the program instructions of the thread is defined, and context data which supplies arguments etc. necessary to effect the program instructions, is assembled.","To start a Thread, a first thread of a distributed process selects one of its ProcessingUnits (step ) to effect the thread. Typically a first ProcessingUnit (connected to the distributed process) that is not currently executing any methods is chosen. The first thread effects the sending of a START notification to the Thread at the selected ProcessingUnit (step ), by invoking the SendNotificationToOne method of the Thread object that is locally accessible through the main shared memory pool. The START notification includes start address of code space program instructions that the started thread will execute, and an address of the context in the code space of the ProcessingUnit . The thread running the Start method then sets a timer, and goes to sleep (step ). If receipt of a positive START_ACK is reported before the timeout, the Thread started successfully, and the method completes successfully. Otherwise a report of error, or a timeout wakes the first thread, and the first thread returns to step .",{"@attributes":{"id":"p-0271","num":"0277"},"figref":"FIG. 46","b":["1720","1724","1730"]},"If the retry counter has reached its maximum value, the retry counter is zeroed and the local list of ACKs is cleared (step ). The thread then removes a ProcessingUnit from the pool member list that did not respond to the notification any of the times it was issued (step ). More precisely all members of the pool member list for which there is no ACK in the local list are determined to be dead and removed from the pool member list.","In order to indicate to the remaining members that the removed ProcessingUnit(s) is\/are non-responsive, a DEAD notification is multicast (step ). The thread then sets a timer and goes to sleep (step ). Either all the remaining members of the group respond to the DEAD notification resulting in a success report, or the timer expires first. If the success report is received, the thread returns to retry the notification that had previously timed out the maximum number of times. The success report restores confidence in the pool member list.","If the thread awakes to a timeout the thread returns to step , but if the retry counter is not maximum, in step  the thread will return to step  because the notification will be determined to be a DEAD notification, in step . If a member of the group does not reply to any of the DEAD notifications, the thread reiterates the steps of removing the ProcessingUnit from the pool member list until there are no members of the pool member list that do not respond, as indicated in a success report of step .","Aggregation",{"@attributes":{"id":"p-0275","num":"0281"},"figref":"FIG. 47","b":["80","82","80","86","52","80","86","86","50","50"]},"Each aggregation manager  (two shown) is a master type plug and play driver of a respective Ethernet bus, which subscribes to all packets, and passes all packets from the Ethernet bus to the aggregator . The aggregator  sends all of the packets from either of the Ethernet buses to the Ethernet bus driver *. In the opposite direction, the aggregator  selects the aggregation manager  to which the packet is directed. In this way the aggregate Ethernet bus  is provided with a bandwidth of the combined Ethernet buses which it accesses through the aggregation managers . The number of aggregation manager  instances to be created may be defined when the aggregator  is loaded.","Each aggregator manager  is a master plug and play driver of a respective Ethernet bus, and may or may not be the only plug and play driver (other than the adapter bus driver). Any other plug and play driver coupled to a respective one of the Ethernet buses is unable to exchange notifications over the other Ethernet buses.","In accordance with the present embodiment, the aggregator  and aggregation manager(s)  may conform to the Institute of Electrical and Electronics Engineers (IEEE) standard 802.3-2002, or a later version, for example. The settings defined by IEEE Standard 802.3-2002 may all be supported by including respective functionality in the aggregator, aggregation manager, and\/or Ethernet bus driver (including a system priority, the system MAC address, the maximum number of aggregator addresses, the aggregator identifier and aggregator operational key settings. The aggregator manager  preferably has settings to manage the ports (priority and port number) and the port operational keys.","More specifically, the aggregator  accepts connection from an aggregation manager , and is responsible for:\n\n","The aggregation manager  passes all packets from the Ethernet bus to the aggregator and from the aggregator to the respective Ethernet Bus.","Using the same architecture for the Ethernet buses over each of the NICs has numerous advantages. First, it is efficient to reuse the Ethernet bus driver and avoid creating new drivers. Second, the aggregation managers  get access to respective plug and play functionality so that the aggregation managers can be instantiated and deleted as required. Effectively each Ethernet bus driver performs the same tasks regardless of whether it effects an aggregate Ethernet bus, or one of the other Ethernet buses. Further still using prior art methods for aggregation, which involve providing adapter drivers for each of the NICs, and an aggregator directly coupled to the adapter drivers, a respective aggregation manager must be developed for each NIC type. By recycling the services of the Ethernet bus driver the aggregation managers remain at arms length from the adapter drivers, and the same Ethernet bus driver, and same aggregation managers can be used.","Multi-Bus Bridges","The network bus driver  may define a number of instances of the network bus  to permit different plug and play devices to communicate with the hardware devices  of the data network using separate encryption schemes, for example, or to otherwise partition the plug and play devices of the processor node . If so the network bus driver  has settings to define the number of network buses  to instantiate at load time. Each network bus  is logically independent and may use the same bus adapter driver  and NIC , or each may use different respective bus adapter drivers  and corresponding NICs .","The bus adapter driver  is connected to zero, one or more software abstractions of network buses . If a bus adapter driver  is connected to two (or more) software abstractions of the network bus , then effectively there are two (or more) network bus drivers  (or instances thereof), each associated with a respective, disjoint set of the plug and play drivers. In such an embodiment the NIC  is adapted to publish two (or more) MAC addresses, and associates one MAC address with each of the network buses. Messages received over the data network  are directed to the network bus driver  instance of the correct network bus  according to the destination MAC address.","In such an embodiment, the distributed memory manager  stores a setting that indicates how many instances of the distributed memory service  to start: one service instance is created per Ethernet bus. The distributed memory manager  maintains instance settings as needed to keep separate the respective Ethernet buses.","Two Ethernet buses can alternatively be interconnected using a bus-to-bus bridge. Depending on a topology of the network subtending the network bus, a bridge between two Ethernet buses may be needed. Further bus-to-bus bridges ,\u2032 may be useful when it is desired to control the exchange of data, and the use of resources, between different interests (e.g. companies, network service providers etc.). The bus-to-bus bridge provides an effective firewall between two buses .","Bus-to-bus bridges ,\u2032 work similarly to PCI to PCI bridges known in the art, and offer similar capabilities.  is a block diagram of a hardware view of two possible configurations of bus-to-bus bridges  and \u2032 respectively. The first bus-to-bus bridge  is effected within Processor Node A, which accesses two (or more) physical Ethernets , via respective Ethernet NICs . Typically the Ethernet NICs  are part of respective subnets, in a manner known in the art.","The second illustrated configuration includes Processor Nodes B and C which connect two possibly remote Ethernet Buses and , and passes packets using a communication link such as Ethernet links, Internet tunneling protocols (including virtual private networks (VPNs)), ISDN telephone connections, or any other communications means including firewire, USB, Hotlink, optical fiber channel, SONET, etc.","Each bus-to-bus bridge \u2032and \u2032is independently configured, so that management of each Ethernet bus can independently provide the other Ethernet bus and with permission to access respective Ethernet devices. This is effected by providing permissions that control passage of notifications between plug and play drivers of the respective Ethernet buses and . In addition, permissions can be defined to allow only a subset of Ethernet device capabilities to be accessible through the bridge. To avoid address and identifier conflicts, the bus may need to translate addresses and identifiers when relaying Ethernet device packets. This configuration procedure also helps to ensure secure connections between distinct Ethernet buses.","The bus to bus bridge  can be implemented as a software device gateway , either as a service on top of the device and service connector  or directly as a plug and play software device gateway driver as described above. This implementation decision may depend on the required performance and communication link constraints. Higher performance can be achieved using a kernel mode plug and play software Ethernet device gateway. Regardless of to the implementation, the network bus driver  sees the bridge as a master entity.","Encryption","If required, the implementation can employ cryptographic algorithms to ensure secure communications between the driver and device.","In accordance with some embodiments of the invention, the network bus driver  implements a lowest level of security management. This level may use a symmetric cryptographic algorithm and a shared secret key to encrypt all sent packets, for example, in which case the shared secret key is known by all hardware devices . As is well known in the art a symmetric cryptographic system applies the same algorithm for encrypting and decrypting data. Typically encryption involves applying a known algorithm using a set of parameters (a key) that specifies the algorithm. The key can be shared in any convenient manner.","In accordance with some embodiments of the invention, the distributed memory manager  implements a second level of security. Using a known private key cryptographic system, a secret key is shared between all processing units of the same distributed memory pool. In some embodiments, the secret key is used with a symmetric cryptographic algorithm to both encrypt and decrypt all object notifications sent over the network. When a new processing unit joins a shared memory pool, it receives the pool's secret key from the global part of the corresponding ProcessingUnit in the CONNECT notification, as described above in relation to . The keys may be exchanged using the global shared memory space . Alternatively, an asymmetric cryptographic algorithm can be used to exchange secret keys without making them available to other processing units.","The secret key of the user mode and kernel mode systems shared memory pool cannot be exchanged using the global distributed memory space, as the keys are required to encrypt messages used to initially distribute these objects. Accordingly, this secret key may be manually configured or distributed using another secure protocol.","Implementation of the Ethernet bus driver is architecturally different for different operating systems (OSs) due to the different services available from, and structural features of, each OS. A description of the Ethernet bus driver implementation in Windows XP (Windows\u00ae) will be presented first, followed by a description of the differences between the Windows and a Linux\u00ae implementation.","Windows Implementation","In the Windows implementation schematically illustrated in , the Ethernet bus driver runs in kernel mode, providing plug and play drivers with access to the remote hardware Ethernet devices through the legacy bus adapter driver, which is embodied as a Windows plug and play functionality driver . The bus adapter function driver communicates with the NIC  using hardware abstraction layer (HAL) I\/O access routines known in the art.","In some embodiments the bus adapter function driver is a commercially available NIC driver that provides hardware abstraction for the NIC in a well known manner, configured and operating in a known manner except that it is not registered with the operating system on start up, but rather is adapted to connect to the Ethernet bus driver . In operation, the bus adapter driver passes Ethernet packets from the Ethernet network to the Ethernet bus driver , and vice versa. The bus adapter driver publishes a Windows driver model (WDM) driver interface. An application or class installer can connect to it for viewing and editing settings of the NIC .","The plug and play drivers include an Ethernet device function driver for each of the Ethernet devices of the Ethernet bus, a device and service connector function driver , a distributed memory function driver , and a legacy network support Network Driver Interface Specification (NDIS) miniport driver . Each plug and play driver handles protocol processing and Ethernet-specific operations, and takes care of Ethernet negotiations etc. so that the overlying software layers are not required to monitor such operations.","Each Ethernet device function driver controls a respective Ethernet device. Many Ethernet device function drivers can be connected on the top of the same Ethernet bus driver . The respective interfaces Ethernet device function drivers provide, and how it is provided depends on the device type (printer, network attached storage, camera or other). Accordingly only the protocol processing required for controlling the respective Ethernet device is used saving considerable CPU usage used for protocol processing in accordance with the prior art.","The Windows DLL , accesses the kernel mode Ethernet bus driver and the plug and play drivers through an I\/O system services application programming interface (API)  and a Windows input\/output (I\/O) manager , both of which being well known in the art. Direct access between the I\/O manager and the Ethernet bus driver is also provided so that the plug and play functionality that is provided in the kernel mode by the Windows can communicate with the Ethernet bus driver to effect the instantiation or deletion of plug and play device drivers, as required.","Access to the Ethernet bus driver is also provided via a Network Driver Interface Specification (NDIS)-compatible miniport driver that provides legacy network support through the Transport Driver Interface (TDI)  of the Windows XP OS. The Windows plug and play (Plug and play) subsystem loads legacy network support at boot time, as is well known in the art.","The Windows DLL files are called by user mode applications, and are executed in the user mode. Each of the plug and play drivers is associated with respective class installer\/co-installer DLL files. Specifically, a bus adapter class installer \u2032, a distributed memory driver class installer \u2032, an Ethernet device driver co-installer \u2032 (for each Ethernet hardware device ), a device and service connector class installer, and a legacy network support co-installer \u2032 are provided in the user mode for changing settings of the corresponding driver, in a manner well known in the art. The class installers may represent multiple objects instantiated at different times, but are only registered once, when the first instance is encountered. The co-installers are launched with the corresponding plug and play device installer. The class installers and co-installers provide an interface for setting parameters for the respective plug and play drivers.","The distributed memory function driver channels memory requests and access from the plug and play drivers to a distributed memory DLL which in turn passes the requests to a distributed memory service executable and further permits the exchange of notifications between the distributed memory manager's system level objects (Threads, ProcessingUnits, Processes, Pools, etc.) through the Ethernet bus. The distributed memory manager  provides services to enable access to distributed memory across the Ethernet bus, as well as DLL files and executables to manage distributed processes. The distributed memory function driver also handles user mode memory access requests received through the distributed memory library ","The distributed memory function driver is configured to keep a part of the OS's main memory at boot time. It uses these physical pages to store the distributed memory pages used by the local processing units. It works with the Windows memory manager to configure a processor memory management unit.","The distributed memory function driver is implemented as a plug and play Windows Driver Model (WDM) function driver and is loaded over a PDO (the Windows embodiment of a base driver) created by the Ethernet bus driver at load time. The distributed memory function driver publishes a numbered symbolic name. The distributed memory service, ProcessingUnits, and Processes can connect to the distributed memory function driver to access its functionalities, using the numbered symbolic name, and interfaces through the distributed memory library (the current embodiment of the DriverInterface ).","A device and service connector DLL  provides a method for user mode software Ethernet device gateway executables and other special services or protocol executables to access the Ethernet bus driver permitting the software devices and special services to be implemented as normal applications (i.e. as Windows services) that use to the Ethernet bus. Using the device and service connector DLL , applications and services can be built to take advantage of the Ethernet bus without any knowledge of the details of the I\/O system services API  and other internal OS functions. Examples of such applications include imaging applications, remote storage, and networking protocols. The device and service connector DLL  provides the ability to connect new software services to the Ethernet bus driver without having to provide corresponding plug and play drivers, making the service or protocol less costly to support.","Table 1 shows how the device and service connector function driver handles the minor I\/O request packets (IRPs) in relation to plug and play management.",{"@attributes":{"id":"p-0307","num":"0317"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Device and Services Connector FDO functions"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Minor IRPs","Comment"]},{"entry":["CANCEL_REMOVE_DEVICE","Indicate success and pass"]},{"entry":["CANCEL_STOP_DEVICE","request to PDO."]},{"entry":["DEVICE_USAGE","Not currently supported"]},{"entry":"NOTIFICATION"},{"entry":["EJECT","Ignore the request and pass it"]},{"entry":[{},"to PDO."]},{"entry":["FILTER_RESOURCE","Not currently supported"]},{"entry":"REQUIREMENTS"},{"entry":"QUERY_BUS_INFORMATION"},{"entry":["QUERY_CAPABILITIES","Ignore the request and pass it"]},{"entry":[{},"to PDO."]},{"entry":["QUERY_DEVICE_RELATIONS","Support:"]},{"entry":[{},"Removal Relations"]},{"entry":["QUERY_DEVICE_TEXT","Not currently supported"]},{"entry":"QUERY_ID"},{"entry":"QUERY_INTERFACE"},{"entry":"QUERY_LEGACY_BUS"},{"entry":"INFORMATION"},{"entry":["QUERY_PLUG AND","Ignore the request and pass it"]},{"entry":["PLAY_DEVICE_STATE","to PDO."]},{"entry":["QUERY_REMOVE_DEVICE","Fail if an application is"]},{"entry":[{},"connected or if an enumeration"]},{"entry":[{},"is in progress."]},{"entry":["QUERY_RESOURCE","Not currently supported"]},{"entry":"REQUIREMENTS"},{"entry":"QUERY_RESOURCE"},{"entry":["QUERY_STOP_DEVICE","Fail if an application is"]},{"entry":[{},"connected or if an enumeration"]},{"entry":[{},"is in progress."]},{"entry":["READ_CONFIG","Not currently supported"]},{"entry":["REMOVE_DEVICE","Always succeed. Delete the FDO."]},{"entry":["SET_LOCK","Not currently supported"]},{"entry":["START_DEVICE","Supported"]},{"entry":["STOP_DEVICE","Always succeed"]},{"entry":["SURPRISE_REMOVAL","Not currently supported"]},{"entry":"WRITE_CONFIG"},{"entry":["IRP_MN","Comments"]},{"entry":["POWER_SEQUENCE","Ignore the request and pass it"]},{"entry":["QUERY_POWER","to PDO."]},{"entry":"SET_POWER"},{"entry":"WAIT_WAKE"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"The device enumerator service uses the device and service connector DLL  to access the Ethernet bus driver The device enumerator service is provided as a Windows service, that is loaded by Windows at boot time.","The Ethernet bus driver is implemented as a non plug and play WDM driver. When the device enumerator service detects a new Ethernet hardware device  (using the enumeration method described above, for example), it notifies the Ethernet bus driver of the addition. Afterwards, the Ethernet bus driver creates an associated Physical Device Object (PDO) for the hardware device , and notifies the Windows plug and play (Plug and play) subsystem. The PDO implements an Ethernet bus driver-programming interface.","The Ethernet bus driver plays two Windows roles. First it is the function driver of the software bus abstraction. Table 2 shows the minor I\/O request packets (IRPs) it processes and how it processes them when acting as function driver. The Ethernet bus driver also acts as the Physical Device Object (PDO) on top of which the Ethernet device function drivers connect. When acting as PDO, the driver processes Plug and play requests as presented in Table 3.",{"@attributes":{"id":"p-0311","num":"0321"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Ethernet bus driver FDO functions"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Minor IRPs","Comment"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["CANCEL_REMOVE_DEVICE","Indicate success and pass"]},{"entry":["CANCEL_STOP_DEVICE","request to PDO."]},{"entry":["DEVICE_USAGE","Not currently supported"]},{"entry":"NOTIFICATION"},{"entry":"EJECT"},{"entry":"FILTER_RESOURCE"},{"entry":"REQUIREMENTS"},{"entry":"QUERY_BUS_INFORMATION"},{"entry":["QUERY_CAPABILITIES","Add the following capabilities"]},{"entry":[{},"before passing it down:"]},{"entry":[{},"Remove the following"]},{"entry":[{},"capabilities after the lower"]},{"entry":[{},"device completes the request:"]},{"entry":[{},"DeviceD1"]},{"entry":[{},"DeviceD2"]},{"entry":[{},"Device D3"]},{"entry":[{},"LockSupported"]},{"entry":[{},"EjectSupported"]},{"entry":[{},"Removable"]},{"entry":[{},"DockDevice"]},{"entry":[{},"RawDeviceOK"]},{"entry":[{},"SurpriseRemovalOK"]},{"entry":[{},"WarmEjectSupported"]},{"entry":[{},"WakeFromD0"]},{"entry":[{},"WakeFromD1"]},{"entry":[{},"WakeFromD2"]},{"entry":[{},"WakeFromD3"]},{"entry":[{},"DeviceState array items are"]},{"entry":[{},"all set to D0"]},{"entry":["QUERY_DEVICE_RELATIONS","Support:"]},{"entry":[{},"BusRelations"]},{"entry":[{},"Pass to lower driver:"]},{"entry":[{},"EjectionRelations"]},{"entry":[{},"RemovalRelations"]},{"entry":["QUERY_DEVICE_TEXT","Not currently supported"]},{"entry":"QUERY_ID"},{"entry":"QUERY_INTERFACE"},{"entry":"QUERY_LEGACY_BUS"},{"entry":"INFORMATION"},{"entry":["QUERY_PLUG AND","Supported"]},{"entry":"PLAY_DEVICE_STATE"},{"entry":["QUERY_REMOVE_DEVICE","Failed if one or more devices"]},{"entry":[{},"are connected."]},{"entry":["QUERY_RESOURCE","Not currently supported"]},{"entry":"REQUIREMENTS"},{"entry":"QUERY_RESOURCE"},{"entry":["QUERY_STOP_DEVICE","Failed if one or more devices"]},{"entry":[{},"are connected"]},{"entry":["READ_CONFIG","Not currently supported"]},{"entry":["REMOVE_DEVICE","Always succeed. Delete the FDO."]},{"entry":["SET_LOCK","Not currently supported"]},{"entry":["START_DEVICE","Supported"]},{"entry":["STOP_DEVICE","Always succeed"]},{"entry":["SURPRISE_REMOVAL","Not currently supported"]},{"entry":"WRITE_CONFIG"},{"entry":["POWER_SEQUENCE","Not currently supported"]},{"entry":["QUERY_POWER","Always accepted"]},{"entry":["SET_POWER","Always succeed"]},{"entry":["WAIT_WAKE","Not currently supported"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"It will be noted that the function driver object (FDO) handling of the minor IRP types defined by Windows is specified in Table 2 above.","It should also be noted that the Table 3 shows the Ethernet bus driver's handling of the minor IRPs in relation to its role as the primary PDO.",{"@attributes":{"id":"p-0314","num":"0324"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 3"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Ethernet bus driver PDO functions"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Minor IRPs","Comment"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["CANCEL_REMOVE_DEVICE","Complete the request indicating"]},{"entry":["CANCEL_STOP_DEVICE","a success."]},{"entry":["DEVICE_USAGE","Not currently supported"]},{"entry":"NOTIFICATION"},{"entry":["EJECT","Complete the request indicating"]},{"entry":[{},"a success."]},{"entry":["FILTER_RESOURCE","Not currently supported"]},{"entry":"REQUIREMENTS"},{"entry":["QUERY_BUS_INFORMATION","Complete the request indicating"]},{"entry":[{},"a success. The following"]},{"entry":[{},"information are returned:"]},{"entry":[{},"the GUID associated with"]},{"entry":[{},"the Ethernet bus;"]},{"entry":[{},"the INTERFACE TYPE of the"]},{"entry":[{},"Ethernet bus controller;"]},{"entry":[{},"the Ethernet bus number;"]},{"entry":["QUERY_CAPABILITIES","Add the following capabilities:"]},{"entry":[{},"EjectSupported"]},{"entry":[{},"Removable"]},{"entry":[{},"UniqueID"]},{"entry":[{},"SurpriseRemovalOK"]},{"entry":[{},"WarmEjectSupported"]},{"entry":[{},"Remove the following"]},{"entry":[{},"capabilities:"]},{"entry":[{},"DeviceD1"]},{"entry":[{},"DeviceD2"]},{"entry":[{},"LockSupported"]},{"entry":[{},"DockDevice"]},{"entry":[{},"RawDeviceOK"]},{"entry":[{},"WakeFromD0"]},{"entry":[{},"WakeFromD1"]},{"entry":[{},"WakeFromD2"]},{"entry":[{},"WakeFromD3"]},{"entry":[{},"DeviceState array items are"]},{"entry":[{},"all set to D0"]},{"entry":["QUERY_DEVICE_RELATIONS","Support:"]},{"entry":[{},"EjectionRelations"]},{"entry":[{},"RemovalRelations"]},{"entry":[{},"TargetDeviceRelation"]},{"entry":["QUERY_DEVICE_TEXT","Supported"]},{"entry":["QUERY_ID","Supported. The device ID is"]},{"entry":[{},"built from data received from"]},{"entry":[{},"Ethernet Device at enumeration."]},{"entry":[{},"The instance ID is built with"]},{"entry":[{},"the Ethernet address and the sub"]},{"entry":[{},"device ID. A special Ethernet"]},{"entry":[{},"Device is used for a driver not"]},{"entry":[{},"associated with a hardware"]},{"entry":[{},"device."]},{"entry":["QUERY_INTERFACE","Not currently supported"]},{"entry":"QUERY_LEGACY_BUS"},{"entry":"INFORMATION"},{"entry":["QUERY_PLUG AND","Supported. The following bits"]},{"entry":["PLAY_DEVICE_STATE","are never set:"]},{"entry":[{},"PLUG AND"]},{"entry":[{},"PLAY_DEVICE_DISABLED"]},{"entry":[{},"PLUG AND"]},{"entry":[{},"PLAY_DEVICE_DONT"]},{"entry":[{},"DISPLAY_IN_UI"]},{"entry":[{},"PLUG AND"]},{"entry":[{},"PLAY_DEVICE_RESOURCE"]},{"entry":[{},"REQUIREMENTS_CHANGED"]},{"entry":["QUERY_REMOVE_DEVICE","Always succeed"]},{"entry":["QUERY_RESOURCE","Complete the request without"]},{"entry":["REQUIREMENTS","changing IRP."]},{"entry":["QUERY_RESOURCES","Complete the request without"]},{"entry":[{},"changing IRP."]},{"entry":["QUERY_STOP_DEVICE","Always succeed"]},{"entry":["READ_CONFIG","Not currently supported"]},{"entry":["REMOVE_DEVICE","Always succeed. Delete the PDO."]},{"entry":["SET_LOCK","Not currently supported"]},{"entry":["START_DEVICE","Always succeed"]},{"entry":"STOP_DEVICE"},{"entry":"SURPRISE_REMOVAL"},{"entry":["WRITE_CONFIG","Not currently supported"]},{"entry":["POWER_SEQUENCE","Not currently supported."]},{"entry":["QUERY_POWER","Accept all changes in system"]},{"entry":[{},"power state. Refuse all changes"]},{"entry":[{},"in device power state."]},{"entry":["SET_POWER","Always succeed"]},{"entry":["WAIT_WAKE","Not currently supported"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"The Ethernet bus driver publishes a numbered symbolic name. An application or a class installer can connect to the Ethernet bus driver using the numbered symbolic name for viewing and editing settings, to prompt Windows to load a plug and play driver, or to retrieve information about loaded plug and play drivers.","The processing unit is embodied as a start image executable file . When it is invoked without arguments it becomes an IDLE ProcessingUnit, and accordingly is an item in the ListHead. The programmer can also execute it with the name of a DLL file, in which case, the native process becomes a RUNNING ProcessingUnit. In accordance with the current implementation, a part of the distributed memory manager's functions are provided in the start image executable , these functions include:\n\n","All functions of the distributed process are provided by files in a DLL. The DLL complies with the interface defined by the ProcessingUnit start image.","The distributed process can access all system resources, including those that are native to the processor node. The user mode application programmer must maintain a distinction between shared resources (those which can be invoked from any processor node) and the native resources which are only available at a respective processor node . If a distributed process connects to a native device driver, the connection cannot be \u201cshared\u201d. Connections to Ethernet device drivers and software device gateways are inherently sharable.","A distributed process creates the main process memory pool  immediately before the Process object is instantiated for the distributed process. A distributed memory DLL file  invoked to create the main process memory pool  provides links to distributed process image DLL functions for connecting to the main process memory pool, and for managing it. If needed, the distributed process can create the additional shared memory pools  that can be created or taken down depending on program instructions of the user mode application. The main memory pool, however remains until the end of the distributed process's execution. The creation of the additional shared memory pools  permits the sharing of data between different distributed processes. Furthermore the ability to create and take down the additional memory pools as needed reduces network communication loads, physical memory utilization, and virtual address space utilization.","If aggregation is used in the Windows XP implementation, the aggregator  is implemented as a non-plug and play WDM function driver that publishes a numbered symbolic name. The symbolic name is created using the aggregator's operational key. The aggregation managers  use this numbered symbolic name to connect to the aggregator . Applications or class installers can also connect to the aggregator  using the symbolic name for viewing and editing settings and retrieving status and statistical information. The aggregation manager  is implemented as a plug and play WDM function driver, and has a numbered symbolic name as well. Application or class installers can use this interface for viewing and editing settings, and retrieving status and statistics. Preferably the Ethernet bus drivers loads the respective aggregator manager instances on startup.","The aggregator managers configured using the same \u201caggregator operational key\u201d use this symbolic name to directly connect to the aggregator (or instance thereof).","LINUX","Having described the operation of the Windows implementation, a comparison with the LINUX implementation is set out below. While Windows natively supports the layered architecture presented in , operating systems such as Linux that do not support layered drivers require a modified architecture. An architecture for these operating systems is presented in . It will be noted that blocks of software functionality shown with corresponding reference numerals suffixed with \u2018b\u2019 rather than \u2018a\u2019 as, in , correspond and their descriptions are not necessarily repeated.","In Linux, the Ethernet bus driver does not manage plug and play, it only provides entities with a way to communicate locally and network wide. All plug and play related tasks and settings are moved to the device enumerator and plug and play manager server ","The bus adapter driver is responsible for controlling the NIC , and relaying Ethernet packets between the NIC  and the Ethernet bus driver The bus adapter driver is implemented as a character (char) Linux driver, rather than a network driver. It directly connects to the Ethernet bus driver using the symbolic name exported by the Ethernet bus driver.","The device and service connector is also implemented as a Linux char driver. It provides similar interfaces as that of the Windows implementation.","The device enumerator and plug and play manager server is responsible for enumerating devices and for loading needed loadable modules when devices are detected or when requested by configuration information. The Linux server provides plug and play support that facilitates changes to the connected members of the Ethernet bus.","Legacy network support is implemented as a Linux network driver. It connects directly to the Ethernet bus driver, whereas in the prior art, it connected to the native Linux bus support directly for effecting the control over the NIC.","Because the Linux kernel permits loadable modules to interact with the memory manager, the Linux implementation of the distributed memory driver handles more tasks than the Windows distributed memory driver In particular, the distributed memory driver is responsible for catching and processing page faults.","Ethernet device drivers are implemented as char drivers or block drivers, depending on a device type of the corresponding Ethernet device. The device enumerator and plug and play manager server always loads the Ethernet device drivers in the Linux implementation.","As shown in the illustrated embodiment, software Ethernet device gateway servers are implemented as Linux servers that connect to a top of the device and service connector char driver using device and service connector library shared object although in other embodiments software Ethernet device gateway servers may be implemented as a plug and play driver using kernel mode program instructions.","As with Windows, all of the, processing units begin by loading a start image executable file The main difference is that the implementation does not rely on Windows structured exceptions to catch page faults, which are effected by the distributed memory char driver ","The invention has therefore been described in relation to a method and system for effecting a network bus over a data network in order to selectively use OS functionality of processor nodes for managing hardware devices of the data network. The invention has further provided a distributed processing system that provides for the sharing of network resources among the processor nodes.","The embodiment(s) of the invention described above is(are) intended to be exemplary only. The scope of the invention is therefore intended to be limited solely by the scope of the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Further features and advantages of the present invention will become apparent from the following detailed description, taken in combination with the appended drawings, in which:",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIGS. 6 and 7"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIGS. 12 and 13"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIGS. 18 and 19"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIGS. 20","b":["21","22"]},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIGS. 24 and 25"},"FIGS. , and  are flow charts illustrating principal steps involved in PopItem, PushItem and notification handling methods of the ListHead object used to manage a queue of IDLE ProcessingUnits, in accordance with an embodiment of the invention;","FIGS. , and  are flow charts illustrating principal steps involved in ReadWriteMutex methods used to provide shared read locks on a data structure, in accordance with an embodiment of the invention;",{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 33"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 34"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 35"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 36"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 37"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 38"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIGS. 39-45"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 46"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 47"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 48"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 49"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 50"}]},"DETDESC":[{},{}]}
