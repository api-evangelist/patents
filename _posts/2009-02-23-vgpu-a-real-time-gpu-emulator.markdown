---
title: VGPU: a real time GPU emulator
abstract: An exemplary method for emulating a graphics processing unit (GPU) includes executing a graphics application on a host computing system to generate commands for a target GPU wherein the host computing system includes host system memory and a different, host GPU; converting the generated commands into intermediate commands; based on one or more generated commands that call for one or more shaders, caching one or more corresponding shaders in a shader cache in the host system memory; based on one or more generated commands that call for one or more resources, caching one or more corresponding resources in a resource cache in the host system memory; based on the intermediate commands, outputting commands for the host GPU; and based on the output commands for the host GPU, rendering graphics using the host GPU where output commands that call for one or more shaders access the one or more corresponding shaders in the shader cache and where output commands that call for one or more resources access the one or more corresponding resources in the resource cache. Other methods, devices and systems are also disclosed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08711159&OS=08711159&RS=08711159
owner: Microsoft Corporation
number: 08711159
owner_city: Redmond
owner_country: US
publication_date: 20090223
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["RELATED APPLICATIONS","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application is related to a U.S. Patent Application entitled \u201cContent based cache for graphics resource management\u201d, having Ser. No. 12\/361,216, filed on Jan. 28, 2009, which is hereby incorporated by reference.","A Graphics Processing Unit (GPU) provides special features for graphics rendering tasks on a computing device (e.g., a PC, a game console, etc.). Various types of GPUs exist and these types often vary in hardware architecture, functionalities and performance. These differences can complicate development of graphics applications as a developer typically wants a graphics application to produce the same rendering results in about the same amount of time regardless of the GPU used.","To assess rendering results and performance, a developer normally \u201cports\u201d an application from one platform to another to test different GPUs and even different CPUs or CPU-GPU combinations. When an application is expected to perform on many types of GPU, porting can be a time consuming process. Various exemplary techniques described herein allow for real time emulation of a target GPU and can be used to assess results and performance of a graphics application without physically porting the application to a computing platform with the actual target GPU.","An exemplary method for emulating a graphics processing unit (GPU) includes executing a graphics application on a host computing system to generate commands for a target GPU where the host computing system includes host system memory and a different, host GPU; converting the generated commands into intermediate commands; based on one or more generated commands that call for one or more shaders, caching one or more corresponding shaders in a shader cache in the host system memory; based on one or more generated commands that call for one or more resources, caching one or more corresponding resources in a resource cache in the host system memory; based on the intermediate commands, outputting commands for the host GPU; and based on the output commands for the host GPU, rendering graphics using the host GPU where output commands that call for one or more shaders access the one or more corresponding shaders in the shader cache and where output commands that call for one or more resources access the one or more corresponding resources in the resource cache. Other methods, devices and systems are also disclosed.","Overview","An exemplary GPU emulation framework, referred to as a virtual GPU (VGPU), can emulate functionality of a specific, target GPU on a computing platform that has a different GPU. As explained, the VGPU can emulate a target graphics subsystem at the binary level to provide for portability and compatibility testing with real time performance. When compared to API level porting or emulation, the exemplary VGPU approach operates without requiring any special porting work from a graphics application developer.","An exemplary VGPU system emulates target or \u201cguest\u201d graphics commands using a host CPU and a host GPU. The VGPU's inputs are groups of low level graphics commands generated by a host CPU or guest CPU at run-time. For example, a guest CPU can be emulated using a guest CPU just-in-time (JIT) emulator executing on the host CPU at run-time. Whether from a host CPU or a guest CPU, the VGPU parses emitted graphics commands and converts them to intermediate representations. In essentially concurrent operation, the shader and other graphics resources (e.g., vertex and texture data) are loaded and converted from guest GPU formats to host GPU formats. The graphics resources and shaders are correctly linked and packed in a commands stream for the host GPU. The VGPU executes intermediate representations (e.g., graphics commands) in the form of host graphics commands on the host platform (e.g., using the host GPU and\/or the host CPU).","The real time performance of the VGPU is achieved mainly by two caches, one for shaders and one for graphics resources. The two caches store various graphics resources that can reused, to avoid time consuming shader compilation and resource conversion. By efficiently utilizing the host CPU and the host GPU, the VGPU can achieve real time performance with reasonable memory overhead.",{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 1","FIG. 1","FIG. 1"],"b":["100","105","110","120","150","180","110","114","118","150","110","150","160","164","154","168","150"]},"Given the arrangement of , when the application  executes on the CPU , it generates low level graphics commands and transmits them in one or more packed command buffers  to the GPU . At essentially the same time, the application code also creates or loads the graphics resources (e.g., per commands ) and shaders (e.g., per commands ) into memory of the GPU . The GPU  parses the command buffers, loads the graphics data and then performs the corresponding rendering tasks.","With respect to the porting examples , a developer or equipment manufacturer may wish to assess rendering results and performance of an application using various hardware. The examples  show an application on a platform with CPU A and GPU A being ported to a platform with CPU A and GPU B, a platform with CPU B and GPU B and a platform with CPU B and GPU A. Techniques described herein can perform any of these porting examples using a platform such as CPU A and GPU A, which is referred to as the host platform. Where an exemplary VGPU framework is used, the target CPU or target GPU are referred to as a guest CPU or a guest GPU, respectively. As discussed herein, the exemplary VGPU framework executes on a host CPU using memory resources of the host platform to ultimately render graphics using a host GPU where the VGPU framework emulates a guest CPU, a guest GPU or a guest CPU and guest GPU. In various examples, the VGPU is shown for emulating a guest GPU while a component of the VGPU framework is shown for emulating a guest CPU (e.g., a just-in-time component or \u201cjitter\u201d).","With respect to emulation, the arrangement of  poses several challenges. First, in a conventional system, all the hardware graphics features can be exposed to a developer (e.g., as on game console). In another words, a game developer can directly access hardware. Second, as GPU command buffers are generated at run-time, it is hard to retrieve the command buffers by static pre-parsing approaches. Given such conditions, a pre-compilation to GPU emulation is not practical.","While  shows one conventional arrangement, others exist. Further, architecture of guest graphics system and host graphics system can be different. For example, the XBOX360\u00ae and XBOX\u00ae (Microsoft Corporation, Redmond, Wash.) use a unified memory architecture where a CPU and a GPU share the same memory. In contrast, most PC systems use non-UMA architecture, where graphics resources need to be copied from main system memory to GPU memory. These architectural aspects can be accounted for by resource management in an exemplary VGPU framework.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 2","FIG. 1","FIG. 2"],"b":["160","164","150","110"]},"A general goal of any type of rendering is to minimize or avoid bottlenecks. However, if such bottlenecks are specific to a particular GPU, emulation should capture them. In emulation, techniques should not compound or inadvertently create bottlenecks that may exist for a target GPU. As described herein, via appropriate memory techniques, an exemplary VGPU also aims to minimize or avoid bottlenecks that would not exist but for the VGPU.","With respect to the CPU part, many applications are CPU bound, for example, due to complex physics or AI, and sometimes because of poor batching or resource management. The purpose of CPU porting (see, e.g., porting examples  of ) is to test rendering results and performance of an application on a different CPU. An exemplary VGPU framework does not aim to optimize a guest CPU but rather maintain its pros and cons while executing a graphics application. Hence, for proper assessment, issues that may exist in communication (e.g., commands, content, etc.) between a guest CPU and a GPU should be maintained during emulation of the guest CPU.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 3","b":["301","350","301","310","320","430","340","320","340","350","350","350","350"]},"In , the API\/runtime layer  provides a relatively uniform manner to expose certain GPU functionality. However, it does not \u201cemulate\u201d a GPU but rather abstracts functionality that may be available on various GPUs.","In the architecture , commands are delivered to the pipeline  via a memory buffer in which it is possible to append commands. Commands are either of two classes: those that allocate or free resources and those that alter pipeline state. Accordingly, each API command calls through the runtime to the driver  to add hardware-specific translation of the command to the buffer. The buffer is transmitted to the GPU hardware  when it is full or when another operation requires the rendering state to be synchronized (e.g., reading the contents of a render target).","In the example of , the pipeline  corresponds to that of the Direct3D\u00ae10 framework (e.g., Direct3D\u00ae API\/runtime) (Microsoft Corporation, Redmond, Wash.). In the Direct3D\u00ae10 framework, a user may create programmable shaders for the pipeline using the High Level Shading Language (HLSL). HLSL is to the Direct3D\u00ae framework as the GLSL shading language is to the OpenGL\u00ae framework (Silicon Graphics, Inc., Mountain View, Calif.). Further, HLSL shares aspects of the NVIDIA\u00ae Cg shading language (NVidia Corporation, Fremont, Calif.).","In general, the stages of the framework pipeline  can be configured using the Direct3D\u00ae API. Stages featuring common shader cores (the rounded rectangular blocks ,  and ) are programmable using the HLSL programming language, which makes the pipeline  flexible and adaptable. HLSL shaders can be compiled at author-time or at runtime, and set at runtime into the appropriate pipeline stage. In general, to use a shader, a process compiles the shader, creates a corresponding shader object, and sets the shader object for use. The purpose of each of the stages is listed below.","Input-Assembler Stage \u2014The input-assembler stage  is responsible for supplying data (triangles, lines and points) to the pipeline .","Vertex-Shader Stage \u2014The vertex-shader stage  processes vertices, typically performing operations such as transformations, skinning, and lighting. A vertex shader takes a single input vertex and produces a single output vertex.","Geometry-Shader Stage \u2014Conventionally, the geometry-shader stage  processes entire primitives where its input is a full primitive (which is three vertices for a triangle, two vertices for a line, or a single vertex for a point). In addition, each primitive can also include the vertex data for any edge-adjacent primitives, which may include at most an additional three vertices for a triangle or an additional two vertices for a line. The geometry shader stage  also supports limited geometry amplification and de-amplification. Given an input primitive, the geometry shader stage  can discard the primitive, or emit one or more new primitives.","Stream-Output Stage \u2014The stream-output stage  is designed for streaming primitive data from the pipeline to memory on its way to a rasterizer. Data can be streamed out and\/or passed into a rasterizer. Data streamed out to memory  can be recirculated back into the pipeline  (e.g., as input data or read-back from a CPU).","Rasterizer Stage \u2014The rasterizer stage  is responsible for clipping primitives, preparing primitives for the pixel shader and determining how to invoke pixel shaders.","Pixel-Shader Stage \u2014The pixel-shader stage  receives interpolated data for a primitive and generates per-pixel data such as color.","Output-Merger Stage \u2014The output-merger stage  is responsible for combining various types of output data (pixel shader values, depth and stencil information) with the contents of the render target and depth\/stencil buffers to generate the final pipeline result.","Conventionally, at a very high level, data enter the graphics pipeline  as a stream of primitives that are processed by up to as many as three of the shader stages:","The vertex shader stage  performs per-vertex processing such as transformations, skinning, vertex displacement, and calculating per-vertex material attributes. Conventionally, tessellation of higher-order primitives should be done before the vertex shader stage  executes. As a minimum, a vertex shader stage  must output vertex position in homogeneous clip space. Optionally, the vertex shader stage  can output texture coordinates, vertex color, vertex lighting, fog factors, and so on.","Conventionally, the geometry shader stage  performs per-primitive processing such as material selection and silhouette-edge detection, and can generate new primitives for point sprite expansion, fin generation, shadow volume extrusion, and single pass rendering to multiple faces of a cube texture.","The pixel shader stage  performs per-pixel processing such as texture blending, lighting model computation, and per-pixel normal and\/or environmental mapping. Pixel shaders of the pixel shader stage  work in concert with vertex shaders of the vertex shader stage ; conventionally, the output of the vertex shader stage  provides the inputs for the pixel shader stage .","In addition to allowing access to whole primitives, the geometry shader stage  can create new primitives on the fly. Specifically, the geometry shader in Direct3D\u00ae10 can read in a single primitive (with optional edge-adjacent primitives) and emit zero, one, or multiple primitives. As shown in the pipeline of , the output from the geometry shader stage  may be fed to the rasterizer stage  and\/or to a vertex buffer in memory  via the stream output stage . Output fed to memory  can be expanded to individual point\/line\/triangle lists (e.g., in a manner as they would be passed to the rasterizer stage ).","The geometry shader stage  outputs data one vertex at a time by appending vertices to an output stream object of the stream output stage . The topology of the streams is typically determined by a fixed declaration, choosing one of: PointStream, LineStream, or TriangleStream as the output for the geometry shader stage . In Direct3D\u00ae10, there are three types of stream objects available, PointStream, LineStream and TriangleStream which are all templated objects. The topology of the output is determined by their respective object type, while the format of the vertices appended to the stream is determined by the template type. Execution of a geometry shader instance is atomic from other invocations, except that data added to the streams is serial. The outputs of a given invocation of a geometry shader of the geometry shader stage  are independent of other invocations (though ordering is respected). Conventionally, a geometry shader generating triangle strips will start a new strip on every invocation.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 4","FIG. 3"],"b":["303","400","150","350","400","150","320","400","320","400","400","320","400"]},"The VGPU emulator  includes a command processor , a draw engine , a shader management module  that manages a shader cache , and a resource management module  that manages a resource cache . The VGPU emulator  is typically present as a framework on a host computing device for execution on a host CPU. As described herein, the VGPU emulator  may be invoked as desired to emulate a guest GPU. As mentioned, in general, the VGPU framework includes one or more components for emulating a guest CPU. Hence, an exemplary VPGU framework can emulate the various porting examples  of .","The VGPU emulator  emulates a GPU at the binary level. The inputs of VGPU are the low level command buffers, shaders and graphics resources generated by the application  code at run-time. In this particular example, to allow the VGPU emulator  to operate on different hardware, the host-side GPU graphics command execution can be handled using the Direct3D\u00ae API\/runtime ; noting that OpenGL\u00ae or other framework may be used to achieve some degree of hardware agnostics. In other words, that although the Direct3D\u00ae interface is referred to for VGPU to host GPU rendering tasks, the exemplary design is flexible and may use other host execution solutions, such as OpenGL\u00ae, host GPU direct low level graphics commands execution, or even software rendering using a host CPU. In such examples, the architecture  would differ accordingly at the API\/runtime layer .","In the VGPU emulator , the command processor  parses low level graphics commands and generates intermediate VGPU commands. The draw engine  receives the intermediate VGPU commands and then generates the resulting host Direct3D\u00ae calls, which are used to drive the host GPU for rendering. The draw engine  also drives resource management  and shader management  to translate a guest GPU graphics data to host Direct3D\u00ae resource and shaders. Logic for the VGPU emulator  generally runs on a host CPU. As discussed herein, careful design and implementation are keys to VGPU performance as run-time resource conversion and creation are expensive tasks.","The exemplary VGPU emulator  of  maintains the original interface between a CPU and a guest GPU where all graphics features can be supported host side without awareness from guest side.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 5","FIG. 4","FIG. 5","FIG. 1"],"b":["500","310","345","400","404","408","407","430","440","404","408","404","408","400","400","404","400","315","180"]},"As shown in the example of , the command\/general management layer  includes a command processor module  (front-end), a VGPU commands module  and a draw engine\/shader\/resource management module  (back-end); the shader management layer  includes a shader cache lookup module  (front-end), a shader cache  and a shader compiler  (back-end); and the resource management layer  includes a resource cache lookup module  (front-end), a resource cache  and a resource conversion module  (back-end).","To arrive at the rendered result , the guest CPU jitter on the host CPU  executes the application  and transmits low level graphics commands to a command buffer (see, e.g., the packed commands  of  and the commands of the GPU video memory  of ). In this regard, the emulation framework, per the arrangement , handles the low level graphic commands as being directed to the VGPU  and not directly to a GPU (or to a conventional API abstraction layer of a GPU).","Once generated, the commands are received by the command processor  of the VGPU front-end  in the command\/general management layer , for example, as being present in a command buffer (e.g., a buffer that may batch various commands). In turn, the command processor  parses the input command buffer and generates intermediate VGPU commands , which are independent of both the host system and the guest system. In other words, in the example of , the VGPU command processor  relies on an intermediate representation that can adequately represent the intent of input commands in a manner suitable for further processing, for example, by the draw engine , which is configured to output commands to the host GPU  (e.g., optionally via an API).","As indicated in , the guest CPU jitter  also generates shader related actions. These actions may be directly routed to the front-end  shader cache lookup module  in the shader management layer . In another manner, a shader cache lookup module  may receive calls from the command parser , for example, to determine if a shader or shaders are called for in producing the rendered result . If the command parser  calls for a shader cache lookup by the module  and a corresponding shader is not in the shader cache , then the front-end  of the VGPU  is responsible for accessing the shader or shader commands (e.g., optionally shader code) and transferring the shader or compiling the shader via the shader compiler  and placing the shader in the shader cache , which becomes accessible by the back-end  of the VGPU .","As indicated in , the guest CPU jitter  also generates resource related actions. These actions may be directly routed to the front-end  resource cache lookup module  in the resource management layer . In another manner, a resource cache lookup module  may receive calls from the command parser , for example, to determine if a resource or resources are called for in producing the rendered result . If the command parser  calls for a resource cache lookup by the module  and a corresponding resource (e.g., a texture) is not in the resource cache , then the front-end  of the VGPU  is responsible for accessing the resource or resource commands (e.g., optionally code) and transferring the resource or creating the resource, converting the resource via the resource conversion module , if required, and placing the resource in the resource cache , which becomes accessible by the back-end  of the VGPU .","In the VGPU , a dotted line between the shader management layer  and the draw engine\/general management module  and a dotted line between the shader management layer  and the draw engine\/general management module  indicate that the module  coordinates output of commands for rendering by the host GPU . Specifically, the module  at the back-end  receives VGPU commands (e.g., as in a command buffer) and generates host calls for the host GPU , which may be API calls for an interface that exposes functionality of the host GPU . The module  manages situations where a resource or a shader is not cached, for example, by invoking the resource conversion module  or the shader compiler  to create a new corresponding host resource or shader. Configured in such a manner, the VGPU allows for parallelization of VGPU tasks by utilizing multiple host CPU cores (see, e.g., cores  of the processing unit  of ).",{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 6","b":["600","680","690","600"]},"As described herein with respect to , cache performance is considered as being important. For example, consider two typical cache scenarios: (a) guest CPU write, then guest GPU reads for game resource loading and (b) guest GPU write, then guest GPU read, which is common in multiple-pass rendering. For scenario (a), the method  includes a guest CPU write block  followed by a guest GPU read block while for scenario (b), the method  includes a guest GPU write block  followed by a guest GPU read block .","The scheme  includes a content based CPU resource cache  and an address based GPU resource cache . In the context of the method , a guest CPU  places information in guest memory , which is subsequently written, via write block , to the content based CPU resource cache  associated with a VGPU (e.g., the VGPU ). The guest CPU  upon execution of code generates a command that is placed in a command buffer , which is accessible to the VGPU (i.e., the \u201cguest\u201d GPU). Upon a guest GPU read per block , the resource cache lookup module  initiates an appropriate lookup in the content based CPU resource cache  of the main resource cache  of the VGPU to access the content written per the guest CPU write block .","As mentioned, the cache scheme  includes a content based CPU resource cache  and an address based GPU resource cache . The content based cache  can cache resources generated by a guest CPU (e.g., from a DVD ROM, a hard disk or other memory) and rely on a content based method for cache lookup. The address based cache  caches resources as generated by a GPU, for example a frame buffer rendered by a GPU or some other buffer that is used by a GPU (e.g., a compute buffer), where the GPU relies on address for lookup. For example, a GPU can track a cached resource based on its address and the scheme  can ensure that an address range in memory is maintained (or otherwise monitored) to allow for addressed based cache access. In general, for a CPU, data integrity in memory is important and for applications that stream, it is possible to move a graphics resource into memory and then feed the graphics resource to the content based cache .","In the hybrid cache scheme , a content based cache  can be used to store VB, IB, and texture resources and implemented, for example, according to the method  where a CPU write occurs in block  and a GPU read occurs in block . For the example of , the resource key storage is reduced and lookup speed improved.","With respect to the address based cache , it may be used for resources generated by the GPU side, such as render to texture. The Least Recently Used (LRU) algorithm can be used to retire the cache content when the cache is full. The LRU aims to discard the least recently used items first, which typically correspond to resources of a frame for a scene not currently being rendered. The LRU algorithm can track what resources were used, for example, with respect to time and successively discard the least recently used resource. The LRU algorithm may keep \u201cage bits\u201d for cache-lines and track the \u201cLeast Recently Used\u201d cache-line based on age-bits. As described herein, a cache may be shared by multiple threads. Hence, a resource cache may be feed by one thread and read by another thread (e.g., shared by a front-end process and a back-end process). Such an approach further allows a host GPU to access resources (e.g., VGPU cache to host GPU cache) in an efficient manner, which facilitates emulation of a GPU in real time.","With respect to gaming, the hybrid scheme  in combination with an exemplary VGPU can facilitate emulation of legacy GPU behavior on a newer gaming platform. Such an approach takes advantage of scene behavior with respect to resource caching, which facilitates real time GPU emulation.","As described herein, an exemplary method for caching resources associated with a graphics application during emulation of a graphics processing unit (GPU) on a host computing system includes establishing a content based resource cache in memory of the host computing system; establishing an address based resource cache in memory of the host computing system; upon execution of the graphics application by a CPU of the host computing system, writing a graphics resource to the content based cache based on a CPU instruction issued by the CPU of the host computing system; and upon rendering of graphics by a GPU of the host computing system, based at least in part on execution of the graphics application, reading a graphics resource from the address based cache based on a GPU instruction issued by the GPU of the host computing system. Such a method may further include writing a graphics resource generated by the GPU of the host computing system to the address based cache where the writing a graphics resource generated by the GPU may be part of a multi-pass rendering process.","An exemplary method can include writing a graphics resource to a content based cache based on a CPU instruction issued by the CPU of the host computing system that includes writing a graphics resource from a storage medium accessible by the host computing system. For example, the storage medium may be a removable storage medium (e.g., DVD, portable drive, etc.) or a remote storage medium accessed via a network. In a particular example, a storage medium includes graphics resources for a game and writing pertains to game loading.",{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 7","b":["700","701","705","709","750","790","702","705","701","701","703","701","704","701","701","708","750"]},"The host system memory  provides memory for storage of application code and\/or content  and memory for commands as in a command buffer . The host system memory  is accessible by the host CPU  and the VGPU . Further, upon invocation, the VGPU  establishes memory resources such as the shader cache  and the resource cache  in the host system memory . Not explicitly shown in  is memory of the host GPU , which may be memory such as that of the GPU  of  (e.g., video memory and caches).","In a particular rendering process, the VGPU  may receive commands via the command processor , generate intermediate VGPU commands  and perform shader management  and resource management  operations via a draw engine and general management module  to output commands to the API framework , which, in turn, instruct the host GPU  to render a result to a monitor .","As mentioned, the shader cache  may store a previously used shader and the resource cache  may store previously used and converted frame content and presently converted frame content. Where a particular shader or shaders are used repeatedly as content is rendered, the shader cache  facilitates real time GPU emulation by the VGPU . Similarly, where a particular resource or resources are used repeatedly as content is rendered, the resource cache  facilitates real time GPU emulation by the VGPU .",{"@attributes":{"id":"p-0070","num":"0069"},"figref":["FIG. 8","FIGS. 4 and 5","FIG. 8"],"b":["800","400"]},"In an issue block , the guest CPU issues the following commands (e.g., low level graphics commands) to a target GPU: Use Texture T, Use Shader S, Draw Object O, Use Texture T, Use Shader S, and Draw Object O. In a reception block , the VGPU front-end command processor receives the commands as issued by the guest CPU. In a parse block , the command processor of the front-end of the VGPU parses the received commands.","Once parsed, in a dispatch block , the command processor dispatches the commands to the appropriate modules of the VGPU or otherwise initiates appropriate action to handle the commands. In the example of , command processor dispatches commands to a shader cache module block  and a resource cache lookup block  of the front-end of the VGPU. In response, the shader cache lookup block  creates a cache item to hold shader S and the resource cache lookup block  creates two cache items to hold texture T and texture T.","The front-end command process also generates the following VGPU commands for the back-end of the VGPU: Translate Texture T to Host, Translate Shader S to Host, Draw Object O, Translate Texture T to Host, Use translated Shader S (as in cache per block ), and Draw Object O. In an instruction block , the back-end receives the VGPU commands. In turn, a back-end action block  acts such that the draw engine performs the commands, dispatchs a message to the shader compiler and the resource conversion module; the shader compiler compiles the shader S and places it into the shader cache as a cache item; and the resource conversion module converts the texture T and the texture T and places them into the resource cache as appropriate corresponding cache items. Hence, according to the method , the shader S is now in the shader cache  and the textures T and T are now in the resource cache .","If future commands issued by the guest CPU and received by the VGPU call for shader S, texture T or texture T, the VGPU can reuse the items in the shader cache  and\/or the resource cache , unless one or both caches have been purged due to operational constraints.","As already mentioned, the draw engine of the back-end of the VGPU issues commands to appropriately cause a host GPU to render the graphics per instructions of a graphics application. In various examples, the Direct3D\u00ae API framework is mentioned as an abstraction layer that exposes functionality of the host GPU; noting that other techniques may be used.","As described herein, an exemplary method for emulating a GPU (e.g., target or guest GPU) includes executing a graphics application on a host computing system to generate commands for a target GPU where the host computing system includes host system memory and a different, host GPU; converting the generated commands into intermediate commands (e.g., the intermediate commands intermediate the generated commands for the target GPU and commands for the host GPU); based on one or more generated commands that call for one or more shaders, caching one or more corresponding shaders in a shader cache in the host system memory; based on one or more generated commands that call for one or more resources, caching one or more corresponding resources in a resource cache in the host system memory; based on the intermediate commands, outputting commands for the host GPU (e.g., directly or to an interface that exposes functionality of the host GPU); and, based on the output commands for the host GPU, rendering graphics using the host GPU where output commands that call for one or more shaders access the one or more corresponding shaders in the shader cache and where output commands that call for one or more resources access the one or more corresponding resources in the resource cache. The foregoing method may rely on one or more processor-readable media that include processor-executable instructions for performing the converting, the cachings and the outputting. In such a method, the host computing system can include multiple processing cores configured to execute tasks of the method in parallel (e.g., two cores, with one directed primarily to front-end tasks such as CPU tasks and another directed primarily to back-end tasks such as GPU tasks).","In such a method, the one or more corresponding shaders can be converted shaders, converted for compatibility with the host GPU and the one or more corresponding resources can be converted resources, converted for compatibility with the host GPU.","As mentioned, a resource cache can include a content based resource cache and an address based resource cache where the content based cache caches a resource or resources based on a write command from a CPU, for example, for later access by a read command from a GPU and where the address based cache caches a resource or resources accessible by a read command from a GPU, for example, where the cached resource or resources were previously cached based on a write command from the GPU. While various caches are described with respect to a general host system memory architecture, other types of memory architectures may be suitable. For example, a custom architecture may account for CPU and GPU specifics to achieve greater performance (e.g., especially where a computing device includes multiple processor cores\/CPUs, multiple GPUs or multiple cores\/CPUs and multiple GPUs). Various techniques may also be applied entirely with CPU-based GPU emulation (e.g., where a computing device does not include a GPU). In such circumstances, memory architecture and caches may be structured to account for the lack of a \u201creal\u201d GPU.","As mentioned, a resource cache can cache one or more resources used to render a previous frame of graphics to expedite rendering a present frame of graphics.","As mentioned, execution of a graphics application may rely on a jitter, for example, where the jitter emulates a target CPU and where a host computing system includes a different, host CPU.","As described with respect to , in an exemplary method, generated commands can include a shader command, a texture command and a draw object command, where rendering renders an object using a host GPU responsive to a converted shader command, a converted texture command and a converted draw object command that renders the object, in part, by accessing a corresponding shader in a shader cache and by accessing a corresponding resources in a resource cache.","As described herein, an exemplary system for emulating execution of a graphics application on a target GPU includes one or more processors; memory; a host GPU; control logic to convert commands generated by execution of the graphics application to commands to instruct the host GPU to render graphics of the graphics application; control logic to convert a shader associated with a graphics application to a converted shader compatible with the host GPU; control logic to cache one or more converted shaders in a shader cache established in the memory and accessible to the host GPU; control logic to convert a resource associated with a graphics application to a converted resource compatible with the host GPU; and control logic to cache one or more converted resources in a resource cache established in the memory and accessible to the host GPU. Such a system may further include control logic to emulate a target processor using the one or more processors. Control logic may be in the form of processor-executable instructions and optionally stored on a storage medium accessible and readable by a computing device (e.g., computer, game unit, etc.).",{"@attributes":{"id":"p-0083","num":"0082"},"figref":["FIG. 9","FIG. 1"],"b":["900","180"]},"In a very basic configuration, computing device  typically includes at least one processing unit  and system memory . As indicated, the processing unit  may include multiple cores . As explained, an exemplary VGPU may execute processes in parallel to facilitate GPU emulation. Such parallel processing may rely on two or more cores. Various trials demonstrated that two cores could execute tasks in parallel to allow for real time emulation of a GPU. Depending on the exact configuration and type of computing device, system memory  may be volatile (such as RAM), non-volatile (such as ROM, flash memory, etc.) or some combination of the two. System memory  typically includes an operating system , one or more program modules , and may include program data . The operating system  include a component-based framework  that supports components (including properties and events), objects, inheritance, polymorphism, reflection, and provides an object-oriented component-based application programming interface (API), such as that of the .NET\u2122 Framework marketed by Microsoft Corporation, Redmond, Wash. The device  is of a very basic configuration demarcated by a dashed line . Again, a terminal may have fewer components but will interact with a computing device that may have such a basic configuration.","Computing device  may have additional features or functionality. For example, computing device  may also include additional data storage devices (removable and\/or non-removable) such as, for example, magnetic disks, optical disks, or tape. Such additional storage is illustrated in  by removable storage  and non-removable storage . Computer storage media may include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, or other data. System memory , removable storage  and non-removable storage  are all examples of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media may be part of device . Computing device  may also have input device(s)  such as keyboard, mouse, pen, voice input device, touch input device, etc. Output device(s)  such as a display, speakers, printer, etc. may also be included. These devices are well know in the art and need not be discussed at length here. An output device  may be a graphics card or graphical processing unit (GPU). In an alternative arrangement, the processing unit  may include an \u201con-board\u201d GPU. In general, a GPU can be used in a relatively independent manner to a computing device's CPU. For example, a CPU may execute a gaming application where rendering visual scenes occurs via a GPU without any significant involvement of the CPU in the rendering process. Examples of GPUs include but are not limited to the Radeon\u00ae HD 3000 series and Radeon\u00ae HD 4000 series from ATI (AMD, Inc., Sunnyvale, Calif.) and the Chrome 430\/440GT GPUs from S3 Graphics Co., Ltd (Freemont, Calif.). As described herein, a computing device may include multiple GPUs where an exemplary method relies on one or more of these GPUs. Further, one or more of such GPUs may be on-board (e.g., one-to-one correspondence with the number of CPUs or cores), independent or a combination of on-board and independent.","Computing device  may also contain communication connections  that allow the device to communicate with other computing devices , such as over a network. Communication connections  are one example of communication media. Communication media may typically be embodied by computer readable instructions, data structures, program modules, or other data forms. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media.","Although the subject matter has been described in language specific to structural features and\/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as example forms of implementing the claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF DRAWINGS","p":["Non-limiting and non-exhaustive examples are described with reference to the following figures:",{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":["FIG. 5","FIG. 4"]},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 7","FIGS. 4 and 5"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 8","FIGS. 4 and 5"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
