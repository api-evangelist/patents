---
title: High precision integer division using low precision hardware operations and rounding techniques
abstract: One or more embodiments of the invention set forth techniques to perform integer division using a floating point hardware unit supporting floating point variables of a certain bit size. The numerator and denominator are integers having a bit size that is greater than the bit size of the floating point variables supported by the floating point hardware unit. Error correcting techniques are utilized to account for any loss of precision caused by the floating point operations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08655937&OS=08655937&RS=08655937
owner: Nvidia Corporation
number: 08655937
owner_city: Santa Clara
owner_country: US
publication_date: 20090429
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["1. Field of the Invention","The present invention relates generally to computer arithmetic and more specifically to performing integer division using floating-point units.","2. Description of the Related Art","Many current computer processors do not incorporate integer division logic into the digital circuit design of their arithmetic logic units (ALUs) because integer division operations tend to be infrequent operations that do not justify the hardware expense to incorporate such logic. As such, integer division is typically implemented in software, utilizing algorithms that leverage arithmetic operations that are available in the ALU, such as addition, subtraction, multiplication, logical operations (AND, NOT, OR, XOR), and bit-shifting. For example, a classic \u201cshift and subtract\u201d algorithm for integer division utilizes only addition, subtraction, compare (i.e., AND operation) and shifting operations and mimics well-known long division techniques.",{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1A","b":["100","105","110","115","117","119","120","125","105","119","120"]},{"@attributes":{"id":"p-0007","num":"0006"},"figref":["FIG. 1B","FIG. 1A","FIG. 1B"],"b":["175","105","110","115","117","119","105","110","120","125","130","105","110","115","117","119"]},"In contrast, floating point division is an operation that is typically provided in the digital circuit design of floating point units (FPUs) of processors. As such, floating point division is often significantly faster than integer division because floating point division is implemented in the hardware while integer division is implemented at the software level. For example, certain commercial processors report that integer division in software for a 32 bit integer consumes 39 cycles while floating point division in hardware for a double precision float (64 bits) consumes only 20 cycles.","Depending upon the format used for floating point numbers in a computing system, integer division can be performed by converting the integers into the floating point format and then executing a floating point division in the FPU.  depicts various integer and floating point formats used in a typical computing system. Format  represents a single precision floating point in accordance with the IEEE 754 standard (hereinafter, also referred to as a \u201cfloat\u201d). As can be seen, the format of a float is subdivided into 3 sections: 1 bit is a sign bit, 8 bits represent the exponent, and 23 bits represents the mantissa or fractional value. The mantissa contains the digits of value in the float, in this case, 23 bits of precision (24 bits of precision, implicitly, in accordance with the IEEE 754 standard). As such, integer division can be performed on integers that utilize less then 24 bits, such as an 8 bit unsigned integer , by converting or casting the integers into floats (i.e., inserting the 8 bits into the mantissa) and executing the division as a floating point division through an FPU. The float result can be converted or cast back into an integer without loss of precision. However, a 64 bit unsigned integer  would not fit into the 24 bits of mantissa of float (see ). Specifically, 40 bits of precision would be lost if a 64 bit unsigned integer  was converted into a 32 bit float.","As the foregoing illustrates, what is needed in the art is a technique for performing higher precision (e.g., 64 bit) integer division operations with a low precision (e.g., 32 bit) hardware operation, such as a division operation in a floating point unit that only supports floating point formats (e.g., 32 bit float with 24 bits of precision, etc.) whose mantissas are significantly smaller than the bit size of the integers (e.g., 64 bits).","One or more embodiments of the present invention provide methods for performing higher precision integer division (e.g., 64 bit) with a low precision (e.g., 32 bit) hardware operation such as a division operation in a floating point unit. Such methods may be incorporated into a compiler to enable a programmer to write code including integer division that can then be compiled into an executable that can, for example, run in on a computing system that includes an FPU but does not include an ALU that performs integer division.","According to one embodiment of the present invention, a computer-implemented method for performing integer division between a numerator and a denominator on a processing unit that supports operations using variables of a first bit size, wherein the numerator and the denominator are integers having a second bit size that is greater than the first bit size, is disclosed herein: The method begins by subdividing the numerator into a plurality of equal sized partitions, wherein each partition has a third bit size, converting the denominator into a variable of the first bit size, dividing the numerator by the variable of the first bit size to obtain a current approximation of a current portion of a quotient, wherein the current approximation of the current portion of the quotient has the third bit size, subtracting a product of the current approximation of the current portion of the quotient and the denominator from the numerator to generate a subsequent numerator, wherein a fourth bit size of most significant bits associated with the subsequent numerator represents a bit overflow error value utilized to correct the first approximation of the first portion of the quotient, and storing the current approximation of the current portion of the quotient in a memory.","The method, according to one embodiment of the present invention, further continues by dividing the subsequent numerator by the variable of the first bit size to obtain a subsequent approximation of a subsequent portion of the quotient that has a bit size equal to the third bit size plus the fourth bit size, adding a number of most significant bits equal to the fourth bit size associated with the subsequent approximation to a number of least significant bits equal to the fourth bit size associated with the current approximation to generate a corrected current approximation of the current portion of the quotient, multiplying the subsequent approximation of the subsequent portion of the quotient with the denominator to obtain a product, and subtracting the product from the subsequent numerator to generate a next numerator, wherein the fourth bit size of most significant bits associated with the next numerator represents a bit overflow error value utilized to correct the subsequent approximation of the subsequent portion of the quotient.","The foregoing steps of dividing, adding, multiplying and subtracting are repeated, wherein, for each current iteration of the dividing, adding, multiplying and subtracting steps, the next numerator generated in the subtracting step of the immediately preceding iteration is used as the subsequent numerator in the dividing step of the current iteration, the subsequent approximation obtained in the dividing step of the current iteration is used as the subsequent approximation in the adding step of the current iteration, and the subsequent approximation obtained in the dividing step of the immediately preceding iteration is used as the current approximation of the adding step of the current iteration, until a total number of corrected approximations of portions of the quotient have been generated equal to the number of equal sized partitions included in the plurality of equal sized partitions.","One advantage of the disclosed method is that integer division can be performed more efficiently by using floating-point hardware relative to techniques that are performed solely in software (e.g., only utilizing integer-based operations offered in an ALU).","In the following description, numerous specific details are set forth to provide a more thorough understanding of the present invention. However, it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details. In other instances, well-known features have not been described in order to avoid obscuring the present invention.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 2","FIG. 2","FIG. 2"],"b":["200","202","204","205","202","205","206","207","207","208","202","206","205","214","207","216","207","218","220","221","207"]},"A multithreaded processing subsystem  is coupled to memory bridge  via a bus or other communication path  (e.g., a PCI Express, Accelerated Graphics Port, or HyperTransport link). In the embodiment of , multithreaded processing subsystem  is a graphics subsystem that delivers pixels to a display device  (e.g., a conventional CRT or LCD based monitor). Multithreaded processing subsystem  includes subsystem memory  and incorporates one or more parallel processors , each having its own floating point processor (FPU) . One such example of a multithreaded processing system  is NVIDIA's GeForce\u00ae 8 GPU, which has 128 processing cores (i.e., processors), with each core having its own FPU and a set of 1024 registers. Each cluster of 8 processing cores also has 16 KB of shared memory supporting parallel data access. Such an architecture is able to support up to 12,288 concurrent threads, with each thread having its own stack, registers (i.e., a subset of the 1024 registers in a processing core), program counter and local memory.","CPU  operates as the control processor of computer system , managing and coordinating the operation of other system components. In particular, CPU  can issue floating point operations for execution on the FPUs of parallel processors  within multithreaded processing subsystem . For example, when executing an application that includes a portion of highly parallelized and computationally expensive graphics processing code (e.g., including floating point operations, etc.), CPU  instructs multithreaded processing subsystem  to perform the instructions of the code portion in order to leverage parallel processors  and their corresponding FPUs .","System memory  includes an execution image of an operating system, a device driver , and original source code  that contains programming instructions that include integer division operations. In the context of the present description, code refers to any source code, human readable programming language code, or other computer code, instructions, and\/or functions that may be executed or compiled for execution on a processor. For example, in various embodiments, the code may be C code, C++ code, etc. In one embodiment, the original code  may include a language extension or library for a computer language (e.g., an extension or library for C, C++, etc.), for example, to support specialized functions, such as parallel processing in multithreaded processing system . Because original code  includes integer division operations and CPU  does not include an ALU that supports integer division directly on hardware, original code is transformed using translator component  of a compiler  to produce transformed code  that contains a set of instructions that perform integer division utilizing floating point operations. In one embodiment, transformed code  is represented in the same programming language used in original code  (e.g., C or C++, etc.). It should be recognized that alternative embodiments may utilize a translator that functions separately from the compiler  but whose function is similar to translator component . In other embodiments, compiler  may be included within device driver  that is configured to interface between original code , transformed code  and CPU  and to provide instructions for managing and coordinating the operation of multithreaded processing subsystem . Those with ordinary skill in the art will recognize that  is merely one exemplary embodiment of a computing system in which the inventions disclosed herein may be utilized and that any computing system architecture that does not support integer division in its ALUs and includes an accessible FPU can utilize the teachings herein.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIGS. 3A-3B","FIG. 1C"],"b":["300","305","310"]},"However, due to loss of precision caused by the use of lower precision (e.g., 32 bit) floating point operations to obtain Q1 in , Q1 may be an underestimation of the correct first 16 bits of the 64 bit quotient of N and D such that the subtraction in  results in a 2 bit error overflow, shown as xx  in  (i.e., Q1 is an underestimation such that the subtraction  does not properly clear the first 16 bits of N). To incorporate this 2 bit error overflow into the next iteration, as depicted in , this intermediary value of N is shifted 14 bits to the left, referred to in  as N, and utilized in the next iteration.","In the next iteration, the first 32 bits of Nare cast into a 32 bit float and, in , floating point operations on an FPU (i.e., taking the reciprocal of D and multiplying by N) are performed on the float representations of the first 32 bits of Nand D yielding a float value, Q2, that estimates the quotient of the first 32 bits of Ndivided by the first 32 bits of D to a precision of 24 bits. Because the mantissa of Q2 contains the bits of value, the first 18 bits of the mantissa of Q2 are taken as a concatenation of (1) an error adjustment for the last 2 bits of the first 16 bits of the 64 bit quotient of N and D, and (2) the subsequent next 16 bit portion (i.e., second 16 bits) of the 64 bit quotient of N and D, as shown in . Specifically, the first two bits of Q2 represent adjustment to bits  and  of the 64 bit quotient of N and D, if, bits  and  were underestimated in Q1 during the first iteration. Q2 (the first 18 bits) is then multiplied by D (all 64 bits) and the product is subtracted from N(all 64 bits) as shown in , yielding another intermediary value of N. Similar to the first iteration, Q2 may be an underestimation due to loss of precision in the lower precision floating point operation of  that results in a 2 bit error overflow, shown as yy . As depicted in , the intermediary value of N is shifted 16 bits to the left, referred to in  as N, and utilized in the next iteration. As shown in , two more iterations are performed ( and , respectively) to obtain 18 bits of the mantissa of Q3 (representing a concatenation of (1) a 2 bit error adjustment for the second 16 bits, and (2) the subsequent third 16 bits of the 64 bit quotient of N and D) and 18 bits of the mantissa of Q4 (representing a concatenation of (1) a 2 bit error adjustment for the third 16 bits, and (2) the subsequent fourth 16 bits of the 64 bit quotient of N and D). Similar to the previous iterations, subtraction step  of the last iteration  may result in a 2 bit error remainder, referred to as rr  in , due to the loss of precision in generating Q4. The final 64 bit quotient is generated, as shown in , by concatenating Q1, Q2, Q3 and Q4 in an overlapping manner so as to enable the upper 2 bits of Q2, Q3 and Q4, which represent error adjustments, to be added to the bottom 2 bits of Q1, Q2 and Q3 respectively. Additionally, if the 2 bit error remainder rr  is greater than zero, 1 is added to the final quotient, as depicted in  to adjust for such error.",{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 4","FIG. 4"]},"Similar to , as used in , the first 64 bit integer is N and represents the numerator and the second 64 bit integer is D and represents the denominator. The method begins at step , where a compiler  creates a 32 bit integer Dfrom the 32 most significant bits of 64 bit integer D (e.g., left bit shifting D until the most significant bit position contains the first 1 of the value of D). At step , compiler  converts Dto a 32 bit float and performs a floating point operation to calculate its reciprocal (1\/D). At step , compiler  copies the first 32 bits of N into a 32 bit integer, n1. At step , compiler  casts n1 into a float, n1, and at step , compiler  multiplies n1by 1\/D, yielding a float product, which compiler  then shifts 16 bits to the left (on a first iteration, and 18 bits on subsequent iterations) and casts back into a 32 bit integer Q1, at step . At step , compiler  multiplies Q1 by D (full 64 bits) and at step , compiler  subtracts the product from N (full 64 bits), the difference being retained as a new value for N. At step , compiler  shifts this new N 14 bits (on a first iteration, and 16 bits on subsequent iterations) to the left. At step , during a first iteration, compiler  places the first 16 bits of Q1 in the first most significant 16 bits of a 64 bit integer reserved for the final quotient value. In subsequent iterations of step , compiler  inserts the first 18 bits of Q1 into the 64 bit integer reserved for the final 64 bit quotient as follows: (1) the upper 2 bits of the 18 bits of Q1 are added to the bottom 2 bits of the 16 bit portion written to in the previous iteration, and (2) the remaining 16 bits of the 18 bits of Q1 are inserted as the subsequent upper 16 bit portion of the 64 bit integer. At step , if the iteration if less than 4, compiler  returns to step  to continue the process. If the fourth iteration has completed, then at step , compiler  adds 1 to the final 64 bit quotient if the fourth iteration resulted in a 2 bit error remainder (see, e.g., 2 bit error remainder rr  in ), and in step , compiler  bit shifts final 64 bit quotient value back right to compensate for the left bit shifting of D in order to create Din step , yielding the final 64 bit quotient for long division between 64 bit N and D.","The following Example further includes a C-based code used by a compiler when it encounters 64 bit integer division between N and D. It should be recognized that this Example reflects an embodiment of the invention that executes within an NVDIA GPU, and therefore includes functions (e.g., fsetround( ), etc.) specifically relating floating point instructions available in such NVIDIA GPU. It should be recognized that various bit shifting and other alternative general programming techniques used to manipulate bits between various types of variables may be used in embodiments and that the Example sets forth one potential code base:",{"@attributes":{"id":"p-0034","num":"0033"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"EXAMPLE"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"static UInt64 divide (UInt32 n1, UInt32 n0, UInt32 d1, UInt32 d0)"},{"entry":"{"},{"entry":"\u2003UInt32 order_d;"},{"entry":"\u2003UInt32 D;"},{"entry":"fesetround(FE_TOWARDZERO);"},{"entry":"\u2003\/*"},{"entry":"\u2003\u2009* Step 0: Get the most significant bits of the 64 bit"},{"entry":"\u2003\u2009* \u2003\u2003\u2003number (d1, d0) in a 32 bit integer. Also"},{"entry":"\u2003\u2009* \u2003\u2003\u2003calculate the bit position of the most"},{"entry":"\u2003\u2009* \u2003\u2003\u2003significant bit (the order of d1, d0)"},{"entry":"\u2003\u2009*\/"},{"entry":"\u2003UInt32 d;"},{"entry":"\u2003if (d1 != 0) {d = d1;}"},{"entry":"\u2003\u2003else {d = d0;}"},{"entry":"\u2003order_d = order(d);"},{"entry":"\u2003D = d << (31 \u2212 order_d);"},{"entry":"\u2003if (d1 != 0) {"},{"entry":"\u2003\u2003if (order_d != 31) {"},{"entry":"\u2003\u2003\u2003D += d0 >> (order_d + 1);"},{"entry":"\u2003\u2003\u2003order_d += 32;"},{"entry":"\u2003}"},{"entry":"\u2003\/*"},{"entry":"\u2003\u2009* Step 1: Calculate a single precision floating point"},{"entry":"\u2003\u2009* \u2003\u2003\u2003value lower than 1\/D, within relative"},{"entry":"\u2003\u2009* \u2003\u2003\u2003precision of 2**-22"},{"entry":"\u2003\u2009*\/"},{"entry":"fsetround(FE_TONEAREST);"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"119pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003Float fD ","= D;"]},{"entry":["\u2003Float f_D ","= 1.0f\/fD;"]},{"entry":["\u2003Float f _Dlowered ","= Lower(f_D);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"fsetround(FE_TOWARDZERO);"},{"entry":"\u2003\/*"},{"entry":"\u2003\u2009* Step 2: Left shift d1, d0 to get its most significant"},{"entry":"\u2003\u2009* \u2003\u2003\u2003bit a position 63"},{"entry":"\u2003\u2009*\/"},{"entry":"\u2003UInt32 1 = 64 \u2212 order_d;"},{"entry":"\u2003if (1 == 0) { \/* nothing *\/ )"},{"entry":"\u2003else {"},{"entry":"\u2003\u2003if (1 == 32) {"},{"entry":"\u2003\u2003\u2003d1 = d0;"},{"entry":"\u2003\u2003\u2003d0 = 0;"},{"entry":"\u2003\u2003} else {"},{"entry":"\u2003\u2003\u2003UInt32 r;"},{"entry":"\u2003\u2003\u2003if (1 < 32) {"},{"entry":"\u2003\u2003\u2003\u2003r = 32 \u2212 1;"},{"entry":"\u2003\u2003\u2003\u2003d1 = (d1 << 1) | (d0 >> r);"},{"entry":"\u2003\u2003\u2003\u2003d0 = (d0 << 1);"},{"entry":"\u2003\u2003\u2003} else {"},{"entry":"\u2003\u2003\u2003\u20031 = 1 \u2212 32;"},{"entry":"\u2003\u2003\u2003\u2003r = 32 \u2212 1;"},{"entry":"\u2003\u2003\u2003\u2003d1 = (d0 << 1)\u2032"},{"entry":"\u2003\u2003\u2003\u2003d0 = 0;"},{"entry":"\u2003\u2003\u2003}"},{"entry":"\u2003\/*"},{"entry":"\u2003\u2009* Get 3*24 bit representation of d, and forget all about d"},{"entry":"\u2003\u2009* afterwards to reduce register pressure."},{"entry":"\u2003\/*"},{"entry":"\u2003UInt32 a2 = (d1 >> 8);"},{"entry":"\u2003UInt32 a1 = (d1 << 16) | <d0 >> 16);"},{"entry":"\u2003UInt32 a0 = (d0 << 8);"},{"entry":"\u2003UInt32 q1 = 0, q0 = 0;"},{"entry":"\u2003\/*"},{"entry":"\u2003\u2009* Loop 4 times, deriving one 16 bit result digit per"},{"entry":"\u2003\u2009* iteration. The first iteration is handled a little bit"},{"entry":"\u2003\u2009* differently and can be peeled off in another"},{"entry":"\u2003\u2009* implementation."},{"entry":"\u2003\u2009* The first iteration leaves a 2 bit overflow area in the"},{"entry":"\u2003\u2009* two highest bits of n. It can be shown that due to the"},{"entry":"\u2003\u2009* inexact \u2018Dlowered\u2019 a value of at most 2 is left, which"},{"entry":"\u2003\u2009* is rounded up in the next iteration by yielding 2 bits"},{"entry":"\u2003\u2009* of prevision in the estimation of Q (because we are"},{"entry":"\u2003\u2009* using only about 16 and have about 21, there is ample"},{"entry":"\u2003\u2009* precision slack for this.)"},{"entry":"\u2003\u2009* Also note that the last two iterations can be done in 32"},{"entry":"\u2003\u2009* bit precision, so peeling off the last two can save some"},{"entry":"\u2003\u2009* more cycles in this algorithm. In case we do this"},{"entry":"\u2003\u2009* peeling, then the first two iterations can ignore"},{"entry":"\u2003\u2009* updating q1, saving even more cycles, and also saving"},{"entry":"\u2003\u2009* more registers because an increased prevision in q is"},{"entry":"\u2003\u2009* used with a decreased precision in n."},{"entry":"\u2003\u2009*\/"},{"entry":"\u2003for (UInt32 i = 0; i < 4; i++) {"},{"entry":"\u2003\u2003*\/"},{"entry":"\u2003\u2003\u2003* Step 3.i: Using floating point calculations with"},{"entry":"\u2003\u2003\u2003*\u2003\u2003\u2003\u2003rounding mode towards zero, calculate the"},{"entry":"\u2003\u2003\u2003*\u2003\u2003\u2003\u2003the highest 21 bits of the quotient: Note"},{"entry":"\u2003\u2003\u2003*\u2003\u2003\u2003\u2003that due to scaling of D and lowering of"},{"entry":"\u2003\u2003\u2003*\u2003\u2003\u2003\u2003the reciprocal of this scaled value,"},{"entry":"\u2003\u2003\u2003*\u2003\u2003\u2003\u2003f_Dlowered * n1 returns a value between"},{"entry":"\u2003\u2003\u2003*\u2003\u2003\u2003\u2003zero (inclusive) and two (exclusive). "},{"entry":"\u2003\u2003\u2003*\u2003\u2003\u2003\u2003Soan 8 bit digit can be split off by"},{"entry":"\u2003\u2003\u2003*\u2003\u2003\u2003\u2003multiplication with 128."},{"entry":"\u2003\u2003\u2003*\/"},{"entry":"\u2003\u2003\u2003Float fErr1 = n1;"},{"entry":"\u2003\u2003\u2003Float fQ1;"},{"entry":"\u2003\u2003\u2003if (i == 0) {"},{"entry":"\u2003\u2003\u2003\u2003fQ1 = fErr1 * f_Dlowered * ((1 << 15));"},{"entry":"\u2003\u2003\u2003}else {"},{"entry":"\u2003\u2003\u2003\u2003fQ1 = fErr1 * f_Dlowered * ((1 << 15) * 4);"},{"entry":"\u2003\u2003\u2003}"},{"entry":"\u2003\u2003\u2003UInt32 Q1 = (UInt32)fQ1;"},{"entry":"\u2003\u2003\/*"},{"entry":"\u2003\u2003\u2003* Step 4.i: n \u2212= Q1 * D"},{"entry":"\u2003\u2003\u2003*\/"},{"entry":"\u2003\u2003\u2003UInt32 Q12 = 2 * Q1;"},{"entry":"\u2003\u2003\u2003UInt32 s3 \u2002= UMUL24HI(Q12, a2) >> 8;"},{"entry":"\u2003\u2003\u2003UInt32 s21 = UMUL24HI(Q12, a1) >> 8;"},{"entry":"\u2003\u2003\u2003UInt32 s11 = UMUL24HI(Q12, a0) >> 8;"},{"entry":"\u2003\u2003\u2003UInt32 s20 = UMUL24LO(Q12, a2) & 0x00ffffff;"},{"entry":"\u2003\u2003\u2003UInt32 s21 = UMUL24LO(Q12, a1) & 0x00ffffff;"},{"entry":"\u2003\u2003\u2003UInt32 s1 = s10 + s11;"},{"entry":"\u2003\u2003\u2003UInt32 s2 = s20 + s21;"},{"entry":"\u2003\u2003\u2003s2 += s1 >> 24; s1 &= 0x00ffffff;"},{"entry":"\u2003\u2003\u2003UInt32 c1, c0;"},{"entry":"\u2003\u2003\u2003if (i == 0) {"},{"entry":"\u2003\u2003\u2003\u2003\/\/ << 16"},{"entry":"\u2003\u2003\u2003\u2003c1 = (s3 << 16) + (s2 >> 8);"},{"entry":"\u2003\u2003\u2003\u2003c0 = (s2 << 24) + (s1);"},{"entry":"\u2003\u2003\u2003} else {"},{"entry":"\u2003\u2003\u2003\u2003\/\/ << 14"},{"entry":"\u2003\u2003\u2003\u2003c1 = (s3 << 14) + (s2 >> 10);"},{"entry":"\u2003\u2003\u2003\u2003c0 = (s2 << 22) + (s1 >> 2);"},{"entry":"\u2003\u2003\u2003\u2003n1 \u2212= c1 + BORROW(n0, c0);"},{"entry":"\u2003\u2003\u2003\u2003n0 \u2212= c0;"},{"entry":"\u2003\u2003\u2003\/*"},{"entry":"\u2003\u2003\u2003* Step 5.i: Shift n and q, and shift Q1:"},{"entry":"\u2003\u2003\u2003*\/"},{"entry":"\u2003\u2003\u2003if (i == 0) {"},{"entry":"\u2003\u2003\u2003\u2003\/\/ << 14"},{"entry":"\u2003\u2003\u2003\u2003n1 = (n1 << 14) | (n0 >> 18);"},{"entry":"\u2003\u2003\u2003\u2003n0 = (n0 << 14);"},{"entry":"\u2003\u2003\u2003} else {"},{"entry":"\u2003\u2003\u2003\u2003\/\/ << 16"},{"entry":"\u2003\u2003\u2003\u2003n1 = (n1 << 16) | (n0 >> 16);"},{"entry":"\u2003\u2003\u2003\u2003n0 = (n0 << 16);"},{"entry":"\u2003\u2003\u2003}"},{"entry":"\u2003\u2003\u2003\u2003q1 = (q1 << 16) | (q0 >> 16);"},{"entry":"\u2003\u2003\u2003\u2003q0 = (q0 << 16);"},{"entry":"\u2003\u2003\u2003\u2003q1 += CARRY(q0, Q1);"},{"entry":"\u2003\u2003\u2003\u2003q0 += Q1;"},{"entry":"\u2003\u2003\u2003} \/\/ for loop"},{"entry":"\u2003\u2003\u2003\/*"},{"entry":"\u2003\u2003\u2003\u2009* Step 6: Round up error <= 1 in q by reconstructing"},{"entry":"\u2003\u2003\u2003\u2009* a shifted value of d from a."},{"entry":"\u2003\u2003\u2003\u2009*\/"},{"entry":"\u2003\u2003\u2003d1 = (a2 << 7) | (a1 >> 17);"},{"entry":"\u2003\u2003\u2003d0 = (a1 << 15) |(a0 >> 9);"},{"entry":"\u2003\u2003\u2003UInt32 error = n1 >= d1;"},{"entry":"\u2003\u2003\u2003q1 += CARRY(q0, error);"},{"entry":"\u2003\u2003\u2003q0 += error;"},{"entry":"\u2003\u2003\u2003\/*"},{"entry":"\u2003\u2003\u2003\u2009* Step 7: Right shift q as compensation for Step 2"},{"entry":"\u2003\u2003\u2003\u2009*\/"},{"entry":"\u2003\u2003\u2003UInt32 r = order_d;"},{"entry":"\u2003\u2003\u2003if (r == 0) { \/* nothing *\/ }"},{"entry":"\u2003\u2003\u2003else {"},{"entry":"\u2003\u2003\u2003\u2003if (r == 32) {"},{"entry":"\u2003\u2003\u2003\u2003\u2003q0 = q1;"},{"entry":"\u2003\u2003\u2003\u2003\u2003q1 = 0;"},{"entry":"\u2003\u2003\u2003\u2003} else {"},{"entry":"\u2003\u2003\u2003\u2003\u2003UInt32 1;"},{"entry":"\u2003\u2003\u2003\u2003\u2003if (r < 32) {"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u20031 = 32 \u2212 r;"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003q0 = (q0 >> r) | (q1 << 1);"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003q1 = (q1 >> r);"},{"entry":"\u2003\u2003\u2003\u2003\u2003} else {"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003r = r \u2212 32;"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003q0 = (q1 >> r);"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003q1 = 0;"},{"entry":"\u2003\u2003\u2003\u2003\u2003}"},{"entry":"\u2003\u2003\u2003\u2003}"},{"entry":"\u2003\u2003\u2003return (((UInt64)q1) << 32) | q0;"},{"entry":"}"},{"entry":"\/************** Supporting functions, structs, unions ************\/"},{"entry":"typedef struct { "}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["\u2003UInt32 ","mantissa : 23;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"98pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["\u2003UInt32 ","biased_exp : 9; ","\/\/ includes sign bit (0)"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} My_Float;"},{"entry":"typedef union {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003float ","fl;"]},{"entry":["\u2003My_Float ","mfl;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} Float_Conv;"},{"entry":"static UInt32 order(UInt32 n)"},{"entry":"{ "},{"entry":"\u2003Float_Conv conv;"},{"entry":"\u2003conv.fl = n;"},{"entry":"\u2003return conv.mfl.biased_exp \u2212 127;"},{"entry":"}"},{"entry":"static inline Float Lower(Float x)"},{"entry":"{ "},{"entry":"\u2003UInt32 *ip = (UInt32*)&x;"},{"entry":"\u2003*ip \u2212= 3;"},{"entry":"\u2003return x;"},{"entry":"}"},{"entry":"static int CARRY(UInt32 a, UInt32 b)"},{"entry":"{ "},{"entry":"\u2003return (a*b) < a;"},{"entry":"}"},{"entry":"static int BORROW(UInt32 a, UInt32 b)"},{"entry":"{ "},{"entry":"\u2003return (a\u2212b) > a;"},{"entry":"}"},{"entry":"static UInt32 UMUL24LO(UInt32 a, UInt32 b)"},{"entry":"{ "},{"entry":"\u2003return (a & 0x00ffffff) * (b & 0x00ffffff);"},{"entry":"}"},{"entry":"static UInt32 UMUL24HI(UInt32 a, UInt32 b)"},{"entry":"}"},{"entry":"\u2003return ((UInt64) (a & 0x00ffffff) * ((UInt64) (b * 0x00ffffff)) >> 16;"},{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"While the foregoing is directed to embodiments of the present invention, other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example, embodiments herein utilize a 2 bit error overflow under an assumption that underestimations are capped at 2. However, it should be recognized that bit error overflows in alternative embodiments may be more or less bits depending upon the cap of underestimations as a result of loss of precision. Similarly, embodiments herein have utilized a 32 bit floating point division operation as the low precision (e.g., 32 bit) operation that is available in hardware for use in higher precision (e.g., 64 bit) integer division. However, it should be recognized that, consistent with the teachings herein, any other available low precision operation available in hardware may be utilized, including, for example, a 32 bit integer division operation that is available in hardware. Similarly, the descriptions herein use 64 bit integers and 32 bit floating point variables in its embodiments, however, it should be recognized that the techniques disclosed herein may be used with any integer bit size that is greater than the bit size of the floating point variables used by the FPUs. Similarly, the descriptions herein depict the transformation of original code , written in the C language, into a sequence of instructions that are also expressed in the C language. However, it should be recognized that any level of code generated during the compilation process may be transformed using the techniques described herein, including any intermediary forms of code, assembly code and the like. It should further be recognized that any other computer programming language such as C++, Java, other object-oriented languages, other procedural language and any other languages may be utilized in alternative embodiments. While the foregoing description has described integer division transformations from a compiler's perspective, it should be recognized that the same transformations can be considered as being executed by a processor at run-time (in accordance with code transformations made by the compiler). Furthermore, it should be recognized that the techniques disclosed herein may also be utilized directly by application programmers rather than compilers.","In addition, aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program(s) of the program product define functions of the embodiments (including the methods described herein) and can be contained on a variety of computer-readable storage media. Illustrative computer-readable storage media include, but are not limited to: (i) non-writable storage media (e.g., read-only memory devices within a computer such as CD-ROM disks readable by a CD-ROM drive, flash memory, ROM chips or any type of solid-state non-volatile semiconductor memory) on which information is permanently stored; and (ii) writable storage media (e.g., floppy disks within a diskette drive or hard-disk drive or any type of solid-state random-access semiconductor memory) on which alterable information is stored. Such computer-readable storage media, when carrying computer-readable instructions that direct the functions of the present invention, are embodiments of the present invention.","In view of the foregoing, the scope of the present invention is determined by the claims that follow."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["So that the manner in which the above recited features of the present invention can be understood in detail, a more particular description of the invention, briefly summarized above, may be had by reference to embodiments, some of which are illustrated in the appended drawings. It is to be noted, however, that the appended drawings illustrate only typical embodiments of this invention and are therefore not to be considered limiting of its scope, for the invention may admit to other equally effective embodiments.",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 1B","FIG. 1A"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1C"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIGS. 3A-3B"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
