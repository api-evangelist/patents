---
title: Printer with audio/video localization
abstract: A multimedia printing device receives multimedia data, processes it, and outputs it, thereby enhancing the handling and use of such data. In an embodiment, the processed data are output in a variety of formats, including on video paper, through a multimedia broadcast, or a bar code pointer to a digital archive. In another embodiment, the multimedia printing device receives multimedia data and uses the data to perform multimedia and video localization on the peripheral devices that generate the multimedia data. In another embodiment, the multimedia printing device carries out commands to capture and process multimedia data, including by inserting multimedia objects into existing documents.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07415670&OS=07415670&RS=07415670
owner: Ricoh Co., Ltd.
number: 07415670
owner_city: Minato-Ku, Tokyo
owner_country: JP
publication_date: 20040330
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","BACKGROUND","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["The present application claims the benefit of U.S. Provisional Patent Application Ser. No. 60\/506,303 filed Sep. 25, 2003, entitled \u201cPrinter Including One or More Specialized Hardware Devices,\u201d and U.S. Provisional Patent Application 60\/506,302 filed on Sep. 25, 2003, entitled \u201cPrinter Including Interface and Specialized Information Processing Capabilities,\u201d each of which is hereby incorporated by reference in its entirety.","The present application is a continuation-in-part of the following co-pending U.S Patent Applications: application Ser. No. 10\/001,895, \u201c(Video Paper) Paper-based Interface for Multimedia Information,\u201d filed Nov. 19, 2001 now U.S. Pat. No. 7,263,659; application Ser. No. 10\/001,849, \u201c(Video Paper) Techniques for Annotating Multimedia Information,\u201d filed Nov. 19, 2001 now U.S. Pat. No. 7,263,671; application Ser. No. 10\/001,893, \u201c(Video Paper) Techniques for Generating a Coversheet for a paper-based Interface for Multimedia Information,\u201d filed Nov. 19, 2001 now U.S. Pat. No. 7,266,782; application Ser. No. 10\/001,894, \u201c(Video Paper) Techniques for Retrieving Multimedia Information Using a Paper-Based Interface,\u201d filed Nov. 19, 2001 now U.S. Pat. No. 7,149,957; application Ser. No. 10\/001,891, \u201c(Video Paper) Paper-based Interface for Multimedia Information Stored by Multiple Multimedia Documents,\u201d filed Nov. 19, 2001; application Ser. No. 10\/175,540, \u201c(Video Paper) Device for Generating a Multimedia Paper Document,\u201d filed Jun. 18, 2002; and application Ser. No. 10\/645,821, \u201c(Video Paper) Paper-Based Interface for Specifying Ranges CIP,\u201d filed Aug. 20, 2003; each of which is each hereby incorporated by reference in its entirety.","The present application is related to the following U.S Patent Applications: \u201cPrinter With Embedded Retrieval and Publishing Interface,\u201d to Hull et. al, filed Mar. 30, 2004, Ser. No. 10\/814,536; \u201cPrinter With Document-Triggered Processing,\u201d to Hull et. al, filed Mar. 30, 2004, Ser. No. 10\/814,580; \u201cPrinter User Interface,\u201d to Hart et. al, filed Mar. 30, 2004, Ser. No. 10\/814,700; \u201cUser Interface for Networked Printer,\u201d to Hart et. al, filed Mar. 30, 2004, Ser. No. 10\/814,500; \u201cMultimedia Print Driver Dialog Interfaces,\u201d to Hull et. al, filed Mar. 30, 2004, Ser. No. 10\/814,944; and application Ser. No. 10\/754,907, and \u201cGenerating and Displaying Level-Of-Interest Values\u201d, filed Jan. 9, 2004; each of which is hereby incorporated by reference in its entirety.","1. Field of the Invention","The present invention relates to document printers and, more specifically, to document printers that can receive, process, and transform multimedia data, and output it in a different format.","2. Background of the Invention","Cost and quality improvements in multimedia technologies have led to a proliferation of monitoring devices and their applications. High-quality video cameras and microphones are becoming commonplace in the home and workplace, and have proven to be useful for diverse purposes ranging from teleconferencing to surveillance to work flow management. Multimedia data captured by such monitoring devices are typically delivered in an unprocessed form to a medium such as a digital tape, hard disk, or memory card. Typically, the user must then filter the data in order to isolate the useful elements\u2014for instance, by editing out unwanted noise. Often the data will have to be further processed to create a usable record, for instance by isolating relevant events. The process of sifting through such data is often tedious and error-prone, requiring users to play, fast-forward, and rewind through voluminous stores of data. In the case of surveillance applications, in which the primary purpose of such applications is essentially to wait for certain events to occur, the time and resources spent carrying out the repeated steps of event detection can be considerable.","The processing of multimedia data to create a usable record typically involves several disparate steps, each potentially requiring considerable effort. Oftentimes a user will have to convert and transfer multimedia data in different stages to different devices\u2014for instance from an analog tape to an unprocessed digital file, then into a summary file containing excerpts of the data, then to a memory or output device. While the processing of a multimedia files commonly involves the same repeated tasks\u2014for instance, making an multimedia recording of a meeting, filtering out the noise, adding participant and other identifier information, and then sending the processed multimedia record to the meeting attendants\u2014there is no easy way to automate them. In addition, because the data are typically not printed to a paper document, they are difficult to incorporate into the existing paper-based workflow by which most offices function. Although means do exist to map multimedia data to paper friendly outputs\u2014for instance, to transcribe intelligible multimedia records to a dialog script or to extract images or frames from a video record\u2014which then could be printed, these additional conversion steps are often not automated or performed.","Thus, there is a need for an integrated system that can receive multimedia data, process it, and deliver an output to a printed document or other media.","The present invention overcomes the deficiencies and limitations of the prior art by providing systems and apparati in which multimedia data are received by a multimedia processing device, the data are processed, and the result is output. It also provides apparati and methods of generating a control signal for a peripheral device based on data captured by the peripheral device (or another peripheral device) and received by a multimedia processing device. Finally, other embodiments of the invention are provided in which a multimedia processing device receives a command to process multimedia data and to perform an action responsive to the occurrence of a multimedia event and the command is executed if the event is detected.","The present invention provides systems and methods for managing multimedia data from the capture of the data to its eventual output in a useful format. By combining monitoring, processing, and output capabilities, embodiments of the invention provide a unified solution to various monitoring, recording, and other needs. The integrated management of multimedia data that the present invention makes possible has several benefits\u2014including enhancing the efficiency of multimedia monitoring and processing, reducing the number of steps it takes to extract useful information from multimedia data, and enabling greater integration of multimedia data into decision-making and analysis.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1A","b":["101","155","100","106","180","170","100","155","130","100","100","100","100","100"]},"For the purposes of this invention, the terms \u201cmultimedia data\u201d, \u201cmultimedia file\u201d, \u201cmultimedia information\u201d or \u201cmultimedia content\u201d include any one or combination of video data, audio data, graphics data, animation data, sensory data, still video, slides information, whiteboard images information, and other types of data. The data can be in analog form, stored on magnetic tape, or digital files that can be in a variety of formats including ASF, Divx, 3DO, .mmx, .sdmi, .mpeg, .smil, multimedia, .mp3, .wav, magnetic tape, digital audio tape, various MPEG formats (e.g., MPEG 1, MPEG 2, MPEG 4, MPEG 7, etc.), HTML+TIME, WMF (Windows Media Format), RM (Real Media), Quicktime, Shockwave, various streaming media formats, formats being developed by the engineering community, proprietary and customary formats, and others. In certain cases, multimedia data may also comprise files in other formats.","For purposes of the invention, the multimedia data discussed throughout the invention can be supplied to multimedia processing device  in any number of ways including in the form of streaming content, a live feed from a multimedia capture device, a discrete file, or as a portion of a larger file. In addition, for the purposes of this invention, the terms \u201cprint\u201d or \u201cprinting,\u201d when referring to printing onto some type of medium, are intended to include printing, writing, drawing, imprinting, embossing, generating in digital format, and other types of generation of a data representation. While the words \u201cdocument\u201d and \u201cpaper\u201d are referred to in these terms, output of the system  in the present invention is not limited to such a physical medium, like a paper medium. Instead, the above terms can refer to any output that is fixed in a tangible medium. In some embodiments, the output of the system  of the present invention can be a representation of multimedia data printed on a physical paper document. By generating a paper document, the present invention provides the portability of paper and provides a readable representation of the multimedia information.","In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the invention. It will be apparent, however, to one skilled in the art that the invention can be practiced without these specific details. In other instances, structures and devices are shown in block diagram form in order to avoid obscuring the invention.","Reference in the specification to \u201cone embodiment\u201d or \u201can embodiment\u201d or the like means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the invention. The appearances of \u201cin one embodiment\u201d and like phrases in various places in the specification are not necessarily all referring to the same embodiment.","Still referring to , a block diagram shows the multimedia processing device or multimedia printer  in accordance with an embodiment of the invention. The multimedia processing device  preferably comprises an multimedia interface , a memory , a processor , and an output system .","As shown, in one embodiment, multimedia data  from the peripheral device  is passed through signal line coupled to multimedia processing device  to multimedia interface  of multimedia processing device . As discussed throughout this application, the term \u201csignal line\u201d includes any connection or combination of connections supported by a digital, analog, satellite, wireless, firewire (IEEE 1394), 802.11, RF, local and\/or wide area network, Ethernet, 9-pin connector, parallel port, USB, serial, or small computer system interface (SCSI), TCP\/IP, HTTP, email, web server, or other communications device, router, or protocol. In certain cases, signal line facilitates bi-directional communication, or in other cases, may only support unidirectional communication. Signal line , for instance, allows for data captured from peripheral device  to be transmitted to multimedia processing device , and also allows for command signals to change the orientation of peripheral device  to be sent to peripheral device  from multimedia processing device . Multimedia data  may be sourced from various peripheral devices including microphones, video cameras, sensors, and other multimedia capture or playback devices. Multimedia data  can also be sourced from a portable storage medium (not shown) such as a tape, disk, flash memory, or smart drive, CD-ROM, DVD, or other magnetic, optical, temporary computer, or semiconductor memory. In an embodiment, data  are accessed by the multimedia processing device  from a storage medium through various card, disk, or tape readers that may or may not be incorporated into multimedia processing device .","In an embodiment, multimedia data  are received over signal line from multimedia data source or peripheral device . Alternatively, the data may be delivered over signal line to multimedia interface  over a network from a server hosting, for instance, a database of multimedia files. Additionally, the multimedia data may be sourced from a receiver (e.g., a satellite dish or a cable receiver) that is configured to capture or receive (e.g., via a wireless link) multimedia data from an external source (not shown) and then provide the data to multimedia interface  over signal line ","Multimedia data  are received through multimedia interface  adapted to receive multimedia data  from signal line . Multimedia interface  may comprise a typical communications port such as a parallel, USB, serial, SCSI, Bluetooth\u2122\/IR receiver. It may comprise a disk drive, analog tape reader, scanner, firewire, IEEE 1394, Internet, or other data and\/or data communications interface.","Multimedia interface  in turn supplies multimedia data  or a processed version of it to system bus . System bus  may represent one or more buses including an industry standard architecture (ISA) bus, a peripheral component interconnect (PCI) bus, a universal serial bus (USB), or some other bus known in the art to provide similar functionality. In an embodiment, if multimedia data  is received in an analog form, it is first converted to digital form for processing using a conventional analog-to-digital converter. Likewise, if the multimedia data  is a paper input, for instance video paper, multimedia interface  may contain bar code reading or optical character recognition (OCR) capabilities by which the multimedia data within the paper document can be accessed. Multimedia data  is sent in digitized form to system bus  of multimedia processing device .","In , multimedia data  is delivered over signal line to multimedia processing device . However, in other embodiments, multimedia data  may also be generated within multimedia processing device  and delivered to processor  by system bus . For instance, multimedia data  may be generated on multimedia processing device  through the use of movie making software, a video editor, or other similar multimedia tools (not shown). Once created on the multimedia processing device , a multimedia file can be sent along the system bus , to processor  or memory  for instance. In another embodiment, multimedia processing device  contains a digital multimedia recorder as the peripheral device  through which sound and\/or images generated outside the multimedia processing device , for instance, can be recorded. Once captured, digital signals comprising the multimedia recording can then be further processed by the multimedia processing device .","Commands  to process or output multimedia data  may be transmitted to multimedia processing device  through signal line coupled to multimedia processing device . In an embodiment, commands  reflect a user's specific conversion, processing, and output preferences. Such commands could include instructions to convert multimedia data  from an analog to digital format, or digital to analog, or from one digital format to another. Alternatively, commands  could direct processor  to carry out a series of conversions, or to index raw or processed multimedia data . In an embodiment, commands  specify where the processed multimedia data  should be output\u2014for instance to a paper document , electronic data , portable storage medium, or the like. A specific set of commands sent over a signal line to bus  in the form of digital signals instruct, for instance, that multimedia data  in a .mpeg format should be compressed to a smaller format and then bar coded, and the result burned to a CD.","In an embodiment, commands  to processor  instruct that the processed multimedia data  be output to a paper document . Preferably commands  describe the layout of the document  on the page, and are sent as digital signals over signal line in any number of formats that can be understood by processor  including page description language (PDL), Printer Command Language (PCL), graphical device interface (GDI) format, Adobe's Postscript language, or a vector- or bitmap-based language. Communication protocols as disclosed in U.S. Patent Application entitled, \u201cPrinter With Embedded Retrieval and Publishing Interface,\u201d to Hull et. al, filed Mar. 30, 2004, Ser. No. 10\/814,536 or U.S. Patent Application entitled, \u201cPrinter With Document-Triggered Processing,\u201d to Hull et. al, filed Mar. 30, 2004, Ser. No. 10\/814,580 each of which is hereby incorporated by reference in its entirety, for instance, could be used to facilitate PDL-based and other communications to the multimedia processing device . The instructions  also specify the paper source, page format, font, margin, and layout options for the printing to paper of multimedia data . Commands  could originate from a variety of sources including a print dialog on a processing device  coupled to multimedia processing device  by signal line that is programmed to appear every time a user attempts to send multimedia data  to the multimedia processing device  for instance.","Alternatively, commands  in the form of responses provided by a user to a set of choices presented in a graphical user interface could be sent to processor  via a signal lines , , or . Graphical interfaces such as the ones described in U.S. Patent Applications entitled \u201cPrinter User Interface,\u201d to Hart et. al, filed Mar. 30, 2004, Ser. No. 10\/814,700 or \u201cUser Interface for Networked Printer,\u201d to Hart et. al, filed Mar. 30, 2004, Ser. No. 10\/814,500, each of which is hereby incorporated by reference in its entirety, could be used, for instance. A similar set of choices and responses could be presented by a hardware display, for instance through a touch screen or key pad hosted on a peripheral device  coupled to multimedia processing device  by a signal line or incorporated as part of the multimedia processing device . The commands may be transmitted, in turn, to multimedia processing device  through signal line connected to the peripheral device  or could be directly provided to multimedia processing device .","In yet another embodiment, conventional software hosted on a machine (not shown) could be adapted to solicit processing and output choices from a user and then send these to processor  on multimedia processing device . This software could be modified through a software plug-in, customized programming, or a driver capable of adding \u201cprint\u201d options to multimedia rendering applications such as Windows Media Player. Various possible interfaces for controlling and managing multimedia data are further discussed in U.S. Patent Application entitled, \u201cMultimedia Print Driver Dialog Interfaces,\u201d to Hull et. al, filed Mar. 30, 2004, Ser. No. 10\/814,944.","Although processor  of multimedia processing device  of  is configured to receive processing commands  over a signal line , as described above, in another embodiment of the invention, processing commands  are input or generated directly on multimedia processing device . In another embodiment, multimedia processing device  does not receive commands at all to process the multimedia data , but contains logic that dictates what steps should automatically be carried out in response, for instance, to receiving a certain kind of data . For instance, the multimedia processing device  could be programmed to convert every.mp3 or .wav file it receives to multimedia upon receipt, and then to store the resulting multimedia file to a server on a network accessed over signal line ","As shown in , multimedia processing device  receives multimedia data  and commands  over signal lines , and outputs processed multimedia data  as a paper document  or over signal line as electronic data . Multimedia processing device  may be customized for use with multimedia data , and may contain various of the modules - displayed in  and assorted peripherals (such as an electronic keyboard, video recorder) (not shown) to generate multimedia data . As used herein, the term \u201cmodule\u201d can refer to program logic for providing the specified functionality that can be implemented in hardware, firmware, and\/or software. In an embodiment, multimedia processing device  comprises a printing device that has the capability to generate paper outputs, and may or may not have the ability to generate electronic outputs as shown. As used herein, the term \u201cprinting device\u201d or \u201cprinter\u201d refers to a device that is capable of receiving multimedia data , has the functionality to print paper documents, and may also have the capabilities of a fax machine, a copy machine, and other devices for generating physical documents. Printing device may comprise a conventional laser, inkjet, portable, bubblejet, handheld, or other printer, or may comprise a multi-purpose printer plus copier, digital sender, printer and scanner, or a specialized photo or portable printer, or other device capable of printing a paper document. It may also comprise a specialized printing devices such as any of the devices disclosed in U.S Patent Applications \u201cPrinter with Multimedia Server\u201d or \u201cNEP Apparatus,\u201d both filed on Mar. 30, 2004, which are hereby each incorporated by reference in its entirety. In an embodiment, printing device comprises a conventional printer adapted to receive multimedia data, and\/or to output electronic data.","Multimedia processing device  preferably comprises output system  capable of outputting data in a plurality of data types. For example, output system  preferably comprises a printer of a conventional type and a disk drive capable of writing to CDs or DVDs. Output system  may comprise a raster image processor or other device or module to render multimedia data  onto a paper document . In another embodiment, output system  may be a printer and one or more interfaces to store data to non-volatile memory such as ROM, programmable read-only memory (PROM), erasable programmable read-only memory (EPROM), electrically erasable programmable read-only memory (EEPROM), flash memory, and random access memory (RAM) powered with a battery. Output system  may also be equipped with interfaces to store electronic data  to a cell phone memory card, PDA memory card, flash media, memory stick or other portable medium. Later, the output electronic data  can be accessed from a specified target device. In an embodiment, output system  can also output processed multimedia data  over signal line to an email attaching the processed multimedia data  to a predetermined address via a network interface (not shown). In another embodiment, processed multimedia data  is sent over signal line to a rendering or implementing device such as a CD player or media player (not shown) where it is broadcast or rendered. In another embodiment, signal line comprises a connection such as an Ethernet connection, to a server containing an archive where the processed content can be stored. Other output forms are also possible.","Multimedia processing device  further comprises processor  and memory . Processor  contains logic to perform tasks associated with processing multimedia data  signals sent to it through the bus . It may comprise various computing architectures including a reduced instruction set computer (RISC) architecture, a complex instruction set computer (CISC) architecture, or an architecture implementing a combination of instruction sets. In an embodiment, processor  may be any general-purpose processor such as that found on a PC such as an INTEL x86, SUN MICROSYSTEMS SPARC, or POWERPC compatible-CPU. Although only a single processor  is shown in , multiple processors may be included.","Memory  in multimedia processing device  can serve several functions. It may store instructions and associated data that may be executed by processor , including software and other components. The instructions and\/or data may comprise code for performing any and\/or all of the functions described herein. Memory  may be a dynamic random access memory (DRAM) device, a static random access memory (SRAM) device, or some other memory device known in the art. Memory  may also include a data archive (not shown) for storing multimedia data  that has been processed on processor . In addition, when multimedia data  is first sent to multimedia processing device  via signal line , the data  may temporarily stored in memory  before it is processed. Other modules - stored in memory  may support various functions, for instance to process, index, and store multimedia data. Exemplary modules in accordance with an embodiment of the invention are discussed in detail in the context of , below.","Although in , electronic data output  is depicted as being sent outside multimedia processing device  over signal line , in some embodiments, electronic data output  remains in multimedia processing device . For instance, processed multimedia data  could be stored on a repository (not shown) stored in memory  of multimedia processing device , rather than output to external media. In addition, multimedia processing device  may also include a speaker (not shown) or other broadcasting device. A multimedia card or other multimedia processing logic may process the multimedia data  and send them over bus  to be output on a remote speaker. Not every embodiment of the invention will include an output system  for outputting both a paper document  and electronic data . Some embodiments may include only one or another of these output formats.","Multimedia processing device  of  is configured to communicate with processing device . In an embodiment, multimedia processing device  may share or shift the load associated with processing multimedia data  with or to processing device . Processing device  may be a PC, equipped with at least one processor coupled to a bus (not shown). Coupled to the bus can be a memory, storage device, a keyboard, a graphics adapter, a pointing device, and a network adapter. A display can be coupled to the graphics adapter. The processor may be any general-purpose processor such as an INTEL x86, SUN MICROSYSTEMS SPARC, or POWERPC compatible-CPU. Alternatively, processing device  omits a number of these elements but at a minimum includes a processor and interface for communicating with multimedia processing device . In an embodiment, processing device  receives unprocessed multimedia data  over signal line from multimedia processing device . Processing device  then processes multimedia data , and returns the result to multimedia processing device  via signal line . Output system  on multimedia processing device  then outputs the result, as a paper document  or electronic data . In another embodiment, multimedia processing device  and processing device  share processing load or interactively carry out complementary processing steps, sending data and instructions over signal line ",{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 1B","b":["70","10","20","165","170","10","20","70","30","20","40","10","20","10","20","106","70","10","20","10","20","165"]},{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 2","FIG. 1A","FIG. 2","FIG. 1A","FIG. 2"],"b":["104","100","104","106","100","110","100","104","160","106","100","104","160","160","100","130","200","216","104","100","160"],"i":"c"},"Memory  is comprised of main system module , assorted processing modules - and processing storage  coupled to processor  and other components of multimedia processing device  by bus . Processing storage  is configured to store audio\/video data at various stages of processing, and other data associated with processing. In the embodiment shown, processing storage  is shown as a portion of memory  for storing data associated with the processing of audio\/video data. Those skilled in the art will recognize that processing storage  may include databases, subroutines, and other functionality, and may alternately be portions of the multimedia processing device  or processing device . Main system module  serves as the central interface between processing storage , the other elements of multimedia processing device , and modules -. In various embodiments of the invention, main system module  receives input to process audio\/video data, sent by processor  or another component via system bus . The main system module  interprets the input and activates the appropriate module -. System module  retrieves the relevant data from processing storage  in memory  and passes it to the appropriate module -. The respective module - processes the data, typically on processor  or another processor, and returns the result to system module . The result may then be passed to output system , to be output as a paper document  or electronic data .","In an embodiment, system module  contains logic to determine what series of steps, in what order, should be carried out to achieve a desired result. For instance, system module  may receive instructions from system bus  specifying that if a certain event occurs, then a series of actions should take place. System module  can parse these instructions to determine that it must monitor multimedia data for the event, and then when the event happens, that an event table containing various event triggers and their corresponding actions should be accessed. Based on information retrieved from the event table, system module  can initiate the requested action. System module  can carry out the action and other steps in the process by sending commands to the various modules described below to carry out these steps.","Filtering\/processing module  is coupled to system module  and processing storage  by bus . System module , having received the appropriate input, sends a signal to filtering\/processing module  to filter or process multimedia data  received by multimedia processing device  and save the result to processing storage . In one embodiment, filtering\/processing module  is equipped with audio processing technology to filter out routine background noise or sounds, smooth data, enhance audio signals, returning the processed audio data to processing system . In another embodiment, filtering\/processing module  uses a look-up table of pre-defined events to determine what events\u2014for instance, the ring of a telephone at a certain frequency\u2014should be left out of a summary of audio events. Similarly, in another embodiment, filtering\/processing module  can also filter, smooth, or change video content that is received by multimedia processing device . Filtering\/processing module  can, for instance, automatically adjust the contrast and tracking, or decrease the resolution of the image in order to allow the raw data to be saved in a more compact format. In yet another embodiment, filtering\/processing module  includes voice recognition technology that can be used to distinguish speech from background noise. In another embodiment, multimedia data  is filtered such that periods of non-activity are deleted, and the processed file only contains periods of activity as defined by certain pre-determined parameters such as decibel level, shape of waveform, scene changes, or other measure. In an embodiment, filtering\/processing module  can grab certain frames from video data, using conventional frame grabber technology, or can parse multimedia data to isolate only data \u201cevents\u201d that match certain profiles.","Motion detection module  is coupled to system module  and processing storage  by bus . System module , having received the appropriate input, sends a signal to motion detection module  to detect motion in video data.  depicts steps carried out in part by motion detection module  in one embodiment to process a video stream received by multimedia processing device . Performance of the steps depicted in  allows for motion detected by motion detection module  from video data to be compared against pre-existing elements supplied to multimedia processing device  by a user. The process begins when a frame of video data, frame N, is captured, for instance by a digital video recorder, at a resolution of 640 pixels by 480 pixels. Multimedia processing device  is coupled to the recorder and receives  a stream of the frames over signal line . At regular intervals, a frame of video data captured by the video recorder is stored in processing storage  of memory  and is designated as the current base frame. As individual video frames are received, it is determined whether or not, based on a counter for instance, the received frame should replace the existing frame as the base frame. After multimedia processing device  receives frame N, system module  sends a command to motion detection module  to calculate  the difference between frame N and the current base frame. Motion detection module  takes frame N and the base frame and generates a pixel by pixel map of the differences between the two frames, the difference frame. The differences are compared  to a threshold value. Differences below the threshold are considered noise, however, changes at or are above the threshold indicate that \u201cmotion\u201d has occurred. When motion has been detected, motion detection module  extracts  connected components by grouping adjacent pixel differences into \u201ccomponents\u201d . Each connected component can then be characterized by dimensional size (\u03a3), and center location (x, y). The results are returned to system module . The system module  then instructs event detection module  to detect predetermined events that are reflected in the motion detected.","Returning to , event detection module  is coupled to system module  and processing storage  by bus . In an embodiment, a user has supplied a list of element descriptions  referenced in  to multimedia processing device  over bus line , each of which describes an event in terms of sizes and locations, for instance a person standing in a doorway. Returning to , event detection module  compares  the connected components extracted from frame N to the element descriptions . Event detection module  detects  a match, for example, when it detects a proportional correlation between a detected component and an element description above a certain match threshold. The result is returned by bus line  to system module . If there are additional connected components , the process is repeated until no more connected components are identified. In an embodiment, event detection module  can use any of a number of conventional algorithms and processes to detect a range of multimedia event.","Returning to , in an embodiment, event detection module  uses audio feature analysis and recognition techniques which are commonly known in the art, for example those described in \u201cUsing Structure Patterns of Temporal and Spectral Feature in Audio Similarity,\u201d by Rui Cai, Lie Lu, Hong-Jiang Zhang, and Lian-Hong Cai, ACM Multimedia 2003, Berkeley, Calif., November 2-8, 219-222, to detect whether an event has happened. In another embodiment, event detection module  uses face detection algorithms such as those described in U.S. Patent Application entitled, \u201cMultimedia Print Driver Dialog Interfaces,\u201d to Hull et. al, filed Mar. 30, 2004, Ser. No. 10\/814,944, to determine when a certain person has appeared in a video frame. Similarly, event detection module  can be \u201ctrained\u201d to recognize the events profiled in a lookup table. A profile of a phone ringing could be based on the direction from which a tone emanates, and the pitch, duration, and frequency of the tone for instance. The greater the match between profile and received multimedia data, the higher the confidence level that event detection module  has correctly identified the \u201cevent.\u201d Similarly, event detection module  can determine that a phone conversation has taken place when it detects a combination of the appropriate ring tone and one-way voice communication. In another embodiment, an office discussion may be identified by the presence of several elements including a video image of one or more persons within a confined space for at least a fixed duration of time and the presence of two or more voices captured by an audio device.","Event direction module  can also be used to carry out event-triggered data processing. Steps in an exemplary process for event-triggered data processing are depicted in the flowchart of . Multimedia data is received  by multimedia processing device , and processed  by filtering\/processing module . Event detection module  runs  event detection, preferably with reference to an event table  that stores descriptions and profiles of predetermined multimedia \u201cevents\u201d and the actions they trigger, if any. If an event is detected , a further determination is made, based on the event table , as to whether or not the event has triggered  an action. This step could be carried out by system module  accessing event table  and processing storage . If an action has been triggered , system module  activates the appropriate module or modules - to carry out  the action associated with the event. Regardless of the outcome\u2014if no event has been detected, or if no action has been triggered, or even if the indicated actions have been performed , multimedia processing device  continues to receive  and process  data, and run event detection  on the data.","Localization module  is coupled to system module  and processing storage  by bus . In an embodiment, system module , having received the appropriate input, sends a signal to localization module  to perform localization. In an embodiment, localization module  performs localization based on audio data received from a microphone array responsive to such a command from system module . The microphones are connected to multimedia processing device  through a network. As localization module  performs audio localization, multimedia processing device  commands the microphones to orient towards the source of a sound. The microphones are positioned in response to the command, thereby improving the quality of the audio data sent to multimedia processing device . In an embodiment, two pairs of microphones are placed in a fixed configuration around a meeting room. A first in first out (FIFO) buffer attached to each microphone receives audio samples at fixed intervals. The samples are sent in real-time to multimedia processing device  over signal line , and are routed to processing storage . System module  directs localization module  to perform localization  based on the samples. To do this, localization module  calculates the time delay of arrival between each of the pairs of microphones based on the speed of sound and the physical distance between the microphones. It then calculates the offset that maximizes the correlation between each pair of samples. This information is used to estimate the direction from which the sound originated; that is, the point in space that yields maximum energy. Filtering\/processing module  sends this information to system module , which then converts it into commands to mechanically reposition the microphone or microphones to point towards the source of the sounds. System module  sends these commands to output system , which sends them over signal line back to the peripheral devices . This process is repeated for various samples.","In another embodiment, localization module  performs localization based on data captured by one or more of a visual sensor, stereo camera, video detection unit, and temperature sensor. Algorithms such as those described in \u201cPerson Tracking Using Audio-Video Sensor Fusion,\u201d by Neal Checka, Kevin Wilson & Vibhav Rangarajan of the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology of Cambridge, Mass. to perform localization based on sets of data inputs may be used.","Indexing\/mapping module  is coupled to system module  and processing storage  by bus . In an embodiment, system module , having received the appropriate input, sends a signal to indexing\/mapping module  to map multimedia data  to a summary file or index. To carry out this instruction, indexing\/mapping module  accesses multimedia data  through system bus . Indexing\/mapping module , using or adapting any number of data mapping programs such as the Audition product offered by Adobe Systems Incorporated of San Jose, Calif. or any of the algorithms described in \u201cVisualizing Multimedia Content on Paper Documents: Key Frame Selection for Video Paper,\u201d by Jonathan J. Hull, Berna Erol, Jamey Graham, Dar-Shyang Lee, 7th International Conference on Document Analysis and Recognition, 2003 (for key frame selection from video); \u201cPortable Meeting Recorder,\u201d by Dar-Shyang Lee, Berna Erol, Jamey Graham, Jonathan J. Hull and Norihiko Murata, ACM Multimedia Conference, 2002 (for event detection from audio and video); and \u201cKey frame selection to represent a video,\u201d by Dirfaux, F., IEEE International Conference on Image Processing 2000 (for key frame selection); each of which is hereby incorporated by reference in its entirety, can analyze multimedia data  and map it to a summary file for further analysis. In another embodiment, indexing\/mapping module  segments multimedia data  by various measures including time interval, speaker during a meeting, scene change, or other multimedia cues and prepares an index that references each of the segments. In an embodiment, indexing\/mapping module  creates a new file to store the map or index information generated, and sends the new file by system bus  to processing storage  to be stored. It may in an embodiment use an algorithm such as one described in \u201cMultimodal Summarization of Meeting Recordings,\u201d by Berna Erol, Dar-Shyang Lee, and Jonathan J. Hull, IEEE International Conference on Multimedia and Expo, Baltimore, Md., July, 2003 to compute map or index information. Various techniques and interfaces for audio segmentation and audio mapping are discussed in more detail in U.S. Patent Application entitled, \u201cMultimedia Print Driver Dialog Interfaces,\u201d to Hull et. al, filed Mar. 30, 2004, Ser. No. 10\/814,944.","In an embodiment, indexing\/mapping module  can also generate identifiers to correspond to segments of multimedia data such as barcodes. Conventional software, for instance provided by Barcode Software Center of Evanston, Ill., can be used or adapted to create a readable bar code that corresponds to the location of a specific segment of multimedia data for instance a phone call, a conversation between, or visitor at night to an office.","Report module  is coupled to system module  and processing storage  by bus . System module , having received the appropriate input, sends a signal to report module  to initiate the generation of a report based on multimedia data . The steps carried out by report module  will depend on the type of report requested. In an embodiment, for instance, multimedia processing device  receives a processing command  from a user to create a video paper document that presents on a piece of paper selected key video frames and bar codes positioned near the key frames to allow a user to play video beginning at the specific points in time referenced by the frames. Using video paper technology such as that described in \u201cA Paper-based Interface for Video Browsing and Retrieval,\u201d Jamey Graham and Jonathan J. Hull, IEEE International Conference on Multimedia and Expo (ICME), Baltimore, Md., Jul. 6-9, 2003; or any of U.S. patent application Ser. No. 10\/001,895, \u201c(Video Paper) Paper-based Interface for Multimedia Information,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/001,849, \u201c(Video Paper) Techniques for Annotating Multimedia Information,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/001,893, \u201c(Video Paper) Techniques for Generating a Coversheet for a paper-based Interface for Multimedia Information,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/001,894, \u201c(Video Paper) Techniques for Retrieving Multimedia Information Using a Paper-Based Interface,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/001,891, \u201c(Video Paper) Paper-based Interface for Multimedia Information Stored by Multiple Multimedia Documents,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/175,540, \u201c(Video Paper) Device for Generating a Multimedia Paper Document,\u201d filed Jun. 18, 2002; and U.S. patent application Ser. No. 10\/645,821, \u201c(Video Paper) Paper-Based Interface for Specifying Ranges CIP,\u201d filed Aug. 20, 2003; each of which is each hereby incorporated by reference in its entirety can be used to generate the report.","In another embodiment, report module  inserts multimedia objects as they are created into an existing document template that includes placeholders for objects that are predicted to occur in the future. The flow chart of  depicts one series of steps for completing this process that could be carried out in part by report module . First, a user sends processing commands  to processor  of multimedia processing device , over signal line . As described above, these commands can be sourced from a graphical user interface on multimedia processing device , inputs to a print dialog, or another system for receiving user commands. The commands are received  by system module . They instruct multimedia processing device  to capture data at some future time or in response to some future event, convert the data into a multimedia object, and insert it into a document to be printed out. In an embodiment, system module  instructs report module  to generate a report template document based on the user's request. Taking advantage of the insert object function and a Microsoft Word plug-in, report module  could create a template document that includes placeholders for future multimedia data objects not yet in existence. In an embodiment, the template document could be prepared on the processor  of multimedia processing device ; alternatively the task of creating the template document could be offloaded onto processing device  in communication with multimedia processing device  through signal line . In another embodiment, a user, rather than multimedia processing device , creates the template document, in Microsoft Word. Using the insert object function, report module  could insert non-printing PDL comments into a file that detail the relevant events to be detected. The user sends the template document with embedded PDL comments over system bus  to multimedia processing device . The document is not printed until the specified data objects have been created and inserted into the template.","After multimedia processing device  receives  the commands, event detection module  monitors  the multimedia data, responsive to a request sent by system module . Event detection module  scans the multimedia data for the specific triggering events identified by the user. Once event detection module  detects  the event, it sends a signal over system bus  to system module  indicating that the specified event in multimedia data  has occurred. System module  proceeds to capture  the event as a multimedia object. As one example, anytime a \u201cphone conversation\u201d or \u201coffice discussion\u201d is identified in a stream of multimedia data , identified according to an event table, for instance, report module  could save the event as a discrete object to processing storage  and send a signal to system module  indicating that a relevant object had been detected and captured. Report module , responsive to commands from system module , then inserts  the captured object into the report template saved to processing storage  and saves it as a document capable of being output. Report module  also inserts  meta data about the object, such as the date and time when it was created, into the document. At this point, system module  determines  whether or not the document is complete and is ready to be output. For instance, the document might contain placeholders for several multimedia data objects and not be considered complete until all of the placeholders are filled with objects. Alternatively, a document could be considered \u201ccomplete\u201d if it exceeds its time limit in a queue even if the designated event did not occur. If the document is not considered complete, monitoring , detection , capture , etc. continue. When the document is determined  to be complete, for instance because all of the placeholders in a template document have been filled, or because the monitoring period has elapsed, the document is output .","Returning to , archiving module  is coupled to system module  and processing storage  by bus . System module , having received the appropriate input, sends a signal to archiving module  to store multimedia data , or processed multimedia data , to an archive. The archive could be stored on the archiving module  or other location on multimedia processing device . In another embodiment, archiving module  can send the multimedia data  to output system, to be sent to a network over signal line and saved on a remote server. In an embodiment, multimedia data  is saved to processing device , or another device.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 6","FIG. 1A","FIG. 1A"],"b":["600","612","100","612","100","102","202","110","214","200","202","100"]},"System module  then instructs event detection module  through signals sent over system bus  to process the filtered data and identify any events that took place. Event detection module  then scans the data for pre-identified sound forms associated with certain events. The pre-identified sound forms may be stored in a database in processing storage , populated by a system administrator based on a series of sound observations over a period of time. Each event is associated in the database with a short description, such as \u201cdoor opens\u201d and \u201cdoor closes.\u201d Comparing the stored profiles to the audio data it receives, the event detection module  makes matches for several events\u2014the beginning and end of a phone conversation and a door opening and closing. An index to the location of the events in the data is created, by indexing\/mapping module . System module  receives the data from event detection module  that the beginning and the end of a phone conversation has been detected. System module  contains logic that instructs it to send a request to indexing\/matching module  to create a bar code reference to the phone conversation.","Indexing\/matching module  creates a readable bar code that corresponds to the location of the phone conversation in the archive, which identifies the beginning and end of the conversation, and links to the audio data. System module  then sends a request to report module  to generate the report . Report module  accesses a repository of report templates stored on processing storage  and selects the appropriate template, which already contains the name of the report as well as its layout, spacing, and other details. Report module  then takes the filtered raw data and maps it to a scaled timeline  in the report file. The events detected are exaggerated in size to allow the user to quickly identify that events have taken place. Report module  inserts the short description associated with each event stored in the event database next to the event , and also identifies the time each event began . Dotted lines connecting the text to the graphical representation of the event are also included. A date stamp  reflecting the date of the report is included on the top of the report. A bar code  that points to the location of the conversation in the processed data file saved to the archive is inserted. Later, when someone wants to review the record of the conversation, they can use the barcode to access it, rather than having to manually locate the conversation within the 15 hours of tape, much of it containing just silence. The entire report is saved to processing storage . System module  sends it to output system  with a command to automatically send a printable copy of the report to a predesignated secure email address.","A user skilled in the art will know that  depicts just one of the many reports that could be generated by a multimedia printer or multimedia processing device . Other outputs are also possible. For instance, an abbreviated report could show only a record of events that happen, and omits periods of time when no activity is occurring. The data could be video data, and could be sourced from an optical disk to which it has been burned. In addition to using a template, report module  could also receive formatting instructions from system module  based on PDL comments sent with the data that can be read and processed by the multimedia data processor . Other outputs may be generated by multimedia processing device . In one embodiment, multimedia processing device  bums audio and video data to a rewritable CD (not shown) responsive to input provided by a user through a user interface. The CD contains both a compressed version of raw data received from audio and data feeds, and higher level reports.","In an embodiment, an administrator uses multimedia processing device  to streamline the process of detecting traffic violations and accidents at an intersection. A video camera is installed at an intersection and sends data though a monitoring network comprised of broadband wireline and wireless connections to multimedia processing device . Through a user interface on multimedia processing device , the user profiles the event it would like to monitor. The user specifies, for instance, that it would like reports of accidents that occur at the intersection to be printed out. In another embodiment, the user could direct photos to be taken of cars facing a certain direction that are in the intersection even when there is a red light. The user can choose the output it would like to see\u2014for instance a snapshot image grabbed from the video data, or just a log of events indicating when there were apparent red light violations over a 72-hour period for instance. Finally, the user can use the interface to indicate how the data should be stored\u2014for instance in a database or burned to disk. Multimedia processing device  receives these commands and applies them to the stream of video data it receives from the intersection. In one embodiment, an accident report is created every week that identifies the time of apparent violations occurring over a fixed period of time, and inserts snapshots taken of the violation event, preferably which capture a license plate view of each car. Once generated, the report is printed on paper to multimedia processing device .",{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 7","b":["100","704","706","702","706","100","100","702","710","710","704","710","100","704","100","100","702","702","708","712","708"],"i":["a ","b","a ","b"]},"As described above, embodiments of the present invention make it easier to handle raw multimedia data and to transform the data into a useful output that can be integrated into a paper-based or other existing workflow. In an embodiment, the invention allows a user to define and specify events in terms of multimedia data. Based on the user's descriptions, multimedia processing device  can detect events in the data it receives and perform specific actions triggered by the events.  depicts an example of an event table  that matches events to actions in this way. As shown, the event table stores descriptions of multimedia \u201cevents.\u201d The descriptions are preferably expressed in a multimedia data metric, for instance, the dimensional size (\u03a3) and center location (x, y) of an image on a video frame, but can be in a variety of forms that allow for the identification of the event in multimedia data. The event table can be implemented in the form of a database, series of statements in a programming language, XML document, or for simple algorithms, in the form of a simple table or series of data strings. If an event is detected, in the event table of , an event counter is updated, for instance through a special purpose application in the print driver or a web browser interface using a cgi script. The event is associated with an action, triggered when a certain number of events have occurred.","In an embodiment of the invention, a printer equipped with motion detection capabilities could be programmed to sound a ring tone of a specific frequency whenever a paper was removed from a specific paper tray. As shown in , a user could specify the ringing of a paper tray tone as an event, based on its specific frequency and duration. Every day, a report could be generated that disclosed the number of times a document was removed from a tray and sent to an office administrator. A user could program the counter to be reset whenever the report was sent. Another event specified in  is a discussion in an office. Algorithms such as the one described above could be used to determine this event. Each time the event is detected, the action of recording the discussion and archiving it to a specific discussion server is triggered or set in motion. A third event comprises a telephone ring. Each time the event of the telephone ring is detected, another event detection is triggered, the event of detecting a voice. As specified in event table , if a voice is detected, the action of recording the voice until the call is complete is triggered. The three examples provided in the table are just a few of any number of event, action triggers, and action combinations of varying complexity that could be specified.",{"@attributes":{"id":"p-0071","num":"0070"},"figref":["FIG. 10","FIG. 9","FIG. 10"],"b":["1000","100","900","1000","1012","1002","1000","1012","1006","1008","1010","1004","1012"]},"Multimedia processing device  receives audio and video data feeds, and event detection module  looks for each of the specified events in the data. A first event is detected, the removal of a document from a tray. The first report section is populated with the date and time of the event  and a description of the event as it appears in the lookup table . The action associated with the event in the table is to identify the person who performed the event. Filtering\/processing module  of multimedia processing device  grabs an image from the relevant video feed and event detection module  performs face recognition analysis, matching the face that appears on the feed to a database of faces stored on an archive. It finds a match for an employee, and retrieves a pre-existing photograph of the employee. Report module  then inserts this identifying picture is then inserted into placeholder in the template document . A similar process of event detection, followed by the insertion of meta data about the event, the performance of face recognition on video data, and the insertion of a stock photo of an identified employee is repeated to produce the output of the second section . The third section reflects a slightly different event, the event of a conversation between two employees. The detection of the event by event detection module  triggers the capture of the conversation, and the creation of a bar code index to the event by indexing\/mapping module  to be inserted in the third section . At the same time, rather than inserting a stock photo, report module  inserts a frame that has been grabbed from the video feed by filtering\/processing module . The completed report  is sent to a printer to be output.","The foregoing description of the embodiments of the invention has been presented for the purpose of illustration; it is not intended to be exhaustive or to limit the invention to the precise forms disclosed. For example, any number of functionalities disclosed and hardware or software required to carry out these functionalities could be added to a conventional printer. Modifying an already existing network of printers to include multimedia monitoring and processing capabilities disclosed could create a minimally intrusive monitoring network and at a minimal additional cost. Persons skilled in the relevant art can appreciate that many modifications and variations are possible in light of the above teachings. It is therefore intended that the scope of the invention be limited not by this detailed description, but rather by the claims appended hereto."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1B"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 2","FIG. 1A"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 10","FIG. 9"]}]},"DETDESC":[{},{}]}
