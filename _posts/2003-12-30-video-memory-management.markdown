---
title: Video memory management
abstract: A video memory manager manages and virtualizes memory so that an application or multiple applications can utilize both system memory and local video memory in processing graphics. The video memory manager allocates memory in either the system memory or the local video memory as appropriate. The video memory manager may also manage the system memory accessible to the graphics processing unit via an aperture of the graphics processing unit. The video memory manager may evict memory from the local video memory as appropriate, thereby freeing a portion of local video memory use by other applications. In this manner, a graphics processing unit and its local video memory may be more readily shared by multiple applications.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06947051&OS=06947051&RS=06947051
owner: Microsoft Corporation
number: 06947051
owner_city: Redmond
owner_country: US
publication_date: 20031230
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS"],"p":["This application claims priority of U.S. Provisional Application Ser. No. 60\/448,399 entitled \u201cVideo Memory Manager Architecture,\u201d filed Feb. 18, 2003.","The invention relates generally to the field of computing, and, more particularly, to a technique for performing video memory management and virtualizing video memory.","The use of graphics in computers has increased dramatically over the years due to the development of graphics based user-friendly application programs and operating systems. To support the computing requirements associated with graphics, computer component manufacturers have developed specialized graphics processing units (GPUs) to offload some of the intense graphics computing demands from the central processing unit (CPU) to these specialized GPUs. Many of these GPUs are implemented on a Peripheral Component Interconnect (PCI) compatible card and include local graphics memory (also referred to herein as video memory) on the card itself. This local video memory enables the GPU to process graphics more quickly.","Current operating systems typically grant GPU resources (e.g., video memory) on a first come-first served basis. If one application has been allocated all of the GPU resources (e.g., the entire local memory of the GPU), then other applications may not be able to run or they may run with errors. As the use of GPUs may become more prevalent, there is a need for techniques for more fairly allocating GPU resources among applications.","A video memory manager manages and virtualizes memory so that an application or multiple applications can utilize both system memory and local video memory for processing graphics with a graphics processing unit. The video memory manager allocates memory in either the system memory or the local video memory as appropriate. The video memory manager may also manage system memory accessible to the graphics processing unit via an aperture of the graphics processing unit. The video memory manager may also evict memory from the local video memory as appropriate, thereby freeing a portion of local video memory use by other applications. In this manner, a graphics processing unit and its local video memory may be shared by multiple applications.","The video memory manager may distinguish between various types of graphics data and treat them differently. For example, resources may be distinguished from surfaces. Resources may be stored in a kernel mode of the operating system. Surfaces may be stored in a user mode process space of the operating system. Surfaces may be classified as either static or dynamic, depending on whether the central processing unit has direct access to the surface.","The video memory manager may use a fencing mechanism, for example, a monotonic counter, to determine information about the status of the graphics processing unit. The graphics processor may increment the counter for each command buffer processed. The video memory manager may determine whether a surface has been used or is about to be used by reading the counter.","Memory allocation may be divided into big and small memory allocations and treated differently. Big memory allocations may use entire dedicated pages. Small memory allocations may share a single page to conserve memory.","Other features are described below.","Computer System",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 1","b":["100","100","100","100"]},"The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, embedded systems, distributed computing environments that include any of the above systems or devices, and the like.","The invention may-be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network or other data transmission medium. In a distributed computing environment, program modules and other data may be located in both local and remote computer storage media including memory storage devices.","With reference to , an illustrative system for implementing the invention includes a general purpose computing device in the form of a computer . Components of computer  may include, but are not limited to, a processing unit  (e.g., central processing unit CPU ), a system memory , and a system bus  that couples various system components including the system memory  to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus (also known as Mezzanine bus).","Computer  typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CDROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer . Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , other program modules , and program data . System memory  may be separated into kernel memory (which is a memory protected by the operating system ) and application or process memory (which is a memory used by application programs  and is subject to less protection than kernel memory).","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk , such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the illustrative operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media discussed above and illustrated in , provide storage of computer readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that, at a minimum, they are different copies. A user may enter commands and information into the computer  through input devices such as a keyboard  and pointing device , commonly referred to as a mouse, trackball or touch pad. Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . In addition to the monitor, computers may also include other peripheral output devices such as speakers  and printer , which may be connected through an output peripheral interface .","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer , although only a memory storage device  has been illustrated in FIG. . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on memory device . It will be appreciated that the network connections shown are illustrative and other means of establishing a communications link between the computers may be used.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 2","FIG. 2"],"b":["100","1","190","290","290","290","290","110","120","290","291","291","191"]},"Video interface  communicates with other devices in computing environment  via Peripheral Component Interconnect (PCI) controller  and chipset . GPU  may include an aperture  that functions as a high-speed \u201cwindow\u201d into system memory . That is, aperture  of GPU  maps to corresponding system memory  and allows GPU  to view system memory  via a virtual memory addressing scheme. This allows GPU 's view of a memory allocation to appear contiguous, even though the memory allocation may actually be located in discontiguous physical system memory pages.","Video memory manager  may provide address translation for GPU , thereby virtualizing memory for GPU . Video memory manager  may include an address translation mechanism to convert between virtual addresses and physical memory addresses. In this manner, GPU  may be more easily shared between multiple applications at the same time. Video memory manager  (also referred to herein as VidMm) may reside in a kernel mode component of operating system .","Application program  may access various components of computing environment  via driver . Driver  may be implemented as two separate drivers, such as, for example, a user mode driver and a kernel mode driver. The user mode driver (which is typically provided by a GPU supplier) is typically loaded in the private address space of application . The user mode driver may request the creation and destruction of memory allocation and generate their references. However, the user mode driver is typically not involved in the actual management of allocations (e.g., the allocation of actual underlying resources, paging, eviction, and the like). The kernel mode driver (which is typically provided by a GPU supplier) is typically loaded in kernel space of operating system . The kernel mode driver may interact with video memory manager  in the management of allocations. For example, when video memory manager  desires to evict an allocation from video memory to system memory, video memory manager  may call the kernel mode driver, which in turn requests GPU  to perform some function associated with eviction.","Such virtualization is made possible because GPU  only needs a subset of the allocated memory to be present in local video memory  or non-local video aperture  at any given time. For example when drawing a triangle for an application, GPU  only uses the texture for that triangle, not the entire set of texture used by the application. Thus video memory manager  may attempt to keep the correct subset of graphics content visible to GPU  and move unused graphics content to an alternative medium (e.g., system memory ).","Video memory manager  may arbitrate the resources among the applications by tracking the allocations made on behalf of every process and balancing resource usage among the processes. Video memory manager  may implement the virtualization of memory through the use of a video memory manager  created handle. Clients (e.g., application ) of video memory manager  may reference addresses and allocations through the use of the handle. In this manner, a client may not actually know the physical address of the graphics data. Video memory manager  may convert a given handle to a GPU visible address.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIG. 3","FIG. 3"],"b":["200","200","310","320","330","310","305","200","100","310","310"]},"Video Memory Manager and Address Translation","Virtual memory manager  includes an address translation mechanism  which performs address mapping between a source  (e.g., application , GPU , and the like) that requests data and a data storage device containing the requested data (e.g., video memory ). The requested data may be stored in video memory , system memory RAM , system memory  and may be accessible via GPU aperture , hard disk , and other addressable entities.","Address translation mechanism  may perform various address mapping functions between sources and addressable entities (e.g., memory, etc.).  depicts a simple addressable entity (), where each row of the table has a member of A on the left, and a member of M on the right. Thus, in the example of , if f is the function defined by addressable entity (), then f(\u2018a\u2019)=17, f(\u2018b\u2019)=6, f(\u2018c\u2019)=3, and so on.","With reference to , a write operation  (\u201cwrite(\u2018b\u2019,14)\u201d) on the simple addressable entity () changes the mapping to ()\u2032, by changing the value \u201c6\u201d to \u201c14\u201d on the line whose set \u201cA\u201d value is \u2018b\u2019. If read operation  (\u201cread(\u2018b\u2019)\u201d) is subsequently performed on mapping ()\u2032, this read operation will return the value \u201c14,\u201d since write operation  has changed the original mapping () such that the set A element \u2018b\u2019 now maps to the set M element \u201c\u201d. As noted above, the semantics that allow a read operation following a write operation to return the value that was written are illustrative, but not definitive, of an addressable entity. As discussed below, there are examples of addressable entities whose read and write operations have different semantics.","Addressable entities include physical random access memory (e.g., RAM , shown in FIG. ).  shows an example of RAM  as an addressable entity. RAM , in this example, comprises 2bytes, each having a physical address in the range 0 to 2\u22121. In this example, the value 17 is stored at address , 6 is stored at address , 137 is stored at address , and so on. Addressable entities also include control registers, CPU registers, and the like.","Address translation mechanism  may be based on paging and segmentation schemes.  depict examples of such schemes. It should be understood that pages and segments are a way of grouping addressable entities and into \u201cbuckets\u201d so they can be dealt with conveniently in large units.",{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIG. 8","FIG. 8","FIG. 8","FIG. 8"],"b":["132","806","1","806","2","806","132","806","1","806","2","806","0","1","4095"],"i":["n","n"]},"Page table  is a list of pointers to the various pages () through (). Each entry in page table  may also contain one or more \u201cattributes\u201d as described above\u2014i.e., a marker that indicates whether the page pointed to by the pointer is read\/write or read-only, or another marker that indicates whether the page is \u201cpresent\u201d in RAM  or \u201cnot present.\u201d (A page might be marked as not present if, say, it had been swapped to disk to make room in RAM  for other data.) Each element of page table  contains the base address of a page in the page table. Moreover, each element can be identified by an offset into the page table. Thus, the element of page table  stored at offset  is 0x0000, which is the base address of page (); the element stored at offset  is 0x2000, which is the base address of page (); and the element stored at offset  is 0xf000, which the base address of offset (). Other offsets into page table  point to different pages that are not depicted in FIG. . It should be noted that page table  is typically stored in RAM , and shown by the dashed line encompassing page table .","Address translation mechanism  may use page table  to convert a virtual address  into a physical address. Address translation mechanism  may include hardware and software that performs various functions, including the translation of virtual addresses into physical addresses. In the example of , virtual address  comprises two parts: a table offset  and a page offset . Address translation mechanism  identifies a particular physical address in RAM  based on virtual address . In order to identify a physical address, address translation mechanism  first reads table offset , and uses this value as an index into page table . Next, address translation mechanism  retrieves whatever address appear in the page table  entry defined by table offset , and adds page offset  to this value. The resulting value is the address of a particular byte in one of the pages () through (). In the example of , table offset  is 0x0002. Thus, address translation mechanism  locates the base address stored at offset  from the beginning of page table . In this case, that base address is 0x2000. Address translation mechanism  then adds page offset  to the value located in the page table. Page offset , in this example, is also 0x0002, so address translation mechanism  adds 0x2000+0x0002=0x2002, which is the physical address of the byte in page () that is indicated by slanted lines.","Address translation mechanism  may also be configured to perform some action based on the attribute(s) contained in the page table. For example, if the access request is to write to a byte of memory, and the page table entry for the page in which that byte is located indicates that the page is read-only, then address translation mechanism  may abort the request and\/or invoke some type of fault handler. Similarly, if the byte is on a page marked as \u201cnot present,\u201d then video memory manager  (or the memory manager of the operating system) may take steps to copy the image of the page back into RAM  from wherever that image is stored (e.g., disk), and\/or may invoke some type of fault handler.",{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 9","b":["305","305","808","811","812","305"]},{"@attributes":{"id":"p-0057","num":"0056"},"figref":["FIG. 10","FIG. 10"],"b":["132","1006","0","1006","1","1006","2","1006","3","1008","1006","0","1006","3","1006","0","4096","1006","1","1024","1008","132","1008"]},"Address translation mechanism  converts a virtual address  into a physical address using segment table . Virtual address  comprises a segment number  and a segment offset . Thus, in the example of , address translation mechanism  uses segment number  as an offset into segment table . In this example, segment number  is \u201c1\u201d, so address translation mechanism  looks at offset  into segment table , and locates the address 0x4000. Address translation mechanism  then adds segment offset  (in this case 0x0000) to this address to create a physical address. Thus, 0x4000+0x0000=0x4000. Thus, address translation mechanism  identifies the byte in segment () indicated by slanted lines.","Moreover, the virtual address may include a field or bits to indicate which storage medium contains the physical memory. For example, a first field (of two bits) may have the value of one if the physical memory is in video memory , may have the value of two if the physical memory is in system memory  and not visible through non-local aperture , and may have the value of three is the physical memory is in system memory  visible through non-local aperture .","As seen, address translation allows video data to be stored in various data storage devices and allows virtualization of video memory (e.g., video memory , non-local aperture , system memory ). Video memory manager  may also perform memory management (including memory allocation\/deallocation) to support the virtualization of memory. A video memory allocation is a collection of bits that holds some content for a surface. Before discussing memory management in detail, we describe various types of graphics data and resources for processing graphics.","Surfaces","A surface represents a logical collection of bits allocated on behalf of an application. The content of a surface (i.e., the logical collection of bits) is typically under the control of the application. A surface may be constructed out of one or more video memory allocations. These video memory allocations may or may not be directly visible to the application even though the application can ultimately control the content. An example of a surface having more than one video memory allocation is a palletized texture on hardware that doesn't support such a type of texture. The driver could use one video memory allocation to hold the content of the texture in palletized mode, and use a second video memory allocation to hold the content of the texture in expanded mode. Surfaces may be dynamic or static\u2014the difference is how the application accesses the content of that surface.","A static surface is a surface for which the application doesn't have direct CPU access to the bits of the surface, even though it can control the content indirectly. An application may understand the logical format of the surface and control the content, for example, through a GPU operation. \u2018Static\u2019 means that the content of the surface should only change if those surfaces are the target of a GPU  operation. Static surfaces may be used to allocate textures, vertex buffers, render targets, z-buffers, and the like. A static surface may include multiple static video memory allocations, described in more detail below.","Dynamic surfaces are similar to static surfaces, except that an application can request to have direct CPU access to the bits of the surface. Dynamic surfaces allow the application to access the content of the surface through GPU operation and through direct CPU access. A dynamic surface includes at least one dynamic video memory allocation and can include static video memory allocations, described in more detail below.","Resources","A resource is a memory allocation (e.g., video memory) that driver  may use to support one or more applications but for which no application controls or should be allow to control the content directly. For example, when an application uses a vertex shader, the driver compiles the shader into a GPU specific binary that is executed by the GPU. While the application controls the content of that buffer indirectly by specifying the vertex shader to use, the application doesn't control the exact binary that get produced. For security reasons, the content of those allocations are not typically made directly available to the application. A resource typically includes a single physical video memory allocation. Resources include application resources and driver resources.","An application resource is a resource used by driver  to support a particular application but the resource can't be directly accessed by the application. If the resource fails, the application doesn't work properly, but other applications continue to work properly. An example is a pixel shader binary compiled for a particular application's pixel shader code, an application GPU page table, and the like.","Driver resources are resources that driver  uses to allow the operation of all applications. The difference is that driver resources aren't bound to a particular application. A driver resource may be, for example, the primary swap chain for the desktop.","Video Memory Allocation","As stated above, a video memory allocation is a collection of bits that holds some content for a surface. A static video memory allocation is a video memory allocation that, in general, is not directly accessed by CPU . A dynamic video memory allocation is a video memory allocation that may be directly accessed by CPU , A dynamic surface, therefore, includes at least one dynamic allocation while a static surface does not include a dynamic allocation.","A physical video memory allocation is an allocated range in a particular physical video memory segment of video memory .","A non-local aperture allocation is an allocated range in the physical space controlled by non-local aperture . It should be understood that this type of allocation can't by itself hold any graphics data. It's only a physical space allocation and that physical space in non-local aperture  is redirected to the system memory  (e.g., pages holding the video memory allocation data).","Video Memory Manager","Video memory manager  performs various functions during memory management, such as for example, allocation and deallocation of physical memory, allocation and deallocation of virtual memory, protection of memory, eviction of data from one data storage device to another, and the like. Video memory manager  may use one or a combination of a virtual memory manager , a physical memory manager , and a non-local aperture manager  to perform various functions related to memory management. While video memory manager  is shown as having three memory managers, video memory manager  may include any number of memory managers and the functionality may be apportioned between the various memory managers in any convenient fashion.","Physical Memory Manager","Physical memory manager  manages physical video memory  and a portion of physical system memory . Physical memory manager  attempts to find an appropriate free range of contiguous physical video memory  when a video memory allocation is requested. When physical video memory  is full, physical memory manager  (in conjunction with virtual memory manager ) may evict data to system memory . Physical memory manager  may also determine which allocation to evict when physical video memory  is full. The address space of the physical video memory  can be divided into one or more segments and each segment may be managed separately as a linear heap, pages, and the like. Driver  may decide how each segment should be managed.","The physical address space of GPU  may be divided into multiple segments (referred to herein as physical video memory segments) that form the pool of available local video memory . Each physical video memory allocation is allocated from one of those segments. Segmenting the physical address space of GPU  allows different portions of video memory  to be treated differently. For example, only a subset of the address space might be visible through the aperture. Similarly, certain type of surfaces might only be allocated from certain segments, and not others.","In heap management mode, physical memory manager  may create a heap the size of the segment and satisfy requests for memory allocations by allocating a linear contiguous range in that heap. Physical memory manager  may maintain for each segment a list of surfaces and a list of processes having commitment in the heap, as shown in FIG. . The list of allocations may be maintained in a least recently used (LRU) order. Each time driver  notifies physical memory manager  of the usage of an allocation, physical memory manager  puts that allocation at the end of the list for the segment in which it is allocated. Similarly, each time a surface is allocated in the segment, the process it's associated with is updated with information about how much memory it has committed in that segment. These two pieces information may be used to implement an eviction policy.","When the segment is full and something needs to be allocated, physical memory manager  may chose as candidate for eviction, as follows. First, check if some surfaces haven't been used for a long time and move those surfaces to the eviction list (and add their memory to the free list). Second, try allocating memory again. If successful, determine which allocation in the eviction list gets to be reused, evict those allocations to system memory , and return a new physical address to the caller. Third, trim all processes to the maximum working set. For each process, move all the least recently used allocations to the eviction list until that process's total committed memory is below the maximum working set. Fourth, try allocating memory again. Fifth, trim all processes to the minimum working set. For each process, move all the least recently used allocations to the eviction list until that process's total committed memory is below the maximum working set. Sixth, try allocating memory again. Seventh, scan the list of allocations for that process in LRU order\u2014if a block fits, use it. Eighth, try allocating memory again. Ninth, if the surface shouldn't be aggressively committed, return an error to the caller. Tenth, mark all allocations already committed for that process in the heap for eviction. Eleventh, try allocating memory again. Twelfth, mark all allocations in the heap for every process (from the surface allocator) as ready for eviction. Thirteenth, try memory allocation again.","When marking surfaces for eviction, physical memory manager  doesn't have to actually evict the surface at that moment\u2014it can just reclaim the physical memory range (and remember the range in the eviction list). When memory is actually allocated for the new allocation, physical memory manager  may check the list to see which surface is currently located in that range. Then, physical memory manager  may evict those surfaces from video memory  and truly reclaim memory. Surfaces not actually evicted may remain on the eviction list until the next eviction or until driver  references a surface, in which case it may be removed from the eviction list and put back at the end of the allocated list. An illustrative API for use by driver  to allocate physical memory for an application or a driver resource is given by:",{"@attributes":{"id":"p-0076","num":"0075"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmAllocateContiguous("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN VIDMM_SEGMENT Segment,"]},{"entry":[{},"\u2003\u2003IN SIZE_T Size,"]},{"entry":[{},"\u2003\u2003IN ULONG Alignment,"]},{"entry":[{},"\u2003\u2003OUT PPHYSICAL_ADDRESS PhysAddress);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"A surface allocator for dynamic and static surfaces may use a slightly different API to allocate physical memory, as shown below.",{"@attributes":{"id":"p-0078","num":"0077"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmiAllocateContiguous("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN VIDMM_SEGMENT Segment,"]},{"entry":[{},"\u2003\u2003IN HANDLE hAlloc,"]},{"entry":[{},"\u2003\u2003IN BOOLEAN Aggressive);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},{"@attributes":{"id":"p-0079","num":"0078"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmFreeContiguous("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN PPHYSICAL_ADDRESS PhysAddress);"]},{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmiFreeContiguous("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN HANDLE hAlloc);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"Non-local aperture manager  manages non-local aperture . Non-local aperture manager  doesn't actually \u201callocate\u201d any memory; rather, non-local aperture manager  allocates a memory range in aperture  itself. Aperture  is really an address space and thus non-local aperture manager  doesn't really allocate memory but allocates address space to be redirected (mapped) to some actual system physical memory in system memory . Non-local aperture manager  may manage the space inside the aperture on a page basis. Once a range is allocated, non-local aperture manager  can lock a system memory surface into place and map it through the non-local aperture . Non-local aperture manager  may call a driver responsible for aperture  to do the mapping on its behalf.  depicts illustrative management of non-local aperture . An illustrative API is given below.",{"@attributes":{"id":"p-0081","num":"0080"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmNonLocalMap("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN PVOID pvLin,"]},{"entry":[{},"\u2003\u2003OUT PPHYSICAL_ADDRESS PhysAddr);"]},{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmNonLocalUnMap("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN PHYSICAL_ADDRESS PhysAddr);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"Virtual memory manager  may perform dynamic and static video memory allocations. Virtual memory manager , in effect, creates a hierarchy of data storage for graphics data. Thus, as described above, a video memory allocation may not be resident in physical video memory . Instead, the bits of a video memory allocation might be in physical video memory , in physical system memory  (and may be visible or not visible through aperture ), or even on hard disk  accessible via the page file system of operating system .","Resource Allocation and Management","As described above, resources are important to the proper rendering of graphics. As such, video memory manager  (in conjunction with virtual memory manager ) may attempt to protect some memory (e.g., memory associated with a resource) from being corrupted by other applications. Some processors allow physical memory to be accessed directly, so an application program  (also referred to herein as a process) could execute an instruction to access a given physical address regardless of whether that address had been assigned to the process's address space.","Video memory manager  may protect a video memory allocation by implementing a process specific handle for each process, by allowing direct CPU access only to video memory allocations owned by a specified process, and the like, described in more detail below.","Video memory manager  may also protect a video memory allocation in system memory  by storing the video memory allocation in kernel memory while other (typically less critical) video memory allocations may be stored in the private process address space of an application . Kernel memory is the area of memory used by operating system  and provides protection against access by processes. That is, when allocating memory for a resource, video memory manager  (e.g., via virtual memory manager  and physical memory manager ) may allocate memory in the kernel memory portion of system memory  if there is not appropriate space in video memory . Also, video memory manager  may store the actual mappings from handles or virtual addresses to actual physical addresses in kernel memory to protect the mappings from being accessed by other applications, etc. Further, video memory manager  (e.g., via virtual memory manager  and physical memory manager ) may evict resource video memory allocations to the kernel memory portion of system memory  and adjust the virtual memory mappings accordingly.","Alternatively, video memory manager  may not evict any resources, but maintain all resources in video memory . This type of allocation may be offered to driver  by means of directly allocating physical video memory  that is not evictable. In such a case, drivers should keep the number of such allocations small, otherwise physical video memory  may get filled with unevictable allocations.","When visible through the non-local aperture , the video memory allocation may be locked in system memory (e.g., using MnProbeAndLockPages( ) mechanism) and mapped through non-local aperture . In this state, the bits of the video memory allocation still reside in the page file system but should remain present in physical system memory  because of the locking operation. To map the video memory allocation through the non-local aperture , a range is allocated in the aperture  itself, referred to herein as a non-local aperture allocation.","Application Access to Graphics Data","When application  sends a rendering command to driver  that references an allocation, driver  informs video memory manager  about the reference so that video memory manager  can load the surface in some accessible physical memory for GPU . If the surface is currently in system memory , video memory manager  may look at flags of the surface and allocates the proper GPU resource (e.g., some address range of non-local aperture  or some address range of local video memory ). If the surface was allocated in video memory , then the video memory manager  allocates memory from the physical memory manager . If the surface was allocated in non-local aperture , then the video memory manager  sends the virtual address of the allocation's system memory buffer to the non-local aperture allocator  which may lock the memory and map the memory through non-local aperture .","Static Video Memory Allocation and Management",{"@attributes":{"id":"p-0089","num":"0088"},"figref":"FIG. 18","b":["130","290"]},"In theory, video memory manager  could allocate a static video memory in system memory  only when the allocation is evicted to system memory  and could free the corresponding portion of system memory  when the allocation resides in local video memory . A disadvantage with this approach is that the virtual address space of the application is also used by the application itself for regular memory allocation. Thus, there is no guarantee that video memory manager  could allocate space in the private address space of the application for the static video memory allocation upon an eviction from video memory . Therefore, video memory manager  may keep the static video memory allocation of system memory  to save space for an eviction from physical video memory .","When video memory  is full, video memory manager  may evict a static allocation to make place for a new allocation. In such a case, video memory manager  brings the content of video memory  back to system memory . If the surface hasn't been modified since it was cached from system memory , then the content of video memory  may be discarded. If the content was modified, then non-local aperture manager  may map the system memory allocation through non-local aperture  and request driver  to transfer the content of video memory  to that buffer. Once the transfer is completed, the surface is unmapped from non-local aperture .","If the surface is currently mapped through non-local aperture , the eviction is relatively easy. As explained before, an allocation visible through the non-local aperture  has its virtual address referencing the pages in system memory . The pointer remains the same whether or not non-local aperture  is redirecting GPU  to the same physical pages. Because of this, removing the redirection range in non-local aperture  has no effect on the application accessing the surface through the CPU page table. Thus, to evict the surface from non-local aperture , video memory manager  reclaims the previously reserved range in aperture  that was being redirected to that allocation and unlocks the page from system memory  so the operating system memory manager can page them out to hard disk . That is, video memory manager  may unmap unused allocations from non-local aperture . The ranges of non-local aperture  that were unmapped can then be reclaimed by video memory manager  (and subsequently reused for other allocations to be accessed by GPU )","Evicting from physical video memory  is more complex than evicting from non-local aperture . When the eviction occurs while the surface is in video memory , video memory manager  allocates pages in system memory  for the allocation, copies the content of the surface from video memory  to these allocated pages, and remaps the user mode virtual address to reference the newly allocated pages. This entire process should occur while the application can actually be accessing the virtual address that needs to be copied and remapped. This may be handled by the memory manager of the operating system through the API MmRotatePhysicalView( ). This API allows rotation of the virtual address from a physical video memory location to a system memory location as an atomic operation as seen by the application.","Static allocations may be allocated from a heap that is created in each process the first time a static allocation is requested. The heap may be managed like a regular heap and the surfaces allocated as regular system memory. The linear address from the heap allocation may be associated with that allocation for it's life. Allocating a static buffer may include allocating the surface in the process video heap. Since there is no content for the surface at creation time, there is no need to actually allocate any video memory  or system memory  viewable through non-local aperture  at that time.","A memory heap is a range of virtual space, in the process private virtual memory space, for allocation of virtual memory. Typically, each video memory allocation gets a small portion of the heap. The heap may grow over time and can actually include multiple ranges of virtual space if the original range can't be grown. A heap may be used to reduce fragmentation of the address space of the application. The heap may be allocated as a rotatable virtual address range. In a rotatable range, video memory manager  can specify for each page of the heap, whether to refer to a location in the frame buffer or to be backed by a page of system memory .","Dynamic Video Memory Allocation and Management","Dynamic video memory allocations use a medium to hold the bits of the allocation and a virtual address referring those bits. Virtual memory manager  may use either physical video memory  or system memory  to hold the bits of a dynamic video memory allocation. While in physical video memory  the dynamic video memory allocation is associated with a physical video memory allocation (from physical video memory manager ). In this state, the video memory allocation is directly visible to GPU  and can be used for rendering operations.","When the bits of the allocation are evicted from video memory , or mapped through the non-local aperture , video memory manager  allocates a portion of system memory  to store those bits. The system memory could potentially be allocated from either the kernel memory or the process space of the application. Since kernel memory is a limited resource that is shared among all applications, video memory manager  allocates from the process space of the application. Because system memory is allocated from the process space of the application, an application can access the bits of that allocation directly without going through the locking mechanism. Because the application controls the content of those allocations anyway, this isn't a security violation. This may result in unknown data being present on those allocations (which may result in a rendering artifact), but it typically won't affect other applications or hang GPU .","When the bits of an allocation reside in system memory , they can't be directly accessed by GPU  unless the physical system pages forming the buffer of system memory are made visible through non-local aperture . In that state, the dynamic video memory allocation will be associated with a range of non-local aperture address space allocated by the non-local aperture manager . The non-local aperture hardware of GPU  redirects that address space to the appropriate physical pages in system memory .","In theory, the virtual address referring to the bits of the allocation is used only when the application accesses those bits or when the surface is in system memory  (to hold the content of the allocation). Thus, when the surface is currently cached in video memory  and the surface isn't being accessed by the application, the virtual address isn't needed. However not having a virtual address associated with the allocation at all time may cause a problem when video memory manager  transitions the allocation from one state to another because it might not be able to allocate that virtual address if the application process space doesn't contain a range large enough for the allocation. In that case, it is possible that a surface couldn't be evicted from video memory  because of not enough free memory in system memory .","For this reason, video memory manager  may associate a virtual address to a dynamic video memory allocation when it's first allocated and store the virtual address as long as the allocation exists. This way, video memory manager  has the virtual address when changing the state of the allocation. Similarly, that virtual address is typically committed up front rather than waiting until eviction time.",{"@attributes":{"id":"p-0101","num":"0100"},"figref":"FIG. 11","b":["291","130"]},"The application  may call the Lock( ) function to obtain the virtual address. When the application is done with the access, it may call the Unlock( ) function to allow GPU operations on the allocation to resume. The application may call the Lock( ) function before accessing the content of the allocation to insure that the driver had a chance to flush all graphics operations for that allocation. Graphics operations (or dma) referencing the allocation should not be sent to GPU  while the surface is being accessed by the application.","The application  typically cannot determine the actual physical location of the allocation when it's accessing it through the virtual address. Furthermore, the actual physical location can be modified while the allocation is being accessed. Video memory manager  could decide, for example, to evict the surface being accessed out of video memory  to make room for another allocation. This eviction process is transparent to application  and doesn't result in any loss of content.","The granularity of the virtual address may define the granularity of the allocation to protect each process's video memory from one another. Similarly, because of the way virtual memory works, the lower \u201cn\u201d bits of a virtual address are really the offset within the physical page where the bits are being held. Thus those \u201cn\u201d lower bits of the virtual address are the same as the \u201cn\u201d lower bits of the physical address, which means that once a surface has been allocated at a specified offset within a page it remains at that relative offset within the new medium even if remapped to a new location. For example, evicting an allocation out of video memory  while being accessed by application  implies having a virtual address in system memory  that has the same lower \u201cn\u201d bits as the current location in physical video memory . The same is true when bringing the surface back to video memory . Therefore, video memory manager  may find a location in video memory  that has the same lower \u201cn\u201d bits as the virtual memory for that allocation.","One mechanism to allocate the virtual address associated with a dynamic video memory allocation may be a memory manager of operating system  (also referred to herein as Mm) that supports a rotatable virtual address description (VAD). When the content of the allocation isn't present in physical video memory , the VAD may be rotated to regular pageable system memory . When the allocation is brought in to physical video memory , the VAD is MEM_RESET so that Mm can reuse the physical pages that were used without transferring the content to the page file on disk. At the first lock operation, the VAD is rotated to the physical memory location where the surface resides in physical video memory . The VAD isn't rotated back on an unlock, instead the VAD referencing the physical video memory location is stored until the allocation is either moved in video memory , freed or evicted to system memory .","Using this mechanism, video memory manager  can control the virtual address space of the application on the natural page size of computing environment  (e.g., 64 K), which means that allocations are expanded to the next page size. To reduce the impact of this expansion, video memory manager  may distinguish between big allocations and small allocations. Video memory manager  may align a big allocation to the natural page size and video memory manager  may pack small allocations inside of chunks to conserve space. The chunks may be managed by the video memory manager  similar to regular dynamic video memory allocations. When video memory manager  changes the state of one surface within the chunk, it may change the state of all the sub-allocations. A virtual memory chunk is a range of virtual space in the process private virtual memory space. It is similar to a process video memory heap except that it typically holds only a few surfaces. The surfaces in the virtual memory chunk may be moved in and out of local video memory  by video memory manager .",{"@attributes":{"id":"p-0107","num":"0106"},"figref":"FIG. 12","b":["135","135","290","135"]},"In state one, the bits of the allocation reside in physical video memory . In this case, the dynamic video memory allocation is associated with a physical video memory allocation from the physical video memory manager . In state one, there doesn't need to be a virtual address referring to physical video memory  as the allocation doesn't need to be accessible. Physical memory could be allocated from a segment that is visible or not visible to CPU . From state one, the allocation can be locked by application  for direct CPU access or evicted out of video memory  to make room for another allocation. In state one, the rotatable VAD for the allocation could be either referring to system memory, if the allocation hasn't be locked yet at it's current location, or rotated to the physical video memory location otherwise.","In state two, the bits of the allocation reside in physical video memory  and the rotatable VAD is currently rotated to the physical video memory location where the allocation resides. Thus, the bits of the allocation can be allocated from a segment that is visible to CPU . If the surface was originally allocated from a segment not visible to CPU  (e.g., in state one) the allocation may be moved to a segment that is visible before the allocation reaches state two. While in state two, application  typically does not send rendering commands to GPU  referring to the allocation. First, application  relinquishes its hold on the virtual address associated with the surface. While in state two, the surface can still get evicted to system memory . In this case, the VAD is rotated to system memory  and the memory manager of the operating system may ensures that this process appears atomic to application  (i.e. the application's access to the virtual address will continue normally during the transfer and no content is lost).","In state three, the bits of the allocation reside in regular pageable system memory . Thus, the dynamic video memory allocation is no longer associated with a physical video memory allocation. In state three, the rotatable VAD may be rotated back to system memory . Even though a virtual address to the bits of the allocation are accessible by application , application  should not try to access those bits while in state three since the runtime may not synchronize accesses with a GPU rendering command. If application  requests a rendering command referencing the allocation, the allocation is brought back to state one or four before GPU  can access the allocation.","In state four, video memory manager  has decided to make the allocation visible through non-local aperture . In state four, the bits of the allocation still reside in system memory  (e.g., VAD rotated to system memory ). However, the pages are locked in place and cannot be paged to hard disk . The GPU can access the allocation through the non-local aperture range directly. Similar to state three, an application should not use the virtual address referencing the allocation directly as this virtual address isn't guaranteed to contain data in the format the application expects or even be valid (e.g., the allocation could transition into another state).","In state five, the allocation is visible through non-local aperture , however, the application may directly access the virtual address referring to the physical system pages of the allocation. While in state five, video memory manager  keeps the virtual address valid and may refuse any GPU rendering command referencing the allocation until application  relinquishes its hold on the allocation. In this case, evicting the surface out of non-local aperture  doesn't have any consequences on application  because the virtual address remains the same except that the non-local aperture  no longer redirects a range to physical system pages referred to by the virtual address.","In state six, the allocation is in system memory , like state three, except that application  may access the bits of the allocation directly. In state six, application  shouldn't send rendering commands to GPU  that reference the allocation (the application should first relinquish hold of the virtual address).",{"@attributes":{"id":"p-0114","num":"0113"},"figref":["FIG. 13","FIGS. 13 and 14"],"b":["1000","320"]},"As shown in , at step , virtual memory manager  allocates virtual memory for referencing some physical memory, which in turn stores the graphics data.","At step , physical memory manager  allocates the physical memory to store the graphics data. The physical memory may be located in video memory , may be located in system memory  and not accessible via aperture , may be located in system memory  and accessible via aperture , and the like.","At step , virtual memory manager  maps from the virtual address allocated in step  to the physical address allocated at step . In this manner, by working with virtual addresses, application  or driver  may request the graphics data without having to know where the graphics data is currently stored.","At step , video memory manager  moves the graphics data from one physical location to another physical location, from being mapped through aperture  to not being mapped through aperture , and the like. At step , virtual memory manager  maps from the virtual address to the \u201cnew\u201d physical address.",{"@attributes":{"id":"p-0119","num":"0118"},"figref":["FIG. 14","FIG. 14","FIG. 14"],"b":["1040","200","1140","200","291","1150","200","291","1160","200","130","292","1170","200","292","200"]},"For example, for a resource, such as an application resource or a driver resource, virtual memory manager  may allocate and commit a kernel virtual address range for the resource. resource. To bring the resource to local video memory , physical memory manager  may allocate memory in local video memory  for containing the resource and may cause the resource to be copied from memory corresponding to the committed kernel virtual address range to the memory allocated in local video memory . Virtual memory manager  may map the kernel virtual address range to the memory allocated in local video memory .","To evict the resource from local video memory , physical memory manager  may cause the resource to be copied from the memory allocated in local video memory  to memory corresponding to the committed kernel virtual address range and then free the memory allocated in local video memory . Virtual memory manager  may free the mapped kernel virtual address range.","To bring the resource \u201cinto\u201d aperture , physical memory manager  may lock the committed kernel virtual address range, whereby the operating system does not have permission to page out the resource from the system memory corresponding to the committed kernel virtual address range. Graphics processing unit aperture manager  may allocate an address range in aperture  for redirection to the resource and may cause the address range in aperture  to be mapped to the committed kernel virtual address range.","To evict the resource from aperture , graphics processing unit aperture manager  may unmap and free the address range allocated in aperture . Physical memory manager  may unlock the committed kernel virtual address range, whereby the operating system has permission to page out the resource from the system memory corresponding to the committed kernel virtual address range.","Alternatively, a resource may be permanently allocated in video memory  or aperture . To permanently allocate memory in video memory , physical memory manager  may allocate memory for the resource in the local video memory and not evict the allocated memory from local video memory. Virtual memory manager  may allocate and commit a kernel virtual address range for the resource and map the kernel virtual address range to the memory allocated in local video memory.","To permanently allocate memory in video memory , virtual memory manager  may allocate and commit a kernel virtual address range for the resource. Physical memory manager  may lock the committed kernel virtual address range, whereby the operating system does not have permission to page out the resource from the system memory corresponding to the committed kernel virtual address range. Graphics processing unit aperture manager  may allocate an address range in aperture  for redirection to the resource and cause the allocated address range in aperture  to be mapped to the committed kernel virtual address range.","For static surfaces, virtual memory manager  may allocate and commit an application private virtual address range for the surface. To bring the static surface into video memory , physical memory manager  may allocate memory in local video memory  for containing the surface and cause the surface to be copied from memory corresponding to the committed application private virtual address range to the memory allocated in local video memory .","To evict the static surface, physical memory manager  may cause the surface to be copied from the memory allocated in local video memory  to memory corresponding to the committed application private virtual address range and then free the memory allocated in local video memory .","To bring the static surface \u201cinto\u201d aperture , physical memory manager  may lock the committed application private virtual address range, whereby the operating system does not have permission to page out the surface from the system memory corresponding to the application private virtual address range. Graphics processing unit aperture manager  may allocate an address range in aperture  for redirection to the surface and cause the address range in aperture  to be mapped to the committed application private virtual address range.","To evict the static surface from aperture , graphics processing unit aperture manager  may unmap and free the allocated graphics processing unit aperture address range. Physical memory manager  may unlock the committed application private virtual address range, whereby the operating system has permission to page out the surface from the system memory corresponding to the committed application private virtual address range.","For dynamic surfaces, virtual memory manager  may allocate and commit an application private virtual address range for the surface. To bring the dynamic surface into local video memory , physical memory manager  may allocate memory in local video memory  for containing the surface and cause the surface to be copied from the memory corresponding to the committed application private virtual address range to the memory allocated in local video memory . Virtual memory manager  may map the committed application private virtual address range to the memory allocated in local video memory .","To evict the dynamic surface from video memory , physical memory manager  may cause the surface to be copied from the memory allocated in local video memory  to memory corresponding to the committed application private virtual address range and may then free the allocated memory in local video memory . Virtual memory manager  may then remap the committed application private virtual. address range to the memory corresponding to the committed application private virtual address range.","To bring the dynamic surface \u201cinto\u201d aperture , physical memory manager  may lock the committed application private virtual address range, whereby the operating system does not have permission to page out the surface from the system memory corresponding to the application private virtual address range. Graphics processing unit aperture manager  may allocate an address range in aperture  for redirection to the surface and causes the address range in the graphics processing unit aperture to be mapped to the committed application private virtual address range.","To evict the dynamic surface from aperture , graphics processing unit aperture manager  may unmap and free the allocated graphics processing unit aperture address range. Physical memory manager  may unlock the committed application private virtual address range, whereby the operating system has permission to page out the surface from the system memory corresponding to the committed application private virtual address range.","Illustrative application programming interfaces are given below for dynamic video memory allocation and deallocation.",{"@attributes":{"id":"p-0135","num":"0134"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmAllocateDynamic("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN DWORD dwFlags,"]},{"entry":[{},"\u2003\u2003IN SIZE_T Size,"]},{"entry":[{},"\u2003\u2003IN ULONG ulAlignment"]},{"entry":[{},"\u2003\u2003OUT PHANDLE Handle);"]},{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmFreeDynamic("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN HANDLE Handle);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Allocating a dynamic video memory allocation may be performed in two steps. First, the virtual address of the allocation is allocated. Second, the actual GPU resources (e.g., physical video memory , non-local aperture ) to store the bits are allocated (typically after the allocation creation time and upon the first application access to the allocation).","Video memory manager  may store bits in system memory  by rotating the virtual address associated with the allocation back to system memory.","Video memory manager  may make an allocation visible through non-local aperture  by making sure the allocation bits are in system memory  then pinning down or locking the pages forming the allocation in physical system memory  so that the paging system doesn't send them to disk. Once the pages are locked, video memory manager  may allocate a range in non-local aperture  that is visible to GPU  and reprogram aperture  to redirect that range to the physical system memory pages. The allocation of address space in non-local aperture  may be done through non-local aperture manager . Once visible or accessible through non-local aperture , a dynamic video memory allocation may be associated with a handle from non-local aperture manager .","Video memory manager  may store bits of video memory  by using physical video memory manager  to allocate a range of physical video memory  in one of the physical memory segments defined by the driver. Since dynamic allocation is visible to CPU , virtual memory manager  looks at the segments that have been defined as visible by CPU .","If more than one segment could hold the allocation, virtual memory manager  chooses a segment. The choice may be made by trying to maximize the balance of allocation in each segment. Rules for such balancing include: if a heap has a free hole big enough for the allocation, use it; if a heap has a lot more free memory than another, use it; use the heap with the oldest allocation; and the like.","Once the content of the surface is transferred to physical video memory , the virtual address may be MEM_RESET so the memory manager of the operating system  won't send the pages to hard disk . The virtual address is rotated to the physical video memory address on the first lock, and remains referring to system memory . An illustrative application programming interface is given below for beginning GPU access.",{"@attributes":{"id":"p-0142","num":"0141"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmBeginGPUAccess("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN PHANDLE phAlloc,"]},{"entry":[{},"\u2003\u2003IN VIDMM_FENCE Fence,"]},{"entry":[{},"\u2003\u2003OUT PBOOLEAN NonLocalVideo,"]},{"entry":[{},"\u2003\u2003OUT PPHYSICAL_ADDRESS PhysAddr"]},{"entry":[{},");"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Hardware not supporting demand paging of video memory specifies which allocations will be used by the hardware before posting a command buffer to GPU  so that video memory manager  can make those allocations visible to GPU . The notification may be done through VidMmBeginGPUAccess( ) API. (The duration of access may be controlled by a fencing mechanism, described below).","When VidMmBeginGPUAccess( ) is called, video memory manager  verifies if the allocations are currently visible to GPU . If the allocations are not visible to GPU , video memory manager  brings the allocations to local physical video memory  or non-local video aperture . Video memory manager  may go through the list of allocations provided by driver  and try to make all of them visible to GPU  by allocating physical video memory  or mapping through non-local aperture . When trying to allocate GPU resources, it's possible that the allocation fails because there isn't enough free room. When this happens physical memory manager  or non-local aperture manager  tries to evict some unused allocation to make room for the new one. Video memory manager  may not be able to allocate memory immediately but may wait until GPU  is done with some surface. It is possible that the function will fail to bring the allocations back in memory. If the call fails, driver  may break down the command buffer in smaller pieces and call video memory manager  again for each subset of allocation.","Once the allocations are in physical video memory  or mapped through non-local aperture , they may remain there as long as they are being used by GPU . To determine when an allocation is no longer in use, a fencing mechanism may be used. The fence may be a 64 bit monotonic counter that is updated by the display hardware, GPU , each time a partial command buffer is completed.",{"@attributes":{"id":"p-0146","num":"0145"},"figref":"FIG. 15","b":["200","210","200","290","290"]},"VidMmBeginGPUAccess may also acquire usage information about the allocations. Because driver  may notify video memory manager  each time GPU  requests the use of an allocation, this is a good place to build usage information. This usage information may be used by video memory manager  when physical video memory  or non-local aperture  is full and video memory manager  wants to find a candidate allocation for eviction. Each time an allocation is used, it may be put at the end of a list of allocations. Thus, when video memory manager  wants to evict an allocation it can use that ordered list to find the best candidate. Video memory manager  can also compare the last fence of an allocation to the last fence GPU  processed to generate an estimate of how long ago the allocation was used.","When application  desires direct access to a dynamic surface, it may use the lock mechanism provided by Direct X runtime. When application  locks a surface, the runtime calls driver  with the lock request. Driver  then verifies which actual allocation to return to application , and may call VidMmBeginUserAccess( ) function (illustrative API shown below) in video memory manager  to get the linear address that was allocated for application  at creation time. If the virtual address is still referencing system memory , it may be rotated to the current location of the surface in video memory  before being returned.",{"@attributes":{"id":"p-0149","num":"0148"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmBeginUserAccess("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN HANDLE hAlloc,"]},{"entry":[{},"\u2003\u2003OUT PVOID pvLin"]},{"entry":[{},");"]},{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmEndUserAccess("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN HANDLE hAlloc"]},{"entry":[{},");"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"VidMmBeginUserAccess( ) doesn't have to page in or evict the allocation; rather, it can safely keep the allocation at its current location and let driver  access the allocation. If the allocation is in video memory  and is to be reclaimed while it's being accessed, the eviction process can ensure there's no loss of data during the transfer. An illustrative eviction API is given below.",{"@attributes":{"id":"p-0151","num":"0150"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"NTSTATUS"]},{"entry":[{},"VidMmEvict("]},{"entry":[{},"\u2003\u2003IN PVOID HwDeviceExtension,"]},{"entry":[{},"\u2003\u2003IN HANDLE hAlloc"]},{"entry":[{},");"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"There are some characteristics of GPU hardware that may affect the implementation of video memory manager  and driver . Those characteristics include a GPU programmable aperture and demand paging.","A GPU programmable aperture is used by some GPU hardware to give a virtual view of video memory  to GPU . Each application  has its own virtual view of video memory  and each allocation done for that application is allocated a contiguous range within a private aperture. For hardware that doesn't support a GPU programmable aperture, video memory manager  may allocate contiguous blocks of memory. Allocating large contiguous block may be inefficient and may cause lots of eviction. Allocating on a page basis may reduce fragmentation.","A GPU programmable aperture may be useful for protecting video memory . Since each application may have its own private aperture, each application will see (via GPU ) surfaces allocated for that application. When GPU  is running in one application's context it is not be able to access any video memory that wasn't allocated for that application. If GPU  tries to access an address in the aperture that wasn't allocated to that application, an interrupt is generated by GPU  and video memory manager  may inject an exception in the application causing a fault (blocking any further rendering from that application until it reinitialized its context).","Demand paging is a mechanism by which some GPUs indicate that the GPU desires access to a surface that is not currently cached in video memory . With old GPU hardware, video memory manager  may confirm that all surfaces referenced by a command buffer are cached in video memory  before submitting the command buffer to GPU . Since there is no way for video memory manager  to determine which surfaces will actually be used by GPU , it load all of those surfaces entirely. If a command buffer is built in user mode, kernel mode components may parse the command buffer to load all those surfaces in video memory  before submitting the command buffer to GPU . Since the command buffer is located in uncached memory, reading from that buffer is very inefficient. Also, a command buffer might be referencing more memory than can actually be loaded at once, which requires that the driver submit the command buffer into multiple sub-buffers.","In order to make this process more efficient, some GPUs can support demand paging. Demand paging may use a GPU programmable aperture. The aperture contains present flags for all pages of each surfaces. If a page being accessed is currently not present, the GPU signals an interrupt. In response to the interrupt, video memory manager  may take control of CPU  and bring the pages in from system memory  and restart the graphics operation that caused the fault.","Program code (i.e., instructions) for performing the above-described methods may be stored on a computer-readable medium, such as a magnetic, electrical, or optical storage medium, including without limitation a floppy diskette, CD-ROM, CD-RW, DVD-ROM, DVD-RAM, magnetic tape, flash memory, hard disk drive, or any other machine-readable storage medium, wherein, when the program code is loaded into and executed by a machine, such as a computer, the machine becomes an apparatus for practicing the invention. The invention may also be embodied in the form of program code that is transmitted over some transmission medium, such as over electrical wiring or cabling, through fiber optics, over a network, including the Internet or an intranet, or via any other form of transmission, wherein, when the program code is received and loaded into and executed by a machine, such as a computer, the machine becomes an apparatus for practicing the above-described processes. When implemented on a general-purpose processor, the program code combines with the processor to provide an apparatus that operates analogously to specific logic circuits.","It is noted that the foregoing description has been provided merely for the purpose of explanation and is not to be construed as limiting of the invention. While the invention has been described with reference to illustrative embodiments, it is understood that the words which have been used herein are words of description and illustration, rather than words of limitation. Further, although the invention has been described herein with reference to particular structure, methods, and embodiments, the invention is not intended to be limited to the particulars disclosed herein; rather, the invention extends to all structures, methods and uses that are within the scope of the appended claims. Those skilled in the art, having the benefit of the teachings of this specification, may effect numerous modifications thereto and changes may be made without departing from the scope and spirit of the invention, as defined by the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing summary, as well as the following detailed description of illustrative embodiments, is better understood when read in conjunction with the appended drawings. For the purpose of illustration, there is shown in the drawings illustrative embodiments of invention; however, the invention is not limited to the specific embodiments described. In the drawings:",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 6","FIG. 5"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 9","FIG. 8"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 18"}]},"DETDESC":[{},{}]}
