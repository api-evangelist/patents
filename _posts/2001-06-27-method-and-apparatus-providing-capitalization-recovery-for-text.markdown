---
title: Method and apparatus providing capitalization recovery for text
abstract: A method for capitalizing text in a document includes processing a reference corpus to construct a plurality of dictionaries of capitalized terms, where the plurality of dictionaries include a singleton dictionary and a phrase dictionary. Each record in the singleton dictionary contains a word in lowercase, a range of phrase lengths m:n for capitalized phrases that the word begins, where m is a minimum phrase length and n is a maximum phrase length, and where each record in the phrase dictionary includes a multi-word phrase in lowercase. The method adds proper capitalization to an input monocase document by capitalizing words found in mandatory capitalization positions; and by looking up each word in the singleton dictionary and, if the word is found in the singleton dictionary, testing the corresponding phrase length range. If the phrase length range indicates that the word does not start a multi-word phrase, the method capitalizes the word, while if the phrase length range indicates that the word does start a multi-word phrase, the method tests the word and an indicated plurality of next words as a candidate phrase to determine if the candidate phrase is found in the phrase dictionary and, if it is, capitalizes the words of the multi-word phrase. If the candidate phrase is not found in the phrase dictionary, the method changes the number of words in the candidate phrase (e.g., decrements by one) to form a revised candidate phrase, and determines whether the revised candidate phrase is found in the phrase dictionary.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06922809&OS=06922809&RS=06922809
owner: International Business Machines Corporation
number: 06922809
owner_city: Armonk
owner_country: US
publication_date: 20010627
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CLAIM OF PRIORITY TO A COPENDING PROVISIONAL PATENT APPLICATION","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["This patent application claims priority under 35 U.S.C. 119(e) from Provisional Patent Application No.: 60\/263,959, filed Jan. 25, 2001, the content of which is incorporated by reference herein in its entirety.","These teachings relate generally to text and document processors, to algorithms and systems that provide properly capitalized text for a document.","Proper capitalization in text is a useful and often mandatory characteristic. Many text processing techniques rely on the text being properly capitalized, and many people can more easily read mixed-case text than monocase text (i.e., all lowercase or all uppercase). However, proper capitalization is often missing from many text sources, including automatic speech recognition output and closed captioned text. As may be appreciated, the value of these sources of text can be greatly enhanced when properly capitalized.","The presence of proper and correct capitalization is also becoming important due to the wide-spread use of Named Entity recognizers in various types of automatic document processing systems. Named Entity recognizers typically require proper capitalization in a document corpus for correct operation. However, some corpi, such as closed caption transcripts, are written in monocase.","Proper capitalization in text is often taken for granted. Most documents, such as newspaper articles, technical papers and most web pages are properly capitalized. Capitalization makes text easier to read and provides useful clues about the semantics of the text. Many text analysis systems exploit these semantic clues to perform various text processing tasks, such as indexing, parsing, sentence boundary disambiguation, extraction of named entities (e.g., people, places, and organizations) and to provide identification of relationships between named entities.","There are several text sources, without proper capitalization, that have experienced wider-spread use. Two of these sources are closed caption text from television broadcasts and the output from automatic speech recognition (ASR) systems. Closed caption text is an extremely valuable source of information about a television broadcast, essentially enabling the application of text analysis and indexing techniques on the audio\/video television program. Closed caption text, however, is typically all upper case, which seriously impedes the effectiveness of many text analysis procedures. Moreover, all upper case text is more difficult to read when displayed on a computer monitor or television screen, or when printed on paper.","Automatic speech recognition has matured to the point where researchers and developers are applying ASR technology in a wide variety of applications, including general video indexing and analysis, broadcast news analysis, topic detection and tracking, and meeting capture and analysis. Although dictation systems built with ASR provide limited capitalization based on dictated punctuation and a lexicon of proper names, the more interesting application of ASR is in the area of speaker independent continuous dictation, which can be used to create a text transcript from any audio speech source. Systems that support this task typically provide a SNOR (Speech Normalized Orthographic Representation) output, which is in an all upper case format.","The ability to recover capitalization in case-deficient text, therefore, is quite valuable and worthy of investigation. Restoring proper capitalization to closed caption text and ASR output not only improves its readability, it also enables the use of a number of text processing tasks as mentioned previously. Even in those domains where capitalization is normally given, a system that recovers proper capitalization can be used to validate that the correct case has been used. Although capitalization rules exist, most are in fact merely conventions.","The recovery of capitalization from a source text has traditionally been rarely considered as a topic by itself. It is briefly discussed by Shahraray and Gibbon, \u201cAutomated Authoring of Hypermedia Documents of Video Programs,\u201d Proc. of the Third ACM International Conf. on Multimedia, San Francisco, 1995, who describe a system that automatically summarizes video programs into hypermedia documents. Their approach relies on the closed caption text from the video, which must be properly capitalized. They describe a series of text processing steps based on Bachenko et al., J. Bachenko, J. Daugherty, and E. Fitzpatrick, \u201cA Parser for Real-Time Speech Synthesis of Conversational Texts,\u201d Proc. of the Third ACL Conf. on Applied Natural Language Processing, pp. 25-32, Trento, Italy, 1992, that includes rules for capitalizing the start of sentences and abbreviations, a list of words that are always capitalized, and a statistical analysis based on training data for deciding how the rest of the words should be capitalized.","In those applications where the proper case is normally expected but not available, a typical approach is to modify the program that relies on the existence of the proper case so that proper case is no longer required to complete the task. An example of such a task is Named Entity extraction on ASR output, a task that appears in DARPA sponsored Broadcast News workshops. One system that has performed especially well under these circumstances is Nymble (also known as IdentiFinder). Reference in this regard can be made to D. Bikel, S. Miller, R. Schwartz, and R. Weischedel, \u201cNymble: a High-Performance Learning Name-finder,\u201d Proc. of the Fifth ACL Conf. on Applied Natural Language Processing, Washington, D.C., 1997, and to F. Kubala, R. Schwartz, R. Stone, and R. Weischedel, \u201cNamed Entity Extraction from Speech,\u201d Proc. of the 1998 DARPA Broadcast News Transcription and Understanding Workshop, 1998.","Nymble is based on a Hidden Markov Model, which must be trained with labeled text. When the training data is converted to monocase, Nymble performs nearly as well on monocase test data as in a mixed case scenario.","Problems that exist with these conventional approaches to dealing with case-deficient text include a requirement to modify applications to support case-deficient text, or providing alternate training sets for every capitalization situation. Both of these approaches are less than desirable.","The foregoing and other problems are overcome by methods and apparatus in accordance with embodiments of these teachings.","These teachings provide a system and method that apply uniform capitalization rules to a corpus. This capability is useful in any system involving text input from humans, such as word processors, email systems, instant messaging systems, and Telecommunications Devices for the Deaf (TDD's). ASR systems and closed caption systems also benefit from the application of these teachings.","The system and method recover capitalization in case-deficient text through a series of processing steps that include the application of heuristics, statistical analysis and dictionary lookup. Experiments have shown that the system and method are capable of recovering more than 88% of the capitalized words from a corpus with better than 90% accuracy.","The system and method enables developers to apply an original text analysis application on any text. Moreover, correctly capitalized text can benefit applications other than named entity extraction, such as parsing, sentence boundary disambiguation, indexing, and the general readability of the text.","These teachings assume the existence of a comparable reference corpus of properly capitalized documents. The reference corpus is processed to build dictionaries of capitalized terms by running a Named Entity recognizer to extract proper names, terms, abbreviations, acronyms and various capitalized noun phrases. The resulting list of capitalized entities is filtered to eliminate infrequently occurring items, and those items with a high likelihood of being erroneous. The list is then processed to build a singleton dictionary and a phrase dictionary. Each record in the singleton dictionary contains a term in lowercase, a range of phrase lengths m:n for capitalized phrases that the term begins, where m is the minimum phrase length and n is the maximum phrase length., and an optional final form for the term if there is an unusual capitalization (i.e., other than an initial uppercase letter followed by lowercase.) Each record in the phrase dictionary contains a phrase in lowercase and an optional final form for the phrase if the phrase has unusual capitalization (i.e., other than an initial uppercase letter followed by lowercase for every term (word) in the phrase.)","All single word entities are added to the singleton dictionary with a phrase length range of 1:1, indicating that the term does not begin any phrase, and should be capitalized by itself. Multi-word entities are added to the phrase dictionary, and the first word of the phrase is added to the singleton dictionary with a phrase length range of n:n, where n is the number of words in the phrase. If the first word already exists in the singleton dictionary, the phrase length range entry for the term is updated to ensure that the length of the current phrase is included in the phrase length range.","Proper capitalization is added to an input monocase document as follows. Those words in mandatory capitalization positions (e.g., words starting a sentence, titles, abbreviations) are capitalized after they are identified. Each word is then looked up in the singleton dictionary. If the word is found in the singleton dictionary, the corresponding phrase length range is then checked. If the phrase length range is 1:1, the word is capitalized and the next word is then checked. If the maximum phase length n is greater than one, the next n\u22121 words in the document are added to the current word to create a candidate phrase with a phrase length n, and the resulting candidate phrase is looked up in the phrase dictionary. If the candidate phrase is found in the phrase dictionary, the phrase is capitalized in the document in the indicated manner, and processing then continues in the document with the next word following the phrase. If the candidate phrase is not found in the phrase dictionary, a candidate phrase length of n\u22121 is considered in the same fashion, and all candidate phrase lengths down to length m are considered in turn until either a match is found, or the loop completes without locating the candidate phrase in the phrase dictionary. The entire input document or body of text is processed in this manner to obtain a properly capitalized corpus.","This processing may be enhanced by using a stop words list, and only considering non-stop words for capitalization or as phrase head words.","The ability to automatically construct the capitalization dictionaries for properly capitalized text enables the capitalization recovery system to be kept current with little human effort.","Reference is first made to  for showing an overall block diagram of a capitalization recovery system  in accordance with these teachings. The capitalization recovery system  assumes the presence of a source  of characters descriptive of text to be capitalized. The source  may represent the output of an ASR system, a close captioned system, manual user input, or any suitable generator or repository of textual data. The output of the source  is connected to a preprocessor , described in , which outputs preprocessed character data to the other component parts and subsystems of the capitalization recovery system . These subsystems include a title processing subsystem , an abbreviations processing subsystem , a punctuation processing subsystem , a singles or singleton processing subsystem  and a phrase processing subsystem .","It should be realized that the capitalization recovery system  may be embodied as a stand alone computer (e.g., as a personal computer or a mainframe computer), or as an embedded computer such as a microprocessor contained or embedded within, for example, a communications device, a text entry system or an ASR system. The computer embodiment includes at least one data processor , a memory , input\/output channels and devices  and possibly a graphical user interface (GUI)  for interacting with a user. In this case the operation of the capitalization recovery system  is controlled by program instructions or software  that is resident in a portion of the memory , or in some other memory or memory media (e.g., a fixed or removable disk or tape) that is accessible by the data processor . The output  of the capitalization recovery system  is textual data that has been correctly capitalized. The output  may be used directly, such as by printing or by transmission electronically to another location, or it may serve as the input to another system or systems, such as a Named Entity recognizer.","The memory  is operated so as to contain all or a portion of a corpus of training text , various dictionaries, such as a singles or singleton dictionary A (see FIG. ), a phrase dictionary B (see FIG. ), a capitalization dictionary C, a title dictionary D and an abbreviations dictionary E, various lists and other data constructions that are employed during the operation of the capitalization recovery system , as described in greater detail below.","The overall approach to restoring correct capitalization in text in accordance with these teachings is based on several assumptions about the text. First, the input text from the source  is assumed to have punctuation, e.g., sentence ending periods, question marks, and exclamation marks, as well as periods after abbreviations. Second, there is assumed to be the training corpus  of text with correct punctuation and capitalization, and this corpus is related to the input text from source  (the text in which capitalization is to be restored). For example, if the input text is closed caption text from a television news broadcast, a suitable training corpus would include newspaper articles from the same time period as the television program. However, these assumptions may be relaxed, as discussed below.","The foregoing assumptions are suggestive of a number of processing steps that can be applied individually or in combination by the capitalization system  and method. First, the system  assumes that the initial word in a document begins a new sentence and should be capitalized. Next, the system  considers punctuation marks. All question marks and exclamation points are treated as sentence boundaries by the system , and the next word following one of these punctuation marks is always capitalized.","Periods appearing in the text require additional processing. A period may mark the end of a sentence, the end of an abbreviation, or both. For the purposes of restoring proper capitalization, however, the system  is not required to distinguish between these cases. Many abbreviations are almost always followed by a capitalized word, namely titles (e.g., Mr., Dr., etc.) and middle initials in proper names. In these cases, the system  may treat the period as if it marked the end of a sentence, and capitalize the next word following the period.","The task, then, is to identify abbreviations where the following word is not normally capitalized. This is accomplished through the use of the abbreviations dictionary E, the titles dictionary D, and some amount of heuristic processing. The abbreviations dictionary E is generated automatically from the training corpus  in two steps. First, all words that end with a period at least 75% of the time, and that precede a lower case word at least half of those times, are added to the abbreviations dictionary E, where a word is any token separated by white space containing at least one letter. Second, all words from the singleton dictionary A (see ) that end with a period are added to the abbreviations dictionary E. In one experiment this procedure was found to produce an abbreviations dictionary E containing  abbreviations from 92MB of training text. The key for each entry in the abbreviations dictionary E is the lowercase version of the abbreviation (with periods), and the value is the properly capitalized form of the abbreviation, e.g.:",{"@attributes":{"id":"p-0043","num":"0042"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Key","Value"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"u.s.","U.S."]},{"entry":[{},"jan.","Jan."]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"The titles dictionary D (or simply a titles list) may be a manually generated list of common titles, including Dr., Gov., Mr., Mrs., Ms., Pres., Prof, Rep., Rev., and Sgt. Clearly other titles could be added to this list. Which titles to include depends on the domain of the text being processed.","The heuristic processing involves three rules for identifying additional abbreviations that don't appear in the abbreviations dictionary E or the titles dictionary D. First, if the word is a single letter followed by a period, the word is assumed to be a middle initial. Second, if the word matches the regular expression \u201c[a-z]\\. {2, }\u201d (single letter followed by a period, repeated two or more times), the capitalization recovery system  assumes the word is an abbreviation (acronym). Third, if the word consists entirely of consonants followed by a period, the capitalization recovery system  assumes the word is an abbreviation.","Using these resources, the capitalization recovery system  processes words that end in a period using the following algorithm:\n\n","After processing punctuation, the capitalization recovery system  applies one additional capitalization heuristic unrelated to abbreviations. All forms of the pronoun T (i.e., I, I've, I'm, I'd, I'll) are always capitalized.","Applying the techniques described thus far has been found to recover more than 36% of the capitalized words with better than 99% accuracy. In order to increase the coverage, the capitalization recovery system  uses more than just the punctuation cues provided in the text being capitalized.","The first technique considered to increase the number of correctly capitalized words is the use of a capitalization frequency dictionary constructed from the training corpus . For each word in the training text that consists entirely of letters, the capitalization dictionary C stores the number of times the word occurs in each of the following forms:\n\n","Items 1 through 3 can be collected in a straightforward manner from the training corpus . Unless the corpus has been annotated with sentence boundaries, item 4 is collected instead by estimating sentence boundaries. This is preferably accomplished by applying the same punctuation, title, and abbreviation processing described above.","The capitalization dictionary C allows the capitalization recovery system  to estimate the probability that any given word should be capitalized. The probability that word should be capitalized is estimated as:\n\n()\u00d7()\/(),\n\nwhere l, c, u, m are counts of the number of times each word in training text occurs lowercased (l), capitalized (c), all uppercase (u), and in a mandatory capitalization position (m).\n","As each word in the test text is processed, if it does not match any of the punctuation, abbreviation, or title rules, the capitalization recovery system  calculates the word's capitalization probability using the capitalization dictionary C. If this probability exceeds a specified threshold (e.g., 0.5), then the word is capitalized. Using the capitalization dictionary C, the capitalization recovery system  was found in one experiment to be able to recover an additional 43% of the capitalized words, or 79% total, with an accuracy over 93%.","Since the capitalization dictionary C contains information about most known common words, it may be safe to assume that any word (consisting entirely of letters) that does not appear in the capitalization dictionary C is most likely a named entity and should be capitalized. Adding this assumption to the processing brings the total coverage up to 82% with an accuracy of over 92%.","At this point, the majority of the missed words that still require capitalization are words that can act as both common words and proper names, e.g., \u2018brown\u2019, which can be both a color and a surname. Proper capitalization of these words depends on the context in which they occur. The preferred approach to adding context processing to the capitalization recovery system  is to create the phrase dictionary B from the training corpus , and to incorporate the phrase dictionary B into the capitalization processing.","In that a goal is to enable named entity extraction in case-deficient text using a Named Entity recognizer that relies on case, the same named entity recognizer may be used to create the phrase dictionary. The presently preferred Named Entity recognizer is one known as Textract (see IBM Intelligent Miner for Text, \u201chttp:\/\/www-4.ibm.com\/software\/data\/iminer\/fortext\/\u201d and Y. Ravin, N. Wacholder and M. Choi, \u201cDisambiguation of Names in Text,\u201d Proc. of the Fifth ACL Conf on Applied Natural Language Processing, pp. 202-208, Washington D.C., 1997.) Textract operates to identify proper names, places, organizations, abbreviations, dates, and a number of other vocabulary items in text. Textract also aggregates variant lexical forms of the same concept and identifies a canonical form for the concept. For example, Textract might identify the canonical form \u201cPresident George Washington\u201d and associate with that form the variants \u201cPresident Washington,\u201d \u201cGeorge Washington,\u201d and \u201cWashington.\u201d The output from Textract is a vocabulary file containing a record for each identified concept that gives the canonical form, its variants, and frequency statistics for how often the concept occurs in the collection.","After Textract has processed the training data, the resulting vocabulary file is filtered to generate the singleton or singles dictionary A (see ) and the phrases dictionary B (see FIG. ). For every concept that occurs in at least three documents, all of the multi-word variants (including the canonical form) with capitalized words are added to the phrase dictionary B and the first word in each phrase is added to the singles dictionary A as a phrase head. For each single word variant, if its capitalization probability (according to the capitalization dictionary C described earlier) is greater than 0.5, then it is added to the singles dictionary A as a singleton. The entry for a phrase head in the singles dictionary A includes the lengths of the shortest and longest known phrases started by the word. Singletons and phrases with unusual capitalization (where \u201cusual\u201d capitalization means only the first letter in each word is capitalized) have preferred capitalization forms stored in their respective dictionaries.","The capitalization recovery system  uses these dictionaries as follows. For each word that does not match any of the punctuation, abbreviation, or title rules, the capitalization recovery system  looks up the word in the singles dictionary A. If the word is a phrase head, n\u22121 additional words are parsed from the input text (where n is the length of the longest known phrase started by the current word) and the phrase is used to probe the phrase dictionary B. If the phrase is not found, it is shortened from the end one word at a time until it is either found or the capitalization recovery system  determines that the phrase is not in the phrase dictionary B. When a phrase is found in the phrase dictionary B, every word in the phrase is capitalized and processing continues with the next word after the phrase.","If the initial probe of the singles dictionary A reveals that the current word is a singleton and not a phrase head, then the word is capitalized. In either case, if the capitalization recovery system  finds a preferred capitalization form in the singles dictionary A or the phrase dictionary B, the capitalization recovery system  uses that form rather than the usual capitalization.","The set of singletons in the singles dictionary A is similar to the set of words in the capitalization dictionary C, with capitalization probabilities greater than 0.5. The differences are that the singletons in the singles dictionary are initially selected by the Textract Named Entity extraction process, the singletons may contain punctuation (e.g., hyphens or periods), and the singletons may have preferred unusual capitalization forms.","For a final processing variant, the capitalization recovery system  may combine the singles and phrases dictionary processing with the capitalization dictionary C processing. If a word is not found in the singles dictionary, the capitalization recovery system  probes the capitalization dictionary C with the word. If it is found, the word is capitalized if its capitalization probability exceeds the probability threshold. If it is not found, and if the word consists entirely of letters, it is assumed to be a proper name that does not appear in the training data, and the word is capitalized.","Having thus provided an overview of the processing performed by the capitalization recovery system , a more detailed description is now provided.","Referring to , the input is the text from the source  which is to be automatically capitalized. A word is defined to be any sequence of characters between the current position and the next space. To be able to use this definition of word appropriately, punctuation should be part of the word it annotates. For example, there should be no space between an opening double quote and the following word. To assure that the text conforms to this, it is first processed by the preprocessor , which is shown in FIG. .","There are three inputs to the preprocessor  as depicted in boxes ,  and . Box  is the original text from which the appropriate spaces are to be removed, and the processed text T is returned at the end in box . The list L shown in box  is a list of punctuation marks which should be following a word without spaces. This list may include \u2018\u2019',.!( )[]? but is dependent, in general, on the language. For English, the list contains all characters which are neither a letter or a number. One preferred embodiment of the preprocessor  is a finite state machine, and the state is initialized to 0 in box . Depicted in box  is the loop through the text, one character at a time. In box  it is checked whether the next character is null, meaning that the end of the input text was reached. In that case, the processed text T is returned in box . If the character is not null, the value of the state is tested in box . Depending on the value different paths in the flowchart are followed. In the case where the state is l it is tested whether the current character is a space in box . In the case where the character is a space, the value of the state is changed to 1 in box  and the preprocessor  continues to get the next character in box . If the character is not a space (as tested in box ), it is appended to the text T in box  and again the preprocessor  continues to get the next character in box . Returning to the description of box , in the case where the value of the state is 1, it is tested in box  whether the current character is a member of the list L1. If it is not, a space (which is actually the previous character) is added to the text T in box . In both cases (whether the current character is a member of the list L1 or not, the preprocessor  continues at box  and set the state to 0 before proceeding to box , where the current character is added to text T. After finishing this task, the next character is examined in box .","The operation of the capitalization recovery system  (without phrase processing, which is shown in the separate flowchart of ) is depicted in the flowchart of FIG. .","The input to the capitalization recovery system  is the text depicted in box  of , and the input to the remainder of the capitalization recovery system  is the processed text T from box  that is output from the preprocessor . In box  the state of the finite state machine is set to 1. Box  depicts the beginning of the loop through all the words in the text. Each word is sent to the several subsystems introduced above and is modified (i.e. capitalized) if appropriate and then appended to a text string T. When the last word is encountered, which is determined by a positive null test in box , the capitalization recovery system  returns the automatically capitalized text T in box . Otherwise, the word becomes the input to the punctuation processing in box . The output of the punctuation processing, shown in box , is three strings: S, E and W_String. S and E can be empty and hold the potential punctuation at the beginning and the end of each word. The string W_String is the word with the non-essential punctuation stripped out and captured in the strings S and E. The string W_String is examined to determine whether it is a title. Note that each of these subsystems return the same information:\n\n","If the title processing returns \u2018no\u2019, W_String is examined by the abbreviation processing subsystem in box . If the abbreviations subsystem  returns \u2018no\u2019, the same string is examined in box  by the single word subsystem which then continues to box . Box  is immediately reached when either the title processing or the abbreviation processing subsystems return \u2018yes\u2019. In box , the string S is prepended and the string E is appended to the string W_String to form the string W. This string W is then appended to the text T followed by a space. Then the next word of the original text T is retrieved in the box  and the loop continues. The dotted line box  denotes the single word processing subsystem.","The first subsystem invoked is the punctuation processing subsystem , as shown in FIG. . The input is shown in box  as the word w. Some other variables are also initialized in this box, including strings W, S and E. It should be noted at this point that the use of strings is one preferred embodiment, and that other representations could be employed as well.","The string W is initialized to be identical to the string W, whereas S and E are empty strings. In box  the first character C of W is determined. In box  it is tested whether C is null, indicating that the end of the string was reached, in which case the capitalization recovery system  continues to box .","Otherwise, it is checked in box  whether it is a letter or number (for English or other characters in different languages). If it is not a letter or a number, the capitalization recovery system  continues to box . There the first character of the string W is removed and the string W is now assigned this new value. The character C is appended to the string S. In box  the next character of the word W is determined and the loop continues in box . On the other hand, if the character C is a letter or number (as tested in box ), the capitalization recovery system  proceeds to box  where the last character C of the word W is determined. The character is tested in box  and if it is null, indicating that the end of the string was reached, it proceeds to box . Otherwise, C is tested for being either a letter or number in box . In the case that C is a letter or number the capitalization recovery system  proceeds to box . Otherwise, the last character of the string W is removed and W is set to this new value in box  and the character C is added to the beginning of string El. In box  the previous character of the string W is determined before continuing in box . Different paths through the flowchart end in box  at which point there are three strings S and E containing punctuations and W the word itself However, a period maybe both a punctuation or a part of the word itself (as in abbreviations or titles). Hence, in box  it is checked whether the first character in E is a period. If that assertion is true, the period is appended in box  and removed from the beginning of E. After box , or if the assertion concerning the period is false, the capitalization recovery system  continues in box  where the three strings W, E and S are returned.",{"@attributes":{"id":"p-0070","num":"0082"},"figref":"FIG. 4","b":["100","100","15","110","15","15","1","15","120","130","140","150"]},{"@attributes":{"id":"p-0071","num":"0083"},"figref":"FIG. 5","b":["200","210","10","215","220","265","275","215","15","225","15","280","15","10","230","235","10","265","240","265","15","245","250","265","245","251","255","10","265","260","265","251","270","275"]},"The next subsystem to be described is the single word processing subsystem  shown in FIG. . The input is a word w and the current state of the capitalization recovery system . The conventions are as follows: when state is equal to 1, the next word is capitalized, and a capitalized word has its first letter capitalized, and the rest of the characters can be either lower or upper case. In box  it is checked whether the last character is a period. If \u2018yes\u2019, the period is removed from the word and S is set to the period in box . Otherwise the capitalization recovery system  proceeds to box . In box  it is checked whether the word ends with the string \u201c's\u201d (apostrophe s), in which case these two characters are removed from the word in box  and prepended to string S in box . It should be noted that testing the word for \u201c.\u201d and \u201c's\u201d are English language-specific, and for other languages a different end of sentence punctuation mark could be substituted for the \u201c.\u201d, and a different string than \u201c's\u201d could be substituted if appropriate. In box  it is checked whether the word w is in the singles dictionary A. The singles dictionary A contains the words which should be capitalized in the text and, if the capitalization is different than only capitalizing the first letter, a preferred spelling is included. If the word w is in the singles dictionary SA its preferred spelling is looked up in box . Otherwise the capitalization recovery system  continues to box  for (language dependent) algorithms for capitalization. For English, the following two algorithms are appropriate, but not exclusive: 1) if the word begins with \u201cmc\u201d, the first letter and the character following the mc are capitalized; and 2) if the word is hyphenated, each word by itself is looked up in the singles dictionary A and the same rules as just described apply to each of the words separately before recombining them with a hyphen. In box  the state is examined and if it is 1 the method continues to box  where the word is capitalized. Recall that a word is also capitalized when it is in the singles dictionary A and, hence, after box . If the state is 0, or after the word has been capitalized, the capitalization recovery system  proceeds to box  where the start of the string S is checked. If it starts with a period or with the string \u201c's.\u201d, the capitalization recovery system  proceeds to box  where the state is set to 1, otherwise processing proceeds to box  where the state is set to 0. After the state has been set correctly, the capitalization recovery system  continues to box  where the string S is appended to word W before returning word W and the current state.",{"@attributes":{"id":"p-0073","num":"0085"},"figref":["FIG. 8","FIG. 8"],"b":["52","50","1","63","410","710","715","780","15","720","15","10","1020","15","1030","1040","1050","15","7","15","725","1030","1040","730","1040","10","600","1040","735","9","600","500","755","760","765","780","770","775","720","760","600","785","760"]},"The operation of the phrase processing subsystem  is illustrated in FIG. . The input is a phrase which is a set of words  and the number n which denotes the number of words in the phrase. In one preferred embodiment, a phrase is a string of characters and, as such, it is input to the punctuation processing subsystem  of FIG. . The punctuation processing subsystem  was previously described as taking a word as input, however, a phrase can be viewed for this purpose as a word with embedded spaces. The output of the punctuation processing subsystem  is shown in box , and contains strings S and E (the punctuation at the beginning and at the end of the phrase) and the remaining phrase (PH_String). In box  the output is tested as to whether the string ends with a period, in which case a period is prepended to the string E and the period is removed from PH_String. In box  a test is made as to whether the ending string \u201c's\u201d (apostrophe s) is present, in which case the string is prepended to E and the string \u201c's\u201d is removed from PH_String. In the next box  a test is made as to whether PH_String is in the phrase dictionary B. In one preferred embodiment, the phrase dictionary B is structured as shown in FIG. . The fields  of the phrase dictionary B include fields holding phrases  and corresponding fields  holding the preferred spelling, and hence the preferred capitalization for the phrases (if it differs from the standard capitalization where each word in the phrase is capitalized). If PH_String is found in the phrase dictionary B, the method executed by the capitalization recovery system  proceeds to box  where a check is made as to whether there is a preferred capitalization of PH_String (as indicated in the field ). In case there is, PH_String is set to this preferred capitalization in box . Otherwise, each word of PH_String is capitalized in box . Next, in box  it is checked whether E starts with \u201c.\u201d or \u201c's\u201d (apostrophe s) in which case the capitalization recovery system  proceeds to box  to set the state to 1. Otherwise processing continues at box  to set the state to 0. The string S is prepended to PH_String in box , while E is appended. The phrase string PH_String, the number n and the state are returned.","If the phrase string is not found in the phrase dictionary B in box , the number n is decreased by 1 in box . In box  it is tested whether this number is 1, in which case the phrase string is set to be an empty string and n is set to 0 before returning. On the other hand, if n is not 1, the processing of capitalization recovery system  continues in box  where S is prepended to PH_String and the last word is removed before starting the loop again in box .",{"@attributes":{"id":"p-0076","num":"0088"},"figref":"FIG. 10","b":["15","15","1010","1020","1030","1040","1050","1030","1040","15"]},{"@attributes":{"id":"p-0077","num":"0089"},"figref":"FIG. 11","b":["15","15","1110","1120","1130","15"]},{"@attributes":{"id":"p-0078","num":"0090"},"figref":"FIG. 12","b":["15","15","1210","1220","1230","1210"],"br":{},"in-line-formulae":[{},{}],"i":["C","c","\u2212m","+u","l","+c","+u"],"sub":["i","i","i","i","i","i","i"]},"In step , the named entities extracted in step  are filtered. All named entities that occur in fewer than, for example, three documents are discarded, and all single-term named entities with capitalization probability (from step ) less than, for example, 0.5 are discarded. These values may be varied as a function of the nature of the reference corpus, and based on other criteria. The named entities that survive this filtering are stored into the singleton dictionary A at step  and into the phrase dictionary B at step .","The inventors have thus described their capitalization recovery system  as applying a series of heuristic, statistical, and dictionary-based processing steps to recover capitalization. Experimental results have shown that the capitalization recovery system  is both effective and robust across a variety of text genres and training conditions. Optimum performance is found to be achieved when a suitable training corpus is available, but for most applications this is not overly burdensome, since properly capitalized text is usually readily available. Unlike other applications, such as named entity recognition or document classification, the training data does not require manual labeling.","In addition to the applications discussed above for the capitalization recovery system , another potential application of these teachings is local document analysis, where dictionaries and statistics are modified on a per document basis as each document is processed, allowing the system to account for the occurrence of named entities that alter capitalization probabilities for the common words in those named entities.","It is also contemplated that the operation of the capitalization recovery system  may be improved by the use of richer statistical models, such as Hidden Markov Models, that incorporate additional features (e.g., context) into the capitalization probability calculation.","Thus, while these teachings have been particularly shown and described with respect to preferred embodiments thereof, it will be understood by those skilled in the art that changes in form and details may be made therein without departing from the scope and spirit of these teachings."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The above set forth and other features of these teachings are made more apparent in the ensuing Detailed Description of the Preferred Embodiments when read in conjunction with the attached Drawings, wherein:",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 5","FIG. 3"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 6","FIG. 3"]},{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 7","FIG. 3"]},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 12","b":["10","11"]}]},"DETDESC":[{},{}]}
