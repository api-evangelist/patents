---
title: Methods and systems for mining datacenter telemetry data
abstract: This disclosure is directed to systems and methods for mining streams of telemetry data in order to identify virtual machines (“VMs”), discover relationships between groups of VMs, and evaluate VM performance problems. The systems and methods transform streams of raw telemetry data consisting of resource usage and VM-related metrics into information that may be used to identify each VM, determine which VMs are similar based on their telemetry data patterns, and determine which VMs are similar based on their patterns of resource consumption. The similarity patterns can be used to group VMs that run the same applications and diagnose and debug VM performance.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09213565&OS=09213565&RS=09213565
owner: VMware, Inc.
number: 09213565
owner_city: Palo Alto
owner_country: US
publication_date: 20130628
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","EXAMPLES"],"p":["This disclosure is directed to computational systems and methods for analyzing performance of virtual machines.","In recent years, virtual machines (\u201cVMs\u201d) have become increasingly used in datacenter operations and in other large-scale computing environments. VMs are a software implemented abstraction of a physical machine, such as a computer, which is presented to the application layer of the system. A VM may be based on a specification of a hypothetical computer and may be designed to recreate a computer architecture and function of a physical computer. In datacenters, VMs are often used in server consolidation. For example, a typical non-virtualized application server may achieve between 5% to 10% utilization. But a virtualized application server that hosts multiple VMs can achieve between 50% to 80% utilization. As a result, virtual clusters composed of multiple VMs can be hosted on fewer servers, translating into lower costs for hardware acquisition, maintenance, energy consumption and cooling system usage. The VMs in a virtual cluster may be interconnected logically by a virtual network across several physical networks.","In order to monitor the performance of VMs, datacenters generate streams of telemetry data. Each stream is composed of metrics that represent different aspects of the behavior of an application, a VM, or a physical machine. For example, virtual machine monitors can be used to produce a stream of telemetry data composed of hundreds of real and synthesized metrics associated with a VM. The telemetry streams may be sampled at very high rates. As a result, the telemetry datasets can be very large, containing hundreds of metrics for each VM resulting in aggregate data volumes that scale with the number of VMs monitored. The telemetry data size and high sample rates strain efforts to store, process, and analyze the telemetry data stream.","This disclosure is directed to systems and methods for mining streams of telemetry data in order to identify virtual machines (\u201cVMs\u201d), discover relationships between groups of VMs, and evaluate VM performance problems. The systems and methods transform streams of raw telemetry data consisting of resource usage and VM-related metrics into information that may be used to identify each VM, determine which VMs are similar based on their telemetry data patterns, and determine which VMs are similar based on their patterns of resource consumption. The similarity patterns can be used to group VMs that run the same applications and diagnose and debug VM performance.","Systems and methods described below model virtual machine (\u201cVM\u201d) metrics in order to obtain VM performance related information. In particular, the systems and methods receive streams of raw telemetry data associated with each VM and determine VM similarity. In other words, the system and methods automatically identify patterns associated with groups of VMs and application workloads. A fingerprint is constructed for each VM. The fingerprint identifies the VM and characterizes the VM's performance. A fingerprint may also be used to identify performance problems of a VM, compare the performance of the VM to the performance of other VMs in order to obtain information about compatible co-location and compare clusters of VMs run by different hosts in order to identify factors that degrade performance.","The power of similarity relationships stems from the additional context that similarity provides. For example, VMs that should ostensibly be \u201csimilar\u201d because the VMs run the same applications (version, configuration etc.) or perform the same task but appear in practice to be dissimilar can be used to signal a possible performance issue. The quantitative or qualitative \u201cdistance\u201d between a VM and its expected cohort may be used to explain or diagnose the discrepancy. Analogously, the distance between a VM and another cohort can be used to explain why the VMs are dissimilar. Moreover, groups of similar VMs may help redefine the notion of normal and abnormal VM performance.","Fingerprints are constructed to determine the relationships between VMs. These relationships (neighborhoods of similarity) between VMs based on their telemetry may then be used to explain performance variations, such as explaining why certain VMs that should ostensibly be similar behave as if they are not. The fingerprints scale with the number of metrics considered not the number of machines, which is important for use in large clusters.","The methods described below uses VM similarity rather than historical observations in order to provide additional context for anomaly detection and diagnosis. The use of similarity also allows users to attempt diagnosis before an extensive history has been collected by comparing a VM with its nearest neighbors. The methods described below use clustering techniques from statistical machine learning to automatically detect instances of similar VMs (i.e., a neighborhood) and then examine the behavior of key telemetry metrics of all the VMs in that neighborhood to detect, explain, and diagnose differences between the metrics.","It should be noted at the onset that streams of telemetry data and data output from the systems and methods for analyzing the streams of telemetry data described below are not, in any sense, abstract or intangible. Instead, the data is necessarily digitally encoded and stored in a physical data-storage computer-readable medium, such as an electronic memory, mass-storage device, or other physical, tangible, data-storage device and medium. It should also be noted that the currently described data-processing and data-storage methods cannot be carried out manually by a human analyst, because of the complexity and vast numbers of intermediate results generated for processing and analysis of even quite modest amounts of data. Instead, the methods described herein are necessarily carried out by electronic computing systems on electronically or magnetically stored data, with the results of the data processing and data analysis digitally encoded and stored in one or more tangible, physical, data-storage devices and media.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1","b":["102","105","108","110","112","110","114","116","118","120","122","127","127","128","128","128"]},"A stream of raw telemetry data is collected for each VM. The telemetry data may be generated by a virtual machine monitor (\u201cVMM\u201d), which may be an application, firmware or hardware that runs VMs and generates metrics in the form of a stream of telemetry data associated with each VM. A performance manager manages statistics collected for each of the VMs and provides an application programming interface (\u201cAPI\u201d) for querying performance counters. A performance counter is the value of a metric at a particular point in time. The telemetry data stream associated with each VM is composed of performance counter values collected for each metric in intervals of time called epochs. In other words, each metric is sampled a number of times within an epoch. An order statistic is used to identify features of each VM. For example, the data collected for each VM is stored in a computer-readable medium and can be represented in the following format:\n\n","subscript L is a VM integer index that ranges from 0 to N;","index i identifies the metric that ranges from 0 to d+1; and","M is the number of performance counter values sampled in an epoch.","The order statistic applied to performance counter values associated with the metric i is called a feature and calculated over each epoch. The feature can be a percentile, minimum, maximum, sample average or sample median. In the following description, the feature is the median of the metric values sampled over an epoch. Performance counters may be sampled at different frequencies, such as every 20 seconds, one minute, or five minutes, and the epoch is longer than the interval between samples. Every epoch is sampled for the previous performance counter values that occur within the epoch. For example, consider a raw telemetry data stream composed of 300 metrics for a VM. Assuming every epoch is 1 hour in duration and the performance manager samples the 300 metrics every 20 seconds. As a result, a 300 metric by 180 sample value matrix (i.e., 54,000 sample values) is generated for each epoch.",{"@attributes":{"id":"p-0030","num":"0032"},"figref":["FIG. 2","FIG. 2","FIG. 2"],"b":["202","204","206","210","204","212","214","216","214"],"sub":["0","1","N ","0","1","N","1","2","3","n ","i ","j ","j","L ","j","0","d ","pq"]},"Next, for each epoch, the metrics are pre-processed to discard constant-valued metrics and system metrics across the VMs. As a result, substantially constant metrics are discarded from the sample data matrices. The union of non-constant metrics are considered for further analysis below. Note that a metric that is constant for one VM but variable for another VM is not discarded, because the sample data matrices of each VM are separately pre-processed for each epoch.","For each metric, the median of the associated sample values collected in an epoch is calculated as follows:\n\n()=median{}\u2003\u2003(1)\n\nwhere m(t)is the median value of the M+1 sample values s, s, . . . , sof the metriccollected in the epoch tfor the VM VM. At each epoch, the median of each metric is calculated for each VM.\n","The d+1 order statics obtained for each epoch and each VM are arranged into vectors that are, in turn, arranged into data matrices associated with each epoch.  shows an example of order statistic associated with an epoch in the streams of telemetry data shown in  arranged into metric data vectors. In the example of , the d+1 median values m(t), . . . , m(t)of the corresponding metrics metric, . . . , metricassociated with the VM VMin the epoch tare called features and arranged into a row feature vector  denoted by:\n\n{right arrow over ()}()()()()]\u2003\u2003(2)\n\nFor the epoch t, feature vectors {right arrow over (VM)}(t), {right arrow over (VM)}(t), {right arrow over (VM)}(t), . . . , {right arrow over (VM)}(t) are formed for each of the VMs VM, . . . , VM, respectively, according to Equation (2). Next, for each epoch t, the associated feature vectors are arranged as rows in data matrices denoted by M(t).  shows an example of feature vectors associated with an epoch arranged into a data matrix. In the example of , feature vectors {right arrow over (VM)}(t), {right arrow over (VM)}(t), {right arrow over (VM)}(t), . . . , {right arrow over (VM)}(t), . . . , VM(t) are arranged into rows of data matrix M(t)  that corresponds to the epoch t. A data matrix is generated for each of the epochs t, t, . . . , t.\n",{"@attributes":{"id":"p-0034","num":"0036"},"figref":["FIG. 4","FIG. 3"],"b":["402","404","406","408"],"sub":["0","N ","1","0 ","N ","2","2 ","n-1","0","N ","n"]},"Next, data matrices may be compacted to eliminate data redundancies and to obtain a compact metric data representation. One computational technique for compacting the data matrices is principle component analysis (\u201cPCA\u201d). PCA has the effect of reducing the dimensions of feature vectors {right arrow over (VM)}(t)to a lower dimensional projection of the original feature vector. For example, feature vectors described above are (d+1)-dimensional. PCA may be used to reduce a (d+1)-dimensional feature vector to a two- or three-dimensional feature vector. By reducing to a two- or three-dimensional data set, clusters of VMs can be represented graphically, enabling visual inspection of the results. PCA is a data summarization technique used to characterize the variance of a set of data, can be used to identify principle vector components, and eliminate components that are redundant. PCA is applied to each of the feature vectors of the data matrices M(t). For the matrix M(t), the mean is calculated for each of the d+1 features as follows:",{"@attributes":{"id":"p-0036","num":"0038"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["m","p"]},"mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"mi":"N","mo":"+","mn":"1"}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"L","mo":"=","mn":"0"},{"mi":"N","mo":"+","mn":"1"}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mrow":{"mi":"m","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["t","j"]}}},"mi":"Lp"}}}}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}},"br":{}},{"@attributes":{"id":"p-0037","num":"0039"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mover":{"mover":{"mi":"VM","mo":"\u21c0"},"mo":"~"},"mi":"L"},"mo":"=","mrow":{"mo":["[","]"],"mrow":{"msub":[{"mrow":[{"mover":{"mi":"m","mo":"~"},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["t","j"]}}},{"mi":"L","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}]},{"mrow":[{"mover":{"mi":"m","mo":"~"},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["t","j"]}}},{"mi":"L","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}]},{"mrow":[{"mover":{"mi":"m","mo":"~"},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["t","j"]}}},{"mi":["L","d"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"\u2026"}}}},{"mrow":{"mo":["(",")"],"mn":"4"}}]}}}},"br":[{},{},{}],"in-line-formulae":[{},{}],"i":["{tilde over (m)}","t","=m","t","\u2212m"],"sub":["j","Lp","j","Lp","p "]},{"@attributes":{"id":"p-0038","num":"0040"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mover":{"mi":"M","mo":"~"},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["t","j"]}}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"msub":{"mrow":{"mover":{"mi":"m","mo":"~"},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["t","j"]}}},"mn":"00"}},{"mi":"\u2026"},{"msub":{"mrow":{"mover":{"mi":"m","mo":"~"},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["t","j"]}}},"mi":"Ld"}}]},{"mtd":[{"mi":"\u22ee"},{"mi":"\u22f1"},{"mi":"\u22ee"}]},{"mtd":[{"msub":{"mrow":[{"mover":{"mi":"m","mo":"~"},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["t","j"]}}},{"mi":"N","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}]}},{"mi":"\u2026"},{"msub":{"mrow":{"mover":{"mi":"m","mo":"~"},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["t","j"]}}},"mi":"Nd"}}]}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}}}},"br":{},"img":{"@attributes":{"id":"CUSTOM-CHARACTER-00001","he":"3.89mm","wi":"4.57mm","file":"US09213565-20151215-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},"sub":"L "},{"@attributes":{"id":"p-0039","num":"0041"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"\u03a3","mo":"=","mrow":{"msub":{"mover":{"mover":{"mi":"VM","mo":"\u21c0"},"mo":"~"},"mi":"L"},"mo":"\u00b7","msubsup":{"mover":{"mover":{"mi":"VM","mo":"\u21c0"},"mo":"~"},"mi":["L","T"]}}}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}}}},"br":[{},{},{},{}],"sub":["j","PCA","j","j","PCA","j","j"],"in-line-formulae":[{},{}],"i":["M","t","{tilde over (M)}","t","F"]},"K-means clustering is then used to identify and group together the VMs that are similar based on their corresponding metric values. K-means clustering is an unsupervised machine learning technique used to identify structure in a data set. K-means clustering can be applied to raw data in the data matrices {tilde over (M)}(t) or applied to the PCA data matrix M(t). K-means clustering treats the feature vectors {right arrow over (VM)}as though the feature vectors lie within a d-dimensional space. As a result, each feature vector {right arrow over (VM)}corresponds to a VM and is assumed to be a point in a (d+1)-dimensional space based on the vector's metric values. The feature vectors that are close in space correspond to VMs that have similar metric values. K-means clustering receives a (d+1)-dimensional feature vector VMand a set of clusters C={C, C, . . . , C} amoung which the features vectors are to be partitioned. K-means clustering minimizes within-cluster sum of squares given by:",{"@attributes":{"id":"p-0041","num":"0043"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"arg","mo":"\u2062","mrow":{"munder":{"mi":["min","C"]},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"s"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munder":{"mo":"\u2211","mrow":{"msub":[{"mi":["VM","L"]},{"mi":["C","i"]}],"mo":"\u2208"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"msub":[{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"},{"mover":{"mi":"Z","mo":"\u21c0"},"mi":"i"}],"mo":"-"}},"mn":"2"}}}}}},{"mrow":{"mo":["(",")"],"mn":"8"}}]}}}},"br":[{},{}],"sub":["1 ","i","1","2","S","L ","j","j"],"sup":["0","0","0 ","t ","t"]},{"@attributes":{"id":"p-0042","num":"0044"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msubsup":{"mi":["Z","j"],"mrow":{"mi":"t","mo":"+","mn":"1"}},"mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"mo":["\uf603","\uf604"],"msubsup":{"mi":["C","j","t"]}}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"msub":{"mi":["VM","L"]},"mo":"\u2208","msubsup":{"mi":["C","j","t"]}}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"}}}}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}}}}},"The K-means method requires number of clusters s to be provided as an input, which implies that an optimal number of clusters for a given data configuration has to be determined. A poor choice for the number of clusters can lead to a poor result. Two different methods may be used to select the optimal number of clusters: the elbow method and Bayesian information criterion (\u201cBIC\u201d). For the elbow method, a marginal loss distortion Dfor a given partition of data s clusters is defined as",{"@attributes":{"id":"p-0044","num":"0046"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["D","s"]},"mo":"=","mrow":{"mfrac":{"mn":"1","mi":"m"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"s"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munder":{"mo":"\u2211","mrow":{"msub":[{"mi":["VM","L"]},{"mi":["C","i"]}],"mo":"\u2208"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"msub":[{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"},{"mover":{"mi":"Z","mo":"\u21c0"},"mi":"i"}],"mo":"-"}},"mn":"2"}}}}}},{"mrow":{"mo":["(",")"],"mn":"10"}}]}}}},"br":{},"figref":["FIGS. 5A-5B","FIG. 5A","FIG. 5B","FIG. 5B"],"b":["502","504","504","506"]},"Alternatively, BIC provides a quantitative method for choosing the number of clusters. If L(\u03b8) is the log-likelihood function and m is the number of clusters, then the BIC is given by:",{"@attributes":{"id":"p-0046","num":"0048"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["BIC","m"]},"mo":"=","mrow":{"mrow":[{"mi":"L","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"\u03b8"}},{"mfrac":{"mi":"f","mn":"2"},"mo":["\u2062","\u2062","\u2062"],"mi":["ln","n"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}],"mo":"-"}}},{"mrow":{"mo":["(",")"],"mn":"11"}}]}}}},"br":{}},"f is the number of free parameters, and","n is the number of observation.","If s is the number of clusters and (d+1) is the number of dimensions, then the number of free parameters is the sum of s\u22121 class probabilities, s(d+1) centroids and sd(d+1)\/2 free parameters in the co-variance matrix. The log-likelihood function of the ith cluster and the BIC are given by:",{"@attributes":{"id":"p-0050","num":"0052"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"L","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["\u03b8","i"]}}},{"mrow":[{"msub":{"mi":["n","i"]},"mo":"\u2062","mrow":{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["n","i"]}}}},{"msub":{"mi":["n","i"]},"mo":"\u2062","mrow":{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}},{"mfrac":{"msub":{"mi":["n","i"]},"mn":"2"},"mo":"\u2062","mrow":{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}}},{"mfrac":{"msub":{"mi":["dn","i"]},"mn":"2"},"mo":["\u2062","\u2062","\u2062"],"mi":"log","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u03a3","i"]}}],"mo":["-","-","-","-"],"mfrac":{"mrow":{"msub":{"mi":["n","i"]},"mo":"-","mi":"m"},"mn":"2"}}],"mo":"="},{"mrow":[{"msub":{"mi":["BIC","m"]},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"m"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"msub":{"mi":["n","i"]},"mo":"\u2062","mrow":{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["n","i"]}}}},{"msub":{"mi":["n","i"]},"mo":["\u2062","\u2062"],"mi":"log","mrow":{"mo":["(",")"],"mi":"n"}}],"mo":["-","-"]}}},{"mtd":{"mrow":{"mrow":[{"mfrac":{"msub":{"mi":["n","i"]},"mn":"2"},"mo":"\u2062","mrow":{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}}},{"mfrac":{"msub":{"mi":["dn","i"]},"mn":"2"},"mo":["\u2062","\u2062","\u2062"],"mi":"log","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u03a3","i"]}}],"mo":["-","-"],"mfrac":{"mrow":{"msub":{"mi":["n","i"]},"mo":"-","mi":"m"},"mn":"2"}}}}]}}}},{"mrow":{"mfrac":{"mi":"f","mn":"2"},"mo":"\u00b7","mi":"ln"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"n"}],"mo":"-"},{"msub":{"mi":["\u03a3","i"]},"mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"msub":{"mi":["n","i"]},"mo":"-","mi":"m"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"msub":[{"mi":["VM","L"]},{"mi":["C","i"]}],"mo":"\u2208"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"msub":[{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"},{"mover":{"mi":"Z","mo":"\u21c0"},"mi":"i"}],"mo":"-"}},"mn":"2"}}}}],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mtext":{}},{"mtext":{}},{"mtext":{}},{"mtext":{}}],"mi":["and","where"]}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}},"br":{},"figref":["FIGS. 6A-6B","FIG. 6A","FIG. 6B","FIG. 6A"],"b":["602","604","605","606","607","608","610","611","612","613","604","605"],"sub":["m\u22121","m+1","m "]},"However, it is not yet determined whether to select the number of clusters that correspond to troughs  and . An angle based method can be used to select the optimal number of clusters. First, the local minimas among the successive differences are found and sorted in the decreasing order of their absolute values. Pointers to the corresponding number of clusters are maintained. The angle associated with each local minimum is computed as follows. When i is the corresponding number of clusters, the angle can be computed according to",{"@attributes":{"id":"p-0052","num":"0054"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"Angle","mo":"=","mrow":{"mrow":[{"mi":"arctan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mn":"1","mrow":{"mrow":[{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"i","mo":"-","mn":"1"}}}],"mo":"-"}}}},{"mi":"arctan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mn":"1","mrow":{"mrow":[{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"i","mo":"+","mn":"1"}}},{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}],"mo":"-"}}}}],"mo":"+"}}},{"mrow":{"mo":["(",")"],"mn":"13"}}]}}}},"br":{}},"Using PCA described above, the original N+1 (d+1)-dimensional feature vectors {right arrow over (VM)}are projected them into u-dimensional vectors. For example, the (d+1)-dimensional feature vectors {right arrow over (VM)}may be projected into 2-dimensional vectors that lie in the Euclidean plane. Furthermore, K-means clustering has been used to group the u-dimensional vectors into clusters. The VMs in the same cluster are similar, but which of the original d+1 metrics responsible for bringing the VMs together in the same cluster remains to be determined. One-vs-all logistic regression is used to determine which metrics best characterize the cluster. BIC works by providing a separator between a cluster of interest and the remaining clusters (e.g., in two dimensions the separator is a line and in three dimensions the separator is a plane). The analytical representation of the separator gives a weight for each of the dimensions. The higher the weight, the more important the dimension is and implicitly the corresponding metric.","One-vs-all logistic regression (\u201cOVA LR\u201d) is used to extract a subset of features that best describe each cluster of VMs. OVA LR is a supervised statistical machine learning technique for classification. Given a dataset of features and labeled points (i.e., feature vector) that represent positive and negative examples, OVA LR identifies the subset of features and their associated coefficients that can be used to distinguish the positive examples from the negative examples. OVA LR uses features in one cluster as the set of positive examples while considering all the points in the remaining clusters as negative examples, reducing the problem to a 2-class classification. The subset of features and coefficients that describe a cluster is the cluster's \u201cfingerprint.\u201d","Logistic regression characterizes the structure of the statistical clusters obtained from K-means clustering described above by identifying the relevant features of each cluster. OVA LR produces a fingerprint for each group of VMs in the form of a summarized\/compressed representation of raw metrics. OVA LR is a classification technique for identifying the aspects that describe a labeled set of data points. OVA LR is based on a sigmoid function classifier taken from values between 0 and 1:",{"@attributes":{"id":"p-0056","num":"0058"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["h","\u0398"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["VM","L"]}}},"mo":"=","mfrac":{"mn":"1","mrow":{"mn":"1","mo":"+","msup":{"mi":"\u2147","mrow":{"mrow":{"mo":"-","msup":{"mover":{"mi":"\u0398","mo":"\u21c0"},"mi":"T"}},"mo":"\u2062","msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"}}}}}}},{"mrow":{"mo":["(",")"],"mn":"14"}}]}}}},"br":{},"sub":["L","L ","\u03b8","L","L"]},{"@attributes":{"id":"p-0057","num":"0059"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"Label","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mrow":{"mrow":{"msub":{"mi":["h","\u0398"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"}}},"mo":"\u2265","mn":"0.5"}}]},{"mtd":[{"mn":"0"},{"mrow":{"mrow":{"msub":{"mi":["h","\u0398"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"}}},"mo":"<","mn":"0"}}]}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"15"}}]}}}},"br":{}},{"@attributes":{"id":"p-0058","num":"0060"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"Label","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mrow":{"mrow":{"msup":{"mi":["\u0398","T"]},"mo":"\u2062","msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"}},"mo":"\u2265","mn":"0"}}]},{"mtd":[{"mn":"0"},{"mrow":{"mrow":{"msup":{"mi":["\u0398","T"]},"mo":"\u2062","msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"}},"mo":"<","mn":"0"}}]}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"16"}}]}}}},"br":{},"sup":"T","sub":"L"},{"@attributes":{"id":"p-0059","num":"0061"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"J","mo":"\u2061","mrow":{"mo":["(",")"],"mover":{"mi":"\u0398","mo":"\u21c0"}}},{"mfrac":{"mn":"1","mi":"u"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"u"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"Cost","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":{"mi":["h","\u0398"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mrow":{"mi":["L","i"],"mo":","}}}},"mo":",","msub":{"mi":["y","i"]}}}}}}],"mo":"="},{"mrow":[{"mi":"Cost","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":{"mi":["h","\u0398"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mrow":{"mi":["L","i"],"mo":","}}}},"mo":",","msub":{"mi":["y","i"]}}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mo":"-","mrow":{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["h","\u0398"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"}}}}}}},{"mrow":{"mi":"y","mo":"=","mn":"1"}}]},{"mtd":[{"mrow":{"mo":"-","mrow":{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mrow":{"msub":{"mi":["h","\u0398"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mover":{"mi":"VM","mo":"\u21c0"},"mi":"L"}}}}}}}},{"mrow":{"mi":"y","mo":"=","mn":"0"}}]}]}}],"mo":"="}],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mtext":{}},{"mtext":{}}],"mi":"where"}},{"mrow":{"mo":["(",")"],"mn":"17"}}]}}}},"br":{}},"The quality of the classification is analyzed by examining certain measures, such as precision, recall, and an F-measure given respectively by:",{"@attributes":{"id":"p-0061","num":"0063"},"maths":[{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"precision","mo":"=","mfrac":{"mi":"tp","mrow":{"mi":["tp","fp"],"mo":"+"}}}}},{"@attributes":{"id":"MATH-US-00015-2","num":"00015.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"recall","mo":"=","mfrac":{"mi":"tn","mrow":{"mi":["tn","fn"],"mo":"+"}}}}},{"@attributes":{"id":"MATH-US-00015-3","num":"00015.3"},"math":{"@attributes":{"overflow":"scroll"},"mi":"and"}},{"@attributes":{"id":"MATH-US-00015-4","num":"00015.4"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":["F","measure"],"mo":"-"},"mo":"=","mfrac":{"mrow":[{"mn":"2","mo":["\u00b7","\u00b7"],"mi":["precision","recall"]},{"mi":["precision","recall"],"mo":"+"}]}}}}],"br":{}},"tp is the number of true positives;","fp is the number of false positives;","tn is the number of true negatives; and","fn is the number false negatives.",{"@attributes":{"id":"p-0066","num":"0068"},"figref":["FIG. 7A","FIG. 7B","FIG. 7B","FIG. 7C"],"b":["701","702","703","704"]},{"@attributes":{"id":"p-0067","num":"0069"},"figref":["FIG. 7B","FIG. 7A","FIG. 2","FIG. 2","FIGS. 3-4"],"b":["701","705","706","707","708","709","710","711","706","710"]},{"@attributes":{"id":"p-0068","num":"0070"},"figref":["FIG. 7C","FIG. 7A"],"b":["702","712","713","714","715","716"]},{"@attributes":{"id":"p-0069","num":"0071"},"figref":["FIG. 7D","FIG. 7A","FIG. 7A","FIG. 5","FIG. 6"],"b":["703","717","718","719","720"]},"The data-mining methods described above were applied to debug performance for a tool used to emulate and evaluate large-scale deployments of virtual desktops. The tool was configured to generate workloads that are representative of user-initiated operations (e.g., interacting with documents, media and email) that take place in virtualized desktop infrastructure (\u201cVDI\u201d). The VDI is the practice of hosting a desktop operating system in a virtual machine running on a centralized server.","A tool deployment consists of three groups of VMs: 1) desktops that generate loads, such as launch applications and execute tasks, 2) clients that are connected to the desktops via a remote display protocol, such as PCoIP, and display the results of actions being executed on the desktop, and 3) infrastructure VMs that host the components of the tool (e.g., the controller that launches the experiments), and VMs concerned with monitoring the virtual and physical environment, such as a virtualized data center. During a tool run, the desktop VMs run a mix of applications. Applications perform a randomized mix of tasks including: open, close, save, save as, minimize, maximize, start\/stop presentation, modify document, play\/stop video, as appropriate for the specific application being run.","The tool experiment cluster included a total of 175 VMs: 84 desktop VMs, 84 client VMs that use PCoIP to connect to desktops, and 7 infrastructure VMs (3 vCOPS VMs and 4 tool infrastructure VMs). The tool run lasted for \u02dc5 hours and the 184 VMs generated approximately 360 MB of metric data in a concise CSV-based storage format. The results below show that: (1) The VMs can be automatically group\/clustered based on their telemetry patterns. The clustering results are robust, remaining stable over time and they are not sensitive to various choices of order statistics used on raw telemetry data to create the features used for clustering. (2) An accurate fingerprint that contains the subset of metrics that best describe the behavior of the VMs in the group can be generated. (3) The raw metric feature vectors using techniques like PCA described above can be used to compress the raw metric data and maintain accurate and stable VM groupings. (4) Techniques from signal processing can be used to filter and select fingerprint metrics useful for explaining\/diagnosing differences within groups of ostensibly similar VMs. Finally, it was demonstrated that conditional probability distributions can be used to effect an explanation\/diagnosis.",{"@attributes":{"id":"p-0073","num":"0075"},"figref":["FIG. 8","FIG. 9"],"sup":"th "},"Tables 1, 2 and 3 shows the respective metric fingerprints that best describe (and partition) the clusters of VMs. Table 1 displays the fingerprints for the cluster of 84 clients. Note the prominent contribution of CPU and network metrics.",{"@attributes":{"id":"p-0075","num":"0077"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["Coefficient","Metric Name"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1.239","cpu.latency.average"]},{"entry":["1.204","cpu.ready.summation"]},{"entry":["0.910","cpu.usagemhz.average"]},{"entry":["0.885","cpu.usage.average"]},{"entry":["0.765","net.multicastRx.summation"]},{"entry":["0.714","rescpu.runav1.latest"]},{"entry":["0.710","cpu.demand.average"]},{"entry":["0.706","rescpu.actpk1.latest"]},{"entry":["0.704","rescpu.actav1.latest"]},{"entry":["0.626","rescpu.actav5.latest"]},{"entry":["0.613","rescpu.actpk5.latest"]},{"entry":["0.610","rescpu.runav5.latest"]},{"entry":["0.591","cpu.system.summation"]},{"entry":["0.582","disk.maxTotalLatency.latest"]},{"entry":["0.570","datastore.numberWriteAveraged.average"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0076","num":"0078"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["Coefficient","Metric Name"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["0.637","net.broadcastRx.summation"]},{"entry":["0.584","mem.usage.average"]},{"entry":["0.534","virtualDisk.numberWriteAveraged.average"]},{"entry":["0.528","virtualDisk.writeIOSize.latest (ide0:0)"]},{"entry":["0.502","virtualDisk.write.average"]},{"entry":["0.501","virtualDisk.smallSeeks.latest"]},{"entry":["0.500","virtualDisk.writeLateneyUS.latest"]},{"entry":["0.499","virtualDisk.largeSeeks.latest"]},{"entry":["0.480","virtualDisk.writeIOSize.latest (scsi0:0)"]},{"entry":["0.440","net.multicastRx.summation"]},{"entry":["0.400","mem.consumed.average"]},{"entry":["0.397","mem.entitlement.average"]},{"entry":["0.397","mem.granted.average"]},{"entry":["0.354","disk.numberWriteAveraged.average"]},{"entry":["0.350","datastore.numberWriteAveraged.average"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0077","num":"0079"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 3"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["Coefficient","Metric Name"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1.289","cpu.latency.average"]},{"entry":["1.169","cpu.ready.summation"]},{"entry":["0.912","cpu.usage.average"]},{"entry":["0.909","cpu.usagemhz.average"]},{"entry":["0.815","rescpu.runav1.latest"]},{"entry":["0.751","rescpu.actpk5.latest"]},{"entry":["0.749","rescpu.actpk1.latest"]},{"entry":["0.707","rescpu.actav1.latest"]},{"entry":["0.702","cpu.demand.average"]},{"entry":["0.674","rescpu.runav5.latest"]},{"entry":["0.665","rescpu.actav5.latest"]},{"entry":["0.632","net.broadcastRx.summation"]},{"entry":["0.610","cpu.idle.summation"]},{"entry":["0.608","cpu.wait.summation"]},{"entry":["0.571","rescpu.runav15.latest"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"The original expectation was to have 3 groups of VMs instead of 4. A technique for debugging the difference is now described. Specifically why and how the two adjacent groups of desktop VMs shown in  are different is described. Conditional probability distributions were used to explain the difference.","Spread metrics were used to differentiate two clusters or cause a cluster to split or diffuse. Spread metrics characterize how much the expected value of the order statistic (e.g., the median) of a metric E[m] differs between two clusters (i.e., the expected value is conditioned on the cluster). Note that the expected value summarizes the behavior of the distribution of the order statistics of a metric, which by definition it is the weighted average of all the possible values a random variable can take. The expectation over the distribution of an order statistic captures the aggregate behavior over a population of VMs. In this case, the population of VMs is the neighborhood of similar VMs determined by K-means clustering. Concisely, a spread metric is given by",{"@attributes":{"id":"p-0080","num":"0082"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mrow":{"mi":"abs","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"E","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":"m","mo":"|","mrow":{"mi":["cluster","A"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},{"mi":"E","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":"m","mo":"|","mrow":{"mi":["cluster","B"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}],"mo":"-"}}},"msub":{"mi":["m","max"]}},"mo":">","mi":"\u03b8"}}},"br":{}},"E[m|cluster i] is the expected value of a metric m conditioned on the VM being in cluster i;","mis the maximum value of that metric over the clusters considered and serves as a normalization factor; and","\u03b8 is a tuning parameter that is used to identify metrics to filter\/remove based on the magnitude of the differences in expected values.","Using too small of a value for \u03b8 filters or removes a larger number of metrics, potentially to the point of removing metrics that distinguish previously disparate (non-adjacent) clusters of VMs. Experiments revealed that values for \u03b8 between 0.1 and 0.2 work well. In this example, \u03b8=0.1 was used.","Given that there are possibly hundreds of metrics that can be consider as candidates for spread metrics and considering the computational expense of constructing conditional probability distributions, the Silverman's test was used to identify multi-modal metrics and process these first when looking for candidate metrics to construct the conditional probability distributions over. Entropy-based measures, e.g., mutual information, were also used to determine what metrics to condition metric in on.","Table 4 shows the top ten spread metrics that separate the two clusters of desktops in . The top 10 spread metrics separating cluster (A) of 51 desktops form the remaining (B) 33 desktops.",{"@attributes":{"id":"p-0087","num":"0089"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 4"},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["|E[m|A] \u2212",{},{},"E[m|B]\/"]},{"entry":["E[m|B]|\/m_max","Metric Name","E[m|A]\/m_max","m_max"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["0.453","cpu.ready.summation","0.291","0.744"]},{"entry":["0.443","cpu.latency.average","0.247","0.690"]},{"entry":["0.386","rescpu.actpk1.latest","0.324","0.711"]},{"entry":["0.375","rescpu.runav1.latest","0.335","0.710"]},{"entry":["0.372","cpu.usagemhz.average","0.312","0.684"]},{"entry":["0.372","cpu.usage.average","0.312","0.684"]},{"entry":["0.366","rescpu.actpk5.latest","0.409","0.775"]},{"entry":["0.360","rescpu.actav1.latest","0.196","0.556"]},{"entry":["0.356","cpu.demand.average","0.201","0.558"]},{"entry":["0.311","rescpu.actav5.latest","0.257","0.568"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}}}},{"@attributes":{"id":"p-0088","num":"0090"},"figref":"FIG. 10"},"Next, the data-mining methods were applied to a cluster of computers for 5 days, generating 19 GB of data stored in concise CSV format and 1.2 GB of indexes used for querying.  shows the clustering results obtained for 768 VMs on one of the clusters from an epoch (1 hr) of data. The VMs were coarsely clustered in to 3 groups according to BIC. The 3 clusters are delineated in  as follows: 199 VMs (x's) with *-vc-vpxinstall, *-vc-vcvainstall, *-generic-ovf, *-vcd-vcdinstall, *-vc-cloudvminstall, *-vc-vpxinstall, *-vsm-vsminstall suffixes; 207 VMs (o's) with *-esx-fullinstall and *-esx-pxeboot suffixes; and with 362 VMs (+'s) with *-nfs-default, *-iscsi-default, *-esx-fullinstall and *-esx-pxeboot suffixes.","The spread metrics were computed within the cluster of 207 VMs to identify the metrics that explain the dispersion. Thirty metrics were identified where the spread is greater than \u03b8=0.1 and shown in the top 10 metrics in Table 5.",{"@attributes":{"id":"p-0091","num":"0093"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 5"},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["|E[m|A] \u2212",{},"E[m|A]\/","E[m|B]\/"]},{"entry":["E[m|B]|\/m_max","Metric Name","m_max","m_max"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["0.420","mem.usage.average","0.371","0.791"]},{"entry":["0.356","net.multicastRx.summation","0.773","0.417"]},{"entry":["0.355","net.broadcastRx.summation","0.774","0.419"]},{"entry":["0.355","net.packetsRx.summation","0.774","0.419"]},{"entry":["0.354","net.received.average","0.771","0.417"]},{"entry":["0.354","net.bytesRx.average","0.771","0.417"]},{"entry":["0.352","net.throughput.usage.average","0.772","0.420"]},{"entry":["0.351","net.usage.average","0.768","0.417"]},{"entry":["0.273","cpu.idle.summation","0.397","0.124"]},{"entry":["0.273","cpu.wait.summation","0.397","0.124"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}}},"br":{},"figref":"FIG. 12"},"Embodiments described above are not intended to be limited to the descriptions above. For example, any number of different computational-processing-method implementations that carry out for mining telemetry data may be designed and developed using various different programming languages and computer platforms and by varying different implementation parameters, including control structures, variables, data structures, modular organization, and other such parameters.","It is appreciated that the previous description of the disclosed embodiments is provided to enable any person skilled in the art to make or use the present disclosure. Various modifications to these embodiments will be readily apparent to those skilled in the art, and the generic principles defined herein may be applied to other embodiments without departing from the spirit or scope of the disclosure. Thus, the present disclosure is not intended to be limited to the embodiments shown herein but is to be accorded the widest scope consistent with the principles and novel features disclosed herein."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":["FIG. 3A","FIG. 2"]},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIGS. 5A-5B"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIGS. 6A-6B"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIGS. 7A-7D"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
