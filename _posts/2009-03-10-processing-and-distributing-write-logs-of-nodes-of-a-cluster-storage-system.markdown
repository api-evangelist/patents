---
title: Processing and distributing write logs of nodes of a cluster storage system
abstract: A cluster storage system comprises a plurality of nodes that access a shared storage, each node having two or more failover partner nodes. A primary node produces write logs for received write requests and produces parity data for the write logs (storing the parity data to local non-volatile storage). By storing parity data rather than actual write logs, the non-volatile storage space within the cluster for storing write logs is reduced. Prior to failure of the primary node, the primary node also sub-divides the write logs into two or more sub-sets and distributes the sub-sets to the two or more partner nodes for storage at non-volatile storage devices. Thus, if the primary node fails, its write logs are already distributed among the partner nodes so each partner node may perform the allotted write logs on the storage, thus improving the response time to the primary node failure.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08145838&OS=08145838&RS=08145838
owner: NetApp, Inc.
number: 08145838
owner_city: Sunnyvale
owner_country: US
publication_date: 20090310
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This application is related to U.S. patent application Ser. No. 12\/401,458, entitled \u201cTakeover of a Failed Node of a Cluster Storage System on a Per Aggregate Basis,\u201d by Susan M. Coatney, et al., filed herewith, and incorporated herein by reference.","The present invention relates to storage systems, and particularly, to processing and distributing write logs of nodes of a cluster storage system.","A storage system typically comprises one or more storage devices into which information may be entered, and from which information may be obtained, as desired. The storage system includes a storage operating system that functionally organizes the system by, inter alia, invoking storage operations in support of a storage service implemented by the system. The storage system may be implemented in accordance with a variety of storage architectures including, but not limited to, a network-attached storage environment, a storage area network and a disk assembly directly attached to a client or host computer. The storage devices are typically disk drives organized as a disk array, wherein the term \u201cdisk\u201d commonly describes a self-contained rotating magnetic media storage device. The term disk in this context is synonymous with hard disk drive (HDD) or direct access storage device (DASD).","The storage operating system of the storage system may implement a high-level module, such as a file system, to logically organize the information stored on volumes as a hierarchical structure of data containers, such as files and logical units (LUs). For example, each \u201con-disk\u201d file may be implemented as set of data structures, i.e., disk blocks, configured to store information, such as the actual data for the file. These data blocks are organized within a volume block number (vbn) space that is maintained by the file system. The file system may also assign each data block in the file a corresponding \u201cfile offset\u201d or file block number (fbn). The file system typically assigns sequences of fbns on a per-file basis, whereas vbns are assigned over a larger volume address space. The file system organizes the data blocks within the vbn space as a \u201clogical volume\u201d; each logical volume may be, although is not necessarily, associated with its own file system.","A known type of file system is a write-anywhere file system that does not overwrite data on disks. If a data block is retrieved (read) from disk into a memory of the storage system and \u201cdirtied\u201d (i.e., updated or modified) with new data, the data block is thereafter stored (written) to a new location on disk to optimize write performance. A write-anywhere file system may initially assume an optimal layout such that the data is substantially contiguously arranged on disks. The optimal disk layout results in efficient access operations, particularly for sequential read operations, directed to the disks. An example of a write-anywhere file system that is configured to operate on a storage system is the Write Anywhere File Layout (WAFL\u00ae) file system available from NetApp, Inc. Sunnyvale, Calif.","The storage system may be further configured to operate according to a client\/server model of information delivery to thereby allow many clients to access data containers stored on the system. In this model, the client may comprise an application, such as a database application, executing on a computer that \u201cconnects\u201d to the storage system over a computer network, such as a point-to-point link, shared local area network (LAN), wide area network (WAN), or virtual private network (VPN) implemented over a public network such as the Internet. Each client may request the services of the storage system by issuing access requests (read\/write requests) as file-based and block-based protocol messages (in the form of packets) to the system over the network.","A plurality of storage systems may be interconnected to provide a storage system architecture configured to service many clients. In some embodiments, the storage system architecture provides one or more aggregates and one or more volumes distributed across a plurality of nodes interconnected as a cluster. The aggregates may be configured to contain one or more volumes. The volumes may be configured to store content of data containers, such as files and logical units, served by the cluster in response to multi-protocol data access requests issued by clients.","Each node of the cluster may include (i) a storage server (referred to as a \u201cD-blade\u201d) adapted to service a particular aggregate or volume and (ii) a multi-protocol engine (referred to as an \u201cN-blade\u201d) adapted to redirect the data access requests to any storage server of the cluster. In the illustrative embodiment, the storage server of each node is embodied as a disk element (D-blade) and the multi-protocol engine is embodied as a network element (N-blade). The N-blade receives a multi-protocol data access request from a client, converts that access request into a cluster fabric (CF) message and redirects the message to an appropriate D-blade of the cluster.","The nodes of the cluster may be configured to communicate with one another to act collectively to increase performance or to offset any single node failure within the cluster. Each node in the cluster may have a predetermined failover \u201cpartner\u201d node. When a node failure occurs (where the failed node is no longer capable of processing access requests for clients), the access requests sent to the failed node may be re-directed to the partner node for processing. As such, the cluster may be configured such that a partner node may take over the work load of a failed node. A node may be referred to as a local\/primary node when referring to a current node being discussed, whereas a remote\/partner node refers to a predetermined failover partner node of the local\/primary node. As used herein, various components residing on the primary node may likewise be referred to as a local\/primary component (e.g., local memory, local de-staging layer, etc.) and various components residing on a remote node may likewise be referred to as a remote component (e.g., remote memory, remote de-staging layer, etc.).","A cluster provides data-access service to clients by providing access to shared storage (comprising a set of storage devices). Typically, clients will connect with a node of the cluster for data-access sessions with the node. During a data-access session with a node, a client may submit access requests (read\/write requests) that are received and performed by the node. For the received write requests, the node may produce write logs that represent the write requests and locally store the write logs to a volatile memory device (from which, the node may at a later time perform the write logs on the storage devices). To ensure data consistency, the write logs may also be stored to two non-volatile storage devices. Typically, the write logs of the node may be locally stored to a non-volatile memory device and also be stored remotely to a non-volatile storage device at the partner node. As such, if the local\/primary node fails, the remote\/partner node will have a copy of the write logs and will still be able to perform the write logs on the storage devices. Also, if the write logs stored at the partner node is corrupted or lost, the write logs stored locally in the non-volatile storage device at the primary node can be extracted\/retrieved and used to perform the write logs on the storage devices.","If the write logs of one node has a storage size equal to \u201clogspace,\u201d the non-volatile storage space, within the cluster, required to store the write logs of one node is equal to 2*logspace (where the write logs are stored locally on the primary node and also stored remotely on the partner node). As such, all write logs are stored to a first non-volatile storage device and a full duplicate of the write logs are stored to a second non-volatile storage device (referred to herein as a \u201cmirroring\u201d method). Thus, within the cluster, the non-volatile storage space required to store write logs of all nodes of the cluster is equal to 2n*logspace, where n is equal to the number of nodes in the cluster. As such, conventional mirroring methods for storing write logs may consume a significant amount of valuable non-volatile storage space within the cluster.","In some embodiments, a cluster storage system comprises a plurality of nodes that access a set of storage devices, each node having two or more predetermined failover partner nodes. In these embodiments, a primary node receives write requests and produces write logs that represent the received write requests. The primary node may produce parity data for the write logs and store the parity data locally to a non-volatile storage device. By storing locally only the parity data of the write logs (rather than storing the actual write logs), the non-volatile storage space within the cluster used for storing write logs may be reduced. Also, copies of the write logs of the primary node may be striped\/sub-divided and distributed remotely (prior to failure of the primary node) to two or more partner nodes for storage at non-volatile storage devices. Thus, prior to failure of the primary node, the write logs of the primary node will already be distributed among two or more partner nodes so that each partner node will already have stored locally a sub-set of the write logs to perform on the storage devices. As such, the write logs do not need to be distributed to the two or more partner nodes after failure of the primary node, which improves the response time of the cluster to the failure of the primary node.","In some embodiments, each node may perform write requests in two stages. In a first stage, a primary node may receive write requests (containing blocks of data to be written) and produce a write log for each received write request, a write log representing a write request and containing the blocks of data to be written. The write logs of the primary node may be stored to a local volatile memory device. In a second stage, upon occurrence of a predetermined initiating event (referred to as a \u201cconsistency point\u201d), accumulated write logs stored in the local volatile memory device may be performed on the storage devices (whereby the received blocks of data are written to the storage devices). In some embodiments, each write log may be implemented as a pair of buffers, whereby one buffer is allowed to be filled while the other buffer is held during the consistency point.","In some embodiments, after the first stage and prior to the second stage, the primary node may produce parity data for one or more write logs stored locally in volatile memory (e.g., RAM). The primary node may do so using any parity scheme known in the art, e.g., single parity, double parity, etc. The primary node may then store the parity data locally to a non-volatile storage device (e.g., NVRAM). By storing only the parity data of the write logs to the non-volatile storage device (rather than a full copy of the write logs as done in the mirroring method), the storage space used for storing the write logs may be reduced throughout the cluster.","In some embodiments, the write logs of the primary node (stored locally in volatile memory) may also be stored remotely at two or more partner nodes to non-volatile storage devices. In these embodiments, each primary node of a cluster has two or more failover partner nodes that are configured to take over the workload of the primary node if the primary node fails. As opposed to each primary node having only a single partner node where the entire additional workload (of the failed primary node) is imposed on a single partner node, the additional workload may thus be distributed among two or more partner nodes.","The cluster may be configured such that each primary node may locally store its own write logs and a copy of the write logs stored remotely to only one of the partner nodes. Upon failure of the primary node, the partner node storing the copy of the write logs may sub-divide and distribute the write logs to the other partner nodes of the primary node, whereby each partner node then performs its allotted write logs on the storage devices. However, since the partner node storing the write logs sub-divides and distributes the write logs to the other partner nodes after failure of the primary node, this method increases the response time of the cluster to the failure of the primary node.","In some embodiments, the write logs of the primary node may be striped\/sub-divided and distributed to each of its two or more partner nodes prior to failure of the primary node (e.g., upon the write logs being produced by the primary node) for storage at a non-volatile storage device. As such, upon failure of the primary node, each partner node will already have stored locally a sub-set of its allotted write logs to perform on the storage devices. This avoids having a single partner node sub-divide and re-distribute the write logs to the other partner nodes after failure of the primary node, which improves the response time of the cluster to the failure of the primary node. Also, if the data of the write logs stored at a particular partner node is corrupted or lost, the corrupted or lost write log data can be reconstructed from the parity data stored at the primary node and the write log data stored at the one or more other partner nodes not having corrupted or lost write log data. The particular partner node may then perform the reconstructed write logs on the storage devices.","In the following description, numerous details are set forth for purpose of explanation. However, one of ordinary skill in the art will realize that the embodiments described herein may be practiced without the use of these specific details. In other instances, well-known structures and devices are shown in block diagram form in order not to obscure the description with unnecessary detail.","The description that follows is divided into four sections. Section I describes a cluster environment in which some embodiments operate. Section II describes a storage operating system having a de-staging layer for processing and distributing write logs. Section III describes a shared storage of the cluster. Section IV describes processing and distributing write logs of nodes of a cluster.","I. Cluster Environment",{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIGS. 1A-B","b":["100","100","200","200","100"]},"As shown in , each node  may be organized as a network element (N-blade ) and a disk element (D-blade ). The N-blade  includes functionality that enables the node  to connect to clients  over a computer network , while each D-blade  connects to one or more storage devices, such as disks  of a disk array . The nodes  are interconnected by a cluster switching fabric  which, in the illustrative embodiment, may be embodied as a Gigabit Ethernet switch. In other embodiments, the cluster switching fabric  may be embodied as another clustering network connection. An exemplary distributed file system architecture is generally described in U.S. Patent Application Publication No. US 2002\/0116593 titled METHOD AND SYSTEM FOR RESPONDING TO FILE SYSTEM REQUESTS, by M. Kazar et al. published Aug. 22, 2002.","It should be noted that although disks  are used in some embodiments described below, any other type of storage device may be used as well. For example, a solid state storage device may be used instead, the solid state device having no mechanical moving parts for reading and writing data. Some examples of solid state devices include flash memory, non-volatile random access memory (NVRAM), Magnetic Random Access Memory (MRAM), Phase Change RAM (PRAM), etc. In other embodiments, other storage devices other than those mentioned here may also be used.","Also, it should be noted that while there is shown an equal number of N and D-blades in the illustrative cluster , there may be differing numbers of N and\/or D-blades, and\/or different types of blades implemented in the cluster  in accordance with various embodiments. For example, there may be a plurality of N-blades and\/or D-blades interconnected in a cluster configuration  that does not reflect a one-to-one correspondence between the N and D-blades. As such, the description of a node  comprising one N-blade and one D-blade should be taken as illustrative only. For example, a node  may also have one N-blade and a plurality of D-blades, a plurality of N-blades and one D-blade, or a plurality of N-blades and a plurality of D-blades.","The clients  may be general-purpose computers configured to interact with the node  in accordance with a client\/server model of information delivery. That is, each client  may request the services of the node  (e.g., by submitting read\/write requests), and the node  may return the results of the services requested by the client , by exchanging packets over the network . The client  may submit access requests by issuing packets using file-based access protocols, such as the Common Internet File System (CIFS) protocol or Network File System (NFS) protocol, over the Transmission Control Protocol\/Internet Protocol (TCP\/IP) when accessing information in the form of files and directories. Alternatively, the client may submit access requests by issuing packets using block-based access protocols, such as the Small Computer Systems Interface (SCSI) protocol encapsulated over TCP (iSCSI) and SCSI encapsulated over Fibre Channel (FCP), when accessing information in the form of blocks.","In some embodiments, a client  connects to a node  for a data-access session with the node . During a data-access session, the client  may submit access requests that are received and performed by the node . Such access requests may include storage state requests, a storage state request comprising a request that alters the data state of a storage device . Examples of storage state requests include requests for storing new data to a file, deleting a file, changing attributes of a file, etc. For illustrative purposes, storage state requests may be generically referred to herein as write requests.","In some embodiments, the totality of storage space provided by the disks  and disk arrays  of the cluster  comprise a total shared storage space (referred to as \u201cshared storage \u201d) of the cluster . In other embodiments, the shared storage  comprises the totality of storage space provided by other types of storage devices (such as solid state storage devices). The shared storage  is accessible by each D-blade  of each node  in the cluster . The shared storage  is discussed in detail in Section III. In some embodiments, the cluster  may provide high availability of service to clients  in accessing the shared storage . For example, the nodes  may be configured to communicate with one another (e.g., via cluster switching fabric ) to act collectively to offset any single node  failure within the cluster .",{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 1B","b":["200","200","200","180","200","200","200","200","200"]},"As opposed to each node  having only a single partner node  where the entire additional workload (of the failed node) is imposed on a single partner node, the additional workload may thus be distributed among two or more partner nodes. A cluster  wherein a node  may have two or more predetermined failover partner nodes  may be referred to herein as an \u201cN-way system.\u201d N-way systems are discussed in detail in U.S. patent application Ser. No. 12\/401,458, entitled \u201cTakeover of a Failed Node of a Cluster Storage System on a Per Aggregate Basis,\u201d by Susan M. Coatney, et al., filed herewith, and incorporated herein by reference.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 2","FIGS. 1A-B"],"b":["200","200","222","224","225","226","228","230","223"],"i":"a,b"},"The cluster access adapter  comprises a plurality of ports adapted to couple the node  to other nodes of the cluster . In the illustrative embodiment, Ethernet is used as the clustering protocol and interconnect media, although it will be apparent to those skilled in the art that other types of protocols and interconnects may be utilized within the cluster architecture described herein. In alternate embodiments where the N-blades and D-blades are implemented on separate storage systems or computers, the cluster access adapter  is utilized by the N\/D-blade for communicating with other N\/D-blades in the cluster .","Each node  is illustratively embodied as a dual processor storage system executing a storage operating system  that preferably implements a high-level module, such as a file system, to logically organize the information as a hierarchical structure of named data containers, such as directories, files and special types of files called virtual disks (hereinafter generally \u201cblocks\u201d) on the disks. However, it will be apparent to those of ordinary skill in the art that the node  may alternatively comprise a single or more than two processor system. Illustratively, one processor executes the functions of the N-blade  on the node, while the other processor executes the functions of the D-blade .","The network adapter  comprises a plurality of ports adapted to couple the node  to one or more clients  over point-to-point links, wide area networks, virtual private networks implemented over a public network (Internet) or a shared local area network. The network adapter  thus may comprise the mechanical, electrical and signaling circuitry needed to connect the node to the network. Illustratively, the computer network  may be embodied as an Ethernet network or a Fibre Channel (FC) network. Each client  may communicate with the node  over the network  by exchanging discrete frames or packets of data according to pre-defined protocols, such as TCP\/IP.","The storage adapter  cooperates with the storage operating system  executing on the node  to access information requested by the clients. The information may be stored on any type of attached array of writable storage device media such as video tape, optical, DVD, magnetic tape, bubble memory, electronic random access memory, micro-electro mechanical and any other similar media adapted to store information, including data and parity information. However, as illustratively described herein, the information is preferably stored on the disks  of array . The storage adapter comprises a plurality of ports having input\/output (I\/O) interface circuitry that couples to the disks over an I\/O interconnect arrangement, such as a conventional high-performance, FC link topology.","Storage of information on each array  is preferably implemented as one or more storage \u201cvolumes\u201d that comprise a collection of physical storage disks  cooperating to define an overall logical arrangement of volume block number (vbn) space on the volume(s). Each logical volume is generally, although not necessarily, associated with its own file system. The disks within a logical volume\/file system are typically organized as one or more groups, wherein each group may be operated as a Redundant Array of Independent (or Inexpensive) Disks (RAID). Most RAID implementations, such as a RAID-4 level implementation, enhance the reliability\/integrity of data storage through the redundant writing of data \u201cstripes\u201d across a given number of physical disks in the RAID group, and the appropriate storing of parity information with respect to the striped data. An illustrative example of a RAID implementation is a RAID-4 level implementation, although it should be understood that other types and levels of RAID implementations may be used in accordance with the inventive principles described herein.","The memory  illustratively comprises storage locations that are addressable by the processors and adapters for storing software program code and data used in some embodiments. The processors and adapters may, in turn, comprise processing elements and\/or logic circuitry configured to execute the software code and manipulate the data stored in the memory . In some embodiments, the memory  may comprise a form of random access memory (RAM) comprising \u201cvolatile\u201d memory that is generally cleared by a power cycle or other reboot operation.","The storage operating system , portions of which is typically resident in memory and executed by the processing elements, functionally organizes the node  by, inter alia, invoking storage operations in support of the storage services implemented by the node. It will be apparent to those skilled in the art that other processing and memory means, including various computer readable media, may be used for storing and executing program instructions pertaining to the invention described herein. In some embodiments, the storage operating system  comprises a plurality of software layers (including a de-staging layer ) that are executed by the processors. In some embodiments, the de-staging layer  is implemented to produce write logs, produce parity data for write logs, and sub-divide and distribute\/transfer copies of the write logs to remote partner nodes.","The local non-volatile storage device  may comprise one or more storage devices, such as disks, utilized by the node to locally store configuration information, e.g., provided by one or more management processes. The local non-volatile storage device  that may be employed as a backup memory that ensures that the storage system does not \u201close\u201d received information, e.g., CIFS and NFS requests, in the event of a system shutdown or other unforeseen problem. In some embodiments, the non-volatile storage device  may comprise a rewritable computer memory for storing data that does not require power to maintain data\/information stored in the computer memory and may be electrically erased and reprogrammed. Some examples of non-volatile storage devices include flash memory, non-volatile random access memory (NVRAM), Magnetic Random Access Memory (MRAM), Phase Change RAM (PRAM), etc. In other embodiments, other non-volatile storage devices are used other than those listed here.","II. Storage Operating System","To facilitate access to the disks , the storage operating system  implements a write-anywhere file system that cooperates with one or more virtualization modules to \u201cvirtualize\u201d the storage space provided by disks . The file system logically organizes the information as a hierarchical structure of named directories and files on the disks. Each \u201con-disk\u201d file may be implemented as set of disk blocks configured to store information, such as data, whereas the directory may be implemented as a specially formatted file in which names and links to other files and directories are stored. The virtualization module(s) allow the file system to further logically organize information as a hierarchical structure of blocks on the disks that are exported as named logical unit numbers (luns).","In the illustrative embodiment, the storage operating system is preferably the Data ONTAP\u00ae software operating system available from NetApp, Inc., Sunnyvale, Calif. that implements a Write Anywhere File Layout (WAFL\u00ae) file system. However, it is expressly contemplated that any appropriate storage operating system may be enhanced for use in accordance with the inventive principles described herein. As such, where the term \u201cWAFL\u201d is employed, it should be taken broadly to refer to any storage operating system that is otherwise adaptable to the teachings of this invention.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 3","FIG. 2"],"b":["300","200","300","325","310","180","200","325","312","314","316","315"]},"A file system protocol layer provides multi-protocol file access and, to that end, includes support for the Direct Access File System (DAFS) protocol , the NFS protocol , the CIFS protocol  and the Hypertext Transfer Protocol (HTTP) protocol . A VI layer  implements the VI architecture to provide direct access transport (DAT) capabilities, such as RDMA, as required by the DAFS protocol . An iSCSI driver layer  provides block protocol access over the TCP\/IP network protocol layers, while a FC driver layer  receives and transmits block access requests and responses to and from the node. The FC and iSCSI drivers provide FC-specific and iSCSI-specific access control to the blocks and, thus, manage exports of luns to either iSCSI or FCP or, alternatively, to both iSCSI and FCP when accessing the blocks on the node .","In addition, the storage operating system  includes a series of software layers organized to form a storage server  (D-blade ) that provides data paths for accessing information stored on the disks  of the node . To that end, the storage server  includes a file system module , a de-staging layer , a storage\/RAID system layer  and a disk driver system module . The RAID system layer  manages the storage and retrieval of information to and from the volumes\/disks in accordance with I\/O operations, while the disk driver system  implements a disk access protocol such as, e.g., the SCSI protocol.","The file system  implements a virtualization system of the storage operating system  through the interaction with one or more virtualization modules illustratively embodied as, e.g., a virtual disk (vdisk) module (not shown) and a SCSI target module . The SCSI target module  is generally disposed between the FC and iSCSI drivers ,  and the file system  to provide a translation layer of the virtualization system between the block (lun) space and the file system space, where luns are represented as blocks.","The file system  is illustratively a message-based system that allocates storage space for itself in the disk array  and controls the layout of information on the array. The file system further provides logical volume management capabilities for use in access to the information stored on the storage devices, such as disks. That is, in addition to providing file system semantics, the file system  provides functions normally associated with a volume manager. These functions include (i) aggregation of the disks, (ii) aggregation of storage bandwidth of the disks, and (iii) reliability guarantees, such as mirroring and\/or parity (RAID). The file system  illustratively implements the WAFL file system (hereinafter generally the \u201cwrite-anywhere file system\u201d) having an on-disk format representation that is block-based using, e.g., 4 kilobyte (kB) blocks and using index nodes (\u201cinodes\u201d) to identify files and file attributes (such as creation time, access permissions, size and block location). The file system uses files to store metadata describing the layout of its file system; these metadata files include, among others, an inode file. A file (data container) handle, i.e., an identifier that includes an inode number, is used to retrieve an inode from disk.","All inodes of the write-anywhere file system may be organized into the inode file. A file system (fs) info block specifies the layout of information in the file system and includes an inode of a data container, e.g., file, that includes all other inodes of the file system. Each logical volume (file system) has an fsinfo block that may be stored at a fixed or variable location within, e.g., a RAID group. The inode of the inode file may directly reference (point to) data blocks of the inode file or may reference indirect blocks of the inode file that, in turn, reference data blocks of the inode file. Within each data block of the inode file are embedded inodes, each of which may reference indirect blocks that, in turn, reference data blocks of a file.","Operationally, an access request (read\/write request) from the client  is forwarded as a packet over the computer network  and onto the node  where it is received at the network adapter . A network driver (of layer  or layer ) processes the packet and, if appropriate, passes it on to a network protocol and file access layer for additional processing prior to forwarding to the write-anywhere file system . Here, the file system produces operations to load (retrieve) the requested data from disk  if it is not resident \u201cin core\u201d, i.e., in memory . If the information is not in memory, the file system  indexes into the inode file using the inode number to access an appropriate entry and retrieve a logical vbn. The file system then passes a message structure including the logical vbn to the RAID system ; the logical vbn is mapped to a disk identifier and disk block number (disk,dbn) and sent to an appropriate driver (e.g., SCSI) of the disk driver system . The disk driver accesses the dbn from the specified disk  and loads the requested data block(s) in memory for processing by the node. Upon completion of the access request, the node  (and storage operating system ) returns a reply to the client  over the network .","It should be noted that the software \u201cpath\u201d through the storage operating system layers described above needed to perform data storage access for the client request received at the node may alternatively be implemented in hardware. That is, in an alternate embodiment of the invention, a storage access request data path may be implemented as logic circuitry embodied within a field programmable gate array (FPGA) or an application specific integrated circuit (ASIC). This type of hardware implementation increases the performance of the storage service provided by node  in response to a request issued by client . Moreover, in another alternate embodiment of the invention, the processing elements of adapters ,  may be configured to offload some or all of the packet processing and storage access operations, respectively, from processor , to thereby increase the performance of the storage service provided by the node. It is expressly contemplated that the various processes, architectures and procedures described herein can be implemented in hardware, firmware or software.","As used herein, the term \u201cstorage operating system\u201d generally refers to the computer-executable code operable on a computer to perform a storage function that manages data access and may, in the case of a node , implement data access semantics of a general purpose operating system. The storage operating system  can also be implemented as a microkernel, an application program operating over a general-purpose operating system, such as UNIXO or Windows NT\u00ae, or as a general-purpose operating system with configurable functionality, which is configured for storage applications as described herein.","In addition, it will be understood to those skilled in the art that the invention described herein may apply to any type of special-purpose (e.g., file server, filer or storage serving appliance) or general-purpose computer, including a standalone computer or portion thereof, embodied as or including a storage system. Moreover, the teachings of this invention can be adapted to a variety of storage system architectures including, but not limited to, a network-attached storage environment, a storage area network and disk assembly directly-attached to a client or host computer. The term \u201cstorage system\u201d should therefore be taken broadly to include such arrangements in addition to any subsystems configured to perform a storage function and associated with other equipment or systems. It should be noted that while this description is written in terms of a write any where file system, the teachings of the present invention may be utilized with any suitable file system, including a write in place file system.","In some embodiments, the storage server  is embodied as D-blade  of the storage operating system  to service one or more volumes of array . In addition, the multi-protocol engine  is embodied as N-blade  to (i) perform protocol termination with respect to a client issuing incoming data access request packets over the network , as well as (ii) redirect those data access requests to any storage server  of the cluster . Moreover, the N-blade  and D-blade  cooperate to provide a highly-scalable, distributed storage system architecture of the cluster . To that end, each blade includes a cluster fabric (CF) interface module adapted to implement intra-cluster communication among the blades (e.g., communication between blades of the same node or communication between blades of different nodes) using CF protocol messages.","For example, the protocol layers (e.g., the NFS\/CIFS layers and the iSCSI\/FC layers) of the N-blade  may function as protocol servers that translate file-based and block-based access requests from clients  into CF protocol messages used for communication with the D-blade . In some embodiments, the N-blade servers convert the incoming client access requests into file system primitive operations (commands) that are embedded within CF protocol messages by the CF interface module  for transmission to the D-blades  of the cluster . Notably, the CF interface modules  cooperate to provide a single file system image across all D-blades  in the cluster . Thus, any network port of an N-blade that receives a client request can access any data container within the single file system image located on any D-blade  of the cluster.","In some embodiments, the N-blade  and D-blade  are implemented as separately-scheduled processes of storage operating system . In other embodiments, the N-blade  and D-blade  may be implemented as separate software components\/code within a single operating system process. Communication between an N-blade and D-blade in the same node  is thus illustratively effected through the use of CF messages passing between the blades. In the case of remote communication between an N-blade and D-blade of different nodes, such CF message passing occurs over the cluster switching fabric .","A known message-passing mechanism provided by the storage operating system to transfer information between blades (processes) is the Inter Process Communication (IPC) mechanism. The protocol used with the IPC mechanism is illustratively a generic file and\/or block-based \u201cagnostic\u201d CF protocol that comprises a collection of methods\/functions constituting a CF application programming interface (API). Examples of such an agnostic protocol are the SpinFS and SpinNP protocols available from NetApp, Inc. The SpinFS protocol is described in the above-referenced U.S. Patent Application Publication No. US 2002\/0116593.","The CF interface module  implements the CF protocol for communicating file system commands\/messages among the blades of cluster . Communication is illustratively effected by the D-blade exposing the CF API to which an N-blade (or another D-blade) issues calls. To that end, the CF interface module  is organized as a CF encoder and CF decoder. The CF encoder of, e.g., CF interface on N-blade  encapsulates a CF message as (i) a local procedure call (LPC) when communicating a file system command to a D-blade  residing on the same node  or (ii) a remote procedure call (RPC) when communicating the command to a D-blade residing on a remote node of the cluster . In either case, the CF decoder of CF interface on D-blade  de-encapsulates the CF message and processes the file system command. As used herein, the term \u201cCF message\u201d may be used generally to refer to LPC and RPC communication between blades of the cluster.","In some embodiments, the storage operating system  also comprises a de-staging layer  that operates in conjunction with the other software layers and file system of the storage operating system  to produce and store write logs as described herein. In some embodiments, the de-staging layer  may be pre-included in storage operating system  software. In other embodiments, the de-staging layer  may comprise an external auxiliary plug-in type software module that works with the storage operating system  to enhance its functions. In some embodiments, the de-staging layer  may reside between the file system layer  and the RAID system layer  of the storage operating system  (as shown in ). In other embodiments, the de-staging layer  may reside near other layers of the storage operating system .","The de-staging layer  may be configured to receive write requests for files and perform the received write requests in two stages. In a first stage, write requests received by the file system layer  are sent to the de-staging layer , whereby a write request may contain blocks of data to be written. The de-staging layer  produces a write log for each received write request, a write log representing the write request and containing the blocks of data to be written. The write logs may be stored to a volatile memory device. As used herein, a primary node produces \u201clocal write logs\u201d  that may be stored locally to a volatile memory device, for example, to the memory  (as shown in ).","In a second stage, upon occurrence of a predetermined initiating event (referred to as a \u201cconsistency point\u201d), accumulated local write logs  stored in the local volatile memory device may be performed on the storage devices (e.g., whereby the received blocks of data are written to the storage devices). To do so, the accumulated local write logs  may be sent to the RAID system layer  that then performs the write logs (e.g., by writing the blocks of data in the write logs to a storage device). The consistency point may be initiated by various predetermined initiating events such as the occurrence of a predetermined time interval, the storage size of the accumulated local write logs  reaching a predetermined threshold size, etc. Note that the consistency point may be initiated at different times for each node in the cluster.","In some embodiments, the de-staging layer  may further process the write logs accumulated during the first stage that are awaiting the next consistency point to be written to a storage device  during the second stage. In some embodiments, the de-staging layer  may process the accumulated write logs  (stored locally to a volatile memory device) to produce and store parity data of the write logs . As used herein, a primary node produces \u201clocal parity data\u201d  of the local write logs  and stores the \u201clocal parity data\u201d  to a local non-volatile storage device  (as shown in ). In some embodiments, the de-staging layer  also sub-divides the accumulated write logs  into two or more sub-sets of write logs and distributes (transfers) the sub-sets to two or more remote partner nodes (each remote partner node storing the received allotted sub-set to a non-volatile storage ). As used herein, a primary node receives \u201cremote write logs\u201d  from two or more remote partner nodes and stores the remote write logs  to a local non-volatile storage device  (as shown in ).","After the second stage is initiated at the consistency point, after a write log is performed on a storage device, the write log is committed to disk and thus may be deleted. As such, after the accumulated local write logs  are performed at the consistency point, the local write logs  may then be deleted from volatile memory . The local parity data  produced for the local write logs  may also be deleted from non-volatile storage . Also, the local write logs  distributed\/transferred to the two or more remote partner nodes (and stored as remote write logs ) may also be deleted from the non-volatile storages  of the remote partner nodes. After the consistency point, the process repeats as new write logs are produced for new received write requests, the new write logs being processed by the de-staging layer .","The de-staging layers  in the nodes  of the cluster  may be configured to communicate and operate in conjunction with each other to perform the methods described herein. As used herein, a local\/primary node may comprise a \u201clocal\u201d de-staging layer  and a remote\/partner node may comprise a \u201cremote\u201d de-staging layer . The de-staging layers of the various nodes  may issue CF messages (via the cluster switching fabric ) or other commands to each other to transfer\/send write logs from one node to another or to delete write logs stored on a remote node (after the write logs are performed and no longer needed). The de-staging layers of the various nodes  may also transfer the actual write logs from one node to another via the cluster switching fabric .","For example, for sending write logs, the de-staging layer  on a primary node may send a CF message to the de-staging layer  on a remote partner node to prepare to receive write logs. The de-staging layer  on the primary node may then begin sending the write logs to the de-staging layer  on the remote partner node through the cluster switching fabric . The de-staging layer  on the remote partner node may then receive and store the write logs to its local non-volatile storage device . For example, for deleting write logs of the primary node (after the write logs have been performed by the primary node), the de-staging layer  on the primary node may send a CF message to the de-staging layer  on a remote partner node to delete particular write logs that have been performed. The de-staging layer  on the remote partner node may then delete the particular write logs from its local non-volatile storage device .","III. Shared Storage","As discussed above, in relation to , the totality of storage space provided by the disks  and disk arrays  of the cluster  comprise a total shared storage space (referred to as \u201cshared storage \u201d) of the cluster . The shared storage  is accessible by each D-blade  of each node  in the cluster . Referring to , for illustrative purposes, node A may be referred to as the local\/primary node that may experience a failure, primary node A having two or more remote partner nodes (such as remote partner nodes B, C, and D) that are configured to assume the workload of the primary node A upon failure.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":["FIG. 4","FIG. 1B","FIG. 4"],"b":["135","100","135","135","200","100","410","135","200"]},"In normal operation (when node failures have not occurred), each node  may be configured to access only the aggregate set associated\/assigned to the node . In particular, in normal operation, the D-blade  of each node  may be configured to access only the aggregate set assigned to the node . For example, in normal operation, the D-blade  of node A may be configured to access and serve data from only aggregate set A and the D-blade  of node B may be configured to access and serve data from only aggregate set B. Therefore, in normal operation, all access requests (received at any N-blade  of any node  in the cluster) for data in aggregate set A are routed through the D-blade  of node A (and have physical addresses\/file handles that specify the D-blade  of node A). Note that the N-blade  of each node can receive access requests for data in any aggregate  of the shared storage , and will route the access requests to the appropriate D-blade  that services the requested data.","In the event of a node failure, the failed node is no longer capable of processing access requests (read\/write requests) from clients  for data in the aggregate set assigned to the failed node. In such an event, the access requests sent to the failed node  may be re-directed to the two or more remote partner nodes  for processing. The remote partner nodes  of the failed node may be configured to collectively replace the failed node by accessing and serving data in the aggregate assigned to the failed node (as well as the accessing and serving data in its own assigned aggregate). For example, upon failure of primary node A, remote partner nodes B, C, and D may each be configured to access and serve data stored in aggregate set A (whereas under normal operating conditions, the remote partner nodes B, C, and D would not have access to or serve data from aggregate set A).",{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 5","b":["500","500","510","510","500","510","502","504","506","508","500","550","550","560","530"]},"IV. Processing and Distributing Write Logs","As discussed above, during a first stage, each node  may produce write logs for received write requests and locally store the write logs to a volatile memory device. During a second stage at a consistency point, accumulated write logs stored in the local volatile memory device may be performed on the storage devices. To ensure data consistency in case the write logs in the volatile memory are lost (before the write logs can be performed) and\/or the node fails, the write logs may also be stored to non-volatile storage devices. For example, the write logs of the node may be locally stored to a non-volatile memory device and also be stored remotely to a non-volatile storage device at the partner node. As such, if the local\/primary node fails, the remote\/partner node will have a copy of the write logs and will still be able to perform the write logs on the storage devices. Also, if the write logs stored at the partner node is corrupted or lost, the write logs stored locally in the non-volatile storage device at the primary node can be extracted\/retrieved and used to perform the write logs on the storage devices.","A. Mirroring Write Logs in Failover Partners",{"@attributes":{"id":"p-0077","num":"0076"},"figref":["FIG. 6","FIG. 6","FIG. 6"],"b":["200","280","230","230","200","290","230"]},"However, there are two disadvantages of the mirroring scheme. First, upon failure of the primary node, the partner node assigned to store the write logs of the primary node may sub-divide and distribute the write logs to the other partner nodes, whereby each partner node then performs its allotted write logs on the storage devices. However, the sub-dividing and distribution of the write logs after failure of the primary node increases the response time of the cluster to the failure of the primary node. Second, the non-volatile storage space, within the cluster, required to store the write logs of one node is equal to 2*logspace (where logspace equals the storage size of the write logs of the one node). As such, the mirroring scheme for storing write logs may consume a significant amount of valuable non-volatile storage space within the cluster.","In some embodiments, the de-staging layer  of each node is implemented to process write logs stored in volatile memory  that are accumulated during the first stage and are awaiting the next consistency point to be written to a storage device  during the second stage.","B. Producing and Storing Parity Data for Write Logs","In some embodiments, after the first stage and prior to the second stage, the de-staging layer  may process write logs (stored in local volatile memory ) to produce parity data for the write logs. The primary node may then store the parity data  locally to a non-volatile storage device  (as shown in ).  shows a conceptual diagram of parity data  that is produced and stored locally (in non-volatile storage device ) for each node of a cluster. For example, node A may process local write logs to produce and locally store parity data  (\u201cNode A Local Parity Data\u201d) for its own write logs.","By storing only a parity image (parity data) of the write logs to the non-volatile storage device (rather than a full copy of the write logs), the non-volatile storage space used for storing the write logs may be reduced throughout the cluster. In these embodiments, a primary node may produce parity data using any parity scheme known in the art, e.g., single parity, double parity, etc. The amount of storage space saved and data protection may vary depending on the parity scheme used. For example, single parity may provide substantial storage savings with some data protection, whereas double parity may provide less storage savings but increased data protection.","For example, if a non-volatile storage size of 2*logspace is required to store, within the cluster, write logs of a primary node using the mirroring scheme, using single parity may require a non-volatile storage size of:\n\n[1+(1\/(m))]*logspace\n\nwhereby m is equal to the number of partner nodes of the primary node. Using double parity may require a non-volatile storage size of:\n\n[1+(2\/(m))]*logspace\n","For example, primary node A has three partner nodes B, C, and D and the write logs of node A have a storage size of 3 GB, the mirroring scheme would require 6 GB of non-volatile storage space within the cluster to store the write logs of node A. Using single parity, however, only 4 GB of non-volatile storage space would be needed within the cluster to store the write logs of node A, thus producing a 33% savings of non-volatile storage space within the cluster. Using double parity, only 5 GB of non-volatile storage space would be needed within the cluster to store the write logs of node A, whereby double parity provides less storage savings but increased data protection over single parity.","C. Sub-Dividing and Distributing Write Logs","In some embodiments, after the first stage and prior to the second stage, the de-staging layer  may also process write logs (stored in local volatile memory ) of a primary node by sub-dividing the accumulated write logs  into two or more sub-sets of write logs. The de-staging layer  may then distribute\/transfer copies of the sub-sets of write logs of the primary node to two or more remote partner nodes. Each remote partner node may receive a sub-set of write logs and store the received sub-set locally to a non-volatile storage . Upon failure of the primary node, each remote partner node may perform the received sub-set of write logs on the storage devices of the shared storage . In some embodiments, the local write logs of a node may be sub-divided and distributed after parity data of the local write logs is produced.",{"@attributes":{"id":"p-0085","num":"0084"},"figref":["FIG. 7","FIG. 7"],"b":["375","280","224","280","375","375","230","1","290","2","290","3","290","280"]},"As such, the local write logs of a primary node may be striped\/sub-divided and distributed to two or more partner nodes prior to failure of the primary node (e.g., upon the write logs being produced by the primary node) for storage at non-volatile storage devices at the partner nodes. Thus, upon failure of the primary node, each partner node will already have stored locally a sub-set of its allotted write logs to perform on the storage devices of the shared storage . This avoids having a single partner node sub-divide and re-distribute the write logs to the other partner nodes after failure of the primary node, which improves the response time of the cluster to the failure of the primary node.","In some embodiments, the local write logs  of a primary node may be sub-divided and distributed to remote partner nodes in a variety of ways (e.g., based on storage size, number of write logs, time periods, etc.). For example, in some embodiments, the local write logs may be sub-divided into two or more sub-sets, each sub-set having approximately the same predetermined storage size so that each remote partner node receives an allotted sub-set that is approximately equal in storage size. For example, a first sub-set comprising approximately 50 MB of write logs may be distributed to a first remote partner node, a second sub-set comprising approximately 50 MB of write logs may be distributed to a second remote partner node, etc. In other embodiments, the local write logs may be sub-divided into two or more sub-sets, each sub-set having approximately the same number of write logs. In further embodiments, the local write logs may be sub-divided into two or more sub-sets, each sub-set having write logs produced during a predetermined time interval. For example, a first sub-set comprising write logs produced during a first day may be distributed to a first remote partner node, a second sub-set comprising write logs produced during a second day may be distributed to a second remote partner node, etc.","As discussed above in Section III, a primary node  of the cluster  is assigned\/associated with a set of one or more aggregates  in the shared storage  to which the primary node stores and serves client data. Write requests received by nodes of the cluster may comprise a block\/data address that specifies a particular aggregate  on which the write request is to be performed. The data address may be used to route the write request to the appropriate node  assigned to store and serve client data for the specified aggregate . A write log produced for a write request represents the write request and also contains the data address specifying a particular aggregate on which the write log is to be performed.","In some embodiments, a plurality of aggregates are associated with a primary node, the plurality of aggregates comprising two or more sub-sets of aggregates. In these embodiments, the local write logs of the primary node may be sub-divided into two or more sub-sets of write logs, each sub-set of write logs comprising write logs to be performed on the predetermined sub-set of aggregates associated with the primary node, wherein each write log in the sub-set of write logs specifies an aggregate in the predetermined sub-set of aggregates. In some embodiments, in the event of a failure of the primary node, each remote partner node of the primary node may be assigned to access and serve data of a predetermined sub-set of aggregates associated with the primary node. Each remote partner node may receive a sub-set of write logs of the primary node that specify the predetermined sub-set of aggregates assigned to the remote partner node upon failure of the primary node.","To illustrate, in the example of , primary node A may be associated with \u201cAggregate Set A\u201d comprising aggregates 1-9. In the event of a failure of primary node A, remote partner node B may be assigned to access and serve data of the sub-set of aggregates 1-3, remote partner node C may be assigned to access and serve data of the sub-set of aggregates 4-6, and remote partner node D may be assigned to access and serve data of the sub-set of aggregates 7-9. The local write logs of primary node A may be sub-divided into three sub-sets of write logs, a first sub-set comprising write logs to be performed on aggregates 1-3, a second sub-set comprising write logs to be performed on aggregates 4-6, and a third sub-set comprising write logs to be performed on aggregates 7-9. The three sub-sets of write logs are then distributed whereby node B receives and stores the first sub-set, node C receives and stores the second sub-set, and node D receives and stores the third sub-set. As such, if node A fails, node B may perform the first sub-set of write logs on the sub-set of aggregates 1-3, node C may perform the second sub-set of write logs on the sub-set of aggregates 4-6, and node D may perform the third sub-set of write logs on the sub-set of aggregates 7-9.","D. Reconstructing Corrupted or Lost Write Logs","As discussed above, the de-staging layers  of the nodes  produce parity data for write logs of a primary node and distribute copies of the write logs to two or more remote partner nodes prior to any failure of the primary node. If the primary node fails, then each remote partner node is configured to perform the received write logs of the primary node (which are stored locally to non-volatile storage ) on the shared storage . However, while performing its received write logs, a particular partner node may determine that the data of the write logs is corrupt or lost. If so, the particular partner node may retrieve the parity data at the primary node (stored in a non-volatile storage device) and the valid data of the other write logs stored at the one or more other remote partner nodes (which do not have corrupted or lost write logs). The particular partner node may then reconstruct the corrupt or lost write logs (using methods well known in the art) from the retrieved parity data and the retrieved valid write logs. After reconstruction of the corrupt or lost write logs, the particular remote partner node may then perform the reconstructed write logs on the shared storage .","For example, the de-staging layer  of primary node A may produce parity data for a first write log and a second write log(stored in local volatile memory ). For example, the parity data may be produced by performing an exclusive OR logical operation (XOR) on the data of the first and second write logs (for simple parity). A copy of the first write log may be transferred and stored to remote node B and a copy of the second write log may be transferred and stored to remote node C. If the first write log becomes corrupt or lost, the parity data and the second write log may be retrieved to reconstruct the first write log. For example, the first write log may be reconstructed by using the XOR logical operation (for simple parity).","E. Method for Processing and Distributing Write Logs",{"@attributes":{"id":"p-0093","num":"0092"},"figref":"FIG. 8","b":["800","200","100","800","800","370","200","800"]},"The method  begins when a primary node  receives (at step ) a plurality of write requests. The primary node  produces (at step ) a plurality of write logs for the write requests, and stores the write logs to a local volatile memory  (\u201cLocal Write Logs\u201d  shown in ). The primary node  then produces (at step ) parity data for the plurality of write logs and stores the parity data to a local non-volatile storage  (\u201cLocal Parity Data\u201d  shown in ). The primary node  sub-divides (at step ) the plurality of write logs into two or more sub-sets of write logs and distributes the sub-sets of write logs to two or more remote partner nodes. Each remote partner node receives (at step ) a sub-set of write logs and stores the received sub-set to a non-volatile storage  (\u201cRemote Write Logs\u201d  shown in ).","The method  then determines (at step ) whether the primary node has failed. If not, the method continues at step . If so, each of the two or more remote partner nodes performs (at step ) its allotted sub-set of write logs (stored to a non-volatile storage ) on the storage devices of the shared storage . The method  then determines (at step ) whether any sub-set of write logs allotted to any partner node is corrupt or lost. If not, the method  ends. If so, the method  retrieves (at step ) the parity data stored at the primary node (in a non-volatile storage device) and the other sub-sets of write logs stored at the one or more other partner nodes (which do not have corrupted or lost write logs). The method then reconstructs (at ) the corrupt or lost write logs (using methods well known in the art) from the retrieved parity data and write logs and performs the reconstructed write logs on the shared storage. The method  then ends.","Some embodiments may be conveniently implemented using a conventional general purpose or a specialized digital computer or microprocessor programmed according to the teachings herein, as will be apparent to those skilled in the computer art. Appropriate software coding may be prepared by programmers based on the teachings herein, as will be apparent to those skilled in the software art. Some embodiments may also be implemented by the preparation of application-specific integrated circuits or by interconnecting an appropriate network of conventional component circuits, as will be readily apparent to those skilled in the art.","Some embodiments include a computer program product comprising a computer readable medium (media) having instructions stored thereon\/in when executed (e.g., by a processor) perform methods, techniques, or embodiments described herein, the computer readable medium comprising sets of instructions for performing various steps of the methods, techniques, or embodiments described herein. The computer readable medium may comprise a storage medium having instructions stored thereon\/in which may be used to control, or cause, a computer to perform any of the processes of an embodiment. The storage medium may include, without limitation, any type of disk including floppy disks, mini disks (MD's), optical disks, DVDs, CD-ROMs, micro-drives, and magneto-optical disks, ROMs, RAMs, EPROMs, EEPROMs, DRAMs, VRAMs, flash memory devices (including flash cards), magnetic or optical cards, nanosystems (including molecular memory ICs), RAID devices, remote data storage\/archive\/warehousing, or any other type of media or device suitable for storing instructions and\/or data thereon\/in.","Stored on any one of the computer readable medium (media), some embodiments include software instructions for controlling both the hardware of the general purpose or specialized computer or microprocessor, and for enabling the computer or microprocessor to interact with a human user and\/or other mechanism utilizing the results of an embodiment. Such software may include without limitation device drivers, operating systems, and user applications. Ultimately, such computer readable media further includes software instructions for performing embodiments described herein. Included in the programming (software) of the general\/specialized computer or microprocessor are software modules for implementing some embodiments.","Those of skill would further appreciate that the various illustrative logical blocks, modules, circuits, techniques, or method steps of embodiments described herein may be implemented as electronic hardware, computer software, or combinations of both. To illustrate this interchangeability of hardware and software, various illustrative components, blocks, modules, circuits, and steps have been described herein generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application, but such implementation decisions should not be interpreted as causing a departure from the embodiments described herein.","The various illustrative logical blocks, modules, and circuits described in connection with the embodiments disclosed herein may be implemented or performed with a general purpose processor, a digital signal processor (DSP), an application specific integrated circuit (ASIC), a field programmable gate array (FPGA) or other programmable logic device, discrete gate or transistor logic, discrete hardware components, or any combination thereof designed to perform the functions described herein. A general purpose processor may be a microprocessor, but in the alternative, the processor may be any conventional processor, controller, microcontroller, or state machine. A processor may also be implemented as a combination of computing devices, e.g., a combination of a DSP and a microprocessor, a plurality of microprocessors, one or more microprocessors in conjunction with a DSP core, or any other such configuration.","The techniques or steps of a method described in connection with the embodiments disclosed herein may be embodied directly in hardware, in software executed by a processor, or in a combination of the two. In some embodiments, a software module or software layer may comprise an engine comprising firmware or software and hardware configured to perform embodiments described herein. In general, functions of a software module or software layer described herein may be embodied directly in hardware, or embodied as software executed by a processor, or embodied as a combination of the two. A software module may reside in RAM memory, flash memory, ROM memory, EPROM memory, EEPROM memory, registers, hard disk, a removable disk, a CD-ROM, or any other form of storage medium known in the art. An exemplary storage medium is coupled to the processor such that the processor can read data from, and write data to, the storage medium. In the alternative, the storage medium may be integral to the processor. The processor and the storage medium may reside in an ASIC. The ASIC may reside in a user device. In the alternative, the processor and the storage medium may reside as discrete components in a user device.","While the embodiments described herein have been described with reference to numerous specific details, one of ordinary skill in the art will recognize that the embodiments can be embodied in other specific forms without departing from the spirit of the embodiments. Thus, one of ordinary skill in the art would understand that the embodiments described herein are not to be limited by the foregoing illustrative details, but rather are to be defined by the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIGS. 1A-B"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
