---
title: Change detection method and system for use in detecting moving targets behind walls, barriers or otherwise visually obscured
abstract: A system and method for locating a moving target behind a wall or barrier comprising: providing a plurality of images of the region of interest; selecting a reference image from the plurality of images; forming a predetermined number of difference images by subtracting the absolute value of the pixels of the reference image from the absolute values of pixels in a predetermined number of the plurality of images; eliminating negative pixel values in the predetermined number of difference images; minimizing the side lobes to form a combined difference image for each reference frame, selecting another reference image from the plurality of images and performing the steps of forming a plurality of difference images, eliminating negative pixel values, averaging the resulting predetermined number of difference images and minimizing the side lobes for each selected reference image to form a set of combined difference images which contain the moving target signature.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09057783&OS=09057783&RS=09057783
owner: The United States of America as represented by the Secretary of the Army
number: 09057783
owner_city: Washington
owner_country: US
publication_date: 20110915
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","STATEMENT OF GOVERNMENT INTEREST","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS","Previous Methodology and Fundamentals of Change Detection","Preferred Embodiment Non-Coherent Change Detection Technique","Simulation Results","Experimental Results","Constant False Alarm Rate (CFAR) Approach","Tracker Algorithm","Clustering Analysis"],"p":["This application is a continuation-in-part and claims priority to U.S. application Ser. No. 13\/008,549 entitled \u201cSystem and Method for Moving Target Detection,\u201d filed Jan. 18, 2011, hereby incorporated by reference.","The embodiments herein may be manufactured, used, and\/or licensed by or for the United States Government without the payment of royalties thereon.","Security and military forces operating in urban environments need the capability to detect slow moving personnel inside buildings. To identify moving personnel inside buildings, a time-domain approach may be used that uses a low-frequency, ultra-wideband (UWB) radar. A low-frequency, UWB radar is desired since the low-frequency UWB radar transmits pulses capable of penetrating through walls and the UWB corresponds to a high range resolution that gives the capability to better locate the moving target (MT). The publication entitled \u201cThrough the Wall Detection of Slow Moving Personnel,\u201d by Martone, A.; et al., in the Proceedings of the SPIE Conference on Radar Sensor Technology XIII, vol. 7308, Orlando, Fla., April 2009, hereby incorporated by reference, discloses a description of a moving target indication (MTI) processing approach to detect and track slow-moving targets inside buildings, which successfully detected moving targets (MTs) from data collected by a low-frequency, ultra-wideband radar. Synchronous Impulse Reconstruction (SIRE) Radar is a low-frequency, ultra-wideband (UWB) radar having a frequency range of 300 MHz-3 GHz. An example of a SIRE system is illustrated in , showing 2 transmitters and 16 receivers in an antenna array 2 m wide having an average power of 5 mW with a downrange swath is 10-35 meters and a downrange resolution is 0.056 meters. Moving Target Indication (MTI) processing algorithms include change detection (CD), used to identify the MT signature; automatic target detection (ATD), used to eliminate imaging artifacts and potential false alarms due to target multi-bounce effects; clustering, used to identify a centroid for each cluster in the ATD output images; and tracking, used to establish a trajectory of the moving target (MT). These algorithms can be implemented in a real-time or near-real-time system.","In research reported in Martone, A. et al., \u201cMoving Target Indication for Transparent Urban Structures,\u201d ARL-TN-4809, U.S. Army Research Laboratory: Adelphi, Md., May 2009, both of which are hereby incorporated by reference, the effectiveness of time-domain, moving target indication (MTI) approach was reported for detecting moving personnel inside wood and cinderblock structures, moving personnel walking in nonlinear trajectories, and multiple moving personnel walking in linear trajectories. In the research, a time-domain approach to MTI was considered as an alternative to a frequency-domain approach, i.e., Doppler processing, since a very small Doppler shift in backscattered frequency is generated due to (1) the slow motion of the mover and (2) the low frequency needed to penetrate through the wall. The reported time-domain processing algorithms are based on the change detection (CD) paradigm, which is inherently similar to clutter cancellation. In the CD paradigm, the Synchronous Impulse Reconstructive (SIRE) radar remains stationary and generates a set of images for a region of interest (ROI). Each image in the set is formed every two-thirds of a second. The stationary objects in the building remain in the same location in each image; however, moving personnel will be at different locations. The moving personnel can be detected by subtracting adjacent images in the set, thereby eliminating the stationary objects and identifying the MT signature. Additional processing is utilized to enhance the MT signature, including a constant false alarm rate (CFAR) algorithm, morphological processing, k-Means clustering, and a tracking algorithm. CFAR and morphological processing are approaches used to eliminate imaging artifacts and potential false alarms due to target multi-bounce effects. The k-Means clustering algorithm is used to identify centroids for given input clusters, where the clusters are produced by the CFAR and morphological processing algorithms. Based upon input of the centroids, the tracker is used to establish a trajectory of the moving target (MT). Notwithstanding the above reported efforts, there exists a need for further refinement and improved accuracy of the moving target tracking system.","The present invention includes an enhanced change detection technique for detecting and\/or tracking moving targets inside buildings or behind walls, barriers, or the like. The present invention is adapted to detect signatures associated with moving targets, significantly attenuates imaging artifacts thereby reducing the number of false alarms, and has been successfully demonstrated detection capabilities of personnel walking inside wood and cinderblock buildings. The present invention comprises a change detection algorithm used in conjunction with a fully automated moving target indication (MTI) system. The MTI system can be used to detect and track hostile personnel, snipers or hostages inside, inter alia, wood and cinderblock buildings. The MTI system can be used to track personnel inside buildings in a range from 8 meters to 33 meters inside building structures.","A preferred embodiment of the present invention comprises a system capable of determining the presence of a moving target behind a wall or barrier based upon a time progression radar images of a region of interest, the system comprising at least one processor and at least one memory operatively connected; the at least one memory adapted to store a plurality of radar images of the region of interest that may contain a moving target signature taken at different points in time; the at least one processor operating to sequentially designate one of the plurality of radar images as a reference frame, subtract the absolute pixel values of the reference image from the absolute pixel values of a predetermined number of radar images to form difference images, eliminate the negative pixel values to form a set of \u201cpositive\u201d difference images, and, minimize the side lobes to form a combined difference image for each reference frame, whereby the system forms a series of combined difference images which contain the moving target signature.","Optionally, following the elimination of the negative pixel values; the system may sequentially average the resulting difference images for each reference frame prior to minimizing the side lobes.","The series of combined difference images formed by the preferred embodiment change detection technique may be further processed by utilizing constant false alarm reduction (CFAR), morphological processing, cluster prediction, clustering and tracking as described further in U.S. application Ser. No. 13\/008,549, hereby incorporated by reference.","Optionally, the processor may form the difference images by selecting a reference image and selecting a first image taken prior in time to the reference image and a second image taken after the reference image. First and second difference images may then be formed by subtracting the reference image (absolute pixel values) from each of the absolute pixel values of the first and second images to form first and second difference images, respectively.","Optionally, when the moving target is located between a front wall or barrier and a back wall or barrier, and when the front wall and back wall or barrier produce radar signatures on the images of the region of interest, such signatures are effectively subtracted out or eliminated from the difference images during the subtraction process.","A preferred method comprises providing a plurality of images of the region of interest that may contain a moving target signature taken at different points in time; selecting a reference image from the plurality of images; forming a predetermined number of difference images of the region of interest by subtracting the absolute value of the pixels of the reference image from the absolute values of pixels in a predetermined number of the plurality of images; eliminating the negative pixel values in the predetermined number of difference images; minimizing the side lobes to form a combined difference image for each reference frame, selecting another reference image from the plurality of images and performing the steps of forming a plurality of difference images, eliminating the negative pixel values, averaging the resulting predetermined number of difference images and minimizing the side lobes for each selected reference image to form a set of combined difference images which contain the moving target signature.","Optionally, following the elimination of the negative pixel values; the preferred method may include sequentially averaging the resulting difference images for each reference frame prior to minimizing the side lobes.","Optionally, the preferred method may include forming the difference images using images taken immediately before and after the difference images.","These and other aspects of the embodiments herein will be better appreciated and understood when considered in conjunction with the following description and the accompanying drawings. It should be understood, however, that the following descriptions, while indicating preferred embodiments and numerous specific details thereof, are given by way of illustration and not of limitation. Many changes and modifications may be made within the scope of the embodiments herein without departing from the spirit thereof, and the embodiments herein include all such modifications.","The embodiments herein and the various features and advantageous details thereof are explained more fully with reference to the non-limiting embodiments that are illustrated in the accompanying drawings and detailed in the following description. Descriptions of well-known components and processing techniques are omitted so as to not unnecessarily obscure the embodiments herein. The examples used herein are intended merely to facilitate an understanding of ways in which the embodiments herein may be practiced and to further enable those of skill in the art to practice the embodiments herein. Accordingly, the examples should not be construed as limiting the scope of the embodiments herein.","A preferred embodiment moving target indication (MTI) system is comprised of two main components. The first component detects potential moving targets by generating a time series of binary images that contain clusters. The second component of the MTI system tracks the centroid of each cluster thereby indicating any moving target in the building. Both components have been studied individually in past research reported in A. Martone, et al., \u201cAutomatic Through the Wall Detection of Moving Targets using Low-Frequency Ultra-Wideband Radar,\u201d Proceedings of the IEEE international radar conference, Washington, D.C., May 2010, A. Martone, et al., \u201cAn Analysis of Clustering Tools for Moving Target Indication; ARL-TN-5037; U.S. Army Research Laboratory: Adelphi, Md., November 2009, A. Martone, et al., \u201cThrough the wall detection of slow moving personnel,\u201d Proceedings of the SPIE conference on Radar Sensor Technology XIII, vol. 7308, Orlando, Fla., April 2009, and A. Martone, et al., \u201cMoving Target Indication for Transparent Urban Structures,\u201d ARL-TN-4809; U.S. Army Research Laboratory, Adelphi, Md., May 2009, all of which are hereby incorporated by reference. However, the individual components could not be combined since the second component (the tracking of the centroid of each cluster thereby indicating any moving target in the building) required manual input. Specifically, the number of clusters in the binary images (output of the first component) was previously unknown and required manual input into the second component of the system. A methodology for automating this stage of the procedure using a \u201cAdaptive Knee Point\u201d algorithm is described in detail in copending application Ser. No. 13\/008,549 entitled \u201cSystem and Method for Moving Target Detection,\u201d filed Jan. 18, 2011.","Referring now to , the Moving Target Indication system comprises the following processing routines: change detection, image formation via a specially adapted version of the back-projection algorithm, constant false alarm rate (CFAR) processing, morphological processing, cluster prediction algorithm, k-Means clustering, and tracking via the Kalman filter. Radar data may be first focused via the backprojection technique to form a sequence of focused images for the given region of interest (ROI); known as ROI images. In the preferred embodiment of , change detection is next applied to the ROI images, thereby creating a series of change detection images. However, generally change detection cannot automatically identify the MT signature located in the change detection image. Performance is improved by applying automatic target detection (ATD) algorithms. The ATD algorithms include the Constant False Alarm Rate (CFAR) algorithm and the morphological processing algorithm. CFAR is utilized to eliminate potential false alarms produced by slow moving targets. The CFAR algorithm performs a test of local contrast that is designed to achieve a constant false alarm rate. It generates a CFAR imagery of binary pixels for each input change detection image. This CFAR image contains clusters of points of interest (POIs) corresponding to either the MT signature or a false alarm. The CFAR algorithm does not eliminate all false alarms. One way to reduce the number of false alarms is to input the POIs into a morphological processing algorithm. Briefly, the morphological processing algorithm implements a dilation and erosion procedure. Dilation is used to grow the POI clusters and erosion is used to shrink the size of each POI cluster back to its original size. The morphological algorithm generates a morphological image for each input CFAR image. Before POIs are input into a tracking algorithm, reduction of their number is desired. The number of POIs is refined by first identifying the number of clusters in each morphological image and then implementing a cluster algorithm. One clustering routine used is the K-Means algorithm.","The tracker algorithm is intended to reduce the number of false alarms and segregate targets from both clutter and one another as they move through buildings. The centroids generated by the clustering algorithm serve as inputs to the tracker; so it is possible to have multiple tracker inputs even when a single moving target is present. The centroids may indicate the true position of a target or false alarms. The tracker estimates the correlation between each centroid and the existing tracks and then associates the existing tracks with the most correlated centroid. Non-assigned centroids are used to initiate new tracks and outdated tracks are deleted. A Kalman filter determines the present track position and predicts the next measurement.","Each processing routine is described in detail in copending application Ser. No. 13\/008,549, hereby incorporated by reference. The cluster prediction algorithm i) automatically determines the number of clusters present in the binary images, ii) reduces false alarms in the binary images, iii) combines the detection and tracking components of the MTI system thereby automating the entire system.","In past research, coherent change detection was implemented as described in copending application Ser. No. 13\/008,549. The change detection paradigm of a preferred embodiment may be utilized to process a sequence of focused images generated by a stationary radar for a region of interest (ROI) inside a building. The stationary objects in the ROI remain in the same position\/location in each image; however, moving personnel are at different locations. The moving personnel are detected by subtracting the focused images, thereby eliminating the stationary objects and identifying the moving target (MT) signature. The effectiveness of this time domain approach has been demonstrated for people walking inside wood and cinderblock buildings.","Coherent change detection is defined in the following paragraph. First, I(x, y) may be defined as the focused image for a region of interest, where \u201cx\u201d and \u201cy\u201d are down-range and cross-range indexes. Each pixel in I(x,y) consists of magnitude, \u03b1, and phase, \u03b8, information represented as \u03b1e. Next, a sequence of ROI images may be defined as:\n\n{(),(), . . . ()}\u2003\u2003(1)\n\nwhere each image is of the same ROI at a different time. Coherent change detection may then be defined as\n\n\u03b4()=|()\u2212()|\u2003\u2003(2)\n\nwhere k\u2260r, and I(x,y) is the reference image. Each pixel in \u03b4(x,y) has the magnitude \u221a{square root over (\u03b1+\u03b1\u22122\u03b1\u03b1cos(\u03b8\u2212\u03b8))}.\n","Non-coherent change detection may be defined as\n\n\u0394()=|()|\u2212|()\u2003\u2003(3)\n\nwhere each pixel in the non-coherent change detection image has the magnitude |\u03b1|\u2212|\u03b1|. The positive magnitudes in \u0394(x,y) are generated by |\u03b1|, which indicates a contribution from I(x,y). The negative magnitudes in \u0394(x,y) are generated by |\u03b1|, which indicates a contribution from I(x,y). The non-coherent change detection approach can therefore be used to determine the ROI image (i.e. I(x,y) or I(x,y)) that produces the MT signature, back-wall shadow, front-wall response, and sidelobe imaging artifacts generated in \u0394(x,y).\n","The processing of the preferred embodiment non-coherent change detection technique is illustrated in . This technique determines the MT signature for a given reference image, I(x,y), by first generating a set of M non-coherent change detection images:\n\n{\u0394(1,), . . . \u0394(), . . . \u0394()}\u2003\u2003(4)\n\nwhere\n\n\u0394()=|()|\u2212|()|\u2003\u2003(5) or\n\nand M\u2266N, 1\u2266\u03b3\u2266N for a given k, 1\u2266r\u2266N, \u03b3\u2260r. Note the following: Equation 4 considers M of N ROI images; I(x,y) is constant for all k; r is the index indicating the reference image; and the parameter \u03b3, is the index for an ROI image and is dependent upon k. The choices for \u03b3and M are application dependent and discussed further in the following.\n","Equations 4 and 5 indicate that the MT signature, associated with I(x, y), is positive in magnitude and constant in position. In addition, all pixels in image \u0394(k,x,y) associated with I(x,y) are negative in magnitude and can be eliminated since these pixels do not contribute to the MT signature of I(x,y). Therefore, the second step of the proposed change detection technique is to eliminate the negative magnitudes in each image of Equation 4:",{"@attributes":{"id":"p-0070","num":"0069"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["\u039b","r"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","x","y"],"mo":[",",","]}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"msub":{"mi":["\u0394","r"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","x","y"],"mo":[",",","]}}}},{"mrow":{"mrow":{"msub":{"mi":["\u0394","r"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","x","y"],"mo":[",",","]}}},"mo":"\u2265","mn":"0"}}]},{"mtd":[{"mn":"0"},{"mrow":{"mrow":{"msub":{"mi":["\u0394","r"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","x","y"],"mo":[",",","]}}},"mo":"<","mn":"0"}}]}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}}}}},"The processing of Equation 6 produces the following sequence of images:\n\n\u039b={\u039b(1,), . . . \u039b()}\u2003\u2003(7)\n","The third step of the proposed change detection technique is to average the images in \u039b to enhance the MT signature. It is possible that the MT signature is severely attenuated in one or more images in \u039b. The minimization process (step 4 in ) selects the most attenuated MT signature in \u039b. Therefore, the severely attenuated MT signature becomes the dominate feature for the minimization process and is characterized as the MT signature for the reference image. In order to prevent a severely attenuated MT signature from being the dominant feature, all MT signatures in \u039b are averaged as follows:",{"@attributes":{"id":"p-0073","num":"0072"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["\u0398","r"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","x","y"],"mo":[",",","]}}},"mo":"=","mfrac":{"mrow":{"mrow":[{"msub":{"mi":["\u039b","r"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"i","mo":"+","mn":"1"},"mo":[",",","],"mi":["x","y"]}}},{"msub":{"mi":["\u039b","r"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","x","y"],"mo":[",",","]}}}],"mo":"+"},"mn":"2"}}},{"mrow":{"mo":["(",")"],"mn":"8"}}]}}}},"br":[{},{}],"in-line-formulae":[{},{}],"sub":["r","r"],"i":["x,y","M\u2212","x,y"]},"Note that, as indicated in (8), the averages described herein are calculated using two samples. However, the number of samples used to calculate the averages can be increased depending on the application. The final step of the proposed technique is to eliminate sidelobe imaging artifacts using the following minimization procedure:",{"@attributes":{"id":"p-0075","num":"0074"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["\u03a8","r"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"munder":{"mi":["min","i"]},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":{"mi":["\u0398","r"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","x","y"],"mo":[",",","]}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"10"}}]}}}}},"The minimization procedure attenuates sidelobes associated with the MT signature, back-wall shadow, and front-wall response. The minimization procedure is used since the magnitude variations associated with the moving target are less than the magnitude variations associated with the sidelobes, as described in greater detail in L. Nguyen, \u201cSAR imaging technique for reduction of sidelobes and noise,\u201d in Proceedings of SPIE, vol. 7308, (2009) hereby incorporated by reference. The minimum pixel value of a sidelobe pixel should therefore be less than that of the MT signature due to this larger variation of pixel values associated with the sidelobes. For example, consider the scenario of a person walking cross-range to a radar sensor (from left to right). This scenario has been modeled using near-field scattering simulations (the details of the simulations are discussed in SIMULATION RESULTS). ROI images are generated using the back-projection procedure on the simulated data, as described further in J. McCorkle, \u201cFocusing of Synthetic Aperture Ultra Wideband Data,\u201d in Proceedings of the IEEE International Conference on Systems Engineering, Dayton, Ohio, August 1991, pp. 1-5 (hereby incorporated by reference). The preferred embodiment change detection technique processes the sequence of ROI images to generate the sequence of images in \u0398 (Equation 9). The minimization technique (Equation 10) processes the images in \u0398 and the results are compared,  & B, with the results of the maximization technique:",{"@attributes":{"id":"p-0077","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"munder":{"mi":["max","i"]},"mo":"\u2062","mrow":{"mrow":{"mo":["{","}"],"mrow":{"msub":{"mi":["\u0398","r"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","x","y"],"mo":[",",","]}}}},"mo":"."}}}},"br":{},"figref":["FIGS. 5A and 5B","FIGS. 5A and 5B","FIG. 5A","FIG. 5B"]},"\u03a8(x, y) constitutes the final change detection image generated by the proposed change detection technique for the reference image I(x,y). Thus, the MT signature in the reference image is identified and the trajectory of the moving target is determined by changing the reference image index, r. The final set of change detection images are defined as\n\n\u03a8={\u03a8(), . . . \u03a8()}\u2003\u2003(11)\n","The near-field scattering simulations are computed using XPATCH. XPATCH is a physical optics (PO) based code that uses a ray-tracing technique to calculate the scattering field from a target, as referenced in T. Dogaru, L. Nguyen, C. Le, \u201cComputer Models of the Human Body Signature for Sensing Through the Wall Radar Applications,\u201d ARL-TR-4290, U.S. Army Research Laboratory: Adelphi, Md., September (2007), hereby incorporated by reference. The simulated radar scattering data are computed for 24 moving target positions shown in , where \u201cX\u201d denotes range and \u201cY\u201d denotes cross-range. The building structure consists of four brick walls and a ground-plane. The walls have a thickness of 8\u2033 and are modeled as brick with a dielectric constant of 3.8-j0.24. The ground-plane has a dielectric constant of 6.8 (dry soil). The antenna array is located 8 m from the front wall. The antenna array consists of effectively 17 monostatic antennas distributed across a 2 m aperture. For a given antenna position 2404 frequency bins of in-phase and quadrature (I\/Q) information is collected. The 2404 frequency bins form the frequency domain representation of an I\/Q range profile, and the range profile is constructed via an inverse fast Fourier transform (IFFT). Note that a range profile is generated for each antenna position. The bandwidth of the collected frequency information is 4 GHz and ranges from 0.1-4.1 GHz.","The 17 I\/Q range profiles are collected for each moving target position. For a given moving target position, the 17 I\/Q range profiles constitute one frame of data and each frame of data is used to form an ROI image. The moving target positions are spaced 0.15 m apart. The total distance covered by the moving target is 3.6 m.","To form an ROI image, each I\/Q range profile is first windowed using a Hanning window of size 2404 (i.e. the size of the range profile). The window size is chosen to make the bandwidth of each range profile similar to that of radar measurements (discussed in ER). The windowed range profile is next converted to a time domain sequence using the IFFT. The time domain sequence is next processed by the back-projection algorithm (as described in, inter alfa, J. McCorkle, \u201cFocusing of Synthetic Aperture Ultra Wideband Data,\u201d in Proceedings of the IEEE International Conference on Systems Engineering, Dayton, Ohio, August 1991, pp. 1-5) to focus the raw data. Each ROI image is of size 8\u00d78 m and contains 400\u00d7400 pixels with a pixel spacing of 0.02\u00d70.02 m. 24 ROI images are generated (i.e. N=24).","The proposed moving target indication (MTI) non-coherent change detection (MNCD) technique is used to process the N=24 ROI images to produce \u03a8. M=8 non-coherent change detection images are generated where:\n\n{\u03b3, . . . \u03b34,3,2,1,1,2,3,4}\n\nfor r>4 and r\u2266N\u22124, where r is the index for the reference image. \u03b3is chosen to select the ROI images \u201cclosest\u201d to the reference image. The closest ROI images have sidelobe patterns similar to the sidelobe patterns in I(x,y). If the distance between the MT signatures of I(x,y) and I(x,y) is large, then the sidelobe patterns of the images are unaligned and will not cancel effectively. When r\u22664 and r>N\u22124, i.e. the boundary conditions, \u03b3is selected to create a set of ROI images that contains the closest MT signature to the MT signature in I(x,y). For example, if r=3, then {\u03b3, . . . \u03b3}={1, 2, 4, 5, 6, 7, 8, 9}.\n","Three pairs of images are shown in . Each pair consists of a change detection image generated by the MNCD technique, i.e. the MNCD image, and by the coherent change detection (CCD) technique (Equation 2), i.e. the CCD image. The images in  represent a subset of all the images that were generated and are shown to illustrate key difference between the MNCD and CCD techniques. Each image in  is normalized by dividing the magnitude of each pixel by the maximum magnitude of the image. As is shown in , the MT signature is clearly visible and identifiable in both the MNCD and CCD images.  illustrates a close-up of the MT signature in  and reveal that the MT signature generated using the MNCD technique is very similar to the MT signature generated using the CCD technique. If the MT signature generated by the MNCD technique was severely attenuated, than automatic target recognition and tracking results could be adversely affected.","The back-wall shadow, front-wall response, and sidelobe imaging artifacts in the MNCD images of , D and F are significantly attenuated compared to those artifacts in the CCD images (, C and E). To develop a more quantitative understanding of the attenuation, the average power of each artifact category (i.e. sidelobe, shadow, and front-wall) in the MNCD image is estimated and compared to the corresponding average power in the CCD image. The results are illustrated in . The \u201cred box\u201d window in each image indicates the area of pixels that are averaged (note that the window shown in each figure is not drawn to scale). A 24.8 dB attenuation is observed for the sidelobes in the MNCD image using a 1.1\u00d70.4 m (range x cross-range) window. A 21.3 dB attenuation is observed for the back-wall shadow in the MNCD image using a 0.3\u00d70.6 m window.","A 14 dB attenuation is observed for the front-wall response in the MNCD image using a 1.3\u00d70.08 m window. The results of this quantitative comparison indicate that the MNCD technique is significantly more effective in attenuating imaging artifacts compared to the CCD technique.","In addition to processing modeling data, the MNCD and CCD techniques are used to process measurement data collected by the U.S. Army Research Laboratory's (ARL) ground-based Synchronous Impulse Reconstruction (SIRE) radar. The SIRE radar is an impulse-based, UWB imaging radar with an effective bandwidth covering 500 MHz to 1.5 GHz, a frequency range appropriate for sensing through the wall (STTW) applications. As is illustrated in , the SIRE radar employs 2 transmit antennas and 16 receiver antennas mounted in a wooden structure and attached to the top of a Ford Expedition. The receive antennas are equally spaced across a linear 2 m long aperture. The two impulse transmitters are located at each end of the wooden structure and slightly above the receive array. The SIRE radar constructs a high-resolution (0.15 m) down-range profile through ARL-developed signal-processing techniques, as described in J. McCorkle, \u201cFocusing of Synthetic Aperture Ultra Wideband Data,\u201d in Proceedings of the IEEE International Conference on Systems Engineering, Dayton, Ohio, August 1991, pp. 1-5, hereby incorporated by reference.","For the experiments described in this section, the SIRE radar remains stationary and the downrange swath measured by the radar extends from approximately 8 to 30 m. The received measurements are effectively buffered in one downrange profile from each receive channel, and the time required to assemble these profiles represents one frame of data. After buffering the data from one frame, another set of downrange profiles are collected from each receive channel.","The down range profiles for each frame are directly processed (without windowing or filtering) using the back-projection algorithm to form a set N=34 ROI images. Each ROI image is of size 10\u00d710 m and contains 500\u00d7500 pixels with a pixel spacing of 0.02\u00d70.02 m. The ROI images are processed using the CCD and MNCD techniques with the same parameter set described in the above SIMULATION RESULTS.","Two operational scenarios are considered. The first scenario is of a person walking inside a wood building as depicted in  (left side). Two pairs of images are shown in . Each pair of images consists of a MNCD image and a CCD image. The images in  represent a subset of all the images that were generated and are shown to illustrate key difference between the MNCD and CCD techniques. Each image in  is normalized relative to the peak pixel value and has a dynamic range of 20 dB. As is shown in , the MT signature is clearly visible and identifiable in both the MNCD and CCD images. Closer examination of the MT signature, , reveals that the MT signature generated using the MNCD technique is slightly attenuated and remains identifiable. Note also that the MT signature in  (from measurement data) is more attenuated than the MT signature in  (from modeled data) indicating that the fidelity of measurement data is less than that of the model data (as expected).","The sidelobe, shadow, and front-wall artifacts in the MNCD images of  are significantly attenuated compared to those artifacts in the CCD images (). Similar to the analysis conducted for the modeling data, the average power of each artifact category in the MNCD image is estimated and compared to the corresponding average power in the CCD image. The results are illustrated in . The \u201cred box\u201d window in each image indicates the area of pixels that are averaged. A 16.3 dB attenuation is observed for the sidelobes in the MNCD image using a 1\u00d71 m window. A 7.4 dB power attenuation is observed for the back-wall shadow in the MNCD image using a 0.2\u00d71.2 m window. A 12.7 dB power attenuation is observed for the front-wall response in the MNCD image using a 0.4\u00d71 m window. The results of this comparison indicate that the MNCD technique is significantly more effective in attenuating imaging artifacts compared to the CCD technique.","The second operational scenario is of a person randomly walking inside a cinderblock building (, right side). The radar is position 38\u00b0 off the broadside position. The off-broadside angle was selected in an attempt to reduce imaging artifacts present in the change detection images due to large reflections from the wall. See, A. Martone, K. Ranney, R. Innocenti, \u201cAutomatic Through the Wall Detection of Moving Targets using Low-Frequency Ultra-Wideband Radar,\u201d in Proceedings of the IEEE International radar conference, Washington, D.C., (May 2010), hereby incorporated by reference. Two pairs of images are shown in . Each pair of images consists of a MNCD image and a CCD image. Each image in  is normalized relative to the peak pixel value and has a dynamic range of 20 dB. The observations illustrated in  (cinderblock building) are similar to those illustrated in  (modeled brick building) and  (wood building) and are summarized as: 1) the MT signature is clearly visible and identifiable in both the MNCD and CCD images; 2) the MT signature, , generated using the MNCD technique is more attenuated compared to the MT signature generated using the CCD technique, ; 3) the back-wall shadow, front-wall response, and sidelobe imaging artifacts in the MNCD images of  are significantly attenuated compared to those artifacts in the CCD images of . Power level differences for the artifacts are illustrated in . The window sizes used for averaging are as follows: 0.6\u00d71.4 m for sidelobe; 0.3\u00d71.4 m for shadow; 0.6\u00d71 m for front-wall.","Not all imaging artifacts generated using the MNCD technique are significantly attenuated compared to those generated by the CCD technique. For example, consider the cinderblock front-wall response in the CCD and MNCD images of , respectively. In general the imaging artifacts generated using the MNCD technique appear more attenuated then those generated by the CCD technique, however, this difference is insignificant. In another example, consider the CCD and MNCD images in . As is shown significant imaging artifacts are present in the MNCD image and not the CCD image. These imaging artifacts occur when the averaging process (Equation 8) does not properly enhance the MT signature. As discussed in CHANGE DETECTION TECHNIQUE (above), if the MT signature is severely attenuated then it becomes the dominate feature during the minimization process and is present in the MNCD image. The attenuated MT signature has power similar to imaging artifacts; hence the image in . The choice for M (i.e. M=8) and the number of averages (i.e. two averages) are chosen to prevent attenuated MT signatures and to minimize sidelobe artifacts for the majority of MNCD images. It is verified that the majority of change detection images generated by the MNCD technique contains less imaging artifacts than the set of images generated by the CCD technique.","The Moving target indication (MTI) non-coherent change detection (MNCD) technique is a novel and effective method for identifying the MT signature and eliminating imaging artifacts. The simulation and experimental results demonstrated the effectiveness of the proposed method. In rare cases, the anticipated enhancement of the MNCD image is not realized (see ). In these cases, imaging artifacts are retained when the averaging process (Equation 8) does not properly enhance the MT signature; the phenomenon is dependent on the number of averages taken and M. As a whole, however, the results indicated a significant attenuation of imaging artifacts observed in the MNCD image relative to those observed in the coherent change detection (CCD) image. The simulation results indicated a 24.8 dB attenuation of the sidelobes, a 21.3 dB attenuation of the shadow, and a 14 dB attenuation of the front-wall response in the MNCD images. The wood building experimental results indicated a 16.3 dB attenuation of the sidelobes, a 7.4 dB attenuation of the shadow, and a 12.7 dB attenuation of the front-wall response in the MNCD images. The cinderblock building experimental results indicated a 10.6 dB attenuation of the sidelobes, a 15.3 dB attenuation of the shadow, and a 18.7 dB attenuation of the front-wall response in the MNCD images.","Interpretation of the resulting MT signature is still challenging after change detection. For example, change detection cannot automatically identify the MT signature located in the difference image and the MT signature can only be identified through visual inspection of a sequence of difference images. Therefore, it is not possible to implement additional signal processing techniques like classification using a single difference image. Another challenge with change detection is that sidelobe artifacts are produced in the difference image, which confuse the true moving target location.","A way to improve user interpretation of the resulting difference image is to apply the CFAR algorithm. CFAR is a well-established approach to eliminating potential false alarms. Typically, the algorithm performs a test of local contrast that is designed to achieve a constant false alarm rate as reported in Gandhi, P. P. & Kassam, S. A., \u201cAnalysis of CFAR Processors in Homogeneous Background,\u201d July 1988, 24 (4), 427-445, hereby incorporated by reference.","A further description of the CFAR process, as well as the outputting of morphological output images, is presented in application Ser. No. 13\/008,549 entitled \u201cSystem and Method for Moving Target Detection,\u201d filed Jan. 18, 2011, hereby incorporated by reference.","The tracker algorithm is intended to reduce the number of false alarms and segregate targets from both clutter and one another as they move inside a building. The centroids generated by the clustering algorithm serve as inputs to the tracker; so it is possible to have multiple tracker inputs even when a single moving target is present. These centroids may indicate the true position of a moving target or false alarms. The tracker estimates the correlation between each centroid and the existing tracks and then associates the existing tracks with the most highly correlated (i.e., most reasonable) centroid. Non-assigned centroids are used to initiate new tracks and outdated tracks are deleted. A Kalman filter determines the present track position and predicts the next measurement.","The k-Means algorithm is referenced Wilpon, J., et al., \u201cA Modified K-means Clustering Algorithm for Use in Isolated Work Recognition,\u201d IEEE Transactions on Acoustics, Speech and Signal Processing vol. 33, no. 3, July 1985, 587-594, hereby incorporated by reference. Note that the k-Means algorithm requires the number of clusters present in the morphological images and is provided by the cluster prediction algorithm described in the section entitled Cluster Prediction Algorithm. A cluster is defined as a group of one or more POIs that are close to one another in the image. The total number of clusters present in the morphological image referred to as T. For example, consider the POIs in , a morphological image where each POI corresponds to a blue diamond. When these images are input into a clustering algorithm, two clusters are identified; the clusters and corresponding centroids are shown in . The POIs connected to each other form a cluster as illustrated in . As is shown, T=2 clusters are present in the morphological image. Once the number of clusters in the image is known, the k-Means algorithm is used to indicate the centroid of each cluster.","The k-Means algorithm identifies the centroids of the POIs by an iterative procedure. This iterative procedure minimizes the square-error between centroid estimates and their corresponding POIs. It should be noted that the clusters identified by the clustering algorithm are not unique and it is possible that the centroid locations differ for different iterations of the clustering algorithm. A block diagram of the k-Means algorithm is shown in .","A further description of the clustering analysis, cluster prediction algorithm, and the K-Means Algorithm is set forth in application Ser. No. 13\/008,549 entitled \u201cSystem and Method for Moving Target Detection,\u201d filed Jan. 18, 2011, hereby incorporated by reference.","The moving target indication system of the present invention can be used for commercial applications including (1) law enforcement, (2) search and rescue, (3) building surveillance, (4) vehicle tracking on highways or in remote locations.","As used herein, the terminology \u201ctarget\u201d means a person or persons, or portion thereof, animal or animals, thing, object, or a combination thereof.","As used herein \u201ctime progression radar images\u201d means taking images over time as time progresses; not necessarily at fixed intervals of time.","As used herein the terminology \u201cpoint of interest\u201d or \u201cpoints of interest\u201d refer to an signature or area in the image which appears to be a target but may or may not be a target; i.e., potentially the point of interest may be a target; subject to further processing or testing.","As used herein, the \u201cenergy\u201d corresponds to the intensity of the image pixels.","As used herein the terminology \u201cprocessor\u201d includes computer, controller, CPU, microprocessor; multiprocessor, minicomputer, main frame, personal computer, PC, coprocessor, and combinations thereof or any machine similar to a computer or processor which is capable of processing algorithms.","As used herein the terminology the terminology \u201cprocess\u201d means: an algorithm, software, subroutine, computer program, or methodology.","As used herein the terminology \u201ctarget signature\u201d means the characteristic pattern of a target displayed by detection and identification equipment.","As used herein, the terminology \u201calgorithm\u201d means: sequence of steps using computer software, process, software, subroutine, computer program, or methodology.","As used herein the terminology \u201csuccession\u201d means the act or process of following in order or sequence, but is not limited to sequential order. As used herein the terminology \u201csuccession\u201d refers to a later taken image being compared with an earlier taken image.","The foregoing description of the specific embodiments are intended to reveal the general nature of the embodiments herein that others can, by applying current knowledge, readily modify and\/or adapt for various applications such specific embodiments without departing from the generic concept, and, therefore, such adaptations and modifications should and are intended to be comprehended within the meaning and range of equivalents of the disclosed embodiments. It is to be understood that the phraseology or terminology employed herein is for the purpose of description and not of limitation. Therefore, while the embodiments herein have been described in terms of preferred embodiments, those skilled in the art will recognize that the embodiments herein can be practiced with modification within the spirit and scope of the appended claims."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The patent or application file contains at least one drawing executed in color. Copies of this patent or patent application publication with color drawing(s) will be provided by the Office upon request and payment of the necessary fee.","In , B, A-F, , A-D, A, B, A-D, A, B, A, B, A and B the colors represent a decibel range which ranges from red to blue, red being the strongest signal and blue being the weakest.","The embodiments herein will be better understood from the following detailed description with reference to the drawings, in which:",{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 5B","FIGS. 5A and 5B"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIGS. 7A-7F"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 7A"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 7B"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 7C"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 7D"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 7E"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 7F"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 8","FIGS. 7A and 7B"]},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIGS. 10A-D"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 10A"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 10B"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 10C"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 10D"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 11A","FIG. 10A"]},{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 11B","FIG. 10B"]},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIGS. 12A through 12D"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 12A"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 12B"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 12C"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 12D"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 13A","FIG. 12A"]},{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 13B","FIG. 12B"]},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIGS. 14A-B"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 14A"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 14B"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIGS. 15A and 15B"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 15A"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 15B"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 18A"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIG. 18B","FIG. 18A"]},{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 19"}]},"DETDESC":[{},{}]}
