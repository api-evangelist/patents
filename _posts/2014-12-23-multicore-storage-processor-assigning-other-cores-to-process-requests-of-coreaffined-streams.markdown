---
title: Multi-core storage processor assigning other cores to process requests of core-affined streams
abstract: A multi-core processor of a network attached storage system processes requests from host computers for services of a file system service. Each core maintains endpoints of respective connection-layer connections to the hosts to affine respective streams of network traffic with the core, and dynamically and preferentially assigns execution threads of the core to process file system service requests of the streams affined with the core. Each core also co-operates with the other cores to dynamically and non-preferentially (a) assign execution threads of the core to process file system service requests of the streams affined with the other cores, and (b) assign execution threads of the other cores to process file system service requests of the streams affined with the core, promoting efficient use of the cores for the processing workload of the file system service.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09485310&OS=09485310&RS=09485310
owner: EMC IP Holding Company LLC
number: 09485310
owner_city: Hopkinton
owner_country: US
publication_date: 20141223
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The present invention is related to the field of data storage systems providing file system services to host computers via a network, referred to herein as \u201cnetwork attached storage\u201d systems.","A network attached storage (NAS) system may employ one or more storage processors that execute a file system service application and other programs to form functional modules that collectively provide a file system service to host computers via a network. Examples of network-provided file system services include Network File System (NFS) and Common Internet File System (CIFS). In operation, the NAS system forms persistent network connections with the hosts over which the hosts request file system operations and the NAS system returns corresponding responses. Typical file system operations include opening, closing, reading from and writing to a file contained in a file system on the NAS, which is treated by the host as an extension of its file system.","Like other processor-based systems, NAS systems may employ so-called \u201cmulti-core\u201d processors that include multiple independent instruction execution units sharing the processing load for a single instance of an application program that is executed to provide file system services. Typically, the cores are realized as separate sections of a single monolithic integrated circuit serving as a processing unit having connections to a memory, I\/O circuitry, etc. In such systems, it is necessary to divide the processing load intelligently among the cores to obtain efficient use of hardware resources and desirably high performance.","In a NAS system specifically, it can be desirable to persistently associate, or affine, the network traffic of different hosts with respective different cores, and as a general matter to process the file system service requests of the hosts within the respective affined cores. Employing such core affinity can promote high performance and efficiency by minimizing the need for host-specific data to be transferred among the cores, a situation that can lead to cache thrashing and reduce performance. However, there can be situations during operation in which the network traffic directed to a given core exceeds the processing capability of that core, while at the same time there may be other cores experiencing relatively lighter loading. This represents inefficiency by failure to fully use all available hardware resources, and can also adversely affect performance. Maintaining strict affinity between the hosts and cores can reinforce this inefficiency. If at a given time certain hosts are generating significant file system demand while other hosts are not, the cores handling the connections to those other hosts may be relatively idle, and the strict affinity would prevent any redistributing of the workload for better overall utilization of the cores.","Methods and apparatus are disclosed that can improve the efficiency and performance of multi-core processors in the context of a NAS system, in particular efficiency and performance based on the utilization of the cores. A NAS system can use the disclosed techniques to realize a desired balance between the benefits of host-core affinity and the benefits of fuller utilization of the cores.","A method is disclosed of operating a multi-core processor of a network attached storage system to process requests from host computers for services of a file system service. The method includes, at each core of a set of cores of the multi-core processor, (1) maintaining endpoints of respective connection-layer connections to the hosts to affine respective streams of network traffic with the core, and (2) dynamically and preferentially assigning execution threads of the core to process file system service requests of the streams affined with the core. This much of the method promotes the efficiency and performance benefits from host-core affinity.","The method further includes (3) co-operating with the other cores to dynamically and non-preferentially (a) assign execution threads of the core to process file system service requests of the streams affined with the other cores, and (b) assign execution threads of the other cores to process file system service requests of the streams affined with the core. This operation is performed only under appropriate conditions, such as when all local threads are busy and another core has at least one idle thread and no overriding local requests, so that the idle thread of the other core can be used to process the request. While this operation effectively reduces affinity and the benefits thereof, it enables overall better utilization of processing resources and can provide offsetting efficiency and performance benefits.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1","b":["10","12","14","16","14","12","12","12","14","16","20","12","14","22","12","14","16"]},"The NAS  includes a network interface , storage processor , data storage device (DSD) interface , and data storage devices . The data storage devices  provide nonvolatile read\/write data storage, and may be realized as magnetic disks, Flash memory, etc. The network interface  provides the physical-layer connection to the network , e.g., Ethernet connectivity. The DSD interface  provides connection to the data storage devices  via a storage-oriented interface such as Small Computer System Interface (SCSI) and FibreChannel. The storage processor  is a high-performance processing complex that provides extensive functionality in software-implemented form, including a high-level protocol endpoint (e.g., NFS, CIFS) for the FS protocol, functionality of the file system service, and use of the data storage devices  to provide the underlying data storage for the file system service.",{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 2","b":["26","40","42","44","46","48"]},"The memory  is the directly addressable system memory of the processing unit . It is commonly realized using high speed dynamic random access memory (DRAM) connected to the processing unit  by a high speed data bus (not shown). The network I\/O circuitry  connects the physical-layer network interface  () to the memory  for data transfer therebetween, and similarly the DSD I\/O  connects the DSD interface  to the memory  and\/or storage cache .","The processing unit  is of a type known as \u201cmulti-core\u201d, having multiple independent execution units called \u201ccores\u201d . The cores  have shared access to the memory , typically via a large shared cache  and smaller respective per-core caches . In operation, the cores  can simultaneously execute respective streams of instructions and access respective data from the memory , under the control of hardware and software mechanisms that manage the use of the cores  for a processing workload, such as that of the file system service as mentioned above and described more below.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 3","FIG. 1"],"b":["26","50","12","60","16","40","60","26","60","50","50","1","60","12","50","2","60","60","60","44","50"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 4","FIG. 3"],"b":["70","50","72","74","72","76","78","80","74","82","82","1","82","2","82","3","12","60"]},"The stream network stacks  provide paths for the file system service  to communicate with the hosts  via network  using a \u201cstream\u201d paradigm that is distinct from other types of network connections, notably from so-called \u201csocket\u201d connections. From the perspective of the file system service  including the threads , each stream network stack  is a \u201cstream\u201d object that can be written to and read from by the threads  using a stream application programming interface (API). The stream API includes routines such as Open_Stream, Close_Stream, Read_Stream, and Write_Stream that operate upon a head object or \u201chead\u201d  serving as the point of communication between the respective stream network stack  and the threads . In the description below, the term \u201cstream\u201d refers to a flow of data items through a stream network stack , which corresponds to a flow of file system requests  and responses . Thus successive requests  are received from the network  and processed upward in a stream network stack , resulting in the information content of the requests  being conveyed to threads  in a series of Read_Stream calls. Similarly, the threads  provide response information to a stream network stack  using a series of Write_Stream calls, and the response information is processed downward in the stream network stack  to result in a series of responses  sent across network  to requesting hosts , i.e., each response  is sent to the host  from which the corresponding request  was received.","Additional layers of a stream network stack  include a streamhead module  and an application module . Service functions may be defined if a module deals with flow control. The TCP-oriented stream network stacks (), () include a remote procedure call\u2014TCP (RPC-TCP) module  and a TCP module , while the UDP-oriented stream network stack () includes a UDP module . In each of the modules -, stream traffic is divided into separate read and write portions, processed separately and independently at each layer. In the illustrated arrangement, all three stream network stacks  interface to a single IP module  that interfaces to the network  and to which the read\/write separation of stream processing also extends as shown.","For ease of description, the data read from a head  that conveys the contents of a request  to a thread  is referred to as a \u201crequest\u201d or a \u201cfile system service request\u201d, and the data written to a head  that conveys the contents of a response  from a thread  is referred to as a \u201cresponse\u201d or \u201cfile system service response\u201d. The application module  and RPC-TCP module  translate between these internal representations of requests and responses and the corresponding protocol-compliant, or \u201cwell formed\u201d requests  and responses  carried by network . In particular, the application module  is responsible for parsing the contents of remote procedure calls in received network traffic to identify well-formed requests  (e.g., NFS or CIFS requests), and for providing these well-formed requests to the streamhead module  where they are provided to threads  in response to Read_Stream calls. The application module  is also responsible for generating RPC callbacks from responses written into the stream by Write_Stream calls, and providing the callbacks to the RPC-TCP module  for forwarding to a host  across the network .","At a high level, the organization of  effects multi-threading as well as core-affined stream processing that promote computing efficiency. Each core  includes a number of threads  that can process file system service requests  as received from the stream network stacks . In practice the number of threads  is fixed over at least short periods of operation, e.g., days to months, although the number might be adjustable in some embodiments to enable a system administrator to tune performance. Each core  also has a respective set of stream network stacks  as described above, and a respective collector  that manages the connections of the threads  to the streams of the stream network stacks  as described more below. Maintaining stream affinity helps maintain stream-specific execution context within a given core . Over time as the file system operations of a given stream are performed, respective file system metadata migrates to the cores  with which the respective streams are affined, specifically to the respective per-core caches  of the cores . Processing efficiency is obtained by reducing average memory latency due to increased cache hit ratios.","There can be situations during operation in which the network traffic directed to a given core  exceeds the processing capability of that core , while at the same time there may be other cores  experiencing relatively lighter loading. This represents a certain inefficiency, namely failure to fully use all available hardware resources (i.e., cores ). It will be appreciated that maintaining strict stream affinity could reinforce this inefficiency. If at a given time certain hosts  are generating significant file system demand while other hosts  are not, the cores  handling the connections  to those other hosts  may be relatively idle, and strict affinity of the streams would prevent any redistributing of the workload for better overall utilization of the cores .","Thus as described more below, another function of the collector  is to monitor both the availability of local threads  (i.e., of the same core ) for processing requests , as well as the level of demand for processing from the local stream network stacks  (i.e., of the same core ), and provide for selectively routing file system requests and responses among the cores  to make better overall utilization of them. Specifically, the collector  of each core  provides for a local thread  to be used to process a request from a stream network stack  of another core , and vice-versa\u2014for a thread  of another core  to be used to process a request from a local stream network stack  of this core . For this functionality the other core  may be referred to as a \u201cremote\u201d core  and its requests and threads  as \u201cremote\u201d requests and threads respectively. While this cross-core activity effectively reduces stream affinity and the context-related efficiency that comes with it, it does so in furtherance of another efficiency in the form of full use of hardware resources. Those skilled in the art will appreciate based on the present description that the disclosed techniques can be implemented to achieve a desired balance between these two forms of efficiency to best achieve overall system goals.",{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 5","FIG. 4"],"b":["80","100","102","100","78","102","100","80","50","102","86","102","82","78"]},"Referring to both  and , once a well-formed file system service request reaches the stream head  of a respective stream network stack , the streamhead module  calls a function of the collector . Assuming there is at least one thread  available to process the request, an entry is added to the queue , and the collector  selects a thread  for handling the request and activates or \u201cawakens\u201d the selected thread. The selected thread  obtains the next entry from the queue , which identifies the head  that the thread  is to read from to obtain a file system request for processing. The thread  issues a Read_Stream to the identified head  to obtain the file system service request, then performs the file system processing for the request and returns a corresponding response by issuing a Write_Stream to the same head . The response travels down the stream network stack  and becomes a protocol-level response  to the requesting host . After issuing the Write_Stream, the thread  becomes available to the collector  to process another file system service request from the queue .","Thus the collector  manages the signaling of new requests to the file system service  on behalf of all the stream network stacks , making the signaling simpler over alternatives in which the threads  poll or otherwise engage in signaling with the several local stream network stacks .","The above assumes immediate availability of a thread  to process a new file system request in the stream from a given stream network stack . In the event that all threads  of the core  are already busy, then under some circumstances (described more below) an entry for the new file system service request is placed on the queue  to await availability of a thread . Additional entries for subsequent file system service requests might also be placed on the queue . Once a thread  becomes available, the collector  assigns the thread  to process a next request as identified by the next entry on the queue , i.e., the top or head of the queue. Processing then proceeds as described above for the immediate availability situation.","Regarding the above-described local processing (in a core ) of streams affined to that core , i.e., streams of the stream network stacks  of the core , the following will be appreciated:\n\n","Thus the collectors  of the respective cores  have additional functionality enabling a thread  of one core  to process requests of streams affined to another core . This operation can help address both issues 1 and 2 above, i.e., it can improve efficiency and performance over an alternative in which streams can be processed only locally. This additional functionality of each collector  includes both the following:\n\n","A collector  monitors for availability of the local threads  in the course of assigning these threads  for processing requests and then being informed when the processing is completed and a response has been returned to the head  from which the request was obtained. When at least one local thread  is idle, it can be assigned. The collector  preferentially assigns the thread  to process requests from a local stream network stack , if there are any. If no local requests are waiting, the collector  signals to the other collectors  its ability to receive a request from one of them for processing by a local thread . Another collector  can use this indication to direct a request to this collector  if necessary, i.e., if that other collector  has no local threads  available. This operation of directing a request to another core is non-preferential, i.e., it is done only if a request cannot be processed locally. Local processing is preferred for the reasons discussed above, i.e., to maintain context and relatively high hit ratio of the local cache  rather than causing data to migrate to the cache  of another core  along with the request processing.","In one embodiment, a collector  signals its ability to accept a request from another core  when there are no new local requests in the local queue  and there is at least one local thread  that is idle. In this case the signal might have a binary nature, i.e., the signal has two distinct states, one of which indicates ability to accept a request and the other indicating inability to accept a request. In alternative embodiments, both the conditions and the signaling may be different, and in particular may be non-binary. While this may be somewhat more complicated to implement, it may provide greater efficiency and\/or performance. As an example, a collector  might signal the number of idle threads  it currently has, and another collector  can implement a selection from among multiple candidate destinations for a request based on the respective numbers. Thus a collector  having multiple idle threads  may be preferred over a collector  having only one idle thread . Similarly, a collector  might have a non-binary condition for routing a request to another core. There could be levels of urgency for such routing, based for example on the number of entries in the local queue  (more entries implies greater urgency), and a collector  could employ a threshold, which could be dynamically adjustable, to trigger the routing of requests to another core .",{"@attributes":{"id":"p-0037","num":"0040"},"figref":"FIG. 6","b":["50","110","50","60","12","50","82","88","90","92","112","50","78","50","50","82","114","50","50","78","50","78","50","112","114","80"]},"While various embodiments of the invention have been particularly shown and described, it will be understood by those skilled in the art that various changes in form and details may be made therein without departing from the spirit and scope of the invention as defined by the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing and other objects, features and advantages will be apparent from the following description of particular embodiments of the invention, as illustrated in the accompanying drawings in which like reference characters refer to the same parts throughout the different views.",{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
