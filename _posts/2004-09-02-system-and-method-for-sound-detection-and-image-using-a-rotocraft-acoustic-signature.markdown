---
title: System and method for sound detection and image using a rotocraft acoustic signature
abstract: One embodiment of the system is implemented as an aircraft comprising a rotor. For example, the aircraft may be a helicopter. This embodiment also comprises an acoustic source, wherein this acoustic source comprises an acoustic signature of the aircraft. This particular embodiment also comprises an acoustic collection device affixed to the aircraft. The acoustic collection device preferably comprises an array of microphones. Finally, this embodiment also has a data processing device, such as a computer, for collecting the data detected by the microphones and processing this data. In operation, the aircraft is flown for a distance along a path while the aircraft emits acoustic energy. Then, the microphones detect the acoustic energy that is reflected off the terrain. Optionally, the detected energy may be stored as data and processed, so that noise may be reduced and a terrain image may be formed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07149147&OS=07149147&RS=07149147
owner: The United States of America as represented by the Secretary of the Army
number: 07149147
owner_city: Washington
owner_country: US
publication_date: 20040902
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["GOVERNMENT INTEREST","BACKGROUND","SUMMARY","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["The invention described herein may be manufactured, used, and licensed by or for the United States Government.","1. Technical Field","The present invention is generally related to terrestrial imaging and, more particularly, is related to a method and apparatus for imaging terrain via synthetic aperture sound detection and imaging from the acoustic signature of a rotorcraft, such as, for example, a helicopter.","2. Description of the Related Art","Various applications, industries, endeavors, and studies require the ability of a person or device to accurately map the earth's terrain. In some specific applications of terrain mapping technology it is necessary not only to map terrain, but also to use terrain mapping technology to detect specific terrain features, or to detect certain objects on the terrain. For example, a military may wish to find and destroy military targets such as tanks and mobile missile launchers that can be hidden under foliage. The ability to accurately locate and image such objects would greatly assist this goal.","Traditionally, terrain mapping has been accomplished by using RADAR imaging. For example, in military target imaging applications, a standard approach for imaging targets under foliage is to use an ultra wide band radar. The concept of RADAR imaging is usually considered relatively simple: project microwave radiation at the terrain to be imaged and detect the reflected energy with an antenna. It is often it is desirable to maximize the resolution of standard RADAR imaging. One factor that can limit the resolution of a given RADAR system is the size of the antenna. Therefore, one way to achieve increased resolution is to increase the size of the antenna. Because of various constraints, it is not be practical to increase the size of an antenna beyond some finite point.","Scientists developed a technique called Synthetic Aperture RADAR (\u201cSAR\u201d) to assist in resolving the limitation of inadequate antenna size. The idea behind SAR is to mount an antenna on a structure and fly the antenna along a path. As the flying structure, such as an aircraft, travels along its path, it emits a wide beam of microwave radiation. The antenna on the aircraft collects the energy reflected. Then, the various data sets are combined to form an image with higher crossrange resolution than with a real-beam system. In essence, the size of the antenna has been increased \u201csynthetically.\u201d","One problem with using SAR for terrain imaging is the high cost of radar systems. For this reason, there is typically a limited number of aircraft equipped for terrain imaging. It would be desirable to have a lower cost alternative to using SAR for terrain imaging. This would permit a greater number of aircraft to be equipped for terrain imaging.","In addition to RADAR, there are other technologies that utilize acoustic waves to gain information about the location or position of objects or structures. As is known, SONAR is a technology widely used for underwater imaging. SONAR uses the propagation of sound waves through a water medium to detect the location of objects and to image those objects. Specifically, a source of sound waves emits acoustic waves into the water. Then, a receiver, typically on the same object as the source, detects the returning acoustic energy in order to map the underwater terrain, or locate an object.","Similar to SONAR, another known type of technology used for a rudimentary type of imaging is Sound Detection and Ranging (\u201cSODAR\u201d). SODAR is similar to SONAR in that it uses acoustical energy. However, SODAR uses acoustic waves transmitted through air. SODAR has been used in the past to measure turbulence or other wind profiles in the earth's atmosphere by observing the acoustic energy reflection due to scattering by atmospheric turbulence. SODAR has not been used for any type of terrain mapping. Traditionally, SODAR has only been used to image weather patterns, wind, rain, and the like.","A heretofore unaddressed need exists in the industry to address the aforementioned deficiencies and inadequacies.","Embodiments of the present invention provide a system and method for imaging terrain by using synthetic aperture sound detection and imaging techniques with a reflected acoustic signature of a rotorcraft.","Briefly described, in architecture, one embodiment of the system, among others, can be implemented as a system for generating a terrain image map. This one embodiment comprises an aircraft with a rotor, such as, for example, a helicopter. This embodiment also comprises an acoustic source, wherein this acoustic source comprises an acoustic signature of the aircraft. This particular embodiment also comprises an acoustic collection device affixed to the aircraft, and a data processing device for processing data collected by the acoustic collection device. The acoustic collection device may comprise, for example, an array of microphones affixed to a lower portion of the aircraft.","Embodiments of the present invention can also be viewed as providing methods for imaging a terrain with a rotorcraft through synthetic aperture sound detection and ranging techniques. In this regard, one embodiment of such a method, among others, can be broadly summarized by the following steps: (i) providing a rotorcraft; (ii) affixing an acoustic detection mechanism to the rotorcraft; (iii) flying the rotorcraft for a distance along a path, where the rotorcraft emits an acoustic energy; and (iv) detecting the acoustic energy that is reflected off the terrain with the acoustic detection mechanism.","Other systems, methods, features, and advantages of the present invention will be or become apparent to one with skill in the art upon examination of the following drawings and detailed description. It is intended that all such additional systems, methods, features, and advantages be included within this description, be within the scope of the present invention, and be protected by the accompanying claims.","The present disclosure is directed to a method and apparatus for generating terrain and object imagery. As a conceptual overview, one possible embodiment of the present disclosure involves generating terrain imagery by flying a helicopter with an array of microphones mounted below a body of the helicopter over a terrain having physical features or objects to be imaged. The microphones detect acoustical energy reflected by the terrain and process this information into an image of the terrain, or objects on the terrain.","As will be discussed in greater detail below, specific embodiments of the present disclosure may involve other devices and\/or methods for accomplishing an imaging task, or collecting data for the imaging task.",{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 1","FIG. 1"],"b":["10","10","11","12","11","11","13","15","13","16"]},"In addition to the main cabin , the helicopter  of the embodiment  also preferably comprises a main rotor  attached to the body  via a main rotor hub . As is known, the main rotor  of the helicopter  generally comprises a number of rotor blades (not individually depicted in ). These rotor blades can be thought of a individual, three-dimensional \u201cwings\u201d that rotate around the rotor hub  at a selected speed and pitch.","Attached to a rear portion of the main cabin  is a tail boom  with a vertical tail structure . Attached to the vertical tail structure  is a tail rotor  attached via a tail rotor hub . As with the main rotor , the tail rotor  typically comprises a number of tail rotor blades , . As is common, the tail boom  typically houses a mechanical linkage (not depicted) and control structures (not depicted) necessary to connect the tail rotor  to the helicopter engine  in order to drive the tail rotor .","The helicopter  of the first embodiment  also comprises standard landing skids  with the platform  mounted thereto by a hooking mechanism . Of course, landing skids  are not required by the present disclosure. For example, some helicopters are not equipped with landing skids and have, for example, wheels or pontoons. This does not change the present disclosure. The platform, for example, could be mounted directly to the body  of the helicopter  or to another landing structure.","In this embodiment , hooking mechanism simply comprises metal straps with hooks to attach the platform  to the landing skids . Of course, other attachment devices could be used to secure the platform  to the helicopter body . For example, the platform  could be mounted directly to the helicopter . In another example, the platform could be designed to retract into the body  of the helicopter . As another example, the platform  could be formed as an integral part of the landing skid . Certainly, many other possible attachment mechanisms would be apparent to one of ordinary skill in the art and are included in the present disclosure.","As is known, the helicopter  depicted in  is generally the shape and construction of a UH-1 (\u201cHuey\u201d) helicopter manufactured for the U.S. Army by the Bell Helicopter Corporation. This aircraft has been chosen for the present embodiment because of the relative ubiquity of the craft in the U.S. Army's helicopter fleet. However, another type of helicopter may be just as easily used with the present disclosure.","In fact, in a broader sense, any rotorcraft generally could be used. For example, the craft chosen to be used with the present disclosure could just as easily have multiple main rotors (such as the Boeing CH-46 \u201cSea Knight\u201d or CH-47 \u201cChinook\u201d helicopters), different numbers of main rotor blades (the \u201cHuey\u201d has two, the Aerospatiale HH-65 \u201cDolphin,\u201d for example, has 4, the Boeing RAH-66 \u201cComanche,\u201d for further example, has 5), a tilt-rotor (such as the V-22 \u201cOsprey\u201d and others), no tail rotor (such as the MD 520N \u201cNOTAR\u201d and others), or many other possible variations.","The receiver array platform  can be of any number of configurations. The basic goal in the depicted embodiment  is to provide a relatively sturdy platform  for a receiver array (not depicted in ).  is a drawing from an underside  of the platform , depicting an array of receivers . As shown in , the receiver array  preferably comprises a number of microphones ","In the present embodiment , the microphones of the array  are standard acoustical noise receiving microphones with a large dynamic range. Typical a\/d samples rates for the microphones of the preferred embodiment  are 1\u20132 KHz with 24-bits of resolution. The sample rate is preferably at least two times larger than the highest significant frequency signal being emitted by the source of sound. Microphones with large dynamic range and high fidelity are provided by Bruel & Kjaer (B&K). B&K model 4166, for example, provides a dynamic range up to 157 dB with some nonlinear distortion after 146 dB. This may be beneficial in some instances because even with shielding, the source may saturate linear microphones and the signals to be detected will be lost.","The array of microphones are mounted on the underside  of the platform  such that the microphones are carried below the main cabin  of the helicopter , and pointed at a terrain  to be imaged.","The platform  preferably comprises a smooth planar member that will preferably not create additional air turbulences over the microphones. Each microphone is preferably embedded in a flow noise reduction windscreen (not depicted) to minimize wind noise. The present embodiment , for example, preferably uses windscreens developed by Scientific Applications & Research Associates, Inc., which have shown acceptable wind noise reduction at moderate speed. The platform  is preferably constructed from a rigid material so that the microphones do not move relatively to each other. The platform  is preferably separated from the body  of the helicopter  with a vibration-damping material (not depicted)\u2014although the particular preferred B&K microphones mentioned above already have a built-in anti-vibration mechanism. Generally, the platform  is designed in a rectangular shape, as viewed from below (). Of course, the platform  could be any number of different shapes. The shape of the platform , may, for example, be dictated by the number or placement of the microphones , or the particular body style of the helicopter . One with ordinary skill in the art will readily be able to adapt the shape of the platform  as desired.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 2","FIG. 2"],"b":["29","28","29","29","17","22"],"i":["a\u2013f ","a\u2013f ","a\u2013f "]},"Preferably, the helicopter  of the present embodiment  further comprises a data processing mechanism , such as a computer or other processor, in the main cabin  of the helicopter . The processor  is preferably used to fetch the received signals from analog-to-digital converters (not depicted) sampling data collected by the microphone array , store this information as data, and in some circumstances process the data to generate a real-time image of the terrain  over which the helicopter  is flying. The processing system  is also designed to receive other data from the helicopter , and potentially use this data in the processing and\/or imaging phases. The processing of data collected by the processor , or some other computing device, will be described in more detail below.","Preferably, however, the computer  is simply used to receive data from the array of microphones  and store the data (preferably not in memory). Then, once the data is collected, and the helicopter  returns to a base site, the data is downloaded to a more powerful processing system for data processing and terrain imaging.","The helicopter  of the preferred embodiment  also comprises a global positioning system (\u201cGPS\u201d) receiver (not depicted in ), an inertial guidance system (not depicted in ) in the main cabin  of the helicopter , and a pitot tube system (not depicted in ). The combination of a GPS receiver and the information provided from an inertial guidance system (\u201cIGS\u201d) permit computation of the helicopter  position, altitude, attitude, and velocity at any point in time. By comparing these results, to the relative velocity computed using the pitot tube system, the wind speed can be estimated. The wind speed is preferably used as a correction factor in the image formation algorithms, discussed below.",{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 3","FIG. 3"],"b":["31","11","32","33","34","37","28","30","30","11","35","36","30","11","33","34","32","28","11","36"]},"The preferred method of operation involves a series of steps. Not all of the steps discussed below are necessary to perform the preferred method. Indeed, some of the steps may be omitted or replaced depending on the particular implementation of the embodiment disclosed herein. One having ordinary skill in the art, after reading the present description, will be able to determine which steps may be omitted, or additional steps to be added, in certain applications of the present embodiment.","In a general sense, the preferred method  of using the first embodiment  depicted and described above is presented in . As shown in , the first step  of the preferred method  comprises collecting a set of \u201cbase-line\u201d acoustical data. That is, before the device  and method  are employed to attempt to detect any ground-based object, or to attempt to map any terrain , a set of \u201cnormal,\u201d or standard, acoustical data is preferably collected and stored in a database . Preferably, this data is collected directly from sounds emitted from the helicopter  while operating, and not as reflected acoustical noise. Of course, in certain implementations, the \u201cbase-line\u201d acoustical data may be collected from reflected acoustical noise, or from theoretical information regarding the theoretical acoustical signature of the helicopter .",{"@attributes":{"id":"p-0051","num":"0050"},"figref":["FIG. 5","FIG. 6","FIG. 5","FIG. 6"],"b":["41","60","41","41","51","61","20"]},"The second step ( in ) in collecting the base-line data  is to attach the microphone  to a computer , as shown in . The computer  preferably comprises a CPU  and storage . The microphone  is electronically attached via wiring  to the computer  through an analog-to-digital converter .","As shown in , the next step  in the preferred method of collecting base line data  is to adjust a particular trajectory, or aspect angle, of the helicopter  relative to the microphone  on the ground . Then, the helicopter  is flown at the selected aspect angle over the stationary microphone  at a constant altitude and velocity (step ). In the next step , the microphone  collects the acoustical data emitted by the helicopter  over time as the helicopter  passes the microphone . This data is, in turn, collected by the computer CPU . The data collected is stored in the memory  of the computer  (step ) for analysis and use during the processing phase later.","After collecting this first set of data, the trajectory of the helicopter is adjusted to a different aspect angle (step ), and the helicopter  repeats its flight over the microphone  (step ). A new series of data is collected (step ) and stored (step ). This process is preferably repeated for a number of different helicopter aspect angles in order to generate a complete set of baseline data .","It is generally preferred to collect the \u201cbase-line\u201d data because each class of helicopter or other rotorcraft emits a different acoustical signature. For example, as mentioned previously, various helicopters have different numbers of blades and different blade configurations. For at least this reason, the acoustical signature emitted from a given helicopter's blades will vary. Also, the acoustical signature may vary with speed and various other factors. This data will be used to estimate the spectral content and directivity of the acoustic signature emitted by the helicopter.","The process  of collecting the \u201cbase-line\u201d data is basically an attempt to determine the frequency and aspect angle response of the amplitude of the acoustic pressure wave produced by the helicopter  to be used for data collection. For a U.S. Army UH-1 \u201cHuey\u201d helicopter, an example of collected \u201cbase-line\u201d data is depicted in .","As can be seen from , the spectrum of the acoustical energy generated by the exemplary UH-1 \u201cHuey\u201d helicopter is dominated by the acoustical noise generated by the helicopter main rotor blades . The main rotor blades of a typical helicopter rotate at a near constant speed and produce a coherent acoustical signal. This signal is readily recognizable in the \u201cbase-line\u201d data collected. The acoustical noise generated by the tail rotor blades  is also readily recognizable.",{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIGS. 7A and 7B","FIG. 7A","FIG. 7B"]},"The main harmonic from the main rotor blade  is at approximately 11 Hz, as shown in . The time response from the main rotor blade can be approximated by a series of impulses of approximately 0.01 seconds duration, as shown in  (see ). The first harmonic from the tail rotor blade  is at approximately 56 Hz as shown in , and the time response is the smaller set of impulse-like signals  seen in .","As noted above, the \u201cbase-line\u201d data collected from the helicopter flyover is preferably stored by the computer CPU  in a database . This stored data is then preferably used later to help generate imagery from data collected over the terrain .","Returning to , the next steps in the preferred method of imaging terrain is to collect helicopter flight data  and helicopter acoustical data  as the helicopter  flies over a terrain  to be imaged. These steps are preferably accomplished at approximately the same time, or very close in time.",{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 8","b":["11","10","20","20","81"]},"In this configuration, the helicopter  emits acoustical signals, these signals reflect off of the terrain , and the microphone array  on the helicopter  collects the reflected acoustical data (step  in ). As will be explained in more detail below, the main rotor  and the tail rotor  on the helicopter  produce the primary acoustic energy that is reflected off the terrain  and measured with the microphone array .","At approximately the same time as this acoustical data is collected (step ) by the microphone array , the helicopter's position, altitude, attitude, and speed are tracked using the GPS  and the IGS  referred to above. Of course, other means of collecting the preferred helicopter flight data are possible.","In the next steps (, ), both the helicopter flight data and the collected acoustical data are recorded by the computer  in a memory\/storage device  (steps  and ). These steps ,  may happen at approximately the same time, but this timing is not required by the present embodiment.","Returning to , the helicopter  is preferably flown over a terrain  at a height of about 100 meters. The image formation, or the synthetic aperture, is generated over 200 meters of forward flight by the helicopter . The ground surface, or terrain , beneath the flight path  of the helicopter  can be imagined to include a number of grid points , as depicted in .","As the helicopter  of the preferred embodiment passes over the terrain  to be imaged, the helicopter  naturally emits an acoustical signature. This acoustical signature echoes from the terrain . These acoustical echoes are measured with the microphone array  and recorded in the computer system memory .","Of course, the sensor array , i.e. the microphones , on the bottom of the helicopter  generally measure the acoustical signal emitted from the helicopter  as it is reflected off the terrain . However, the sensor array  will also measure the acoustical signal generated by the helicopter  before the acoustical signal is reflected off of the terrain . The latter, direct measurement of the acoustical signal, will be referred to as \u201cself noise.\u201d Self noise is generally not helpful in generating an image of the terrain , as this portion of the helicopter acoustical signal has no interaction with the terrain . Therefore, in the preferred embodiment, the processing of the microphone data preferably begins with the minimization, or complete removal, of the self noise from the data collected by the microphones .","As shown in , after the acoustical data and the flight data have been recorded, the next step  is preferably to process the recorded data by removing the self noise. Alternatively, the data may be processed as it is received by the CPU  of the computer , before being recorded into the computer memory . Alternatively, and preferably, the data from the microphone array  is stored in the memory  on the helicopter  and is processed after the helicopter  has returned to a base and the data moved to another, more powerful computer.","Regardless of the timing, the preferred method  of processing the data, particularly processing out the self noise, is depicted in . As depicted, the preferred noise removal steps are to remove or reduce main rotor noise , remove or reduce tail rotor noise , remove or reduce engine noise , and remove or reduce vibration noise . Of course, these steps do not have to be accomplished in the particular order depicted and any linear operations can be combined. Further, some of these steps may be omitted in certain implementations. For example, it may be possible to omit one or more steps if the level of that particular acoustical noise is relatively low. Additionally, other sources of noise can be removed, if the acoustical data is more finely processed.","Stated differently, the primary sources of acoustical noise are, generally, the rotor blades, engines and other moving parts on the helicopter, vibration noise on the platform, and the wind. There may be other sources that can be removed with additional techniques, or the techniques described below. The preferred noise reduction\/removal steps  will now be described in greater detail.","The first step in the preferred noise removal methodology  is to remove or reduce the self noise from the main rotor  (step ) collected directly from the main rotor . The main rotor leakage acoustical signal is preferably reduced by not using the data from the microphones when the self noise is large, or by turning the microphones  off during a period when the detected acoustic signal is large. In other words, the data collection device, or computer CPU  in the preferred embodiment , monitors the signal level, and when this level experiences a significant, dramatic increase, the microphone data is discarded for a brief period of time.","As will be recognized, this preferred method of reducing the main rotor acoustical leakage signal will cause a \u201cblind spot\u201d in the collected acoustical data for a brief period of time. However, this \u201cblind spot\u201d will be filled in as the helicopter  moves over the terrain  to be imaged. As will be recognized by one of ordinary skill in the art, the basic process of synthetic aperture creation will fill in this data as the helicopter  moves along its path. As one example,  shows that for an exemplary UH-1 helicopter, the \u201cblind\u201d region in the data is approximately 0.01 seconds in duration.","Returning to , the next step in the preferred noise reduction method  is the reduction of self noise collected by the microphone array  from the tail rotor  (step ). One method for reducing this source of acoustical noise is to employ a lowpass filter and filter the data collected by the microphone array . The filtering can be applied by the CPU  on the helicopter  as the data is being collected, or by any computer after the data has been saved to memory . A preferred lowpass filter has a cutoff frequency below 56 Hz. As discussed above in relation to , the first harmonic from the tail rotor is at approximately 56 Hz. However, for the preferred UH-1 helicopter  (and possibly many other helicopters), the acoustic signal from the main rotor  and the tail rotor  cannot be effectively separated to an acceptable degree using a low pass filter because of a significant overlap in the acoustic spectrum of the two acoustic sources. For this reason, using a low pass filter for reducing tail rotor self noise is not preferred, but possible.","As an alternative method of reducing tail rotor noise, the acoustic data could be ignored when the tail rotor noise increases dramatically. This would be similar to the methodology preferred to reduce the main rotor noise. However, the total time response of the tail rotor leakage signal is longer that of the main rotor acoustic signal. Therefore, simply ignoring the data when the tail rotor portion of the acoustical signal increases will also remove a significant portion of the desirable return acoustical signal. In other words, this method will create too great of a \u201cblind spot\u201d in the data for many applications. Again, this method of reducing tail rotor self noise is not preferred, but possible.","Although either of the above-described methods of tail rotor noise reduction may be used, the preferred method for reducing tail rotor noise is to use an adaptive comb filter on the data collected by the microphone array . The preferred adaptive comb filter starts filtering data that has a fundamental frequency at approximately 56 Hz. With this approach, the signal reflected from directly below the helicopter will be rejected, but most of the reflected acoustic energy collected by the microphone array  will be Doppler-shifted, and therefore, will pass through the filter. Thus, this method does not exhibit the difficulty of creating an excessive blind spot, or of filtering out too much of the reflected main rotor signal.","This can be understood from the following equations, and with reference to . As shown in , the sound, or emitted acoustic signal  from the helicopter  is emitted at a first point . A portion of the emitted acoustical signal  strikes the terrain  at a certain grid point . Then, the reflected acoustic signal  is received by the microphone array  at a second point  some distance further along the helicopter's path of travel . The ground  will generally introduce a two-way Doppler shift in the reflected acoustic signal  approximately equal to:",{"@attributes":{"id":"p-0078","num":"0077"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["f","d"]},"mo":"=","mrow":{"msub":{"mi":["f","c"]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"v"},"mi":"c"},"mi":["cos","\u03b3"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}},"where fis the Doppler shift, fis the carrier frequency, \u03bd is the velocity of the helicopter, c is the velocity of sound, and \u03b3 is the angle between the direction of the helicopter  and the vector of the sound  emitted from the helicopter  to a grid point  on the ground . For example, if \u03bd=50 m\/s, c=330 m\/s, and the maximum value of \u03b3 of interest is 45 degrees, then",{"@attributes":{"id":"p-0080","num":"0079"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"msub":[{"mi":["f","d"]},{"mi":["f","c"]}]},"mo":"=","mrow":{"mn":"0.21","mo":"."}}}}},"As will be recognized by one of ordinary skill in the art, this result indicates that the Doppler shift is potentially a large percentage of the frequency of the harmonics. See . Therefore, a narrow-band comb filter could be implemented with minimal loss of reflected signal power.","In addition to the above-discussed techniques for reducing the main and tail rotor self noise, the self noise from the rotors ,  can also be reduced by simply shielding the microphones  from the direct path of the acoustical signals emitted from the rotors , . The shape of a windscreen for the microphones  can be chosen to do a portion of the shielding. The microphones  could also be directional in pick-up. Although the preferred methods described above generally deal with data processing steps, these simple techniques may be used as a stand-alone method or in combination in certain implementations or with certain helicopters.","Lower frequency vibration of the helicopter engines  is also a self noise source that the microphone array  may collect. It is preferable to also reduce this source of acoustical self noise. As shown in , reduction or removal of engine self noise is the third step  in the data processing method , and removal or reduction of vibration self noise is the fourth step  in the preferred method . In the preferred embodiment, the reduction of these types of self noise is accomplished by using two techniques. First, an accelerometer (not depicted) mounted near the microphones  and the engine  will help estimate the level of these self noise sources. Using the accelerometer as a reference, an adaptive filter using a least-mean-square (\u201cLMS\u201d) algorithm can be used to reduce the engine and vibration self noise. Basically, the microphone data is simply run through this adaptive LMS filter. This technique is widely used in many active noise cancellation systems and well known to one of ordinary skill in the appropriate art.","However, due to effects such as turbulence, near-field effects, and diffraction, the relationship between the reference signal created by the accelerometers and the noise will have nonlinear components. For this reason, using an LMS filter alone is not preferred. Another filter is preferably used to further process the microphone  data and remove engine  and vibration self noise.","Therefore, the output of the LMS filter will be further processed to remove the remaining components. It is known that, in general, most of the self noise sources are coherent acoustical signals, and quickly decorrelate with respect to the reflected acoustical signals ( in ) over time. Knowledge of this fact allows further reductions in the vibration and engine  self noise (steps  and ).","First, a spectral analysis is preferably performed on the data collected by each microphone after the LMS filter has been applied Then, the frequency, amplitude, and, optionally, a phase of the self noise signals is estimated and a filter is designed to subtract the remaining self noise from the recorded data.","The spectrum can be determined using a variety of techniques. For example, this can be performed by taking fast fourier transforms (\u201cFFTs\u201d) of the data and averaging or smoothing them together. For increased accuracy, the FFTs can be padded with zeros. Increased accuracy can also be obtained by using a digital phase-locked-loop. Other super-resolution techniques such as Prony's method or MUSIC could also be applied. Once the noise is characterized, it can be directly subtracted out, or removed with a narrow band filter.","As also shown in , the final step  in the data processing method  is preferably to compensate for a downwash effect. The effect of the downwash of the main rotor blade  is preferably compensated for by first estimating the effect of downwash on the acoustical data gathered by the microphones .","The downwash effect is preferably estimated by slowly flying the helicopter over microphones on the ground, similar to the procedure for collecting baseline data discussed above and depicted in . The frequency of the acoustic energy on the ground is compared with the rotation rate of the main rotor blades. The Doppler frequency is estimated using the GPS and IGS information at a particular data collection point. The downwash will create a difference between the estimated and measured Doppler shift. This difference is preferably used to determine an effective average windspeed for the down wash.","Although typically not implemented in the data processing phase , it is also preferable to reduce the airflow noise. Airflow noise, which is mostly broadband and random, can be mitigated with windshield designs that can result in a 20 dB improvement. Thus, a specially-adapted microphone that has a windshield design to reduce the airflow noise is preferred.","As noted above, there may be other sources of self noise that the user may wish to remove or reduce from the collected acoustical data. These particular noise sources may depend on the particular rotorcraft used, and\/or the particular terrain to be imaged. One of ordinary skill in the art will be able to adapt the above-explained principals in order to reduce noise from an additional source, if one is identified.","Returning to the overall method of the present disclosure, depicted in , once the data has been processed, imagery of the terrain  is preferably generated from the remaining acoustical data. The imagery may be generated on board the helicopter  as the helicopter  flies over the terrain . Alternatively, the data may be collected and stored in the memory , and then a more powerful computer may be used to perform the imagery.","Regardless of the location of the image-generating computer system, the imagery is preferably generated on a two-dimensional or three-dimensional grid that is at the approximate height of the ground. Also, it is preferred in the present embodiment that the image processing be performed using backprojection techniques in either the time or frequency domain.","The backprojection technique in the time domain is generally more computationally efficient, but use of this technique usually does not account for the frequency-dependent attenuation in the acoustical signal. Alternatively, the imagery may be processed by backprojection techniques in the frequency domain. Such a processing methodology may remedy some of the expected issues involved in time domain backprojection. Both the time and frequency domain techniques will be discussed below.","Range ambiguity for an image based upon a static transmitter is the speed of sound multiplied by the period of the transmit waveform divided by two. For the present described embodiment, however, backprojection techniques in the time and frequency domain both rely on triangulation to resolve any range ambiguities.","First, backprojection imaging in the frequency domain will be discussed. Generally, the preferred method  for processing the microphone data in the frequency domain is depicted in . To process in the frequency domain, narrow band acoustical data is preferred. To generate the desired narrow band data, first, the microphone data is preferably filtered with a series of narrow band filters (step ). These narrow band filters are preferably designed to operate around the helicopter harmonic frequencies, plus or minus the maximum expected Doppler shifts. Of course, the helicopter harmonic frequency is the fundamental frequency of the helicopter rotor blades, plus all of the associated harmonics of the helicopter.","In the second step  of the preferred embodiment , for each element of data recorded at a particular time and angle (y from ), beamforming coefficients are preferably determined (step ). The beamforming coefficients are preferably generated using a minimum variance distortionless response (MVDR) algorithm with a pregenerated covariance matrix. The covariance matrix preferably contains the contributions from only the major sources of interference, such as the tail rotor  and the engine  of the helicopter . Because of the usually limited number of sensors, only the major noise sources are typically nulled using MVDR. Because the step of generating the covariance matrix preferably occurs prior to imaging, this step is not depicted in . The beamforming coefficients are determined by applying the MVDR algorithm to the covariance matrix and to the steering vectors associated with each grid point  for each analog-to-digital converted sample of the microphone data. Coefficients can be loaded from a look-up table for each steering vector, or calculated for each data set.","To better explain this step , specific possible equations are presented below. Specifically, beamforming is preferably performed using the following equation:",{"@attributes":{"id":"p-0099","num":"0098"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"A","mrow":{"mi":["n","k","f"],"mo":[",",","]}},"mo":"=","mrow":{"mrow":{"mo":["(",")"],"mrow":{"msubsup":{"mi":["c","H"],"mrow":{"mi":["n","k","f"],"mo":[",",","]}},"mo":"\u2062","msub":{"mi":"X","mrow":{"mi":["n","k","f"],"mo":[",",","]}}}},"mo":"\u2062","msup":{"mi":"\u2147","mrow":{"mo":"-","msub":{"mi":"j\u03d5","mrow":{"mi":["n","k","f"],"mo":[",",","]}}}}}}}},"br":{},"sub":["n,k,f ","n,k,f ","n,k,f ","e","n,k,f"],"sup":["th ","th ","th ","th ","th ","j\u03c6"]},"The next step (step ) in the preferred imaging process is to compensate for the motion of the helicopter . The motion of the helicopter  results in different transmit  and receive  paths for the acoustical signals generated by the helicopter  and received by the microphone array . This fact is graphically-depicted in . As can be seen, the path  of the acoustical signal from the helicopter  to the ground  is depicted by Dand is transmitted at angle \u03b3. The path  of the reflected acoustical signal to the helicopter  is represented by Dand is received at angle \u03b8. During the time it takes the acoustical signal to transmit to the ground and reflect back to the helicopter , the helicopter  has traveled a distance (dx) along its path .","The path lengths (Dand D) and angles (\u03b3 and \u03b8) from the transmit source , to the ground , and back to the microphone array  are determined from the location of the helicopter  and the selected grid point . The phase and frequency of the transmitted signal , Dis preferably known with a high degree of precision. This is preferably performed by tracking the peak of any of the impulse-like signals, or by bandpass filtering the microphone data or the accelerometer data to obtain a strong harmonic, then using a digital phase-locked loop (PLL).","To further explain motion compensation, exemplary mathematical equations are presented below. Specifically, the motion compensation calculation is preferably performed using the following equation:",{"@attributes":{"id":"p-0103","num":"0102"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"M","mrow":{"mi":["n","k","f"],"mo":[",",","]}},"mo":"=","mrow":{"msub":{"mi":"A","mrow":{"mi":["n","k","f"],"mo":[",",","]}},"mo":"\u2062","mrow":{"msup":{"mi":"\u2147","mrow":{"mo":"-","mi":"j"}},"mo":["(","\u2062",")"],"mstyle":{"mspace":{"@attributes":{"width":"0.em","height":"0.ex"}}},"mrow":{"msub":{"mi":"\u03c8","mrow":{"mi":["n","k","f"],"mo":[",",","]}},"mo":["+","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.em","height":"0.ex"}}},"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03c0","mfrac":{"mrow":[{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"1","mo":[",",","],"mi":["n","k"]}}},{"mo":["(",")"],"mrow":{"mi":"c","mo":["-","+"],"msub":{"mi":"Vd","mrow":{"mn":"1","mo":[",",","],"mi":["n","k"]}},"mrow":{"msub":{"mover":{"mi":"V","mo":"\u2192"},"mi":"w"},"mo":"\u2062","mfrac":{"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"1","mo":[",",","],"mi":["n","k"]}},"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"1","mo":[",",","],"mi":["n","k"]}}}}}}}]}},"mo":"+","mfrac":{"mrow":[{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"2","mo":[",",","],"mi":["n","k"]}}},{"mo":"\u2009","mrow":{"mo":["(",")"],"mrow":{"mi":"c","mo":["+","+"],"msub":{"mi":"Vd","mrow":{"mn":"2","mo":[",",","],"mi":["n","k"]}},"mrow":{"msub":{"mover":{"mi":"V","mo":"\u2192"},"mi":"w"},"mo":"\u2062","mfrac":{"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mrow":{"mn":"2","mo":"\u2062","mi":"n"},"mo":",","mi":"k"}},"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"2","mo":[",",","],"mi":["n","k"]}}}}}}}}]}}},{"msub":{"mi":["F","f"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"+","mrow":{"mfrac":[{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mover":{"mi":"V","mo":"\u2192"},"mi":"H"},{"mover":{"mi":"V","mo":"\u2192"},"mi":"w"}],"mo":"+"}},"mi":"c"},{"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mrow":{"mn":"2","mo":"\u2062","mi":"n"},"mo":",","mi":"k"}},"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"1","mo":[",",","],"mi":["n","k"]}}}}],"mo":"\u00b7"}}}}],"mo":"\u2062"}}}}}}}},"where Mis the motion compensated signal for the na\/d sample, ksteering vector, and ffrequency, Ais the amplitude for the nth a\/d sample, kgrid point, and ffrequency, \u2225{right arrow over (D)}\u2225 is the norm of the vector from the grid point on the ground to the microphone array, \u2225{right arrow over (D)}\u2225 is the norm of the vector from the center of the transmit source to a grid point on the ground, {right arrow over (V)}is the velocity of the helicopter, {right arrow over (V)}is the velocity of the wind, c is the velocity of the speed of sound, Vdand Vdare the correction factors for the effective wind speed due to the downwash from the helicopter blades, Fis the frequency of the fharmonic of the helicopter, and \u03c8is the motion compensation term to adjust the phase of each frequency to compensate for the motion of the helicopter and starting phase of the transmit frequency.","As is noticed, and discussed above, the exemplary motion compensation equations need the path lengths of the acoustical signals and the angles of the paths as a function of time, grid point, and helicopter velocity. The following equations are preferably used for determining \u2225{right arrow over (D)}\u2225 and \u03b3 given \u2225{right arrow over (D)}\u2225, \u03b8 which are a function of the helicopter position  and grid point , and the helicopter velocity. Again, with reference to , c is the speed of sound, V is the helicopter velocity, {right arrow over (D)}is the path from the source to the grip point, {right arrow over (D)}is the path from the grid point to the microphones, and dx is the distance traveled by the helicopter. It is assumed that the helicopter  is flying in a straight line at a constant velocity. From , it is seen that",{"@attributes":{"id":"p-0106","num":"0105"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":[{"mrow":{"mrow":[{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}},{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"2"}}],"mo":"+"},"mi":"c"},{"mi":["dx","V"]}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}},"br":{},"sub":"2"},{"@attributes":{"id":"p-0107","num":"0106"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"2"}},{"mfrac":{"mi":["dxc","V"]},"mo":"-","mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}},"br":[{},{},{}],"figref":"FIG. 10","in-line-formulae":[{},{}],"i":["{right arrow over (D)}","=\u2225{right arrow over (D)}","+dx","\u2225{right arrow over (D)}","\u2225dx "],"sub":["2","1","1"],"sup":["2","2","2"]},{"@attributes":{"id":"p-0108","num":"0107"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msup":[{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"2"}},"mn":"2"},{"mrow":{"mo":["(",")"],"mrow":{"mfrac":{"mi":["dxc","V"]},"mo":"-","mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}}}},"mn":"2"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"4"}}]}}}},"br":{}},{"@attributes":{"id":"p-0109","num":"0108"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msup":{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"2"}},"mn":"2"},"mo":"=","mrow":{"msup":[{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}},"mn":"2"},{"mrow":{"mo":["(",")"],"mfrac":{"mi":["dxc","V"]}},"mn":"2"}],"mo":["+","-"],"mfrac":{"mrow":{"mn":"2","mo":["\u2062","\u2062"],"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}},"mi":"dxc"},"mi":"V"}}}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}}}},"br":{}},{"@attributes":{"id":"p-0110","num":"0109"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"O","mo":"=","mrow":{"mrow":[{"msup":{"mi":"dx","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msup":{"mrow":{"mo":["(",")"],"mfrac":{"mi":["c","V"]}},"mn":"2"}}}},{"mn":"2","mo":"\u2062","mrow":{"mi":"dx","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":{"mrow":{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}},"mo":"\u2062","mi":"C"},"mi":"V"},"mo":"-","mrow":{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}},"mo":["\u2062","\u2062","\u2062"],"mi":["cos","\u03b8"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}}],"mo":"+"}}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}}}},"br":{}},{"@attributes":{"id":"p-0111","num":"0110"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"dx","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msup":{"mrow":{"mo":["(",")"],"mfrac":{"mi":["c","V"]}},"mn":"2"}}}},{"mn":"2","mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}},"mo":["\u2062","\u2062","\u2062"],"mi":["cos","\u03b8"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"-","mfrac":{"mrow":{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}},"mo":"\u2062","mi":"c"},"mi":"V"}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"7"}}]}}}},"br":{}},{"@attributes":{"id":"p-0112","num":"0111"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"dx","mo":"=","mrow":{"mn":"2","mo":"\u2062","mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mrow":{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}},"mo":["\u2062","\u2062","\u2062"],"mi":["cos","\u03b8"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"-","mfrac":{"mrow":{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}},"mo":"\u2062","mi":"c"},"mi":"V"}}},{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msup":{"mrow":{"mo":["(",")"],"mfrac":{"mi":["c","V"]}},"mn":"2"}}}],"mo":"\/"}}}},{"mrow":{"mo":["(",")"],"mn":"8"}}]}}}},"br":[{},{}],"in-line-formulae":[{},{}],"i":["{right arrow over (D)}","\u2225\u2225d{circumflex over (x)}","d{circumflex over (x)}\u00b7D"],"sub":["1","1"]},"from equation (9), one can derive the following relationship:",{"@attributes":{"id":"p-0114","num":"0113"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"=","mfrac":{"mrow":[{"mi":"d","mo":"\u2062","mrow":{"mover":{"mi":"x","mo":"^"},"mo":"\u00b7","msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}}},{"mn":"1","mo":"\u2062","mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}}}]}}},{"mrow":{"mo":["(",")"],"mn":"10"}}]}}}}},"Again, from , and the Cosine Rule of trigonometry, the following relationship is derived:\n\n\u2225\u2225\u2225\u22122cos \u03b3\u2003\u2003(11)\n\nRearranging, equation (11) yields:\n",{"@attributes":{"id":"p-0116","num":"0115"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":["cos","\u03b3"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"=","mfrac":{"mrow":[{"msup":[{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"2"}},"mn":"2"},{"mi":"dx","mn":"2"},{"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}},"mn":"2"}],"mo":["+","-"]},{"mn":"2","mo":["\u2062","\u2062"],"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mn":"1"}},"mi":"dx"}]}}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}}},"Now, dx can be determined from equation (8), \u03b3 can be determined from equation (12), and \u2225{right arrow over (D)}\u2225 can be determined from equation (2). Generally, the use of narrow band filters on the data creates a phase delay in the data. It is desirable to remove this phase delay. Generally and preferably, this can be accomplished by either multiplying the data by a phase factor or by time-shifting the data to account for the delays in the narrow band filters.","Next, an amplitude correction term is calculated to adjust for propagation loss and the directivity of the source using the following equation:",{"@attributes":{"id":"p-0119","num":"0118"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"A","mrow":{"mi":["n","k","m"],"mo":[",",","]}},"mo":"=","mfrac":{"msub":{"mi":"G","mrow":{"mi":["n","k","m"],"mo":[",",","]}},"mrow":{"mrow":[{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"1","mo":[",",",",","],"mi":["n","k","m"]}}},{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"2","mo":[",",",",","],"mi":["n","k","m"]}}}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}},"br":{},"sub":["n,k,f ","n,k,m "]},"For the next steps in the preferred imaging method (steps  and ), two images are generated. A first image is generated for the relatively lower frequency harmonics of the helicopter  generated by the main rotor blade  (step ) and a second image is generated for the relatively higher frequency harmonics generated by the tail rotor  of the helicopter  (step ). To accomplish this preferred step, first, Q(t) the \u201cfiltered projection,\u201d is obtained using the following equation:\n\n()=}\n\nwhere tis time or equivalently range bin number, Fis an inverse DFT, wis the frequency of interest, Wis the start frequency, and Ais an amplitude correction term.\n","Next, backprojection imagery is computed using the following equation:",{"@attributes":{"id":"p-0122","num":"0121"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["g","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["r","\u03c6"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":[{"mi":"n","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":"Q","mrow":{"mi":["n","k"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"r","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"\u03c6","mo":"-","msub":{"mi":"\u03b8","mrow":{"mi":["k","n"],"mo":","}}}}}}}}}],"mo":"="}}}},"where gis an image of acoustic reflectivity the terrain at polar angle coordinates r and \u03c6 relative to the kth grid point, \u03b8is the angle of the center of the microphone array with respect to the grid point of interest, and Q(t) is obtained at t=r cos(\u03c6\u2212\u03b8) from the set of samples {Q(t)} via interpolation.","Image processing can also be performed in the time domain by summing the product of the data with appropriate delays associated with each grid point and sample time.","The signal processing can be performed using complex variables by applying a Hilbert transform to the measured data and then generating an analytic signal. The time delays are preferably determined from the time that the signals were transmitted, the position of the helicopter  as a function of time, path lengths from the transmitter to the receiver, wind, and the effects of the downwash from the helicopter blades. The following exemplary equation shows how to determine t, the time delay associated with the nth analog-to-digital converted sample of the microphone data, for the kth grid point g(x, y, z), and for the mth microphone.",{"@attributes":{"id":"p-0126","num":"0125"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":"t","mrow":{"mi":["n","k","m"],"mo":[",",","]}},"mo":"=","mrow":{"mo":["(",")"],"mrow":{"mfrac":[{"mrow":[{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"1","mo":[",",",",","],"mi":["n","k","m"]}}},{"mo":["(",")"],"mrow":{"mi":"c","mo":["-","+"],"msub":{"mi":"Vd","mrow":{"mn":"1","mo":[",",","],"mi":["n","k"]}},"mrow":{"msub":{"mover":{"mi":"V","mo":"\u2192"},"mi":"w"},"mo":"\u00b7","mfrac":{"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"1","mo":[",",",",","],"mi":["n","k","m"]}},"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"1","mo":[",",",",","],"mi":["n","k","m"]}}}}}}}]},{"mrow":[{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"2","mo":[",",",",","],"mi":["n","k","m"]}}},{"mo":["(",")"],"mrow":{"mi":"c","mo":["+","+"],"msub":{"mi":"Vd","mrow":{"mn":"2","mo":[",",","],"mi":["n","k"]}},"mrow":{"msub":{"mover":{"mi":"V","mo":"\u2192"},"mi":"w"},"mo":"\u00b7","mfrac":{"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"2","mo":[",",",",","],"mi":["n","k","m"]}},"mrow":{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"2","mo":[",",",",","],"mi":["n","k","m"]}}}}}}}]}],"mo":"+"}}},"mo":")"}}}},"The image is formed as follows:",{"@attributes":{"id":"p-0128","num":"0127"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["g","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y","z"],"mo":[",",","]}}},{"munder":{"mo":"\u2211","mi":"M"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munder":{"mo":"\u2211","mi":"N"},"mo":"\u2062","mfrac":{"mrow":[{"mrow":{"mi":"X","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"nT","mo":["-","-"],"msub":[{"mi":"t","mrow":{"mi":["n","k","m"],"mo":[",",","]}},{"mi":"\u03c4","mrow":{"mi":["n","k"],"mo":","}}]}}},"mo":"\u2062","msub":{"mi":"G","mrow":{"mi":["n","k","m"],"mo":[",",","]}}},{"mrow":[{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"1","mo":[",",",",","],"mi":["n","k","m"]}}},{"mo":["\uf605","\uf606"],"msub":{"mover":{"mi":"D","mo":"\u2192"},"mrow":{"mn":"2","mo":[",",",",","],"mi":["n","k","m"]}}}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}}}],"mo":"="}}},"br":{},"sub":["n,k,m","n,k","n,k,m","n,k ","n,k,m ","n,k,m ","n,k,m "],"sup":["th ","th "]},"The pulse repetition interval (PRI), or the period of the transmitted signal, is preferably determined from the accelerometers on the helicopter  and\/or self noise and using techniques such as PLL.","The theoretical range resolution of the imagery based only upon the bandwidth of the transmitted signal is the speed of sound divided by twice the bandwidth for each set of frequencies (3 and 1 m) and the unambiguous range is the speed of sound divided by the frequency step (15 and 3 m). These results indicate that scatterers are wrapped multiple times in each high resolution profile. However, the ambiguity will preferably be resolved by triangulation and focusing over the entire synthetic aperture and the resolution will be improved.",{"@attributes":{"id":"p-0131","num":"0130"},"figref":["FIG. 12","FIG. 1"]},"It should be emphasized that the above-described embodiments of the present invention, particularly, any \u201cpreferred\u201d embodiments, are merely possible examples of implementations, merely set forth for a clear understanding of the principles of the invention. Many variations and modifications may be made to the above-described embodiment(s) of the invention without departing substantially from the spirit and principles of the invention. All such modifications and variations are intended to be included herein within the scope of this disclosure and the present invention and protected by the following claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Many aspects of the invention can be better understood with reference to the following drawings. The components in the drawings are not necessarily to scale, emphasis instead being placed upon clearly illustrating the principles of the present invention. Moreover, in the drawings, like reference numerals designate corresponding parts throughout the several views.",{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 6","FIG. 5"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 7A","FIG. 5","FIG. 1"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 7B","FIG. 5","FIG. 1"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 8","FIG. 1"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 10","FIG. 1"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 12","FIG. 1","FIG. 11"]}]},"DETDESC":[{},{}]}
