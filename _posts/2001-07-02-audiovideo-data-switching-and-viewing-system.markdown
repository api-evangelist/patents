---
title: Audio-video data switching and viewing system
abstract: A computer system and method providing for viewing and switching of audio-video data. The system comprises: a plurality of audio/video sources containing information referring to an event; a streaming server, streaming the contents of a first audio signal and a first video signal from the audio and video sources to a user; a feed distributor controllably feeding the first audio signal and first video signal to the streaming server; and a user-operated control unit communicating with the feed distributor and controlling operation of the feed distributor, so as to instruct the feed distributor to switch between audio or video. Switching between audio signals occurs without altering the video signals and switching between video signals occurs without altering the audio signals.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07571244&OS=07571244&RS=07571244
owner: 
number: 07571244
owner_city: 
owner_country: 
publication_date: 20010702
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","Prior Art","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["The present invention relates to webcast streaming of audio-visual events. More specifically, the invention relates to an audio-video data switching and viewing system which allows viewing and smooth remote switching from one video signal to another or from one audio signal to another.","According to the webcast streaming technology, a client-server connection is established, where the server transmits multiple streams or files to each client. Each stream or file relates to a different point of view. Each stream or file is output either from stored files or from live encoded feeds, for example by means of encoding stations.",{"@attributes":{"id":"p-0004","num":"0003"},"figref":"FIG. 1","b":["1","1","2"]},"The audio-visual content of the number n of files  (three in the example) is streamed from the server to the client over a connection . The connection  is an Internet connection. As a consequence, it can assemble different network technologies, such as Ethernet, Frame Relay, ATM switch, CDN, satellite uplink and downlink, DS, D, DS (or the corresponding European E, E, E ), fiber, modem, ISDN, xDSL and so on. All these technologies use the IP protocol and are interconnected by routers, bridges and gateways. Assuming that the maximum available bandwidth for the connection is b, the maximum bandwidth for each streamed file will be b\/3.","On the client side, a streaming client software  provides for the interpretation of the received streams. One of the streams is shown on the screen of the client in a current view. For example, the contents relating to the video file FV can be shown, as indicated by the box , represented in solid lines and relating to the \u201ccurrent view(2)\u201d, namely the view relating to the contents of FV.","As soon as the viewer wants to switch on a different point of view, he will send a command to the GUI (graphic user interface) , for example by means of a pointing device (not shown in the Figure), and from the GUI  to the streaming client . As a result, the audio-visual content shown on the screen will from now on relate for example to the contents of FV, indicated by the box , represented in dotted lines.","A problem of the prior art shown in  is that the required bandwidth is directly proportional to the number of cameras (different points of view) adopted. Therefore, a high bandwidth is required in order to obtain an audio-visual content of a good quality.","In order to solve such problem, a different session for each view could be established. This means that only a single audio-visual content at the time would be streamed and, each time a client desires to switch from one view to another, the streaming server  would pick a different file and retransmit it to the client. Such technology is, for example, adopted in the \u201cBigBrother\u201d series, when transmitted over the Internet. See, for example, http:\/\/www.endemol.com or http:\/\/www.cbs.com\/primetime\/bigbrother. While this solution allows a larger bandwidth, the switching delay is unacceptable for the user. In fact, according to the usual way of streaming signals, a first step of the streaming process is that of buffering data on the client computer. Then, after a predetermined amount of time, the data are shown on the screen of the client while, at the same time, the remaining data are being transferred over the connection. This means that, each time a switching occurs, a considerable amount of time would be spent in buffering again the audio-visual data of the following stream, with a delay which would be unacceptable for most kind of commercial applications and which would result in an interruption of both the audio and the visual content of the signal transmitted on the screen.","The present invention solves the prior art problems cited above, by allowing each user to remote controlling between different cameras, thus creating a customized show with a seamless switching and optimal use of bandwidth. More specifically, when switching among different points of view, the system according to the present invention is such that neither audio nor video interruptions occur, and the new view replaces the old one with a perfect transition.","According to a first aspect, the present invention provides a computer system for viewing and switching of audio-video data, comprising: a plurality of audio and video sources containing information referring to an event; a streaming server, streaming the contents of a first audio signal and a first video signal from the audio and video sources to a user; a feed distributor, connected between the audio and video sources and the streaming server, the feed distributor controllably feeding the first audio signal and first video signal to the streaming server; and a user-operated control unit communicating with the feed distributor and controlling operation of the feed distributor, so as to instruct the feed distributor to switch between video signals whereby, upon switching, the feed distributor feeds to the streaming server a second video signal which is different from the first video signal without altering the first audio signal.","According to a second aspect, the present invention provides a computer system for viewing and switching of audio-video data, comprising: a plurality of audio and video sources containing information referring to an event; a streaming server, streaming the contents of a first audio signal and a first video signal from the audio and video sources to a user; a feed distributor, connected between the audio and video sources and the streaming server, the feed distributor controllably feeding the first audio signal and first video signal to the streaming server; and a user-operated control unit communicating with the feed distributor and controlling operation of the feed distributor, so as to instruct the feed distributor to switch between audio signals whereby, upon switching, the feed distributor feeds to the streaming server a second audio signal which is different from the first audio signal without altering the first video signal.","According to a third aspect, the present invention provides a computer-operated method for viewing and switching of audio-video data, comprising the steps of: providing a plurality of audio and video sources containing information referring to an event; streaming contents of a first audio signal and a first video signal from the audio and video sources to a user; controlling the streaming of video signals, so as to switch between video signals, streaming, upon switching, a second video signal which is different from the first video signal without altering the first audio signal.","According to a fourth aspect, the present invention provides a computer-operated method for viewing and switching of audio-video data, comprising the steps of: providing a plurality of audio and video sources containing information referring to an event; streaming contents of a first audio signal and a first video signal from the audio and video sources to a user; controlling the streaming of audio signals, so as to switch between audio signals, streaming, upon switching, a second audio signal which is different from the first audio signal without altering the first video signal.","Advantageous embodiments of the present invention are claimed in the attached dependent claims.","The present invention overcomes the problems of the prior art in several aspects: first, the bandwidth is not wasted as done with prior art systems. The Internet connection carries, at every time, only one video stream and one audio stream. As a consequence, a virtually unlimited number of different points of view can be used. Second, the audio signal is not interrupted during switching. Third, there is a smooth video transition on the screen of the user between different points of view.","In accordance with the present invention, there is no need to establish a new session over a new connection each time a switching of point of view occurs.","The present invention is particularly advantageous in a system requiring a high number of cameras, like for example from 30 to 50 cameras. Such high number of cameras shooting an event, provides the user with a sort of a virtually infinite camera, the cameras being arranged with the correct parallax in a matrix fashion. In this case, a system like the system described in  cannot be implemented. By contrast, this case is well suited to the system according to the present invention, where the occupied bandwidth is independent from the number of different cameras.","Other features and advantages of the invention will become apparent to one skilled in the art upon examination of the following drawings and detailed description. It is intended that all such additional features and advantages be included herein within the scope of the invention, as is defined by the claims.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 2","b":["11","12","13","12","11","13","14","14","15","14","17","50","14","14","13","16","21","30","14","13"]},"As also explained later, the feed distributor  could be implemented either on a computer which is separate from the computer containing the streaming server, or on the computer containing the streaming server. In the preferred embodiment of the present application, the streaming server and the feed distributor are on the same computer.","A first embodiment of the present invention provides transmitting only a single stream of audio-visual data (coming for example from the video file FV and also comprising the audio file FA) along a connection  between the streaming server  and the streaming client . A second embodiment could provide a main stream of audio-visual data output on a main window of the user, and a plurality of accessory streams output on secondary windows (thumbnails), wherein the accessory streams have an extremely reduced bandwidth occupation and wherein the audio-visual contents of the main window can be switched by the user according to the present invention.","During operation, as soon as the user wishes to change from a first point of view to a second point of view, switching for example from the video file FV to the video file FV, the active GUI  instructs the GUI manager , which in turn instructs the feed distributor  on the server side to switch between video files. Upon receipt of such instructions, the feed distributor  selects the video file VF and transmits this file to the streaming server . During the switching of points of view, the audio file\u2014which is usually interleaved with the video file during the streaming operation\u2014is not altered. Thus, no audio switching occurs when changing view from one camera to another. Moreover, according to a preferred embodiment of the present invention, the video switching between points of view occurs in a smooth manner. Differently from what disclosed in the prior art of , here, a switching command by the user causes a switch on the server side, so that the streaming server  streams a signal which is different from the signal which was streamed before the switching command. Further, differently from what disclosed in the prior art like the Internet transmission of the BigBrother\u2122 format, switching occurs on the video signal without need for the audio signal to be affected. Still further, as it will be clear from the following detailed description, switching can also occur on the audio signal without need for the video signal to be affected.","In the present specification, the output of the audio and video sources  will be usually called \u201caudio file\u201d and \u201cvideo file\u201d. However, also a live encoded feed output is possible. The person skilled in the art will recognize that the particular kind of output from the sources  is not essential to the present invention, so that sometimes also the generic term \u201caudio signal\u201d and \u201cvideo signal\u201d will be used.","The present invention will now be disclosed with reference to , which describes in greater detail the diagram shown in . First, the general operation of the system according to the present invention will be described with reference to three main events: 1) Request of event parameters; 2) Streaming; and 3) Switching. Subsequently, the software procedures adopted by the system according to the present invention will be described in a more detailed manner.","Request of Event Parameters","The GUI manager  comprises a software procedure , called interface builder. A first task of the interface builder  is that of building a graphical representation of the event parameters, by requesting such parameters to the server. The request of parameters to the server is effected through a remote procedure call (RPC), using a client proxy . A client proxy, known as such, is a software object encapsulating remote procedure calls. The client proxy  communicates with a server stub , located on the server side. A server stub is known as such and its function is substantially specular to that of a client proxy. The event parameters requested by the interface builder  are accessed by the theatre descriptor . The theatre descriptor  is a software object activated by the request of the interface builder , which operates by reading event information from a database on the server (not shown in the figures) and returning the event parameters to the client","Streaming","As soon as the event parameters are returned to the client, the interface builder  requests the server to start streaming, the initial point of view being a predefined point of view of the event In this respect, the interface builder  activates a further software procedure  on the server side, called session manager. The session manager  first reads the audio and video files to be streamed, by creating a stream reading procedure , called stream reader. The stream reader  receives the outputs of the audio-video files  and preloads audio and video samples from each point of view in corresponding vectors. Once the audio and video samples are ready to be streamed to the client, the session manager  generates a stream producer . The stream producer  is a software procedure responsible for performing a streaming session on the server side. More specifically, the stream producer  has the task of establishing a persistent connection with the client, sending stream global parameters to the client, and then sending the audio and video samples to the client.","On the client side, the interface builder  creates a stream consumer  and a stream renderer . The stream consumer  will receive samples from the stream producer , while the stream renderer  will render both the audio and the video streams. The GUI manager  also comprises an interface renderer , for rendering the user interface. More specifically, the interface renderer  provides an abstraction layer which takes care of details such as the operating system, the windowing interface, and the container application, like for example a Web browser. Should this be the case, the user could receive multimedia and interactive information inside the browser window at the same time as he is receiving the streaming data. The interface renderer  receives instructions to render the specific user interface by means of a local method call.","Switching","As a consequence of what described above, the user can enjoy the event on the video window . The user can now switch from the current point of view to a different point of view by interacting, for example with the click of a mouse button, with active icons representing alternative points of view. These icons are shown as elements I . . . In in the GUI  of . As soon as the user sends a switching request, a method of the user event manager  is activated. The user event manager  is a software object which is operating system dependent. The switching request is sent from the user event manager  to the server session manager , and from the server session manager  to the stream reader . The stream reader  does not alter the streaming of the audio samples along connection , but activates the streaming of a different video sample, corresponding to the requested point of view. In order to minimize the loss of quality when switching between video files, the switching preferably occurs when a key frame of the video samples corresponding to the requested point of view is encountered, as later explained in better detail. As soon as such key frame is encountered, the new point of view is streamed to the client.","Consequently, even when switching between different points of view, the bandwidth of the streaming connection operated by the present invention, i.e. the network connection  between the stream producer  on the server side and the stream consumer  on the client side, is the average bandwidth of a single audio\/video stream, and not the cumulative bandwidth of the n audio\/video streams, one for each point of view, as in the prior art systems of .","The preferred embodiment of the present invention considers the case in which a single audio file and a plurality of video files, each video file representing a distinct point of view, are provided. However, different embodiments are also possible where a single video file and a plurality of audio files, each audio file representing a different point of listening or a different audio source, are provided. Finally, also an embodiment with plural audio files and plural video files is possible. In the case of a single video file and a plurality of audio files, switching between audio files will occur without altering the streamed video file. In the case of multiple video files and multiple audio files, switching will occur either on video files without altering the streamed audio file, or on audio files without altering the streamed video file. Should also the audio frames be provided with a key-frame technology, the audio switching preferably occurs when an audio key frame is encountered.","The system according to the present invention is a distributed application. A first way of implementing the system according to the invention provides for personal computers on the client side and two server stations on the server side, the first server station comprising the streaming server  and the second server station comprising the feed distributor . A second way provides for personal computers on the client side and one server station on the server side, the latter comprising both the streaming server  and the feed distributor . In this, way installation and maintenance of the system are easier and the communication time (latency) between the streaming server and the streaming distributor is reduced. A third way provides for both the client and the server residing on the same machine. A first example of this last embodiment is when the contents are distributed by means of a medium like a CD-ROM, where the use of a single machine is preferred. A second example is when the contents are distributed in a place like an opera theatre, where each spectator is provided with an interactive terminal, used nowadays to allow the spectator to choose the captioning for the performance he is viewing in that moment, as adopted, for example, by the Metropolitan Theatre in New York. In that case, each spectator would be provided with a simple graphic interface (thin client), and the bulk of the system would reside on a single machine, for example a multiprocessor server with a Unix\u2122 operating system. By managing different cameras, the spectator could use the present invention like some sort of \u201celectronic opera glass\u201d.","The preferred embodiment of the present invention is described with reference to a single server computer and to a single client operating in a Windows\u2122 environment, where the single client is representative of n different clients which can be connected to the server. The client computer can, for example, be a Pentium III\u2122, 128 MB RAM, with a Windows 98\u2122 operating system. The server computer can, for example, be a Pentium III\u2122, 512 MB RAM, with a Windows 2000 Server\u2122 operating system. Visualization can occur on a computer monitor, a television set connected to a computer, a projection TV or visualization peripherals such as the PC Glasstron\u2122 by Sony.","Data streaming services can adopt a unicasting model or a multicasting model. In the unicasting model, every recipient is sent his own stream of data. A unique session is established between the unique IP address of the server and the unique IP address of the client. In the multicasting model, one single stream of data reaches the various users through routers. There is a single broadcast IP address for the server, which is used as a source of data for the different IP addresses of the various clients. However, in the current implementation over the Internet, routers first ignore and then discard multicast packets. Typically, routers are not configured to forward multicast packets. As a consequence, the present invention preferably embodies a unicasting model. Moreover, the waste of bandwidth of the unicast method, i.e. multiple copies of the same data one for each client, is here an advantage because each client can personalize his or her own show.","Advantageously, in the present invention, a particular user can control the switching between points of view or between listening points for a number of other user. Further, it is also possible for switching commands to be preprogrammed, so that a switching between points of view or listening points occurs automatically, unless differently operated by the user.","The operation of the system according to the present invention will be now described in greater detail.","Request of Event Parameters","As soon as a client application is started, a specific event is requested. This request can, for example, occur through a specific command line argument. From the point of view of the client application, an event is preferably described by the following event parameters:\n\n","These parameters are used by the client application to build the user interface for the requested event. More specifically, the client application should build:\n\n","Parameters 3), 5), and 7) will be stored for future use, later described in better detail.","As already explained above, the interface builder  is a software object whose task is that of building the above parameters. A C++ language definition of the interface builder  (CInterfaceBuilder) is, for example, the following:",{"@attributes":{"id":"p-0045","num":"0054"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class CInterfaceBuilder {"]},{"entry":[{},"public:"]},{"entry":[{},"..."]},{"entry":[{},"void BuildInterface(long int eventId);"]},{"entry":[{},"..."]},{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Throughout the present specification, the C++ programming language will be used to describe the functions, procedures and routines according to the present invention. Of course other programming languages could be used, like for example C, Java, Pascal, or Basic.","In order to build the above parameters on the client side, the interface builder  will request such parameters to the server, by means of a remote procedure call (RPC). A remote procedure call is sometimes also known as remote function call or remote subroutine call and uses the client\/server model. More specifically, a remote procedure call is a protocol used by a program located in a first computer to request a service from a program located in a second computer in a network, without the need to take into account the specific network used. The requesting program is a client and the service-providing program is the server. Like a regular or local procedure call, a remote procedure call is a synchronous operation requiring the requesting program to be suspended until the results of the remote procedure are returned.","In the preferred embodiment of the present invention, the remote procedure call is comprised in the client proxy  on the client side. A proxy is an interface-specific object that provides the \u201cparameter marshaling\u201d and the communication required to a client, in order to call an application object running in a different execution environment, such as on a different thread or in another process or computer. The proxy is located on the client side and communicates with a corresponding stub located within the application object being called. The term \u201cparameter marshaling\u201d indicates the process of packaging, sending, and unpackaging interface method parameters across thread or process boundaries.","For a generic description of SOAP (Simple Object Access Protocol) binding of request-response remote procedure call operation over the HTTP protocol, reference can be made to http:\/\/msdn.microsoftcom\/xml\/general\/wsdl.asp. A generic SOAP client (\u201cMSSOAP.SoapClient\u201d) is provided on http:\/\/msdn.microsoft.com\/code\/sample.asp?url=\/msdn-files\/027\/001\/580\/msdncompositedoc.xml. The SOAP client, when used through its high-level API (Application Programming Interface, with reference to RPC-oriented operations) is a fully functional example, in the Windows\u2122 environment, of a client proxy like the client proxy  of the present application.","A C++ language definition of the client proxy  (CClientProxy) can, for example, be the following:",{"@attributes":{"id":"p-0051","num":"0060"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"class CClientProxy {"},{"entry":"public:"},{"entry":"CClientProxy(std::string serverConnectionString);"},{"entry":"..."},{"entry":"void GetEventParameters(long int eventId,"},{"entry":"std::string& eventParameters);"},{"entry":"void EstablishVirtualConnection(long int eventId, long int& sessionId);"},{"entry":"void Play (long int sessionId, long int povId,"},{"entry":"std::string& connectionString);"},{"entry":"void SwitchPOV(long sessionId, long povId);"},{"entry":"..."},{"entry":"};"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}},"br":{}},"It is assumed that the procedure Interface Builder  encapsulates a pointer to an object of the C++ class CClientProxy. The client application creates this object during the initialization thereof and passes this object to the Interface Builder  as a constructor parameter, according, for example, to the following class, where the term class is intended in its C++ meaning.",{"@attributes":{"id":"p-0053","num":"0062"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class CInterfaceBuilder {"]},{"entry":[{},"public:"]},{"entry":[{},"CInterfaceBuilder(CClientProxy* clientProxy):"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},{"sup":"\u2003"}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"..."]},{"entry":[{},"private:"]},{"entry":[{},"CClientProxy* mClientProxy;"]},{"entry":[{},"..."]},{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The request by the interface builder  of the event parameters to the server using the client proxy  is syntactically equivalent to a regular (local) method call:",{"@attributes":{"id":"p-0055","num":"0064"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"void CInterfaceBuilder::BuildInterface(long int eventId) {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2003\u2003std::string",{"sup":"\u2009"}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003\u2003mClientProxy\u2212>GetEventParameters(eventId, eventParameters);"]},{"entry":[{},"\u2003..."]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":[{},{},{}],"in-line-formulae":[{},{}]},"The remote procedure call details are encapsulated in the server stub  on the server side. A server stub is an interface-specific object that provides the \u201cparameter marshaling\u201d and communication required for an application object to receive calls from a client running in a different execution environment, such as on a different thread or in another process or computer. The stub is located with the application object and communicates with a corresponding proxy located within the client effecting the call. For a description of a server stub, reference is made again to http:\/\/msdn.microsoft.com\/code\/sample.asp?url=\/msdn-files\/\/\/\/msdncompositedoc.xml, where a SOAP server (listener) is provided, which wraps COM (Component Object Model) objects exposing their methods to remote callers, such as MSSOAP.SoapClient. The object described in the cited reference is an example, in the Windows\u2122 environment, of the server stub .","The Theatre Descriptor  is a software object activated by the remote method call GetEventParameters of the interface builder , above described.",{"@attributes":{"id":"p-0058","num":"0067"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"class CTheatreDescriptor {"},{"entry":"public:"},{"entry":"void GetEventParameters(long int eventId, std::string& eventParameters);"},{"entry":"void GetServerEventParameters(long int eventId,"},{"entry":"std::string& audioFilepath,"},{"entry":"std::vector<std::string>& videoFilepaths, std::vector<long>& povIds);"},{"entry":"};"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The Theatre Descriptor  reads event information from a RDBMS (Relational Database Management System), using the primary key eventId, and returns the event parameters to the interface builder . An XML string expressing the operation of the Theatre Descriptor  is for example the following:",{"@attributes":{"id":"p-0060","num":"0069"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"266pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"<EVENT_PARAMETERS>"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2002<POINTS_OF_VIEW_NUMBER>3<\/POINTS_OF_VIEW_NUMBER>"]},{"entry":[{},"\u2002<DEFAULT_POINT_OF_VIEW_ID>1<\/DEFAULT_POINT_OF_VIEW_ID>"]},{"entry":[{},"\u2002<POINTS_OF_VIEW>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2009<POINT_OF_VIEW>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2009<\/POINT_OF_VIEW>"]},{"entry":[{},"\u2009<POINT_OF_VIEW>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2009<\/POINT_OF_VIEW>"]},{"entry":[{},"\u2009<POINT_OF_VIEW>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2009<\/POINT_OF_VIEW>"]},{"entry":[{},"\u2009<\/POINTS_OF_VIEW>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2002<MAIN_WINDOW>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2009<WIDTH>320<\/WIDTH>"]},{"entry":[{},"\u2009<HEIGHT>240<\/HEIGHT>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"252pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2002<\/MAIN_WINDOW>"]},{"entry":[{},"\u2002<BANDWIDTH_KBPS>300<\/BANDWIDTH_KBPS>"]},{"entry":[{},"\u2002<DURATION_SEC>3600<\/DURATION_SEC>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"266pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"<\/EVENT_PARAMETERS>"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"As soon as the remote procedure call is returned to the interface builder , the interface builder  parses the XML string and stores the event parameters. XML parsing techniques are known per se. A known software product adopting such techniques is, for example, Microsoft XML Parser\u2122.","The Interface Renderer ","The interface builder  instructs the interface renderer  to render the specific user interface by means of a local method call, for example:",{"@attributes":{"id":"p-0063","num":"0072"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"class CInterfaceRenderer {"},{"entry":"public:"},{"entry":"CInterfaceRenderer( ) {}"},{"entry":"void RenderInterface(std::string& GUIInterfaceDescription);"},{"entry":"..."},{"entry":"};"},{"entry":"..."},{"entry":"void CInterfaceBuilder::BuildInterface(long int eventId) {"},{"entry":"..."},{"entry":"CInterfaceRenderer* mInterfaceRenderer;"},{"entry":"}"},{"entry":"..."},{"entry":"void CInterfaceBuilder::BuildInterface(long int eventId) {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2002..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2002long int","\u2002initialPointOfView;"]},{"entry":[{},"\u2002..."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2002\/\/ store events parameters"]},{"entry":[{},"\u2002..."]},{"entry":[{},"\u2002\/\/ generates abstract graphical user interface definition string (an"]},{"entry":[{},"\u2002XML string)"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2002std::string","\u2009\u2009GUIInterfaceDescription;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2002..."]},{"entry":[{},"\u2002mInterfaceRenderer = new CInterfaceRenderer;"]},{"entry":[{},"\u2002mInterfaceRenderer\u2212>RenderInterface(GUIInterfaceDescription);"]},{"entry":[{},"\u2002..."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"The string GUIlnterfaceDescription of the above local method call is an abstract definition of the GUI. A definition in XML language of the GUI is for example the following:",{"@attributes":{"id":"p-0065","num":"0074"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"<GUI_INTERFACE>"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},{"sup":"\u2009\u2009"}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2009\u2009<X>10<\/X>"]},{"entry":[{},"\u2009\u2009<Y>10<\/Y>"]},{"entry":[{},"\u2009\u2009<WIDTH>320<\/WIDTH>"]},{"entry":[{},"\u2009\u2009<HEIGHT>240<\/HEIGHT>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2009\u2009<X>100<\/X>"]},{"entry":[{},"\u2009\u2009<Y>10<\/Y>"]},{"entry":[{},"\u2009\u2009<CAPTION>Front<\/CAPTION>"]},{"entry":[{},"\u2009\u2009<POINT_OF_VIEW_ID>1<\/POINT_OF_VIEW_ID>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2009\u2009<X>150<\/X>"]},{"entry":[{},"\u2009\u2009<Y>10<\/Y>"]},{"entry":[{},"\u2009\u2009<CAPTION>Left<\/CAPTION>"]},{"entry":[{},"\u2009\u2009<POINT_OF_VIEW_ID>2<\/POINT_OF_VIEW_ID>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2009\u2009<X>200<\/X>"]},{"entry":[{},"\u2009\u2009<Y>10<\/Y>"]},{"entry":[{},"\u2009\u2009<CAPTION>Right<\/CAPTION>"]},{"entry":[{},"\u2009\u2009<POINT_OF_VIEW_ID>3<\/POINT_OF_VIEW_ID>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]},{"entry":[{},{"sup":"\u2009\u2009"}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"<\/GUI_INTERFACE>"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"The interface renderer  uses the services provided by the operating system, the windowing interface or the container application to render the correct user interface.","Detailed Description of the Streaming Operation","As already explained above, the interface builder , on return of the local method call BuildInterface, requests start of streaming. The initial point of view is the default point of view above defined. Usually, RPC-oriented SOAP over HTTP connections are not persistent. As a consequence, the interface builder  must first establish a virtual persistent session with the server. This can be done by means of the following remote method call:",{"@attributes":{"id":"p-0068","num":"0077"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["long int","\u2009gSessionId;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"..."},{"entry":"void CInterfaceBuilder::BuildInterface(long int eventId) {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"..."]},{"entry":[{},"mClientProxy\u2212>EstablishVirtualSession(eventId, gSessionId);"]},{"entry":[{},"..."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"br":[{},{},{}],"in-line-formulae":[{},{}],"b":["26","26"]},{"@attributes":{"id":"p-0069","num":"0078"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"class CSessionData {"},{"entry":"public:"},{"entry":"CSessionData(long int eventId):"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2002mEventId(eventId) {}"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"..."},{"entry":"long int GetEventId() {return mEventId;}"},{"entry":"..."},{"entry":"private:"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"238pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["long int","\u2009mEventId;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"..."},{"entry":"};"},{"entry":"..."},{"entry":"class CServerSessionManager {"},{"entry":"public:"},{"entry":"..."},{"entry":"void EstablishVirtualSession(long int eventId, long int& sessionId);"},{"entry":"void Play(long int sessionId, long int povId, std::string& connectionString);"},{"entry":"void SwitchPOV(long int sessionId, long int povId);"},{"entry":"..."},{"entry":"private:"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["CTheatreDescriptor*",{"sup":"\u2009"}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"119pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["std::map<long int, CSessionData*>","mSessions;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"..."},{"entry":"};"},{"entry":"..."},{"entry":"void CServerSessionManager::EstablishVirtualSession(long int eventId, long int& sessionId) {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"sup":"\u2003"}]},{"entry":[{},{"sup":"\u2003"}]},{"entry":[{},{"sup":"\u2003"}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"It can be assumed, without loss of generality, that mTheatreDescriptor is a pointer to an instance of the Theatre Descriptor . On the client side, gSessionId is a global variable which is accessible from all application objects.","The interface builder  can perform streaming by means, for example, of the following remote procedure call:",{"@attributes":{"id":"p-0072","num":"0081"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"void CInterfaceBuilder::BuildInterface(long int eventId) {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"..."]},{"entry":[{},"std::string \u2003\u2003\u2003connectionString."]},{"entry":[{},"..."]},{"entry":[{},"mClientProxy\u2212>Play(gsessionId, initialPointOfView,"]},{"entry":[{},"connectionString);"]},{"entry":[{},"..."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"where"]},{"entry":[{},"void Play (long int sessionId, long int povId, std::string&"]},{"entry":[{},"connectionString);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{},"b":"26"},{"@attributes":{"id":"p-0073","num":"0082"},"tables":{"@attributes":{"id":"TABLE-US-00012","num":"00012"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"void CServerSessionManager::Play(long int sessionId, long int povId,"},{"entry":"std::string& connectionString) {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"CSessionData*","\u2002callerSessionData = mSessions [sessionId];"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"long int","eventId = callerSessionData\u2212>GetEventId();"]},{"entry":[{},"long int","defaultPovId;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"std::vector<long>","\u2002povIds;"]},{"entry":[{},"std::string","\u2002audioFilepath;"]},{"entry":[{},"std::vector<std::string>","videoFilepaths;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"mTheatreDescriptor\u2212>GetServerEventParameters(eventId,"]},{"entry":[{},"audioFilepath, videoFilepaths, povIds);"]},{"entry":[{},"..."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"br":{}},{"@attributes":{"id":"p-0074","num":"0083"},"tables":{"@attributes":{"id":"TABLE-US-00013","num":"00013"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"void GetServerEventParameters (long eventId, std::string& audioFilepath,"},{"entry":"std::vector<std::string>& videoFilepaths, std::vector<long>& povIds);"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}},"br":{},"b":"28"},"On return, the server session manager  knows the path of the file containing the audio samples and the path of each file containing the video samples. In the preferred embodiment of the present invention, each video file refers to a different point of view. The video file paths are stored in the STL (Standard Template Library) vector videoFilepaths. The logic identifiers of the points of view, which are the same as those returned from the theatre descriptor  to the client by GetEventParameters, are stored in the above defined STL vector povIds. A standard template library (STL) is a C++ library which uses templates to provide users with an easy access to powerful generic routines. The STL is now part of the C++ standard.","At this point, the server session manager  creates an instance of the above described software object stream reader  and instructs the stream reader  to read the files returned from GetServerEventParameters. A partial C++ definition of the class CStreamReader is, for example, the following:",{"@attributes":{"id":"p-0077","num":"0086"},"tables":{"@attributes":{"id":"TABLE-US-00014","num":"00014"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"class CStreamReader {"},{"entry":"public:"},{"entry":"CStreamReader(std::string& audioFilepath, std::vector<std::string>&"},{"entry":"videoFilepaths, std::vector<long>& povIds, long initialPovId);"},{"entry":"..."},{"entry":"};"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The following is a continuation of the implementation of the \u201cPlay\u201d method of the server session manager :",{"@attributes":{"id":"p-0079","num":"0088"},"tables":{"@attributes":{"id":"TABLE-US-00015","num":"00015"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"void CServerSessionManager::Play(long int sessionId, long int povId,"},{"entry":"std::string& connectionString) {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"..."]},{"entry":[{},"CStreamReader* \u2003\u2003streamReader = new CStreamReader"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"(audioFilepath, videoFilepaths, povIds, povId);"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"callerSessionData\u2212>SetStreamReader(streamReader);"]},{"entry":[{},"..."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"CSessionData will encapsulate the stream reader  of its session according to the following definitions:",{"@attributes":{"id":"p-0081","num":"0090"},"tables":{"@attributes":{"id":"TABLE-US-00016","num":"00016"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"class CSessionData {"},{"entry":"public:"},{"entry":"..."},{"entry":"void SetStreamReader(CStreamReader* streamReader) {mStreamReader ="},{"entry":"streamReader;}"},{"entry":"CStreamReader* GetStreamReader( ) {return mStreamReader;}"},{"entry":"..."},{"entry":"private:"},{"entry":"CStreamReader* \u2003\u2003mStreamReader;"},{"entry":"..."},{"entry":"};"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}},"br":{}},"A typical audio\/video file intended for streaming comprises a continuous succession of samples. Each sample is either a video sample or an audio sample.","Generally speaking, both audio and video samples are compressed. Each sample is univocally defined by sample attributes, like for example:\n\n","Each sample contains compressed raw sample data. A sample stream id identifies the sample stream. For example, a sample stream id equal to 1 can identify a video stream, and a sample stream id equal to 2 can identify an audio stream.","In each stream samples are stored by time order. Moreover, in the audio\/video file, video samples are interleaved with audio samples. The actual interleaving sequence is determined at the time of compression, according to explicit choices which relate to performance and optimal rendering considerations. A one-to-one interleaving (audio-video-audio-video . . .) will be assumed throughout the present application. The person skilled in the art will, of course, recognize also different interleaving sequences suitable for the purposes of the present application. According to the preferred one-to-one interleaving sequence, the content an audio\/video file can be represented as follows:\n\n","The timestamp of each sample depends on video parameters, mainly on the number of frames per second (fps) of the video stream. If a video stream contains 25 frames per second, each video sample has a timestamp that is a multiple of 40 ms. Audio samples are timed in a corresponding manner, in order to obtain interleaving. With reference to the above example, the following is obtained:\n\n","A C++ representation of a generic sample can for example be the following:",{"@attributes":{"id":"p-0088","num":"0116"},"tables":{"@attributes":{"id":"TABLE-US-00017","num":"00017"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"struct generic_sample {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"long int","sampleStreamId;"]},{"entry":[{},"long int","sampleTime;"]},{"entry":[{},"long int","sampleDuration;"]},{"entry":[{},"long int","sampleSize;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"bool","isKeyFrame;"]},{"entry":[{},"void*","sampleRawData;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"A generic stream can be represented as a STL vector of samples:",{"@attributes":{"id":"p-0090","num":"0118"},"tables":{"@attributes":{"id":"TABLE-US-00018","num":"00018"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"std::vector<generic_sample>","videoStream;"]},{"entry":[{},"std::vector<generic_sample>","audioStream;"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"Once a stable network connection has been established, a streaming session on the server side comprises the following steps:\n\n","As soon as the last iteration is terminated, the connection is closed.","Streaming of Audio\/video Samples from Server to Client","At the application layer, data are sent by the server and received by the client in accordance with one of a plurality of known application-level protocols. For example, data are sent in a binary mode for optimum performance. Alternatively, data are packaged to compensate for different byte-ordering on the client side.","At the transport layer, data can be sent using reliable (with error checking) or unreliable (without error checking) protocols. For example, TCP (Transfer Control Protocol) is a reliable protocol, while UDP (User Datagram Protocol) is an unreliable protocol. Most streaming servers allow the client to choose between unreliable (and intrinsically faster, due to less overhead) and reliable transport protocols. In the case of unreliable protocols, the loss of stream samples due to the absence of an error checking feature is compensated by the client with various algorithms related to the optimal rendering of streams on the client side. Such algorithms are known to the person skilled in the art and will not be described here in detail. In the following, the TCP (transfer control protocol) will be used, without loss of generality. For a more detailed discussion of the TCP protocol, reference is made to \u201cTCP\/IP Illustrated, Volume 1\u2032\u201d, W. Richard Stevens\u2014The Protocols\u2014Addison\u2014Wesley Publishing Company\u201410Printing\u2014Jul. 1997, in particular with reference to the following fields: Network Layering, TCP, UDP, TCP connection establishment and termination; TCP interactive data flow, TCP bulk data flow, and TCP timeout and retransmission.","With reference to the exact timing of the transmission of the samples, the main goal of the streaming technology is that of having the sample on the client side when needed. With reference to a generic video sample N and relative to the sampleTime of the first video sample, which can be set to zero without loss of generality, this can be expressed in C++ with the instruction\n\nVideoStream[N].sampleTime\n","Two additional factors have to be considered:\n\n","A combined client\/server data sending algorithm suitable for the purposes of the present invention comprises the following steps:\n\n","The second step can be performed by means of a variety of methods. For example, the client could delay acknowledgement of the samples to prevent buffer overrun, or could explicitly request the next sample or samples. The request is part of the application-level protocol. In the preferred embodiment of the present invention, it will be assumed that the client delays the acknowledgement of the samples \u201cas needed\u201d More specifically, no delay is present during the pre-buffering step, and adaptive delay is used during the second step, to prevent overrun of the subsequent samples while maintaining the buffer full, on average. With this assumption, a C++ implementation of the second step can be as follows:",{"@attributes":{"id":"p-0099","num":"0138"},"tables":{"@attributes":{"id":"TABLE-US-00019","num":"00019"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"long \u2003IVideo = 0;"]},{"entry":[{},"long \u2003IAudio = 0;"]},{"entry":[{},"while (IVideo < videoStream.size( )) {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"SendToClient(videoStream[IVideo++]);"]},{"entry":[{},"SendToClient(audioStream[IAudio++]);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":[{},{},{},{}],"in-line-formulae":[{},{}],"b":"40"},"A more detailed C++ definition of the stream reader  is the following:",{"@attributes":{"id":"p-0101","num":"0140"},"tables":{"@attributes":{"id":"TABLE-US-00020","num":"00020"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"class CStreamReader {"},{"entry":"..."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["public:",{}]},{"entry":["void","SetRequestedPov(long povId) {mRequestedPov = povId;}"]},{"entry":["long","GetSamplesNumber( ) {return mAudioStream.size( );}"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["generic_sample","GetCurrentSample();"]},{"entry":"..."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["private:",{}]},{"entry":["bool","mLastSampleIsVideo;"]},{"entry":["long","mRequestedPov;"]},{"entry":["long","mCurrentPov;"]},{"entry":["long","mCurSample;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"140pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["std::map<long, std::vector<generic_sample>>","mVideoStreams;"]},{"entry":["std::vector<generic_sample>","\u2002mAudioStream;"]},{"entry":"..."},{"entry":"};"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"More specifically, it is assumed that the stream reader  (CStreamReader) preloads audio samples in a STL vector (mAudioStream), and preloads video samples from each point of view in STL vectors. These vectors (in a number of n, one for each point of view) are stored as values in a STL map (mVideoStreams) whose keys are the logic identifier of the points of view. The current point of view is stored in the data member mCurrentPov. The current sample is stored in the data member mCurSample. The initial value of mCurSample is 0. The details of preloading the samples from the files will not be described in detail in the present application because methods to fill memory structures from input file streams (the term stream being used here in the STL meaning) are well known to the person skilled in the art.","The current audio\/video samples are obtained from the files FA and FVl . . FVN  (see ) by means of the method GetCurrentSample. An implementation of the method GetCurrentSample of CStreamReader is the following:",{"@attributes":{"id":"p-0104","num":"0143"},"tables":{"@attributes":{"id":"TABLE-US-00021","num":"00021"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"generic_sample CStreamReader::GetCurrentSample() {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"generic_sample\u2003\u2003currentSample;"]},{"entry":[{},"if (mLastSampleIsVideo) {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003\/\/outputs audio"]},{"entry":[{},"\u2003\/\/accesses current sample"]},{"entry":[{},"\u2003currentSample = mAudioStream[mCurSample];"]},{"entry":[{},"\u2003mLastSampleIsVideo = false;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"else {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003\/\/outputs video."]},{"entry":[{},"\u2003\/\/selects correct stream in map using requested point of"]},{"entry":[{},"\u2003view as the key"]},{"entry":[{},"\u2003\/\/then accesses current sample"]},{"entry":[{},"\u2003currentSample = (mVideoStreams[mRequestedPov])"]},{"entry":[{},"\u2003[mCurSample];"]},{"entry":[{},"\u2003mLastSampleIsVideo = true;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"mCurSample++;"]},{"entry":[{},"return currentSample;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"It is assumed that in the CStreamReader constructor the data member mLastSampleIsVideo has been initially set to false, so that the first output sample of the interleaved sequence is a video sample. The mRequestedPov initialization will be described later.","Switching (Server Side)","The stream reader  (CStreamReader) comprises an access method SetRequestedPov which allows switching of the point of view. In particular, once the value of the variable mRequestedPov of CStreamReader has been modified by means of the access method SetRequestedPov, the method GetCurrentSample of CStreamReader begins (on the following calls) to output video samples of the new point of view to the streaming server . It has to be noted that the output of audio samples is unaffected by this method. As a consequence, the switching of point of view has no audible effect.","With reference to the quality of the video after switching, the following should be considered. A video frame is usually both statically and dynamically compressed. Static compression is obtained by use of methods deriving from static image compression. With dynamic compression, a differential compression of each sample with reference to the previous sample is intended. As a consequence, a random switch would degrade rendering on the client side. This is because the reconstruction of the full sample (known as differential decoding) would fail, due to the unavailability of a correct uncompressed base (i.e. previous) sample, because the actual previous sample belongs to a different stream. However, it is common that a video stream also comprises frames which are not differentially compressed. Such frames are known as \u201cstatic frames\u201d or \u201ckey frames\u201d. Usually, key frames are generated to avoid unacceptable degradation in video quality. Key frame generation follows both deterministic rules (for example, by generating a key frame every n frames, like  key frame every  frames) and adaptive rules (for example, by generating a key frame each time the encoder detects a sudden change in the video content). Deterministic rules avoid drifts in video quality caused by accumulation of small losses of video details through successive differential compressions. Adaptive rules avoid instantaneous degradation of video quality caused by intrinsic limits of differential encoding in presence of sudden changes in video content from one frame to the following. Key frame generation techniques, which depend on the encoder and the video source, are well known to the person skilled in the art A detailed description of such techniques is omitted, because known as such.","In the preferred embodiment, the present invention allows a smooth video switching without degradation of video quality by preferably ensuring that a switch takes place when a key frame of a video frame sample is generated. In this way, no loss of video quality occurs on the client side, since the client does not need the correct base (i.e. previous) sample to render the sample. Although waiting for a key frame would cause a switch which, technically speaking, is not instantaneous, the maximum delay, in case for example of video frames having 1 key frame every 8 frames, would be that of about 0.3 seconds. In order to perform switching by means of the procedure stream reader , the following is a preferred implementation of the above described method GetCurrenSample():",{"@attributes":{"id":"p-0109","num":"0148"},"tables":{"@attributes":{"id":"TABLE-US-00022","num":"00022"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"generic_sample CStreamReader::GetCurrentSample() {"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"generic_sample\u2003\u2003currentSample;"]},{"entry":[{},"if (mLastSampleIsVideo) {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"231pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/outputs audio"]},{"entry":[{},"\/\/accesses current sample"]},{"entry":[{},"currentSample = mAudioStream[mCurSample];"]},{"entry":[{},"mLastSampleIsVideo = false;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"else {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"231pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/outputs video."]},{"entry":[{},"if (mRequestedPov == mCurrentPov) {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003\/\/no switch requested"]},{"entry":[{},"\u2003\/\/selects correct stream in map using current point of view as the key"]},{"entry":[{},"\u2003\/\/then accesses current sample"]},{"entry":[{},"\u2003currentSample = (mVideoStreams[mCurrentPov])[mCurSample];"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"231pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"else {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003\/\/a switch was requested"]},{"entry":[{},"\u2003generic_sample\u2003\u2003newStreamSample;"]},{"entry":[{},"\u2003\/\/get current sample from new (requested) stream"]},{"entry":[{},"newStreamSample = (mVideoStreams[mRequestedPov])[mCurSample];"]},{"entry":[{},"if (newStreamSample.isKeyFrame) {"]},{"entry":[{},"\/\/current sample in new (requested) stream is a key frame"]},{"entry":[{},"\/\/so streams can be seamlessly switched"]},{"entry":[{},"mCurrentPov = mRequestedPov;"]},{"entry":[{},"\/\/output key frame sample from new (requested) stream"]},{"entry":[{},"currentSample = newStreamSample;"]},{"entry":[{},"}"]},{"entry":[{},"else {"]},{"entry":[{},"\/\/continue output of previous stream"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"currentSample = mVideoStreams[mCurrentPov])[mCurSample];"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"}"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"231pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"mLastSampleIsVideo = true;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"mCurSample++;"]},{"entry":[{},"return currentSample;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"It is here assumed that, when constructing CStreamReader, both the mRequestedPov and the mCurrentPov data members are set to the value of the identifier of the initial point of view, which is the parameter initialPovId of the CStreamReader constructor.","In conclusion, the control unit  instructs the feed distributor  to switch between a first video file and a second video file when a key frame of the second video file is encountered. In the case where the audio files are differentially compressed before streaming and comprise key frames, the control unit  can similarly instruct the feed distributor (13) to switch between a first audio file and a second audio file when a key frame of the second audio file is encountered.","Detailed Description of the Method Play of the Server Session Manager ","The stream producer  is responsible for performing a streaming session on the server side. More specifically, after having initialized a new instance of the stream reader  and having stored the pointer to the stream reader  in CSessionData for later retrieval, the server session manager  creates a new instance of the software object stream producer , according to the following exemplary code:",{"@attributes":{"id":"p-0113","num":"0152"},"tables":{"@attributes":{"id":"TABLE-US-00023","num":"00023"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"class CStreamProducer{"},{"entry":"public:"},{"entry":"CStreamProducer(CStreamReader* streamReader):"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"mStreamReader(streamReader) {}"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"std::string&\u2003\u2003BeginStreamingSession();"},{"entry":"..."},{"entry":"private:"},{"entry":"CStreamReader* mStreamReader;"},{"entry":"static void ThreadStreamingSession(void* pParm);"},{"entry":"..."},{"entry":"};"},{"entry":"..."},{"entry":"void CServerSessionManager::Play(long int sessionId, long int povId,"},{"entry":"std::string&"},{"entry":"connectionString) {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"..."]},{"entry":[{},"CStreamProducer* streamProducer ="]},{"entry":[{},"new CStreamProducer(streamReader);"]},{"entry":[{},"callerSessionData->SetStreamProducer(streamProducer);"]},{"entry":[{},"connectionString = streamProducer->BeginStreamingSession();"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":"CSessionData encapsulates the stream producer 34 in the following way:"},{"entry":"class CSessionData {"},{"entry":"public:"},{"entry":"..."},{"entry":"void SetStreamProducer(CStreamProducer* streamProducer)"},{"entry":"{mStreamProducer ="},{"entry":"streamProducer;}"},{"entry":"..."},{"entry":"private:"},{"entry":"CStreamProducer*\u2003\u2003mStreamProducer;"},{"entry":"..."},{"entry":"};"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"The method BeginStreamingSession of CStreamProducer returns control to the caller immediately after having created a new thread associated with the execution of the static method ThreadStreamingSession, which controls the streaming session. Execution of threads per se is well known in the prior art and will not be discussed in detail. The variable connectionstring (which will be passed by reference when returning to the client) contains the specific connection string the client must use to connect to the stream producer . For a TCP\/IP connection, a connection stream is in the form protocol:\/\/server-ip-address-or-name:port-number.","Although the definition of the method CStreamProducer is operating system specific and will be here described with reference to the Windows\u2122 environment, the person skilled in the art will easily recognize those minor changes that will allow the method to be executed in different environments.","As already explained above, in a streaming session the stream producer  first establishes a persistent connection with the client, then sends stream global parameters to the client, and finally sends samples to the client. The loop for sending samples becomes the following:",{"@attributes":{"id":"p-0117","num":"0156"},"tables":{"@attributes":{"id":"TABLE-US-00024","num":"00024"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"void CStreamProducer::ThreadStreamingSession(void* pParm) {"},{"entry":"\/\/listen for client connection request"},{"entry":"..."},{"entry":"\/\/establish connection"},{"entry":"..."},{"entry":"\/\/send stream global parameters"},{"entry":"..."},{"entry":"\/\/send all samples"},{"entry":"\/\/We assume that \u201cthis\u201d pointer was cast to a void pointer"},{"entry":"\/\/and passed as pParm during thread creation."},{"entry":"\/\/For example in a Windows environment"},{"entry":"\/\/_beginthread(ThreadStreamingSession,"},{"entry":"NULL, static_cast<void*>(this));"},{"entry":"\u2003CstreamProducer*\u2003thisPtr = static_cast<CStreamProducer*>(pParm);"},{"entry":"\u2003for (long I = 0; I < thisPtr->mStreamReader->GetSamplesNumber();"},{"entry":"\u2003I++) {"},{"entry":"\u2003\u2003\u2003SendToClient(thisPtr->mStreamReader->GetCurrentSample());"},{"entry":"\u2003}"},{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"As shown in the loop, the point of view whose samples are sent to the client is determined by the value of the logic point of view identifier stored in the data member mCurrentPov of the stream reader  (CStreamReader).","Routines that can be called from multiple programming threads without unwanted interaction between the threads are known as thread-safe. By using thread-safe routines, the risk that one thread will interfere and modify data elements of another thread is eliminated by circumventing potential data race situations with coordinated access to shared data. It is possible to ensure that a routine is thread-safe by making sure that concurrent threads use synchronized algorithms that cooperate with each other.","According to the present invention, an object of the class CStreamReader should be thread-safe (this is, for example, mandatory when using C++), since the critical variable (data member) of the class, mCurrentPov, is indirectly accessed by two different threads, namely by methods of CServerSessionManager and by CStreamProducer::ThreadStreamingSession, which is executed in another thread. Access to the critical variable mCurrentPov of CStreamReader must be synchronized using synchronization objects. Thread-safe access to critical data through synchronization is well known as such to the person skilled in the art and will not be here discussed in detail.","Receiving Audio\/Video Samples on the Client Side","On the client side, on return of the remote method call mClientProxy.Play of the interface builder , the interface builder  creates the software objects \u201cstream consumer\u201d  and \u201cstream renderer\u201d . The stream consumer  receives the samples from the stream producer , while the stream renderer  renders the received samples.","The stream rendering operation is operating system dependent. The stream renderer  operates by decompressing video samples and displaying video samples (with proper timing according to the timestamps of the video samples) as static raster images using the main video window created by the interface builder . This video window is accessible to the stream renderer  by means, for example, of a global pointer to the main video window initialized by the interface builder . The stream renderer  must be able to decompress audio samples and play them (with proper timing according to timestamps of audio samples) as audio chunks, using services from the operating system, or from the multimedia API of the stream renderer itself.","The stream consumer : ) implements the client side portion of the streaming session; 2) is connected to the stream producer  by means of the connection string defined above; 3) receives the global stream parameters;4) pre-buffers the content as needed; and 5) enters a loop to receive all samples from the stream producer , delaying acknowledges of the samples to maintain the buffer full on average, as already explained above. A C++ expression of the stream consumer  and of the stream renderer  can be as follows:",{"@attributes":{"id":"p-0124","num":"0163"},"tables":{"@attributes":{"id":"TABLE-US-00025","num":"00025"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"class CStreamRenderer {"},{"entry":"public:"},{"entry":"..."},{"entry":"void RenderSample(generic_sample curSample);"},{"entry":"\/\/implementation is operating system specific"},{"entry":"..."},{"entry":"};"},{"entry":"..."},{"entry":"class CStreamConsumer {"},{"entry":"public:"},{"entry":"CStreamConsumer (CStreamRenderer* streamRenderer, std::string&serverConnectionString):"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2002mStreamRenderer(streamRenderer),"]},{"entry":[{},"mServerConnectionString(serverConnectionString) {}"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"void\u2003\u2003\u2003BeginStreamingSession();"},{"entry":"..."},{"entry":"private:"},{"entry":"CStreamRenderer*\u2003\u2003mStreamRenderer;"},{"entry":"std::string\u2003\u2003\u2003\u2003mServerConnectionString;"},{"entry":"static void ThreadStreamingSession(void* pParm);"},{"entry":"..."},{"entry":"};"},{"entry":"..."},{"entry":"class CInterfaceBuilder {"},{"entry":"..."},{"entry":"private:"},{"entry":"CStreamConsumer* mStreamConsumer;"},{"entry":"CStreamRenderer* mStreamRenderer;"},{"entry":"..."},{"entry":"};"},{"entry":"..."},{"entry":"void CInterfaceBuilder::BuildInterface(long int eventId) {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"..."]},{"entry":[{},"mStreamRenderer = new CStreamRenderer;"]},{"entry":[{},"mStreamConsumer = new CStreamConsumer(mStreamRenderer, connectionString);"]},{"entry":[{},"mStreamConsumer->BeginStreamingSession();"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"The method BeginStreamingSession of the stream consumer  (CStreamConsumer) returns control to the caller immediately after creating a new thread associated with the execution of the static method ThreadStreamingSession, which takes care of the streaming session. For example:",{"@attributes":{"id":"p-0126","num":"0165"},"tables":{"@attributes":{"id":"TABLE-US-00026","num":"00026"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"void CStreamConsumer::ThreadStreamingSession(void* pParm) {"]},{"entry":[{},"\/\/request connection to server"]},{"entry":[{},"..."]},{"entry":[{},"\/\/establish connection"]},{"entry":[{},"..."]},{"entry":[{},"\/\/get streams global parameters"]},{"entry":[{},"..."]},{"entry":[{},"\/\/get all samples"]},{"entry":[{},"\/\/We assume that \u201cthis\u201d pointer was cast to a void pointer"]},{"entry":[{},"\/\/and passed as pParm during thread creation."]},{"entry":[{},"\/\/For example in a Windows environment"]},{"entry":[{},"\/\/_beginthread(ThreadStreamingSession,"]},{"entry":[{},"NULL, static_cast<void*>(this));"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003CStreamConsumer*\u2003\u2003thisPtr ="]},{"entry":[{},"\u2003static_cast<CStreamConsumer*>(pParm);"]},{"entry":[{},"\u2003generic_sample\u2003\u2003curSample;"]},{"entry":[{},"while (ReceiveFromServer(curSample)) {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2002thisPtr->mStreamRenderer->RenderSample(curSample);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"}"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":[{},{},{}],"in-line-formulae":[{},{}]},"Although the definition of the method CStreamConsumer::ThreadStreamingSession is operating system specific and will be here described with reference to the Windows\u2122 environment, the person skilled in the art will easily recognize those minor changes that will allow the method to be executed in different environments.","The stream consumer  implements pre-buffering using well-known standard pre-buffering techniques, which will not be described in detail.","As soon as the client side application has ended initialization, the main event loop is entered, which depends on the operating system. The stream consumer  receives samples from the stream producer  on a different execution thread. After each sample is received, the stream consumer  calls the method RenderSample of the stream renderer  (CStreamRenderer), which renders the sample.","Switching (Client Side)","The user can request a switch of current point of view by interacting, for example, with the click of a mouse button, with the active icons I . . In representing the alternative points of view. As soon as the user requests a switch of current point of view, an operating system (or windowing manager) event is triggered. Details on the handling of mouse events are operating system dependent Without loss of generality, it will be assumed that the appropriate event handler calls the method SwitchPOV of the user event manager . The call is effected after decoding the requested point of view logic id from the event parameters (the coordinates of the mouse click, from which a unique icon can be determined) or from the context In the latter case, the called event handler could be a method of the window class encapsulating the icon, the term class being here used in the C++ meaning. For example:",{"@attributes":{"id":"p-0131","num":"0170"},"tables":{"@attributes":{"id":"TABLE-US-00027","num":"00027"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class CUserEventManager {"]},{"entry":[{},"public:"]},{"entry":[{},"CUserEventManager(CClientProxy* clientProxy):"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"mClientProxy(clientProxy) {}"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"void SwitchPOV(long povId);"]},{"entry":[{},"..."]},{"entry":[{},"private:"]},{"entry":[{},"CClientProxy* mClientProxy;"]},{"entry":[{},"..."]},{"entry":[{},"};"]},{"entry":[{},"..."]},{"entry":[{},"void CUserEventManager::SwitchPOV(long povId) {"]},{"entry":[{},"mClientProxy.SwitchPOV(gSessionId, povId);"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":[{},{},{}],"in-line-formulae":[{},{}],"b":"26"},"The server session manager  (CServerSessionManager) retrieves the session data (encapsulated in a CSessionData object) from the session identifier sessionid, through the following exemplary use of the associative map:",{"@attributes":{"id":"p-0133","num":"0172"},"tables":{"@attributes":{"id":"TABLE-US-00028","num":"00028"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"void CServerSessionManager::SwitchPOV (long int sessionId,"]},{"entry":[{},"long int povId) {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"CSessionData*\u2003\u2003callerSessionData = mSessions[sessionId];"]},{"entry":[{},"CStreamReader*\u2003\u2003streamReader ="]},{"entry":[{},"callerSessionData->GetStreamReader();"]},{"entry":[{},"streamReader->SetRequestedPov(povId);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"As shown above, setting data member mRequestedPov of the Stream Reader  (CStreamReader) associated to session sessionId using its access member SetRequestedPov causes a switch of the video stream returned by the stream reader  (through its method GetCurrentSample) to the stream producer , and consequently sent from the stream producer  to the stream consumer  on the client side. The switch occurs in method GetCurrentSample of Stream Reader  (CStreamReader) preferably when a key frame in the video stream containing the requested point of view is encountered.","In concluding the detailed description, it should be noted that it will be obvious to those skilled in the art that many variations and modifications may be made to the preferred embodiment without substantially departing from the principles of the present invention. All such variations and modifications are intended to be included herein within the scope of the present invention, as set forth in the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention will be understood in better detail with reference to the attached drawings, where:",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 3","FIG. 2"]}]},"DETDESC":[{},{}]}
