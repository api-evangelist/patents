---
title: System and method for super-resolution imaging from a sequence of color filter array (CFA) low-resolution images
abstract: A method and system for improving picture quality of color images by combing the content of a plurality of frames of the same subject; comprising: at least one processor; the at least one processor comprising a memory for storing a plurality of frames of a subject; the at least one processor operating to combine the content of plurality of frames of the subject into a combined color image by performing: a process in which at least two multicolored frames are converted to monochromatic predetermined color frames; a gross shift process in which the gross shift translation of one monochromatic predetermined color frame is determined relative to a reference monochromatic predetermined color frame; a subpixel shift process utilizing a correlation method to determine the translational and/or rotational differences of one monochromatic predetermined color frame to the reference monochromatic predetermined color frame to estimate sub-pixel shifts and/or rotations between the frames; and an error reduction process to determine whether the resolution of the resulting combined color image is of sufficient resolution; the error reduction process comprising applying at least one spatial frequency domain constraint and at least one spatial domain constraint to the combined color image to produce at least one high-resolution full color image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08577184&OS=08577184&RS=08577184
owner: The United States of America as represented by the Secretary of the Army
number: 08577184
owner_city: Washington
owner_country: US
publication_date: 20101215
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","GOVERNMENT INTEREST","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS","EXAMPLE"],"p":["This application is a Continuation-In-Part of U.S. patent application Ser. No. 12\/576,132, filed Oct. 8, 2009, entitled System and Method of Super-Resolution Imaging from a Sequence of Translated and Rotated Low-Resolution Images, and which in turn is a Continuation-In-Part of application Ser. No. 11\/038,401, filed on Jan. 19, 2005, now U.S. Pat. No. 7,602,997, entitled \u201cMethod of Super-Resolving Images.\u201d Priority is being claimed under 35 U.S.C. \u00a7120 to both application Ser. Nos. 12\/576,132 and 11\/038,401, and both are hereby incorporated by reference.","The invention described herein may be manufactured, used, and\/or licensed by or for the United States Government.","This invention relates in general to a method of digital image processing, and more specifically relates to super-resolution image reconstruction.","The terminology \u201csubpixel\u201d or \u201csubpixels\u201d as used herein refers to one or more components of a single pixel. In a color subpixelated image, the components of a single pixel comprise several primary color primaries, which may be three ordered color elements such as blue, green, and red (BGR), or red, green, and blue (RGB), or green, blue, red. Some image displays have more than three primaries, further including yellow (RGBY), or white (RGBW), or yellow and cyan (RGBYC). Sub-pixels may appear as a single color when viewed directly by the human eye due to spatial integration by the eye. However, the components may be visible under a magnification. Upon achieving a predetermined resolution, the colors in the sub-pixels are not visible, but the relative intensity of the components may cause a shift in the apparent position or orientation of a line. The resolution at which sub-pixels go unnoticed may depend upon the viewer or the application as the visual processes of humans vary; whereby the colored \u201cfringes\u201d resulting from sub-pixel rendering may cause distraction in some individuals or applications but not others. Methods that account for sub-pixel rendering are generally called subpixel rendering algorithms.","Image resolution relates to the detail that an image possesses. For satellite images, the resolution generally correlates to the area represented by each pixel. Generally speaking, an image is considered to be more accurate and detailed as the area represented by each pixel is decreased. As used herein, the term images includes digital images, film images, and\/or other types of images.","As used herein, the terminology \u201csampling\u201d refers to the practice of collecting a subset of individual observations intended to yield some knowledge about a subject. \u201cSampling\u201d includes the act, process, or technique of selecting a representative part of a population or sequence of moving images for the purpose of determining parameters or characteristics of the whole population or moving image sequence. For example, according to the 1949 sampling theorem by C E Shannon, in order to recover a signal function \u0192(t) precisely, the sampling rate must be done at a rate greater than twice the signal's highest frequency component.","Many low-cost sensors (or cameras) may spatially or electronically undersample an image. Similarly, cameras taking pictures from great distances, such as aerial photos, may not obtain detailed information about the subject matter. This may result in aliased images in which the high frequency components are folded into the low frequency components in the image. Consequently, subtle or detail information (high frequency components) are not present in the images.","Many digital cameras acquire images using a single image sensor overlaid with a color filter array (CFA), and demosaicing is required to render these images into a viewable format. \u201cDemosaicing process\u201d is a digital image process of reconstructing a full color image from incomplete color samples output from an image sensor or camera overlaid with a color filter array (CFA).","When an image is captured by a monochrome camera, a single charge-coupled device (CCD) or complementary metal-oxide semiconductor (CMOS) sensor is used to sample the light intensity projected onto the sensor. Color images are captured in much the same way, except that the light intensity is measured in separate color channels, usually red, green, and blue. In order to do this, three separate sensors could be used in conjunction with a beam splitter to accurately measure each of the three primary colors at each pixel. However, this approach is expensive and mechanically difficult to implement, making its use in commercial imaging systems infeasible. To overcome this obstacle, the color filter array (CFA) was introduced to capture a color image using only one sensor.","A CFA is an array that is used in front of the image sensors to alternate color filters that samples only one color channel at each pixel location. The most popular and common CFA is arranged in mosaic pattern, called the Bayer pattern, as described in U.S. Pat. No. 3,971,065, \u201cColor image array,\u201d July 1976, B. E. Bayer, which is illustrated in . For each 2\u00d72 set of pixels, two diagonally opposed pixels have green filters, and the other two pixels have red and blue filters, which is called quincunx sampling pattern. A Bayer image can be also seen as a grayscale image as shown in .","This pattern results in half of the image resolution being dedicated to accurate measurement of the green color channel and quarter of the image resolution of the red or blue color channel. The peak sensitivity of the human visual system lies in the medium wavelengths, justifying the extra green sampling as described in X. Li, B. Gunturk, and L. Zhang, \u201cImage demosaicing: a systematic survey,\u201d Proc. SPIE, Vol. 6822, 68221J, 2008. Because each pixel now has only one color sampled, in order to produce a three-channel full color image, that is, each pixel contains three color channel values, missing information needs to be estimated from surrounding pixels of CFA pattern raw data. This is called demosaicing algorithm or process. The simplest demosaicing algorithm is linear interpolation applied to every color channel. More advanced demosaicing methods are summarized in X. Li, B. Gunturk, and L. Zhang, \u201cImage demosaicing: a systematic survey,\u201d Proc. SPIE, Vol. 6822, 68221J, 2008; D. Alleysson and B. C. de Lavarene, \u201cFrequency selection demosaicking: a review and a look ahead,\u201d Proc. SPIE-IS&T Electronic Imaging, Vol. 6822, 68221M, 2008.","Sampling by color filter array (CFA) causes severe aliasing in addition to the aliasing caused by undersampling of many low-cost sensors, e.g., the CCD aperture.","The resolution of a color image reconstructed from the demosaicing method is equal to the physical resolution of a CCD. However, the resolution of an image sensor can be improved by a digital image processing algorithm: super-resolution image reconstruction.","Super-resolution image reconstruction generally increases image resolution without necessitating a change in the design of the optics and\/or detectors by using a sequence (or a few snapshots) of low-resolution images. Super-resolution image reconstruction algorithms effectively de-alias undersampled images to obtain a substantially alias-free or, as identified in the literature, a super-resolved image.","When undersampled images have sub-pixel shifts between successive frames, they contain different information regarding the same scene. Super-resolution image reconstruction involves, inter alia, combining information contained in undersampled images to obtain an alias-free (high-resolution) image. Super-resolution image reconstruction from multiple snapshots, taken by a detector which has shifted in position, provides far more detail information than any interpolated image from a single snapshot.","Methods for super-resolving images that are acquired from CFA sensors are in the following references.","One of these methods is to capture multiple appropriately positioned CFA images that are used to fill in the \u201choles\u201d in a Bayer pattern, as for example in U.S. Pat. No. 7,218,751, \u201cGenerating super resolution digital images,\u201d May 15, 2007, A. M. Reed and B. T. Hannigan. Values of the pixels in multiple images which are appropriately aligned to each pixel position are averaged to generate a better value for each pixel position. In this method, in order to produce a useful result, information carried by a digital watermark is used to determine the alignment of the images.","Another type of these methods is called separate approach or two-pass algorithm. The CFA images are first demosaicked and then followed by the application of super-resolution, as for example in U.S. Pat. No. 7,260,277, \u201cMethod for obtaining a high-resolution digital image,\u201d Aug. 21, 2007, G. Messina, S. Battiato, and M. Mancuso. Each CFA input image is subjected to an interpolation phase to generate a complete low-resolution with three color channels containing three primary colors in RGB format and is thus linearly transformed into a complete low-resolution image in the YCrCb format, where Y represents the luminance component, Cr and Cb represent two chrominance components. After this, a modified back projection super-resolution approach, based in M. Irani and S. Peleg, \u201cSuper resolution from image sequence,\u201d Proceedings of the 10th International Conference on Pattern Recognition, Vol. 2, pages 115-120, is applied only to the luminance component Y of the multiple images.","The third type of these methods is called joint or one-pass method in which demosaicing and super-resolution algorithms are simultaneously carried for a CFA image sequence, as for example in U.S. Pat. No. 7,515,747, \u201cMethod for creating high resolution color image, system for creating high resolution color image and program creating high resolution color image,\u201d Apr. 7, 2009, M. Okutomi and T. Goto; U.S. Pat. No. 7,379,612, \u201cDynamic reconstruction of high-resolution video from color-filtered low-resolution video-to-video super-resolution,\u201d May 27, 2008, P. Milanfar, S. Farsiu, and M. Elad. In this method, an observation model is formulated to relate the original high-resolution image to the observed low-resolution images to incorporate color measurements encountered in video sequences. Then, the high-resolution full color image is obtained by solving an inverse problem by minimizing a cost function which is the function of the difference between the estimated low-resolution input images and the measured input images by imposing penalty terms, such as smoothness of chrominance and inter-color dependencies.","There is a need to produce high-resolution three channel full color images from a sequence of low-resolution images captured by a low-cost CFA imaging device that has experienced translations and\/or rotations. The amount of sub-pixel translation and\/or rotation may be unknown and it creates a need to estimate sub-pixel translation and rotation. In order to produce high-resolution images from a sequence of CFA undersampled (low-resolution) images, there exists a need to eliminate aliasing, while taking into account natural jitter.","The present invention provides a method and system for the super-resolving images reconstructed from sequences of CFA lower resolution imagery affected by undersampled color filter array sensor.","An embodiment of the present invention utilizes a sequence of undersampled CFA low-resolution images from the same scene with sub-pixel translations and\/or rotations among the images to reconstruct an alias-free high-resolution three-channel full color image, or to produce a sequence of such alias-free high-resolution full color frames as in a video sequence. The undersampled CFA low resolution images may be captured in the presence of natural jitter or some kind of controlled motion of the camera. For example, the natural jitter may be the result of a vehicle traveling down a bumpy road or an aircraft experiencing turbulence. The present invention is adaptable to situations where prior knowledge about the high-resolution full color image is unknown, as well when unknown, irregular or uncontrolled sub-pixel translations and\/or rotations have occurred among the low-resolution CFA images.","As depicted in , a sequence of original input CFA low resolution images is passed into a transformation parameter estimation algorithm (Box ). The transformation parameters include translation and rotation values. The Box  includes three steps obtaining gross and sub-pixel transformation parameter estimation for the green channel, from which the demosaiced green channel sequence is obtained (Box ), an estimate of the overall shift of each frame with respect to a reference frame in the green channel sequence is obtained (Box ), and a sub-pixel translation and\/or rotation estimation is obtained (Box ). Since the luminance component in a full color image contains most information and a Bayer color filter array is used in this embodiment, the green channel is chosen as the luminance component for transformation parameter estimation. Because it is important to keep the mosaicing order of the input CFA images, the input images are not aligned with respect to the gross-shift estimates. Rather, both estimated gross and sub-pixel transformation parameters are assigned to the red and blue channel sequences (Box  and ). An error reduction algorithm is applied (Box ) to the input CFA low resolution images with the estimated gross translations and sub-pixel shifts and\/or rotations among images to obtain the high-resolution (alias-free) full color output.","According to a preferred embodiment of the present invention, there is provided a system for improving picture quality of color images by combing the content of a plurality of frames of the same subject; comprising:","at least one processor; the at least one processor comprising a memory for storing a plurality of frames of a subject; the at least one processor operating to combine the content of plurality of frames of the subject into a combined color image by performing:","a process in which at least two multicolored frames are converted to monochromatic predetermined color frames;","a gross shift process in which the gross shift translation of one monochromatic predetermined color frame is determined relative to a reference monochromatic predetermined color frame;","a subpixel shift process utilizing a correlation method to determine the translational and\/or rotational differences of one monochromatic predetermined color frame to the reference monochromatic predetermined color frame to estimate sub-pixel shifts and\/or rotations between the frames; and","an error reduction process to determine whether the resolution of the resulting combined color image is of sufficient resolution; the error reduction process comprising applying at least one spatial frequency domain constraint and at least one spatial domain constraint to the combined color image to produce at least one high-resolution full color image.",{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 8","b":["310","320","330","340","350","360","370"]},"The present invention now will be described more fully hereinafter with reference to the accompanying drawings, in which embodiments of the invention are shown. However, this invention should not be construed as limited to the embodiments set forth herein. Rather, these embodiments are provided so that this disclosure will be thorough and complete, and will fully convey the scope of the invention to those skilled in the art. In the drawings, the thickness of layers and regions may be exaggerated for clarity. Like numbers refer to like elements throughout. As used herein the term \u201cand\/or\u201d includes any and all combinations of one or more of the associated listed items.","The terminology used herein is for the purpose of describing particular embodiments only and is not intended to limit the full scope of the invention. As used herein, the singular forms \u201ca\u201d, \u201can\u201d and \u201cthe\u201d are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms \u201ccomprises\u201d and\/or \u201ccomprising,\u201d when used in this specification, specify the presence of stated features, integers, steps, operations, elements, and\/or components, but do not preclude the presence or addition of one or more other features, integers, steps, operations, elements, components, and\/or groups thereof.","Unless otherwise defined, all terms (including technical and scientific terms) used herein have the same meaning as commonly understood by one of ordinary skill in the art to which this invention belongs. It will be further understood that terms, such as those defined in commonly used dictionaries, should be interpreted as having a meaning that is consistent with their meaning in the context of the relevant art and will not be interpreted in an idealized or overly formal sense unless expressly so defined herein.","With reference to , components of a preferred embodiment of the present invention include gross translation estimation (Box ) and sub-pixel transformation estimation (Box ). Gross translation (or shift) estimates are intended to obtain the overall shift of each image with respect to a reference image.","Sub-pixel transformation, also known as fraction pixel displacement, subpixel shift, or subpixel displacement, is estimated by a variety of methods in both patents and literature. Frame-to-frame motion detection based on gradient decent methods are most commonly used (see: (1) U.S. Pat. No. 5,767,987, \u201cMethod and apparatus for combining multiple image scans for enhanced resolution,\u201d Jun. 16, 1998, G. J. Wolff and R. J. Van Steenkiste; (2) U.S. Pat. No. 6,650,704, \u201cMethod of producing a high quality, high resolution image from a sequence of low quality, low resolution images that are undersampled and subject to jitter,\u201d Nov. 18, 2003, R. S. Carlson, J. L. Arnold, and V. G. Feldmus; (3) U.S. Pat. No. 6,285,804, \u201cResolution improvement from multiple images of a scene containing motion at fractional pixel values,\u201d Sep. 4, 2001, R. J. Crinon and M. I. Sezan; (4) U.S. Pat. No. 6,349,154, \u201cMethod and arrangement for creating a high-resolution still picture,\u201d Feb. 19, 2002, R. P. Kleihorst). One of the variations of these methods is to estimate the velocity vector field measurement based on spatio-temporal image derivative (see U.S. Pat. No. 6,023,535, \u201cMethods and systems for reproducing a high resolution image from sample data,\u201d Feb. 8, 2000, S. Aoki). Most of these methods need to calculate matrix inversion or use iterative methods to calculate the motion vectors. Bergen (see U.S. Pat. No. 6,208,765, \u201cmethod and apparatus for improving image resolution,\u201d Mar. 27, 2001, J. R. Bergen) teaches a method to use warp information to obtain sub-pixel displacement. Stone et al (see U.S. Pat. No. 6,628,845, \u201cMethod for subpixel registration of images,\u201d Sep. 30, 2003, H. S. Stone, M. T. Orchard, E-C Chang, and S. Martucci) teaches another method that is to estimate the phase difference between two images to obtain sub-pixel shifts. In this method, the minimum least square solution has to be obtained to find the linear Fourier phase relationship between two images. U.S. Pat. No. 7,602,997, invented by the inventor herein, utilizes a correlation method without solving the minimum least square problem to explore the translational differences (shifts in x and y domains) of Fourier transforms of two images to estimate sub-pixel shifts between two low resolution aliased images.","Translation and Rotation Estimation","Two image frames of a low-resolution image sequence may be designated \u0192(x,y) and \u0192(u,v). Because of the conditions under which the frames are acquired, the second image is a shifted and\/or rotated version of the first image, that is,",{"@attributes":{"id":"p-0069","num":"0068"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"f","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["u","v"],"mo":","}}},{"msub":{"mi":"f","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"\u2062","mi":"A"}}}}]},{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"u"}},{"mtd":{"mi":"v"}}]}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mrow":{"mi":["sin","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]},{"mtd":[{"mrow":{"mrow":{"mo":"-","mi":"sin"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03b8"}},{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"x","mo":"-","msub":{"mi":["x","s"]}}}},{"mtd":{"mrow":{"mi":"y","mo":"-","msub":{"mi":["y","s"]}}}}]}}],"mo":"\u2061"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"2","mo":"\u2062","mi":"A"}}}}]},{"mtd":[{"mi":"or"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"u"}},{"mtd":{"mi":"v"}}]}},{"mrow":[{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mrow":{"mi":["sin","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]},{"mtd":[{"mrow":{"mrow":{"mo":"-","mi":"sin"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03b8"}},{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"x"}},{"mtd":{"mi":"y"}}]}}],"mo":"\u2061"},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["u","s"]}}},{"mtd":{"msub":{"mi":["v","s"]}}}]}}],"mo":"+"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"3","mo":"\u2062","mi":"A"}}}}]}]}}},"br":{},"figref":["FIG. 2","FIG. 2"],"sub":["s","s","1","2","s","s","s","s","s","s"]},{"@attributes":{"id":"p-0070","num":"0069"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["u","s"]}}},{"mtd":{"msub":{"mi":["v","s"]}}}]}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mrow":{"mi":["sin","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]},{"mtd":[{"mrow":{"mrow":{"mo":"-","mi":"sin"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03b8"}},{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mo":"-","msub":{"mi":["x","s"]}}}},{"mtd":{"mrow":{"mo":"-","msub":{"mi":["y","s"]}}}}]}}],"mo":"\u2061"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"4","mo":"\u2062","mi":"A"}}}}]}}}},"br":{},"sub":["s","s","s","s","s","s","s","s","s","s"]},"Signal Registration\u2014The signal registration method is described in the following. Almost all of the transformation parameter estimation methods are based on the signal registration method. It is assumed that the signals to be matched differ only by an unknown translation. In practice, beside translation, there may be rotation, noise, and geometrical distortions. Nevertheless, the signal registration description offers a fundamental solution to the problem. The procedure for pixel-level registration is to first calculate the correlation between two images \u0192(x,y) and \u0192(x,y) as:",{"@attributes":{"id":"p-0072","num":"0071"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"r","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","l"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mi":"R","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"msub":{"mi":"f","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":["n","k"],"mo":["+","-"],"mn":"1"},{"mi":["m","l"],"mo":["+","-"],"mn":"1"}],"mo":","}}},{"msub":{"mi":"f","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["n","m"],"mo":","}}}],"mo":","}}}}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"5","mo":"\u2062","mi":"A"}}}}]}}}},"br":{},"sub":["s","s","s","s","2","1"]},"A signal registration based correlation method is used for translation parameter estimation between two images based on 1) the correlation theorem; and 2) the shift property of Fourier transform. This method begins with the cross-correlation between two images. The terminology \u201ccross-correlation\u201d or \u201ccross correlation\u201d as used herein is a measure of similarity of two frames in terms of a function of one of them. The two-dimensional normalized cross-correlation function measures the similarity for each translation:",{"@attributes":{"id":"p-0074","num":"0073"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"C","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","l"],"mo":","}}},"mo":"=","mfrac":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":"f","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["n","m"],"mo":","}}},{"msub":{"mi":"f","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":["n","k"],"mo":["+","-"],"mn":"1"},{"mi":["m","l"],"mo":["+","-"],"mn":"1"}],"mo":","}}}],"mo":"\u2062"}}},"msqrt":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"msubsup":{"mi":"f","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":["n","k"],"mo":["+","-"],"mn":"1"},{"mi":["m","l"],"mo":["+","-"],"mn":"1"}],"mo":","}}}}}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"6","mo":"\u2062","mi":"A"}}}}]}}}},"br":{},"sub":["1","2","s","s","s","s"],"i":"Digital Picture Processing, Vol. II "},"Correlation Theorem More efficient signal registration method for translation estimation is using the correlation method in the spatial frequency domain via the Correlation Theorem. The Correlation Theorem states that the Fourier transform of the cross-correlation of two images is the product of the Fourier transform of one image and the complex conjugate of the Fourier transform of the other, that is,\n\n()=\u2111[()]=()\u00b7*()\u2003\u2003Equation (7A)\n\nwhere F(k,k) and F(k,k) are Fourier transforms of two images, \u0192(x,y) and \u0192(x,y), respectively, F*(k,k) is the conjugate of F(k,k).\n","Fourier Transform Properties\u2014The properties of Fourier transform are described in the following that include shift property of Fourier transform, polar transformation and polar function mapping, and rotation property of Fourier transform. A Fourier transform is an operation that transforms one complex-valued function of a real variable into a new function. In such applications as image processing, the domain of the original function is typically space and is accordingly called the spatial domain. The domain of the new function is spatial frequency, and so the Fourier transform is often called the spatial frequency domain (or Fourier domain) representation of the original function as it describes which frequencies are present in the original function. As used herein the terminology \u201cFourier transform\u201d refers both to the frequency domain representation of a function and to the process or formula that \u201ctransforms\u201d one function into the other.","Shift Property of Fourier Transform\u2014Two members of the image sequence are denoted by \u0192(x,y) and \u0192(x,y). The second image is a shifted version of the first image, such as,\n\n\u0192()=\u0192()\u2003\u2003Equation (8A)\n\nwhere (x,y) are the relative shifts (translational differences) between \u0192(x,y) and \u0192(x,y). Then,\n\n()=()exp[\u2212()]\u2003\u2003Equation (9A)\n\nwhere F(k,k) and F(k,k) are Fourier transforms of two images. Thus, a shift in one domain results in the addition of a linear phase function in the Fourier domain.\n","Polar Transform and Polar Function Mapping\u2014The polar transformation of the domain (x,y) for a 2-D signal \u0192(x,y) may be represented by",{"@attributes":{"id":"p-0079","num":"0078"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["f","p"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["\u03b8","r"],"mo":","}}},{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}],"mo":"\u2261"}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"10","mo":"\u2062","mi":"A"}}}}]},{"mtd":[{"mi":"where"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"mi":"\u03b8","mo":"\u2261","mrow":{"mi":"arctan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mi":["y","x"]}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"11","mo":"\u2062","mi":"AA"}}}}]},{"mtd":[{"mi":"and"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"mi":"r","mo":"\u2261","msqrt":{"mrow":{"msup":[{"mi":"x","mn":"2"},{"mi":"y","mn":"2"}],"mo":"+"}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"11","mo":"\u2062","mi":"AB"}}}}]}]}}},"br":{},"sub":["p","x","y"]},{"@attributes":{"id":"p-0080","num":"0079"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["F","p"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["\u03d5","\u03c1"],"mo":","}}},{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["k","x"]},{"mi":["k","y"]}],"mo":","}}}],"mo":"\u2261"}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"12","mo":"\u2062","mi":"A"}}}}]},{"mtd":[{"mi":"where"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"mi":"\u03d5","mo":"\u2261","mrow":{"mi":"arctan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":["k","y"]},{"mi":["k","x"]}]}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"13","mo":"\u2062","mi":"AA"}}}}]},{"mtd":[{"mi":"and"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"mi":"\u03c1","mo":"\u2261","msqrt":{"mrow":{"msubsup":[{"mi":["k","x"],"mn":"2"},{"mi":["k","y"],"mn":"2"}],"mo":"+"}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"13","mo":"\u2062","mi":"AB"}}}}]}]}}},"br":{},"sub":["p","p"]},"Rotation Property of Fourier Transform\u2014Two members of the image sequence are denoted \u0192(x,y) and \u0192(u,v), the second image being a rotated version of the first image,",{"@attributes":{"id":"p-0082","num":"0081"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"f","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["u","v"],"mo":","}}},{"msub":{"mi":"f","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"\u2062","mi":"A"}}}}]},{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"u"}},{"mtd":{"mi":"v"}}]}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mrow":{"mi":["sin","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]},{"mtd":[{"mrow":{"mrow":{"mo":"-","mi":"sin"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03b8"}},{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"x"}},{"mtd":{"mi":"y"}}]}}],"mo":"\u2061"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"3","mo":"\u2062","mi":"A"}}}}]}]}}},"br":[{},{},{}],"sub":["1","2","2","u","v","1","x","y","u","v","x","y"],"in-line-formulae":[{},{}],"i":["F","k",",k","F","k",",k"]},{"@attributes":{"id":"p-0083","num":"0082"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["k","u"]}}},{"mtd":{"msub":{"mi":["k","v"]}}}]}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mrow":{"mi":["sin","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]},{"mtd":[{"mrow":{"mrow":{"mo":"-","mi":"sin"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03b8"}},{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["k","x"]}}},{"mtd":{"msub":{"mi":["k","y"]}}}]}}],"mo":"\u2061"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"15","mo":"\u2062","mi":"A"}}}}]}}}},"br":[{},{},{}],"sub":["1","y","y","2","u","v","p2","p1"],"in-line-formulae":[{},{}],"i":["F","F"]},"Gross Translation Estimation Theory","The gross translation estimation (Box , and, alternatively, Boxes , , ) is described in the following. The second image can be expressed as a shifted version of the first image, such as, \u0192(u,v)=\u0192(x,y) Equation (1A)",{"@attributes":{"id":"p-0086","num":"0085"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"u"}},{"mtd":{"mi":"v"}}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"x","mo":"-","msub":{"mi":["x","s"]}}}},{"mtd":{"mrow":{"mi":"y","mo":"-","msub":{"mi":["y","s"]}}}}]}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"17","mo":"\u2062","mi":"A"}}}}]}}}},"br":{},"sub":["s","s","1","2","s","s"]},"According to the Correlation Theorem, the Fourier transform of the cross-correlation of the two images, \u0192(x,y) and \u0192(x,y) can be found as follows:\n\n()=\u2111[()]=()\u00b7*()\u2003\u2003Equation (7A)\n\nwhere F(k,k) and F(k,k) are Fourier transforms of two images, \u0192(x,y) and \u0192(x,y), respectively, F*(k,k) is the conjugate of F(k,k).\n","Using the shift property of Fourier transform, the Fourier transform, F(k,k), can be substituted via\n\n()=()exp[\u2212()]\u2003\u2003Equation (9A)\n\nThen, the Fourier transform of the cross-correlation of the two images, \u0192(x,y) and \u0192(x,y), that is, the product of the Fourier transform of one image and the complex conjugate of the Fourier transform of the other, can then be expressed as\n",{"@attributes":{"id":"p-0089","num":"0088"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"msub":{"mi":"Q","mn":"12"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["k","x"]},{"mi":["k","y"]}],"mo":","}}},{"mrow":[{"msub":{"mi":"F","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["k","x"]},{"mi":["k","y"]}],"mo":","}}},{"msubsup":{"mi":"F","mn":"1","mo":"*"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["k","x"]},{"mi":["k","y"]}],"mo":","}}},{"mi":"exp","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mo":"-","mrow":{"mi":"j","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":[{"mi":["k","x"]},{"mi":["x","s"]}],"mo":"\u2062"},{"msub":[{"mi":["k","y"]},{"mi":["y","s"]}],"mo":"\u2062"}],"mo":"+"}}}}}}],"mo":["\u2062","\u2062"]}],"mo":"="}}},{"mtd":{"mrow":{"mo":"=","mrow":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mi":"F","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["k","x"]},{"mi":["k","y"]}],"mo":","}}}},{"mi":"exp","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mo":"-","mrow":{"mi":"j","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":[{"mi":["k","x"]},{"mi":["x","s"]}],"mo":"\u2062"},{"msub":[{"mi":["k","y"]},{"mi":["y","s"]}],"mo":"\u2062"}],"mo":"+"}}}}}}],"mo":"\u2062"}}}}]}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"18","mo":"\u2062","mi":"A"}}}}]}}}},"br":{},"sub":["s","s","12","x","y"]},"Translation Estimation with Aliasing Consideration\u2014Since both images \u0192(x,y) and \u0192(u,v) are aliased, i.e., the high frequency components are folded into a portion of low frequency components. In general, for an aliased image, the image energy at lower frequency components is stronger than the folded high frequency components. Thus, the signal to aliasing power ratio is relatively high around (k,k)\u2248(0,0). Therefore, a low-pass filtering, W, is applied to the Fourier transforms F(k,k) and F(k,k). A schematic diagram of the computational efficient translation estimation method as described in U.S. Pat. No. 7,602,997, \u201cMethod of Super-Resolving Images,\u201d filed Jan. 19, 2005, S. S. Young, hereby incorporated by reference, is shown in .","Since the Fourier transform can be computed efficiently with existing, well-tested programs of FFT (fast Fourier transform) (and occasionally in hardware using specialized optics), the use of the FFT becomes most beneficial for cases where the images to be tested are large as described in L. G. Brown, \u201cA survey of image registration techniques,\u201d ACM Computing Survey, Vol. 24, No. 4, December 1992, pp. 325-376.","Sub-Pixel Translation Estimation","Translation Estimation with Sub-pixel Accuracy and Aliasing Consideration\u2014In super-resolution image reconstruction of a preferred embodiment, sub-pixel shifts (or fractional pixel displacements) among the input images are estimated using a method to estimate or calculate frame-to-frame motion within sub-pixel accuracy. In general, the smallest motion that can be obtained from conventional motion estimation is one pixel. Obtaining sub-pixel motion accurately is not straightforward. A method to achieve the sub-pixel accuracy solution has been described in the aforementioned U.S. Pat. No. 7,602,997. This method is based on resampling via frequency domain interpolation by using a Fourier windowing method as described in S. S. Young, \u201cAlias-free image subsampling using Fourier-based windowing methods,\u201d Optical Engineering, Vol. 43, No. 4, April 2004, pp. 843-855 (hereby incorporated by reference), called power window.","Because the low-resolution input images contain aliasing, a low-pass filter is applied to the input images first. A schematic diagram of the computational efficient sub-pixel translation estimation method as described in U.S. Pat. No. 7,602,997 is shown in .","Theory of Translation and Rotation Estimation","The sub-pixel translation and rotational estimation is described in the following. Assuming the second image is a shifted and rotated version of the first image, i.e.,",{"@attributes":{"id":"p-0095","num":"0094"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"f","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["u","v"],"mo":","}}},{"msub":{"mi":"f","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"\u2062","mi":"A"}}}}]},{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"u"}},{"mtd":{"mi":"v"}}]}},{"mrow":[{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mrow":{"mi":["sin","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]},{"mtd":[{"mrow":{"mrow":{"mo":"-","mi":"sin"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03b8"}},{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"x"}},{"mtd":{"mi":"y"}}]}}],"mo":"\u2061"},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["u","s"]}}},{"mtd":{"msub":{"mi":["v","s"]}}}]}}],"mo":"+"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"3","mo":"\u2062","mi":"A"}}}}]}]}}},"br":{},"sub":["s","s","1","2"]},"From the shift property of Fourier transform of these images, the following relation is derived:\n\n()=()\u00b7exp[\u2212()]\u2003\u2003Equation (9A)\n\nwhere F(k,k) and F(k,k) are the Fourier transforms of the two images, and the (k,k) domain is the rotated version of the (k,k) domain; that is,\n",{"@attributes":{"id":"p-0097","num":"0096"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["k","u"]}}},{"mtd":{"msub":{"mi":["k","v"]}}}]}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mrow":{"mi":["sin","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]},{"mtd":[{"mrow":{"mrow":{"mo":"-","mi":"sin"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03b8"}},{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["k","s"]}}},{"mtd":{"msub":{"mi":["k","y"]}}}]}}],"mo":"\u2061"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mn":"15","mo":"\u2062","mi":"A"}}}}]}}}},"br":{},"figref":"FIG. 5","sub":["u","v","x","y"]},"Then from the polar transformation, the rotation and shift properties of Fourier transform as described previously, the polar function mappings (see operation in Equation 12A) of the 2-D Fourier transforms of the two images are related by\n\n(\u03c6,\u03c1)=(\u03c6\u2212\u03b8,\u03c1)\u00b7exp[\u2212()]\u2003\u2003Equation (19A)\n","Thus, for their magnitudes we have,\n\n|(\u03c6,\u03c1)|=|(\u03c6\u2212\u03b8,\u03c1)\u2003\u2003Equation (20A)\n\nThat is, if one image is a rotated and shifted version of the other image, then the magnitude of polar function mapping of one is the shifted version of the magnitude of polar function mapping of the other one in the spatial frequency domain.\n","Note the difference between Equation (20A) and Equation (16A). One image is represented as a rotated version of the other image in Equation (16A), while one image is represented as a rotated and shifted version of the other image in Equation (20A).","Therefore, the rotation angle difference \u03b8 is represented as a translational difference using the polar transformation and polar function mapping of Fourier transform. Using the correlation method, the rotation angle between the two images is estimated in a manner similar to the translation estimation.","The rotation estimation is described in the following in detail. Because the rotation difference is only represented in the first domain of the Fourier transform, the rotation angle \u03b8 is found as the peak of inverse of the marginal 1-D Fourier transform of the cross-correlation with respect to \u03c6. The marginal 1-D Fourier transform is an operation of performing the one-dimensional Fourier transform of a 2-D function \u0192(x,y) with respect to one of the variables, x or y.","The marginal 1-D Fourier transform of the cross-correlation with respect to \u03c6 between the two images is defined as:\n\n(,\u03c1)=\u2111(,\u03c1)\u2111*(,\u03c1)\u2003\u2003Equation (21A)\n\nwhere \u2111(k,\u03c1) and \u2111(k,\u03c1) are the marginal 1-D Fourier transforms with respect to \u03c6 for the two images |F(\u03c6,\u03c1)| and |F(\u03c6,\u03c1)| (as defined in Equation 12A), respectively, and \u2111(k,\u03c1) is the complex conjugate of \u2111(k,\u03c1).\n","After the rotation angle is estimated, the second image is rotated back by the angle \u2212\u03b8 to form the backward rotated image \u0192(x,y). Then the shifts (x,y) between the two images are estimated between \u0192(x,y) and \u0192(x,y) according to the correlation method based on the Correlation Theorem and the shift property of Fourier transform as discussed previously.","Sub-Pixel Rotation and Translation Estimation","Rotation and Translation Estimation with Sub-pixel Accuracy\u2014Similar as in the translation estimation with sub-pixel accuracy, the rotation estimation with sub-pixel accuracy is achieved by resampling via frequency domain interpolation. However, the resampling operation is only performed in the \u03c6 domain (as defined in Equation 13A) since the rotation angle is the only parameter to be estimated. The subsequent sub-pixel translation estimation, (x,y) between the backward rotated image \u0192(x,y) and the first image \u0192(x,y), is achieved by resampling for both kand kdomains via frequency domain interpolation (see ).","Rotation with Aliasing Consideration The common center area of the two images \u0192(x,y) and \u0192(u,v) contributes most to the rotation angle estimation. A radially symmetrical window is applied to both images to emphasize the center common region between the two images. This radially symmetrical window is also designed as a low-pass filter to achieve accurate rotation estimation by filtering out the aliased high frequency components in the input images. As mentioned previously, the terminology aliased refers to the high frequency components folded into a portion of low frequency components. In general, for an aliased image, the image energy at lower frequency components is stronger than the folded high frequency components. Thus, the signal to aliasing power ratio is relatively high around (k,k)\u2248(0,0).","The radially symmetrical and low-pass window, W, is applied to the Fourier transforms F(k,k) and F(k,k) in the first step of the rotation estimation procedure, that is,\n\n()=()\u00b7()\u2003\u2003Equation (22AA)\n\n()=()\u00b7()\u2003\u2003Equation (22AB)\n\nSub-Pixel Rotation and Translation Estimation Procedure\n","A procedure to estimate translation and rotation parameters with sub-pixel accuracy between two images, \u0192(x,y) and \u0192(u,v), is summarized in the following.  shows a schematic representation of this estimating algorithm, which may comprise:\n\n","An illustration of translation and rotation estimation with sub-pixel accuracy is shown in FIGS. 7a, 7b, 8, and 9 of application Ser. No. 12\/576,132. In the featured example, a high-resolution forward looking infrared (FLIR) image was used to simulate a sequence of low-resolution undersampled images with translations and rotations.","An original FLIR tank image is shown in of application Ser. No. 12\/576,132. The size of this image is 40\u00d776. First, we up-sample this image using the Fourier windowing method by a factor of 30 to obtain a simulated high-resolution image with a size of 1200\u00d72280 as shown in of application Ser. No. 12\/576,132. Then the low-resolution images are generated from this simulated high-resolution image by sub-sampling and rotating. The randomly selected translation and rotation parameters for six of each low-resolution image are listed as follows:\n\n","After applying the correlation method for sub-pixel shift and rotation estimation to these 6 simulated low-resolution images, the sub-pixel shift and rotation values are obtained. The estimated sub-pixel shift and rotation values are all correct according to the actual values. FIG. 9 of application Ser. No. 12\/576,132 shows the transformation of the plane of one image (image 6) into the target domain of the reference image (image 1).",{"@attributes":{"id":"p-0112","num":"0123"},"figref":"FIG. 7","b":["200","210","212","214","216","240","250"]},"The method of acquiring a sequence of images in super-resolution image reconstruction in this embodiment may involve non-controlled sub-pixel translations and rotations; e.g. natural jitter. This can be more cost effective and more practical than the controlled sub-pixel translation and rotation image acquisition. In many applications, the imager may be carried by a moving platform or the object itself may be moving. In military reconnaissance situations, the moving platform may be a person, an unmanned ground vehicle (UGV), or an unmanned aerial vehicle (UAV) flying in a circular motion or a forward motion. As a result, acquired images may contain sub-pixel translations and\/or rotations. During the process of super-resolution image reconstruction, after multiple sub-pixel translated and\/or rotated CFA images are obtained, they are then combined to reconstruct the high-resolution full color image by projecting low-resolution CFA images onto three high-resolution grids representing red, green, and blue channels, respectively. Each grid is of a finer sampled grid than the CFA lower resolution grid. The sub-pixel translations and rotations found in images resulting from natural jitter pose a need for accurate estimation.","In Box  of , the gross translations and the sub-pixel translations and rotations are obtained for each color channel sequence. In Box  of , an error reduction algorithm is applied to the input CFA low resolution images with the estimated gross shifts and sub-pixel shifts and\/or rotations among images to obtain the high-resolution (alias-free) full color output. The output may be either a single high-resolution full color image that is generated from a sequence of CFA low-resolution images or a sequence of high-resolution full color images that are generated from multiple sequences of CFA low-resolution images.","The procedure of obtaining the reconstructed green channel image (Box ) is first described in the following.","Fourier Domain Reconstructing from Incomplete Sampled Data Based on Spectral Properties of Rectangular and Hexagonal Sampling","Green Channel Candidate\u2014One important step in super-resolution is to accurately estimate sub-pixel shifts and rotations among low-resolution images. Since the undersampled CFA images are captured either by natural jitter or some kind of controlled motion of the camera, the images of successive frames contain not only the sub-pixel shifts but also the integer pixel shifts.","Because CFA images contain severe aliasing, using the direct raw input images does not give accurate shift estimation. Using low-pass filtered version of the input images is a better choice because the low-frequency spectrum is less corrupted by aliasing.","In general, it was found in K. A. Prabhu and A. N. Netravali, \u201cMotion compensated component color coding,\u201d IEEE Trans. Communications, Vol. COM-30, pp. 2519-2527, December 1982; R. C. Tom and A. K. Katsaggelos, \u201cResolution enhancement of monochrome and color video using motion compensation,\u201d IEEE Trans. Image Processing, Vol. 10, No. 2, February 2001; U.S. Pat. No. 7,515,747, \u201cMethod for creating high resolution color image, system for creating high resolution color image and program creating high resolution color image,\u201d Apr. 7, 2009, M. Okutomi and T. Goto, that it was sufficient to estimate the motion field of a color sequence based on the luminance component only. Since a Bayer color filter array is used in this embodiment, the green channel is chosen as the luminance component for transformation parameter estimation. However, when the other CFAs are used, the luminance channel is chosen based on that CFA to be used.","The green channel in the Bayer pattern is sampled using a hexagonal sampling pattern. Obtaining the reconstructed green signal is equivalent to the process of reconstructing the original green signal at each pixel location from hexagonal sampled green signal in the Bayer pattern. Before describing the hexagonal sampling, we describe the properties of a more common sampling pattern, rectangular sampling.","Two-Dimensional Rectangular Sampling\u2014Let \u0192(x,y) be a two-dimensional delta-sampled signal of an arbitrary signal, \u0192(x,y):",{"@attributes":{"id":"p-0121","num":"0132"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"msub":{"mi":["f","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mrow":[{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"\u03b4","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"x","mo":"-","mrow":{"mi":"m","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u0394","x"]}}},{"mi":"y","mo":"-","mrow":{"mi":"n","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u0394","y"]}}}],"mo":","}}}}}],"mo":"\u2062"}],"mo":"="}}},{"mtd":{"mrow":{"mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":"\u2062","mrow":{"mrow":[{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["x","m"]},{"mi":["y","n"]}],"mo":","}}},{"mi":"\u03b4","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"x","mo":"-","msub":{"mi":["x","m"]}},{"mi":"y","mo":"-","msub":{"mi":["y","n"]}}],"mo":","}}}],"mo":"\u2062"}}}}}}]}}},"br":{},"sub":["m","x ","n","y","x ","y ","\u03b4","x","y","x","y"]},{"@attributes":{"id":"p-0122","num":"0133"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["k","x"]},{"mi":["k","y"]}],"mo":","}}},{"mfrac":{"mn":"1","mrow":{"msub":[{"mi":["\u0394","x"]},{"mi":["\u0394","y"]}],"mo":"\u2062"}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":"\u2062","mrow":{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":{"mi":["k","x"]},"mo":"-","mfrac":{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","m"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["\u0394","x"]}}},{"msub":{"mi":["k","y"]},"mo":"-","mfrac":{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","n"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["\u0394","y"]}}}],"mo":","}}}}}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0123","num":"0134"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":["(",")"],"mrow":{"mfrac":[{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","m"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["\u0394","x"]}},{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","n"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["\u0394","y"]}}],"mo":","}}}},"br":{},"sub":["x","y"]},{"@attributes":{"id":"p-0124","num":"0135"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["k","x"]},{"mi":["k","y"]}],"mo":","}}},{"mrow":{"mrow":[{"mrow":{"mrow":{"mn":"0","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"for","mrow":{"mo":["\uf603","\uf604"],"msub":{"mi":["k","x"]}}},"mo":"\u2265","mfrac":{"msub":{"mi":"k","mrow":{"mi":"x","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}},"mn":"2"}},"mo":"&"},{"mo":["\uf603","\uf604"],"msub":{"mi":["k","y"]}}],"mo":"\u2062"},"mo":"\u2265","mfrac":{"msub":{"mi":"k","mrow":{"mi":"y","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}},"mn":"2"}}],"mo":"="},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0125","num":"0136"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":"k","mrow":{"mi":"x","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}},"mo":"=","mrow":{"mrow":{"mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"},"msub":{"mi":["\u0394","x"]}},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"and","msub":{"mi":"k","mrow":{"mi":"y","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}}},"mo":"=","mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"},"msub":{"mi":["\u0394","y"]}}}},"mo":","}}},"br":{},"sub":["\u03b4","\u03b4","x","y","x","y"],"figref":["FIG. 9","FIG. 10"]},{"@attributes":{"id":"p-0126","num":"0137"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"k","mrow":{"mi":"xs","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}},"mo":"=","mrow":{"mrow":{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u0394","x"]}}]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"and","msub":{"mi":"k","mrow":{"mi":"ys","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}}},"mo":"=","mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u0394","y"]}}]}}}}},"br":{},"figref":"FIG. 10"},{"@attributes":{"id":"p-0127","num":"0138"},"maths":{"@attributes":{"id":"MATH-US-00019","num":"00019"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"\u03c1","mrow":{"mi":"s","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}},"mo":"=","mrow":{"mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"},"mn":"2"},"mo":"\u2062","msub":{"mi":"\u03c1","mn":"0"}}}}},"br":{},"sub":["x","y","x","y","0","x","y","x","y"],"sup":["2","2","2","2","2","2"]},"Spectral Properties of CFA Blue and Red Channel with Two-Dimensional Rectangular Sampling\u2014For CFA blue or red channel, it is a two-dimensional rectangular sampling. However, if the sampling spaces of the CFA pattern in x and y domains are \u0394and \u0394, respectively, the sampling spaces of blue or red channel are \u0394=2\u0394and \u0394=2\u0394, where Cis for red or blue. Therefore, the cutoff frequency for red or blue channel is",{"@attributes":{"id":"p-0129","num":"0140"},"maths":{"@attributes":{"id":"MATH-US-00020","num":"00020"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"k","mrow":{"mrow":{"mi":"xs","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},"mo":",","mi":"C"}},"mo":"=","mrow":{"mrow":{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"4","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u0394","x"]}}]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"and","msub":{"mi":"k","mrow":{"mrow":{"mi":"ys","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},"mo":",","mi":"C"}}},"mo":"=","mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"4","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u0394","y"]}}]}}}}},"br":{}},{"@attributes":{"id":"p-0130","num":"0141"},"maths":{"@attributes":{"id":"MATH-US-00021","num":"00021"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"\u03c1","mrow":{"mrow":{"mi":"s","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},"mo":",","mi":"C"}},"mo":"=","mrow":{"mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"},"mn":"4"},"mo":"\u2062","msub":{"mi":"\u03c1","mn":"0"}}}}},"br":{}},"Two-Dimensional Hexagonal Sampling\u2014As used herein the terminology \u201chexagonal sampling\u201d is depicted in the insert in ; and refers to the pattern formed by replacing the red and blue pixels (in the Bayer pattern shown in ) with zero values.","As discussed in M. Soumekh, Fourier Array Imaging, Prentice Hall, 1994, pp. 167-177, the hexagonal sampling has the following linear transformation:",{"@attributes":{"id":"p-0133","num":"0144"},"maths":{"@attributes":{"id":"MATH-US-00022","num":"00022"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"\u03b1"}},{"mtd":{"mi":"\u03b2"}}]}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"T","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}},{"mtd":{"mrow":{"msub":{"mi":"T","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mi":["ax","by"],"mo":"+"}}},{"mtd":{"mrow":{"mi":["cx","dy"],"mo":"+"}}}]}}],"mo":"="}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0134","num":"0145"},"maths":{"@attributes":{"id":"MATH-US-00023","num":"00023"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"x"}},{"mtd":{"mi":"y"}}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mi":["A","\u03b1"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":["B","\u03b2"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}],"mo":"+"}}},{"mtd":{"mrow":{"mrow":[{"mi":["C","\u03b1"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":["D","\u03b2"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}],"mo":"+"}}}]}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0135","num":"0146"},"maths":{"@attributes":{"id":"MATH-US-00024","num":"00024"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"mo":"\u2202","mrow":{"mo":["(",")"],"mrow":{"mi":["\u03b1","\u03b2"],"mo":","}}},{"mo":"\u2202","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}]}},{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"msup":{"mi":["T","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},{"mo":["\uf603","\uf604"],"mrow":{"mi":["ad","bc"],"mo":"-"}}],"mo":"="}],"mo":"="}}},"br":[{},{},{},{},{},{},{}],"in-line-formulae":[{},{},{},{},{},{},{},{},{},{}],"i":["g","x,y","g[T","x,y","T","x,y","x,y","=m\u0394","=T","x",",y","=n\u0394","=T","x",",y"],"sub":["1","2","m","\u03b1","n","\u03b2","mn","mn","m","\u03b1","1","mn","mn","n","\u03b2","2","mn","mn"]},"It is shown following in M. Soumekh, Fourier Array Imaging, Prentice Hall, 1994, pp. 167-177,\n\n\u03b4()=|\u2032()|\u03b4(\u03b1\u2212\u03b1,\u03b2\u2212\u03b2).\n\nThe delta-sampled signal is defined via\n",{"@attributes":{"id":"p-0137","num":"0148"},"maths":{"@attributes":{"id":"MATH-US-00025","num":"00025"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"msub":{"mi":["f","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mrow":[{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"\u03b4","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"x","mo":"-","mrow":{"mi":"m","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u0394","x"]}}},{"mi":"y","mo":"-","mrow":{"mi":"n","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u0394","y"]}}}],"mo":","}}}}}],"mo":"\u2062"}],"mo":"="}}},{"mtd":{"mrow":{"mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":"\u2062","mrow":{"mrow":[{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["x","m"]},{"mi":["y","n"]}],"mo":","}}},{"mi":"\u03b4","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"x","mo":"-","msub":{"mi":["x","m"]}},{"mi":"y","mo":"-","msub":{"mi":["y","n"]}}],"mo":","}}}],"mo":"\u2062"}}}}}}]}}},"br":{},"sub":"\u03b4"},{"@attributes":{"id":"p-0138","num":"0149"},"maths":{"@attributes":{"id":"MATH-US-00026","num":"00026"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"msub":{"mi":["f","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mrow":[{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mo":["\uf603","\uf604"],"mrow":{"msup":{"mi":["T","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":"\u2062","mrow":{"mi":"\u03b4","mo":["[",")"],"mrow":{"mrow":[{"mrow":[{"msub":{"mi":"T","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mi":"m","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u0394","\u03b1"]}}],"mo":"-"},{"mrow":[{"msub":{"mi":"T","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mi":"n","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u0394","\u03b2"]}}],"mo":"-"}],"mo":","}}}}],"mo":["\u2062","\u2062"]}],"mo":"="},"mo":"]"}}},"br":{},"sub":["\u03b4","x","y","x","y"]},{"@attributes":{"id":"p-0139","num":"0150"},"maths":{"@attributes":{"id":"MATH-US-00027","num":"00027"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["k","x"]},{"mi":["k","y"]}],"mo":","}}},{"mfrac":{"mn":"1","mrow":{"msub":[{"mi":["\u0394","x"]},{"mi":["\u0394","y"]}],"mo":"\u2062"}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":"\u2062","mrow":{"mi":"F","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"msub":{"mi":["k","x"]},"mo":"-","mrow":{"mfrac":{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","m"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["\u0394","\u03b1"]}},"mo":"\u2062","mrow":{"msub":{"mi":"T","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}},{"msub":{"mi":["k","y"]},"mo":"-","mrow":{"mfrac":{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","n"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["\u0394","\u03b2"]}},"mo":"\u2062","mrow":{"msub":{"mi":"T","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}}],"mo":","}}}}}}],"mo":"="}}},"br":{},"sub":["1","2"]},{"@attributes":{"id":"p-0140","num":"0151"},"maths":{"@attributes":{"id":"MATH-US-00028","num":"00028"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["F","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["k","x"]},{"mi":["k","y"]}],"mo":","}}},{"mfrac":{"mn":"1","mrow":{"msub":[{"mi":["\u0394","x"]},{"mi":["\u0394","y"]}],"mo":"\u2062"}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"m","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mrow":{"mo":"-","mi":"\u221e"}},"mi":"\u221e"},"mo":"\u2062","mrow":{"mi":"F","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"msub":[{"mi":["k","x"]},{"mi":["k","xmn"]}],"mo":"-"},{"msub":[{"mi":["k","y"]},{"mi":["k","ymn"]}],"mo":"-"}],"mo":","}}}}}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0141","num":"0152"},"maths":{"@attributes":{"id":"MATH-US-00029","num":"00029"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["k","xmn"]},"mo":"=","mrow":{"mrow":[{"mfrac":{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","ma"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["\u0394","\u03b1"]}},"mo":"+","mrow":{"mfrac":{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","nc"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["\u0394","\u03b2"]}},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"and","msub":{"mi":["k","ymn"]}}},{"mfrac":{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","mb"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["\u0394","\u03b1"]}},"mo":"+","mrow":{"mfrac":{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","nd"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["\u0394","\u03b2"]}},"mo":"."}}],"mo":"="}}}},"br":{},"sub":["xmn","ymn"]},"Spectral Property of CFA Green Channel with Two-Dimensional Hexagonal Sampling\u2014In the case of CFA green channel, the hexagonal sampling has the following linear transformation:",{"@attributes":{"id":"p-0143","num":"0154"},"maths":{"@attributes":{"id":"MATH-US-00030","num":"00030"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"\u03b1"}},{"mtd":{"mi":"\u03b2"}}]}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"T","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}},{"mtd":{"mrow":{"msub":{"mi":"T","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}}}]}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mi":["ax","by"],"mo":"+"}}},{"mtd":{"mrow":{"mi":["cx","dy"],"mo":"+"}}}]}},{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"1"}]},{"mtd":[{"mrow":{"mo":"-","mn":"1"}},{"mn":"1"}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"x"}},{"mtd":{"mi":"y"}}]}}],"mo":"\u2061"},"mo":"."}],"mo":"="}],"mo":"="}],"mo":"="}}},"br":{},"figref":"FIG. 11","sub":["x","y","\u03b1","\u03b2","\u03b4","x","y"]},{"@attributes":{"id":"p-0144","num":"0155"},"maths":{"@attributes":{"id":"MATH-US-00031","num":"00031"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"msub":[{"mi":["k","xmn"]},{"mi":["k","ymn"]}],"mo":","}},{"mo":["(",")"],"mrow":{"mrow":[{"mfrac":[{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","m"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msqrt":{"mn":"2"}},{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","n"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msqrt":{"mn":"2"}}],"mo":"-"},{"mfrac":[{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","m"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msqrt":{"mn":"2"}},{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","n"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msqrt":{"mn":"2"}}],"mo":"+"}],"mo":","}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0145","num":"0156"},"figref":["FIG. 11","FIG. 12"],"sub":["\u03b4","x","y","x","y"]},{"@attributes":{"id":"p-0146","num":"0157"},"maths":{"@attributes":{"id":"MATH-US-00032","num":"00032"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"k","mrow":{"mi":"x","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}},"mo":"=","mrow":{"mrow":[{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"msub":{"mi":["\u0394","x"]},"mo":"\u2062","msqrt":{"mn":"2"}}]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"and","msub":{"mi":"k","mrow":{"mi":"y","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}}},{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"msub":{"mi":["\u0394","y"]},"mo":"\u2062","msqrt":{"mn":"2"}}]},"mo":"."}],"mo":"="}}}},"br":{}},{"@attributes":{"id":"p-0147","num":"0158"},"maths":{"@attributes":{"id":"MATH-US-00033","num":"00033"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"k","mrow":{"mi":"xs","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}},"mo":"=","mrow":{"mrow":{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"2","mo":["\u2062","\u2062"],"msqrt":{"mn":"2"},"msub":{"mi":["\u0394","x"]}}]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"and","msub":{"mi":"k","mrow":{"mi":"ys","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}}},"mo":"=","mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"2","mo":["\u2062","\u2062"],"msqrt":{"mn":"2"},"msub":{"mi":["\u0394","y"]}}]}}}}},"br":{}},{"@attributes":{"id":"p-0148","num":"0159"},"maths":{"@attributes":{"id":"MATH-US-00034","num":"00034"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"\u03c1","mrow":{"mi":"s","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}},"mo":"=","mrow":{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"2","mo":"\u2062","msqrt":{"mn":"2"}}]},"mo":"\u2062","msub":{"mi":"\u03c1","mn":"0"}}}}},"br":{},"figref":"FIG. 12"},"Reconstructing CFA Green Channel and Red\/Blue Channel\u2014The spectral property of the hexagonal sampled data provides the basis for reconstructing the original signal to avoid nonlinear aliasing.  is a schematic diagram of sequence of steps representing an algorithm for reconstructing CFA green channel. The original green signal \u0192(x,y) is passed through an imaging system with the CFA (Box ) to become the hexagonal sampled signal \u0192(x,y). The cutoff frequency for the green channel is designed as",{"@attributes":{"id":"p-0150","num":"0161"},"maths":{"@attributes":{"id":"MATH-US-00035","num":"00035"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"k","mrow":{"mrow":{"mi":"xs","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},"mo":",","mi":"G"}},"mo":"=","mrow":{"mrow":{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"2","mo":["\u2062","\u2062"],"msqrt":{"mn":"2"},"msub":{"mi":["\u0394","x"]}}]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"and","msub":{"mi":"k","mrow":{"mrow":{"mi":"ys","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},"mo":",","mi":"G"}}},"mo":"=","mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"2","mo":["\u2062","\u2062"],"msqrt":{"mn":"2"},"msub":{"mi":["\u0394","y"]}}]}}}}},"br":{}},{"@attributes":{"id":"p-0151","num":"0162"},"maths":{"@attributes":{"id":"MATH-US-00036","num":"00036"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"\u03c1","mrow":{"mrow":{"mi":"s","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},"mo":",","mi":"G"}},"mo":"=","mrow":{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"2","mo":"\u2062","msqrt":{"mn":"2"}}]},"mo":"\u2062","msub":{"mi":"\u03c1","mn":"0"}}}}},"br":[{},{},{}],"b":["630","640","620","650"],"sub":["g","x","y","s0,G ","g\u03b4","x","y","gL","x","y","gL","x","y","g\u03b4","x","y","g","x","y","gL","x","y","g"],"in-line-formulae":[{},{}],"i":["F","k",",k","F","k",",k","W","k",",k"]},"Reconstructing red or blue channel is similar to the procedure of reconstructing the green channel except the cutoff frequency for the low-pass filter is designed as",{"@attributes":{"id":"p-0153","num":"0164"},"maths":{"@attributes":{"id":"MATH-US-00037","num":"00037"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"k","mrow":{"mrow":{"mi":"xs","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},"mo":",","mi":"C"}},"mo":"=","mrow":{"mrow":{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"4","mo":"\u2062","msub":{"mi":["\u0394","x"]}}]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"and","msub":{"mi":"k","mrow":{"mrow":{"mi":"ys","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},"mo":",","mi":"C"}}},"mo":"=","mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"4","mo":"\u2062","msub":{"mi":["\u0394","y"]}}]}}}}},"br":{}},{"@attributes":{"id":"p-0154","num":"0165"},"maths":{"@attributes":{"id":"MATH-US-00038","num":"00038"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"\u03c1","mrow":{"mrow":{"mi":"s","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},"mo":[",","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"C"}},"mo":"=","mrow":{"mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"},"mn":"4"},"mo":"\u2062","msub":{"mi":"\u03c1","mn":"0"}}}}},"br":[{},{}]},"An illustration of reconstructing green and red\/blue channels is shown in . In this example, we use a gray scale image to simulate a hexagonal sampled green image and a rectangular subsampled red or blue image. The subsampled red or blue image is decimated\/subsampled by 2 from the original image.","The original gray scale image of a nature scene is shown in . Its spectrum is shown in . Note that in  the spectrum is centered around the low frequencies. The subsampled rectangular grid for red or blue image which is subsampled by 2 (every other pixel is sampled) from the original image is illustrated in .  shows the red or blue sampled image. Its spectrum is shown in , in which the repeated versions of the spectrum of the original image are presented in the rectangular sampling fashion.  is the spectrum for the red and blue sampled image. Note that by comparing  with , one can see that in  the spectrum is repeated at nine locations around the perimeter correlating to the repeated versions of the original spectrum shown . The reconstructing red or blue sampled image is shown in .","The hexagonal sampling grid for the green image is shown in .  shows the hexagonal sampled green image. Its spectrum is shown in , in which the repeated versions of the spectrum of the original image are presented in the hexagonal sampling fashion. Note that by comparing  to , one can see repeated versions in the hexagonal sampling pattern as shown in . The reconstructing green sampled image is shown in .","Gross Translation Estimation for Color Filter Array Image Sequences","The gross translation estimation ( Box ) as described in the foregoing and in U.S. patent application Ser. No. 12\/576,132, \u201cSystem and Method of Super-Resolution Imaging from a Sequence of Translated and Rotated Low-Resolution Images,\u201d filed Oct. 8, 2009, S. S. Young is illustrated in . The gross translation estimation is applied to the reconstructed green channel images in the preferred embodiment. Then the estimated translations are assigned to the red and blue channels (Box ). If other CFA pattern is used, the gross translation estimation is applied to the reconstructing luminance channel. Then the estimated translations are assigned to two other chrominance channels. In the alternative embodiment, depicted schematically in , the gross translation estimation is applied to three color channel images, respectively (Box , , ). One may also use the estimated translations in other manners; e.g., the averages of the estimated translations for three color channels, respectively, are used for all three color channels.","SUB-PIXEL ROTATION AND TRANSLATION ESTIMATION FOR COLOR FILTER ARRAY IMAGE SEQUENCES The sub-pixel translation and rotation estimation (Box ) as described in the foregoing and in U.S. patent application Ser. No. 12\/576,132, \u201cSystem and Method of Super-Resolution Imaging from a Sequence of Translated and Rotated Low-Resolution Images,\u201d filed Oct. 8, 2009, S. S. Young is illustrated in , -. The sub-pixel translation and rotation estimation is applied to the reconstructed green channel images in the preferred embodiment. Then the estimated sub-pixel translations and rotations are assigned to the red and blue channels (Box ). If other CFA pattern is used, the sub-pixel translation and rotation estimation is applied to the reconstructing luminance channel. Then the estimated translations and rotations are assigned to two other chrominance channels. In the alternative embodiment, the sub-pixel translation and rotation estimation is applied to three color channel images, respectively. One may also use the averages of the estimated translations and rotations for three color channels, respectively, for all three color channels, as used by others.","Error-Energy Reduction Algorithm","Error-Energy Reduction Algorithm for CFA Input Images\u2014An error-energy reduction algorithm for CFA images is derived to reconstruct the high-resolution alias-free output image that is a three-channel full color image containing red, green and blue channels. A primary feature of this proposed error-energy reduction algorithm for CFA images is that, for each color channel, we treat the spatial samples from low-resolution images that possess unknown and irregular (uncontrolled) sub-pixel shifts and\/or rotations as a set of constraints to populate an over-sampled (sampled above the desired output bandwidth) processing array. The estimated sub-pixel shifted and rotated locations of these samples and their values constitute a spatial domain constraint. Furthermore, the bandwidth of the alias-free image (or the sensor imposed bandwidth) is the criterion used as a spatial frequency domain constraint on the over-sampled processing array.","In an error-energy reduction algorithm, the high-resolution image is reconstructed by removing aliasing from low resolution images. The high-resolution image is reconstructed by applying non-uniform interpolation using the constraints both in the spatial and spatial frequency domains. The algorithm is based on the concept that the error-energy is reduced by imposing both spatial and spatial frequency domain constraints: the samples from the low-resolution images; and the bandwidth of the high-resolution, alias-free output image.","In accordance with the error-energy reduction algorithm of the present invention, spatial samples from low resolution images that possess unknown and irregular (uncontrolled) sub-pixel shifts and rotations are treated as a set of constraints to populate an over-sampled (sampled above the desired output bandwidth) processing array. The estimated sub-pixel locations of these samples and their values constitute a spatial domain constraint. Furthermore, the bandwidth of the alias-free image (or the sensor imposed bandwidth) is the criterion used as a spatial frequency domain constraint on the over-sampled processing array. One may also incorporate other spatial or spatial frequency domain constraints that have been used by others; e.g., positivity of the image in the spatial domain. Since each color channel presents a unique spatial and spatial frequency properties as described earlier, the spatial and spatial frequency domain constraints are designed accordingly.","Image acquisition model\u2014 shows the system model for acquiring an undersampled image in a one-dimensional case. Let \u0192(x) be the ideal target signature that is interrogated by the sensor. The measured target signature g(x) by the sensor is modeled as the output of a Linear Shift Invariant (LSI) system whose impulse response is the sensor's point spread function (PSF), h(x); this is also known as the sensor blurring function. The relationship between the measured target signature and the original target signature in the spatial frequency kdomain is:\n\n()=()()\n\nwhere G(k), F(k), and H(k) are the Fourier transforms of g(x), \u0192(x), and h(x), respectively.\n",{"@attributes":{"id":"p-0164","num":"0175"},"figref":["FIG. 25","FIG. 25"],"sub":["x","o","t","s","o","t ","s ","o"],"br":[{},{}],"in-line-formulae":[{},{}],"i":["B","B",",B"]},"Assuming the measurement system stores the incoming images at the sample spacing of \u0394, the measured target signature, g(x), is then sampled at the integer multiples of \u0394, e.g., x=n\u0394,n=0, \u00b11, \u00b12, . . . , \u00b1N, to obtain the undersampled (aliased) image; the resultant can be modeled as the following delta-sampled signal in the spatial domain (see );",{"@attributes":{"id":"p-0166","num":"0177"},"maths":{"@attributes":{"id":"MATH-US-00039","num":"00039"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["g","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mrow":{"mo":"-","mi":"N"}},"mi":"N"},"mo":"\u2062","mrow":{"mrow":[{"mi":"g","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mi":"\u03b4","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"x","mo":"-","msub":{"mi":["x","n"]}}}}],"mo":"\u2062"}},{"mrow":[{"mi":"g","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mrow":{"mo":"-","mi":"N"}},"mi":"N"},"mo":"\u2062","mrow":{"mrow":{"mi":"\u03b4","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"x","mo":"-","msub":{"mi":["x","n"]}}}},"mo":"."}}],"mo":"\u2062"}],"mo":"="}],"mo":"="}}}},"The Fourier transform of the above delta-sampled signal is",{"@attributes":{"id":"p-0168","num":"0179"},"maths":{"@attributes":{"id":"MATH-US-00040","num":"00040"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["G","\u03b4"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["k","x"]}}},{"mfrac":{"mn":"1","msub":{"mi":["\u0394","x"]}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"l","mo":"=","mrow":{"mo":"-","mi":"N"}},"mi":"N"},"mo":"\u2062","mrow":{"mrow":{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["k","x"]},"mo":"-","mfrac":{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mi":["\u03c0","l"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":["\u0394","x"]}}}}},"mo":"."}}}],"mo":"="}}}},"An acquired image is aliased when",{"@attributes":{"id":"p-0170","num":"0181"},"maths":{"@attributes":{"id":"MATH-US-00041","num":"00041"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["\u0394","x"]},"mo":">","mrow":{"mfrac":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"},"msub":{"mi":["B","o"]}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["Nyquist","sample","spacing"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]}},"mo":"."}}}}}},"As mentioned previously, many low resolution sensors possess a spatial sample spacing \u0394that violates the Nyquist rate. The emphasis of the super-resolution image reconstruction algorithm in a preferred embodiment is to de-alias a sequence of undersampled aliased images to obtain the alias-free or a super-resolved image. Again it should be emphasized that the resolution of the output alias-free image is limited by the minimum bandwidth of the sensor and the ideal target signature.","One of the considerations in super-resolution image reconstruction is the number of the undersampled images that are required to recover the alias-free image. For monochrominance images, let the sampling space of the original undersampled images be \u0394. From an information-theory point of view, the sampling space of the output high-resolution image that is reconstructed from k frames (with distinct sub-pixel shifts) is",{"@attributes":{"id":"p-0173","num":"0184"},"maths":{"@attributes":{"id":"MATH-US-00042","num":"00042"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"msub":{"mi":["\u0394","x"]},"mi":"k"}}},"br":{}},{"@attributes":{"id":"p-0174","num":"0185"},"maths":{"@attributes":{"id":"MATH-US-00043","num":"00043"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":["(",")"],"mrow":{"mfrac":[{"msub":{"mi":["\u0394","x"]},"msqrt":{"mi":"k"}},{"msub":{"mi":["\u0394","y"]},"msqrt":{"mi":"k"}}],"mo":","}}}},"br":{}},"A numerical example is given in the following. An image array of 100\u00d7100 is initially acquired to represent a scene. The total number of pixels is 10,000. If the resolution of the image is desired to be 4 times in each direction, the image array of 400\u00d7400 is required. The total number of pixels for the high-resolution image is 160,000. That means that it requires 16 low-resolution images to achieve the resolution improvement factor of 4. Therefore, the number of input low-resolution image frames is the square of the resolution improvement factor. In other words, the resolution improvement factor is the square root of the number of the input images.","Now consider a CFA image, an image array of n*nis initially acquired to represent a scene. The total number of pixels is N=n*n. The total number pixels in the green channel is N=N\/2, while the total number of pixels in the blue or red channel is N=N\/4, where C represents for red or blue channel. When k frames of CFA images are acquired to reconstruct the high-resolution full color image, the total number of pixels of the green channel of the output high-resolution image is",{"@attributes":{"id":"p-0177","num":"0188"},"maths":{"@attributes":{"id":"MATH-US-00044","num":"00044"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":"N","mrow":{"mi":["G","_","SR"],"mo":["\u2062","\u2062"]}},"mo":"=","mrow":{"mfrac":{"mi":"N","mn":"2"},"mo":"\u2062","mi":"k"}},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0178","num":"0189"},"maths":{"@attributes":{"id":"MATH-US-00045","num":"00045"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":"N","mrow":{"mi":["C","_","SR"],"mo":["\u2062","\u2062"]}},"mo":"=","mrow":{"mfrac":{"mi":"N","mn":"4"},"mo":"\u2062","mi":"k"}},"mo":","}}},"br":{},"sub":"x"},{"@attributes":{"id":"p-0179","num":"0190"},"maths":{"@attributes":{"id":"MATH-US-00046","num":"00046"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":["(",")"],"mrow":{"mfrac":[{"msub":{"mi":["\u0394","x"]},"msqrt":{"mrow":{"mi":"k","mo":"\/","mn":"2"}}},{"msub":{"mi":["\u0394","y"]},"msqrt":{"mrow":{"mi":"k","mo":"\/","mn":"2"}}}],"mo":","}}}},"br":{}},{"@attributes":{"id":"p-0180","num":"0191"},"maths":{"@attributes":{"id":"MATH-US-00047","num":"00047"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":["(",")"],"mrow":{"mfrac":[{"msub":{"mi":["\u0394","x"]},"msqrt":{"mrow":{"mi":"k","mo":"\/","mn":"4"}}},{"msub":{"mi":["\u0394","y"]},"msqrt":{"mrow":{"mi":"k","mo":"\/","mn":"4"}}}],"mo":","}}}},"br":{}},"Theoretically, more frames should provide more information and, thus, larger bandwidth and\/or higher resolution. However, the super-resolution image quality does not improve when the number of processed undersampled images exceeds a certain value. This is due to the fact that the bandwidth recovery is limited by the minimum of the bandwidths of the sensor or ideal target signature.","Implementation of Error-Energy Reduction Algorithm for CFA Images\u2014For each color channel, the bandwidth of the input undersampled (aliased) images is designated B. The bandwidth of the alias-free (high-resolution) output image for that channel is denoted as B. In order to recover the desired (alias-free) bandwidth, it is important to select a processing array with a sample spacing smaller than the sample spacing of the desired high-resolution image. In this case, the 2D FFT of the processing array yields a spectral coverage Bthat is larger than the bandwidth of the output image.  illustrates this phenomenon in the 2D spatial frequency domain for one color channel.","The high-resolution alias-free image on the processing array (grid) is designated as p(x,y) where D\u03b5{G,C}, G for the green channel and C\u03b5{R,B} for the red or blue channel. The low-resolution (aliased) snap-shots only provide a sub-set of samples of this image. The location of each aliased image on the processing grid is dictated by its corresponding sub-pixel shifts and rotations in the (x,y) domain.","In the following, the error-energy reduction algorithm is described for the CFA input images containing translational shifts and\/or rotational differences.  shows a schematic representation of the error-energy reduction algorithm for CFA input image sequences transformed by translations and\/or rotations.","Inputs to the error energy reduction algorithm are a sequence of low-resolution CFA input images. In the preferred embodiment, the estimated gross shifts and sub-pixel shifts and\/or rotations of each image with respect to the reference image are obtained for each color channel; usually the first image is chosen as the reference image. Denote \u0192(u,v) to be L CFA images from the input image sequence, where l=1, 2, . . . , L, i=1, 2, . . . , I, j=1, 2, . . . , J; I\u00d7J is the dimension of the input image. After the transformation parameters ({circumflex over (\u03b8)},{circumflex over (x)},\u0177) are estimated for all L images, the transform coordinates are calculated from the estimated sub-pixel shifts and rotation angles as follows:",{"@attributes":{"id":"p-0186","num":"0197"},"maths":{"@attributes":{"id":"MATH-US-00048","num":"00048"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mover":{"mi":"x","mo":"^"},"mi":"ijl"}}},{"mtd":{"msub":{"mover":{"mi":"y","mo":"^"},"mi":"ijl"}}}]}},{"mrow":[{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"cos","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mover":{"mi":"\u03b8","mo":"^"},"mi":"l"}}},{"mrow":{"mi":"sin","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mover":{"mi":"\u03b8","mo":"^"},"mi":"l"}}}]},{"mtd":[{"mrow":{"mrow":{"mo":"-","mi":"sin"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mover":{"mi":"\u03b8","mo":"^"},"mi":"l"}}},{"mrow":{"mi":"cos","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mover":{"mi":"\u03b8","mo":"^"},"mi":"l"}}}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["u","i"]}}},{"mtd":{"msub":{"mi":["v","j"]}}}]}}],"mo":"\u2061"},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mover":{"mi":"x","mo":"^"},"mi":"sl"}}},{"mtd":{"msub":{"mover":{"mi":"y","mo":"^"},"mi":"sl"}}}]}}],"mo":"+"}],"mo":"="}}},"br":{}},"In the initializing step (Box ), three processing arrays are initialized for three color channels by populating each grid using the input images according to the estimates of shifts and rotation angles, respectively. Each processing array is selected with a sample spacing that is smaller than the sample spacing of the desired high-resolution image.","In this procedure, the available CFA image values (from multiple snapshots) for three color channels are assigned to each shifted and rotated grid location of three processing arrays, respectively. At the other grid locations of each processing array, zero values are assigned. This can be written as",{"@attributes":{"id":"p-0189","num":"0200"},"maths":{"@attributes":{"id":"MATH-US-00049","num":"00049"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":"p","mrow":{"mn":"1","mo":",","mi":"D"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["X","m"]},{"mi":["Y","n"]}],"mo":","}}},{"mo":"{","mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"f","mrow":{"mi":["l","D"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mover":{"mi":"x","mo":"^"},"mi":"ijl"},{"mover":{"mi":"y","mo":"^"},"mi":"ijl"}],"mo":","}}}}},{"mtd":{"mn":"0"}}]}}],"mo":"="}}},"br":{},"sub":["m","n","ijl","ijl","1,G ","1,C"],"figref":["FIG. 20","FIG. 16"]},"In Box , a 2-D Fourier transform P(k,k) is preformed on the processing array, where D\u03b5{G,C}, G for the green channel and C\u03b5{R,B} for the red or blue channel. Its spectrum has a wider bandwidth than the true (desired) output bandwidth. Therefore, the spatial frequency domain constraint (Box ) is applied, that is, replacing zeros outside the desired bandwidth.","In this step, the desired bandwidth for the green channel and the one for red or blue channel are determined first (Box ). Based on the spectral properties of the hexagonal sampling and the resolution improvement factor for the green channel when L CFA images are acquired, the desired bandwidth for the green channel is obtained as",{"@attributes":{"id":"p-0192","num":"0203"},"maths":{"@attributes":{"id":"MATH-US-00050","num":"00050"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mrow":{"mi":["Ox","G"],"mo":","}},{"mi":"B","mrow":{"mi":["Oy","G"],"mo":","}}],"mo":","}},{"mo":["(",")"],"mrow":{"mrow":[{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"2","mo":["\u2062","\u2062"],"msqrt":{"mn":"2"},"msub":{"mi":["\u0394","x"]}}]},"mo":"\u2062","msqrt":{"mrow":{"mi":"L","mo":"\/","mn":"2"}}},{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"2","mo":["\u2062","\u2062"],"msqrt":{"mn":"2"},"msub":{"mi":["\u0394","y"]}}]},"mo":"\u2062","msqrt":{"mrow":{"mi":"L","mo":"\/","mn":"2"}}}],"mo":","}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0193","num":"0204"},"maths":{"@attributes":{"id":"MATH-US-00051","num":"00051"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"msub":[{"mi":"B","mrow":{"mi":["Ox","C"],"mo":","}},{"mi":"B","mrow":{"mi":["Oy","C"],"mo":","}}],"mo":","}},{"mo":["(",")"],"mrow":{"mrow":[{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"4","mo":"\u2062","msub":{"mi":["\u0394","x"]}}]},"mo":"\u2062","msqrt":{"mrow":{"mi":"L","mo":"\/","mn":"4"}}},{"mfrac":{"mrow":[{"mn":"2","mo":"\u2062","mi":"\u03c0"},{"mn":"4","mo":["\u2062","\u2062","\u2062"],"mi":["\u0394","y"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},"mo":"\u2062","msqrt":{"mrow":{"mi":"L","mo":"\/","mn":"4"}}}],"mo":","}}],"mo":"="}}},"br":[{},{},{},{}],"in-line-formulae":[{},{}],"i":["P","k",",k","P","k",",k","W","k",",k"],"sub":["2,D","x","y","1,D","x","y","p,D","x","y","p,D","x","y","Ox,G","Oy,G","Ox,c","Oy,C","2,D","2,D","x","y"],"b":"410"},"The resultant inverse array is not a true image because the image values at the known grid locations are not equal to the original image values. Then the spatial domain constraint is applied for all three color channels (Box ), that is, replacing those image values at the known grid locations with the known original image values.","In this step of applying spatial domain constraints using shifts and rotations (Box ), we have the function",{"@attributes":{"id":"p-0196","num":"0207"},"maths":{"@attributes":{"id":"MATH-US-00052","num":"00052"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":"p","mrow":{"mrow":{"mi":"k","mo":"+","mn":"1"},"mo":",","mi":"D"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["X","m"]},{"mi":["Y","n"]}],"mo":","}}},{"mo":"{","mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"f","mrow":{"mi":["l","D"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mover":{"mi":"x","mo":"^"},"mi":"ijl"},{"mover":{"mi":"y","mo":"^"},"mi":"ijl"}],"mo":","}}}}},{"mtd":{"mrow":{"msub":{"mi":"p","mrow":{"mi":["k","D"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["X","m"]},{"mi":["Y","n"]}],"mo":","}}}}}]}}],"mo":"="}}},"br":{},"sub":["k+1,D","m","n","k,D","m","n"]},"Similarly, the use of the available information in the spatial and spatial frequency domains results in a reduction of the energy of the error at each iteration step. At the odd steps of the iteration, the error for each of three color channel is defined by",{"@attributes":{"id":"p-0198","num":"0209"},"maths":{"@attributes":{"id":"MATH-US-00053","num":"00053"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"e","mrow":{"mrow":{"mrow":{"mn":"2","mo":"\u2062","mi":"k"},"mo":"+","mn":"1"},"mo":",","mi":"D"}},"mo":"=","mrow":{"munder":{"mo":"\u2211","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},"mo":"\u2062","msup":{"mrow":{"mo":["[","]"],"mrow":{"mrow":[{"msub":{"mi":"p","mrow":{"mrow":{"mrow":{"mn":"2","mo":"\u2062","mi":"k"},"mo":"+","mn":"1"},"mo":",","mi":"D"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["X","m"]},{"mi":["Y","n"]}],"mo":","}}},{"msub":{"mi":"p","mrow":{"mrow":{"mrow":{"mn":"2","mo":"\u2062","mi":"k"},"mo":"-","mn":"1"},"mo":",","mi":"D"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["X","m"]},{"mi":["Y","n"]}],"mo":","}}}],"mo":"-"}},"mn":"2"}}}}},"br":{}},"In Box , the condition of the error-energy reduction is examined by defining the following ratio:",{"@attributes":{"id":"p-0200","num":"0211"},"maths":{"@attributes":{"id":"MATH-US-00054","num":"00054"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":["S","N"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"msub":{"mi":"R","mrow":{"mrow":{"mrow":{"mn":"2","mo":"\u2062","mi":"k"},"mo":"+","mn":"1"},"mo":",","mi":"D"}}},{"mn":"10","mo":"\u2062","mrow":{"msub":{"mi":"log","mn":"10"},"mo":["(",")"],"mfrac":{"mrow":[{"munder":{"mo":"\u2211","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},"mo":"\u2062","msup":{"mrow":{"mo":["[","]"],"mrow":{"msub":{"mi":"p","mrow":{"mrow":{"mrow":{"mn":"2","mo":"\u2062","mi":"k"},"mo":"+","mn":"1"},"mo":",","mi":"D"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["X","m"]},{"mi":["Y","n"]}],"mo":","}}}},"mn":"2"}},{"munder":{"mo":"\u2211","mrow":{"mo":["(",")"],"mrow":{"mi":["m","n"],"mo":","}}},"mo":"\u2062","msup":{"mrow":{"mo":["[","]"],"mrow":{"mrow":[{"msub":{"mi":"p","mrow":{"mrow":{"mrow":{"mn":"2","mo":"\u2062","mi":"k"},"mo":"+","mn":"1"},"mo":",","mi":"D"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["X","m"]},{"mi":["Y","n"]}],"mo":","}}},{"msub":{"mi":"p","mrow":{"mrow":{"mrow":{"mn":"2","mo":"\u2062","mi":"k"},"mo":"-","mn":"1"},"mo":",","mi":"D"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["X","m"]},{"mi":["Y","n"]}],"mo":","}}}],"mo":"-"}},"mn":"2"}}]}}}],"mo":"="}}},"br":{},"sub":["2k+1,D","max,D ","max,D ","2k+1,D","max,D","p ","o "],"b":["416","418","420"]},"An illustration of super-resolving images from CFA low-resolution sequences is shown in .  shows an example of scene of a license plate. One of original CFA input images is shown in the left column. The super-resolved three channels including the red, green and blue channels are shown in the middle column. These three images can be used to display as a color image. In order to show the effectiveness of the super-resolved full color image, the super-resolved luminance image is shown in the right column. The conversion from RGB to luminance is presented in the first row of the following matrix:",{"@attributes":{"id":"p-0202","num":"0213"},"maths":{"@attributes":{"id":"MATH-US-00055","num":"00055"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"T","mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0.2989"},{"mn":"0.5870"},{"mn":"0.1140"}]},{"mtd":[{"mn":"0.5959"},{"mrow":{"mo":"-","mn":"0.2744"}},{"mrow":{"mo":"-","mn":"0.3216"}}]},{"mtd":[{"mn":"0.2115"},{"mrow":{"mo":"-","mn":"0.5229"}},{"mn":"0.3114"}]}]}}}}},"br":{}},"Another example of scene of a car emblem is illustrated in . By observing , it can be seen that the super-resolved image shows a significant improvement from the CFA low-resolution images by exhibiting the detailed information especially in the digits and letters in the license plate and the car emblem. This illustrates that the super-resolved image is obtained even under the condition that a color filter array image sequence is acquired.",{"@attributes":{"id":"p-0204","num":"0215"},"figref":["FIG. 30","FIG. 30"],"b":["500","502","500","502","504","504","502","504","500","502","505","506"]},"Although various preferred embodiments of the present invention have been described herein in detail to provide for complete and clear disclosure, it will be appreciated by those skilled in the art, that variations may be made thereto without departing from the spirit of the invention.","As used herein, the terminology \u201csubject\u201d means: an area, a scene, an object or objects, a landscape, overhead view of land or an object or objects, or a combination thereof.","As used herein, the terminology \u201cframe\u201d means: a picture, an image or one of the successive pictures on a strip of film or video.","As used herein, the terminology \u201cprocess\u201d means: an algorithm, software, subroutine, computer program, or methodology.","As used herein, the terminology \u201calgorithm\u201d means: sequence of steps using computer software, process, software, subroutine, computer program, or methodology.","As used herein, the terminology \u201cdemosaicing process\u201d is a digital image process of reconstructing a full color image from incomplete color samples output from an image sensor or camera overlaid with a color filter array (CFA). Demosaicing or demosaicing is also referred to as CFA interpolation or color reconstruction.","As used herein, the terminology \u201cimage sensor\u201d means: a camera, charge coupled device (CCD), video device, spatial sensor, or range sensor. The image sensor may comprise a device having a shutter controlled aperture that, when opened, admits light enabling an object to be focused, usually by means of a lens, onto a surface, thereby producing a photographic image OR a device in which the picture is formed before it is changed into electric impulses.","The terminology \u201ctransformation\u201d as used herein (not to be confused with the terminology Fourier transform) refers to changes induced by movement of the image capture device, including translation and rotation.","The terminology \u201cprocessor\u201d or \u201cimage processor\u201d as used in the following claims includes a computer, multiprocessor, CPU, minicomputer, microprocessor or any machine similar to a computer or processor which is capable of processing algorithms.","The terminology \u201cluminescence\u201d or \u201cluminescence contrast\u201d refers to the difference in luminosity (or lightness) of an object as compared to the background. A more detailed description of the human visual reaction to various levels of contrast is found at NASA's Applied Color Science site http:\/\/colorusage.arc.nasa.gov\/design_lum1.php, hereby incorporated by reference. In general, the primary colors are been given luminances by design, to achieve white alignment of the monitor. Early designers of computer displays decided that equal R, G, and B digital codes should produce a particular neutral chromaticity, the \u201calignment white\u201d of the monitor (usually 6500K or 5300K). Once the white alignment color was decided and the chromaticities of the three primaries were chosen the maximum luminances of the primaries were set so that luminances of the primaries would mix to give the alignment white. For example, the human eye is more sensitive to the color green. For example, the color green is used in the color array of  to a greater extent than red or blue, so that green is designated as the luminescent color. In graphics that have the appearance of surfaces (like this page, for example) it can be useful to describe luminance contrast in terms of the difference between the lightness of the symbol or text and its background, relative to the display's white-point (maximum) luminance.","As used herein, the terminology \u201cspatial anti-aliasing\u201d refers to a technique in which distortion artifacts (also refer to as aliasing) are minimized when creating a high-resolution image at a lower resolution. Anti-aliasing relates to the process of removing signal components of a frequency higher than is able to be properly resolved by the optical recording or sampling device.","The terminology \u201coperations\u201d as used in the following claims includes steps, a series of operations, actions, processes, subprocesses, acts, functions, and\/or subroutines.","As used herein the terminology \u201ccolor channel\u201d is used in the context of a grayscale image of the same size as a color image, made of just one of the primary colors. For example, an image from a standard digital camera generally has green, red, and blue channels. A grayscale image has just one channel.","The terminology \u201cfull color\u201d as used herein includes three primary color channels where three colors are utilized to produce the color image or four or more primary color channels where four or more colors are used to produce the color image.","It should be emphasized that the above-described embodiments are merely possible examples of implementations. Many variations and modifications may be made to the above-described embodiments. All such modifications and variations are intended to be included herein within the scope of the disclosure and protected by the following claims. The invention has been described in detail with particular reference to certain preferred embodiments thereof, but it will be understood that variations and modifications can be effected within the spirit and scope of the invention."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention can best be understood when reading the following specification with reference to the accompanying drawings, which are incorporated in and form a part of the specification, illustrate alternate embodiments of the present invention, and together with the description, serve to explain the principles of the invention. In the drawings:",{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 2","sub":["uv ","xy","s","s","s","s"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 5","sub":["u","v","x","y"]},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 30"}]},"DETDESC":[{},{}]}
