---
title: System and method for balancing block allocation on data storage devices
abstract: A modular block allocator includes a front end module and a back end module communicating with each another via an application programming interface (API). The front end module receives cleaner messages requesting dirty buffers associated with the cleaner messages be cleaned. The back end module provides low and high level data structures which are formed by examining bitmaps associated with data storage devices. A stripe set data structure mapping to the low level data structures are formed. The front end module cleans the dirty buffers by allocating data blocks in the high level data structures to the dirty buffers. The low level data structures are used to map the allocated data blocks to the stripe set and when the stripe set is full it is sent to the data storage devices.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08898419&OS=08898419&RS=08898419
owner: NetApp, Inc.
number: 08898419
owner_city: Sunnyvale
owner_country: US
publication_date: 20111222
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This invention relates to data storage systems and methods and, more specifically, to systems and methods for balancing block allocation on data storage devices.","The creation and storage of digitized data has proliferated in recent years. Accordingly, techniques and mechanisms that facilitate efficient and cost effective storage of large amounts of digital data are common today. For example, a cluster network environment of nodes may be implemented as a data storage system to facilitate the creation, storage, retrieval, and\/or processing of digital data. Such a data storage system may be implemented using a variety of storage architectures, such as a network-attached storage (NAS) environment, a storage area network (SAN), a direct-attached storage environment, and combinations thereof. The foregoing data storage systems may comprise one or more data storage devices configured to store digital data within data volumes.","A data storage system includes one or more storage devices. A storage device may be a disk drive organized as a disk array. Although the term \u201cdisk\u201d often refers to a magnetic storage device, in this context a disk may, for example, be a hard disk drive (HDD) or a solid state drive (SSD) or any other media similarly adapted to store data.","In a data storage system, information is stored on physical disks as storage objects referred to as volumes that define a logical arrangement of disk space. The disks in a volume may be operated as a Redundant Array of Independent Disks (RAID). A volume may have its disks in one or more RAID groups. The RAID configuration enhances the reliability of data storage by the redundant writing of data stripes across a given number of physical disks in a RAID group and the storing of redundant information (parity) of the data stripes. The physical disks in a RAID group may include data disks and parity disks. The parity may be retrieved to recover data when a disk fails.","Information on disks is typically organized in a file system, which is a hierarchical structure of directories, files and data blocks. A file may be implemented as a set of data blocks configured to store the actual data. The data blocks are organized within a volume block number (VBN) space maintained by the file system. The file system may also assign each data block in the file a corresponding file block number (FBN). The file system assigns sequences of FBNs on a per-file basis, while VBNs are assigned over a large volume address space. The file system generally comprises contiguous VBNs from zero to n\u22121, for a file system of size n blocks.","An example of a file system is a write-anywhere file layout (WAFL) that does not overwrite data on disks when that data is updated. Instead an empty data block is retrieved from a disk into a memory and is updated or modified (i.e., dirtied) with new data, and the data block is thereafter written to a new location on the disk. A write-anywhere file system may initially assume an optimal layout such that the data is substantially contiguously arranged on disks, which results in efficient read operation. When accessing a block of a file in response to a request, the file system specifies a VBN that is translated into a disk block number (DBN) location on a particular disk within a RAID group. Since each block in the VBN space and in the DBN space is typically fixed (e.g., 4 K bytes) in size, there is typically a one-to-one mapping between the information stored on the disks in the DBN space and the information organized by the file system in the VBN space. The requested data block is then retrieved from the disk and stored in a buffer cache of the memory as part of a buffer tree of the file. The buffer tree is an internal representation of blocks for a file stored in the buffer cache and maintained by the file system.","If a data block is updated or modified by a central processing unit (CPU) or processor, the dirty data remains in the buffer cache for a period of time. Multiple modifying operations by the CPU are cached before the dirty data is stored on the disk (i.e., the buffer is cleaned). The delayed sending of dirty data to the disk provides benefits such as amortized overhead of allocation and improved on-disk layout by grouping related data blocks together. In the write anywhere file system, the point in time when a collection of changes to the data blocks is sent to the disk is known as consistency point (CP). A CP may conceptually be considered a point-in-time image of the updates to the file system since the previous CP. The process of emptying the buffer cache by sending the dirty data to the disk is accomplished by collecting a list of inodes that have been modified since the last CP and then cleaning the inodes by flushing the inodes to the disk. An inode is a data structure used to store information, such as metadata, about a file, whereas data blocks are data structures used to store the actual data for the file. The information in an inode may include ownership of the file, access permission for the file, size of the file, and file type and references to locations on disk of the data blocks for the file. The references to the locations of the file data are provided by pointers which may reference the data blocks.","Initially a CPU issues a cleaner message indicating that the dirty buffers of one or more inodes need to be allocated on disks. In response, a block allocator in the file system selects free blocks on disks to which to write the dirty data and then queues the dirty buffers to a RAID group for storage. The block allocator examines a block allocation bitmap to select free blocks within the VBN space of a logical volume. The selected blocks are generally at consecutive locations on the disks in a RAID group for a plurality of blocks of a particular file. When allocating blocks, the file system traverses a few blocks of each disk to lay down a plurality of stripes per RAID group. In particular, the file system chooses VBNs that are on the same stripe per RAID group to avoid parity reads from disks.","For efficient utilization of storage resources, it is desirable to balance block allocation across storage devices in RAID groups. Improvements which will allow balanced block allocation are desired.","The present invention is directed to systems and methods for balancing block allocation on storage devices using a hierarchical data structure for mapping data across storage devices. According to embodiments of the invention, a low level data structure of the hierarchical data structure is formed by examining one or more storage devices. The storage devices may comprise a plurality of RAID groups. A high level data structure of the hierarchical data structure that maps to the low level data structure is also formed according to embodiments of the invention. The high level data structure is used to clean dirty buffers associated with a cleaner message by allocating data blocks in the high level data structures to the dirty buffers. The data blocks allocated using the high level data structure are mapped to a stripe set (i.e., data structure comprising a plurality of stripes each mapping to a set of data blocks) using the low level data structure and the stripe set is sent to storage devices when the stripe set is full. The low level data structures are then used to map the allocated data blocks to bitmaps.","In one embodiment of the invention, a method includes providing a plurality of block allocation areas from N storage devices of a RAID group by dividing the storage devices into a plurality of regions. The block allocation areas span across the N storage devices and comprise N regions, at least one region from each of the N storage devices. A region comprises a plurality of sequential disk blocks on one of the N storage devices. The block allocation areas are classified based on a number of free data blocks available in each block allocation area. The block allocation areas are divided into a plurality of block allocation units. According to embodiments of the invention, a block allocation unit is the maximum number of consecutive FBNs of a file which are written to sequential DBNs of a disk. A block allocation unit size may vary (e.g., 64 disk blocks, 128 disk blocks, etc.).","Embodiments provide a low level bucket cache comprising a plurality of low level buckets each mapping to a plurality of the aforementioned block allocation units and provide a high level bucket cache comprising a plurality of high level buckets each mapping to a plurality of consecutive block allocation units in a single storage device in two respective low level buckets. Thus, according to embodiments of the invention, a low level bucket spans all storage devices of a RAID group, whereas a high level bucket spans a single storage device. In one embodiment, a high level bucket cache comprises buckets from all storage devices in the RAID groups. When a cleaner message is received, dirty buffers associated with the cleaner message are cleaned by selecting one of the high level buckets and allocating data blocks of the high level bucket to the dirty buffers. Since a high level bucket spans only a single storage device and a high level bucket cache spans all storage devices in the RAID groups, as the data blocks in the high level buckets are allocated to the dirty buffers, block allocation is balanced over all storage devices of the RAID groups. The low level bucket is used to map the allocated data blocks to a stripe set and to send the stripe set to storage devices when the stripe set is full. The low level bucket is also used to update filesystem bitmaps.","The foregoing has outlined rather broadly the features and technical advantages of the present invention in order that the detailed description of the invention that follows may be better understood. Additional features and advantages of the invention will be described hereinafter which form the subject of the claims of the invention. It should be appreciated by those skilled in the art that the conception and specific embodiment disclosed may be readily utilized as a basis for modifying or designing other structures for carrying out the same purposes of the present invention. It should also be realized by those skilled in the art that such equivalent constructions do not depart from the spirit and scope of the invention as set forth in the appended claims. The novel features which are believed to be characteristic of the invention, both as to its organization and method of operation, together with further objects and advantages will be better understood from the following description when considered in connection with the accompanying figures. It is to be expressly understood, however, that each of the figures is provided for the purpose of illustration and description only and is not intended as a definition of the limits of the present invention.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 1","FIG. 1"],"b":["100","102","104","106","102","104","102","104","102","104","116","118","128","130","102","104","116","118","120","122","124","126","128","130","132","132"]},"The modules, components, etc. of data storage systems  and  may comprise various configurations suitable for providing operation as described herein. For example, nodes  and  may comprise processor-based systems, such as file server systems, computer appliances, computer workstations, etc. Accordingly, nodes  and  of embodiments comprise a processor (e.g., central processing unit (CPU), application specific integrated circuit (ASIC), programmable gate array (PGA), etc.), memory (e.g., random access memory (RAM), read only memory (ROM), disk memory, optical memory, flash memory, etc.), and suitable input\/output circuitry (e.g., network interface card (NIC), wireless network interface, display, keyboard, data bus, etc.). The foregoing processor-based systems may operate under control of an instruction set (e.g., software, firmware, applet, code, etc.) providing operation as described herein.","Data store devices  and  may, for example, comprise disk memory, flash memory, optical memory, solid state memory, and\/or other suitable computer readable media. It will be apparent to those skilled in the art that data store devices  and  may comprise one or more RAID Groups. Each of storage systems  and  may further implement a storage operating system, portions of which are typically resident in memory and executed by the processor, which functionally organizes the storage system by, in one embodiment, invoking operations in support of a storage services implemented by the storage system. To facilitate access to data store devices  and , the storage operating system may further implement a file system that logically organizes the information as a hierarchical structure of directories and files on the disks using a e.g., write-anywhere file layout. In one embodiment, nodes of the storage system may carry out respective operations of the storage operating system to enable the N-Module and D-Module to provide respective network and data store device access services respectively.","In one embodiment, modular block allocator A resides in data module  and modular block allocator B resides in the data module . Modular block allocators A and B, as will be explained later, balance block allocation on data store devices  and . Data modules  and  of nodes  and  may be adapted to communicate with data store devices  and  according to a storage area network (SAN) protocol (e.g., small computer system interface (SCSI), fiber channel protocol (FCP), INFINIBAND, etc.) and thus data store devices  and  may appear a locally attached resources to the operating system. That is, as seen from an operating system on nodes  and , data store devices  and  may appear as locally attached to the operating system. In this manner, nodes  and  may access data blocks through the operating system, rather than expressly requesting abstract files.","Network modules  and  may be configured to allow nodes  and  to connect with client systems, such as clients  and  over network connections  and , to allow the clients to access data stored in data storage systems  and . Moreover, network modules  and  may provide connections with one or more other components of system , such as through network . For example, network module  of node  may access data store device  via communication network  and data module  of node . The foregoing operation provides a clustered storage system configuration for system .","Clients  and  of embodiments comprise a processor (e.g., CPU, ASIC, PGA, etc.), memory (e.g., RAM, ROM, disk memory, optical memory, flash memory, etc.), and suitable input\/output circuitry (e.g., NIC, wireless network interface, display, keyboard, data bus, etc.). The foregoing processor-based systems may operate under control of an instruction set (e.g., software, firmware, applet, code, etc.) providing operation as described herein.","Network  may comprise various forms of communication infrastructure, such as a SAN, the Internet, the public switched telephone network (PSTN), a local area network (LAN), a metropolitan area network (MAN), a wide area network (WAN), a wireless network (e.g., a cellular communication network, a wireless LAN, etc.), and\/or the like. Network , or a portion thereof may provide infrastructure of network connections  and  or, alternatively, network connections  and\/or  may be provided by network infrastructure separate from network , wherein such separate network infrastructure may itself comprise a SAN, the Internet, the PSTN, a LAN, a MAN, a WAN, a wireless network, and\/or the like.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 2","b":["136","136","204","208","212","204","108","110","208","128","130","128","130","204","208","212","204","208"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 3A","FIG. 3A"],"b":["302","120","130","304","308","312","208","302","300","320","320","320","320","320","320","320","320","320","304","308","312","320","320","320","4096"]},"Referring again to , back end module  uses bitmap  associated with storage system  to sort or rank the block allocation areas based on free data blocks available. It will be appreciated that a bitmap shows free data blocks available in a storage device. In one embodiment, a data block is a volume block number (VBN) in a file system. A VBN maps to a disk block number (DBN) on a disk.","In embodiments of the invention, back end module  assigns a score which is an estimate of free data blocks in the block allocation areas and sorts the block allocation areas based on the scores. The block allocation areas may be sorted or ranked, for example. in an ascending order based on the scores. The score represents the estimate of free VBNs available in a block allocation area. In some embodiments, back end module  selects a block allocation area receiving the highest score from each RAID group. It will be understood by those skilled in the art that by selecting the block allocation area having the highest score, a probability of writing a full stripe on disks is increased due to there being more free blocks in the selected block allocation area.","Referring still to , consider for example, that back end module  selects block allocation area I because area I received the highest score based on free data blocks available. Next, the block allocation areas are divided into a plurality of block allocation units. Referring now to , by way of example, block allocation area I is divided into a plurality of block allocation units A-D, A-D, and A-D. A block allocation unit resides within a disk. For example, block allocation units A, A and A reside within disks ,  and , respectively. A block allocation unit can be considered a sub-unit of a region. So, for example, block allocation units A-D are sub-units of region IA. Similarly, block allocation units A-D are sub-units of region IB. A block allocation unit comprises a set of data blocks that a block allocator using a high level data structure of embodiments of the invention allocates to a disk before a switch is made to the next disk. By limiting the number of blocks a block allocator may write to a particular disk and making a switch to a next disk, block allocation is balanced or spread across a plurality of disks of the storage system and a full stripe may be written on the RAID groups. In general, the term \u201cstripe\u201d refers to a collection of blocks in a volume with the same DBN number on each disk. The number of data blocks in a block allocation unit may vary depending on system configurations. For example, a block allocation unit may comprise 64 data blocks or 128 data blocks.","The block allocation units of the selected block allocation area are used to form a data structure referred to as a low level bucket cache. Referring now to , by way of example, block allocation units in block allocation area I are used to form low level bucket cache . A low level bucket cache comprises a plurality of low level buckets. Low level bucket cache  comprises low level buckets A-N. According to embodiments of the invention, a low level bucket is a data structure having a plurality of block allocation units, one from each disk. By way of example, low level bucket A comprises block allocation units A, A and A. Similarly, low level bucket B comprises block allocation units B, B and B. Thus, a low level bucket spans across all disks. According to embodiments of the invention, low-level buckets A-N may be created when system  is started or when storage systems  and  are initialized.","According to embodiments, back end module  forms a plurality of stripe sets A-N that map to buckets in the low level cache. A stripe set comprises a plurality of stripes. By way of example, stripe set A comprises stripes Ai, Aj, Ak, . . . , An, each mapping to either one or a plurality of low level buckets. As low level buckets are created, back end module  also creates corresponding stripe set data structures.","Back end module  of embodiments also forms a high level bucket cache  comprising a plurality of high level buckets A-N. According to embodiments of the invention, a high level bucket is a data structure that maps to a plurality of low level buckets. According to embodiments of the invention, a high level bucket comprises two consecutive block allocation unit of data blocks spanning across two low level buckets but residing in a same disk. In other words, a high level bucket includes two consecutive block allocation units, each from a respective low level bucket, residing in a same disk. For example, high level bucket A maps to block allocation units A and B. Block allocation units A and B, which map to low level buckets A and B, respectively, both reside in disk . Similarly, high level bucket B maps to block allocation units A and B. Block allocation units A and B, which map to low level buckets A and B, respectively, both reside in disk . Thus, according to embodiments of the invention a low level bucket comprises a plurality of block allocation units, one from each disk in a RAID group whereas a high level bucket comprises two block allocation units, each from a respective low level bucket, but both residing in a same disk. In other words, a low level bucket spans across all disks in a RAID groups whereas a high level bucket maps to a single disk. Referring still to , high level buckets A, B and C maps to disks ,  and , respectively. Thus, each high level bucket in high level bucket cache  maps to a respective disk. According to embodiments of the invention, back end module  creates high-level bucket cache  after low-level buckets are created. According to embodiments of the invention, a plurality of RAID groups contribute to a high level bucket cache via their low level bucket caches so that block allocation is balanced across all disks. According to embodiments of the invention, the high level bucket cache is a lock protected data structure. Thus, multiple cleaner messages executing on multiple CPUs can request high level buckets and safely work on the high level buckets.","In operation, according to embodiments of the invention, when front end module  () receives a cleaner message originating from a processor, front end module  requests API  to provide a high level bucket from high level bucket cache . A cleaner message may originate from a processor at, for example, a consistency point. It will be appreciated that a cleaner message contains a request to clean dirty buffers associated with that cleaner message. In response, API  obtains a high level bucket from high level bucket cache  and passes the high level bucket to front end module . Consider for example, responsive to a request, API  passes high level bucket A to front end module . Next, front end module  allocates VBNs associated with high level bucket A to the dirty buffers associated with the cleaner message. In embodiments of the invention, API  responsive to a request selects the first bucket queued in high level bucket cache  and passes that bucket to front end module . After the first bucket in the queue is consumed, API  passes the next bucket in the queue in response to the next request. By way of example, after high level bucket A is consumed, API  passes the next bucket which in this example is high level bucket B, and after high level bucket B is consumed, high level bucket C is consumed. As explained before, high level buckets A, B and C maps to disks ,  and , respectively, block allocation is balanced or distributed across the disks. According to embodiments of the invention, after the VBNs of a high level bucket has been allocated, back end module maps the allocated VBNs to the stripe set. As mentioned before, a stripe set maps to low-level buckets and furthermore a high-level bucket maps to a plurality of low-level buckets. Thus, it will be appreciated that the allocated VBNs of a high-level bucket may be mapped to the stripe set. After block allocation units A, A and A have been consumed using high level buckets A, B and C, low level bucket A is removed from low level bucket cache . According to embodiments of the invention, back end module  uses low level bucket A to update file system bitmaps to reflect that corresponding VBNs have been allocated. High level bucket A then maps to B and C. Similarly high level bucket B maps to B and C. According to embodiments of the invention, the process is repeated until all low level buckets from the low level bucket cache are removed and thereafter the block allocation area having the next highest score is selected to form new low level buckets. Thereafter, additional high level buckets are formed out of the low level buckets. As noted before, as VBNs of the high level buckets are allocated, back end module  maps the allocated VBNs to the stripe set. When a stripe set is full, back end module  sends the stripe set to the RAID groups.","According to embodiments of the invention, if after servicing a cleaner message a high level bucket has more than one block allocation unit of data blocks still available, the high level bucket is returned to the high level bucket cache so it may be re-used responsive to the next cleaner message. If the high level bucket has less than one block allocation unit available, the high level bucket is set aside. When all high level buckets of a RAID group have less than one block allocation unit available, the high level buckets stop mapping into the first low level bucket and start mapping into the next low level bucket in the bucket cache. Consequently, cleaner messages always have at least one block allocation unit of allocatable blocks. According to embodiments of the invention, high level bucket A begins by mapping to block allocation units A and B of low level buckets A and B, respectively. Similarly, high level bucket B begins by mapping to block allocation units A and B of low level buckets A and B, respectively, and high level bucket C begins by mapping to block allocation units A and B of low level buckets A and B. After block allocation units A, A and A have been consumed using respective high level buckets A, B and C, high level bucket A next maps to B and C, high level bucket B next maps to B and C, and high level bucket C next maps to B and C.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 5","b":["504","508","512"]},"In step , a low level bucket cache is formed using a plurality of block allocation units of the selected block allocation area in accordance with the method described before. The low level bucket cache comprises a plurality of low level buckets. In embodiments of the invention, the low level bucket is formed using one block allocation unit from each disk of the selected block allocation area.","In step , a stripe set is formed that maps to the low level buckets. The stripe set is a data structure comprising a plurality of stripes each mapping to a set of data blocks. In step , a high level bucket cache is formed in accordance with the method described before. A high level bucket cache comprises a plurality of high level bucket. As explained before, a high level bucket maps to a single disk in two low level buckets. In embodiments of the invention, a high level bucket comprises a plurality of block allocation units of data blocks.","In step , VBNs of a high level bucket are allocated to dirty buffers of a cleaner message. In step , the allocated VBNs are mapped to a stripe set. In decision block , back end module  checks if the stripe set is full. If the stripe set is full, in step , back end module  sends the stripe set to the storage devices (e.g., RAID groups). In step , metadata of the file system is updated.","Although the present invention and its advantages have been described in detail, it should be understood that various changes, substitutions and alterations can be made herein without departing from the spirit and scope of the invention as defined by the appended claims. Moreover, the scope of the present application is not intended to be limited to the particular embodiments of the process, machine, manufacture, composition of matter, means, methods and steps described in the specification. As one of ordinary skill in the art will readily appreciate from the disclosure of the present invention, processes, machines, manufacture, compositions of matter, means, methods, or steps, presently existing or later to be developed that perform substantially the same function or achieve substantially the same result as the corresponding embodiments described herein may be utilized according to the present invention. Accordingly, the appended claims are intended to include within their scope such processes, machines, manufacture, compositions of matter, means, methods, or steps."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["For a more complete understanding of the present invention, reference is now made to the following descriptions taken in conjunction with the accompanying drawing, in which:",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIGS. 3A and 3B"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
