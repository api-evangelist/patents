---
title: Method(s) for updating database object metadata
abstract: Two computers are respectively programmed to generate descriptions of database objects (such as tables) in a first database, and compare the generated descriptions to corresponding schema objects in a second database. Objects in the second database are changed to conform to the first database if differences are found during comparison. The just-described differences in objects may arise due to changes being made to a software program that uses data contained in the objects.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07809763&OS=07809763&RS=07809763
owner: Oracle International Corporation
number: 07809763
owner_city: Redwood Shores
owner_country: US
publication_date: 20041015
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Appendix A","Assumptions","Appendix B","Design Details","Appendix C","Generator Utility Usage Notes","EXAMPLES","Appendix D","Comparison Utility Usage Notes","EXAMPLES"],"p":["Distribution of software upgrades and source code changes has become a familiar routine that provides customers of a software product with increased features, bug fixes, new drivers and other updates to the software product (which may be, for example, application software such as \u201cORACLE FINANCIALS\u201d that is commonly used by customers to implement finance-related functions in their computers). An object through which software upgrades are distributed is typically referred to as a software patch.","For application software used in large enterprises (such as a publicly-owned corporation), a database is a quintessential element that provides scalable, performance-oriented data storage. Patches for portions of application software that interface to the database may require corresponding modifications to the database itself. Specifically, changes may need to be made to one or more attributes of tables, indexes, or views, e.g. a new column for holding an employee's middle initial may need to be added to a table and\/or an existing column (or combination of columns) may need to be indexed to support patches being made to application software.","Unlike code changes related to software written in high level languages (e.g. Java\/C\/C++), a change to a database needs to be handled carefully to not adversely impact or in any manner corrupt data that is already existing in the database at the time of the change. Enterprise Applications such as Oracle E-Business Suite Applications rarely enforce a rigid patch level (e.g. identified by a release number and\/or a version number) for their customers. In other words, customers have the flexibility to adopt different patch levels for products used by them, as per their implementation and configuration. Such scenarios pose additional patching challenges for changes to database components.","Keeping in mind the criticality of preserving existing data, patching of a database currently requires extensive potential impact analysis, including consideration of database object revision history with a goal of correctly upgrading the customer's environment per their patch level. Database patch creation process that is traditionally performed involves human inefficiencies and redundancies, as several Release and Development personnel for different products that constitute the application (such as Oracle's E-Business Suite Applications) perform repetitive analysis. Additionally, in spite of laborious analysis, the results are error prone and are likely to cause failures during patching, on account of missing and\/or overlooked object revisions, or failed handling of object dependencies. Yet another reason is a failure in the just-described analysis to anticipate different target database versions that customers may have implemented.","A prior art utility for patching databases, called \u201cODF\u201d, can be used by application development personnel to capture and propagate metadata definitions of four types of database objects\u2014tables, indexes, sequences and views. A listing of the output generated by the ODF utility is shown in  as metadata  for an example of a simple database containing a single object of the type table, which is called \u201cTEST_TABLE\u201d and which has two columns. Note that the listing in  is expressed in a non-standard syntax which is proprietary and requires a custom parser specific to the syntax.","Note that the ODF utility captures metadata  for only four types of objects identified in the previous paragraph, and for no other objects (e.g. triggers, constraints, queues and policies were not supported). Applicants note that the failure of ODF to support all types of database objects makes it an incomplete solution. Furthermore, the metadata  that is captured by ODF for even just these four types of objects is incomplete for another reason. Specifically, Applicants note that many important properties of these database objects (for e.g. Table properties like Partitioned\/non-partitioned, Global temporary v\/s Permanent, Index organized) were not supported.","Moreover, the above-described partial metadata  is extracted by ODF from a set of application-specific tables. Applicants note that the use of application-specific tables, results in at least two issues with ODF. First, the prior art ODF utility additionally requires a CASE (Computer-Aided Software Engineering) data-model repository (such as Oracle Designer) and also other snapshot utilities to propagate metadata definitions  from the CASE data-model repository to the database. Second, metadata  captured by ODF has the risk of being inaccurate, as it is not captured from the source of truth (system data dictionary) but instead from an intermediate repository.","Also, ODF captures metadata  () for only a list of those individual objects that are manually identified by a developer of an application for which a patch is being developed. Applicants note that requiring the developer to list all objects whose metadata is to be captured makes ODF prone to human error and results in one or more object definitions being missed. Furthermore, ODF captures the metadata of objects in a non-standard format shown in . Applicants note that failure to use XML prevents easy data exchange and also does not allow any data transformation\/manipulation. Moreover, ODF's stores the metadata for a huge number of mostly unrelated objects in a very large single file. Applicants have found that such bundling of unrelated objects into a single file has an adverse impact on performance because each and every object in the single file is compared to the target database during patching of the target database. Finally, ODF did not use any sophisticated approaches in comparing metadata  to the target database.","An alternative to ODF is to manually prepare SQL scripts. There is no concept of a metadata definition file in the context of SQL Scripts. Instead, the SQL scripts execute specific, hard-coded DDL (Data Definition Language) commands like DROP TABLE, CREATE TABLE, etc on the source database to make the object metadata definitions match. It is extremely error-prone as it is difficult for developers to know and predict object metadata definitions, in light of varying patch levels and potential customizations applied at the target database. It is very inefficient, time and resource intensive as it is not a generic solution, and requires repeated analysis and the same DDL commands to be used in multiple SQL scripts for different hard-coded objects. For example, a developer may prepare a SQL script file called \u201ccreate_test_table.sql\u201d which contains specific, hard-coded DDL (Data Definition Language) commands like DROP TABLE TEST_TABLE, CREATE TABLE TEST_TABLE to create the TEST_TABLE. A listing of SQL is shown in  for the above-described example of table object called \u201cTEST_TABLE\u201d which has two columns.","The drawbacks of SQL scripts are as follows. First, there is no concept of a metadata definition file in the context of SQL Scripts. Therefore, use of SQL scripts does not allow for the archiving and versioning of object metadata definitions in a source code control system. Second, the SQL is not generic because it cannot accept as input an object whose metadata is to be patched. Instead, prior art SQL contains hard-coded references to individual object names (such as \u201cTEST_TABLE\u201d in the example of ) that are used in a specific database. Third, this method is inefficient, time and resource intensive as it requires extensive analysis to be repeated for many sql scripts that handle different database objects. Fourth, this method is very error-prone as it is often difficult to predict the object metadata at a target database on account of varying patch levels and customizations present at the target database.","U.S. Pat. No. 6,785,673 granted to Fernandez et al. on Aug. 31, 2004 and entitled \u201cMethod For Converting Relational Data Into XML\u201d is hereby incorporated by reference herein in its entirety. This patent describes converting relational data into an XML document, to construct materialized XML views of relational databases.","See also U.S. Pat. No. 6,732,095 granted to Warshavsky et al. on May 4, 2004 and entitled \u201cMethod And Apparatus For Mapping Between XML And Relational Representations\u201d that is also incorporated by reference herein in its entirety. This patent describes a method to convert data between a relational format and an XML document, by creating a set of XML Mapping Definition from metadata; selecting relational data from a relational application database, and converting the relational data to the XML document using the set of XML Mapping Definition.","Computers in accordance with the invention are programmed to automatically generate complete metadata that is descriptive of an object in a first database, compare the generated metadata to a corresponding object in a second database (either directly or indirectly through hashcodes), and change the second database object as may be necessary to conform to the generated metadata if certain differences are found during comparison. The just-described change in the second database is also referred to herein as \u201cpatching\u201d.","In several embodiments, the first database and the second database are relational databases, and the object being compared has at least one table which in turn has columns of predetermined data types. In many applications of the just-described embodiments, differences in tables between the two databases arise from changes being made to one or more software programs (also called \u201capplications\u201d) that use such databases, for example in upgrading the software program(s) to fix defects and\/or provide additional functions, and such changes are propagated. If differences in the tables being compared are due to customizations of the second database that are permitted, then the second database is left unchanged. Therefore, automatic database patching in accordance with the invention, as described in the previous paragraph, supports application upgrade.","Databases are automatically patched in some embodiments of the invention by use of two utilities  and  that are respectively executed in a source computer  and a target computer , as illustrated in . Source computer  is coupled to a storage medium (such as a hard drive) containing a source database  used by an application being maintained by a human (hereinafter \u201cdeveloper\u201d) . Developer  identifies to source computer  one or more objects (which are structures for storage of data, such as tables and views) used by the application, so that the target database  can be patched when the application is changed in target computer . In many of the embodiments described herein, databases  and  are both relational databases, that are accessed through an identical database management system (DBMS). Note, however, that the invention may also be implemented in embodiments wherein the databases are not relational and\/or wherein the databases (that are being kept in conformance) are accessed through different DBMS.","Source computer , when executing utility  (also called \u201cgeneration utility\u201d) automatically extracts, from source database , metadata that completely describes an object identified by developer , for example by querying a data dictionary contained in source database . The data dictionary holds information about the structure of database , such as (1) names of objects (e.g. tables, views, snapshots, indexes, clusters, synonyms, sequences, procedures, functions, packages, triggers, and so on), (2) information about integrity constraints, (3) default values for columns, (4) how much space has been allocated for and is currently used by the objects in the database, (5) auditing information, such as who has accessed or updated various objects.","In many embodiments of the type described herein, a \u201cschema\u201d is a collection of logical structures of data, or schema objects. A schema in some such embodiments is owned by a database user and has the same name as that user, and each user owns a single schema. Schema objects in some embodiments can be created and manipulated with SQL and include the following types of objects: Clusters, Database links, Database triggers, Dimensions, External procedure libraries, Indexes and index types, Java classes, Java resources, and Java sources, Materialized views and materialized view logs, Object tables, object types, and object views, Operators, Sequences, Stored functions, procedures, and packages, Synonyms, Tables and index-organized tables, and Views.","In several of the embodiments described in the previous paragraph, other types of objects are also stored in the database and can be created and manipulated with SQL but are not contained in a schema: Contexts, Directories, Profiles, Roles, Tablespaces, and Users. In such embodiments, schema objects are logical data storage structures. Schema objects of such embodiments do not have a one-to-one correspondence to physical files on disk that store their information. However, in these embodiments, the relational database stores a schema object logically within a tablespace of the database. The data of each object in such embodiments is physically contained in one or more of the tablespace's datafiles. For some objects, such as tables, indexes, and clusters, the embodiments may allow a developer to specify how much disk space the relational database allocates for the object within the tablespace's datafiles. Also, in many embodiments, there is no relationship between schemas and tablespaces: a tablespace can contain objects from different schemas, and the objects for a schema can be contained in different tablespaces.","Note that the metadata being extracted by utility  of some embodiments is all of the information that the data dictionary in source database  maintains for a given object. Therefore utility  captures any change to the object that may have been made in source database  by anyone for any reason. Source computer  uses the extracted metadata to automatically prepare (when programmed by utility ) a text file  that describes the developer-identified schema object, including its property values. For example, if the schema object identified by the developer is a table, then text file  contains at least (a) name, (b) owner, (c) data type of each column in the table, and (d) default data value of each column in the table.","As noted at the beginning of the previous paragraph, many embodiments of generation utility  capture the values of all properties that schema objects of certain types may have. For example, schema objects that are tables have one or more of the following properties: partitioned\/non-partitioned, type of partition, number of partitions, number of subpartitions, global temporary v\/s permanent, index organized table (IOT), clustered or not, and tablespace. All such property values that are held in a data dictionary of a database for the developer-identified object are automatically captured in some embodiments of utility , for example by use of a Metadata API of the Oracle database management system. Therefore, utility  of these embodiments eliminates the use of an enumerated set of properties that each object type has. Hence, utility  does not need to be changed in any manner, even when one or more new properties are created for an object type during a future enhancement.","Furthermore, in some embodiments, generation utility  also captures metadata of one or more objects (called \u201csecondary objects\u201d) that are in some manner related to (e.g. depend on) developer-identified schema objects of certain types. For example, developer-identified objects that are tables could have, associated therewith, one or more of the following types of objects: indexes, policies, triggers and constraints. Such object types are identified in some embodiments in a predetermined set (called \u201ccontainment list\u201d) that is uniquely associated with (and hence identified by) each type of schema object that a developer may identify (also called \u201cprimary object\u201d). As noted in the previous paragraph, for each secondary object (that is associated with a developer-identified object), all its property values are captured by utility , based on the data dictionary, and hence file  provides a complete description of a developer-identified object. Specifically, containment lists R () are used with a data dictionary in source database  to see if any information identified by the just-described list is available in source database  for objects of the type (called primary objects) identified by the developer. Each object type, such as a table or a materialized view, has its own containment list R as shown in .","Note that an object type is primary if its identification by the developer is accepted by utility  for generation of a corresponding text file , and otherwise the object type is secondary. Note also that secondary object types are normally present in one or more containment lists and hence they are not identified explicitly by the developer. Note further that each primary object type has an associated containment list (which may be empty in some cases). Depending on the embodiment, an object type that is primary in one embodiment may be secondary in another embodiment and vice versa. Utility  contains an identification of the types of objects that are primary, and checks the developer's input to confirm that a primary object is being identified before generation of the corresponding text file .","Note that although the word \u201clist\u201d is used in referring to a data structure that holds an identification of all secondary object types that may be associated with a primary object type, any other data structure (such as an array) may be used depending on the embodiment. One or more containment lists are used by generation utility  of some embodiments to extract from the data dictionary in source database  the metadata on all secondary objects (their properties) associated with a developer-identified object. The extracted metadata (in whole or in part, depending on the embodiment) of a given developer-identified object is written to the corresponding text file . Note that text file  is just one of a number of text files that are generated by utility , e.g. one text file for each developer-identified object.","Use of containment lists as discussed herein eliminates the need for a developer to explicitly identify to utility  all objects whose metadata is to be captured, because utility  automatically identifies all the secondary objects of a developer-specified primary object. Therefore, utility  eliminates errors that arise from a developer overlooking one or more objects that may be present in a data dictionary and whose metadata needs to be captured to reflect a change in the database. Moreover, utility  obtains metadata from the data dictionary which is the source of truth, thereby (1) eliminating errors that arise from the use of intermediate data (e.g. if the intermediate data is not up to date) and (2) eliminating the need for a CASE data-model repository and a snapshot utility. Such use of containment lists also results in storage of all metadata of all related objects in an single data structure (such as a file), which can improve performance during comparison with a target database, as discussed below.","File  is referred to herein as a \u201ctext\u201d file when it contains character sequences, e.g. in any predetermined format such as ASCII or EBCDIC. File  of all embodiments is a text file that can be edited by use of a simple text editor, and requires no special or proprietary editing tools. In contrast, binary files are not text-based and thus are neither editable nor accessible to text-oriented tools. Note that in some embodiments, file  is expressed in an XML file format, which defines an industry standard syntax for data exchange, because XML allows for easy data transformation and manipulation unlike proprietary data file formats.","Specifically, file  of several embodiments is expressed in a predetermined language that contains tags, e.g. in extensible markup language XML or any language in conformance with SGML. XML and SGML are well known industry standards, as described at, for example, the website obtained by replacing dashes with dots in the following www-w3-org. Use of an industry standard syntax in file  enables the expression of hierarchical relationships within the metadata in file . For example, an industry standard syntax (e.g. as per XML) allows identification of any number of properties and the values associated with such identified properties for any object in the database.","Regardless of which format (whether binary or text) and which language (XML or SGML) is used, file  that has been prepared by source computer  is supplied to target computer . File  may be supplied to computer  in any conventional manner (e.g. by transmission over a network, or by storage to an optical storage medium that is physically moved between computers  and ).","Next, target computer  retrieves, from target database , metadata that describes a version of the objects in file , and compares the retrieved metadata to file . Target computer  changes the schema object version in target database  to conform to file , depending at least partially on an outcome of comparing.","Note that the mere fact that a schema object differs between databases  and  does not automatically result in changing of target database  in most embodiments, because the difference may arise from customizations that are allowed to be made to target database . For example, a table in target database  may have been customized by addition of a new column, and\/or by addition of a new index and if these are the only differences then the comparison utility leaves database  unchanged in the target computer (although it's structure is different from database ).","Note that the above-described acts can be performed repeatedly, for each of a number of schema objects that are identified by developer . Developer  may identify all schema objects that are used in an application being changed, or alternatively identify only those schema objects that developer  knows are being changed.","Note further that in many embodiments of the type described above, application developer  also changes an application in computer  that uses source database , and the changed application is supplied to computer . Computer  executes the changed application, on target database , after the target database is changed as described above. In this manner, the above-described database patching supports application upgrades.","In some embodiments, databases  and  are Oracle databases that are accessible through RDBMS Release 9.2, and an application programming interface (API) called Meta-data API is used by each of computers  and  to extract metadata from the respective databases  and .","Note that computer 's comparison of metadata retrieved from target database  to file  may be performed either directly (e.g. metadata is itself compared) or indirectly (e.g. a hash code is prepared using the metadata, and it is the hash codes that are compared). Specifically, in many embodiments of the invention, source computer  prepares and stores in file  one or more hash code(s) to be used by target computer  in comparing with corresponding hash code(s) prepared from the schema object's version in target database . Use of hash codes during comparison results in performance optimization which was not achieved in any prior art system known to Applicants.","If the two hash codes from the two databases match, then no change is made on target database . If the two hash codes do not match, then the two metadata versions of each property and\/or each secondary object are compared (which comparison can also be done either directly or indirectly). Specifically, in some embodiments, source computer   prepares and stores in file  a hash code for each and every secondary object whose metadata is being stored in file . Therefore, target computer  compares these hash codes with corresponding hash codes prepared from corresponding secondary objects of the schema object's version in target database .","The following description is of an illustrative embodiment of the invention for Oracle E-Business Suite Application upgrade and\/or patching process. In this embodiment, an XML-based database object definition (XDF) file is prepared and used in the context of an Oracle Database. The above-described two utilities are implemented as command line executables with the generation utility named as FNDXDFGEN and the comparison utility named as FNDXDFCMP. Note that in this embodiment, certain attributes are \u201csecondary\u201d objects, whereas schema objects that result in an XDF file are \u201cprimary\u201d objects. Note that in this embodiment, there is one XDF file for each primary object. The following object types are supported in this embodiment.",{"@attributes":{"id":"p-0043","num":"0042"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"63pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE A"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},{},{},"Primary\/"]},{"entry":[{},"Object Type","Details","Dependent"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"63pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Tables","These include normal tables,","Primary"]},{"entry":[{},{},"partitioned tables, IOTs (index-"]},{"entry":[{},{},"organized tables), tables with"]},{"entry":[{},{},"collection datatypes like"]},{"entry":[{},{},"VARRAYS and nested"]},{"entry":[{},{},"table type, spatial datatypes"]},{"entry":["2","Indexes","These include B*tree, Bitmap,","Dependent, as"]},{"entry":[{},{},"Hash, Domain indexes,","they are based"]},{"entry":[{},{},"partitioned indexes.","on specific"]},{"entry":[{},{},{},"columns in"]},{"entry":[{},{},{},"specific tables."]},{"entry":["3","Views",{},"Primary"]},{"entry":["4","Sequences",{},"Optional - could"]},{"entry":[{},{},{},"be treated as per"]},{"entry":[{},{},{},"user choice as"]},{"entry":[{},{},{},"either"]},{"entry":[{},{},{},"Primary\/secondary"]},{"entry":[{},{},{},"object"]},{"entry":["5","Triggers",{},"Optional - could"]},{"entry":[{},{},{},"be treated as per"]},{"entry":[{},{},{},"user choice as"]},{"entry":[{},{},{},"either"]},{"entry":[{},{},{},"Primary\/secondary"]},{"entry":[{},{},{},"object"]},{"entry":["6","Constraints","These include - Primary Key,","Dependent, as"]},{"entry":[{},{},"Foreign Key, Not null,","they are based"]},{"entry":[{},{},"Unique and Check Constraints","on tables."]},{"entry":["7","User Data-",{},"Primary"]},{"entry":[{},"Types"]},{"entry":[{},"(UDTs)"]},{"entry":["8","Application",{},"Primary"]},{"entry":[{},"Context"]},{"entry":["9","Queue",{},"Primary"]},{"entry":[{},"Tables"]},{"entry":["10","Queus",{},"Primary"]},{"entry":["11","Policies",{},"Dependent"]},{"entry":["12","Materialized",{},"Primary"]},{"entry":[{},"Views on"]},{"entry":[{},"Materialized"]},{"entry":[{},"Views or"]},{"entry":[{},"Base Tables"]},{"entry":["13","Materialized",{},"Primary"]},{"entry":[{},"view logs on"]},{"entry":[{},"base tables"]},{"entry":["14","Materialized",{},"Dependent"]},{"entry":[{},"View logs on"]},{"entry":[{},"Materialized"]},{"entry":[{},"Views"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}]}}},"In this embodiment, the generation utility  (see ) aids in creating XDF files containing database object definitions in XML file format. The generation utility  uses the Metadata API available in Oracle RDBMS v9i to capture the database object definition in XML and augments the XML to enable its use in patching. The generation utility captures object definitions for all specified objects in XDF files. The generation utility  extracts schema object definitions into xml format in files that end with the extension \u201c.xdf\u201d. The xdf extension is to distinguish XML files containing object definitions from other XML files containing data.","The format of each xdf file is such that a primary object along with all its secondary object(s) are clubbed together in one file. For example\u2014the definition of a table along with all its indexes, constraints and triggers are clubbed together in one single xdf file.","The generation utility  is written in PERL (xdfgen) and Java (FndXdfGen). The PERL xdfgen utility is a simplified wrapper over the standalone java utility\u2014FndXdfGen. The generation utility  augments the base definition generated by the Metadata API and has the following features. The generation utility  also: Automatically generates XDF filenames based on the name of primary object; Generates hash codes based on object definitions to enable optimum comparison at the target databases. The generated hashcode gets compared with the hashcode generated for the object in the target database. DBMS_UTILITY.GET_VALUE( ). The generation utility  uses a standard, more granular XDF structure where definition of a primary object gets clubbed along with relevant secondary objects. This allows for a more optimized comparison and enables the developer to easily make change\/maintain the object definitions.","The generation utility  also provides support for features like deferred Indexes, Drop\/Creation of Constraints, CustomDefault. The former two features apply only in the context of Xdf Comparison utility (FndXdfCmp) invoked during application patching. The deferred indexes feature is applicable when extensive data-loading into tables is anticipated in a patch, subsequent to index creation. The deferred indexes feature defers the creations of the \u2018flagged indexes\u2019 to a subsequent phase after the data-loading to optimize the index rebuild. The Drop\/Create Constraint feature is also useful in the data-loading context (similar to deferred indexes) or while making data-model changes that involves changes to relationships between tables.","Note that the CustomDefault feature can be used even while running comparison utility  in standalone mode. This is a very useful feature when a constraint on a column is being changed from NULL to NOT NULL, or while adding a new column with NOT NULL constraint. In such cases, this parameter which can either contain a value or SQL clause can be used. Also, hint generation (which results in a description) for all objects in the XDF files makes it easier for any calling program, e.g. a patching utility (called \u201cADPATCH\u201d) to invoke comparision utility .","Generation utility  also: captures database comments on tables, view, materialized view and their columns; generates tags for Oracle Applications specific metadata such as: Tablespace Classification, Logical Primary Keys & PK Columns, Logical Foreign Keys & FK Columns, Histogram Information, and Translation related information (e.g. whether the data is translatable into a another language, such as German).","Comparison utility  (see ) aids in propagating the definitions of schema objects from a source database to target databases by using compare-merge techniques and can be invoked by any patching utility to process XDF files. In this manner, XDF utilities of  facilitate efficient propagation of database component changes with application changes.","In general, the XDF utilities of  help to streamline the Oracle E-Business Suite Application patching process in the context of database component changes. They also make all Oracle E-Business Suite Applications patches more efficient, performance optimized and easy to debug\/diagnose with respect to database component changes. By converging all database component changes into XML format, they enable customers to proactively review and analyze changes that are to be made to their database on application of a patch in a single and consistent manner. Note that this happens when a debug feature of the comparison utility is used in some embodiments.","The utilities  and  of  are generic and applicable for use in patches\/patching process of any product outside of Oracle that uses Oracle database components. For example, any other Enterprise Applications product or Suite of Applications based on the Oracle Database can use the generation and comparison utilities illustrated in  in their patches\/patching process.","Generation utility  of  includes two components, a program  written in Java that performs acts -, and another program  written in a language for stored programs (e.g. PL\/SQL) that performs acts -. Specifically, input from a human (also called \u201cuser\u201d or \u201cdeveloper\u201d) is provided in act  to identify the database and to identify one or more primary objects whose metadata is to be written into the XDF file. Program  validates the received information in act , e.g. to confirm that the user who provided the information is the owner, etc. Program  also checks in act  that the identified object is a primary object (as per Table \u201cA\u201d above).","If the user's input is found to be valid in act , then program  is invoked. Program  performs act  to extract the metadata for a primary object identified in the user's input, as per act . As noted above, the Metadata API of Oracle RDBMS is used in some embodiments to obtain the metadata of the primary object from the source database. Note that the functions of the Metadata API access the system data dictionary. Next, in act , program  retrieves a containment list of secondary object types that the primary object is likely to have. The just-described list of secondary object types is defined in this particular embodiment in the form of containment rules, as shown in Table \u201cB\u201d.",{"@attributes":{"id":"p-0055","num":"0054"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE B"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"Primary",{},{},{}]},{"entry":[{},"Object",{},"Secondary"]},{"entry":[{},"Types","Details","objects","Containment in XDF"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"5","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Tables","These include Global","Indexes,","One Table & all its"]},{"entry":[{},{},"Temporary tables, IOTs","triggers","secondary object"]},{"entry":[{},{},"(index organized","(optional),","definitions in an XDF"]},{"entry":[{},{},"tables), Queue Tables,","constraints,","file."]},{"entry":[{},{},"normal tables, Tables","sequences,"]},{"entry":[{},{},"with types (eg.","policies"]},{"entry":[{},{},"VARRAYS and nested"]},{"entry":[{},{},"tables types, object"]},{"entry":[{},{},"types, spatial data-"]},{"entry":[{},{},"types) Partitioned"]},{"entry":[{},{},"tables"]},{"entry":["2","Materialized",{},"Indexes,","One MV & its"]},{"entry":[{},"Views on",{},"triggers","secondary object"]},{"entry":[{},"Materialized",{},"(optional),","definitions in an XDF"]},{"entry":[{},"Views",{},"Materialized"]},{"entry":[{},{},{},"view logs."]},{"entry":["3","Materialized",{},"Indexes,","One MV & its"]},{"entry":[{},"Views on",{},"triggers","secondary object"]},{"entry":[{},"Base Tables",{},"(optional)","definitions in an XDF"]},{"entry":["4","Materialized",{},"Indexes,","One MV Log & its"]},{"entry":[{},"View Logs on",{},"triggers","secondary object"]},{"entry":[{},"base Tables",{},"(optional),","definitions in an XDF"]},{"entry":[{},{},{},"constraints"]},{"entry":["5","Views",{},{},"One View definition per"]},{"entry":[{},{},{},{},"XDF"]},{"entry":["6","Application",{},{},"One Context definition"]},{"entry":[{},"Context",{},{},"per XDF"]},{"entry":["7","Queue",{},{},"One Queue Table"]},{"entry":[{},"Tables",{},{},"definition per XDF"]},{"entry":["8","Queue",{},{},"One Queue definition"]},{"entry":[{},{},{},{},"per XDF"]},{"entry":["9","User Data",{},{},"One User Data Type"]},{"entry":[{},"Types",{},{},"per XDF"]},{"entry":["10","Sequences","Optional - could be",{},"One or more"]},{"entry":[{},{},"treated as per user",{},"sequences per XDF"]},{"entry":[{},{},"choice as either"]},{"entry":[{},{},"Primary\/secondary"]},{"entry":[{},{},"object"]},{"entry":["11","Triggers","Optional - could be",{},"One or more triggers"]},{"entry":[{},{},"treated as per user",{},"per XDF"]},{"entry":[{},{},"choice as either"]},{"entry":[{},{},"Primary\/secondary"]},{"entry":[{},{},"object"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Referring to , after act , act  is performed to check whether or not, based on the containment rules for the current object, there are any secondary objects existing in the source database. If the outcome is no, then act  is performed by program  to generate metadata, followed by act  in program . In act , XSL transformation is applied to replace schema references by parsing the object definition. Specifically, schema references for an object (including owner of the object and any other schema references that could be part of the object definition) in the source database are likely to differ at the target database. For example, a customer's requirement could be that same object be created under another schema owner in the target database. For this reason, additional identifiers are added to the XDF file (in a process called \u201cremapping\u201d), to facilitate schema replacement at the target database, to support portability.","Next, as per act , a hash code is prepared for each object in the metadata (regardless of the object's type being primary or dependent). While a hash code may be prepared in any conventional manner, in some embodiments the hash code is obtained by invoking an API in the Oracle database called DBMS_UTILITY.GETHASHVALUE( ). The hash code being prepared is for use in comparing the corresponding definitions of object types (like Tables, Indexes, Queues, Queue Tables, Sequences) in a target database. In case of objects like Tables, there is a base hashcode generated for the table itself. There are additional hashcodes generated for certain properties (e.g. column in a table). This is because, in case of differences in the object being compared, there are additional properties that are compared to quickly identify the change (e.g. column level properties like Column name, Data-types, Data-type length, Constraints, Default Values may be individually compared if a specific column's hash codes are found to be different during comparison).","In an illustrative example, the following table's metadata is extracted from the data dictionary:",{"@attributes":{"id":"p-0059","num":"0058"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"SQL> DESC TEST_TABLE"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Name","Null?","Type"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},"COL1",{},"NUMBER(15)"]},{"entry":[{},"COL2",{},"DATE"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}]}},"br":{},"b":"200"},"After hash codes are obtained, they are written to the xdf file, followed by performance of act  in . Specifically, in act , invocation hints are added to the xdf file, followed by writing of the file to a medium to be used to transfer the xdf file(s) to the target computer. Act  is the last act in program  which therefore concludes, thereby to complete the execution of generation utility .","Note that in act , if a secondary object is found to exist in the source database (i.e. the outcome is yes), then act  is performed to extract metadata of the secondary object, followed by act  in which the secondary objects metadata is physically appended to metadata previously extracted, to form valid XML. Thereafter, act  is again performed, until there are no secondary objects of any of the types defined by object containment rules in Table \u201cB\u201d listed above.","Note that act  of some embodiments may incorporate multiple checks, e.g. an initial check as to whether an object of the type currently being processed has a containment rule, and if so whether any object types are identified by the containment rule for this type of object, and if so whether any actual objects are defined in this database that are of the object type identified in the containment rule. All such checks are performed automatically, to enable generation utility  to extract the metadata of any object that a developer may identify, as well as any dependent objects that the developer-identified object may have.","Comparison utility  () parses the file  prepared by the generation utility , for object definitions that reside in it and compares each object definition with that of a corresponding object present in the target database. If a corresponding object is not present, utility  attempts to create the object by extracting a create DDL from the file , and otherwise, it applies delta differences (Alter DDLs) to make the object definitions in the file  match to the target database .","Comparison utility  of some embodiments also handles differences in database DDL syntax with respect to new features available in specific versions. Comparison utility  of several embodiments also has a debug mode which when invoked reports all the changes that are intended to be made based on a specific file  and a specific target database , without actually making the changes.","Comparison utility  of one embodiment has the following advantages: 1) unlike prior (non-generic) SQL script-based solutions, no manual analysis is required for each database component change, including revision history of the database object; 2) less error-prone and therefore improves patch success rates; 3) enables easy diagnosis and analysis in case of failures; 4) provides support for all Oracle database components; 5) easier to maintain, evolve and avoid costs in terms of resources and time; 6) optimized to improve time taken during patching; 7) eliminates myriad different files involved previously & replaces them with XML file format, which is the Industry standard","A comparison utility  of this embodiment is written in PERL and Java, and it compares database object definitions contained in the file  with the actual database object definitions in the target database and then applies the changes to the object in the target database accordingly. This comparison utility  also contains the following features: Supports Customization to object storage that is frequent occurrence at most customer databases; supports both Dictionary and locally managed Tablespaces available in Oracle Databases; supports propagating database comments for tables\/views\/materialized views at the target database; and supports automatic drop\/recreate of Indexes and materialized view logs on materialized views. When a XDF materialized view query differs from the query in the target database the MV needs to be dropped and re-created. Once a materialized view is dropped the dependent indexes and materialized view logs are automatically dropped. XDF handles the re-creation of these secondary objects automatically.","Comparison utility  of this embodiment also supports object creation in parallel, grants privileges and creates synonyms for base schema objects to the appropriate APPS (application) schema(s) at the time it creates the base schema objects. It verifies the synonyms in the same way that it verifies the base schema objects themselves. This comparison utility  also updates AOL (Application Object Library) Data Dictionary for schema object definition related changes. These tables are automatically updated by XDF with the relevant data. Finally, this comparison utility  also support for new and old tablespace models & integration with the AD (Applications Database) Tablespace API.","AOL (Application Object Library) Data Dictionary tables updated by the XDF Comparison utility are as shown in Table \u201cC\u201d below.",{"@attributes":{"id":"p-0069","num":"0068"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE C"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"FND_TABLES","FND_COLUMNS"]},{"entry":[{},"FND_FOREIGN_KEYS","FND_PRIMARY_KEYS"]},{"entry":[{},"FND_FOREIGN_KEY_COLUMNS","FND_PRIMARY_KEY_COLUMNS"]},{"entry":[{},"FND_VIEWS","FND_HISTOGRAM_COLS"]},{"entry":[{},"FND_OBJECT_TABLESPACES"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"Referring to , on receipt of input from a human, act  is performed to validate the input. Specifically, a database connection is established in act  and an xdf file identified by the human is checked to confirm that its syntax is valid. Note that in many embodiments of the type described herein, the xdf file being checked is the same xdf file which is prepared by the generation utility discussed above. Note, however, that the xdf file may be an altered version of the generated xdf file, depending on the embodiment. For example, because the xdf file is expressed in XML format, a simple text editor can be used by a human to modify the generated xdf file and the modified file can be supplied to the comparison utility . Note further that since the xdf file is in XML format a source code control system (such as SCCS available for the Unix operating system) is used in some embodiments to version control the xdf file. Such version control of the xdf file is used in several such embodiments with version control of application source code, so that changes being made to a database (e.g. addition of a new column to an existing table) are in conformity with changes being made to application source code that refers to the database (e.g. references to the new column).","After act , the comparison utility  performs an act  wherein metadata is extracted from the xdf file. The metadata is being extracted for all the objects in the file. Next, in act  the target database is checked for existence of the object whose metadata is extracted in act . If the object doesn't exist, then act  is performed. In act , XSLT is applied to 1) replace schema references and storage properties for the object and 2) build the Create DDL (data definition language) for the object. XSLT is the XSL Transform language being used to apply remap of schema and storage for the object, as these could differ at the target database.","Act  of the comparison utility  builds the Create DDL. Therefore, after act  is completed, act  is performed to execute a CREATE\/ALTER DDL command on the target database. Next, in act , a check is made to see if metadata for any additional secondary object is still present in the xdf file, and if so then control returns to act . In act  if no additional metadata is present, then act  is performed, wherein APPS (Applications) specific metadata present in the AOL (Application Object Library) Data Dictionary is extracted from the xdf file and updated in the AOL (Application Object Library) Data Dictionary at the target database. Next, logs are generated in act  which record the results of all the Xdf comparison acts including any errors, warnings and finally reports either success\/failure of the metadata propagation to the target database. Applications System Administrators and Database Administrators will monitor the logs to gauge the success\/failure of the patch.","In act , if the object is found to exist in the target database, then act  is performed wherein hash codes are compared. If the hash codes match in act , then act  is performed as discussed above. If there is no match in the hash codes, then act  is performed wherein the object metadata is extracted from the target database. Next, act  is performed wherein the object metadata in the xdf file is compared with the metadata from the target database. All differences between metadata are resolved in favor of the xdf file metadata. Next, act  is performed, as discussed above.",{"@attributes":{"id":"p-0074","num":"0073"},"figref":["FIGS. 4A-4G","FIGS. 4A-4G","FIGS. 4A-4G","FIG. 4A"],"b":["200","401"]},"Following hint  is a list  of all objects whose metadata is present in this file. Following list  is a set of tags  () that contain application specific metadata. Following the application specific metadata tags  is the set of tags  () that contain metadata of the TEST_TABLE object. Note that a hash code  () is included in this file for the entire TEST_TABLE object. This hash code  is generated from not only property values of the table, such as name, flags in  and blocks, groups in , but also additional hash codes as noted next. Specifically, in file , a hash code is also included for certain properties such as each column, as illustrated by hash codes  and  () for the two columns in this example. Note that these hash codes  and , are used in preparation of hash code  for the table. All hash codes - are sent over from the source computer to the target computer, at their appropriate locations in file  to enable quick comparison.","Note that after the metadata of the TEST_TABLE object, in this example file  contains additional metadata as shown in  which is automatically extracted by generation utility  as per act  in , for a secondary object that is automatically identified in this example as being a constraint from a containment list for \u201ctable\u201d type primary objects (because object TEST_TABLE is a table type primary object). Note that the metadata in  for the index is placed in file  immediately after the metadata of TEST_TABLE.","Utilities  and  are used to program a computer system  of the type illustrated in  which is discussed next. Specifically, computer system  includes a bus  () or other communication mechanism for communicating information, and a processor  coupled with bus  for processing information. Computer system  also includes a main memory , such as a random access memory (RAM) or other dynamic storage device, coupled to bus  for storing information and instructions to be executed by processor .","Main memory  also may be used for storing temporary variables or other intermediate information during execution of instructions to be executed by processor . Computer system  further includes a read only memory (ROM)  or other static storage device coupled to bus  for storing static information and instructions for processor . A storage device , such as a magnetic disk or optical disk, is provided and coupled to bus  for storing information and instructions.","Computer system  may be coupled via bus  to a display , such as a cathode ray tube (CRT), for displaying information to a computer user. An input device , including alphanumeric and other keys, is coupled to bus  for communicating information and command selections to processor . Another type of user input device is cursor control , such as a mouse, a trackball, or cursor direction keys for communicating direction information and command selections to processor  and for controlling cursor movement on display . This input device typically has two degrees of freedom in two axes, a first axis (e.g., x) and a second axis (e.g., y), that allows the device to specify positions in a plane.","As described elsewhere herein, automated database patching is provided by computer system  in response to processor  executing one or more sequences of one or more instructions contained in main memory . Such instructions may be read into main memory  from another computer-readable medium, such as storage device . Execution of the sequences of instructions contained in main memory  causes processor  to perform the process steps described herein. In alternative embodiments, hard-wired circuitry may be used in place of or in combination with software instructions to implement the invention. Thus, embodiments of the invention are not limited to any specific combination of hardware circuitry and software.","The term \u201ccomputer-readable medium\u201d as used herein refers to any medium that participates in providing instructions to processor  for execution. Such a medium may take many forms, including but not limited to, non-volatile media, volatile media, and transmission media. Non-volatile media includes, for example, optical or magnetic disks, such as storage device . Volatile media includes dynamic memory, such as main memory . Transmission media includes coaxial cables, copper wire and fiber optics, including the wires that comprise bus . Transmission media can also take the form of acoustic or light waves, such as those generated during radio-wave and infra-red data communications.","Common forms of computer-readable media include, for example, a floppy disk, a flexible disk, hard disk, magnetic tape, or any other magnetic medium, a CD-ROM, any other optical medium, punch cards, paper tape, any other physical medium with patterns of holes, a RAM, a PROM, and EPROM, a FLASH-EPROM, any other memory chip or cartridge, a carrier wave as described hereinafter, or any other medium from which a computer can read.","Various forms of computer readable media may be involved in carrying one or more sequences of one or more instructions to processor  for execution. For example, the instructions may initially be carried on a magnetic disk of a remote computer. The remote computer can load the instructions into its dynamic memory and send the instructions over a telephone line using a modem. A modem local to computer system  can receive the data on the telephone line and use an infra-red transmitter to convert the data to an infra-red signal. An infra-red detector can receive the data carried in the infra-red signal and appropriate circuitry can place the data on bus . Bus  carries the data to main memory , from which processor  retrieves and executes the instructions. The instructions received by main memory  may optionally be stored on storage device  either before or after execution by processor .","Computer system  also includes a communication interface  coupled to bus . Communication interface  provides a two-way data communication coupling to a network link  that is connected to a local network . Local network  may interconnect multiple computers (as described above). For example, communication interface  may be an integrated services digital network (ISDN) card or a modem to provide a data communication connection to a corresponding type of telephone line. As another example, communication interface  may be a local area network (LAN) card to provide a data communication connection to a compatible LAN. Wireless links may also be implemented. In any such implementation, communication interface  sends and receives electrical, electromagnetic or optical signals that carry digital data streams representing various types of information.","Network link  typically provides data communication through one or more networks to other data devices. For example, network link  may provide a connection through local network  to a host computer  or to data equipment operated by an Internet Service Provider (ISP) . ISP  in turn provides data communication services through the world wide packet data communication network  now commonly referred to as the \u201cInternet\u201d. Local network  and network  both use electrical, electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on network link  and through communication interface , which carry the digital data to and from computer system , are exemplary forms of carrier waves transporting the information.","Computer system  can send messages and receive data, including program code, through the network(s), network link  and communication interface . In the Internet example, a server  might transmit a requested code for an application that has been changed and file  (describing objects in a changed database that are used by the application) through Internet , ISP , local network  and communication interface . In accordance with the invention, one such downloaded application and file  provides for implementing automated patching of a database, as described herein.","The received application and file  may be executed by processor  as it is received, and\/or stored in storage device , or other non-volatile storage for later execution. In this manner, computer system  may obtain the file  and the related application in the form of a carrier wave.","Note that  is a very low-level representation of many hardware components of a computer system. Several embodiments have one or more additional software components in main memory  as shown in : Operating System  (e.g. Microsoft WINDOWS 2000), Database Server  (e.g. Oracle Server v9i2 for the source computer; e.g. Oracle Server v8i for the target computer), Java Development Kit  (e.g. JDK v118), Java XMLParser  (e.g. xmlparser available from Oracle Corporation), and JDBC drivers  (e.g. JDBC driver available from Oracle Corporation).","Numerous modifications and adaptations of the embodiments described herein will become apparent to the skilled artisan in view of this disclosure. For example, although two computers  and  are shown in , all acts described above as being performed by these computers are performed by a single computer in an alternative embodiment. In the alternative embodiment, the source database and the target database are both present in the single computer. In still other embodiments, generation of file  and comparison with target database  are performed in one computer while changing of the database is performed in another computer. Moreover, file  as well as changes to an application that are supported by database changes documented in file  may be packaged into a set of files that are distributed together (on a single storage medium or on the same carrier wave) to customers interested in upgrading their version of the application. In addition, the comparison utility may itself be packaged into the just-described distribution in some embodiments. Also, the above-described generation and comparison utilities can be used i) by internal development teams during creation and testing of object definitions and ii) for propagating these object definitions to customer databases during patching.","Numerous modifications and adaptations of the embodiments described herein are encompassed by the scope of the invention.","The following appendices A-E are a integral part of this detailed description and are incorporated by reference herein in their entirety. These appendices provide further detailed descriptions of an illustrative embodiment of the type shown in .","The following assumptions have been made in the context of XDF Generation\/Comparison Utility Design.","The format of the xdf (xml file containing object definitions) file is such that the parent object and its secondary object(s) are clubbed together in one file. For Example\u2014the table definition along with all its indexes, constraints and triggers are clubbed together in one single XML file. XDF utility creates the grants and synonyms for base schema objects to the appropriate APPS (applications) schema(s) at the time the base schema objects are created. This happens in the comparison utilty. This utility verifies the synonyms in the same way that it verifies the base schema objects themselves, and only recreates the synonym if they are missing or incorrect. XDF utility creates a grant for a base object giving the corresponding APPS (applications) schema \u2018grant all with grant option\u2019 on that base object.","Tables","In addition to normal tables, XDF supports the following types of tables:\n\n","Hence XDF utility does not support partitioning of an existing non-partitioned table.\n\n","The query underlying the view should not contain any schema references. The view query should be using the synonym created for the base tables and should not refer the base tables directly.","Materialized Views","Materialized views are schema objects that can be used to summarize, precompute, replicate, and distribute data. They are suitable in various computing environments such as data warehousing, decision support, and distributed or mobile computing. Materialized views are used to precompute and store aggregated data, such as sums and averages. They can also be used to precompute joins with or without aggregations. Cost-based optimization can make use of materialized views to improve query performance by automatically recognizing when a materialized view can and should be used to satisfy a request. The optimizer transparently rewrites the request to use the materialized view. Queries are then directed to the materialized view and not to the underlying detail tables or views. Materialized views are similar to indexes in several ways: they consume storage space, they must be refreshed when the data in their master tables changes, and, when used for query rewrites, they improve the performance of SQL execution and their existence is transparent to SQL applications and users.","Oracle maintains the data in materialized views by refreshing them after changes are made to their master tables. The refresh method can be incremental (fast refresh) or complete. For materialized views that use the fast refresh method, a materialized view log or direct loader log keeps a record of changes to the master tables.","Materialized views can be refreshed either on demand or at regular time intervals. Alternatively, materialized views in the same database as their master tables can be refreshed whenever a transaction commits its changes to the master tables.","A materialized view, when created, will create a table, an index and may be one or more views, all in the same schema as that of the materialized view. If you create a materialized view MV, a table (MV), an index (I_SNAP$_MV) will be created in the same schema.","XDF supports the following Materialized View features\u2014\n\n","XDF does not support the following Materialized View features at this point\n\n","XDF recommends the following standards, applicable to Materialized Views creation and modification. Some of these are enforced\u2014\n\n","XDF drops & re-creates the Materialized View in the following cases\u2014\n\n","XDF supports the following Materialized View Log features\u2014\n\n","XDF alters the Materialized view Log in the following cases\u2014\n\n","XDF drops & re-creates the Materialized View Log in the following cases\u2014\n\n","The \u2018START WITH\u2019 value of a sequence cannot be modified once the sequence has been already created because the data could be potentially already used.","Indexes",{"@attributes":{"id":"p-0109","num":"0000"},"ul":{"@attributes":{"id":"ul0019","list-style":"none"},"li":["1. The physical attributes of a partition in a partitioned index are assumed to be the same as that of the underlying index. If different sets of values have been specified for different partitions then modification to these physical attributes is not supported by XDF phase 2.","2. If the functional indexes use a user-defined function then the function must exist in the database i.e. the creation of function-based index should in a phase after the creation of PL\/SQL packages.","3. As per divisional standards for Function-based indexes\u2014The packages are created in the APPS schema and in order to create a function-based index, the schema owning the table (BASE) must have EXECUTE privilege on the functions used in the index. Also, the packages are created with INVOKERS RIGHTS privileges. So the schema owning the table must have access to underlying objects.\n\nTypes\n"]}},"Object types are schema objects. They are abstractions of the real-world entities\u2014for example, purchase orders\u2014that application programs deal with. There are two categories of object datatypes:\n\n","Object datatypes use the built-in datatypes and other user-defined datatypes as the building blocks for datatypes that model the structure and behavior of data in applications.","Each collection type describes a data unit made up of an indefinite number of elements, all of the same datatype. The collection types are array types and table types. The corresponding data units are called VARRAYs and nested tables.","XDF alters the ADT in the following cases:\n\n","XDF drops & re-creates the ADT in the following cases:\n\n","Table and Constraints on Table","XSL (kutable.xsl) is used to transform the XDF file containing the description of the table into a create DDL statement, if the object does not exist in the target database. If the object exists then a hashcode is generated for the object from the target database and is compared with the hashcode present in the XDF. If they do not match the individual columns are compared based on the column names. The column sequence of the column is not considered. Any difference in the column structure is modified with \u2018ALTER TABLE\u2019 clause.","To add an additional column to the table the following syntax is used","ALTER TABLE <table name> ADD (<column definition>)","If the column to be added is a NOT NULL column then a database default value has to be provided. Otherwise an error is returned indicating that a NOT NULL column without any default value is being added to the existing table.","To modify a column from NOT NULL to NULL","ALTER TABLE <table name> MODIFY (<column name> NULL)","To modify a column from NULL to NOT NULL","ALTER TABLE <table name> MODIFY (<column name> NOT NULL)","If the column contains NULL values then the above DDL statement fails and the corresponding error is returned.","To modify other properties of a column","ALTER TABLE <table name> MODIFY (<new column definition>)","The datatype of any column can be changed only if all the rows for the column are null. The size of a column can be increased. But to decrease the size of column all the rows for the column must contain NULL. If the column to be modified is part of the table or index partitioning key or part of a domain index the definition of the column cannot be modified. Corresponding errors are returned for any of the above exceptions.","To modify the storage parameters","ALTER TABLE <table name> STORAGE (<storage clause> <value>)","ALTER TABLE <table name> INITRANS <value> MAXTRANS <value> etc . . .","The storage parameters are modified only if the modified value is greater than the current existing default value. Error related to auto segment space management is ignored. Also the degree of parallelism is always set to NOPARALLEL if otherwise. The PCTINCREASE is also always set to  if otherwise and similarly MAXEXTENTS to UNLIMITED.","To modify the integrity and referential constraints","If the constraint already exists and has evolved then the constraint is first dropped using","ALTER TABLE <tableName> DROP CONSTRAINT <constraintName>","The keyword CASCADE is appended to the above ALTER statement if the constraint is a primary or unique key.","The constraint definition is then constructed from the xdf file and created using the following statement","ALTER TABLE <tableName> ADD CONSTRAINT <constraintName> [UNIQUE|PRIMARY KEY] (column list separated by a \u2018,\u2019)","If the constraint is a foreign key constraint then the following DDL is used","ALTER TABLE <tableName> ADD CONSTRAINT <constraintName> FOREIGN KEY (column list separated by a \u2018,\u2019) REFERENCES <tableName> (column list separated by a \u2018,\u2019)","The referenced table name cannot exist in multiple schemas. The table schema should be uniquely identifiable.","If the constraint is a check constraint then the following DDL is used.","ALTER TABLE <tableName> ADD CONSTRAINT <constraintName> CHECK (check condition)","Views","If the view contained in the XDF file does not exist in the target database then a XSL file (kuview.xsl ) is used to transform the XDF file into a create DDL statement. If the object exists then the underlying view query in the xdf file is compared with the query in the database and if different the view is re-created by transforming the XDF file into a create or replace DDL statement.","ODF creates all views with FORCE option. The default behavior for existing views is \u201creplace\u201d (replace existing view using \u2018CREATE OR REPLACE FORCE VIEW\u2019).","Sequences","The \u2018kuseq.xsl\u2019 XSL file is used to transform the XDF file containing the description of the sequence into a create DDL statement, if the sequence does not exist in the target database. If the object exists in the target database the existing sequence is compared with the sequence description in the XDF file and any difference is modified with the ALTER SEQUENCE clause.","An Error is returned if the existing START WITH value of the sequence is greater than MAXVALUE of the sequence in the XDF file.","The DDL statements that can be issued to equate the sequence in the target database are","ALTER SEQUENCE <sequenceName> INCREMENT BY <new Value> [MAXVALUE <integer>\/NOMAXVALUE] <MINVALUE <integer>\/NOMINVALUE] [CYCLE\/NOCYCLE] [CACHE <integer>\/NOCACHE] [ORDER\/NOORDER]","Indexes","The \u2018kuindex.xsl\u2019 XSL file is used to transform the XML file containing the description of the index, into a create DDL statement, if the object does not exist in the target database. If the DDL statement execution fails because of \u201cmaximum number of extents exceeded\u201d error, then the initial extent is set to the value of how much space the index used when it hit maxextents and the process is looped to maximum of ten times for the CREATE statement to succeed.","If the create statement fails because of \u201ccolumn list already indexed\u201d error then an attempt is made to rename the already existing index to the one specified in the XML file. But if the uniqueness of both the indexes is different then the existing index is dropped and recreated according to the definition in the XML file along with a warning message.","An error message is displayed for any other unacceptable error in the creation of the index.","To rename the index the following DDL statement is used:","ALTER INDEX <existing index name> RENAME to <indexName>","To alter storage parameters the following statements are used:","ALTER INDEX <indexName> STORAGE (<storage clause> <value>)","ALTER INDEX <indexName> INITRANS <value> MAXTRANS <value> etc . . .","To split or add to an existing partitioned index the following statement is used","ALTER INDEX <indexName> SPLIT PARTITION <partition_name> INTO (PARTITION <partition_name1> PARTITION <partition_name2>)","To rename an existing partition","ALTER INDEX <indexName> RENAME PARTITION <partition name> TO <partition name1>","If the index already exists in the database, then the index in the XML file and the index in the database are compared. If the difference is because of any of the following cases then the index is dropped and recreated:","The table name or table owner is incorrect","The uniqueness is wrong","The database index has too few columns","The database index has too many columns","The database index has right number, wrong column names","The database index has right number, right names, and wrong order","The database index is a non-partitioned index and the file index is a partitioned index and vice versa","The database index is a global index partition and the file index is a local index partitions and vice versa.","The database index partition is a range partition and the file index is a hash partition","The database index is bitmap index and file index is a non-bitmap index","The following statement is used to drop the index: DROP INDEX <index name>","Once the index is dropped then the XSL transformation is applied to the XML file to generate the CREATE INDEX statement.","The XDF generator program is the next generation version of the current odf utilities to generate database object definitions in XML. The specific file extension used for these xml files is .xdf (to distinguish xml files containing object definitions from others). The generator program currently requires Oracle 9iR2 database, since it uses the metadata API (dbms_metadata).","Note: The xdf file contains the complete definition of the primary object and secondary object(s). After initial generation of the xdf file, subsequent changes, regardless of whether they are specific only to the primary object and\/or secondary object(s) result in the complete definition of the primary and secondary object(s) being generated.","Usage:","java oracle.apps.fnd.odf2.FndXdfGen","jdbc_conn_string=<jdbc tns info> object_name=<object name>","xsl_directory=<xsl file Dir>","[object type=<object type>]","[owner_app_shortname=<application short name of schema in which object is to be created in>]","[apps_schema=<appld>]","[apps_pwd=<appPassword>]","[jdbc_protocol=<jdbc driver type>]","[xdf_filename=<xdf file name>]","[deferred=<all|<list>>]","[Dropcr=<list>]","[logfile=<filename>]","[Custom_Defval=colName1=col1Value;colname2=col2Value]","[IncludeTriggers=<n|<list>>]","[IncludePolicy=<n|<list>>]","[PolObjName=<object_name>]","[PolObjOwner=<object_owner>]","[Data_Sec_Vpd=<y|Y>]","[Base_Partition=<partition_name>]","[IncludeSequence=<list>]","[Apply_DbVersion=<Database_Version>]","[Comments_Only=<Y\/N>]","[obsolete=<all|none>]","Mandatory Arguments","jdbc_conn_string: jdbc tns information either in format of Net8 connect string enclosed in double quotes or hostname:port:oracle_sid format.","object_name: The name of the database object whose XML object definition is being extracted. If the mode is trigger or sequence then the wildcard character \u2018%\u2019 can be used in the object name to retrieve a set of related sequences or triggers.","xsl_directory: The xsl directory, which contains all the xsl files required for XSLT transformation. This is parameterized to facilitate any additional custom transformations that may be required for hosting or other purposes.","Optional Parameters","apps_schema: ORACLE schema name of current APPS(Applications) schema. Default=APPS, if not specified.","apps_pwd: ORACLE schema password of current APPS(Applications) schema. Default=APPS, if not specified.","jdbc_protocol: jdbc protocol (thin or oci8). This parameter is required to procure a connection from the JDBC Driver manager. Default=thin, if not specified.","object_type: The Primary object type for which the xml definition is required\u2014table, qtable, mview, mviewlog, sequence, type, trigger, view owner_app_shortname: This parameter refers to the Application short name of the application to which the object belongs. The owner_app_shortname is currently used as an informational parameter only. The Application information is used to populate the AOL (Applications object Library) Data Dictionary. Since the Database allows the same object name to be used in different schemas, this is required. This will be used to determine the schema in which to create the object, given that schema names can be different at customer sites. If object already exists, it defaults to the value in AOL(Applications object Library) data Dictionary. Otherwise, the base application (application with lowest application id will be picked).","xdf_filename: The default behavior is that the xdf file name will be autogenerated based on the Primary Object Name. The object definition of the specified object is retrieved in the file mentioned. The file name will be automatically prefixed with \u201c.xdf\u201d extension. Default=<object_name>.xdf","Deferred: This is support for the deferred creation of indexes until later. To specify which indexes to defer, use the option: deferred=<comma-separated list of indexes to defer> or if all indexes have to be deferred then deferred=all. This option is relevant in context of Applications Database Patching Utility. It is relevant for the standalone utility usage only when used in conjunction with constraints.","DropCr: ODF supports dropping constraints and recreating them in a later phase. The list of constraints that have to be dropped and recreated are specified as dropCr=<comma separated list of constraints>.","Logfile: The output of odfv2 generator program is written to standard out. Specify a logfile name if it has to be written to a log file.","Custom_defval: This pertains only when the mode is equal to table. If a table column needs to be updated with a specific value when the table definition is modified (usually from null to not null, or adding a new not null column), then the custom_defval parameter can be used. The format of this parameter value is columnName=<value>. If more than one column in the table has to be updated, then the delimiter is semicolon \u2018;\u2019.","IncludeTriggers: This is to specify a list of triggers to be included with the table definition. By default all triggers on a table are included in the XDF file along with the table definition. If trigger definitions are not to be included along with table definitions, this parameter needs to be used with \u2018N\u2019. Else, a comma-separated list of trigger names should be provided. The default value is IncludeTriggers=y","Base_Partition: This is to specify the name of the partition to be included with the table definition. By default all the partitions on a table, is included in the XDF file along with the table definition. By specifying this parameter it is ensured that only the specific partition is included in the XDF file.","IncludeSequence: This is to specify a list of sequences to be included with the table definition. By default the sequence, which drives the (logical) primary key on a table, is included in the XDF file along with the table definition. It is assumed to be of the format <table_name>_S. If additional sequence definitions are to be included along with table definition, this parameter needs to be used with a comma-separated list of sequence names.","Apply_DbVersion:This is to specify the minimum version of the target database to apply the objects in the XDF file. By default all the objects in the XDF file are created\/compared on the target database. By specifying this option you apply the objects in the XDF file if and only if the target database version is greater than or equal to the specified apply_dbversion.","Comments_only: [Y\/N], This option is used if, only the comments specified on the object in the XDF file have to be propagated. By default the value for this option is N i.e. all the objects specified in the XDF file are propagated.","Obsolete: Currently, support to obsolete MVs & base table MV logs is provided. In case of MVs, the base MV will be dropped, obsoleting all its secondary objects like indexes, MV log, triggers, etc, In case of base table MV logs, the MV log is dropped, obsoleting secondary objects like indexes, triggers, etc. Partial obsoletion of secondary objects is an enhancement we are considering for the future. Permitted values are obsolete=all. The default value is obsolete=none.",{"@attributes":{"id":"p-0217","num":"0000"},"ul":{"@attributes":{"id":"ul0026","list-style":"none"},"li":"1. Global Temporary Table\u2014The following command is used to generate a XDF file with file name wf_local_users_temp.xdf for a table WF_LOCAL_USERS_TEMP, which belongs to a product with application short name FND."}},"java oracle.apps.fnd.odf2.FndXdfGen","jdbc_conn_string=ap105fam:1521:atg9idev","object_name=WF_LOCAL_USERS_TEMP xsl_directory=\/nfs\/group\/fnddev\/fnd\/11.5\/patch\/115\/xdf\/xsl\n\n","java oracle.apps.fnd.odf2.FndXdfGen","jdbc_conn_string=ap105fam:1521:atg9idev object_name=JTF_TASKS_B xsl_directory=\/nfs\/group\/fnddev\/fnd\/11.5\/patch\/115\/xdf\/xsl custom_defval=\u201cOBJECT_VERSION_NUMBER=1;\u201d\n\n","java oracle.apps.fnd.odf2.FndXdfGen","jdbc_conn_string=ap105fam:1521:atg9idev","object_name=PER_CONTRACTS_F xsl_directory=\/nfs\/group\/fnddev\/fnd\/11.5\/patch\/115\/xdf\/xsl","deferred=PER_CONTRACTS_F_PK dropCr=PER_CONTRACTS_F_PK\n\n","java oracle.apps.fnd.odf2.FndXdfGen jdbc_conn_string=\u201c(DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=ap513dbs)(POR T=1521))(CONNECT_DATA=(SID=OLAPDEV)))\u201d object_name=BIL_BI_OPTY_T_MV xsl_directory=\/nfs\/group\/fnddev\/fnd\/11.5\/patch\/115\/xdf\/xsl\n\n","java oracle.apps.fnd.odf.FndXdfGen","jdbc_conn_string=ap105fam:1521:atg9idev","object_name=ABMBG_ACT_ACCT_DATA_VAR_V","xsl_directory=\/nfs\/group\/fnddev\/fnd\/11.5\/patch\/115\/xdf\/xsl\n\n","java oracle.apps.fnd.odf2.FndXdfGen","jdbc_conn_string=ap105fam:1521:atg9idev object_name=AK_REGIONS object_type=mviewlog","xsl_directory=\/nfs\/group\/fnddev\/fnd\/11.5\/patch\/115\/xdf\/xsl","The Comparison Utility compares database object definitions contained in a file with extension \u201c.xdf\u201d (which is an XML file) with the database objects in an ORACLE schema, detects any differences in database structure, and executes SQL statements to propagate the differences, so that the objects in the schema will match the definitions in the xdf file.","XDF (xml) files are generated by the XDF generator utility. The .xdf file extension is used to distinguish xml files containing object definitions from others.","Usage:","java oracle.apps.fnd.odf2.FndXdfCmp","<schemald>","<schemaPassword>","<appld>","<appPassword>","<jdbc driver type>","<jdbc tns info>","<object_type>","<xdf file name>","<xsl file directory>","[deferred=<list>]","[dropCr=<list>]","[logfile=<filename>]","[Data_Sec_Vpd=<y|Y>]","[Standalone=<y|Y>]","[changedb=<y|n>]","Mandatory Arguments","schema_name: ORACLE schema name in which the object exists or should be created.","schema_Pwd: ORACLE schema password in which the object exists or should be created.","apps_schema: ORACLE schema name of current APPS(Applications) schema.","apps_pwd: ORACLE schema password of current APPS(Applications) schema.","jdbc_protocol: jdbc protocol (thin or oci8).","jdbc_connect_string: jdbc tns information either in format of Net8 connect string enclosed in double quotes or hostname:port:oracle_sid format.","object_type: the object type information\u2014table, qtable, mview, mviewlog, sequence, type, trigger, view, policy","xdf_filename: The xdf file name, which contains the object definition.","xsl_directory: The xsl directory, which contains all the xsl files required for XSLT transformation.","Optional Parameters","Deferred: XDF supports deferring creation of some indexes until later. The list of indexes that have to be deferred are specified as deferred=<comma-separated list of indexes to defer>","Logfile: The output of XDF comparison utility is written to standard out. Specify a logfile name if it has to be written to a log file.","ChangeDb: The default for changeDB=y. If the changedb is specified as \u2018n\u2019 then the SQL statements generated by the odf comparison utility are not executed but displayed on the standard output or a log file.","DropCr: XDF supports dropping constraints and recreating them in a later phase. The list of constraints that have to be dropped and recreated are specified as dropCr=<comma separated list of constraints>.","Data_Sec_Vpd: This is used to specify that a service security synonyms or view has to be created dynamically based on the database version. If the database version is 9 then a synonym is created else a view is created. Permitted values are data_sec_vpd=y","Standalone: This option is used to execute the XDF comparison utility in a standalone mode. Permitted values are standalone=y",{"@attributes":{"id":"p-0268","num":"0000"},"ul":{"@attributes":{"id":"ul0032","list-style":"none"},"li":"1. Global temporary Table\u2014The following command is used to compare a table definition in the XDF file wf_local_users_temp.xdf with the definition in the database atgcore and run sql statements to remove the differences such that the object defintion in the database matches the definition in the XDF file."}},"java oracle.apps.fnd.odf2.FndXdfCmp applsys apps apps apps thin ap105 fam:1521:atgcore table \/home\/sbrahman\/wf_local_users_temp.xdf \/fnddev\/fnd\/11.5\/patch\/115\/xdf\/xsl\n\n","java oracle.apps.fnd.odf2.FndXdfCmp jff jff apps apps thin ap 112fam:1521:atgcore table jta_sync_contact_mapping.xdf \/fnddev\/fnd\/11.5\/patch\/115\/xdf\/xsl","deferred=JTA_SYNC_CONTACT_MAPPING_U1\n\n","java oracle.apps.fnd.odf2.FndXdfCmp apps apps apps apps thin ap105fam:1521:atgcore mview bil_bi_opty_t_mv.xdf \/fnddev\/fnd\/11.5\/patch\/115\/xdf\/xsl\n\n","java oracle.apps.fnd.odf2.FndXdfCmp apps apps apps apps thin ap112fam:1511:atgcore view abmbg_act_acct_data_var_v.xdf \/fnddev\/fnd\/11.5\/patch\/115\/xdf\/xsl",{"@attributes":{"id":"p-0274","num":"0332"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"APPENDIX E"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"(Table Example)"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"21pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"1","CREATE TABLE \u201cTEST_TABLE\u201d"]},{"entry":[{},"2","\u2003( \u201cCOL1\u201d NUMBER(15,0),"]},{"entry":[{},"3","\u2003\u2003\u201cCOL2\u201d DATE"]},{"entry":[{},"4","\u2003) STORAGE (INITIAL 4096 NEXT 40960 MINEXTENTS"]},{"entry":[{},{},"\u20031 MAXEXTENTS 505"]},{"entry":[{},"5","\u2003PCTINCREASE 50 FREELISTS 1 FREELIST GROUPS 1"]},{"entry":[{},{},"\u2003BUFFER_POOL"]},{"entry":[{},"6","DEFAULT)"]},{"entry":[{},"7"]},{"entry":[{},"8"]},{"entry":[{},"9","CREATE INDEX \u201cTEST_TABLE_I1\u201d ON TA"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE FIGURES","p":[{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIGS. 4A-4G","FIG. 2","FIG. 3"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 5A","FIG. 1","FIG. 5B","FIG. 5A"],"b":"506"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIGS. 6A and 6B"}]},"DETDESC":[{},{}]}
