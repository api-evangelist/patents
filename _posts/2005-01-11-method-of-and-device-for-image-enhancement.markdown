---
title: Method of and device for image enhancement
abstract: A method of enhancing an image comprises determining whether brightness values have changed in an output screen of documents that include a text and an image, with respect to a pixel located in a predetermined edge detection region; calculating binarization data values based on each pixel brightness values of a plurality of windows that are formed by applying different samplings to the detected region, when the brightness values are changed in excess of a predetermined threshold Tha, and determining a connectivity of the calculated binarization data values with respect to each of a plurality of windows; estimating the pixel to be edge pixel when the binarization data values have a connectivity; and determining finally the estimated pixel to be an edge pixel when a number of pixels estimated as an edge is in excess of a predetermined fixed value THd, and if not, determining the estimated edge pixel as not being an edge pixel.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07746503&OS=07746503&RS=07746503
owner: Samsung Electronics Co., Ltd.
number: 07746503
owner_city: Suwon-Si
owner_country: KR
publication_date: 20050111
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["PRIORITY","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE EXEMPLARY EMBODIMENTS"],"p":["This application claims priority under 35 U.S.C. \u00a7119(a) to Korean Patent Application No. 2004-03047, entitled \u201cMethod of and Device for Image Enhancement\u201d, filed on Jan. 15, 2004, in the Korean Intellectual Property Office, the entire contents of which are hereby incorporated by reference.","1. Field of the Invention","The present invention relates to a method of, and a device for enhancing an image that obtains improved quality output when a printer prints a document printed with respect to an image input from an image scanning device. More particularly, the present invention relates to a method of, and a device for enhancing an image that distinguishes an actual edge of a text region from an edge of an image region to emphasize the actual edge of the text region.","2. Description of the Related Art","An image enhancement apparatus operates to ensure that a given image is converted to the extent that a human can easily discern. An example of a general image enhancement apparatus and method thereof is disclosed in Korean Patent No. 10-2002-0059531 (the '531 Korean Patent), the entire contents of which are hereby incorporated by reference, which discloses a method and device for enhancing the quality of a text and image document. The '531 Korean Patent device mainly comprises a classification unit, a post-process unit, an emphasis unit.","The classification unit of the '531 Korean Patent uses saturation, slope information, and the number of connecting element number to estimate pixels to be processed as either \u2018T\u2019, \u2018I\u2019 and \u2018U\u2019 pixels. The post-process unit corrects errors in classified information to determine \u2018T\u2019 or \u2018I\u2019 pixels. The emphasis unit emphasizes a present pixel from the classified \u2018T\u2019 information to obtain an improved image.","The above-described conventional method compares the average values of the mask and brightness value of each pixel from a single window mask to extract a binary value and calculate a connecting element value N. Because the conventional method uses only a single window to calculate a connecting element value N, characteristics around the target pixel can not be fully reflected. Accordingly, edge detection accuracy may be decreased or the requirements for memory and calculation increased, especially for documents that are output based on a low line per inch (LPI) requirement, such as a newspaper having characteristics around the observed pixel similar to a letter.","The conventional method computes the binary data on the basis of average values in a window mask. The number of pixels having the binarization data value of 1 is not regular. Therefore, the possibility of mis-classification increases between a text edge and a halftone image edge, when the edge is configured diagonally.","The present invention has been developed in order to solve the drawbacks discussed above, as well as others not mentioned, and other problems associated with the conventional arrangement. An aspect of the present invention is to provide a method and device for enhancing image quality wherein an actual edge of a text region and an edge of an image region are distinguished from each other, and only the actual edge of text region are allowed to pass through a high frequency improving filter so that an improved quality reproducing image can be obtained.","It is another aspect of the present invention to provide a method and a device for enhancing image quality that considers a relativity and similarity of each binarization data of a plurality of windows to output an improved image and text mixed document, regardless of the LPI characteristic.","It is yet another aspect of the present invention to provide a method and device for enhancing image quality that calculates a binarization data value using a threshold value preset by a user, and keeps the regular number of pixels having the binarization data value of 1 to reduce the possibility of mis-classification between an edge of a text region and an edge of an image region.","The above-mentioned aspects and\/or other features of the present invention can be substantially achieved by providing a method of enhancing an image comprising determining whether brightness values have changed with respect to a pixel located in a predetermined edge detection region in an output screen of documents that includes a text and an image, calculating binarization data values based on each pixel brightness values of a plurality of windows that are formed by applying different samplings to the detected region when the brightness values are in excess of a predetermined threshold THa, and determining a connectivity of the calculated binarization data values with respect to each of a plurality of windows, estimating the predetermined pixel to be an edge pixel when the binarization data values exhibit connectivity, and determining that the predetermined pixel is an edge pixel when the number of predetermined pixels estimated as edge pixels are in excess of a predetermined preset value THd, and if the number of predetermined pixels estimated as edge pixels are not in excess of the predetermined preset value, determining that the predetermined pixel is not an edge pixel.","When the binarization data values exhibit connectivity, the step of estimating the predetermined pixel to be an edge pixel can further comprise determining a similarity of the binarization data values of pixels corresponding to each of the plurality of windows, and estimating the predetermined pixel to be an edge pixel when the binarization data values of the predetermined pixel corresponding to each of the plurality of windows have a similarity.","The method of enhancing an image according to an embodiment of the present invention further comprises emphasizing the pixel determined as an edge. The step of emphasizing the pixel determined to be an edge further comprises estimating as a pixel to not be edge pixel when the change of each pixel brightness value is less than the predetermined threshold THa.","The method of enhancing an image according to an embodiment of the present invention further comprises the step of estimating a pixel to not be an edge pixel when the binarization data values have no connectivity. The method of enhancing an image according to an embodiment of the present invention further comprises the step of estimating the predetermined pixel to not be an edge pixel when the binarization data values of the predetermined pixel corresponding to a plurality of windows have no similarity.","The step of calculating binarization data values according to an embodiment of the present invention further comprises generating a plurality of 3\u00d73 window masks by applying different samplings to a 5\u00d79 window of the detection region wherein a predetermined brightness value is indicated on each pixel, generating binarization data values from the brightness values of each pixel of a plurality of the sampled 3\u00d73 window masks, and grouping the binarization data values to calculate a connected component value N with respect to each window mask. The samplings as applied can comprise 5\u00d75, 5\u00d77 and 5\u00d79 samplings with respect to a 600 dpi image.","The binarization data value can be \u20181\u2019 when the brightness value of each pixel is less than a predetermined threshold THb, and the binarization value is \u20180\u2019 when the brightness value of each pixel exceeds the predetermined threshold THb. The binarization data values can be estimated to have connectivity when all the connected component values N of each window mask are \u20181\u2019. The similarity of the binarization data value is determined by the equation:",{"@attributes":{"id":"p-0019","num":"0018"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"0"},"mn":"3"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"0"},"mn":"3"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":[{"mi":["a","ij"]},{"mi":["b","ij"]},{"mi":["c","ij"]}],"mo":["\u2062","\u2062"]}}},"mo":"\u2265","mi":"THc"}}}},"wherein a, b, care binarization data values of each pixel, THc is a predetermined threshold. The binarization data values are considered to have a similarity when the equation above is satisfied.","The above-mentioned aspects and\/or other features of the present invention can be substantially achieved by providing an image enhancement apparatus, comprising an edge classification unit for estimating an actual edge of a text region in a predetermined edge detection region of an output screen with respect to a document having text and image, an edge detection unit for confirming the edge estimated pixel to be a pixel edge if the number of the predetermined pixels estimated as pixel edges is in excess of a predetermined preset threshold THd, and if not, determining the edge estimated pixel to not be edge pixel, and an edge emphasis unit for emphasizing the pixel confirmed as an edge pixel.","The edge classification unit can further comprise a luminosity variance measurement unit for determining whether brightness value has changed with respect to the pixels in a predetermined edge detection region and a half tone detection unit for calculating binarization data value based on each pixel brightness value of a plurality of windows that are formed by applying various samplings to the detection region when the brightness values are in excess of a predetermined threshold Tha, determining a connectivity of the calculated binarization data values with respect to each of a plurality of windows, determining a similarity of the binarization data values of pixel corresponding to the plurality of windows when the binarization values have a connectivity, and estimating the predetermined pixel as an edge when the binarization data values have a similarity. The binarization data value can be \u20181\u2019 if each pixel brightness is less than a predetermined threshold THb, and the binarization data value can be \u20180\u2019 if each pixel brightness exceeds the predetermined threshold THb.","Several embodiments of the present invention will now be described in detail with reference to the annexed drawings. In the drawings, the same or similar elements are denoted by the same reference numerals even though they are depicted in different drawings. The matters defined in the description such as a detailed construction and elements are provided to assist in a comprehensive understanding of the embodiments of the present invention. Accordingly, those of ordinary skill in the art will recognize that various changes and modifications to the embodiments described herein can be made without departing from the scope and spirit of the present invention. In the following description, a detailed description of known functions and configurations incorporated herein have been omitted for conciseness and clarity.","Throughout the following detailed description of the exemplary embodiments of the present invention, reference is made to , which illustrates a method for implementing the embodiments of the present invention. The references are made to the various steps, for example step S, S, and so on. Attention should be directed towards  in such instances in order to appreciate the method.",{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 1","b":["40","10","20","30"]},"The image enhancement apparatus  detects and emphasizes an edge with respect to the image being input from an image inputting device , and provides the information after the emphasis to an image output\/reproducing device  such as a printer. The edge classification unit  comprises a luminosity variance measure unit  and halftone image detection unit . The luminosity variance measurement unit  measures a luminosity variance of pixels around a target pixel to classify the edges. The surrounding pixels are not estimated to be an edge when the luminosity variance is less than a predetermined threshold THa.","When documents are scanned using a high definition scanner with over 300 DPI resolution, the luminosity variance is sensed at intervals of \u201cline per inch\u201d (LPI) corresponding to the documents in an image region having a constant brightness. The luminosity variances act as noise, and severely deteriorate the image quality when an edge is emphasized. In one exemplary embodiment of the present invention, an image region having a constant brightness is defined as a halftone image region. A halftone image detection unit  distinguishes an actual edge in a text region from an edge in the above-described halftone image region. The halftone image detection unit  estimates that a pixel is not an edge pixel when the pixel is determined as halftone image.","The edge detection unit  receives the pixel estimated as an edge pixel in an edge classification unit  and detects the edge pixel to be finally emphasized. The edge emphasis unit  applies a high frequency improving filter to emphasize the edge pixel detected from the edge detection unit .",{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 2","b":["5","10"]},"According to an exemplary embodiment of the present invention, the luminosity variance of pixels is measured by use of a difference d between the highest value and the lowest value in the corresponding window. In decision step S of the method according to an embodiment of the present invention, the user sets in advance a proper threshold THa, and compares the difference d between the highest brightness value and the lowest brightness value of each pixel, with the preset threshold THa to determine a luminosity variance of each pixel.","If the difference d between the highest brightness value and the lowest brightness value does not equal or exceed the threshold THa, it is determined that no luminosity variance occurred and no edge is estimated (\u201cNo\u201d path from decisions step S; step S). If the difference d between the highest brightness value and the lowest brightness value equals or exceeds the threshold Tha (\u201cYes\u201d path from decision step S), it is determined that a luminosity variance has occurred, and therefore, a binarization data value is generated based on the brightness value of each pixel (step S). The process of generating the binarization data value is explained as below.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIGS. 3A through 4G","FIGS. 3A through 4G","FIG. 3A","FIG. 3B","FIG. 3A"],"b":["220","240","280"]},{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 3C","FIG. 3A"]},{"@attributes":{"id":"p-0042","num":"0041"},"figref":["FIG. 3D","FIG. 3A"]},{"@attributes":{"id":"p-0043","num":"0042"},"figref":["FIG. 4A","FIG. 4B","FIG. 4A","FIG. 4C","FIG. 4A","FIG. 4D","FIG. 4A"],"b":["1","3","5","3","5","7","1","3","5","2","5","8","1","3","5","1","5","9"]},"Each pixel brightness value shown in  and , can be compared to a threshold THb that is preset by a user, to calculate the binarization data value. For each pixel brightness value (BrV) that is less than the threshold THb, a binarization data of \u20181\u2019 is calculated, and for pixel brightness values that are greater than or equal to the threshold THb, a binarization data \u20180\u2019 is calculated. These relationships are illustrated in the table below. The threshold value THb can be a range of values. For example, 124 through 130 could be a threshold value THb. Also, the threshold value THb can be different among the different window masks shown in .",{"@attributes":{"id":"p-0045","num":"0044"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"140pt","align":"center"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]},{"entry":[{},"Binarization Data"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"BrV < THb","1"]},{"entry":[{},"BrV => THb","0"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"For example, the threshold THb of  can be 124, which is greater than 123 and less than 125. The threshold THb of  is greater than 125 and less than 144, while the threshold THb of  is greater than 150 and less than 159. The thresholds THb are set in advance by user. The threshold THb of  is 183, which is greater than 182 and less than 184. The threshold THb of  is greater than 180 and less than 187, and the threshold THb in (d) of  is more than 185 and less than 193.",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIGS. 3E through 3D","FIGS. 3B through 3D","FIGS. 4E through 4G","FIGS. 4B through 4D"]},"In a preferred embodiment of the present invention, only four directions are considered for the grouping: up, down, left and right. The diagonal direction is not considered when determining the grouping of a window mask. Grouping according to an embodiment of the present invention refers to the process of quantifying the physical locations of the binary data values in the binarization data value windows. Grouping is performed with respect to the binary \u201c1\u201d values only. As discussed above, the only directions that are considered in a preferred embodiment of the present invention are up, down, left and right. To group a binary data value window, the locations of the 1's are determined. All the 1's that are located to the left, right, up, and down of each other constitutes a group. If there are other 1's in the binary data value window that cannot reached from another 1 by an up, down left or right movement, that 1, or group of 1's constitutes another group. Hereinbelow, the number of groups will be referred to as a connected component value N for purposes of explanation of the embodiments of the present invention. When the process of grouping is completed, the number of the connected component value N of each 3\u00d73 window is determined. Generally, the connected component value is 1 in a text region, and greater than or equal to 2 in a halftone image region.","Referring to , the connected component value N of the text region remains 1, even though several windows are used. For example, in , each 1 in that binary data value window can be reached from another 1 by an up, down, left or right movement. The same is true for . Referring to , the connected component value N of a halftone image region is changed in accordance with the sampling mask. For example,  shows binarization values of a window of 5\u00d75 sampled pixels, where the connected component value N is 1.  show binarization values of windows of 5\u00d77 and 5\u00d79 sampled pixels, where the connected component value N is 2. In , the first group is the lone 1 at the top left corner of the binary data value window. All the other 1's can be reached from each other by a left, right, up or down movement, and therefore constitute a single group. Thus, in  there are two groups, and N=2.","The edge of the text region is not very sensitive to the change of window sizes, whereas the edge of the halftone image is sensitive to the change of window sizes. Accordingly, if a plurality of windows are used as above, the probability of mis-classification can be decreased with respect to the image pixel. The connectivity of each binarization data of a plurality of windows is determined based on the each connected component value N, and in decision step S, it is determined whether the window has connectivity.","If all the connected component values N of each window are 1, each binarization data of a plurality of windows is determined to have a connectivity (\u201cYes\u201d path from decision step S; step S). If all the connected component values N of each window are not 1, each binarization data of a plurality of windows is determined to have no connectivity. If it is determined to have no connectivity, it is estimated to not be an edge (\u201cNo\u201d path from decision step S).","Because all the connected component values N of  are 1, each binarization data of a plurality of windows is determined to have a connectivity. On the contrary, because all the connected component values N of  are not 1, each binarization data of the plurality of windows is determined to have no connectivity and estimated to not be an edge.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIGS. 5A through 5C","FIGS. 5A-5C"],"b":["280","320"]},"To determine whether the binarization data values between a plurality of windows have a similarity, equation 1 is used:",{"@attributes":{"id":"p-0055","num":"0054"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"0"},"mn":"3"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"0"},"mn":"3"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":[{"mi":["a","ij"]},{"mi":["b","ij"]},{"mi":["c","ij"]}],"mo":["\u2062","\u2062"]}}},"mo":"\u2265","mi":"THc"}},{"mrow":{"mo":["[","]"],"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}},"mn":"1"}}}]}}}}},"wherein a, b, care the binarization data values of each pixel in , and THc is a threshold preset by a user.","Generally, an edge of a text region has less change of location binarization as 1's, and an edge of a halftone image has greater change of the location being binarized as 1's, and therefore, a user needs to set a proper threshold THc. If equation 1 is satisfied, the binary data of a plurality of windows is determined to have a similarity so that it is estimated to be an edge. If equation 1 is not satisfied, the binary data of a plurality of windows is determined to not have similarity, so that it is estimated not to be an edge","For example, if the threshold THc is set to \u20183\u2019 by a user, applying equation 1 to  results in",{"@attributes":{"id":"p-0059","num":"0058"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"0"},"mn":"3"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"0"},"mn":"3"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":[{"mi":["a","ij"]},{"mi":["b","ij"]},{"mi":["c","ij"]}],"mo":["\u2062","\u2062"]}}},"mo":"=","mn":"3"},"mo":","}}},"br":{},"b":["280","320","340"]},"In step S of the method according to an embodiment of the present invention, pixels estimated to be an edge based on the process described above are labeled as E, and pixels estimated as no edge are labeled as N. When an edge is estimated based on the above process, the edge detection unit  removes the edge-estimated pixel from the halftone image region, and compensates for the non-edge estimated pixels of an actual edge region such as text, so that the edge can be finally detected.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 6A","FIG. 6B","FIG. 6C","FIG. 6A","FIGS. 6B and 6C"],"b":"10"},"The method according to an embodiment of the present invention determines in decision step S, whether the number of edge estimated pixels E in the window of 9 pixels is greater than the preset threshold THd (S). If the number of edge estimated pixels E is greater than the preset threshold THd (\u201cYes\u201d path from decision step ), it is finally determined to be an edge (step S), while if not, it is determined to not be an edge in step S (\u201cNo\u201d path from decision step ).","The threshold THd is preset to 6 by a user according to an exemplary embodiment of the present invention. Referring back to , the number of pixels labeled as E among the 9 pixels is 7 and therefore, it is finally determined to be an edge. Referring to , the number of pixels labeled as E among 9 pixels is 5, and therefore, it is finally determined to not be an edge.","When the pixels corresponding to edges are detected based on the above process, the next step according to an embodiment of the present invention is executed to emphasize the output of the edge detected pixels (S). For pixel emphasis, edge emphasizing filters such as unsharp masking are applied. Pixels detected as not being an edge are output as originally input.","According to one example of an emphasizing filter according to an embodiment of the present invention, the pixel brightness of the pixels to be emphasized is obtained based on equation 2 below;\n\n()\u2003\u2003[Equation 2]\n","wherein L is an original pixel brightness to be emphasized, L\u2033 is an average brightness value in a window, and L\u2032 is an emphasized brightness value. K is an emphasis coefficient.","According to the exemplary embodiments as explained above, an actual edge of a text region is distinguished from an edge of an image region, and a high frequency improvement filter is applied only to the actual edge of the text region to prevent degradation of image quality. The edges of text and thin lines are easily determined and emphasized without any damage thereto, and therefore the quality of reproduced images can be substantially improved.","Additionally, the image enhancement method and device according to the exemplary embodiments of the present invention can provide improved image quality even with respect to the document of mixed text and images irrespective of LPI characteristics and therefore, high edge detection accuracy can be obtained even in documents being output based on a low LPI, such as newspapers.","Additionally, the image enhancement method and device according to the embodiments of the present invention is based on a threshold being preset by a user instead of an average value of window mask which is used in the conventional art, to keep the number of pixels having a binarization data value to 1. Accordingly, the possibility of misclassifying a text edge and a halftone image edge can be substantially decreased in the case of a diagonal edge.","The foregoing embodiments and advantages are merely exemplary and are not to be construed as limiting the present invention. The present teaching can be readily applied to other types of apparatuses. Also, the description of the embodiments of the present invention is intended to be illustrative, and not to limit the scope of the claims, and many alternatives, modifications, and variations will be apparent to those skilled in the art."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The above aspects and features of the present invention will be more apparent by describing certain embodiments of the present invention with reference to the accompanying drawings, in which:",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIGS. 3A through 4G"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIGS. 5A-C"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 6B"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 6C"}]},"DETDESC":[{},{}]}
