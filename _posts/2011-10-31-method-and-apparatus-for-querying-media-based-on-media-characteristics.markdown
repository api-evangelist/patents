---
title: Method and apparatus for querying media based on media characteristics
abstract: An approach is provided for querying media based on media characteristics. A media platform processes and/or facilitates a processing of one or more images, one or more videos, or a combination thereof to determine one or more latent vectors associated with the one or more images, the one or more videos, or the combination thereof. The media platform further causes, at least in part, a comparison of the one or more latent vectors to one or more models. The media platform also causes, at least in part, an indexing of the one or more images, the one or more videos, or the combination thereof based, at least in part, on the one or more latent vectors, the one or more models, or a combination thereof.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09477664&OS=09477664&RS=09477664
owner: Nokia Technologies Oy
number: 09477664
owner_city: Epsoo
owner_country: FI
publication_date: 20111031
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SOME EXAMPLE EMBODIMENTS","DESCRIPTION OF SOME EMBODIMENTS"],"p":["Service providers and device manufacturers (e.g., wireless, cellular, etc.) are continually challenged to deliver value and convenience to consumers by, for example, providing compelling network services. The amount of user-created content accessible by devices through the network services is increasing. However, no services currently exist that allow a consumer to query for media (e.g., an image or a video) based on the characteristics associated with the media, such as a location associated with the media, or a location associated with the media that is within a boundary of a location. Further, no such services currently exist that allow a consumer to query for media based on the type of content that is contained within the media. By way of example, a consumer cannot tell that a video contains mountains unless the author of the video tagged the video as including mountains. Therefore, service providers and device manufacturers face significant technical challenges in providing a service that allows consumers to query media based on, for example, the location of the media, as well as other characteristics associated with the media.","Therefore, there is a need for an approach for querying media based on characteristics associated with the media.","According to one embodiment, a method comprises causing, at least in part, a rendering of a user interface for determining a selection of at least one of the one or more models, one or more objects represented by the one or more models, or a combination thereof. The method also comprises causing, at least in part, a querying of the index for the one or more images, the one or more videos, one or more segments of the one or more images, one or more segments of the one or more videos, or a combination thereof based, at least in part, on the selection. The method further comprises causing, at least in part, a rendering of one or more results of the query in the user interface. According to another embodiment, a method comprises processing and\/or facilitating a processing of one or more images, one or more videos, one or more segments of the one or more images, one or more segments of the one or more videos, or a combination thereof to determine one or more latent vectors (also known as eigenvectors, characteristic vectors or invariant vectors) associated with the one or more images, the one or more videos, the one or more segments of the one or more images, the one or more segments of the one or more videos, or the combination thereof. The method also comprises causing, at least in part, a comparison of the one or more latent vectors to one or more models. The latent vectors may represent one or more objects and\/or topics contained in the media and act as a signature for the media. The one or more models may represent one or more known objects and the associated latent vectors of the known objects. The latent vectors are representational vectors based on one or more latent parameters that characterize the associated images, videos, and segments of the images\/and or videos. The method further comprises causing, at least in part, an indexing of the one or more images, the one or more videos, the one or more segments of the one or more images, the one or more segments of the one or more videos, or the combination thereof based, at least in part, on the one or more latent vectors, the one or more models, or a combination thereof.","According to another embodiment, an apparatus comprises at least one processor, and at least one memory including computer program code for one or more computer programs, the at least one memory and the computer program code configured to, with the at least one processor, cause, at least in part, the apparatus to render a user interface for determining a selection of at least one of the one or more models, one or more objects represented by the one or more models, or a combination thereof. The apparatus is also caused to query the index for the one or more images, the one or more videos, one or more segments of the one or more images, one or more segments of the one or more videos, or a combination thereof based, at least in part, on the selection. The apparatus is further caused to render one or more results of the query in the user interface. According to another embodiment, an apparatus comprises at least one processor, and at least one memory including computer program code for one or more computer programs, the at least one memory and the computer program code configured to, with the at least one processor, cause, at least in part, the apparatus to process and\/or facilitate a processing of one or more images, one or more videos, one or more segments of the one or more images, one or more segments of the one or more videos, or a combination thereof to determine one or more latent vectors associated with the one or more images, the one or more videos, the one or more segments of the one or more images, the one or more segments of the one or more videos, or the combination thereof. The apparatus is also caused to compare the one or more latent vectors to one or more models. The apparatus is further caused to index the one or more images, the one or more videos, the one or more segments of the one or more images, the one or more segments of the one or more videos, or the combination thereof based, at least in part, on the one or more latent vectors, the one or more models, or a combination thereof.","According to another embodiment, a computer-readable storage medium carries one or more sequences of one or more instructions which, when executed by one or more processors, cause, at least in part, an apparatus to render a user interface for determining a selection of at least one of the one or more models, one or more objects represented by the one or more models, or a combination thereof. The apparatus is also caused to query the index for the one or more images, the one or more videos, one or more segments of the one or more images, one or more segments of the one or more videos, or a combination thereof based, at least in part, on the selection. The apparatus is further caused to render one or more results of the query in the user interface. According to another embodiment, a computer-readable storage medium carries one or more sequences of one or more instructions which, when executed by one or more processors, cause, at least in part, an apparatus to process and\/or facilitate a processing of one or more images, one or more videos, the one or more segments of the one or more images, the one or more segments of the one or more videos, or a combination thereof to determine one or more latent vectors associated with the one or more images, the one or more videos, the one or more segments of the one or more images, the one or more segments of the one or more videos, or the combination thereof. The apparatus is also caused to compare the one or more latent vectors to one or more models. The apparatus is further caused to index the one or more images, the one or more videos, the one or more segments of the one or more images, the one or more segments of the one or more videos, or the combination thereof based, at least in part, on the one or more latent vectors, the one or more models, or a combination thereof.","According to another embodiment, an apparatus comprises means for causing, at least in part, a rendering of a user interface for determining a selection of at least one of the one or more models, one or more objects represented by the one or more models, or a combination thereof. The apparatus also comprises means for causing, at least in part, a querying of the index for the one or more images, the one or more videos, one or more segments of the one or more images, one or more segments of the one or more videos, or a combination thereof based, at least in part, on the selection. The apparatus also comprises means for causing, at least in part, a rendering of one or more results of the query in the user interface. According to another embodiment, an apparatus comprises means for processing and\/or facilitating a processing of one or more images, one or more videos, the one or more segments of the one or more images, the one or more segments of the one or more videos, or a combination thereof to determine one or more latent vectors associated with the one or more images, the one or more videos, the one or more segments of the one or more images, the one or more segments of the one or more videos, or the combination thereof. The apparatus also comprises means for causing, at least in part, a comparison of the one or more latent vectors to one or more models. The apparatus further comprises means for causing, at least in part, an indexing of the one or more images, the one or more videos, the one or more segments of the one or more images, the one or more segments of the one or more videos, or the combination thereof based, at least in part, on the one or more latent vectors, the one or more models, or a combination thereof.","In addition, for various example embodiments of the invention, the following is applicable: a method comprising facilitating a processing of and\/or processing (1) data and\/or (2) information and\/or (3) at least one signal, the (1) data and\/or (2) information and\/or (3) at least one signal based, at least in part, on (or derived at least in part from) any one or any combination of methods (or processes) disclosed in this application as relevant to any embodiment of the invention.","For various example embodiments of the invention, the following is also applicable: a method comprising facilitating access to at least one interface configured to allow access to at least one service, the at least one service configured to perform any one or any combination of network or service provider methods (or processes) disclosed in this application.","For various example embodiments of the invention, the following is also applicable: a method comprising facilitating creating and\/or facilitating modifying (1) at least one device user interface element and\/or (2) at least one device user interface functionality, the (1) at least one device user interface element and\/or (2) at least one device user interface functionality based, at least in part, on data and\/or information resulting from one or any combination of methods or processes disclosed in this application as relevant to any embodiment of the invention, and\/or at least one signal resulting from one or any combination of methods (or processes) disclosed in this application as relevant to any embodiment of the invention.","For various example embodiments of the invention, the following is also applicable: a method comprising creating and\/or modifying (1) at least one device user interface element and\/or (2) at least one device user interface functionality, the (1) at least one device user interface element and\/or (2) at least one device user interface functionality based at least in part on data and\/or information resulting from one or any combination of methods (or processes) disclosed in this application as relevant to any embodiment of the invention, and\/or at least one signal resulting from one or any combination of methods (or processes) disclosed in this application as relevant to any embodiment of the invention.","In various example embodiments, the methods (or processes) can be accomplished on the service provider side or on the mobile device side or in any shared way between service provider and mobile device with actions being performed on both sides.","For various example embodiments, the following is applicable: An apparatus comprising means for performing the method of any of originally filed claims -, -, and -.","Still other aspects, features, and advantages of the invention are readily apparent from the following detailed description, simply by illustrating a number of particular embodiments and implementations, including the best mode contemplated for carrying out the invention. The invention is also capable of other and different embodiments, and its several details can be modified in various obvious respects, all without departing from the spirit and scope of the invention. Accordingly, the drawings and description are to be regarded as illustrative in nature, and not as restrictive.","Examples of a method, apparatus, and computer program for querying media based on characteristics associated with the media are disclosed. In the following description, for the purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the embodiments of the invention. It is apparent, however, to one skilled in the art that the embodiments of the invention may be practiced without these specific details or with an equivalent arrangement. In other instances, well-known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the embodiments of the invention.","As used herein, the term media refers to any type of media that may include, for example, one or more images, one or more fragments or portions of images, one or more animated images, one or more fragments or portions of animated images, one or more videos, one or more fragments or portions of videos, or a combination thereof, where the media may be two-dimensional, three-dimensional, or a combination thereof. Although various embodiments are described with respect to images and videos, it is contemplated that the approach described herein may be used with other type of content that can be indexed according to one or more characteristics associated with the media.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 1"},"By way of example, a user may capture a video of the surrounding environment while out on a hike. To remember the content of the video, the user may label the video according to the date the video was taken and the general subject of video (e.g., hike). However, the user may fail to tag the video according to the location of the video, where automatic tagging of the video according to, for example, the location is not done automatically based on the acquiring device. Alternatively, even if the video is tagged according to, for example, the location by the user or by the device, the user may not provide additional annotations to the already embedded location metadata. Further, the user may fail to tag the video according to the video covering topics such as mountains, rivers, trees, fields, etc. that the user passed by while on the hike. The user also may have failed to tag the various aspects of how the video was captured (e.g., frame rate, perspective, direction, field of view, etc.). Moreover, even considering media that includes all of the above metadata (e.g., location information, topic information, characteristic information, etc.), and assuming such media is uploaded to querying services, current media querying services do not provide ways to query for media based on the above-mention characteristics. Therefore, although the amount of media is increasing at an ever increasing rate based on new services and devices, the ability of users to access this media based on querying platforms has not increased to meet the increase in the amount of media.","To address this problem, a system  of  introduces the capability to query media based on characteristics associated with the media. The system  may render a user interface for determining a selection of at least one of one or more models, at least one of one or more objects represented by the one or more models, one or more characteristics associated with the media, or a combination thereof. By way of example, the system  may render a user interface in the form of a map on a user device. The map may cover an area that is selected by a user, such as a specific country, specific coordinates, a boundary around a specific location, or the like. Thus, based on the user interface of the map, the user may query for media that is associated with the location represented by the map.","The queried media may be defined by a selected model, a selected object represented by the model, or characteristics associated with the media. By way of example, if the user is querying for media associated with a mountain for the specific location, the user may provide a query string, such as mountain, that would result in selecting the appropriate model of a mountain on a server end as a basis for performing a match\/selection process. Alternatively, or in addition to the foregoing, the user may select an object represented by the model of a mountain, such as a representative image of a mountain, that would result in selecting the model of a mountain on a server end as a basis for performing a match\/selection process. Further, the user may enter characteristics associated with a mountain, and may further select one or more characteristics associated with the media, such as time of day, season, orientation, depth of field, etc.","The system  further queries an index of media based on the selection associated with the user interface. The queried media may represent one or more images and\/or one or more videos. In one embodiment, the queried media may represent one or more segments of the one or more images and\/or one or more videos. Thus, in one embodiment, the system  allows for segmenting media associated with the system  into one or more segments that more narrowly define the content of the media within the segments. By way of example, if a single video includes segments associated with a lake, mountains, and a river, respectively, the video can be segmented into the three respective segments and each segment may be queried for separately as compared to the entire video.","The system  further renders one or more results of the query in the user interface. The one or more results of the query represent the media that are associated with the selected models, objects, and\/or characteristics. For example, where the user interface is associated with a map of a location, the results of the query are media that are associated with the location. The media may be further defined by the selected models, objects represented by the models, and\/or the characteristics.","By way of example, the user selects the object of mountains associated with a certain area represented by a map rendered in the user interface. The system  then queries an index for all of the media associated with the model of mountains and associated with the location represented by the map. Upon determining the media that are associated with the model of mountains and the location, the system  presents all of the media satisfying the query to the user for the user to select from. Accordingly, the system  presents a way for querying and presenting media associated with, for example, a specific location, a boundary around a specific location, and other characteristics associated with the media. Thus, by way of example, if the user is creating a video and requires many different videos with many different topics and\/or objects associated with the videos, the system  may provide the user a way of querying for media based on the topics and\/or objects associated with the media according to the characteristics associated with the media.","In one embodiment, the system  indexes media so that the media may be queried by the system . The system  may process the media to determine one or more latent vectors associated with the media. Prior to processing the media to determine the one or more latent vectors, the media may be segmented into one or more smaller segments. The system  may then process the segments of the media to determine one or more latent vectors associated specifically with the segments. The latent vectors may represent the one or more objects and\/or topics contained in the media and act as a signature for the media. The system  may then cause a comparison of the one or more latent vectors with one or more models. The one or more models may represent one or more known objects and the associated latent vectors of the known objects. The latent vectors associated with the objects are determined based on factorizing one or more media covering or associated with one or more known topics, sets of topics, and\/or content using latent parameters. By comparing the one or more latent vectors determined from the media with the one or more models, the system  may determine the topics and\/or objects within the media and index the media accordingly. Further, by optionally segmenting the media into one or more smaller segments, the system  may determine topics, sets of topics, and\/or objects within the segments of the media and index the segments accordingly. Thus, by way of example, one or more segments of media may by indexed differently than the media itself based on the specificity of the content within the one or more segments.","By way of example, one media may be a video of a mountain. The latent vector calculated for the mountain will have certain signatures that are unique to a mountain. By comparing the latent vector associated with the video, and, therefore, associated with the mountain, to a latent vector associated with a model of a mountain, the system  may determine that the media is associated with the object of a mountain. The system  may then cause an indexing of the media based on the one or more latent vectors associated with the media, the one or more models associated with the media according to the comparison, or a combination thereof. Therefore, the system  allows the media to be indexed based on the media including the object of the mountain regardless of whether the media was tagged as being associated with a mountain. Accordingly, the system  allows for access to the increasing number of media based on latent vectors associated with the media.","As shown in , the system  comprises a user equipment (UE)  having connectivity to media platform  via a communication network . The user equipment may include one or more applications -(collectively referred to as applications ) executed by the UE . By way of example, exemplary applications  may include video editing applications, image editing applications, Internet browsing applications, social networking applications, media sharing applications, and the like. In one embodiment, one or more of the applications  interface with the media platform  for querying for the media.","In one embodiment, the media platform  may include or be associated with a model database  and an index database . The model database  may include the models that are compared to the latent vectors of the processed media to determine the one or more objects associated with the media. The models may be latent vectors of known media that have been factorized using one or more latent parameters. By way of example, a media of a known topic, and only the known topic, may be factorized using one or more latent parameters to build a model for the known topic. The model database  may also include the one or more topics and\/or objects that are associated with the models. The index database  may store the indexed latent vectors associated with the media. In one embodiment, the index database  stores the indexed latent vectors without storing the associated media. Thus, in such an embodiment, the index database  also includes one or more links (e.g., URLs, URIs) to the respective media associated with the indexed latent vectors. In one embodiment, the index database  stores the indexed latent vectors associated with the media, and the media itself, rather including links to the media. In one embodiment, the index database  can store the topics determined such as the name of one or more topics, based on matching between latent vectors of the media and known models, negating the need to store the latent vectors.","The system  also includes a services platform  and content providers -(collectively referred to as content providers ). The services platform  includes one or more services -(collectively referred to as services ). The services  may include one or more social networking services, one or more content provisioning services (e.g., media provisioning services), one or more information provisioning services (e.g., context information, metadata information, etc.), and the like. The content providers  can provide content to the UE , the media platform  and the services  of the services platform . The content may include, for example, the media that is indexed by the media platform , media used by the services platform , and media from or for the UE .","By way of example, the communication network  of the system  includes one or more networks such as a data network, a wireless network, a telephony network, or any combination thereof. It is contemplated that the data network may be any local area network (LAN), metropolitan area network (MAN), wide area network (WAN), a public data network (e.g., the Internet), short range wireless network, or any other suitable packet-switched network, such as a commercially owned, proprietary packet-switched network, e.g., a proprietary cable or fiber-optic network, and the like, or any combination thereof. In addition, the wireless network may be, for example, a cellular network and may employ various technologies including enhanced data rates for global evolution (EDGE), general packet radio service (GPRS), global system for mobile communications (GSM), Internet protocol multimedia subsystem (IMS), universal mobile telecommunications system (UMTS), etc., as well as any other suitable wireless medium, e.g., worldwide interoperability for microwave access (WiMAX), Long Term Evolution (LTE) networks, code division multiple access (CDMA), wideband code division multiple access (WCDMA), wireless fidelity (WiFi), wireless LAN (WLAN), Bluetooth\u00ae, Internet Protocol (IP) data casting, satellite, mobile ad-hoc network (MANET), and the like, or any combination thereof.","The UE  is any type of mobile terminal, fixed terminal, or portable terminal including a mobile handset, station, unit, device, multimedia computer, multimedia tablet, Internet node, communicator, desktop computer, laptop computer, notebook computer, netbook computer, tablet computer, personal communication system (PCS) device, personal navigation device, personal digital assistants (PDAs), audio\/video player, digital camera\/camcorder, positioning device, television receiver, radio broadcast receiver, electronic book device, game device, or any combination thereof, including the accessories and peripherals of these devices, or any combination thereof. It is also contemplated that the UE  can support any type of interface to the user (such as \u201cwearable\u201d circuitry, etc.).","In one embodiment, the media platform  processes the media to determine one or more latent parameters associated with the media. The latent parameters can be human recognizable, computer recognizable, or a combination thereof. The media platform  determines the latent vectors associated with the media based on the latent parameters.","In one embodiment, the media may be associated with metadata. The metadata, for example, may be automatically generated by the device that created the media. By way of example, metadata may provide information regarding the context and characteristics of the media, such as the length, size, encoding, location, time, date, orientation, depth of field associated with the metadata. The type and kind of metadata may vary according to the type and kind of media associated with the metadata. The media platform  may process the media to determine the metadata associated with the media. Upon determining the metadata, the media platform  may index the media based on the metadata. By way of example, the media may be indexed according to the time of day, date (e.g., season), location, depth of field, direction, etc. By indexing the media according to the metadata, along with according to the latent factors, the media platform  allows user to include additional characteristics by which to choose from to query the media.","In one embodiment, the media platform  processes the media to determine one or more segments associated with the media. By way of example, where the media is a video, the media platform  may process the video determine the number of different scenes that exist in the video, which potentially concern different topics and\/or objects. For instance, a video may include mountains in one scene and a river in another scene. By way of example, where the media is an image, the media platform  may process the image to determine one or segments within the image that concern different objects. For instance, one segment of the image may concern mountains and another segment of the image may concern a tree.","The media platform  determines the various segments associated with the media and, for each segment, determines one or more latent vectors associated with the specific segment based on one or more latent parameters associated with the segment. Next, the media platform  compares the segment latent vectors with the one or more models. The media platform  can determine the topics and\/or objects associated with the specific segments of the media. The media platform  may also index the determined segments and\/or the media based on the segment latent vectors according to the comparison of the segment latent vectors with the models.","In one embodiment, where the media platform  determines one or more segments of the media, the media may also contain metadata. The metadata may not apply to the entire media, such that the metadata does not apply to all of the segments. In which case, the media platform  may synchronize at least part of the metadata with one or more of the determined segments of the media and\/or one or more segment latent vectors associated with the media. After synchronizing the metadata with the segments, the media platform  may index or cause an indexing of the one or more segments based on the synchronized metadata.","By way of example, where the media is a video that includes two scenes, one of a mountain and one of a river, the metadata may include orientation information associated with the mountain scene and the river scene. The media platform  may determine that the scene with the mountain and the scene with the river are two different segments. The media platform  then may determine what metadata belongs to what scene. For instance, the mountain scene may have been filmed while the camera was pointing north, and the river scene may have been filmed while the camera was pointing south. The media platform  may associate the north metadata with the mountain scene and the south metadata with the river scene and index the scenes accordingly.","In one embodiment, the media platform  may determine metadata based on one or more objects contained in the media in correlation with metadata associated with the models and\/or the objects associated with the models. The media platform  may determine that a latent vector associated with media matches a model that is associated with an object that has known metadata. For example, the object may be a well-known landmark. The media platform  may therefore index the media based on the metadata associated with the landmark, regardless of whether the media was created with the metadata.","By way of example, the media may be an image that includes the Eiffel Tower. The media platform  also may include a model that represents the Eiffel Tower. The model may also be associated with metadata associated with the Eiffel Tower, such as the location information of the Eiffel Tower. If the media platform  determines that the image matches the model associated with the Eiffel Tower, because the Eiffel Tower is in the image, the media platform  also may associate, for instance, the location information of the Eiffel Tower with the image based on the stored metadata associated with the model associated with the Eiffel Tower. Therefore, the media platform  may provide metadata to the media where the models include metadata.","In one embodiment, the media platform  may include one or more models that are associated with advertising information. Upon processing media that includes one or more representations of a specific object, if the media matches, at least in part, one or more models representing the specific object, and the specific object is associated with advertising information, the media platform  may index the media as being associated with the advertising information. In one embodiment, the media platform  may also overlay advertising information over the media such that, once a user is presented the media in response to a query, the advertising information is overlaid on the media.","By way of example, the media platform  may process a video a determine that a trademark or service mark is contained in the video based on comparing the latent parameters and\/or latent vectors associated with the video to one or more models associated with the trademark or service mark. The media platform  may index the media based, at least in part, on the trademark or service mark. Further, the media platform  may overlay information associated with the trademark or service mark over the video. Thus, when another user is presented the video based on a query, whether or not the query is regarding the trademark or the service mark, the video presents the additional information associated with the model representing the trademark or service mark.","By way of example, the UE , the media platform , the services platform , and the content providers  communicate with each other and other components of the communication network  using well known, new or still developing protocols. In this context, a protocol includes a set of rules defining how the network nodes within the communication network  interact with each other based on information sent over the communication links. The protocols are effective at different layers of operation within each node, from generating and receiving physical signals of various types, to selecting a link for transferring those signals, to the format of information indicated by those signals, to identifying which software application executing on a computer system sends or receives the information. The conceptually different layers of protocols for exchanging information over a network are described in the ISO Open Systems Interconnection (OSI) Reference Model.","Communications between the network nodes are typically effected by exchanging discrete packets of data. Each packet typically comprises (1) header information associated with a particular protocol, and (2) payload information that follows the header information and contains information that may be processed independently of that particular protocol. In some protocols, the packet includes (3) trailer information following the payload and indicating the end of the payload information. The header includes information such as the source of the packet, its destination, the length of the payload, and other properties used by the protocol. Often, the data in the payload for the particular protocol includes a header and payload for a different protocol associated with a different, higher layer of the ISO OSI Reference Model. The header for a particular protocol typically indicates a type for the next protocol contained in its payload. The higher layer protocol is said to be encapsulated in the lower layer protocol. The headers included in a packet traversing multiple heterogeneous networks, such as the Internet, typically include a physical (layer 1) header, a data-link (layer 2) header, an internetwork (layer 3) header and a transport (layer 4) header, and various application (layer 5, layer 6 and layer 7) headers as defined by the ISO OSI Reference Model.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 2","b":["103","103","103","201","203","205","207","209","211"]},"The control module  executes at least one algorithm for executing functions of the media platform . For example, the control module  may execute an algorithm for processing a query associated with a UE  for media associated with a certain location. By way of another example, the control module  may execute an algorithm to interact with the segmentation module  to cause segmentation of media. The control module  also may execute an algorithm to interact with the metadata module  to determine the metadata associated with media. The control module  also may execute an algorithm to interact with the analyzer module  to analyze media.","The segmentation module  segments the media into one or more segments depending on deviations within the media. For media such as video, deviations may occur from one set of frames to another based on changing scenes. For media such as images, deviations may occur from one grouping of pixels to another grouping of pixels. In one embodiment, the segmentation module  may use deviation thresholds and\/or metadata changes to determine a deviation. Where the segmentation module  determines a segment in the media, each segment is treated as separate and is separately processed.","By way of example for video media, the segmentation module  may skip N number of frames between two analyzed frames to check for a deviation. If no deviation is observed, the segmentation module  will move on to the next frame separated by N number of frames. If, instead, a deviation is observed that is above a set threshold, the segmentation module  will revert back to t\u2212N\/2 frames, where t is the position of the current frame. If f(A(t\u2212N\/2)\u2212f(A(t))>p, where f is the analysis function, A(t) represents the frame characteristics at position t and p is the threshold, then the distance is decreased to A (t\u2212N\/4) and so forth until the deviation is <p (e.g., less than the threshold deviation). Thus, for example, the frame where scene segmentation occurs is found through an iterative process. A similar process may be used where the media is an image based on, for example, one or more pixels and\/or sets of pixels rather than frames.","The foregoing segmentation process may be combined with metadata related to changes were available to reinforce the segmentation process. Alternatively, changes in metadata, alone, may be used to determine segmentation. Such as, for example, where location, time, date, orientation, depth of field, etc. change from one scene to another.","The metadata module  processes metadata associated with the media. Current metadata structures provide information on media such as length, encoding, location, time, date, depth of field, orientation, etc. Such metadata may be applicable for the entire media, and some metadata may be applicable for part of the media. By way of example, location may be constant across a single video. However, metadata such as orientation, depth of field, white balance, etc. may vary within the media between segments of the media. The metadata module  processes and extracts the metadata from the media.","In one embodiment, the metadata module  makes higher level inferences from a metadata stream along with timing and frame information, where applicable. Where applicable, the metadata module  synchronizes between extracted segments of the media and metadata. For example, in certain instances, there could be a mismatch between timing information extracted by the metadata module  for segments and between extracted segments from the segmentation module . The metadata module  re-negotiates the extracted media and the extracted metadata based on, for example, a metadata timing stream or additional analysis regarding the objects associated with the media. Thus, the metadata module  outputs a set of fully segmented and metadata synchronized segments of the media for further analysis.","The analyzer module  analyzes the media to determine the latent vectors used in indexing the media and the associated metadata. The analyzer module  transforms or collapses parameter space of the media and\/or segments of the media into a sub-parameter space as a representational vector that is stored in the index database . The analyzer module  receives the media and\/or segments of the media and processes the media to build one or more latent vectors associated with the media based on cluster patterns represented by latent parameters. By way of example for video media, the analyzer module  receives one or more segments of a video and processes each segment individually. The analyzer module  processes consecutive frame sets, with the set size being a pre-defined number, and builds a latent vector representing cluster patterns or scene patterns represented by one or more latent parameters. The latent parameters may be human recognizable and\/or machine (e.g., computer) recognizable. In one embodiment, the number of latent parameters used in building the latent vector is the same as the number of latent parameters used in building the latent vectors of the known topics (models). In one embodiment, for video, the analyzer module  may create a latent vector for each frame and average the latent vectors over the entire segment (e.g., scene) to determine one or more latent vectors associated with the entire segment. In one embodiment, the analyzer module  interfaces with the segmentation module  and\/or the metadata module  to also index the media and\/or segments of the media based on the metadata information, such as location, orientation, depth of field, etc.","In one embodiment, the analyzer module  also performs a similarity analysis. The analyzer module  searches, for example, the model database , the index database , or a combination thereof to find n number of most similar latent vectors as the latent vector associated with the media and\/or segment of media being processed. The similarity between the latent vectors may be determined based on, for example, the distance found between latent vectors according to a matching process (e.g., Cosine distance calculation), metadata match, or a combination of thereof. In one embodiment, the analyzer module  may determine multiple match sets based on different criterion and\/or parameters and thus create one or more similarity indexes for each latent vector analyzed.","In one embodiment, the media platform  can store latent vectors associated with standard object and\/or scene information related to, for example, mountains, rivers, forests, buildings, etc. as the models in the model database . Based on the distance between the latent vectors being analyzed and the latent vectors associated with the standard objects (e.g., models), a classification and indexing of the latent vectors associated with the media being analyzed can be performed through matching against the model latent vectors. In one embodiment, the latent vectors associated with the models and\/or objects represented by the models stored in the model database  are derived through a set of media that were previously manually tagged as containing certain properties with respect to any standard topology definition and factorized using latent parameters.","In one embodiment, the media platform  by way of the analyzer module  allows for a learning process where the indexed latent vectors generated from processing media are used to index additional media in conjunction with the models. Thus, by way of example, if media is analyzed as being associated with a forest based on the stored model associated with a forest, the analyzer module  may subsequently use both the model associated with the forest and the media that was analyzed as being associated with a forest to process additional media based on the latent vectors. Thus, the analyzer module  allows for the media platform  to continuously learn and update the processing to more accurately reflect the topics, objects and scenes that are associated with the media, starting from pre-defined models and using subsequently processed media and the associated latent vectors.","In one embodiment, the analyzer module  relies on building a unique signature for the media that is based on signal properties. Upon receiving the media and\/or segments of the media, the analyzer module  extracts feature coefficients that act as a signature for the media. The analyzer module  may then map the feature coefficient signature to one or more sets of topics through a simple match process where patterns have already been mapped to topics through a learning process.","In one embodiment, the analyzer module  uses a Label Latent Dirichlet Allocation (LLDA) (e.g., supervised LDA) clustering process that clusters data along topic distribution into sets of topics where the topics themselves are known based on one or more models. These sets of topics are based on frequency of similar data occurring within the corpus. Thus, in one embodiment, the LLDA process involves labeling a latent topic that has been pre-clustered. Once a latent pattern has been labeled, the models associated with the LLDA process whose topics are known can be used for clustering content along the particular labels\/models. Thus, a pattern of latent parameters associated with the media can be obtained that indicates how much a model is contained with the distribution. Such a modeling of media using pre-labeled models gives a unique distribution pattern of pre-modeled topics that act as a unique signature built upon know latent distributions. In one embodiment, the granularity of the models can increase to the extent that smaller and smaller objects and\/or topics can be determined based on the latent vectors. By way of example, the granularity of the model may be increased such that individual leafs can be distinguished in a picture of a forest.","The query module  receives one or more queries for media and determines the media that satisfy the query. The query module  interfaces with the user interface module  to render the presentation of the user interface for querying the media and for presenting the results of the query. In one embodiment, applications  interfacing with the media platform  interface with the query module  to query a backend service associated with the media platform . The query module  may provide a sequential query interface, a semantical query interface, a RESTful interface, or the like. The query module  queries the index database  for the media that are associated with a selection by the user. The query module  causes a querying of the index for the one or more media, the one or more segments of media, or a combination thereof based on a selection of a user. In one embodiment, the query module  queries the media based on one or more latent vectors associated with the media. By way of example, a user makes a selection of one or more latent vectors associated with a model, an object represented by a model, or a combination thereof by selecting a topic and\/or the object represented by the model. The query module  then searches the index database  for one or more latent vectors associated with the indexed media that match the one or more latent vectors associated with the selected models and\/or objects represented by the models.","In one embodiment, the query module  accepts further details regarding the specific media that a user is searching for and can accept details that are associated with the latent parameters and metadata used to index the media. By way of example, the query module  accepts details such as presence of individuals in the media, time, date, season, orientation, depth of field, type of scenery, etc.","The UI module  causes a rendering of a user interface associated with determining a selection of at least one of the one or more models, one or more objects represented by the one or more models, one or more characteristics associated with the models and\/or objections, or a combination thereof. By way of example, the UI module  can render a user interface associated with a map covering a location (e.g., a part of the world, a country, a city, etc.). A user may then select one or more specific locales associated with the location to query for media associated with the location. Upon determining one or more media that are associated with the selected models and\/or objects associated with the models, the UI module  presents the one or more media. In one embodiment, the UI module  presents the results overlaid on the rendering of a map to illustrate the location of the results with respect to the map. The UI module  can present further user interfaces, as described below with respect to .",{"@attributes":{"id":"p-0069","num":"0068"},"figref":["FIG. 3","FIG. 8"],"b":["300","103","300","301"]},"In one embodiment, the rendering may permit a user to filter the selection of a model and\/or an object represented by a model based on any characteristic used to index the media, such as any human recognizable characteristic, latent parameter and\/or metadata. By way of example, the rendering of the user interface (e.g., a map) may allow a user to filter the media based on the level of light associated with the media, whether users are contained and\/or associated with the media, the season associated with the media, a depth of field associated with the media, a time associated with the media, orientation of the media, or any combination thereof.","In step , the media platform  receives one or more media queries based on the selection of the user in response to the rendering of the user interface. In one embodiment, the query may correspond to a selection of a location, or a boundary of a location associated with a map, and a text string describing the queried media. In one embodiment, the query may not be related to a specific location but may instead include all of the locations that are indexed and associated with the media. In one embodiment, the query includes one or more models and\/or one or more objects represented by the models that the user is interested in for the query. By way of example, the user may be interested in media associated with mountains. Thus, the user may have selected one or more models that represent mountains. The media platform  receives the query and receives the indication of the models representing the mountains.","In step , the media platform  causes a querying of, for example, the index database  for media that satisfies the queried selection. The media platform  searches the index database  for the media that satisfies the parameters used in the query. For example, if the query is for videos associated with the topic of mountains associated with a certain location or a boundary of the location, the media platform  searches the index database  for the media that satisfy the topic of mountains and the location criteria.","In step , the media platform  determines all of the media that satisfy the query. By way of example, a query may be associated with a certain location as provided for based on a selection associated with a map. In one embodiment, the media platform  determines the media that satisfy the query based on the latent vectors and\/or the metadata associated with the media. In one embodiment, metadata associated with the media indicates the location associated with the media. Further, one or more latent parameters or latent vectors associated with the media may associate the media with an orientation, a depth of field, etc. Thus, in one embodiment, based on the topic the user selected and\/or the object the user selected, the latent vectors used to index the media according to the models and\/or the objects the models represent allow the media platform  to select the media that satisfy the user's selection.","In step , the media platform causes a rendering that presents the media based on the results of the query. The rendering may present the media based on one or more textual descriptions of the media, may present the media based on one or more graphical representations of the media, or a combination thereof. By way of example, when a location is used to query and\/or filter the media, the media may be rendered with respect to the graphical representation. By way of example, the media may be presented according to the specific locations associated with the media with respect to a map covering the area.",{"@attributes":{"id":"p-0075","num":"0074"},"figref":["FIG. 4","FIG. 8"],"b":["400","103","400","401","103","109","107","113","101","101","103","101","101","109","107","103"],"i":"a "},"In step , the media platform  processes the media to determine one or more sets of latent parameters associated with the media. As discussed above, the one or more sets of latent parameters define cluster patterns and\/or scene patterns associated with the media. The latent parameters may be human recognizable, machine (e.g., computer) recognizable, or a combination thereof.","In step , the media platform  processes the one or more sets of latent parameters to determine one or more latent vectors. The media platform  transforms or collapses the scene parameter space into a sub-parameter space as a representational vector based on the parameters. Thus, the latent vectors denote a clustering of the patterns for the media. In one embodiment, the media platform , where the media is associated with a video, may create latent vectors based on the latent parameters for every frame associated with the video. The media platform  can then average the latent vectors for the various frames to determine a latent vector associated with the entire media and\/or segments associated with the media.","In step , the media platform  causes a comparison of the one or more latent vectors to one or more models. In one embodiment, the comparison may be based on a signal-processing approach where a unique signature is built for the media based on signal properties. Feature coefficients are extracted for the media and act as a signature for the media. The feature coefficients may be mapped to one or more sets of topics through a match process where patterns have already been mapped to topics through a learning process. In one embodiment, the media platform  uses a Label Latent Dirichlet Allocation clustering process for the comparison that clusters data along topic distribution into sets of topics where the topics themselves are known based on one or more models. The LLDA process involves labeling a latent topic that has been pre-clustered. Once a latent pattern has been labeled, the models associated with the LLDA process whose topic is known can be used for clustering content along the particular labels\/models.","In one embodiment, based on the comparison, the media platform  can associate the media or segment of the media that is being processed with metadata associated with a model and\/or an object represented by a model based on known metadata associated with the model and\/or object represented by the model. By way of example, a model and\/or an object represented by a model may represent a specific object, such as a specific landmark. Information regarding the landmark may already be known, such as the location of the landmark. If, in comparing the latent vectors of the media to the models, the media platform  determines a match between the latent vectors of the media to a model representing a landmark, the media platform  may automatically associate the metadata information of the landmark with the media. Therefore, for instance, if an image includes a picture of the Eiffel Tower, the media platform  may automatically associate the location of the media as Paris, France regardless of whether the media includes metadata indicating that the image was taken in Paris, France.","Further, in one embodiment, information may be associated with the media for subsequent processing of the media with the additional information. The information may include additional media that may be overlaid over the original media based on the original media including one or more latent vectors associated with one or more models and\/or one or more objects represented by the models. By way of example, where a video includes a trademark that is detected by one or more latent vectors, the video may be associated with information that is associated with the trademark, such as advertisements associated with the trademark. Accordingly, in subsequent processing, the media platform  may overlay the advertisements over the media when presented to users in the form of query results.","In step , the media platform  causes an indexing of the media based on the latent vectors and\/or models associated with the latent vectors based on the comparison. In addition, where the media platform  associated the media with a model and\/or an object represented by a model that included metadata information, the media platform  may index the media based on the metadata information. By way of example, where the media platform  associated an image with the Eiffel Tower, the media platform may index the image based on the location Paris, France.",{"@attributes":{"id":"p-0082","num":"0081"},"figref":["FIG. 5","FIG. 8"],"b":["500","103","500","501","103","103"]},"In step , the media platform  processes the media to determine one or more segments associated with the media. The segments may be related to deviations in the media based on one or more deviation thresholds. The deviations may be determined based on the latent parameters and\/or of the metadata associated with the media. By way of example for videos, the deviation may be determined by analyzing the frames of the video to determine a deviation that exceeds a pre-defined threshold from one frame to the next. In one embodiment, a deviation is checked for between frames separated by N number of frames. Where a deviation is not detected, a deviation is checked for between the next frame separated by N number of frames. Where a deviation is detected, the analysis reverts back to t\u2212N\/2 frames, where t is the position of the current frame. If f(A(t\u2212N\/2)\u2212f(A(t))>p, where f is the analysis function, A(t) represents the frame characteristics at position t and p is the pre-defined threshold, then the distance is decreased to A (t\u2212N\/4) and so forth until the difference is <p (e.g., no longer greater than a threshold deviation). Thus, for example, the frame where scene segmentation occurs is found through an iterative process. A similar process may be used where the media is an image based on, for example, one or more pixels and\/or sets of pixels rather than frames.","In one embodiment, the metadata may be used to determine a deviation in the media. By way of example, for a video, where the metadata changes based on, for example, location, time, and\/or date by a pre-defined threshold, the media platform  may determine that there is a deviation in the media. After determining one or more segments of the media, the media platform  determines the latent vectors associated with the segments based on the same process described above with respect to the media, except for performing the processing with respect to only the segment.","In step , the media platform  causes a comparison of the segment latent vectors with the models according to the process described above with respect to the media as a whole, except the comparison is performed with respect to only the segment. Thus, in one embodiment, by way of example, where a media is associated with a video including many different scenes, one scene regarding mountains may be determined as a segment of the video and the scene is compared to one or more models to determine that the scene is associated with the topic of mountains. Accordingly, although the video as a whole may not have been determined to be about the topic of mountains (e.g., based on the proportion of mountains in the video with respect to other objects), the specific portion of the video that corresponds to the scene is determined to concern mountains.","In step , the media platform  may cause a synchronization of the metadata with the determined segments and\/or segment latent vectors. Some of the metadata associated with the media may apply to the entire media, such as location, date, time, etc. However, some of the metadata may apply to only a segment of the media, such as orientation, depth of field, etc. The media platform  in step  re-negotiates between the metadata module  and the segmentation module  regarding synchronizing the metadata with the determined segments. The re-negotiation may be based on a metadata stream that is re-negotiated with the timing information associated with the media. For example, a video may include metadata timing information associated with when the orientation and\/or depth of field changed. This timing information can be negotiated with the timing information of when images related to the video were captured to determine what metadata applies to what segments of the media. Accordingly, based on the synchronization, the media platform  associates the correct metadata with the correct segment.","In step , the media platform  causes an indexing of the media based on the one or more segments, the one or more segment latent vectors, the metadata, the synched metadata, or a combination thereof. Based on this indexing, the media platform  can provide one or more media more specifically associated with an object and\/or a topic. By way of example, rather than presenting an image of, among other things, a forest in response to a query for an image of a forest, the media platform  can present the segment of the image that specifically concerns the forest only, without other objects in the forest. Additionally, by determining and indexing the media based on the associated metadata, the media platform  allows a user to search for media based on the parameters of the metadata, such as location, date, time, season, depth of field, orientation. Therefore, a user looking for a video for a specific location, at a specific orientation and depth of field can search specifically for that video based on the metadata.",{"@attributes":{"id":"p-0088","num":"0087"},"figref":["FIGS. 6A-6D","FIGS. 3-5","FIG. 6A"],"b":["601","601","111","101","103","601","603","603","605","607","607","607","603","603","607","607","601","607","103","117","609"],"i":["a ","a ","a ","a","b ","a ","a","b","a ","b","a","b","a ","c "]},"In response to the query,  illustrates the user interface associated with the returned media based on the query. By way of example, media and represent returned media results that are associated with the boundary selected by the user on the map , filtered according to the time and date, and associated with the model and\/or the object represented by the model of mountains as described with respect to . Indicators and illustrate on the map  where the media and were created, respectively, which, as illustrated, is within the boundary . Using the user interface , the user may select one or more of the query results (e.g., and ) to use in one or more applications.",{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 6C","b":["601","103","103","109","113","103","613","103","103","103"],"i":["c ","a "]},"The user interface may include still frame shots and associated with the two video segments Scene 1 and Scene 2, respectively. As illustrated by the still frame shots , Scene 1 does in fact include mountains as objects in the video. However, as illustrated by still frames shots , Scene 2 includes a biker but does not necessarily include mountains (e.g., the first frame of Scene 2 does not include mountains). Thus, Scene 1 may be indexed according to the topic of mountain, and Scene 2 may be indexed according to the topic of, for example, biking.",{"@attributes":{"id":"p-0092","num":"0091"},"figref":"FIG. 6D","b":["601","103","103","109","113","103","613","617","103","103","115","103","619","103","619","103","601","619"],"i":["d ","b ","a","a","d ","b "]},"The processes described herein for querying media based on characteristics associated with the media may be advantageously implemented via software, hardware, firmware or a combination of software and\/or firmware and\/or hardware. For example, the processes described herein, may be advantageously implemented via processor(s), Digital Signal Processing (DSP) chip, an Application Specific Integrated Circuit (ASIC), Field Programmable Gate Arrays (FPGAs), etc. Such exemplary hardware for performing the described functions is detailed below.",{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIG. 7","FIG. 7"],"b":["700","700","700","700","710","700","700"]},"A bus  includes one or more parallel conductors of information so that information is transferred quickly among devices coupled to the bus . One or more processors  for processing information are coupled with the bus .","A processor (or multiple processors)  performs a set of operations on information as specified by computer program code related to querying media based on characteristics associated with the media. The computer program code is a set of instructions or statements providing instructions for the operation of the processor and\/or the computer system to perform specified functions. The code, for example, may be written in a computer programming language that is compiled into a native instruction set of the processor. The code may also be written directly using the native instruction set (e.g., machine language). The set of operations include bringing information in from the bus  and placing information on the bus . The set of operations also typically include comparing two or more units of information, shifting positions of units of information, and combining two or more units of information, such as by addition or multiplication or logical operations like OR, exclusive OR (XOR), and AND. Each operation of the set of operations that can be performed by the processor is represented to the processor by information called instructions, such as an operation code of one or more digits. A sequence of operations to be executed by the processor , such as a sequence of operation codes, constitute processor instructions, also called computer system instructions or, simply, computer instructions. Processors may be implemented as mechanical, electrical, magnetic, optical, chemical or quantum components, among others, alone or in combination.","Computer system  also includes a memory  coupled to bus . The memory , such as a random access memory (RAM) or any other dynamic storage device, stores information including processor instructions for querying media based on characteristics associated with the media. Dynamic memory allows information stored therein to be changed by the computer system . RAM allows a unit of information stored at a location called a memory address to be stored and retrieved independently of information at neighboring addresses. The memory  is also used by the processor  to store temporary values during execution of processor instructions. The computer system  also includes a read only memory (ROM)  or any other static storage device coupled to the bus  for storing static information, including instructions, that is not changed by the computer system . Some memory is composed of volatile storage that loses the information stored thereon when power is lost. Also coupled to bus  is a non-volatile (persistent) storage device , such as a magnetic disk, optical disk or flash card, for storing information, including instructions, that persists even when the computer system  is turned off or otherwise loses power.","Information, including instructions for querying media based on characteristics associated with the media, is provided to the bus  for use by the processor from an external input device , such as a keyboard containing alphanumeric keys operated by a human user, a microphone, an Infrared (IR) remote control, a joystick, a game pad, a stylus pen, a touch screen, or a sensor. A sensor detects conditions in its vicinity and transforms those detections into physical expression compatible with the measurable phenomenon used to represent information in computer system . Other external devices coupled to bus , used primarily for interacting with humans, include a display device , such as a cathode ray tube (CRT), a liquid crystal display (LCD), a light emitting diode (LED) display, an organic LED (OLED) display, a plasma screen, or a printer for presenting text or images, and a pointing device , such as a mouse, a trackball, cursor direction keys, or a motion sensor, for controlling a position of a small cursor image presented on the display  and issuing commands associated with graphical elements presented on the display . In some embodiments, for example, in embodiments in which the computer system  performs all functions automatically without human input, one or more of external input device , display device  and pointing device  is omitted.","In the illustrated embodiment, special purpose hardware, such as an application specific integrated circuit (ASIC) , is coupled to bus . The special purpose hardware is configured to perform operations not performed by processor  quickly enough for special purposes. Examples of ASICs include graphics accelerator cards for generating images for display , cryptographic boards for encrypting and decrypting messages sent over a network, speech recognition, and interfaces to special external devices, such as robotic arms and medical scanning equipment that repeatedly perform some complex sequence of operations that are more efficiently implemented in hardware.","Computer system  also includes one or more instances of a communications interface  coupled to bus . Communication interface  provides a one-way or two-way communication coupling to a variety of external devices that operate with their own processors, such as printers, scanners and external disks. In general the coupling is with a network link  that is connected to a local network  to which a variety of external devices with their own processors are connected. For example, communication interface  may be a parallel port or a serial port or a universal serial bus (USB) port on a personal computer. In some embodiments, communications interface  is an integrated services digital network (ISDN) card or a digital subscriber line (DSL) card or a telephone modem that provides an information communication connection to a corresponding type of telephone line. In some embodiments, a communication interface  is a cable modem that converts signals on bus  into signals for a communication connection over a coaxial cable or into optical signals for a communication connection over a fiber optic cable. As another example, communications interface  may be a local area network (LAN) card to provide a data communication connection to a compatible LAN, such as Ethernet. Wireless links may also be implemented. For wireless links, the communications interface  sends or receives or both sends and receives electrical, acoustic or electromagnetic signals, including infrared and optical signals, that carry information streams, such as digital data. For example, in wireless handheld devices, such as mobile telephones like cell phones, the communications interface  includes a radio band electromagnetic transmitter and receiver called a radio transceiver. In certain embodiments, the communications interface  enables connection to the communication network  for querying media based on characteristics associated with the media at the UE .","The term \u201ccomputer-readable medium\u201d as used herein refers to any medium that participates in providing information to processor , including instructions for execution. Such a medium may take many forms, including, but not limited to computer-readable storage medium (e.g., non-volatile media, volatile media), and transmission media. Non-transitory media, such as non-volatile media, include, for example, optical or magnetic disks, such as storage device . Volatile media include, for example, dynamic memory . Transmission media include, for example, twisted pair cables, coaxial cables, copper wire, fiber optic cables, and carrier waves that travel through space without wires or cables, such as acoustic waves and electromagnetic waves, including radio, optical and infrared waves. Signals include man-made transient variations in amplitude, frequency, phase, polarization or other physical properties transmitted through the transmission media. Common forms of computer-readable media include, for example, a floppy disk, a flexible disk, hard disk, magnetic tape, any other magnetic medium, a CD-ROM, CDRW, DVD, any other optical medium, punch cards, paper tape, optical mark sheets, any other physical medium with patterns of holes or other optically recognizable indicia, a RAM, a PROM, an EPROM, a FLASH-EPROM, an EEPROM, a flash memory, any other memory chip or cartridge, a carrier wave, or any other medium from which a computer can read. The term computer-readable storage medium is used herein to refer to any computer-readable medium except transmission media.","Logic encoded in one or more tangible media includes one or both of processor instructions on a computer-readable storage media and special purpose hardware, such as ASIC .","Network link  typically provides information communication using transmission media through one or more networks to other devices that use or process the information. For example, network link  may provide a connection through local network  to a host computer  or to equipment  operated by an Internet Service Provider (ISP). ISP equipment  in turn provides data communication services through the public, world-wide packet-switching communication network of networks now commonly referred to as the Internet .","A computer called a server host  connected to the Internet hosts a process that provides a service in response to information received over the Internet. For example, server host  hosts a process that provides information representing video data for presentation at display . It is contemplated that the components of system  can be deployed in various configurations within other computer systems, e.g., host  and server .","At least some embodiments of the invention are related to the use of computer system  for implementing some or all of the techniques described herein. According to one embodiment of the invention, those techniques are performed by computer system  in response to processor  executing one or more sequences of one or more processor instructions contained in memory . Such instructions, also called computer instructions, software and program code, may be read into memory  from another computer-readable medium such as storage device  or network link . Execution of the sequences of instructions contained in memory  causes processor  to perform one or more of the method steps described herein. In alternative embodiments, hardware, such as ASIC , may be used in place of or in combination with software to implement the invention. Thus, embodiments of the invention are not limited to any specific combination of hardware and software, unless otherwise explicitly stated herein.","The signals transmitted over network link  and other networks through communications interface , carry information to and from computer system . Computer system  can send and receive information, including program code, through the networks ,  among others, through network link  and communications interface . In an example using the Internet , a server host  transmits program code for a particular application, requested by a message sent from computer , through Internet , ISP equipment , local network  and communications interface . The received code may be executed by processor  as it is received, or may be stored in memory  or in storage device  or any other non-volatile storage for later execution, or both. In this manner, computer system  may obtain application program code in the form of signals on a carrier wave.","Various forms of computer readable media may be involved in carrying one or more sequence of instructions or data or both to processor  for execution. For example, instructions and data may initially be carried on a magnetic disk of a remote computer such as host . The remote computer loads the instructions and data into its dynamic memory and sends the instructions and data over a telephone line using a modem. A modem local to the computer system  receives the instructions and data on a telephone line and uses an infra-red transmitter to convert the instructions and data to a signal on an infra-red carrier wave serving as the network link . An infrared detector serving as communications interface  receives the instructions and data carried in the infrared signal and places information representing the instructions and data onto bus . Bus  carries the information to memory  from which processor  retrieves and executes the instructions using some of the data sent with the instructions. The instructions and data received in memory  may optionally be stored on storage device , either before or after execution by the processor .",{"@attributes":{"id":"p-0108","num":"0107"},"figref":["FIG. 8","FIG. 7"],"b":["800","800","800","800","800","800"]},"In one embodiment, the chip set or chip  includes a communication mechanism such as a bus  for passing information among the components of the chip set . A processor  has connectivity to the bus  to execute instructions and process information stored in, for example, a memory . The processor  may include one or more processing cores with each core configured to perform independently. A multi-core processor enables multiprocessing within a single physical package. Examples of a multi-core processor include two, four, eight, or greater numbers of processing cores. Alternatively or in addition, the processor  may include one or more microprocessors configured in tandem via the bus  to enable independent execution of instructions, pipelining, and multithreading. The processor  may also be accompanied with one or more specialized components to perform certain processing functions and tasks such as one or more digital signal processors (DSP) , or one or more application-specific integrated circuits (ASIC) . A DSP  typically is configured to process real-world signals (e.g., sound) in real time independently of the processor . Similarly, an ASIC  can be configured to performed specialized functions not easily performed by a more general purpose processor. Other specialized components to aid in performing the inventive functions described herein may include one or more field programmable gate arrays (FPGA), one or more controllers, or one or more other special-purpose computer chips.","In one embodiment, the chip set or chip  includes merely one or more processors and some software and\/or firmware supporting and\/or relating to and\/or for the one or more processors.","The processor  and accompanying components have connectivity to the memory  via the bus . The memory  includes both dynamic memory (e.g., RAM, magnetic disk, writable optical disk, etc.) and static memory (e.g., ROM, CD-ROM, etc.) for storing executable instructions that when executed perform the inventive steps described herein to query media based on characteristics associated with the media. The memory  also stores the data associated with or generated by the execution of the inventive steps.",{"@attributes":{"id":"p-0112","num":"0111"},"figref":["FIG. 9","FIG. 1"],"b":"901"},"Pertinent internal components of the telephone include a Main Control Unit (MCU) , a Digital Signal Processor (DSP) , and a receiver\/transmitter unit including a microphone gain control unit and a speaker gain control unit. A main display unit  provides a display to the user in support of various applications and mobile terminal functions that perform or support the steps of querying media based on characteristics associated with the media. The display  includes display circuitry configured to display at least a portion of a user interface of the mobile terminal (e.g., mobile telephone). Additionally, the display  and display circuitry are configured to facilitate user control of at least some functions of the mobile terminal. An audio function circuitry  includes a microphone  and microphone amplifier that amplifies the speech signal output from the microphone . The amplified speech signal output from the microphone  is fed to a coder\/decoder (CODEC) .","A radio section  amplifies power and converts frequency in order to communicate with a base station, which is included in a mobile communication system, via antenna . The power amplifier (PA)  and the transmitter\/modulation circuitry are operationally responsive to the MCU , with an output from the PA  coupled to the duplexer  or circulator or antenna switch, as known in the art. The PA  also couples to a battery interface and power control unit .","In use, a user of mobile terminal  speaks into the microphone  and his or her voice along with any detected background noise is converted into an analog voltage. The analog voltage is then converted into a digital signal through the Analog to Digital Converter (ADC) . The control unit  routes the digital signal into the DSP  for processing therein, such as speech encoding, channel encoding, encrypting, and interleaving. In one embodiment, the processed voice signals are encoded, by units not separately shown, using a cellular transmission protocol such as enhanced data rates for global evolution (EDGE), general packet radio service (GPRS), global system for mobile communications (GSM), Internet protocol multimedia subsystem (IMS), universal mobile telecommunications system (UMTS), etc., as well as any other suitable wireless medium, e.g., microwave access (WiMAX), Long Term Evolution (LTE) networks, code division multiple access (CDMA), wideband code division multiple access (WCDMA), wireless fidelity (WiFi), satellite, and the like, or any combination thereof.","The encoded signals are then routed to an equalizer  for compensation of any frequency-dependent impairments that occur during transmission though the air such as phase and amplitude distortion. After equalizing the bit stream, the modulator  combines the signal with a RF signal generated in the RF interface . The modulator  generates a sine wave by way of frequency or phase modulation. In order to prepare the signal for transmission, an up-converter  combines the sine wave output from the modulator  with another sine wave generated by a synthesizer  to achieve the desired frequency of transmission. The signal is then sent through a PA  to increase the signal to an appropriate power level. In practical systems, the PA  acts as a variable gain amplifier whose gain is controlled by the DSP  from information received from a network base station. The signal is then filtered within the duplexer  and optionally sent to an antenna coupler  to match impedances to provide maximum power transfer. Finally, the signal is transmitted via antenna  to a local base station. An automatic gain control (AGC) can be supplied to control the gain of the final stages of the receiver. The signals may be forwarded from there to a remote telephone which may be another cellular telephone, any other mobile phone or a land-line connected to a Public Switched Telephone Network (PSTN), or other telephony networks.","Voice signals transmitted to the mobile terminal  are received via antenna  and immediately amplified by a low noise amplifier (LNA) . A down-converter  lowers the carrier frequency while the demodulator 941 strips away the RF leaving only a digital bit stream. The signal then goes through the equalizer  and is processed by the DSP . A Digital to Analog Converter (DAC)  converts the signal and the resulting output is transmitted to the user through the speaker , all under control of a Main Control Unit (MCU)  which can be implemented as a Central Processing Unit (CPU).","The MCU  receives various signals including input signals from the keyboard . The keyboard  and\/or the MCU  in combination with other user input components (e.g., the microphone ) comprise a user interface circuitry for managing user input. The MCU  runs a user interface software to facilitate user control of at least some functions of the mobile terminal  to querying media based on characteristics associated with the media. The MCU  also delivers a display command and a switch command to the display  and to the speech output switching controller, respectively. Further, the MCU  exchanges information with the DSP  and can access an optionally incorporated SIM card  and a memory . In addition, the MCU  executes various control functions required of the terminal. The DSP  may, depending upon the implementation, perform any of a variety of conventional digital processing functions on the voice signals. Additionally, DSP  determines the background noise level of the local environment from the signals detected by microphone  and sets the gain of microphone  to a level selected to compensate for the natural tendency of the user of the mobile terminal .","The CODEC  includes the ADC  and DAC . The memory  stores various data including call incoming tone data and is capable of storing other data including music data received via, e.g., the global Internet. The software module could reside in RAM memory, flash memory, registers, or any other form of writable storage medium known in the art. The memory device  may be, but not limited to, a single memory, CD, DVD, ROM, RAM, EEPROM, optical storage, magnetic disk storage, flash memory storage, or any other non-volatile storage medium capable of storing digital data.","An optionally incorporated SIM card  carries, for instance, important information, such as the cellular phone number, the carrier supplying service, subscription details, and security information. The SIM card  serves primarily to identify the mobile terminal  on a radio network. The card  also contains a memory for storing a personal telephone number registry, text messages, and user specific mobile terminal settings.","While the invention has been described in connection with a number of embodiments and implementations, the invention is not so limited but covers various obvious modifications and equivalent arrangements, which fall within the purview of the appended claims. Although features of the invention are expressed in certain combinations among the claims, it is contemplated that these features can be arranged in any combination and order."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The embodiments of the invention are illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings:",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIGS. 6A-6D","FIGS. 3-5"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
