---
title: Webpage information detection method and system
abstract: The present application provides web information detecting method and system. The method according to the present application comprises: pre-extracting keywords from a web page; storing a corresponding relationship between the extracted keywords and a URL of the web page in a database; obtaining a source file of a web page to be detected; searching the database for keywords that have the same URL as that of the web page to be detected; comparing the searched keywords to the source file information of the web page to be detected; and determining the existence of information of the web page to be detected according to a matching degree. The present application increases the accuracy of web information detection.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09519718&OS=09519718&RS=09519718
owner: Peking University Founder R & D Center
number: 09519718
owner_city: Beijing
owner_country: CN
publication_date: 20111222
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","TECHNICAL FIELD","TECHNICAL BACKGROUND","SUMMARY OF INVENTION","DETAILED DESCRIPTION"],"p":["This application is a 35 USC \u00a7371 National Stage application of International Application No. PCT\/CN2011\/084487 filed Dec. 22, 2011, which claims the benefit of priority to China Patent Application No. 201010618403.4 filed Dec. 22, 2010. The disclosure of each of the prior applications is considered part of and is incorporated by reference in the disclosure of this application.","The present application relates to the field of data monitoring, and in particular to web information detecting method and a system thereof.","With the rapid global expansion of the World Wide Web, using the Internet to disseminate and capture information, specifically news related information, has become a primary channel for getting information for people. Generally, people can easily obtain any text or pictures from a computer screen via the Internet. At the same time, there is an increase in quantity, style, and channels for the distribution of news contents via the Internet. Email, internet news groups, forums, and websites have all made the Internet an important media outlet.","The information contained in the Internet is vast and complex, including a lot of good, progressive, and useful information and a lot of controversial material such as pornography, racism, and false information. The Internet is rapidly becoming a battle ground for ideas. Moreover, because of the anonymity one gets when browsing the Internet, more and more people are willing to express themselves through this channel. The rapid explosion of public opinions on the internet might gradually become a threat to social security in the form of \u201ccontent threat\u201d.","The application of a network monitoring system could exert an effective control over the complex internet information. But, most of the traditional network monitoring systems is useless to the \u201chide and seek\u201d operation tactic of certain undesired URLs, since the contents of those URLs are often deleted and restored repeatedly. Therefore, it is desirable to have a new web information detecting system with high accuracy.","There are a number of web information detecting methods currently deployed in various countries.","1. One detection method mainly utilizes XMLHTTP-based techniques and properties to obtain the information from the server. From the status code of a return request, such a method could determine if the content of the web page has been deleted. However, this method only provides information on the deletion of a URL, but does not provide information on the deletion or change of the contents of the original URL. Such a method can be relatively inaccurate.","2. Another detection method obtains the status code from the HTTP's response information. The deletion of URL is determined by status code of 200 or 401. Such a method cannot determine the contents of the web, only the deletion status of the URL. The accuracy of this detection method is relatively low.","3. Yet another detection method has also been proposed, in which the domain name is resolved into IP address to check if the URL is deleted, specifically by determining if the sockets are normal. This method can also be inadequate if the contents have already been deleted.","The above existing methods for determining the web information generally have low accuracy. Most of them rely on the return code to determine whether the URL in question has been deleted. Not only do they have difficulty to detect if a URL exists, those methods cannot determine whether the content has been erased or changed.","The technical problem to be solved by the present application is to provide an accurate method and system for web information detection.","In accordance with an aspect of the present application, a method for detecting web information is provided. The method comprises: pre-extracting keywords from a web page; storing a corresponding relationship between the extracted keywords and a URL of the web page in a database; obtaining a source file of a web page to be detected; searching the database for keywords that have the same URL as that of the web page to be detected; comparing the searched keywords to the source file information of the web page; and determining that the web page to be detected exists according to a matching degree P.","In accordance with another aspect of the present application, a system for detecting web information is provided. The system includes an extracting device configured to extract keywords from a web page, a storing device configured to store a corresponding relationship between the extracted keywords and a URL of the web page in a database, an obtaining device configured to obtain a source file of a web page to be detected, and a searching device configured to search the database for the keywords that have the same URL as that of the web page, to compare the searched keywords to the source file information of the web page and to determine that the web page exists according to a matching degree P.","The technical solution of the present application is to determine the existence of web information by utilizing the keywords extracted from the information of the web page. Such a technical solution could detect the existence of a URL as well as the changes in the web information, thus drastically improving the accuracy of the web information detection. Such detection could effectively maintain the desirability of the network environment, and provide increased security. Moreover, the present application also possesses the ability to provide a main body text, an abstract, and keywords for other networks to use. The main body text is extracted from HTML documents of complex structures as well as of a wide range of formats and types. As for the relevant abstract and keywords, they are obtained from the main body text, the title information, and web information.","Hereinafter, the invention disclosed in the present application is explained in detail with reference to the accompanying drawings in connection with the embodiments.","One primary use of the applications of the invention disclosed in the present application is the detection of web information when the web address exists and the contents of the web have changed. The primary idea behind the application is as follows. First, the keywords are pre-extracted from the web information. And then the extracted keywords as well as a corresponding relationship between the extracted keywords and a URL of the web is stored in a database as contrast materials for the web information detection. When detecting the web information, firstly, an original source file of the target web page should be obtained. A search for the keywords that have the identical URL as the target web page from the database is then conducted. Then the keywords are compared to the source file information of the target web page. Based on the result of the comparing procedure, the existence of the web information is determined.",{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 1","FIG. 1"],"b":["11","12","11","13","15","13","14","15"]},"The extracting device  is used to extract keywords from the information on the web page.","The storing device  stores the extracted keywords as well as the corresponding relationship between the keywords and the associated URL of the web page in a database as contrast materials for the web information detection.","The receiving device  receives the source file of the target web page.","The filtering  filters out the useless information, including the title in the source file of the target web page.","The comparing device  searches the database for the keywords with the URL that is identical to the URL of the target web page, and then compares the keywords to the source file of the target web page. Base on the matching degree of the keywords and the source file, the existence of the web information can be determined.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 2","FIG. 1","FIG. 2"]},"(1) The receiving device  receives HTML source file of a target web page.","(2) The filtering device  filters out the useless information including a title in the source file of the target web page to obtain a clearer text information source file.","A useless HTML tag library for storing all useless HTML tags is predefined. The useless HTML tags include the tag types for title, formulate sentence, multimedia sentence, modifier, table input and hyperlink.","The source file information and the useless HTML tag library are combined together, and all useless tags and the contents those tags associated with can be deleted by organizing a specific regular expression. Only the tag type and the contents associated with this tag type of a partitionable type are remained.","Filtering out the title tag here is to prevent the deletion of the web information and the existence of the title to interfere with the detection process.","(3) The comparing device  reads the keywords that have the identical URL as the target web page from the database. Afterward, the comparing device  compares the read keywords to the filtered the source file information of the target web page.","The keywords stored in the storing device are compared to the text information of the source file, and then the existence of the web page information is determined by a matching degree P. The matching degree P is used to determine if the target web page is a complete match or a partial match according to specific environmental parameters.",{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIG. 3","FIG. 3"]},"(a) A Step of Reading Source File Information of a Web Page","When reading the source file of the web page, first HTTP is emulated to request for returning a information status code. When the status code is not 200 or something unusual occurs, the deletion of web information of that URL can be determined directly. Otherwise, if a 200 status code returns, using command \u201cgetResponseBody( )\u201d from HttpMethodBase to obtain the bit arrays and coding format of the source file. With this code format and the bits arrays information, the bit arrays in the source file are converted into source file information of character format.","(b) A Step of Receiving the Title Information Form the Source File Information of the Web.","Base on the source file information, the title information from the title tag is obtained by using tag matching or a regular expression. In one of the embodiments, Lucene segmentation is used to segment the title. If there is no title or only a short phrase for the title, then during the later detection process the title would not be use as reference. The return title could be left blank.","(c) A Step of Extracting the Content from the Source File Information.","The process for extracting the content from the source file information is as follow.","(i) Filtering Out the Useless Information in the Source File.","The source file information and the useless HTML tag library are combined together, and all useless tags and the contents those tags associated with can be deleted by organizing a specific regular expression. Accordingly, the tag types for title, formulate sentence, multimedia sentence, modifier, table input and hyperlink as well as the contents associated with them are deleted subsequently. Only the tag type and the contents associated with this tag type of a partitionable type are remained.","(ii) Partitioning the Filtered Source File Information","A character interception algorithm is executed based on the information of the filtered source file in accordance with the tags for partitioned sections. Then the source file information is divided into a number of text blocks. At the same time, the total number of the partitionable type tags between any two random adjacent text blocks can be obtained.","For example, it is assumed that the filtered file A is consisted of two text blocks Aand A. Between Aand A, there are only two randomly positioned partitionable type tags Band Bwith number nand nrespectively. According to the character interception algorithm, A is intercepted according to the tag Bto obtain Aand Ablocks, as well as the tag Bnumbered ntherebetween. The source file block A without the tag Bis obtained by combining blocks Aand Atogether. Similarly, A is intercepted according to the tag Bto obtain a new set of Aand Ablocks, as well as the tag Bnumbered ntherebetween, and so on.","After dividing the filtered source file into a number of text blocks, all the character information within each individual text block without the tag as well as the distance from an individual text block to the next text block are stored. Specifically, the above goal can be implemented via one of the two following processes.","{circle around (1)} A process in which the information (data) is stored via a list is proposed. The stored data contains two attributes. One attribute is the character information within the text block and the other attribute is the distance to the next text block.","{circle around (2)} A process in which the information is stored via a character array is proposed. The character information within a text block (hereafter referred to text block) is scattered into a character array. Here, the distance between two adjacent text blocks can be identified by the number of blanks between the stored locations of the two text blocks in the arrays. As shown in , the null value between text block  and text block  is 2, that represents the distance between text block  and text block  is 2.","The distance between two text blocks can be determined by the partitionable type tags. Here, the frequency of a partitionable tag appears in the source file information is a weight, and the distance can be calculated by combining the weight and the number of the partitionable type tags. The specific calculation is as follow. It is assumed that two adjacent text blocks are Aand A, and there are partitionable type tags B. . . B, the weights of the tags are W. . . W, and the number of the partitionable type tags between Aand Aare as n. . . n, respectively. Therefore the distance dbetween Aand Ais calculated as:\n\n.\n","The weight can be set by user in accordance with the operating environment. In other embodiment of the present application, the distance between the two text blocks can be calculated by other means. The purpose of the calculation is to determine the relative distances between the text blocks.","Due to the complexity of the web page information, the source file has to be divided into text blocks. There are always advisements or other useless information inserted into the main body text, and thus the main body text seeing form source file perspective is not as a whole block rather they are scattered.","(iii) Determining the Main Body Text Sample.","The text block that contains the most text information (such a block should satisfy a preset length requirement, the specific requirement is defined by the user in accordance with the operation environment, for example, no less then 20 characters) can be selected as a base block, and then the remain text blocks are searched from the base block upwards and downwards. The upper limit text block and the lower limit text block are determined by the relationship between a threshold and a ratio (distance ratio) of the character count of the text blocks above and below to the distance. The distance ratio is the ratio of the base block and the rest text blocks (thus provide a density for the text), and the threshold could be determined experimentally. The information hold between the upper and lower limit text blocks is considered as a main body text sample.","Specifically, it is assumed that A is the base block that contains the most text information, including a characters. The adjacent text block above the base block is A, which has acharacters. The lower adjacent text block is A, including acharacters. Aand the A has a distance of d, A and Ahas a distance of d. The threshold is M, and the value of M could be set by a user in accordance with the operation environment.","If a\/d=M\u2267M, and a\/d=M\u2267M, then both the above and below adjacent text block Aand Aof text block A are qualified to be combined to the main body text. The average Mof Mand Mis taken as a measured scale for calculating the upper and lower limit blocks. In this regard, the measured scale could be obtained by other means such as defining by the user in accordance with the operation environment. If the measured scale is evaluated on case by case basis, the accuracy of detection will increase.","If one of Mand Mis larger or equal to the threshold M, then the one that is larger or equal to the threshold M is taken and averaged with M to obtain a new Mas the measured scale for calculating the upper and lower limit blocks.","If none of them satisfy the requirement, then there is no need to continue the radiate search in direction either above or below, the base text block can be simply taken as the main body text sample.","After Mis calculated, the text block A is reorganized. If a\/d=M\u2267M, and a\/d=M\u2267M, then A\u2032=A+A+A, that is to incorporate the text block Aand block Ainto the text block A. The Abecomes the new base block and is taken as an anchor, and then the searching is conducted from Ain an upward direction. The Ais compared to an upper adjacent text block A. Mis compared to the ratio of the number of characters in the text block Ato the distance dbetween Aand A. If the ratio is greater then M, then the text of Ais incorporated into A, and the searching is continued in an upward direction with Aas the base block. This process repeats in the upward direction as well as the downward direction until one of the text blocks does not satisfy the requirement. The text block A from the last incorporation becomes the main body text sample.","If only one of Mand Mis larger or equal to threshold M. For example M\u2267M, then the content of the text block Awill be incorporated into the text block A, that is A\u2032=A+A. The process is continuously repeated with Aas an anchor and the searching is conducted in an upward direction, until one of text blocks does not satisfy the requirement. Because M<M does not satisfy radiate requirements, there is no downward radiate search. Then the last text block A\u2032 becomes the main body text sample.","Normally, the more characters there are, the less distance exists between the text blocks, this makes said text more likely to become the main body text. The chance of a text block being the main body text is directly proportion to the number of characters in that text block.","(iv) Verifying the Main Body","The title is divided into segments and the segments are compared to the main body text sample and the resulting matching degree would determine the authenticity of the file. The matching degree is defined by the frequency and the total number of appearance of the title segment in the main body text sample (the weight for the appearance and the frequency are user defined).","Specifically, it is assumed that the title can be divided into W. . . Wsegments. The weight is determined to be w. . . wafter a sample training. The matching numbers in the main body text are n. . . nrespectively. The sample training is a well known method by a person skilled in the art. The method basically divides the main body text into segments, and then combines the frequency of appearances for each individual segment in the main body text with the weight of each keyword as well as the keyword database (here a keyword database is mostly maintained for the frequent used keywords on the internet, each keyword has been assigned with a weight after lengthen statistic analysis, words like \u201cyou, me, he\/she\u201d are not included) to calculate the keywords and the weight for each of them.","The equation of calculating the matching degree of P\u2032 is as follow:\n\n.\u2003\u2003(equation 1)\n","If P\u2032 is greater or equal to the threshold M\u2032, then the main body text sample passes verification. Otherwise, the verification process would be a failure. The threshold M\u2032 is set by user in accordance to the operation environment.","If the verification process fails, the extracting procedure returns to step (iii). The text block with the most characters is ignored. Instead the extracting procedure takes the text block B with the second most characters as the base block for anchoring. The procedure repeats the process in step (iii) to determine another main body text sample. However, the distances between the text block A and the upper and lower text blocks are stored to avoid any interference to the calculation accuracy of the density when the text block B is used as anchor. For example, the text blocks that located above and below the text block A are B and C respectively. Even when the main body text sample that uses the text block A as an anchor does not pass verification process, the distances between the text block A and the text block B, C still exists. Therefore, the distance between B and C is the sum of the distances between the text blocks A, B and the text blocks A, C. By ignoring the distances between A, B and A, C would result in the distance between the text blocks B and C becomes zero, such an effect will definitely affect the accuracy. The process is continued until the main body text sample passes verifications process, and becomes the main body text. If all of the samples are failed to pass the verification process, then none of the text block can be combined to form a meaningful text. That would mean the target web page has no main body text, or simplicity of the main body text renders it meaningless, and can be considered as having been deleted.","If the title cannot be received, then the step that uses segmented title to verify the main body text is canceled, the main body text sample can be directly seen as the main body text. This will weaken the semantic of the main body text, thus the emphases on the extraction of keywords is the way to detect the existence of web information.","(d) A Step of Extracting the Keywords from the Main Body Text.","Firstly, each section of the main body texts is taken, and all the characters in each section are counted, and then an abstract is extracted in accordance with the character count and the matching degree of the title. This abstract provides no summary of the main body text, rather a portion of the main body text for the purpose of obtaining the keywords. The abstract could be used for other web based product as an information abstract (keywords, key point). The specific process for extracting keywords is as follow.","If there is no title, the extracting process would automatically take the section of the main body text with most word as the abstract.","If there is a title, the equation below is used to calculate the matching degree of the title and the section that contains the most characters, the matching degree is denoted as P\u2033.\n\n\n","Wherein, w. . . wrepresent weights for the title segments respectively, they have same value and representation as with their counter-parts in equation 1. n\u2032. . . n\u2032represent the matching numbers of the title segments in the section that has most characters respectively. If the matching degree P\u2033 is greater than 0, then the section is verified and could be used as an abstract. Otherwise, the section with second most characters is verified, and so on.","After extracting the abstract, the extraction process proceeds with segmentation of the abstract, and combines the abstract segments and title segments together for extracting keywords afterward. The process for extracting keywords is as follow.","The title segments are set as the base, then the matching degree P\u2032\u2033 between title segments and the abstract segments is calculated by using the equation as listed below.\n\n\n","Wherein, w. . . wrepresent weights for the title segments W. . . Wrespectively, they have same value and representation as with their counter-parts in equation 1. n\u2033. . . n\u2033represent the matching number of the title segments in the abstract segments respectively. The title segments are extracted based on a descending order of P\u2032\u2033.","The abstract segments are used as bases, the frequency of an abstract segment appears in the abstract is calculated, and the abstract segments are extracted in a descending order in terms of frequency.","The segments that appear in both title and abstract segments are deleted, and then a few segments of the remaining segments are extracted as the keywords. If there is no title, then there would be no combining of title segments. The keywords are taken in a descending order based on the frequency an abstract segment appears in the abstract.","(e) A Step of Storing all the Abstract, Key Works and Other Related URL Information in a Database for Later Use.","The process for extracting the main body text, abstract and keywords from the information of a web page is based on the principle that a specific ratio is directly proportional to the main body text probability. A specific arithmetic is also combined with the process. The technical solution of the present application can obtain the main body text with high probability and the keywords for the detection without any template.","The technical solution of the present application is able to determine the existence of web information by storing the keywords of the web information. Such a method could drastically increase the accuracy of web information detection, effectively maintain a desirable network environment, and provide security. Moreover, with the ability to accurately obtain the main body text, sections, abstract, and keywords from a web page, such method could be used to provide an information base for other network systems or collecting software.","Although the above description makes explanation in detail for the present application in reference to preferred embodiments, the practices of the present application should not be construed to be limited to these descriptions. A person skilled in the art can make various simple deductions or replacements without departing form the spirit and concept of the present application, which should be construed to fall in to the scope of the appended claims of the present application."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
