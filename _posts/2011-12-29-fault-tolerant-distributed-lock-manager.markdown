---
title: Fault tolerant distributed lock manager
abstract: A lock manager running on a machine may write a first entry for a first process to a queue associated with a resource. If the first entry is not at a front of the queue, the lock manager identifies a second entry that is at the front of the queue, and determines whether a second process associated with the second entry is operational. If the second process is not operational, the lock manager removes the second entry from the queue. Additionally, if the queue becomes unavailable, the lock manager may initiate failover to a backup copy of the queue.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09141440&OS=09141440&RS=09141440
owner: Red Hat, Inc.
number: 09141440
owner_city: Raleigh
owner_country: US
publication_date: 20111229
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","DETAILED DESCRIPTION"],"p":["Embodiments of the present invention relate to locking resources in a distributed computing system, and more particularly to a distributed lock manager that is fault tolerant.","In distributed computing systems, it is beneficial to provide software applications with synchronized access to shared resources. To provide such synchronized access to shared resources, some distributed computing systems include a locking mechanism. However, conventional locking mechanisms typically lack fault tolerance. Accordingly, in such locking mechanisms, if a process that holds a lock to a resource crashes or if a lock order is lost, then the system may stall. One example of a distributed locking mechanism is a locking mechanism that implements the Lamport's Bakery Algorithm, which is described in \u201cA New Solution of Dijkstra's Concurrent Programming Problem,\u201d by Leslie Lamport in Communications of the ACM, August 1974, Volume 17, Number 8, pages 453-455. However, as with other conventional locking mechanisms, the bakery algorithm lacks fault tolerance.","Described herein are methods and systems for a fault tolerant locking mechanism usable in a distributed computing environment. The fault tolerant locking mechanism may include a fault tolerant queue that has multiple coherent and concurrent copies, and may additionally or alternatively include a policing mechanism in which lock managers can remove entries from the queue and\/or withdraw locks to processes.","In one embodiment, a lock manager running on a machine receives a request from a first process for a resource, wherein the machine is a node in a distributed system. If no queue has been generated for the resource, the lock manager generates a queue for the resource. Multiple copies of the queue may be created. These copies may be hosted by different machines arranged in a cluster. If a machine storing the queue crashes or otherwise becomes unavailable, the lock manager may fail over the queue to a backup copy.","A process having an entry at a front of the queue is permitted to perform an action associated with the resource. The lock manager writes a first entry for the first process to the queue. If the first entry is not at the front of the queue, the lock manager determines whether a second process associated with a second entry at the front of the queue is operational. In response to determining that the second process is not operational, the lock manager removes the second entry from the queue. If the entry associated with the first process advances to the front of the queue, then the first process is permitted to perform an action associated with the resource. Examples of such actions include obtaining a lock on the resource (e.g., if the resource is data) and executing an operation (e.g., where the resource is an operation).","Embodiments of the present invention provide a fault tolerant distributed locking mechanism. Accordingly, applications running in a distributed computing system may implement embodiments of the present invention to maintain synchronized access to shared resources even in the event of device failures, application failures, network partitions, and so forth. Additionally, lock managers described in embodiments of the present invention can be used when there is an unknown number of participant nodes and\/or processes, enabling a distributed computing system to be elastic (e.g., where nodes and processes can be added or removed dynamically). Moreover, lock managers described herein can manage access to shared resources even in instances in which the lock managers and\/or other processes communicate via shared memory without use of any dedicated mechanisms such as semaphores, atomic set-and-test mechanisms, and so on.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1","b":["100","100","130","104","130","111","112","121","122","130","111","112","110","130","104","104","130","104","130","160","170","180","161","171","181"]},"Clients ,  and  are connected to hosts ,  and the cloud provider system  via a network , which may be may be a private network (e.g., a local area network (LAN), a wide area network (WAN), intranet, or other similar private networks) or a public network (e.g., the Internet). Each client , ,  may be a mobile device, a PDA, a laptop, a desktop computer, or any other computing device. Each host ,  may be a server computer system, a desktop computer or any other computing device. The cloud provider system  may include one or more machines such as server computers, desktop computers, etc.","In one embodiment, the cloud provider system  is coupled to a cloud controller  via the network . The cloud controller  may reside on one or more machines (e.g., server computers, desktop computers, etc.) and may manage the execution of applications in the cloud . In one embodiment, the cloud controller  provides platform packages associated with different applications to the cloud provider . A platform package is a pre-generated image that can be provided to the cloud provider  and stored in an image repository . This image may be a virtual machine image or an image of a physical system. Upon receiving a command identifying a specific platform package, the cloud provider  retrieves the corresponding image from the image repository , creates an instance of it and loads it on the host ,  to run on top of a hypervisor (not shown). The command may be received from the cloud controller  or a user (e.g., a system administrator) via a console computer or a client machine. The image repository  may reside locally or remotely and may represent a single data structure or multiple data structures (databases, repositories, files, etc.) residing on one or more mass storage devices, such as magnetic or optical storage based disks, solid-state drives (SSDs) or hard drives.","The image repository  may also store application packages and\/or support component packages, which may be loaded onto a host and run on a hypervisor in a similar manner as the platform packages. The cloud provider  or the cloud controller  may also load an application package on the host ,  to run on top of the platform package or on top of a component package. Additionally, application packages and\/or component packages may be stored in one or more other repositories (not shown) residing locally or remotely instead of, or in addition to, the image repository .","One example of support component packages are cartridges. Cartridges are component packages that include one or multiple support components along with additional information identifying abstract features provided by the support components. Cartridges may share a similar construction, such that cartridges can be loaded and unloaded from the platform core during execution in accordance with needs of an application or other installed components.","It may be beneficial to provide processes of the distributed computing system with a mechanism for synchronizing their access to shared resources. The shared resources may be entities, operations, and\/or data structures to which shared access is to be controlled. Resources may include data such as a file, a record (e.g., in a table or database), an entire database or table, a column or row of a database or table, an area of shared memory, and so on. Resources may also include, for example, operations that may be executed by various different processes.","In one embodiment, the platform included in the virtual machines , , ,  includes lock managers A, B, C, D. The lock managers A, B, C, D are responsible for providing synchronized access to shared resources. Lock managers A, B, C, D may coordinate with one another to determine processes that are to be given locks to data and\/or to determine processes that are to perform operations. Lock managers A, B, C, D are discussed in greater detail below with reference to .",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 2","b":["250","250","252","254","252","254","258","258","260","260","264","264","264","264","264","258","258","254"]},"The platform core A, B provides a framework that enables components A-E and application parts A-D to communicate with one another, and that enables VMs A, B (nodes) to communicate with (and form clusters with) other VMs A, B. The platform core A, B also includes functionality for managing the application  and components A-E, for managing synchronized access to shared resources, and for scaling the numbers and types of nodes. The platform core A, B may include a guest OS with a kernel, distributed services, a data transport, data services, monitors and\/or other functionality. Distributed services allow communication between nodes when the application runs on multiple nodes arranged in a cluster executing on one or more hypervisors in one or more hosts. Each node may include a separate instance of the platform , or may include a different subset of the platform (e.g., a specific component or components of the platform).","The monitors of the platform core A, B may receive monitoring data from the guest OS and kernel, and pass it to the data services that store this data in a data store inside the platform  and allows querying of this data by the user(s) and\/or client(s). The monitoring data may describe the behavior and measure the performance of components A-E, elements of hardware and the application . Additionally, the monitoring data may be used to identify the state of components A-E, virtual machines A-B, applications , application packages , application parts A-D, services A-C and so on. The data transport communicates data between different components A-E of the platform  and between different platforms when applicable.","The components A-E form a layer (or multiple layers) that provides a variety of middleware, framework and other support software for the application . Components A-E may each provide support functionality used by the application  and\/or by other components A-E. Examples of components A-E include a Java\u00ae component, a Tomcat\u00ae component, an Apache\u00ae component, a JBoss\u00ae component, a PHP\u00ae component and a MySQL\u00ae component. However, many other types of components are also possible. Each component A-E provides specific capabilities. Application  may identify specific capabilities that application  uses to run. Those components A-E that provide the specified capabilities may be loaded in the platform . Additionally, some of the components A-E may specify additional capabilities that those components rely upon. If any such components A-E will be loaded into platform , then the additional components that provide the capabilities that those components rely upon may also be loaded into the platform . The components A-E can issue commands to request system information such as information about the architecture and packages installed, and can further communicate with the platform via communication channels such as the file system, interprocess communication (IPC), and a network.","In one embodiment, at least some components A-E are provided by cartridges (not shown). Cartridges are software packages that provide functionality of one or more components A-E. Components may also be built into the platform  and\/or may be included in an application package .","Application  includes an application package  containing multiple application parts A-D which may correspond to different individually deployable modules of the application. For example, a first application part A may include application code or logic, and another application part B may include static data that will be farmed out to a content delivery network. Application  may be an n-tiered web application based on languages such as Java, Ruby, Python, PHP or the like. The PaaS environment  may also include external services A-C on which the application  depends.","An application package  may be provided by a user or created automatically based on information about the application that is provided by a user via a user interface or by other means. The platform core A, B and components A-E may be provided by the PaaS provider. Components A-E are not typically packaged with the application . Instead, the application package  typically expresses a dependency on platform services provided by components A-E. The platform  may then import the appropriate components A-E at deployment time.","In one embodiment, each VM A-B includes the same platform instance and an instance of the application . Accordingly, each machine runs an instance of all components provided by the platform. In another embodiment, different VMs include distinct platform instances. For example, a first platform instance may include a Java component and host the application package , and a second platform instance may include a MySQL component. Nodes that include the first platform instance may be grouped into a first cluster, and nodes that include the second platform instance may be grouped into a second cluster.","In one embodiment, the platform core A, B includes a lock manger . The lock manager  may manage locks on shared resources for components A-E, applications , application parts A-D, etc. running on a VM A, B with the lock manager . The lock manager  may coordinate with other lock managers  running on other nodes (e.g., in other VMs A, B) to determine a process order, and may maintain this process order in a queue. Processes at a front of the queue may be granted locks to specified resource. The lock managers  may also monitor a process to which a lock has been granted to ensure that the process has not crashed, stalled or otherwise become nonoperational. The lock manager  may use the monitoring data to determine whether a process has become nonoperational. The lock manager  may alternatively or additionally make such determinations based on an amount of time that a lock has been assigned to a process. In addition, in the event that the queue becomes unavailable, the lock manager  may communicate with other lock managers running on the other nodes to elect a backup queue to fail over to. The lock manager  is discussed in greater detail below with reference to .",{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 3","FIG. 1","FIG. 2"],"b":["302","302","190","290","302","310","315","320","328","302","325","310","315","320","328","325","310","315","320","328","325"]},"Lock manager  may be invoked in response to a process attempting or requesting to place a lock on, access or perform some other operation on a shared resource. Lock manager  may additionally be invoked in response to a process committing to perform an operation (e.g., an operation that affects multiple nodes that should not be run concurrently by multiple processes). The process may be a process or an execution thread of a process for an application part, a component, a platform core service, an external service, and so on. In one embodiment, the request is received based on the process calling the locking API , which may be exposed to applications and\/or components. Therefore, any cartridge or application may be written by a third party that can invoke the lock manager  via the locking API  and thereby utilize the locking mechanisms provided by the lock manager .","In response to lock manager  receiving a request from a process for a shared resource, token generator  generates a lock token for the process. The generated lock token may include a timestamp indicating when the request was received and\/or when the token was generated, a machine identifier (ID) uniquely identifying a machine (e.g., a virtual machine and\/or underlying physical machine) on which the process runs, a process identifier (ID) uniquely identifying the process and\/or a thread identifier (ID) identifying a particular thread of the process that requested the lock or operation. The lock token may also include a lock duration (an estimated time at which a granted lock will be released). In one embodiment, token generator  generates a unique hash based on the timestamp, duration, machine ID, process ID and\/or thread ID. The hash may be included in the lock token.","Also in response to lock manager  receiving a request from a process for a shared resource, queue handler  determines whether a queue has been generated for that resource. If no queue has been generated for the resource, then queue handler  generates such a queue . Queue handler  then adds an entry including the lock token generated by token generator  to the queue . If lock manager  receives other requests from other processes for the same shared resource, then token generator  may generate additional lock tokens for those processes and queue handler  may add entries to the queue  with those additional lock tokens. Any other lock managers  may also receive requests for the shared resource. Lock tokens may be generated for each of those other requests and may be added to entries in the queue  by the other lock managers. Accordingly, the queue  may reflect all processes running on any nodes in a distributed computing system that attempt to access the same shared resource. Note that the lock manager may not have information that identifies how many processes will use locks (e.g., how many processes will be participating in the queue) prior to generating the queue. Moreover, new processes may be added to the queue and processes may be removed from the queue at any time. Therefore, membership of the queue may be variable.","Lock tokens are ordered in the queue  based on timestamps. Therefore, entries having earlier timestamps are preferably ordered at a front of the queue, and entries having later timestamps are preferably ordered at a back of the queue. Where two lock tokens have matching timestamps, order between these two lock tokens may be determined arbitrarily (e.g., based on location, lock duration, process ID, machine ID, hash, etc.).","In one embodiment, nodes on which the lock managers  execute have synchronized (or approximately synchronized) time clocks. This ensures that ordering in the queue is accurate. In one embodiment, the nodes synchronize to a network time protocol (NTP) server (e.g., when the nodes are initialized). In another embodiment, nodes use a virtual clock, vector clock and\/or Lamport timestamps to maintain timing. Using such techniques, appropriate ordering may be maintained (e.g., to achieve first in first out ordering) without having synchronized clocks.","Queue handler  may continuously or periodically check the queue to determine whether an entry at the front of the queue is associated with any processes that are being handled by lock manager  (e.g., processes collocated with lock manager  and\/or processes from which lock manager  received a request). In response to queue handler  determining that the entry at the front of the queue is associated with a process handled by lock manager , lock granting module  obtains a lock for that resource. If the resource is data (e.g., a table, record, database, field, shared memory, etc.), then other processes may be restricted from performing operations on the data while the lock is maintained. What operations are restricted may depend on a type of lock obtained. In one embodiment, lock granting module  obtains one or more of a null lock (merely indicates interest in resource), a concurrent read lock (indicates interest in reading a resource and enables other processes to read or update the resource, but disallows other processes from obtaining an exclusive lock), a concurrent write lock (indicates an interest in updating a resource and enables other processes to read or update the resource, but does not permit other processes to obtain an exclusive lock), a protected read lock (indicates an interest in reading a resource and permits other processes to read but not update the resource), a protected write lock (indicates an interest in updating a resource and permits other processes to read but not update the resource) and\/or an exclusive lock (restricts all other processes from reading or updating a resource) on the shared resource for the process.","Once a process to which a lock is granted completes an operation on a shared resource, the process releases the lock. Lock manager  (or the process) additionally removes the entry for that process from the queue. A lock manager  may then grant a lock on that resource to a next process associated with the next entry that advances to a front of the queue.","Policing module  continuously or periodically checks to confirm whether the process associated with an entry at the front of the queue is operational. These checks may be performed by all or just some lock managers  in the distributed system. In one embodiment, policing module  determines whether a process is operational based on a determination of whether a lock duration (or operation duration) has been exceeded. Policing module  may make such a determination based on comparing a time at which the lock was granted (or operation was started) to the provided lock duration (or operation duration). If an amount of time has elapsed since the lock was granted (or operation was started) that is longer than the lock duration (or operation duration), policing module  may determine that the process is no longer operational. In another embodiment, policing module  accesses monitoring data associated with the process that has been gathered by a monitor. The monitoring data may indicate whether the process is still operational.","If policing module  determines that the process associated with the entry at the front of the queue is not operational, queue handler  removes that entry from the queue  and lock granting module  releases the lock. The lock may then be assigned to a process associate with a next entry in the queue.","In one embodiment, lock manager is connected to a recovery manager . Policing module  may notify recovery manager  that the process is not functioning properly. Recovery manager  may then determine whether a machine hosting the process has crashed, whether the process has crashed, whether a particular thread of the process has crashed, or whether some other fault has occurred. If the process or a thread has crashed, then recovery manager  may cause that process to restart and recover a state of the process on a same machine that it was previously operating on or on a different machine. If the machine that was hosting the process crashed, then recovery manager  may cause the process to be restarted and recovered on an alternative machine.","Note that resources may be arranged in a resource hierarchy. For example, a top level in a resource hierarchy may be a database, a second level may be a table, a third level may be a record, and a fourth level may be a field. Lock manager  may obtain locks for appropriate levels of resources in the hierarchy. For example, if a process will be updating a particular record, then lock granting module  may obtain a lock for just that record. However, if the process is making a global update to the database, then lock granting module  may grant a lock to the entire database.","In one embodiment, multiple synchronized copies of the queue  are maintained. Lock managers  running on different nodes may determine a copy of the queue  that will operate as a primary copy that all nodes will use based on election or polling. If that primary copy becomes unavailable (e.g., if a machine hosting the primary copy crashes), then a backup copy of the queue  may be designated as the primary copy (e.g., via election). The system can fail over to a backup queue automatically without any interruptions to executing processes. In one embodiment, the copies of the queue  are maintained in a distributed database. For example, the queue  may be maintained in an Apache\u00ae Casandra\u00ae database, in an HBase\u00ae database, in a Hadoop\u00ae database, and so on.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIGS. 4-6","b":["254","290","260","254"]},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 4","b":"400"},"At block  of method , processing logic receives a request to obtain a lock on a resource (e.g., a data resource). The request may be received from a process. In one embodiment, the process attempts to perform an operation on the resource (e.g., read the resource, update the resource, etc.), and in response a request is automatically sent to the processing logic. In another embodiment, the process invokes the processing logic (e.g., via a locking API) and expressly requests a lock on the resource.","At block , processing logic determines whether a queue has already been created for the resource. The queue may be a lock queue that enables a process at a front of the queue to obtain a lock on the resource. The queue may already have been generated for the resource if another process previously requested a lock on the resource. If there is a preexisting queue for the resource, the method proceeds to block . Otherwise, the method continues to block , and processing logic generates a lock queue for the resource.","At block , processing logic adds an entry to the lock queue for the process. The entry may be a lock token that includes a machine ID of a machine on which the process runs, a process ID of the process and\/or a thread ID of a particular thread of the process that requested the lock. The machine ID, process ID and\/or thread ID may be used to generate a hash that uniquely identifies the process. The lock token may additionally include a timestamp and a lock duration. The timestamp identifies when the process requested the lock and the lock duration identifies how long the process will hold the lock to the resource.","At block , processing logic determines whether the entry for the process is at a front of the lock queue. If the entry is at the front of the lock queue, the method continues to block , and processing logic obtains a lock to the resource for the process. If the entry for the process is not at the front of the queue, the method continues to block .","At block , processing logic checks a status of another process that is associated with another entry that is at the front of the queue. In one embodiment, checking the status of the other process includes comparing a time at which a lock was granted to that process to a lock duration that may be identified in the entry associated with that process. If the process has held the lock for longer than the identified lock duration, then processing logic may determine that the process is no longer operational. In another embodiment, processing logic queries the other process. If processing logic does not receive a response from the other process, then processing logic may determine that the other process is not operational. In another embodiment, processing logic uses monitoring data about the other process that has been gathered by probes, agents and\/or a monitor of a platform core. The monitoring data may identify a state of the other process.","At block , if the other process is still operational, the method returns to block . If the other process is operating correctly, then once it has completed any specified operations (e.g., read or write operations) on the resource, it will release the lock to the resource and remove its entry from the queue. A process associated with a next entry in the queue may then be granted a lock to the resource. However, if the other process is not operating correctly, then it may hold the lock indefinitely. Accordingly, if the other process is not operational, the method continues to block , and processing logic removes the other entry for the other process from the queue. At block , processing logic may then cause the other process to start a recovery procedure (e.g., to restart and recover its state). The method then returns to block . Processing logic may continue to return to block  until the process associated with the entry that processing logic added to the queue is at a front of the queue.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 5","b":"500"},"At block  of method , processing logic receives a commitment to perform an operation from a process. The operation may be a resource for a distributed computing system (e.g., for a cluster). The commitment to perform the operation may be received in response to processing logic identifying that the operation should be performed.","At block , processing logic determines whether a queue has already been created for the operation (for the resource). The queue may be an operational queue that enables a process at a front of the queue to perform the operation. The queue may already have been generated for the operation if another process previously committed to perform the operation. If there is a preexisting queue for the resource, the method proceeds to block . Otherwise, the method continues to block , and processing logic generates an operational queue for the resource.","At block , processing logic adds an entry to the operational queue for the process. The entry may be a token that includes a machine ID of a machine on which the process runs, a process ID of the process and\/or a thread ID of a particular thread of the process that committed to perform the operation. The machine ID, process ID and\/or thread ID may be used to generate a hash that uniquely identifies the process. The token may additionally include a timestamp and an operation duration. The timestamp identifies when the process committed to perform the operation and the operation duration identifies how long it will take for the process to complete the operation.","At block , processing logic determines whether the entry for the process is at a front of the operational queue. If the entry is at the front of the queue, the method continues to block , and processing logic instructs the process to perform the operation. If at block  the entry for the process is not at the front of the queue, the method continues to block . At block , processing logic determines whether another process associated with an entry at the front of the queue has completed the operation. If the other process has completed the operation, the method proceeds to block . Otherwise, the method continues to block . Once the operation is complete, processing logic deletes the operational queue at block .","At block , processing logic checks the status of the other process that is associated with another entry that is at the front of the queue. In one embodiment, checking the status of the other process includes comparing a time at which the operation was started by that process to an operation duration that may be identified in the entry associated with that process. If the process has been performing the operation for longer than the identified operation duration, then processing logic may determine that the process is no longer operational. In another embodiment, processing logic queries the other process. If processing logic does not receive a response from the other process, then processing logic may determine that the other process is not operational. In another embodiment, processing logic uses monitoring data about the other process that has been gathered by probes, agents and\/or a monitor of a platform core. The monitoring data may identify a state of the other process. If the other process is still operational, the method returns to block . If the other process is not operating correctly, then it may not complete the operation. Accordingly, if the other process is not operational, the method continues to block , and processing logic removes the other entry for the other process from the queue. At block , processing logic may then cause the other process to start a recovery procedure (e.g., to restart and recover its state). The method then returns to block . This process may continue until the operation is completed.","Note that at block , a process may in some instances continue the operation from a point at which a previous process left off rather than starting the operation over. This may occur if a state of the operation has been preserved.",{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 6","b":["600","605","600","610","615"]},"Processes may interact with the primary copy so long as the primary copy is accessible. At block , processing logic determines whether the primary copy of the queue is available. If the primary copy of the queue is available, the method ends. If the primary copy of the queue is not available, processing logic automatically fails over to a backup copy of the queue at block . This may cause the backup copy of the queue to become a new primary copy of the queue. Processing logic may fail over to the backup copy of the queue without any interruption in service to processes (e.g., to lock managers that use the queue).",{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 7","b":["700","110","120","130","104","108"]},"The exemplary computer system  includes a processing device , a main memory  (e.g., read-only memory (ROM), flash memory, dynamic random access memory (DRAM) such as synchronous DRAM (SDRAM) or DRAM (RDRAM), etc.), a static memory  (e.g., flash memory, static random access memory (SRAM), etc.), and a secondary memory  (e.g., a data storage device in the form of a drive unit, which may include fixed or removable computer-readable storage medium), which communicate with each other via a bus .","Processing device  represents one or more general-purpose processing devices such as a microprocessor, central processing unit, or the like. More particularly, the processing device  may be a complex instruction set computing (CISC) microprocessor, reduced instruction set computing (RISC) microprocessor, very long instruction word (VLIW) microprocessor, processor implementing other instruction sets, or processors implementing a combination of instruction sets. Processing device  may also be one or more special-purpose processing devices such as an application specific integrated circuit (ASIC), a field programmable gate array (FPGA), a digital signal processor (DSP), network processor, or the like. Processing device  is configured to execute the instructions  for performing the operations and steps discussed herein.","The computer system  may further include a network interface device . The computer system  also may include a video display unit  (e.g., a liquid crystal display (LCD) or a cathode ray tube (CRT)) connected to the computer system through a graphics port and graphics chipset, an alphanumeric input device  (e.g., a keyboard), a cursor control device  (e.g., a mouse), and a signal generation device  (e.g., a speaker).","The secondary memory  may include a machine-readable storage medium (or more specifically a computer-readable storage medium)  on which is stored one or more sets of instructions  embodying any one or more of the methodologies or functions described herein. In one embodiment, the instructions  include instructions for a lock manager . The instructions  may also reside, completely or at least partially, within the main memory  and\/or within the processing device  during execution thereof by the computer system , the main memory  and the processing device  also constituting machine-readable storage media.","The computer-readable storage medium  may also be used to store the instructions  persistently. While the computer-readable storage medium  is shown in an exemplary embodiment to be a single medium, the term \u201ccomputer-readable storage medium\u201d should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and\/or associated caches and servers) that store the one or more sets of instructions. The term \u201ccomputer-readable storage medium\u201d shall also be taken to include any medium that is capable of storing or encoding a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present invention. The term \u201ccomputer-readable storage medium\u201d shall accordingly be taken to include, but not be limited to, solid-state memories, and optical and magnetic media.","The instructions , components and other features described herein can be implemented as discrete hardware components or integrated in the functionality of hardware components such as ASICS, FPGAs, DSPs or similar devices. In addition, the instructions  can be implemented as firmware or functional circuitry within hardware devices. Further, the instructions  can be implemented in any combination hardware devices and software components.","In the above description, numerous details are set forth. It will be apparent, however, to one skilled in the art, that the present invention may be practiced without these specific details. In some instances, well-known structures and devices are shown in block diagram form, rather than in detail, in order to avoid obscuring the present invention.","Some portions of the detailed description which follows are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here, and generally, conceived to be a self-consistent sequence of steps leading to a result. The steps are those requiring physical manipulations of physical quantities. These quantities may take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like.","It should be borne in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussion, it is appreciated that throughout the description, discussions utilizing terms such as \u201creceiving,\u201d \u201cwriting,\u201d \u201cdetermining,\u201d \u201cremoving,\u201d \u201cperforming,\u201d \u201cmaintaining,\u201d \u201cstoring,\u201d \u201caccessing,\u201d or the like, refer to the actions and processes of a computer system, or similar electronic computing device, that manipulates and transforms data represented as physical (e.g., electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.","It is to be understood that the above description is intended to be illustrative and not restrictive. Many other embodiments will be apparent to those of skill in the art upon reading and understanding the above description. The scope of the invention should, therefore, be determined with reference to the appended claims, along with the full scope of equivalents to which such claims are entitled."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Embodiments of the present invention are illustrated by way of example, and not by way of limitation, and can be more fully understood with reference to the following detailed description when considered in connection with the figures in which:",{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
