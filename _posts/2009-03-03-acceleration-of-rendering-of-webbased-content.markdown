---
title: Acceleration of rendering of web-based content
abstract: Systems and methods for hardware accelerated presentation of web pages on mobile computing devices are presented. A plurality of web pages may be received by a computing device capable of processing and displaying web pages using layout engines, hardware accelerated graphics application programming interfaces (APIs). Upon receipt of the web pages, the web pages may be divided into a plurality of rendering layers, based upon stylesheets of the web pages. An algorithm walks through rendering layers so as to select a plurality of layers that may receive compositing layers so as to take advantage of hardware acceleration when rendered. The web pages may be subsequently presented on a display of the mobile computing devices using remaining rendering layers and compositing layers. In this manner, visual representation of web content remains intact even when content which may not have been originally designed for use with layout engine may be displayed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09418171&OS=09418171&RS=09418171
owner: Apple Inc.
number: 09418171
owner_city: Cupertino
owner_country: US
publication_date: 20090303
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["This application claims priority to U.S. Provisional Application No. 61\/033,760 filed on Mar. 4, 2008, which provisional application is incorporated herein by reference in its entirety.","This disclosure relates to display of web-based content.","With increasing use of computers to deliver content such as information and entertainment, web pages designed to display such content have become increasingly complicated over time, containing not only text but also animation and videos. Goals of web developers may be to present this content in visually appealing and timely fashion. Accordingly, developers may consider how to create and manage display of such content when designing web pages.","With improved support for Cascading Style Sheets (CSS) in web browsers, web developers have been able to make use of CSS to control presentation of documents written in hypertext markup language (HTML) independently of its content. Each content element within a web page may be assigned a set of stylistic rules that dictates presentation of that element. In this manner, markup pages can be presented in different styles.","CSS further provides priority schemes that determine which style rules are applied if more than one rule matches a particular content element. This behavior may be referred to as cascade and makes use of weights that are calculated and assigned to rules to provide predictable outcomes. CSS styles can be provided in separate documents or embedded in markup documents. Style sheets can be imported and alternative style sheets specified for user selection.","CSS provides various facilities to control both the appearance of single elements on web pages, for example their size and background color, and how various different elements on pages may be presented visually with respect to each other. For example, properties may be provided that control back-to-front ordering of different elements, and whether elements \u201cclip\u201d elements inside of it. These rendering behaviors may be described by Cascading Style Sheets specifications.","Web pages have traditionally been static collections of text and images. However, as computing performance has increased, and browser technology has improved, web page designers are making frequent use of animated content in web pages, either through JavaScript, or by using plug-ins. However, animation performance remains limited because of the overhead associated with recomputing positions, and redrawing all elements, of web pages as animation runs. This may be particularly true when running on mobile computing devices, which have limited computing power.","Web browsers may therefore choose to make use of hardware acceleration in presentation of animated web page content, whereby certain content elements of web pages may be rendered into hardware textures, and then moved and composited via graphics processing units of mobile computing devices. However, rendering certain page elements via hardware may necessarily alter the visual presentation of pages; those elements may be presented on top of non hardware-rendered content, and thus may cause a layout engine to violate presentation rules described in Cascading Style Sheets specifications.","Embodiments presently disclosed may relate to systems and methods for hardware accelerated rendering of web pages on mobile computing devices. A plurality of web pages may be received by mobile computing devices capable of processing and displaying web pages using hardware accelerated graphics application programming interfaces (APIs). Upon receipt of web pages, devices divide web content into plurality of rendering layers. Rendering layers may be employed to determine actual display of web pages, which may be compared with intended display of web pages based on their stylesheets. Significant deviations between actual and intended displays may be determined and algorithms may be employed to substantially minimize these deviations. In one embodiment, an algorithm selects portions of the plurality of rendering layers to receive hardware-backed layers, allowing selected layers to be hardware-accelerated when rendered. In this manner, visual representation of web pages can continue to conform to a specification, while subsets of page elements may be animated in hardware.","Advantageously, an algorithm may be adapted to web page content, as well as the status of mobile computing devices at the time of rendering web pages. The algorithm may base its selections upon factors which include, but are not limited to, relative placement of web page content, desired rendering order of web page content, whether web page elements overlap one another, requested animation effects represented by web page content, available processing resources, and memory. These and other advantages are discussed in detail below.","The processes presented herein may be described in terms of sequential operations; however, it may be appreciated that some operations may be performed in different orders. Moreover, some operations may be performed in parallel, rather than sequentially. Furthermore, some operations may be omitted, as necessary.","Embodiments may be described with reference to accompanying Figures, wherein like numerals refer to like elements throughout. The terminology used in the description presented herein is not intended to be interpreted in any limited or restrictive manner, simply because it may be utilized in conjunction with the detailed description of certain embodiments. Furthermore, disclosed embodiments may include several novel features, no single one of which may solely responsible for its desirable attributes or which may be essential to practicing inventions herein described.",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1","b":["100","106","100","102","106","106","100","104","106","100","100"]},"Mobile computing devices  may be in communication with network  which delivers pluralities of web pages  to mobile computing devices . Network  may include Local Area Networks (LANs), Wide Area Networks (WANs), intranets, extranets, and Internet. Network  may be further implemented using wired communication mechanisms, wireless communication mechanisms, and combinations thereof. In certain embodiments, mobile computing device  can be, or include, Apple iPhones\u2122.","When received by mobile computing device , web pages  may be provided to layout engine  for web browsers. Layout engine  can include plurality of facilities to parse web page  into elements and compute visual presentation of those elements taking style into account, and to render those elements on mobile computing device . Rendering may be performed via a plurality of graphics application programming interfaces (APIs) that generate instructions that may be used by hardware  to display two-dimensional and three-dimensional computer graphics. In one embodiment, one or more graphics APIs may be OpenGL . Graphics APIs may further be selected from graphics APIs capable of enabling hardware acceleration, such as Core Animation\u2122 (Apple Inc.) . OpenGL may also be used in embodiments to enable hardware acceleration.","Layout engine  may be communicatively coupled, through operating system , to hardware . Hardware  may include, but may not limited to, plurality of processors , , plurality of memory , , at least one display controller , and at least one display . Operating system  may further include plurality of drivers, not shown, which facilitate communication between hardware  and software .","Processors ,  can include, for example, general purpose processors, such as central processing unit (CPU)  and specialty processors, such as graphics processing unit (GPU) . CPU  may comprise plurality of core logics, such as two dimensional (2D) cores and\/or three-dimensional (3D) cores that process different types of graphics data and may use different kinds of graphics resources. Output of GPU  may be stored in graphics memory  which may be fetched by display controller  for display on display . For example, GPU  may employ graphics memory  dedicated to storing information used for processing of graphics, while CPU  may employ memory  shared by CPU  and other components of device .",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 2","b":["200","200","116","116","112","116","116","106","106","116","106"]},"Layout engine  may compute visual presentation for elements on pages, which may be determined by standard rendered appearance for various types of elements, and then how appearance of various elements may be changed by CSS style rules. In addition, layout engine  may compute position on page, and display order of each of elements, based on style rules and interactions between elements.","As part of computing element positions and display order, layout engine  may build hierarchies of objects that control rendering of some subset of elements, which may be referred to as rendering layers.","Of note, layout engine  may look at styles and potentially other things to determine that some subset of rendering layers should be hardware accelerated\/composited. Layout engine  may then analyze hierarchy of rendering layers to determine which other rendering layers may require hardware compositing in order to preserve visual appearance of web page .","In one embodiment, layout engine  identifies intended display  of web pages . For example, intended display  may be identified by processes of walking through  of plurality of stylesheets of web pages . In certain embodiments, stylesheets may be provided in Cascading Style Sheets (CSS) language.","As illustrated in , web pages  () may be divided into content () and document presentation (), which can be written in CSS. Examples of content may include, for example, text A, B, static images , animations designed to take advantage of hardware accelerated rendering , and non-accelerated animations . Animations  may represent operations that modify existing content, and may be treated like other CSS properties, like font face or color.","A plurality of document presentation rules may be applied to web page content. Rules may include, for example, static and dynamic positioning in two dimensions , content visibility , and fonts . For example, rules may specify front-to-back orders (z-index) that relates to stacking index . CSS can further specify priority schemes for web page content which decides what stylistic rules may be applied when multiple rules may be available to pieces of content. Using positioning, content may be placed at any desired location within web page . Using overflow, behavior of elements whose contents spill outside of their box may be controlled. Visibility may be further to show or hide pieces of content.","Index  may be used to specify in what order content may be drawn when elements on page overlap. Font parameters may be used to vary type, size, and style of displayed text. Simple animations may be generated by adjusting content formatting which may include, for example, position of content over time, content visibility, and presentation of plurality of images.","Thus, by walking through formatting instructions within CSS of web pages , intended display  of web pages  may be determined.","In further embodiments, pluralities of rendering layers  may be generated by layout engine  to determine rendered display  of web pages . Rendering layers  comprise hierarchies of objects, each of which may render related subsets of content of pages. Rendering layers  in this hierarchy each paint their content in predetermined sequences in order to generate visual representation of web pages . Example rendering layers A-D derived from web page  are illustrated in .","Process  may also determine which rendering layers  may require hardware-backing, by virtue of their being style, or other sources of input, that indicates that these layers may be subject to animations, or may have presentation that may be only possible when rendering through 3D APIs. For example, if elements have non-affine transforms, such as through rotation transform with perspective, then these operations may be better suited for hardware-backing.","In process , it may also be determined which other rendering layers  may require hardware backing, in order to maintain visual representation of pages. For example, page elements which may normally render on top of something that received hardware-compositing layer in previous steps may need themselves to get hardware layers, so they may continue to be rendered on top. Rendered layers  may be used by process  to determine rendered display . Rendered display  may be compared to intended display  to determine deviation .","From this analysis, algorithm  selects portions of rendering layers  and modifies selected layers, referred to herein as compositing layers , so that they may work in conjunction with graphics APIs for hardware accelerated rendering. In one embodiment, selected rendering layers  are painted into corresponding layers to obtain compositing layers . In this manner, displayed web page  is generated from combinations of remaining rendering layers  and compositing layers . Displayed web page  is substantially the same as intended display . It may be understood that this process may be iterated, as necessary, to achieve this result.","Embodiments of algorithm  may select rendering layers  used to generate compositing layers  based upon pluralities of factors. Factors may include, for example, relative placement of web page content, desired rendering order of web page content, whether web page content overlaps one another, and requested animation effects represented by web page content. Algorithm  may further base its selections on available processing resources, memory, and like concerns.","In algorithm , layout engine  constructs hierarchies of rendering layers in order to paint contents of web pages  in correct back-to-front order. Hierarchy of rendering layers may be based upon structure of the web.","Layout engine  may compute, from this first hierarchy, a new hierarchy of rendering layers, by taking into account styles that affect front-to-back ordering of page elements (i.e. z-index), and styles that force elements to become a \u201cstacking context\u201d. Within a stacking context, child elements may be sorted according to their z-order, but elements within different stacking contexts may not inter-sort.","Styles associated with elements for each rendering layer may then be examined, and layout engine  may make decisions about whether current rendering layers require hardware compositing support. Criteria used to make this decision can include, but are not limited to: whether style rules that are applied to elements for this layer that assign animations, including transient transitions, in certain properties, such as opacity, or display transforms; whether style rules that are applied to elements for this layer that describe display transforms that may be difficult with available 2D drawing APIs, such as non-affine transforms; whether elements associated with rendering layers  would benefit from hardware compositing (for example, elements that display video may be able to display much more efficiently if they may be rendered into hardware-composited destinations).","Layout engine  may perform second passes over hierarchies of rendering layers in order of their visual presentation (back to front), and additional rendering layers can be assigned hardware compositing layers for secondary reasons which include, but are not limited to, following criteria.","For example, layout engine  may consider whether rendering layers  should be drawn in front of another hardware-composited rendering layer in order to preserve visual presentation of pages. Algorithm  may take into account locations of rendering layers on screen, and may only assign hardware-composited layers when overlap is detected, but in this case algorithm  may detect when a change in page display, including animations, could affect that overlap, and assign additional hardware compositing layers.","Layout engine  may also consider whether rendering layers  have styles that causes them to clip their child elements (i.e. \u201coverflow\u201d style), and one or more of their child elements may be rendered into hardware-composited rendering layer. These hardware compositing layers may be utilized since those hardware-composited child elements may not be clipped by standard clipping mechanisms used in software-rendering code path, both because they may be hardware-accelerated, and because clipping itself may be implemented with hardware acceleration since contents of rendering layers  may experience hardware-accelerated animations.","Layout engine  may further inspect rendering layers that have been assigned compositing layers in either of previous steps, and identifies situations in which single rendering layers, which may have been assigned hardware composited layers, may need to create and maintain more than one hardware compositing layer. These situations can include, but are not limited to, following situations: if rendering layers may be stacking contexts, and they may have hardware-composited children with negative z-index, then additional layers may be created for content of that rendering layer's element. This may be useful to preserve visual representation that employs negative z-index children to render in front of that element's background, but behind its content.","Also, if rendering layers  have \u201coverflow\u201d style that may cause them to clip their children, and that rendering layer is not a stacking context, and one of more of its children are associated with hardware-composited layers, then additional hardware-compositing layers may be useful to effect clipping of those children. This may be useful because elements with \u201coverflow\u201d style may not automatically become a stacking context, and so may not necessarily act as parent of its clipped child layers in rendering hierarchy.","If elements may have been assigned rendering layers in order to optimize display of that element (e.g. video), but that styles prescribe additional box decorations on that element, such as borders, then additional hardware compositing layers may be created to render those box decorations, thus preserving efficiency of display of that element.","Hardware-compositing layers may have processing costs, in terms of memory required for their associated data structures and backing store (when necessary), and computational requirements for their creation and maintenance. In some embodiments, layout engine  may be configured to minimize the number and size of hardware compositing layers that may be created via several techniques including, but not limited to: rendering layers  which may be a stacking context, and may have no child elements that may require hardware compositing, can always be rendered into hardware compositing layer associated with it, or some parent rendering layer; elements that draw behind elements that have hardware compositing layers may be rendered into hardware layers associated with some parent rendering layer, or into drawing destination of non-hardware-accelerated elements of pages; hardware-compositing layers created for rendering layers  and their non-accelerated children may need be only large enough to contain those elements, including any box decorations such as outlines and shadows, and may be no larger.","Both page content, and styles applied to elements on pages may change after pages have been loaded in response to user activity, or directly or indirectly through JavaScript. When changes are detected that impact visual presentation of elements on pages, layout engine  may execute its algorithms  over all or part of hierarchy of rendering layers  to ensure that sets of hardware compositing rendering layers may be updated in order to preserve that visual presentation of pages.","In many cases elements associated with hardware-compositing layers created by algorithm  may be rendered into those hardware compositing layers via system-provided drawing APIs. This may be for elements that present mixtures of text, images, borders etc. This may also indicate that such hardware composited layers require memory buffers, or backing stores, to preserve rendered presentation, this memory buffer may be uploaded to graphics processing hardware for compositing on display by that hardware.","Allocating memory buffers for hardware compositing layers can make use of system resources, but may be minimized in various embodiments. To achieve this, algorithm  may be modified to detect certain configurations of elements within rendering layers, which may be presented by available hardware-accelerated graphics API without allocation of a backing store. These configurations may include, but are not be limited to: rendering layers associated with elements that have no visible content, but simply act as containers for their child rendering layers. In this case hardware-accelerated layers may be assigned to those rendering layers, but those hardware-accelerated layers may simply participate in geometry calculations for children, and may not do any drawing of their own.","Rendering layers may be associated with elements that have solid background colors, but may have no other content that may be rendered into that same rendering layer. In this case instructions to draw solid background colors may be passed via hardware-accelerated graphics API to underlying graphics processors, which may fill areas of screen with solid colors much more efficiently than may be possible via software-based drawing APIs. Rendering layers may also be associated with elements that display images. In this case, decoded pixels of images may be passed to hardware-accelerated graphics APIs to be used as graphics textures, without having to render them via software-based drawing APIs. Thus, when page content or styles change, algorithm reexamines page elements, and if it detects any of these configurations, it may reconfigure sets of hardware-accelerated rendering layers to take advantage of them.",{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 5A","b":["2500","2500"]},"In some implementations, the mobile device  includes a touch-sensitive display . The touch-sensitive display  can be implemented with liquid crystal display (LCD) technology, light emitting polymer display (LPD) technology, or some other display technology. The touch-sensitive display  can be sensitive to haptic and\/or tactile contact with a user.","In some implementations, the touch-sensitive display  can include a multi-touch-sensitive display . A multi-touch-sensitive display  can, for example, process multiple simultaneous touch points, including processing data related to the pressure, degree, and\/or position of each touch point. Such processing facilitates gestures and interactions with multiple fingers, chording, and other interactions. Other touch-sensitive display technologies can also be used, e.g., a display in which contact is made using a stylus or other pointing device. Some examples of multi-touch-sensitive display technology are described in U.S. Pat. Nos. 6,323,846, 6,570,557, 6,677,932, and 6,888,536, each of which is incorporated by reference herein in its entirety.","In some implementations, the mobile device  can display one or more graphical user interfaces on the touch-sensitive display  for providing the user access to various system objects and for conveying information to the user. In some implementations, the graphical user interface can include one or more display objects , . In the example shown, the display objects , , are graphic representations of system objects. Some examples of system objects include device functions, applications, windows, files, alerts, events, or other identifiable system objects.","In some implementations, the mobile device  can implement multiple device functionalities, such as a telephony device, as indicated by a Phone object ; an e-mail device, as indicated by the Mail object ; a map devices, as indicated by the Maps object ; a Wi-Fi base station device (not shown); and a network video transmission and display device, as indicated by the Web Video object . In some implementations, particular display objects , e.g., the Phone object , the Mail object , the Maps object , and the Web Video object , can be displayed in a menu bar . In some implementations, device functionalities can be accessed from a top-level graphical user interface, such as the graphical user interface illustrated in . Touching one of the objects , , , or  can, for example, invoke a corresponding functionality.","In some implementations, the mobile device  can implement a network distribution functionality. For example, the functionality can enable the user to take the mobile device  and provide access to its associated network while traveling. In particular, the mobile device  can extend Internet access (e.g., Wi-Fi) to other wireless devices in the vicinity. For example, mobile device  can be configured as a base station for one or more devices. As such, mobile device  can grant or deny network access to other wireless devices.","In some implementations, upon invocation of a device functionality, the graphical user interface of the mobile device  changes, or is augmented or replaced with another user interface or user interface elements, to facilitate user access to particular functions associated with the corresponding device functionality. For example, in response to a user touching the Phone object , the graphical user interface of the touch-sensitive display  may present display objects related to various phone functions; likewise, touching of the Mail object  may cause the graphical user interface to present display objects related to various e-mail functions; touching the Maps object  may cause the graphical user interface to present display objects related to various maps functions; and touching the Web Video object  may cause the graphical user interface to present display objects related to various web video functions.","In some implementations, the top-level graphical user interface environment or state of  can be restored by pressing a button  located near the bottom of the mobile device . In some implementations, each corresponding device functionality may have corresponding \u201chome\u201d display objects displayed on the touch-sensitive display , and the graphical user interface environment of  can be restored by pressing the \u201chome\u201d display object.","In some implementations, the top-level graphical user interface can include additional display objects , such as a short messaging service (SMS) object , a Calendar object , a Photos object , a Camera object , a Calculator object , a Stocks object , a Address Book object , a Media object , a Web object , a Video object , a Settings object , and a Notes object (not shown). Touching the SMS display object  can, for example, invoke an SMS messaging environment and supporting functionality; likewise, each selection of a display object , , , , , , , , , and  can invoke a corresponding object environment and functionality.","Additional and\/or different display objects can also be displayed in the graphical user interface of . For example, if the device  is functioning as a base station for other devices, one or more \u201cconnection\u201d objects may appear in the graphical user interface to indicate the connection. In some implementations, the display objects  can be configured by a user, e.g., a user may specify which display objects  are displayed, and\/or may download additional applications or other software that provides other functionalities and corresponding display objects.","In some implementations, the mobile device  can include one or more input\/output (I\/O) devices and\/or sensor devices. For example, a speaker  and a microphone  can be included to facilitate voice-enabled functionalities, such as phone and voice mail functions. In some implementations, an up\/down button  for volume control of the speaker  and the microphone  can be included. The mobile device  can also include an on\/off button  for a ring indicator of incoming phone calls. In some implementations, a loud speaker  can be included to facilitate hands-free voice functionalities, such as speaker phone functions. An audio jack  can also be included for use of headphones and\/or a microphone.","In some implementations, a proximity sensor  can be included to facilitate the detection of the user positioning the mobile device  proximate to the user's ear and, in response, to disengage the touch-sensitive display  to prevent accidental function invocations. In some implementations, the touch-sensitive display  can be turned off to conserve additional power when the mobile device  is proximate to the user's ear.","Other sensors can also be used. For example, in some implementations, an ambient light sensor  can be utilized to facilitate adjusting the brightness of the touch-sensitive display . In some implementations, an accelerometer  can be utilized to detect movement of the mobile device , as indicated by the directional arrow . Accordingly, display objects and\/or media can be presented according to a detected orientation, e.g., portrait or landscape. In some implementations, the mobile device  may include circuitry and sensors for supporting a location determining capability, such as that provided by the global positioning system (GPS) or other positioning systems (e.g., systems using Wi-Fi access points, television signals, cellular grids, Uniform Resource Locators (URLs)). In some implementations, a positioning system (e.g., a GPS receiver) can be integrated into the mobile device  or provided as a separate device that can be coupled to the mobile device  through an interface (e.g., port device ) to provide access to location-based services.","In some implementations, a port device , e.g., a Universal Serial Bus (USB) port, or a docking port, or some other wired port connection, can be included. The port device  can, for example, be utilized to establish a wired connection to other computing devices, such as other communication devices , network access devices, a personal computer, a printer, a display screen, or other processing devices capable of receiving and\/or transmitting data. In some implementations, the port device  allows the mobile device  to synchronize with a host device using one or more protocols, such as, for example, the TCP\/IP, HTTP, UDP and any other known protocol.","The mobile device  can also include a camera lens and sensor . In some implementations, the camera lens and sensor  can be located on the back surface of the mobile device . The camera can capture still images and\/or video.","The mobile device  can also include one or more wireless communication subsystems, such as an 802.11b\/g communication device , and\/or a Bluetooth\u2122 communication device . Other communication protocols can also be supported, including other 802.x communication protocols (e.g., WiMax, Wi-Fi, 3G), code division multiple access (CDMA), global system for mobile communications (GSM), Enhanced Data GSM Environment (EDGE), etc.",{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 5B","b":["2500","2500"]},"In some implementations, each of one or more system objects of device  has a set of system object attributes associated with it; and one of the attributes determines whether a display object for the system object will be rendered in the top-level graphical user interface. This attribute can be set by the system automatically, or by a user through certain programs or system functionalities as described below.  shows an example of how the Notes object  (not shown in ) is added to and the Web Video object  is removed from the top graphical user interface of device  (e.g. such as when the attributes of the Notes system object and the Web Video system object are modified).",{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 6","b":["3000","2500","3002","3004","3006","3002","3004","3006"]},"Sensors, devices, and subsystems can be coupled to the peripherals interface  to facilitate multiple functionalities. For example, a motion sensor , a light sensor , and a proximity sensor  can be coupled to the peripherals interface  to facilitate the orientation, lighting, and proximity functions described with respect to . Other sensors  can also be connected to the peripherals interface , such as a positioning system (e.g., GPS receiver), a temperature sensor, a biometric sensor, or other sensing device, to facilitate related functionalities.","A camera subsystem  and an optical sensor , e.g., a charged coupled device (CCD) or a complementary metal-oxide semiconductor (CMOS) optical sensor, can be utilized to facilitate camera functions, such as recording photographs and video clips.","Communication functions can be facilitated through one or more wireless communication subsystems , which can include radio frequency receivers and transmitters and\/or optical (e.g., infrared) receivers and transmitters. The specific design and implementation of the communication subsystem  can depend on the communication network(s) over which the mobile device is intended to operate. For example, a mobile device can include communication subsystems  designed to operate over a GSM network, a GPRS network, an EDGE network, a Wi-Fi or WiMax network, and a Bluetooth\u2122 network. In particular, the wireless communication subsystems  may include hosting protocols such that the mobile device may be configured as a base station for other wireless devices.","An audio subsystem  can be coupled to a speaker  and a microphone  to facilitate voice-enabled functions, such as voice recognition, voice replication, digital recording, and telephony functions.","The I\/O subsystem  can include a touch screen controller  and\/or other input controller(s) . The touch-screen controller  can be coupled to a touch screen . The touch screen  and touch screen controller  can, for example, detect contact and movement or break thereof using any of a plurality of touch sensitivity technologies, including but not limited to capacitive, resistive, infrared, and surface acoustic wave technologies, as well as other proximity sensor arrays or other elements for determining one or more points of contact with the touch screen .","The other input controller(s)  can be coupled to other input\/control devices , such as one or more buttons, rocker switches, thumb-wheel, infrared port, USB port, and\/or a pointer device such as a stylus. The one or more buttons (not shown) can include an up\/down button for volume control of the speaker  and\/or the microphone .","In one implementation, a pressing of the button for a first duration may disengage a lock of the touch screen ; and a pressing of the button for a second duration that is longer than the first duration may turn power to the mobile device on or off. The user may be able to customize a functionality of one or more of the buttons. The touch screen  can, for example, also be used to implement virtual or soft buttons and\/or a keyboard.","In some implementations, the mobile device can present recorded audio and\/or video files, such as MP3, AAC, and MPEG files. In some implementations, the mobile device can include the functionality of an MP3 player, such as an iPod\u2122. The mobile device may, therefore, include a 32-pin connector that is compatible with the iPod\u2122. Other input\/output and control devices can also be used.","The memory interface  can be coupled to memory . The memory  can include high-speed random access memory and\/or non-volatile memory, such as one or more magnetic disk storage devices, one or more optical storage devices, and\/or flash memory (e.g., NAND, NOR). The memory  can store an operating system , such as Darwin, RTXC, LINUX, UNIX, OS X, WINDOWS, or an embedded operating system such as VxWorks. The operating system  may include instructions for handling basic system services and for performing hardware dependent tasks. In some implementations, the operating system  can be a kernel (e.g., UNIX kernel).","The memory  may also store communication instructions  to facilitate communicating with one or more additional devices, one or more computers and\/or one or more servers. The memory  may include graphical user interface instructions  to facilitate graphic user interface processing; sensor processing instructions  to facilitate sensor-related processing and functions; phone instructions  to facilitate phone-related processes and functions; electronic messaging instructions  to facilitate electronic-messaging related processes and functions; web browsing instructions  to facilitate web browsing-related processes and functions; media processing instructions  to facilitate media processing-related processes and functions; GPS\/Navigation instructions  to facilitate GPS and navigation-related processes and instructions; camera instructions  to facilitate camera-related processes and functions; and\/or other software instructions  to facilitate other processes and functions. The memory  may also store other software instructions (not shown), such as web video instructions to facilitate web video-related processes and functions; and\/or web shopping instructions to facilitate web shopping-related processes and functions. In some implementations, the media processing instructions  are divided into audio processing instructions and video processing instructions to facilitate audio processing-related processes and functions and video processing-related processes and functions, respectively. An activation record and International Mobile Equipment Identity (IMEI)  or similar hardware identifier can also be stored in memory .","Although the foregoing description has shown, described, and pointed out fundamental novel features of present teachings, it may be understood that various omissions, substitutions, and changes in form of detail of apparatus as illustrated, as well as uses thereof, may be made by those skilled in art, without departing from scope of present teachings. Consequently, scope of present teachings should not be limited to foregoing discussion."],"BRFSUM":[{},{}],"heading":["FIELD OF INVENTION","DESCRIPTION OF RELATED ART","DETAILED DESCRIPTION","Mobile Device Overview","Example Mobile Device Functionality","Example Configurable Top-level Graphical User Interface","Example Mobile Device Architecture"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF DRAWINGS","p":["Exemplary embodiments of invention may be explained in greater detail in following description and are illustrated in drawings, in which:",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIGS. 3A-3C"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 4","FIG. 1"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
