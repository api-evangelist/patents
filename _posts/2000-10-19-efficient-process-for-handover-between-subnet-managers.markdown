---
title: Efficient process for handover between subnet managers
abstract: A method and system for efficiently merging subnets having individual subnet managers (SM) into a single network with one master SM. During discovery and configuration of a subnet, a subnet manager creates a Subnet Management Database (SMDB) representative of the subnet components being managed. Each subnet manager contains an independent SMDB. When two or more subnets are linked/connected together to form a single network, a single one of the subnet managers is selected as the master subnet manager and all the subnets' SMDBs must be merged. An SMDB record labeling mechanism is utilized to differentiate among components from the different subnets that may have the same parameter values, such as protection keys (P_keys) and re-assign individual parameters to create a single SMDB of uniquely defined components.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07409432&OS=07409432&RS=07409432
owner: International Business Machines Corporation
number: 07409432
owner_city: Armonk
owner_country: US
publication_date: 20001019
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["The present invention is related to the subject matter of the following commonly assigned, co-pending U.S. patent applications filed concurrently herewith: U.S. pat. No. 7,136,907 entitled \u201cMethod and System for Informing An Operating System In A System Area Network When A New Device Is Connected\u201d; Ser. No. 09\/692,347 entitled \u201cMethod and System For Scalably Selecting Unique Transaction Identifiers\u201d, now abandoned; U.S. Pat. No. 6,748,559 entitled \u201cMethod And System For Reliably Defining and Determining Timeout Values In Unreliable Datagrams\u201d; and U.S. Pat. No. 6,851,059 entitled \u201cMethod and System For Choosing A Queue Protection Key That is Tamper-proof From An Application\u201d. The content of the above-referenced applications is incorporated herein by reference.","1. Technical Field:","The present invention relates in general to computer networks and, in particular to merging the independent computer networks. Still more particularly, the present invention relates to a method and system for providing an efficient handover of control between Subnet managers of separate subnets, which are being merged into a single subnet.","2. Description of the Related Art:","The use of I\/O interconnects to connect components of a distributed computer system is known in the art. Traditionally, in such systems, individual components are interconnected via a parallel bus, such as a PCIX bus. The parallel bus has a relatively small number of plug-in ports for connecting the components. The number of plug-in ports is set (i.e., the number cannot be increased). At maximum loading, a PCIX bus transmits data at about 1 Gbyte\/second.","The introduction of high performance adapters (e.g., SCSI adapters), Internet-based networks, and other high performance network components has resulted in increased demand for bandwidth, faster network connections, distributed processing functionality, and scaling with processor performance. These and other demands are quickly outpacing the current parallel bus technology and are making the limitations of parallel buses even more visible. PCIS bus, for example, is not scalable, i.e., the length of the bus and number of slots available at a given frequency cannot be expanded to meet the needs for more components, and the limitation hinders further development of fast, efficient distributed networks, such as system area networks. New switched network topologies and systems capable of being easily expanded are required to keep up with the increasing demands, while allowing the network processes on the expanding network to be dynamically completed, i.e., without manual input.","The present invention recognizes the need for faster, more efficient computer interconnects offering the features demanded by the developments of technology. More specifically, the present invention recognizes the need for providing a mechanism within a network such as a System Area Network (SAN) consisting of multiple subnets, that provides efficient, dynamic combining of two or more subnets into a single network.","A method and system is disclosed for efficiently combining (or merging) subnets having individual master subnet managers into a single network with one master subnet manager. The invention is thus applicable to a distributed computing system, such as a system area network, having end nodes, switches, and routers, and links interconnecting these components. The switches and routers interconnect the end nodes and route packets, i.e., sub-components of messages being transmitted, from a source end node to a target end node. The target end node then reassembles the packets into the message.","During discovery and configuration of a subnet, a subnet manager creates a Subnet Management Database (SMDB) representative of the subnet components being managed. Each subnet manager contains an independent SMBD. When two or more subnets are merged (i.e., linked\/connected together) to form a single network, a single one of the subnet mangers is selected as the master subnet manager and all the subnets SMBDs must be merged. The other subnet managers are relegated to standby status. In a preferred embodiment, a SMDB record labeling mechanism is utilized to differentiate among components from the different subnets that may have the same parameter values, such as protection keys (P_keys).","In one embodiment of the invention, when there are two or more separate SMDBs, each maintained by separate master subnet managers on a separate subnet, and those separate subnets are linked together (or merged) into one larger subnet, a process is provided for efficiently merging the SMDBs. In this manner the separate subnets become a single subnet, with a single master subnet and a single SMDB.","All objects, features, and advantages of the present invention will become apparent in the following detailed written description.","The present invention is directed to a method for efficient handover of control to a single master subnet manager when two or more subnets having subnet managers are merged. The invention is applicable to a distributed computer system, such as a system area network (SAN). The invention is implemented in a manner that allows the overlaps in merged subnet parameters, such as P_Keys, to be resolved.","In order to appreciate the environment within which the invention is preferably practiced, a description of a SAN configured with routers, and end nodes, etc. is provided below. Presentation of the environment and particular functional aspects of the environment which enable the invention to be practiced are provided with reference to . Section headings have been provided to distinguish the hardware and software architecture of the SAN. However, those skilled in the art understand that the descriptions of either architecture necessarily includes to both components.","SAN HARDWARE ARCHITECTURE","With reference now to the figures and in particular with reference to , there is illustrated an exemplary embodiment of a distributed computer system. Distributed computer system  represented in  is provided merely for illustrative purposes, and the embodiments of the present invention described below can be implemented on computer systems of numerous other types and configurations. For example, computer systems implementing the present invention may range from a small server with one processor and a few input\/output (I\/O) adapters to very large parallel supercomputer systems with hundreds or thousands of processors and thousands of I\/O adapters. Furthermore, the present invention can be implemented in an infrastructure of remote computer systems connected by an Internet or intranet.","As shown in , distributed computer system  provides a system area network (SAN) , which is a high-bandwidth, low-latency network interconnecting nodes within the distributed computer system. More than one () SAN  may be included in a distributed computer system  and each SAN  may comprise multiple sub-networks (subnets).","A node is herein defined to be any component that is attached to one or more links of a network. In the illustrated distributed computer system, nodes include host processors , redundant array of independent disks (RAID) subsystem , I\/O adapters , switches A-C, and router . The nodes illustrated in  are for illustrative purposes only, as SAN  can connect any number and any type of independent nodes. Any one of the nodes can function as an end node, which is herein defined to be a device that originates or finally consumes messages or frames in the distributed computer system .","SAN  is the communications and management infrastructure supporting both I\/O and inter-processor communications (IPC) within distributed computer system . Distributed computer system , illustrated in , includes switches communications fabric (i.e., links, switches and routers) allowing many devices to concurrently transfer data with high-bandwidth and low latency in a secure, remotely managed environment. End nodes can communicate over multiple ports and utilize multiple paths through SAN . The availability of multiple ports and paths through SAN  can be employed for fault tolerance and increased-bandwidth data transfers.","SAN  includes switches A-C and routers . Switches A-C connects multiple links together and allows routing of packets from one link to another link within SAN  using a small header Destination Local Identifier (DLID) field. Router  is capable of routing frames from one link in a first subnet to another link in a second subnet using a large header Destination Globally Unique Identifier (DGUID). Router  may be coupled via wide area network (WAN) and\/or local area network (LAN) connections to other hosts or other routers.","In SAN , host processor nodes  and I\/O nodes  include at least one Channel Adapter (CA) to interface to SAN . Host processor nodes  include central processing units (CPUs)  and memory . In one embodiment, each CA is an endpoint that implements the CA interface in sufficient detail to source or sink packets transmitted on SAN . As illustrated, there are two CA types, Host CA (HCA)  and Target CA (TCA) . HCA  is used by general purpose computing nodes to access SAN . In one implementation, HCA  is implemented in hardware. In the hardware implementation of HCA , HCA hardware offloads much of CPU and I\/O adapter communication overhead. The hardware implementation of HCA  also permits multiple concurrent communications over a switched network without the traditional overhead associated with communicating protocols. Use of HCAs  in SAN  also provides the I\/O and IPC consumes of distributed computer system  with zero processor-copy data transfers without involving the operating system kernel process. HCA  and other hardware of SAN  provide reliable, fault tolerant communications.","The I\/O chassis includes I\/O adapter backplane  and multiple I\/O adapter nodes  that contain adapter cards. Exemplary adapter cards illustrated in  include SCSI adapter card A, adapter card B to fiber channel hub and PC-AL devices, Ethernet adapter card C, graphics adapter card D, and video adapter card E. Any known type of adapter card can be implemented. The I\/O chassis also includes switch B in the I\/O adapter backplane  to couple adapter cards A-E to SAN .","RAID subsystem  includes a microprocessor , memory , a Target Channel Adapter (TCA) , and multiple redundant and\/or striped storage disks .","In the illustrated SAN , each link  is a full duplex channel between any two network elements, such as end nodes, switches A-C, or routers . Suitable links  may include, but are not limited to, copper cables, optical cables, and printed circuit copper traces on backplanes and printed circuit boards. The combination of links  and switches A-C, etc. operate to provide point-to-point communication between nodes of SAN .","SAN SOFTWARE ARCHITECTURE","Software Components","Software and hardware aspects of an exemplary host processor node  are generally illustrated in . An application programming interface (API) and other software components, such as an operating system (OS) and device drives are utilized to allow software components  to control hardware components . However, the feature of software-hardware interaction at the processor node  is not essential to the discussion of the invention and further description is not required for the understanding of the present invention. The functionally provided by the API, OS and other components collectively provides verbs interface . Verbs interface  operates as a conduit which separates the upper software components  from the lower hardware components .","Host processor node  executes a set of consumer processes . Host processor node  includes HCA  with ports . Each port  connects a link (see line  of ). Ports  can connect to one SAN subnet or multiple SAN subnets. Utilizing message and data services , consumer processes  transfer messages to SAN  via verbs interface . Verbs interface  is generally implemented with an OS-specific programming interface.","A software model of HCA  is illustrated in . HCA  includes a set of queue pairs (QPs) , which transfer messages across ports  to the subnet. A single HCA  may support thousands of QPs . By contrast, TCA  () in an I\/O adapter typically supports a much smaller number of QPs .  also illustrates subnet management administration (SMA) , management packets  and a number of virtual lanes , which connect the transport layer with ports .","Turning now to , there is illustrated software management model for nodes on SAN . SAN architecture management facilities provides a Subnet Manager (SM) A, a Subnet Administration (SA) B, and an infrastructure that supports a number of general management services. The management infrastructure requires a Subnet Management Agent (SMA)  operating in each node  and defines a general service interface that allows additional general services agents. Also, SAN architecture defines a common management datagram (MAD) message structure for communicating between managers and management agents. SM A is responsible for initializing, configuring and managing switches, routers, and channel adapters. SMS A can be implemented within other devices, such as a channel adapter or a switch. One SM A of SAN is dedicated as a master SM and is responsible for: (1) discovering the subnet topology; (2) configuring each channel adapter port with a rang of Local Identification (LID) numbers, Global Identification (GID) number, subnet prefix, and Partition Keys (P_Keys); (3) configuring each switch with a LID, the subnet prefix, and with its forwarding database; and (4) maintaining the end node and service database for the subnet to provide a Global Unique Identification (GUID) number to LID\/GID resolution service as well as a services directory.","In a preferred embodiment, SM A records all configuration information for each component of the network in a SM database (SMDB). Thus, management of SAN  and SAN components, such as HCAs , TCAs (or end nodes) , Switches , and Routers  are completed utilizing Subnet Management (SM) A and Subnet Administration (SA) B. SMPs are used to discover, initialize, configure, and maintain SAN components through management agents  of end nodes . SAN SA packets are used by SAN components to query and update subnet management data. Control of some aspects of the subnet management is provided via a user management console  in host-based end node .","MESSAGE TRANSFER PROCESS","SAN  provides the high-bandwidth and scalability required for I\/O and also supports the extremely low latency and low CPU overhead required for Interprocessor Communications (IPC). User processes can bypass the operating system (OS) kernel process and directly access network communication hardware, such as HCAs , which enable efficient message passing protocols. SAN  is suited to current computing models and is a building block for new forms of I\/O and computer cluster communication. SAN  allows I\/O adapter nodes  to communicate among themselves or communicate with any or all of the processor nodes  in the distributed computer system. With an I\/O adapter attached to SAN , the resulting I\/O adapter node  has substantially the same communication capability as any processor node  in the distributed computer system.","For reliable service types of messages, end nodes, such as host processor nodes  and I\/O adapter nodes , generate request packets and receive acknowledgment packets. Switches A-C and routers  pass packets along from the source to the target (or destination). Except for the variant cyclic redundancy check (CRC) trailer field, which is updated at each transfer stage in the network, switches A-C pass the packets along unmodified. Routers  update the variant CRC trailer field and modify other fields in the header as the packet is routed.","In SAN , the hardware provides a message passing mechanism that can be used for Input\/Output (I\/O) devices and Interprocess Communications (IPC) between general computing nodes. Consumes (i.e., processing devices connected to end nodes) access SAN message passing hardware by posting send\/receive messages to send\/receive work queues (WQ), respectively, on a SAN Channel Adapter (CA).","A message is herein defined to be an application-defined unit of data exchange, which is a primitive unit of communication between cooperating processes. A packet (or frame) is herein defined to be one unit of data encapsulated by networking protocol headers. The headers generally provide control and routing information for directing the packet (or frame) through SAN . The trailer generally contains control and CRC data for ensuring that frames are not delivered with corrupted content.","Consumers use SAN verbs to access HCA functions. The software that interprets verbs and directly accesses the CA is known as the Channel Interface (CI) . Send\/Receive work queues (WQ) are assigned to a consumer as a Queue Pair (QP). Messages may be sent over five different transport types, Reliable Connected (RC), Reliable Datagram (RD), Unreliable Connected (UC), Unreliable Datagram (UD), and Raw Datagram (RawD). Consumers retrieve the results of these messages from a Completion Queue (CQ) through SAN send and receive work completions (WC). The source CA takes care of segmenting outbound messages and sending them to the destination. The destination or target CA takes care of reassembling inbound messages and placing them in the memory space designated by the desintation's consumer. These features are illustrated in the figures below.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIGS. 4","FIG. 4","FIG. 4"],"b":["5","6","7","400","402","404","406","406","408","406","410","412","414"]},"Each QP  provides an input to a Send Work Queue (SWQ)  and a Receive Work Queue (RWQ) . SWQ  sends channel and memory semantic messages, and RWQ  receives channel semantic messages. A consumer calls a verb (within verbs interface ) to place Work requests (WRs) into a work queue (WQ).","A send work request WR  is a channel semantic operation to push a set of local data segments to the data segments referenced by a remote node's Receive work queue element (WQE). For example, work queue element  contains references to data segment  , data segment  , and data segment  . Each of the data segments of the send WR contains a virtually contiguous memory region. The virtual addresses used to reference the local data segments are in the address context of the process that created the local QP .","As shown in , work requests placed onto a work queue are referred to as work queue elements (WQEs). Send work queue  contains work queue elements (WQEs) -, describing data to be transmitted on the SAN fabric. Receive work queue  contains work queue elements (WQEs) -, describing where to place incoming channel semantic data from the SAN fabric. WQBs are executed (processed) by hardware  in the HCA. SWQ  contains WQEs  that describe data to be transmitted on the SAN fabric. RWQ  contains WQEs  that describe where to place incoming channel semantic data received from SAN .","A remote direct memory access (RDMA) read work request provides a memory semantic operation to read a virtually contiguous memory space on a remote node. A memory space can either be a portion of a memory region or portion of a memory window. A memory region references a previously registered set of virtually contiguous memory addresses defined by a virtual address and length. A memory window references a set of virtually contiguous memory addresses which have been bound to a previously registered region.","The RDMA Read work request reads a virtually contiguous memory space on a remote end node and writes the data to a virtually contiguous local memory space. Similar to the send work request, virtual addresses used by the RDMA Read work queue element to reference the local data segments are in the address context of the process that created the local queue pair. For example, work queue element  in receive work queue  references data segment  , data segment  , and data segment . The remote virtual addresses are in the address context of the process owning the remote queue pair targeted by the RDMA Read work queue element.","In one embodiment, Receive Work Queues  only support one type of WQE, which is referred to as a receive WQE -. The receive WQE - provides a channel semantic operation describing a local memory space into which incoming send messages are written. The receive WQE includes a scatter list describing several virtually contiguous memory spaces. An incoming send message is written to these memory spaces. The virtual addresses are in the address contexts of the process that created the local QP .","The verbs interface  also provides a mechanism for retrieving completed work from completion queue . Completion queue  contains Completion Queue Elements (CQEs) - which contain information about previously completed WQEs. CQEs - are employed to create a single point of completion notification for multiple QPs . CQE contains sufficient information to determine the QP  and specific WQE that completed. A completion queue context is a block of information that contains pointers to length and other information needed to manage the individual completion queues .","Turning next to , an illustration of a data packet is depicted in accordance with a preferred embodiment of the present invention. Message data  contains data segment  , data segment , and data segment  , which are similar to the data segments illustrated in . In this example, these data segments form a packet , which is placed into packet payload  within data packet . Additionally, data packet  contains CRC , which is used for error checking. Additionally, routing header  and transport  are present in data packet . Routing header  is used to identify source and destination ports for data packet . Transport header  in this example specifies the destination queue pair for data packet . Additionally, transport header  also provides information such as the operation code, packet sequence number, and partition for data packet .","The operating code identifies whether the packet is the first, last, intermediate, or only packet of a message. The operation code also specifies whether the operation is a send RDMA write, read, or atomic. The packet sequence number is initialized when communications is established and increments each time a queue pair creates a new packet. Ports of an end node may be configured to be members of one or more possibly overlapping sets called partitions.","If a reliable transport service is employed, when a request packet reaches its destination end node, acknowledgment packets are used by the destination end node to let the request packed sender know the request packet was validated and accepted at the destination. Acknowledgment packets acknowledge one or more valid and accepted request packets. The requester can have multiple outstanding request packets before it receives any acknowledgments. In one embodiment, the number of multiple outstanding messages is determined when a QP is created.","Referring to , a schematic diagram illustrating a portion of a distributed computer system is depicted in accordance with the present invention. The distributed computer system  in  includes a host processor node  and . Host processor node  includes a HCA , and host processor node  includes a HCA . The distributed computer system  in  includes a SAN fabric  which includes a switch  and a switch . The SAN fabric  in  includes a link coupling HCA  to switch ; a link coupling switch  to switch ; and a link coupling HCA  to switch .","In the example transactions, host processor node  includes client process A , and host processor node  includes client process B . Client process A  interacts with HCA hardware  through QP . Client process B  interacts with HCA hardware  through QP . QP  and QP  are data structures. QP  includes send work queue  and a receive work queue . QP  also includes send work queue  and receive work queue .","Process A  initiates a message request by posting WQEs to the send queue  of QP . Such a WQE is illustrated by WQE  in . The message request of client process A  is referenced by a gather list contained in the send WQE . Each data segment in the gather list points to a virtually contiguous local memory region, which contains a part of the message. This is indicated by data segments  ,  , and  , which respectively hold message parts , , and .","Hardware in HCA  reads the WQE and segments the message stored in virtual contiguous buffers into packets, such as packet  in . Packets are routed through the SAN fabric , and for reliable transfer services, are acknowledged by the final destination end node, which in this case is host processor node . If not successively acknowledged, the packet is re-transmitted by the source end node, host processor node . Packets are generated by source end nodes and consumed by destination end nodes.","Referring now to , the send request message is transmitted from source end node  to destination end node  as packets  ,  ,  , and  . Acknowledgment packet   acknowledges that all 4 request packets were received.","The message in  is being transmitted with a reliable transport service. Switches (and routers) that relay the request and acknowledgment packets do not generate any packets, only the source and destination HCAs do (respectively).","REMOTE OPERATION FUNCTIONALITY","SAN , with its interlinked arrangement of components and sub-components, provides a method for completing remote operations, by which processor nodes may directly control processes in I\/O nodes. Remote operation also permits the network to manage itself. A remote direct memory access (RDMA) Read work request (WR) provides a memory semantic operation to read a virtually contiguous space on a remote node. A memory space can either be a portion of a memory region or a portion of a memory window. A memory region references a previously registered set of virtually contiguous memory addresses defined by a virtual address and length. A memory window references a set of virtually contiguous memory addresses which have been bound to a previously registered region.","The RDAM Read WR writes the data to a virtually contiguous local memory space. Similar to Send WR , virtual addresses used by the RDMA Read WQE to reference the local data segments are in the address context of the process that created the local QP . The remote virtual addresses are in the address context of the process owning the remote QP targeted by the RDMA Read WQE.","RDMA Write WQE provides a memory semantic operation to write a virtually contiguous memory space on a remote node. RDMA Write WQE contains a scatter list of local virtually contiguous memory spaces and the virtual address of the remote memory space into which the data from the local memory spaces is written.","RDMA FetchOp WQE provides a memory semantic operation to perform an atomic operation on a remote word. RDMA FetchOp WQE is a combined RDMA Read, Modify, and Write operation. RDMA FetchOp WQE can support several read-modify-write operations, such as \u201cCompare and Swap if Equal.\u201d","A Bind (unbind) remote access key (R_Key) WQE provides a command to the HCA hardware to modify a memory window by associating the memory window to a memory region. A second command to destroy a memory window by disassociating the memory window from a memory region is also provided. The R_Key is part of each RDMA access and is used to validate that the remote process has permitted access to the buffer.","EFFICIENT PROCESS FOR HANDOVER BETWEEN SUBNET MANAGERS","The present invention makes use of the features described in the subject matter of U.S. Pat. No. 6,990,528 \u201cASSOCIATION OF END-TO-END CONTEXT VIA RELIABLE DATAGRAM DOMAINS\u201d filed on Oct. 19, 2000, the entire content of which is hereby incorporated by reference. The referenced application allows Reliable Datagram QPs to be used for communicating across multiple partitions. In SAN , QPs that support SAN Service Types are associated with a partition and cannot communicate to QPs that are outside of the partition to which the QP is associated. The QP is barred from communicating with QPs in another partition even if the node_s HCA port, which the QP uses, has access to different partitions. RD QPs, however, can communicate with any given partition the node_s HCA has access to, so long as there is an underlying End-End Context (EEC) which is associated with the given partition.","The present invention provides a method for seamlessly merging (i.e., linking or connecting) two independent subnets having separate subnet managers (SMs) into a single SAN  with a master SM selected from among the separate SMs. The invention utilizes time stamps and GUID addresses on SMDB entries as an aid for a Subnet Manager to efficiently absorb the SMDB of another subnet manager during the subnet management handover process.",{"@attributes":{"id":"p-0070","num":"0069"},"figref":["FIG. 8","FIG. 1A"],"b":["113","1","801","1","803","1","805","1","809","1","807","810","2","811","2","813","2","815","2","819","2","817","820","1","809","1","807","2","819","2","817","821","113","1","807","2","817"],"sub":"13 "},"When the two systems of  are initially merged, one of the two master subnet managers is relegated to a standby subnet manager, while the other SM becomes the master subnet manager of the new merged subnet (SAN ). Selection of the particular SM that becomes the master SM of the merged system may be dependent on priority values associated with each SM during their initial configuration. In a priority scheme, the SM with the highest priority is automatically selected as the master SM. The Priority value may be assigned by a subnet administrator when the subnet is initially configured. In the event that two SMs have been same priority value, then, in the preferred embodiment, the SM with the lowest GUID is selected to be the master subnet manager. During the handover process, the master subnet manager of the newly-formed merged network receives the SMDB of the other subnet manager, reconfigures the network or network components where necessary and takes over management of the total merged network.","The method utilized by the present invention to accomplish the seamless transfer of SMDB involves timestamping each SMDB with the time at which the last change was made in that SMDB. With this timestamp, the SM that is, accepting the handover can then determine the correct action to take in handling each entry as the SMDB(s) being taken over is being absorbed. Referring to , the process of time stamping entries in SMDB is illustrated. The process begins at block , and following, a determination is made whether there is a change to a Subnet Management Database at block . If not then the process loops back to . If there was a change, then the entry is time stamped with the time of the last change to the entry in that SMDB, and the process returns to block .","Referring now to , the process begins at block . Next, a determination is made at block  whether there is a merge of subnets occurring. If, however, a merge of subnets is occurring, the master subnet manager of the new subnet being formed by merging two or more subnets begins to example all entries of SMDBs with it's own SMDBb at block . As utilized herein, SMDBx refers to the database of subnets whose subnet managers are not selected as the master subnet manager when a merger of the subnets occurs. SMDBb refers to the database of the master subnet manager prior to merger of the database.","Returning to , a determination is made at block  whether the master subnet manager finds the same GUID entry in both SMDBx and SMBDb. If the same GUID entry is found, the master subnet manager keeps the one with the latest time stamp and discards the other at block . If, however, the same GUIDs are not found, the process moves to block .","Next a determination is made at block  whether all GUIDS have been examined in SMDBx. If not all the GUIDs have been examined then the process returns to block ; however, if all the GUIDs have been examined, the process moves to block , where a determination is made whether SMDBx has the same P_Key entries for different GUIDS as in SMDBb. If yes, then the master subnet manager will change all occurrences of the P_Key in SMDBx to a new unique P_Key value, which is different than that in either SMDBx or SMDBb at block . The process then moves to block . If the P_Key entries are not the same for SMDBx and SMDBb, then a determination is made at block  whether all entries in SMDBx have been examined. If all the entries have not been examined, the process returns to block . If all entries have been examined in SMDBx, then the SMDBx is merged with SMDBb at block . Next, a determination is made at block  whether there is another database to be merged with master subnet manager's SMBDb, and if so, the process returns to block . Otherwise, the process ends at block .","There may be other overlapping information in the respective databases that may need to be merged as described for the P_Keys and GUIDs above. These would follow a similar process as described in .","In the above detailed description of the preferred embodiments, reference is made to the accompanying drawings which form a part hereof, and in which is shown, by way of illustration, specific embodiments in which the invention may be practice. It is to be understood that other embodiments may be utilized and structural or logical changes may be made without departing from the scope of the present invention. For example, although the invention is described with reference to multiple computing nodes accessing a single database, the invention is applicable to all other transactions occurring on the network. The above detailed description, therefore, is not to be taken in a limiting sense, and the scope of the present invention is defined by the appended claims.","As a final matter, it is important to note that while an illustrative embodiment of the present invention has been, and will continue to be, described in the context of a fully functional data processing system, those skilled in the art will appreciate that the software aspects of an illustrative embodiment of the present invention are capable of being distributed as a program product in a way of forms, and that an illustrative embodiment of the present invention applies equally regardless of the particular type of signal bearing media used to actually carry out the distribution. Examples of signal bearing media include recordable type media such as floppy disks, hard disk drives, CD ROMs, and transmission type media such as digital and analogue communication links."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The novel features believed characteristic of the invention are set forth in the appended claims. The invention itself however, as well as a preferred mode of use, further objects and advantages thereof, will best be understood by reference to the following detailed description of an illustrative embodiment when read in conjunction with the accompanying drawings, wherein:",{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1B"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 9A"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 9B"}]},"DETDESC":[{},{}]}
